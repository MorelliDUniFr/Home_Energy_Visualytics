Using device: cuda

Run 1/72: hidden=128, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Coffee Machine
Dataset length: 36156 windows

Epoch [1/300], Train Loss: 0.001007
Validation Loss: 0.00094736
Epoch [2/300], Train Loss: 0.000982
Validation Loss: 0.00094260
Epoch [3/300], Train Loss: 0.000973
Validation Loss: 0.00093312
Epoch [4/300], Train Loss: 0.000964
Validation Loss: 0.00092341
Epoch [5/300], Train Loss: 0.000948
Validation Loss: 0.00090018
Epoch [6/300], Train Loss: 0.000912
Validation Loss: 0.00084542
Epoch [7/300], Train Loss: 0.000846
Validation Loss: 0.00078276
Epoch [8/300], Train Loss: 0.000781
Validation Loss: 0.00075787
Epoch [9/300], Train Loss: 0.000729
Validation Loss: 0.00070384
Epoch [10/300], Train Loss: 0.000691
Validation Loss: 0.00067632
Epoch [11/300], Train Loss: 0.000667
Validation Loss: 0.00065293
Epoch [12/300], Train Loss: 0.000650
Validation Loss: 0.00068399
Epoch [13/300], Train Loss: 0.000630
Validation Loss: 0.00062514
Epoch [14/300], Train Loss: 0.000608
Validation Loss: 0.00062399
Epoch [15/300], Train Loss: 0.000598
Validation Loss: 0.00060839
Epoch [16/300], Train Loss: 0.000589
Validation Loss: 0.00061830
Epoch [17/300], Train Loss: 0.000580
Validation Loss: 0.00059461
Epoch [18/300], Train Loss: 0.000594
Validation Loss: 0.00059403
Epoch [19/300], Train Loss: 0.000571
Validation Loss: 0.00058288
Epoch [20/300], Train Loss: 0.000561
Validation Loss: 0.00056095
Epoch [21/300], Train Loss: 0.000551
Validation Loss: 0.00055947
Epoch [22/300], Train Loss: 0.000549
Validation Loss: 0.00054794
Epoch [23/300], Train Loss: 0.000539
Validation Loss: 0.00054775
Epoch [24/300], Train Loss: 0.000535
Validation Loss: 0.00053662
Epoch [25/300], Train Loss: 0.000537
Validation Loss: 0.00054187
Epoch [26/300], Train Loss: 0.000525
Validation Loss: 0.00052048
Epoch [27/300], Train Loss: 0.000517
Validation Loss: 0.00052175
Epoch [28/300], Train Loss: 0.000513
Validation Loss: 0.00050956
Epoch [29/300], Train Loss: 0.000509
Validation Loss: 0.00050588
Epoch [30/300], Train Loss: 0.000503
Validation Loss: 0.00049798
Epoch [31/300], Train Loss: 0.000495
Validation Loss: 0.00050742
Epoch [32/300], Train Loss: 0.000492
Validation Loss: 0.00052961
Epoch [33/300], Train Loss: 0.000481
Validation Loss: 0.00047889
Epoch [34/300], Train Loss: 0.000482
Validation Loss: 0.00046955
Epoch [35/300], Train Loss: 0.000498
Validation Loss: 0.00048634
Epoch [36/300], Train Loss: 0.000474
Validation Loss: 0.00046803
Epoch [37/300], Train Loss: 0.000459
Validation Loss: 0.00044122
Epoch [38/300], Train Loss: 0.000444
Validation Loss: 0.00043430
Epoch [39/300], Train Loss: 0.000436
Validation Loss: 0.00040975
Epoch [40/300], Train Loss: 0.000418
Validation Loss: 0.00039505
Epoch [41/300], Train Loss: 0.000422
Validation Loss: 0.00041822
Epoch [42/300], Train Loss: 0.000411
Validation Loss: 0.00039289
Epoch [43/300], Train Loss: 0.000403
Validation Loss: 0.00037136
Epoch [44/300], Train Loss: 0.000391
Validation Loss: 0.00037484
Epoch [45/300], Train Loss: 0.000384
Validation Loss: 0.00035412
Epoch [46/300], Train Loss: 0.000375
Validation Loss: 0.00035636
Epoch [47/300], Train Loss: 0.000374
Validation Loss: 0.00034759
Epoch [48/300], Train Loss: 0.000366
Validation Loss: 0.00034036
Epoch [49/300], Train Loss: 0.000367
Validation Loss: 0.00032991
Epoch [50/300], Train Loss: 0.000358
Validation Loss: 0.00032724
Epoch [51/300], Train Loss: 0.000351
Validation Loss: 0.00033084
Epoch [52/300], Train Loss: 0.000349
Validation Loss: 0.00031563
Epoch [53/300], Train Loss: 0.000346
Validation Loss: 0.00031335
Epoch [54/300], Train Loss: 0.000340
Validation Loss: 0.00031361
Epoch [55/300], Train Loss: 0.000336
Validation Loss: 0.00030542
Epoch [56/300], Train Loss: 0.000335
Validation Loss: 0.00030440
Epoch [57/300], Train Loss: 0.000328
Validation Loss: 0.00029797
Epoch [58/300], Train Loss: 0.000326
Validation Loss: 0.00030795
Epoch [59/300], Train Loss: 0.000327
Validation Loss: 0.00028773
Epoch [60/300], Train Loss: 0.000321
Validation Loss: 0.00029099
Epoch [61/300], Train Loss: 0.000319
Validation Loss: 0.00028637
Epoch [62/300], Train Loss: 0.000316
Validation Loss: 0.00028398
Epoch [63/300], Train Loss: 0.000311
Validation Loss: 0.00027842
Epoch [64/300], Train Loss: 0.000308
Validation Loss: 0.00027587
Epoch [65/300], Train Loss: 0.000305
Validation Loss: 0.00028135
Epoch [66/300], Train Loss: 0.000303
Validation Loss: 0.00026919
Epoch [67/300], Train Loss: 0.000299
Validation Loss: 0.00026704
Epoch [68/300], Train Loss: 0.000301
Validation Loss: 0.00027279
Epoch [69/300], Train Loss: 0.000297
Validation Loss: 0.00026507
Epoch [70/300], Train Loss: 0.000293
Validation Loss: 0.00027878
Epoch [71/300], Train Loss: 0.000289
Validation Loss: 0.00026161
Epoch [72/300], Train Loss: 0.000288
Validation Loss: 0.00026444
Epoch [73/300], Train Loss: 0.000287
Validation Loss: 0.00025940
Epoch [74/300], Train Loss: 0.000285
Validation Loss: 0.00025253
Epoch [75/300], Train Loss: 0.000286
Validation Loss: 0.00025252
Epoch [76/300], Train Loss: 0.000282
Validation Loss: 0.00026080
Epoch [77/300], Train Loss: 0.000278
Validation Loss: 0.00024891
Epoch [78/300], Train Loss: 0.000275
Validation Loss: 0.00024845
Epoch [79/300], Train Loss: 0.000276
Validation Loss: 0.00025176
Epoch [80/300], Train Loss: 0.000273
Validation Loss: 0.00024588
Epoch [81/300], Train Loss: 0.000275
Validation Loss: 0.00025205
Epoch [82/300], Train Loss: 0.000271
Validation Loss: 0.00024711
Epoch [83/300], Train Loss: 0.000269
Validation Loss: 0.00024227
Epoch [84/300], Train Loss: 0.000267
Validation Loss: 0.00024537
Epoch [85/300], Train Loss: 0.000266
Validation Loss: 0.00024203
Epoch [86/300], Train Loss: 0.000263
Validation Loss: 0.00024428
Epoch [87/300], Train Loss: 0.000264
Validation Loss: 0.00024028
Epoch [88/300], Train Loss: 0.000263
Validation Loss: 0.00024274
Epoch [89/300], Train Loss: 0.000264
Validation Loss: 0.00023466
Epoch [90/300], Train Loss: 0.000259
Validation Loss: 0.00023841
Epoch [91/300], Train Loss: 0.000259
Validation Loss: 0.00023235
Epoch [92/300], Train Loss: 0.000257
Validation Loss: 0.00023170
Epoch [93/300], Train Loss: 0.000254
Validation Loss: 0.00023312
Epoch [94/300], Train Loss: 0.000253
Validation Loss: 0.00023686
Epoch [95/300], Train Loss: 0.000256
Validation Loss: 0.00023146
Epoch [96/300], Train Loss: 0.000252
Validation Loss: 0.00022497
Epoch [97/300], Train Loss: 0.000249
Validation Loss: 0.00022472
Epoch [98/300], Train Loss: 0.000248
Validation Loss: 0.00024391
Epoch [99/300], Train Loss: 0.000251
Validation Loss: 0.00022892
Epoch [100/300], Train Loss: 0.000247
Validation Loss: 0.00023250
Epoch [101/300], Train Loss: 0.000248
Validation Loss: 0.00022807
Epoch [102/300], Train Loss: 0.000244
Validation Loss: 0.00022902
Epoch [103/300], Train Loss: 0.000245
Validation Loss: 0.00022185
Epoch [104/300], Train Loss: 0.000243
Validation Loss: 0.00022133
Epoch [105/300], Train Loss: 0.000241
Validation Loss: 0.00022680
Epoch [106/300], Train Loss: 0.000238
Validation Loss: 0.00022350
Epoch [107/300], Train Loss: 0.000239
Validation Loss: 0.00021496
Epoch [108/300], Train Loss: 0.000241
Validation Loss: 0.00022494
Epoch [109/300], Train Loss: 0.000238
Validation Loss: 0.00021396
Epoch [110/300], Train Loss: 0.000238
Validation Loss: 0.00021313
Epoch [111/300], Train Loss: 0.000233
Validation Loss: 0.00021114
Epoch [112/300], Train Loss: 0.000235
Validation Loss: 0.00021566
Epoch [113/300], Train Loss: 0.000233
Validation Loss: 0.00021603
Epoch [114/300], Train Loss: 0.000231
Validation Loss: 0.00021232
Epoch [115/300], Train Loss: 0.000244
Validation Loss: 0.00020946
Epoch [116/300], Train Loss: 0.000230
Validation Loss: 0.00020623
Epoch [117/300], Train Loss: 0.000228
Validation Loss: 0.00020672
Epoch [118/300], Train Loss: 0.000229
Validation Loss: 0.00020507
Epoch [119/300], Train Loss: 0.000228
Validation Loss: 0.00020311
Epoch [120/300], Train Loss: 0.000230
Validation Loss: 0.00021109
Epoch [121/300], Train Loss: 0.000225
Validation Loss: 0.00020093
Epoch [122/300], Train Loss: 0.000225
Validation Loss: 0.00020126
Epoch [123/300], Train Loss: 0.000224
Validation Loss: 0.00020705
Epoch [124/300], Train Loss: 0.000223
Validation Loss: 0.00020417
Epoch [125/300], Train Loss: 0.000224
Validation Loss: 0.00020399
Epoch [126/300], Train Loss: 0.000224
Validation Loss: 0.00019731
Epoch [127/300], Train Loss: 0.000219
Validation Loss: 0.00019830
Epoch [128/300], Train Loss: 0.000220
Validation Loss: 0.00020327
Epoch [129/300], Train Loss: 0.000220
Validation Loss: 0.00019881
Epoch [130/300], Train Loss: 0.000219
Validation Loss: 0.00019360
Epoch [131/300], Train Loss: 0.000219
Validation Loss: 0.00019504
Epoch [132/300], Train Loss: 0.000252
Validation Loss: 0.00020398
Epoch [133/300], Train Loss: 0.000220
Validation Loss: 0.00020115
Epoch [134/300], Train Loss: 0.000216
Validation Loss: 0.00019457
Epoch [135/300], Train Loss: 0.000215
Validation Loss: 0.00019895
Epoch [136/300], Train Loss: 0.000217
Validation Loss: 0.00020953
Epoch [137/300], Train Loss: 0.000213
Validation Loss: 0.00019405
Epoch [138/300], Train Loss: 0.000212
Validation Loss: 0.00019075
Epoch [139/300], Train Loss: 0.000233
Validation Loss: 0.00023847
Epoch [140/300], Train Loss: 0.000236
Validation Loss: 0.00020170
Epoch [141/300], Train Loss: 0.000220
Validation Loss: 0.00019173
Epoch [142/300], Train Loss: 0.000213
Validation Loss: 0.00019089
Epoch [143/300], Train Loss: 0.000213
Validation Loss: 0.00019047
Epoch [144/300], Train Loss: 0.000212
Validation Loss: 0.00018813
Epoch [145/300], Train Loss: 0.000210
Validation Loss: 0.00018999
Epoch [146/300], Train Loss: 0.000210
Validation Loss: 0.00018774
Epoch [147/300], Train Loss: 0.000209
Validation Loss: 0.00018619
Epoch [148/300], Train Loss: 0.000208
Validation Loss: 0.00018538
Epoch [149/300], Train Loss: 0.000207
Validation Loss: 0.00018848
Epoch [150/300], Train Loss: 0.000207
Validation Loss: 0.00018795
Epoch [151/300], Train Loss: 0.000207
Validation Loss: 0.00018759
Epoch [152/300], Train Loss: 0.000207
Validation Loss: 0.00018381
Epoch [153/300], Train Loss: 0.000206
Validation Loss: 0.00018711
Epoch [154/300], Train Loss: 0.000206
Validation Loss: 0.00018863
Epoch [155/300], Train Loss: 0.000206
Validation Loss: 0.00018538
Epoch [156/300], Train Loss: 0.000206
Validation Loss: 0.00018442
Epoch [157/300], Train Loss: 0.000204
Validation Loss: 0.00018843
Epoch [158/300], Train Loss: 0.000204
Validation Loss: 0.00019564
Epoch [159/300], Train Loss: 0.000203
Validation Loss: 0.00018653
Epoch [160/300], Train Loss: 0.000205
Validation Loss: 0.00018560
Epoch [161/300], Train Loss: 0.000201
Validation Loss: 0.00018007
Epoch [162/300], Train Loss: 0.000200
Validation Loss: 0.00018395
Epoch [163/300], Train Loss: 0.000201
Validation Loss: 0.00018694
Epoch [164/300], Train Loss: 0.000200
Validation Loss: 0.00018432
Epoch [165/300], Train Loss: 0.000202
Validation Loss: 0.00018357
Epoch [166/300], Train Loss: 0.000197
Validation Loss: 0.00018450
Epoch [167/300], Train Loss: 0.000205
Validation Loss: 0.00018591
Epoch [168/300], Train Loss: 0.000203
Validation Loss: 0.00018314
Epoch [169/300], Train Loss: 0.000200
Validation Loss: 0.00017921
Epoch [170/300], Train Loss: 0.000200
Validation Loss: 0.00018486
Epoch [171/300], Train Loss: 0.000199
Validation Loss: 0.00018098
Epoch [172/300], Train Loss: 0.000199
Validation Loss: 0.00018036
Epoch [173/300], Train Loss: 0.000199
Validation Loss: 0.00017721
Epoch [174/300], Train Loss: 0.000198
Validation Loss: 0.00017680
Epoch [175/300], Train Loss: 0.000200
Validation Loss: 0.00018591
Epoch [176/300], Train Loss: 0.000197
Validation Loss: 0.00018487
Epoch [177/300], Train Loss: 0.000195
Validation Loss: 0.00018917
Epoch [178/300], Train Loss: 0.000195
Validation Loss: 0.00017853
Epoch [179/300], Train Loss: 0.000197
Validation Loss: 0.00017482
Epoch [180/300], Train Loss: 0.000200
Validation Loss: 0.00017881
Epoch [181/300], Train Loss: 0.000195
Validation Loss: 0.00018217
Epoch [182/300], Train Loss: 0.000194
Validation Loss: 0.00017549
Epoch [183/300], Train Loss: 0.000194
Validation Loss: 0.00017626
Epoch [184/300], Train Loss: 0.000195
Validation Loss: 0.00017383
Epoch [185/300], Train Loss: 0.000194
Validation Loss: 0.00017623
Epoch [186/300], Train Loss: 0.000193
Validation Loss: 0.00017400
Epoch [187/300], Train Loss: 0.000194
Validation Loss: 0.00017265
Epoch [188/300], Train Loss: 0.000192
Validation Loss: 0.00017098
Epoch [189/300], Train Loss: 0.000193
Validation Loss: 0.00017200
Epoch [190/300], Train Loss: 0.000192
Validation Loss: 0.00017144
Epoch [191/300], Train Loss: 0.000193
Validation Loss: 0.00017347
Epoch [192/300], Train Loss: 0.000191
Validation Loss: 0.00017066
Epoch [193/300], Train Loss: 0.000192
Validation Loss: 0.00017204
Epoch [194/300], Train Loss: 0.000191
Validation Loss: 0.00017232
Epoch [195/300], Train Loss: 0.000191
Validation Loss: 0.00018471
Epoch [196/300], Train Loss: 0.000205
Validation Loss: 0.00017509
Epoch [197/300], Train Loss: 0.000191
Validation Loss: 0.00016991
Epoch [198/300], Train Loss: 0.000189
Validation Loss: 0.00017052
Epoch [199/300], Train Loss: 0.000189
Validation Loss: 0.00017013
Epoch [200/300], Train Loss: 0.000187
Validation Loss: 0.00017051
Epoch [201/300], Train Loss: 0.000186
Validation Loss: 0.00017106
Epoch [202/300], Train Loss: 0.000186
Validation Loss: 0.00017233
Epoch [203/300], Train Loss: 0.000188
Validation Loss: 0.00017442
Epoch [204/300], Train Loss: 0.000186
Validation Loss: 0.00017362
Epoch [205/300], Train Loss: 0.000185
Validation Loss: 0.00017242
Epoch [206/300], Train Loss: 0.000184
Validation Loss: 0.00017511
Epoch [207/300], Train Loss: 0.000185
Validation Loss: 0.00016906
Epoch [208/300], Train Loss: 0.000184
Validation Loss: 0.00016681
Epoch [209/300], Train Loss: 0.000183
Validation Loss: 0.00016876
Epoch [210/300], Train Loss: 0.000185
Validation Loss: 0.00016517
Epoch [211/300], Train Loss: 0.000190
Validation Loss: 0.00018892
Epoch [212/300], Train Loss: 0.000194
Validation Loss: 0.00016889
Epoch [213/300], Train Loss: 0.000183
Validation Loss: 0.00016918
Epoch [214/300], Train Loss: 0.000181
Validation Loss: 0.00016592
Epoch [215/300], Train Loss: 0.000182
Validation Loss: 0.00016569
Epoch [216/300], Train Loss: 0.000182
Validation Loss: 0.00016672
Epoch [217/300], Train Loss: 0.000182
Validation Loss: 0.00017167
Epoch [218/300], Train Loss: 0.000181
Validation Loss: 0.00016546
Epoch [219/300], Train Loss: 0.000182
Validation Loss: 0.00016384
Epoch [220/300], Train Loss: 0.000181
Validation Loss: 0.00017794
Epoch [221/300], Train Loss: 0.000183
Validation Loss: 0.00016485
Epoch [222/300], Train Loss: 0.000181
Validation Loss: 0.00016584
Epoch [223/300], Train Loss: 0.000180
Validation Loss: 0.00017908
Epoch [224/300], Train Loss: 0.000182
Validation Loss: 0.00016357
Epoch [225/300], Train Loss: 0.000180
Validation Loss: 0.00016331
Epoch [226/300], Train Loss: 0.000182
Validation Loss: 0.00016415
Epoch [227/300], Train Loss: 0.000179
Validation Loss: 0.00016332
Epoch [228/300], Train Loss: 0.000179
Validation Loss: 0.00016349
Epoch [229/300], Train Loss: 0.000178
Validation Loss: 0.00016221
Epoch [230/300], Train Loss: 0.000179
Validation Loss: 0.00016355
Epoch [231/300], Train Loss: 0.000178
Validation Loss: 0.00016159
Epoch [232/300], Train Loss: 0.000183
Validation Loss: 0.00017969
Epoch [233/300], Train Loss: 0.000178
Validation Loss: 0.00016602
Epoch [234/300], Train Loss: 0.000178
Validation Loss: 0.00016486
Epoch [235/300], Train Loss: 0.000177
Validation Loss: 0.00016799
Epoch [236/300], Train Loss: 0.000176
Validation Loss: 0.00016587
Epoch [237/300], Train Loss: 0.000177
Validation Loss: 0.00016687
Epoch [238/300], Train Loss: 0.000176
Validation Loss: 0.00016480
Epoch [239/300], Train Loss: 0.000179
Validation Loss: 0.00016292
Epoch [240/300], Train Loss: 0.000178
Validation Loss: 0.00016224
Epoch [241/300], Train Loss: 0.000176
Validation Loss: 0.00016060
Epoch [242/300], Train Loss: 0.000176
Validation Loss: 0.00016224
Epoch [243/300], Train Loss: 0.000177
Validation Loss: 0.00015982
Epoch [244/300], Train Loss: 0.000177
Validation Loss: 0.00016111
Epoch [245/300], Train Loss: 0.000175
Validation Loss: 0.00016329
Epoch [246/300], Train Loss: 0.000177
Validation Loss: 0.00017629
Epoch [247/300], Train Loss: 0.000174
Validation Loss: 0.00016226
Epoch [248/300], Train Loss: 0.000174
Validation Loss: 0.00017148
Epoch [249/300], Train Loss: 0.000175
Validation Loss: 0.00017347
Epoch [250/300], Train Loss: 0.000176
Validation Loss: 0.00016492
Epoch [251/300], Train Loss: 0.000175
Validation Loss: 0.00016511
Epoch [252/300], Train Loss: 0.000175
Validation Loss: 0.00016179
Epoch [253/300], Train Loss: 0.000175
Validation Loss: 0.00016186
Early stopping triggered

Evaluating model for: Coffee Machine
Run 1/72 completed in 11926.58 seconds with: {'MAE': np.float32(3.1200662), 'MSE': np.float32(792.6035), 'RMSE': np.float32(28.153215), 'SAE': np.float32(0.0048294486), 'NDE': np.float32(0.45488802)}

Run 2/72: hidden=128, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Coffee Machine
Dataset length: 36156 windows

Epoch [1/300], Train Loss: 0.001056
Validation Loss: 0.00095909
Epoch [2/300], Train Loss: 0.000997
Validation Loss: 0.00095373
Epoch [3/300], Train Loss: 0.000989
Validation Loss: 0.00094890
Epoch [4/300], Train Loss: 0.000983
Validation Loss: 0.00094600
Epoch [5/300], Train Loss: 0.000974
Validation Loss: 0.00092976
Epoch [6/300], Train Loss: 0.000953
Validation Loss: 0.00090131
Epoch [7/300], Train Loss: 0.000892
Validation Loss: 0.00080005
Epoch [8/300], Train Loss: 0.000782
Validation Loss: 0.00074443
Epoch [9/300], Train Loss: 0.000724
Validation Loss: 0.00070105
Epoch [10/300], Train Loss: 0.000688
Validation Loss: 0.00068373
Epoch [11/300], Train Loss: 0.000661
Validation Loss: 0.00064564
Epoch [12/300], Train Loss: 0.000634
Validation Loss: 0.00067028
Epoch [13/300], Train Loss: 0.000612
Validation Loss: 0.00060054
Epoch [14/300], Train Loss: 0.000598
Validation Loss: 0.00062005
Epoch [15/300], Train Loss: 0.000574
Validation Loss: 0.00057287
Epoch [16/300], Train Loss: 0.000572
Validation Loss: 0.00058129
Epoch [17/300], Train Loss: 0.000558
Validation Loss: 0.00057469
Epoch [18/300], Train Loss: 0.000545
Validation Loss: 0.00057106
Epoch [19/300], Train Loss: 0.000549
Validation Loss: 0.00061637
Epoch [20/300], Train Loss: 0.000572
Validation Loss: 0.00056312
Epoch [21/300], Train Loss: 0.000538
Validation Loss: 0.00055312
Epoch [22/300], Train Loss: 0.000530
Validation Loss: 0.00054119
Epoch [23/300], Train Loss: 0.000524
Validation Loss: 0.00053236
Epoch [24/300], Train Loss: 0.000521
Validation Loss: 0.00052172
Epoch [25/300], Train Loss: 0.000511
Validation Loss: 0.00052474
Epoch [26/300], Train Loss: 0.000509
Validation Loss: 0.00051258
Epoch [27/300], Train Loss: 0.000507
Validation Loss: 0.00049976
Epoch [28/300], Train Loss: 0.000496
Validation Loss: 0.00050996
Epoch [29/300], Train Loss: 0.000495
Validation Loss: 0.00049298
Epoch [30/300], Train Loss: 0.000488
Validation Loss: 0.00050216
Epoch [31/300], Train Loss: 0.000494
Validation Loss: 0.00050154
Epoch [32/300], Train Loss: 0.000490
Validation Loss: 0.00048397
Epoch [33/300], Train Loss: 0.000478
Validation Loss: 0.00046249
Epoch [34/300], Train Loss: 0.000473
Validation Loss: 0.00046401
Epoch [35/300], Train Loss: 0.000465
Validation Loss: 0.00045574
Epoch [36/300], Train Loss: 0.000460
Validation Loss: 0.00044814
Epoch [37/300], Train Loss: 0.000453
Validation Loss: 0.00043902
Epoch [38/300], Train Loss: 0.000450
Validation Loss: 0.00043913
Epoch [39/300], Train Loss: 0.000440
Validation Loss: 0.00042377
Epoch [40/300], Train Loss: 0.000435
Validation Loss: 0.00041370
Epoch [41/300], Train Loss: 0.000448
Validation Loss: 0.00041399
Epoch [42/300], Train Loss: 0.000427
Validation Loss: 0.00040066
Epoch [43/300], Train Loss: 0.000422
Validation Loss: 0.00038575
Epoch [44/300], Train Loss: 0.000415
Validation Loss: 0.00039886
Epoch [45/300], Train Loss: 0.000405
Validation Loss: 0.00036326
Epoch [46/300], Train Loss: 0.000388
Validation Loss: 0.00035939
Epoch [47/300], Train Loss: 0.000384
Validation Loss: 0.00035367
Epoch [48/300], Train Loss: 0.000378
Validation Loss: 0.00033740
Epoch [49/300], Train Loss: 0.000366
Validation Loss: 0.00033752
Epoch [50/300], Train Loss: 0.000356
Validation Loss: 0.00032228
Epoch [51/300], Train Loss: 0.000350
Validation Loss: 0.00031753
Epoch [52/300], Train Loss: 0.000344
Validation Loss: 0.00029686
Epoch [53/300], Train Loss: 0.000358
Validation Loss: 0.00032837
Epoch [54/300], Train Loss: 0.000335
Validation Loss: 0.00030461
Epoch [55/300], Train Loss: 0.000330
Validation Loss: 0.00029238
Epoch [56/300], Train Loss: 0.000325
Validation Loss: 0.00029125
Epoch [57/300], Train Loss: 0.000319
Validation Loss: 0.00028362
Epoch [58/300], Train Loss: 0.000312
Validation Loss: 0.00028409
Epoch [59/300], Train Loss: 0.000313
Validation Loss: 0.00026991
Epoch [60/300], Train Loss: 0.000309
Validation Loss: 0.00027071
Epoch [61/300], Train Loss: 0.000302
Validation Loss: 0.00029809
Epoch [62/300], Train Loss: 0.000309
Validation Loss: 0.00026484
Epoch [63/300], Train Loss: 0.000294
Validation Loss: 0.00025712
Epoch [64/300], Train Loss: 0.000298
Validation Loss: 0.00025497
Epoch [65/300], Train Loss: 0.000288
Validation Loss: 0.00026736
Epoch [66/300], Train Loss: 0.000289
Validation Loss: 0.00026439
Epoch [67/300], Train Loss: 0.000283
Validation Loss: 0.00026106
Epoch [68/300], Train Loss: 0.000281
Validation Loss: 0.00024410
Epoch [69/300], Train Loss: 0.000281
Validation Loss: 0.00024362
Epoch [70/300], Train Loss: 0.000277
Validation Loss: 0.00024477
Epoch [71/300], Train Loss: 0.000274
Validation Loss: 0.00023372
Epoch [72/300], Train Loss: 0.000277
Validation Loss: 0.00024579
Epoch [73/300], Train Loss: 0.000283
Validation Loss: 0.00024591
Epoch [74/300], Train Loss: 0.000268
Validation Loss: 0.00023171
Epoch [75/300], Train Loss: 0.000266
Validation Loss: 0.00024005
Epoch [76/300], Train Loss: 0.000264
Validation Loss: 0.00023073
Epoch [77/300], Train Loss: 0.000265
Validation Loss: 0.00023011
Epoch [78/300], Train Loss: 0.000259
Validation Loss: 0.00023331
Epoch [79/300], Train Loss: 0.000257
Validation Loss: 0.00022790
Epoch [80/300], Train Loss: 0.000253
Validation Loss: 0.00022662
Epoch [81/300], Train Loss: 0.000254
Validation Loss: 0.00022610
Epoch [82/300], Train Loss: 0.000257
Validation Loss: 0.00022165
Epoch [83/300], Train Loss: 0.000251
Validation Loss: 0.00022435
Epoch [84/300], Train Loss: 0.000257
Validation Loss: 0.00021825
Epoch [85/300], Train Loss: 0.000249
Validation Loss: 0.00021492
Epoch [86/300], Train Loss: 0.000250
Validation Loss: 0.00021169
Epoch [87/300], Train Loss: 0.000247
Validation Loss: 0.00021851
Epoch [88/300], Train Loss: 0.000243
Validation Loss: 0.00022310
Epoch [89/300], Train Loss: 0.000249
Validation Loss: 0.00022328
Epoch [90/300], Train Loss: 0.000245
Validation Loss: 0.00021364
Epoch [91/300], Train Loss: 0.000262
Validation Loss: 0.00025807
Epoch [92/300], Train Loss: 0.000252
Validation Loss: 0.00021790
Epoch [93/300], Train Loss: 0.000241
Validation Loss: 0.00021102
Epoch [94/300], Train Loss: 0.000237
Validation Loss: 0.00022347
Epoch [95/300], Train Loss: 0.000236
Validation Loss: 0.00021098
Epoch [96/300], Train Loss: 0.000234
Validation Loss: 0.00021319
Epoch [97/300], Train Loss: 0.000231
Validation Loss: 0.00020696
Epoch [98/300], Train Loss: 0.000238
Validation Loss: 0.00022455
Epoch [99/300], Train Loss: 0.000234
Validation Loss: 0.00020889
Epoch [100/300], Train Loss: 0.000230
Validation Loss: 0.00022192
Epoch [101/300], Train Loss: 0.000232
Validation Loss: 0.00021541
Epoch [102/300], Train Loss: 0.000231
Validation Loss: 0.00021175
Epoch [103/300], Train Loss: 0.000233
Validation Loss: 0.00020288
Epoch [104/300], Train Loss: 0.000234
Validation Loss: 0.00020307
Epoch [105/300], Train Loss: 0.000225
Validation Loss: 0.00020197
Epoch [106/300], Train Loss: 0.000224
Validation Loss: 0.00020331
Epoch [107/300], Train Loss: 0.000225
Validation Loss: 0.00019601
Epoch [108/300], Train Loss: 0.000229
Validation Loss: 0.00022418
Epoch [109/300], Train Loss: 0.000230
Validation Loss: 0.00020519
Epoch [110/300], Train Loss: 0.000225
Validation Loss: 0.00020538
Epoch [111/300], Train Loss: 0.000220
Validation Loss: 0.00022199
Epoch [112/300], Train Loss: 0.000227
Validation Loss: 0.00019834
Epoch [113/300], Train Loss: 0.000221
Validation Loss: 0.00019740
Epoch [114/300], Train Loss: 0.000219
Validation Loss: 0.00019680
Epoch [115/300], Train Loss: 0.000237
Validation Loss: 0.00021025
Epoch [116/300], Train Loss: 0.000221
Validation Loss: 0.00019359
Epoch [117/300], Train Loss: 0.000217
Validation Loss: 0.00019952
Epoch [118/300], Train Loss: 0.000217
Validation Loss: 0.00019743
Epoch [119/300], Train Loss: 0.000218
Validation Loss: 0.00020381
Epoch [120/300], Train Loss: 0.000216
Validation Loss: 0.00020155
Epoch [121/300], Train Loss: 0.000213
Validation Loss: 0.00019651
Epoch [122/300], Train Loss: 0.000212
Validation Loss: 0.00019725
Epoch [123/300], Train Loss: 0.000211
Validation Loss: 0.00019854
Epoch [124/300], Train Loss: 0.000215
Validation Loss: 0.00019598
Epoch [125/300], Train Loss: 0.000216
Validation Loss: 0.00018874
Epoch [126/300], Train Loss: 0.000210
Validation Loss: 0.00018978
Epoch [127/300], Train Loss: 0.000216
Validation Loss: 0.00019591
Epoch [128/300], Train Loss: 0.000208
Validation Loss: 0.00019510
Epoch [129/300], Train Loss: 0.000207
Validation Loss: 0.00018809
Epoch [130/300], Train Loss: 0.000205
Validation Loss: 0.00019418
Epoch [131/300], Train Loss: 0.000205
Validation Loss: 0.00018753
Epoch [132/300], Train Loss: 0.000208
Validation Loss: 0.00019944
Epoch [133/300], Train Loss: 0.000205
Validation Loss: 0.00018957
Epoch [134/300], Train Loss: 0.000203
Validation Loss: 0.00018964
Epoch [135/300], Train Loss: 0.000202
Validation Loss: 0.00018895
Epoch [136/300], Train Loss: 0.000201
Validation Loss: 0.00018121
Epoch [137/300], Train Loss: 0.000201
Validation Loss: 0.00018951
Epoch [138/300], Train Loss: 0.000200
Validation Loss: 0.00017685
Epoch [139/300], Train Loss: 0.000199
Validation Loss: 0.00018320
Epoch [140/300], Train Loss: 0.000199
Validation Loss: 0.00017822
Epoch [141/300], Train Loss: 0.000198
Validation Loss: 0.00018264
Epoch [142/300], Train Loss: 0.000199
Validation Loss: 0.00018677
Epoch [143/300], Train Loss: 0.000197
Validation Loss: 0.00018817
Epoch [144/300], Train Loss: 0.000203
Validation Loss: 0.00017673
Epoch [145/300], Train Loss: 0.000197
Validation Loss: 0.00018524
Epoch [146/300], Train Loss: 0.000199
Validation Loss: 0.00018364
Epoch [147/300], Train Loss: 0.000193
Validation Loss: 0.00018845
Epoch [148/300], Train Loss: 0.000191
Validation Loss: 0.00017560
Epoch [149/300], Train Loss: 0.000193
Validation Loss: 0.00018061
Epoch [150/300], Train Loss: 0.000192
Validation Loss: 0.00017623
Epoch [151/300], Train Loss: 0.000192
Validation Loss: 0.00017270
Epoch [152/300], Train Loss: 0.000190
Validation Loss: 0.00017691
Epoch [153/300], Train Loss: 0.000191
Validation Loss: 0.00017605
Epoch [154/300], Train Loss: 0.000192
Validation Loss: 0.00018670
Epoch [155/300], Train Loss: 0.000189
Validation Loss: 0.00017370
Epoch [156/300], Train Loss: 0.000188
Validation Loss: 0.00017040
Epoch [157/300], Train Loss: 0.000188
Validation Loss: 0.00022993
Epoch [158/300], Train Loss: 0.000195
Validation Loss: 0.00016825
Epoch [159/300], Train Loss: 0.000187
Validation Loss: 0.00018078
Epoch [160/300], Train Loss: 0.000186
Validation Loss: 0.00018427
Epoch [161/300], Train Loss: 0.000187
Validation Loss: 0.00017171
Epoch [162/300], Train Loss: 0.000185
Validation Loss: 0.00016886
Epoch [163/300], Train Loss: 0.000184
Validation Loss: 0.00018993
Epoch [164/300], Train Loss: 0.000185
Validation Loss: 0.00017449
Epoch [165/300], Train Loss: 0.000183
Validation Loss: 0.00016977
Epoch [166/300], Train Loss: 0.000183
Validation Loss: 0.00017613
Epoch [167/300], Train Loss: 0.000184
Validation Loss: 0.00017919
Epoch [168/300], Train Loss: 0.000184
Validation Loss: 0.00017941
Early stopping triggered

Evaluating model for: Coffee Machine
Run 2/72 completed in 8209.40 seconds with: {'MAE': np.float32(2.7671096), 'MSE': np.float32(751.1468), 'RMSE': np.float32(27.407057), 'SAE': np.float32(0.18288855), 'NDE': np.float32(0.44283032)}

Run 3/72: hidden=128, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Coffee Machine
Dataset length: 36156 windows

Epoch [1/300], Train Loss: 0.000991
Validation Loss: 0.00094923
Epoch [2/300], Train Loss: 0.000982
Validation Loss: 0.00094831
Epoch [3/300], Train Loss: 0.000980
Validation Loss: 0.00094571
Epoch [4/300], Train Loss: 0.000975
Validation Loss: 0.00093757
Epoch [5/300], Train Loss: 0.000964
Validation Loss: 0.00091787
Epoch [6/300], Train Loss: 0.000915
Validation Loss: 0.00082570
Epoch [7/300], Train Loss: 0.000786
Validation Loss: 0.00072643
Epoch [8/300], Train Loss: 0.000704
Validation Loss: 0.00068544
Epoch [9/300], Train Loss: 0.000660
Validation Loss: 0.00065402
Epoch [10/300], Train Loss: 0.000640
Validation Loss: 0.00062600
Epoch [11/300], Train Loss: 0.000609
Validation Loss: 0.00059935
Epoch [12/300], Train Loss: 0.000594
Validation Loss: 0.00062518
Epoch [13/300], Train Loss: 0.000572
Validation Loss: 0.00057497
Epoch [14/300], Train Loss: 0.000566
Validation Loss: 0.00057846
Epoch [15/300], Train Loss: 0.000554
Validation Loss: 0.00054061
Epoch [16/300], Train Loss: 0.000544
Validation Loss: 0.00056602
Epoch [17/300], Train Loss: 0.000536
Validation Loss: 0.00055570
Epoch [18/300], Train Loss: 0.000525
Validation Loss: 0.00054555
Epoch [19/300], Train Loss: 0.000514
Validation Loss: 0.00054814
Epoch [20/300], Train Loss: 0.000508
Validation Loss: 0.00049320
Epoch [21/300], Train Loss: 0.000496
Validation Loss: 0.00047280
Epoch [22/300], Train Loss: 0.000489
Validation Loss: 0.00045676
Epoch [23/300], Train Loss: 0.000485
Validation Loss: 0.00045665
Epoch [24/300], Train Loss: 0.000476
Validation Loss: 0.00044338
Epoch [25/300], Train Loss: 0.000463
Validation Loss: 0.00042997
Epoch [26/300], Train Loss: 0.000471
Validation Loss: 0.00045574
Epoch [27/300], Train Loss: 0.000456
Validation Loss: 0.00043001
Epoch [28/300], Train Loss: 0.000437
Validation Loss: 0.00042425
Epoch [29/300], Train Loss: 0.000432
Validation Loss: 0.00041934
Epoch [30/300], Train Loss: 0.000419
Validation Loss: 0.00040024
Epoch [31/300], Train Loss: 0.000406
Validation Loss: 0.00038847
Epoch [32/300], Train Loss: 0.000400
Validation Loss: 0.00040646
Epoch [33/300], Train Loss: 0.000390
Validation Loss: 0.00036592
Epoch [34/300], Train Loss: 0.000380
Validation Loss: 0.00037039
Epoch [35/300], Train Loss: 0.000372
Validation Loss: 0.00035566
Epoch [36/300], Train Loss: 0.000366
Validation Loss: 0.00034917
Epoch [37/300], Train Loss: 0.000360
Validation Loss: 0.00034383
Epoch [38/300], Train Loss: 0.000350
Validation Loss: 0.00033729
Epoch [39/300], Train Loss: 0.000342
Validation Loss: 0.00032711
Epoch [40/300], Train Loss: 0.000340
Validation Loss: 0.00032782
Epoch [41/300], Train Loss: 0.000334
Validation Loss: 0.00032605
Epoch [42/300], Train Loss: 0.000333
Validation Loss: 0.00031423
Epoch [43/300], Train Loss: 0.000324
Validation Loss: 0.00031293
Epoch [44/300], Train Loss: 0.000323
Validation Loss: 0.00032842
Epoch [45/300], Train Loss: 0.000318
Validation Loss: 0.00030194
Epoch [46/300], Train Loss: 0.000309
Validation Loss: 0.00030064
Epoch [47/300], Train Loss: 0.000309
Validation Loss: 0.00029840
Epoch [48/300], Train Loss: 0.000303
Validation Loss: 0.00029827
Epoch [49/300], Train Loss: 0.000304
Validation Loss: 0.00028523
Epoch [50/300], Train Loss: 0.000298
Validation Loss: 0.00029334
Epoch [51/300], Train Loss: 0.000296
Validation Loss: 0.00029271
Epoch [52/300], Train Loss: 0.000292
Validation Loss: 0.00028037
Epoch [53/300], Train Loss: 0.000289
Validation Loss: 0.00027305
Epoch [54/300], Train Loss: 0.000291
Validation Loss: 0.00028518
Epoch [55/300], Train Loss: 0.000287
Validation Loss: 0.00027459
Epoch [56/300], Train Loss: 0.000284
Validation Loss: 0.00027421
Epoch [57/300], Train Loss: 0.000277
Validation Loss: 0.00028526
Epoch [58/300], Train Loss: 0.000281
Validation Loss: 0.00027283
Epoch [59/300], Train Loss: 0.000278
Validation Loss: 0.00026666
Epoch [60/300], Train Loss: 0.000285
Validation Loss: 0.00026313
Epoch [61/300], Train Loss: 0.000278
Validation Loss: 0.00026999
Epoch [62/300], Train Loss: 0.000269
Validation Loss: 0.00026548
Epoch [63/300], Train Loss: 0.000279
Validation Loss: 0.00027213
Epoch [64/300], Train Loss: 0.000266
Validation Loss: 0.00025456
Epoch [65/300], Train Loss: 0.000261
Validation Loss: 0.00025192
Epoch [66/300], Train Loss: 0.000263
Validation Loss: 0.00025050
Epoch [67/300], Train Loss: 0.000258
Validation Loss: 0.00024381
Epoch [68/300], Train Loss: 0.000260
Validation Loss: 0.00030364
Epoch [69/300], Train Loss: 0.000256
Validation Loss: 0.00025007
Epoch [70/300], Train Loss: 0.000253
Validation Loss: 0.00024139
Epoch [71/300], Train Loss: 0.000254
Validation Loss: 0.00024569
Epoch [72/300], Train Loss: 0.000251
Validation Loss: 0.00023914
Epoch [73/300], Train Loss: 0.000263
Validation Loss: 0.00023888
Epoch [74/300], Train Loss: 0.000247
Validation Loss: 0.00023081
Epoch [75/300], Train Loss: 0.000247
Validation Loss: 0.00023184
Epoch [76/300], Train Loss: 0.000250
Validation Loss: 0.00023021
Epoch [77/300], Train Loss: 0.000246
Validation Loss: 0.00022737
Epoch [78/300], Train Loss: 0.000245
Validation Loss: 0.00022913
Epoch [79/300], Train Loss: 0.000242
Validation Loss: 0.00023085
Epoch [80/300], Train Loss: 0.000240
Validation Loss: 0.00024521
Epoch [81/300], Train Loss: 0.000237
Validation Loss: 0.00022277
Epoch [82/300], Train Loss: 0.000237
Validation Loss: 0.00022216
Epoch [83/300], Train Loss: 0.000235
Validation Loss: 0.00022089
Epoch [84/300], Train Loss: 0.000235
Validation Loss: 0.00021875
Epoch [85/300], Train Loss: 0.000230
Validation Loss: 0.00021476
Epoch [86/300], Train Loss: 0.000234
Validation Loss: 0.00022287
Epoch [87/300], Train Loss: 0.000229
Validation Loss: 0.00021767
Epoch [88/300], Train Loss: 0.000240
Validation Loss: 0.00021989
Epoch [89/300], Train Loss: 0.000228
Validation Loss: 0.00021846
Epoch [90/300], Train Loss: 0.000229
Validation Loss: 0.00021540
Epoch [91/300], Train Loss: 0.000223
Validation Loss: 0.00021381
Epoch [92/300], Train Loss: 0.000223
Validation Loss: 0.00021393
Epoch [93/300], Train Loss: 0.000221
Validation Loss: 0.00021005
Epoch [94/300], Train Loss: 0.000219
Validation Loss: 0.00020637
Epoch [95/300], Train Loss: 0.000220
Validation Loss: 0.00020700
Epoch [96/300], Train Loss: 0.000236
Validation Loss: 0.00021221
Epoch [97/300], Train Loss: 0.000218
Validation Loss: 0.00021432
Epoch [98/300], Train Loss: 0.000218
Validation Loss: 0.00022086
Epoch [99/300], Train Loss: 0.000217
Validation Loss: 0.00021524
Epoch [100/300], Train Loss: 0.000220
Validation Loss: 0.00025446
Epoch [101/300], Train Loss: 0.000217
Validation Loss: 0.00020556
Epoch [102/300], Train Loss: 0.000211
Validation Loss: 0.00020601
Epoch [103/300], Train Loss: 0.000221
Validation Loss: 0.00021032
Epoch [104/300], Train Loss: 0.000228
Validation Loss: 0.00021653
Epoch [105/300], Train Loss: 0.000215
Validation Loss: 0.00020186
Epoch [106/300], Train Loss: 0.000218
Validation Loss: 0.00020170
Epoch [107/300], Train Loss: 0.000214
Validation Loss: 0.00019789
Epoch [108/300], Train Loss: 0.000210
Validation Loss: 0.00020222
Epoch [109/300], Train Loss: 0.000211
Validation Loss: 0.00019896
Epoch [110/300], Train Loss: 0.000210
Validation Loss: 0.00019778
Epoch [111/300], Train Loss: 0.000209
Validation Loss: 0.00020457
Epoch [112/300], Train Loss: 0.000208
Validation Loss: 0.00019676
Epoch [113/300], Train Loss: 0.000207
Validation Loss: 0.00019539
Epoch [114/300], Train Loss: 0.000206
Validation Loss: 0.00020803
Epoch [115/300], Train Loss: 0.000207
Validation Loss: 0.00019470
Epoch [116/300], Train Loss: 0.000207
Validation Loss: 0.00019271
Epoch [117/300], Train Loss: 0.000204
Validation Loss: 0.00019306
Epoch [118/300], Train Loss: 0.000204
Validation Loss: 0.00019508
Epoch [119/300], Train Loss: 0.000203
Validation Loss: 0.00019066
Epoch [120/300], Train Loss: 0.000202
Validation Loss: 0.00019462
Epoch [121/300], Train Loss: 0.000202
Validation Loss: 0.00019075
Epoch [122/300], Train Loss: 0.000200
Validation Loss: 0.00019306
Epoch [123/300], Train Loss: 0.000198
Validation Loss: 0.00019156
Epoch [124/300], Train Loss: 0.000201
Validation Loss: 0.00019012
Epoch [125/300], Train Loss: 0.000198
Validation Loss: 0.00018935
Epoch [126/300], Train Loss: 0.000196
Validation Loss: 0.00019217
Epoch [127/300], Train Loss: 0.000197
Validation Loss: 0.00019082
Epoch [128/300], Train Loss: 0.000198
Validation Loss: 0.00018967
Epoch [129/300], Train Loss: 0.000195
Validation Loss: 0.00018685
Epoch [130/300], Train Loss: 0.000196
Validation Loss: 0.00018584
Epoch [131/300], Train Loss: 0.000195
Validation Loss: 0.00018372
Epoch [132/300], Train Loss: 0.000192
Validation Loss: 0.00018350
Epoch [133/300], Train Loss: 0.000199
Validation Loss: 0.00018817
Epoch [134/300], Train Loss: 0.000192
Validation Loss: 0.00018266
Epoch [135/300], Train Loss: 0.000192
Validation Loss: 0.00018450
Epoch [136/300], Train Loss: 0.000193
Validation Loss: 0.00018871
Epoch [137/300], Train Loss: 0.000191
Validation Loss: 0.00018575
Epoch [138/300], Train Loss: 0.000188
Validation Loss: 0.00018179
Epoch [139/300], Train Loss: 0.000189
Validation Loss: 0.00018579
Epoch [140/300], Train Loss: 0.000191
Validation Loss: 0.00018533
Epoch [141/300], Train Loss: 0.000188
Validation Loss: 0.00017846
Epoch [142/300], Train Loss: 0.000188
Validation Loss: 0.00018302
Epoch [143/300], Train Loss: 0.000189
Validation Loss: 0.00018808
Epoch [144/300], Train Loss: 0.000187
Validation Loss: 0.00017537
Epoch [145/300], Train Loss: 0.000187
Validation Loss: 0.00018392
Epoch [146/300], Train Loss: 0.000186
Validation Loss: 0.00018908
Epoch [147/300], Train Loss: 0.000184
Validation Loss: 0.00017907
Epoch [148/300], Train Loss: 0.000186
Validation Loss: 0.00018095
Epoch [149/300], Train Loss: 0.000184
Validation Loss: 0.00017688
Epoch [150/300], Train Loss: 0.000184
Validation Loss: 0.00017543
Epoch [151/300], Train Loss: 0.000184
Validation Loss: 0.00017518
Epoch [152/300], Train Loss: 0.000183
Validation Loss: 0.00017750
Epoch [153/300], Train Loss: 0.000185
Validation Loss: 0.00017557
Epoch [154/300], Train Loss: 0.000180
Validation Loss: 0.00018651
Epoch [155/300], Train Loss: 0.000183
Validation Loss: 0.00017581
Epoch [156/300], Train Loss: 0.000180
Validation Loss: 0.00017430
Epoch [157/300], Train Loss: 0.000181
Validation Loss: 0.00018289
Epoch [158/300], Train Loss: 0.000181
Validation Loss: 0.00017220
Epoch [159/300], Train Loss: 0.000179
Validation Loss: 0.00017769
Epoch [160/300], Train Loss: 0.000180
Validation Loss: 0.00017687
Epoch [161/300], Train Loss: 0.000179
Validation Loss: 0.00017290
Epoch [162/300], Train Loss: 0.000178
Validation Loss: 0.00017153
Epoch [163/300], Train Loss: 0.000179
Validation Loss: 0.00017590
Epoch [164/300], Train Loss: 0.000179
Validation Loss: 0.00018107
Epoch [165/300], Train Loss: 0.000180
Validation Loss: 0.00016903
Epoch [166/300], Train Loss: 0.000177
Validation Loss: 0.00017184
Epoch [167/300], Train Loss: 0.000176
Validation Loss: 0.00017089
Epoch [168/300], Train Loss: 0.000177
Validation Loss: 0.00017080
Epoch [169/300], Train Loss: 0.000176
Validation Loss: 0.00017275
Epoch [170/300], Train Loss: 0.000176
Validation Loss: 0.00017070
Epoch [171/300], Train Loss: 0.000175
Validation Loss: 0.00016716
Epoch [172/300], Train Loss: 0.000174
Validation Loss: 0.00016934
Epoch [173/300], Train Loss: 0.000172
Validation Loss: 0.00017079
Epoch [174/300], Train Loss: 0.000175
Validation Loss: 0.00017029
Epoch [175/300], Train Loss: 0.000176
Validation Loss: 0.00017150
Epoch [176/300], Train Loss: 0.000171
Validation Loss: 0.00016797
Epoch [177/300], Train Loss: 0.000172
Validation Loss: 0.00017180
Epoch [178/300], Train Loss: 0.000180
Validation Loss: 0.00016997
Epoch [179/300], Train Loss: 0.000175
Validation Loss: 0.00017246
Epoch [180/300], Train Loss: 0.000172
Validation Loss: 0.00016989
Epoch [181/300], Train Loss: 0.000172
Validation Loss: 0.00016829
Early stopping triggered

Evaluating model for: Coffee Machine
Run 3/72 completed in 8728.04 seconds with: {'MAE': np.float32(2.760336), 'MSE': np.float32(697.46655), 'RMSE': np.float32(26.409592), 'SAE': np.float32(0.05272438), 'NDE': np.float32(0.42671424)}

Run 4/72: hidden=128, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Coffee Machine
Dataset length: 36156 windows

Epoch [1/300], Train Loss: 0.001041
Validation Loss: 0.00095708
Epoch [2/300], Train Loss: 0.000996
Validation Loss: 0.00095373
Epoch [3/300], Train Loss: 0.000990
Validation Loss: 0.00095181
Epoch [4/300], Train Loss: 0.000987
Validation Loss: 0.00095135
Epoch [5/300], Train Loss: 0.000984
Validation Loss: 0.00094586
Epoch [6/300], Train Loss: 0.000977
Validation Loss: 0.00093561
Epoch [7/300], Train Loss: 0.000942
Validation Loss: 0.00084023
Epoch [8/300], Train Loss: 0.000796
Validation Loss: 0.00073901
Epoch [9/300], Train Loss: 0.000705
Validation Loss: 0.00067498
Epoch [10/300], Train Loss: 0.000665
Validation Loss: 0.00065773
Epoch [11/300], Train Loss: 0.000633
Validation Loss: 0.00062136
Epoch [12/300], Train Loss: 0.000606
Validation Loss: 0.00060017
Epoch [13/300], Train Loss: 0.000584
Validation Loss: 0.00056643
Epoch [14/300], Train Loss: 0.000567
Validation Loss: 0.00057986
Epoch [15/300], Train Loss: 0.000555
Validation Loss: 0.00055458
Epoch [16/300], Train Loss: 0.000546
Validation Loss: 0.00055387
Epoch [17/300], Train Loss: 0.000538
Validation Loss: 0.00052288
Epoch [18/300], Train Loss: 0.000522
Validation Loss: 0.00053778
Epoch [19/300], Train Loss: 0.000518
Validation Loss: 0.00058194
Epoch [20/300], Train Loss: 0.000515
Validation Loss: 0.00050537
Epoch [21/300], Train Loss: 0.000505
Validation Loss: 0.00047322
Epoch [22/300], Train Loss: 0.000495
Validation Loss: 0.00045477
Epoch [23/300], Train Loss: 0.000490
Validation Loss: 0.00047294
Epoch [24/300], Train Loss: 0.000482
Validation Loss: 0.00045694
Epoch [25/300], Train Loss: 0.000471
Validation Loss: 0.00042625
Epoch [26/300], Train Loss: 0.000460
Validation Loss: 0.00043983
Epoch [27/300], Train Loss: 0.000457
Validation Loss: 0.00040759
Epoch [28/300], Train Loss: 0.000429
Validation Loss: 0.00036912
Epoch [29/300], Train Loss: 0.000411
Validation Loss: 0.00034823
Epoch [30/300], Train Loss: 0.000388
Validation Loss: 0.00033764
Epoch [31/300], Train Loss: 0.000370
Validation Loss: 0.00032767
Epoch [32/300], Train Loss: 0.000360
Validation Loss: 0.00033266
Epoch [33/300], Train Loss: 0.000349
Validation Loss: 0.00029906
Epoch [34/300], Train Loss: 0.000343
Validation Loss: 0.00030501
Epoch [35/300], Train Loss: 0.000334
Validation Loss: 0.00029137
Epoch [36/300], Train Loss: 0.000332
Validation Loss: 0.00029648
Epoch [37/300], Train Loss: 0.000329
Validation Loss: 0.00028817
Epoch [38/300], Train Loss: 0.000317
Validation Loss: 0.00029232
Epoch [39/300], Train Loss: 0.000315
Validation Loss: 0.00028680
Epoch [40/300], Train Loss: 0.000305
Validation Loss: 0.00028938
Epoch [41/300], Train Loss: 0.000304
Validation Loss: 0.00029076
Epoch [42/300], Train Loss: 0.000299
Validation Loss: 0.00027098
Epoch [43/300], Train Loss: 0.000296
Validation Loss: 0.00027722
Epoch [44/300], Train Loss: 0.000298
Validation Loss: 0.00028359
Epoch [45/300], Train Loss: 0.000287
Validation Loss: 0.00027395
Epoch [46/300], Train Loss: 0.000285
Validation Loss: 0.00026931
Epoch [47/300], Train Loss: 0.000281
Validation Loss: 0.00026980
Epoch [48/300], Train Loss: 0.000285
Validation Loss: 0.00026124
Epoch [49/300], Train Loss: 0.000284
Validation Loss: 0.00025417
Epoch [50/300], Train Loss: 0.000275
Validation Loss: 0.00025826
Epoch [51/300], Train Loss: 0.000270
Validation Loss: 0.00026610
Epoch [52/300], Train Loss: 0.000271
Validation Loss: 0.00025217
Epoch [53/300], Train Loss: 0.000267
Validation Loss: 0.00024835
Epoch [54/300], Train Loss: 0.000265
Validation Loss: 0.00025573
Epoch [55/300], Train Loss: 0.000264
Validation Loss: 0.00025101
Epoch [56/300], Train Loss: 0.000267
Validation Loss: 0.00025053
Epoch [57/300], Train Loss: 0.000255
Validation Loss: 0.00025927
Epoch [58/300], Train Loss: 0.000257
Validation Loss: 0.00024882
Epoch [59/300], Train Loss: 0.000256
Validation Loss: 0.00023890
Epoch [60/300], Train Loss: 0.000252
Validation Loss: 0.00024064
Epoch [61/300], Train Loss: 0.000250
Validation Loss: 0.00024800
Epoch [62/300], Train Loss: 0.000246
Validation Loss: 0.00030077
Epoch [63/300], Train Loss: 0.000244
Validation Loss: 0.00023570
Epoch [64/300], Train Loss: 0.000240
Validation Loss: 0.00023425
Epoch [65/300], Train Loss: 0.000244
Validation Loss: 0.00023290
Epoch [66/300], Train Loss: 0.000239
Validation Loss: 0.00022551
Epoch [67/300], Train Loss: 0.000236
Validation Loss: 0.00022818
Epoch [68/300], Train Loss: 0.000231
Validation Loss: 0.00023063
Epoch [69/300], Train Loss: 0.000231
Validation Loss: 0.00022331
Epoch [70/300], Train Loss: 0.000234
Validation Loss: 0.00022096
Epoch [71/300], Train Loss: 0.000231
Validation Loss: 0.00025111
Epoch [72/300], Train Loss: 0.000229
Validation Loss: 0.00021771
Epoch [73/300], Train Loss: 0.000227
Validation Loss: 0.00022606
Epoch [74/300], Train Loss: 0.000225
Validation Loss: 0.00021425
Epoch [75/300], Train Loss: 0.000221
Validation Loss: 0.00021855
Epoch [76/300], Train Loss: 0.000225
Validation Loss: 0.00021742
Epoch [77/300], Train Loss: 0.000222
Validation Loss: 0.00021197
Epoch [78/300], Train Loss: 0.000220
Validation Loss: 0.00021597
Epoch [79/300], Train Loss: 0.000221
Validation Loss: 0.00021507
Epoch [80/300], Train Loss: 0.000223
Validation Loss: 0.00021085
Epoch [81/300], Train Loss: 0.000212
Validation Loss: 0.00020896
Epoch [82/300], Train Loss: 0.000210
Validation Loss: 0.00020929
Epoch [83/300], Train Loss: 0.000212
Validation Loss: 0.00020861
Epoch [84/300], Train Loss: 0.000214
Validation Loss: 0.00021171
Epoch [85/300], Train Loss: 0.000210
Validation Loss: 0.00021182
Epoch [86/300], Train Loss: 0.000211
Validation Loss: 0.00020477
Epoch [87/300], Train Loss: 0.000210
Validation Loss: 0.00020635
Epoch [88/300], Train Loss: 0.000209
Validation Loss: 0.00021137
Epoch [89/300], Train Loss: 0.000206
Validation Loss: 0.00020514
Epoch [90/300], Train Loss: 0.000214
Validation Loss: 0.00020286
Epoch [91/300], Train Loss: 0.000202
Validation Loss: 0.00020231
Epoch [92/300], Train Loss: 0.000201
Validation Loss: 0.00021825
Epoch [93/300], Train Loss: 0.000202
Validation Loss: 0.00020206
Epoch [94/300], Train Loss: 0.000199
Validation Loss: 0.00020158
Epoch [95/300], Train Loss: 0.000201
Validation Loss: 0.00020446
Epoch [96/300], Train Loss: 0.000200
Validation Loss: 0.00020231
Epoch [97/300], Train Loss: 0.000202
Validation Loss: 0.00019508
Epoch [98/300], Train Loss: 0.000196
Validation Loss: 0.00020640
Epoch [99/300], Train Loss: 0.000196
Validation Loss: 0.00020482
Epoch [100/300], Train Loss: 0.000193
Validation Loss: 0.00022454
Epoch [101/300], Train Loss: 0.000199
Validation Loss: 0.00020311
Epoch [102/300], Train Loss: 0.000193
Validation Loss: 0.00019355
Epoch [103/300], Train Loss: 0.000197
Validation Loss: 0.00020586
Epoch [104/300], Train Loss: 0.000191
Validation Loss: 0.00019701
Epoch [105/300], Train Loss: 0.000190
Validation Loss: 0.00019605
Epoch [106/300], Train Loss: 0.000192
Validation Loss: 0.00019678
Epoch [107/300], Train Loss: 0.000189
Validation Loss: 0.00019083
Epoch [108/300], Train Loss: 0.000189
Validation Loss: 0.00020828
Epoch [109/300], Train Loss: 0.000187
Validation Loss: 0.00019540
Epoch [110/300], Train Loss: 0.000184
Validation Loss: 0.00019075
Epoch [111/300], Train Loss: 0.000185
Validation Loss: 0.00019055
Epoch [112/300], Train Loss: 0.000185
Validation Loss: 0.00018751
Epoch [113/300], Train Loss: 0.000185
Validation Loss: 0.00019993
Epoch [114/300], Train Loss: 0.000184
Validation Loss: 0.00018786
Epoch [115/300], Train Loss: 0.000195
Validation Loss: 0.00019656
Epoch [116/300], Train Loss: 0.000187
Validation Loss: 0.00018623
Epoch [117/300], Train Loss: 0.000182
Validation Loss: 0.00019217
Epoch [118/300], Train Loss: 0.000182
Validation Loss: 0.00018806
Epoch [119/300], Train Loss: 0.000179
Validation Loss: 0.00018787
Epoch [120/300], Train Loss: 0.000178
Validation Loss: 0.00018591
Epoch [121/300], Train Loss: 0.000180
Validation Loss: 0.00020289
Epoch [122/300], Train Loss: 0.000175
Validation Loss: 0.00019574
Epoch [123/300], Train Loss: 0.000178
Validation Loss: 0.00018757
Epoch [124/300], Train Loss: 0.000177
Validation Loss: 0.00018611
Epoch [125/300], Train Loss: 0.000175
Validation Loss: 0.00018148
Epoch [126/300], Train Loss: 0.000175
Validation Loss: 0.00018625
Epoch [127/300], Train Loss: 0.000182
Validation Loss: 0.00019915
Epoch [128/300], Train Loss: 0.000172
Validation Loss: 0.00018424
Epoch [129/300], Train Loss: 0.000174
Validation Loss: 0.00018983
Epoch [130/300], Train Loss: 0.000171
Validation Loss: 0.00018333
Epoch [131/300], Train Loss: 0.000171
Validation Loss: 0.00018272
Epoch [132/300], Train Loss: 0.000170
Validation Loss: 0.00018810
Epoch [133/300], Train Loss: 0.000175
Validation Loss: 0.00018538
Epoch [134/300], Train Loss: 0.000169
Validation Loss: 0.00018523
Epoch [135/300], Train Loss: 0.000175
Validation Loss: 0.00018786
Early stopping triggered

Evaluating model for: Coffee Machine
Run 4/72 completed in 6698.07 seconds with: {'MAE': np.float32(2.5572896), 'MSE': np.float32(750.6114), 'RMSE': np.float32(27.397287), 'SAE': np.float32(0.102497324), 'NDE': np.float32(0.44267228)}

Run 5/72: hidden=128, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Coffee Machine
Dataset length: 18100 windows

Epoch [1/300], Train Loss: 0.000990
Validation Loss: 0.00093193
Epoch [2/300], Train Loss: 0.000968
Validation Loss: 0.00092878
Epoch [3/300], Train Loss: 0.000981
Validation Loss: 0.00092516
Epoch [4/300], Train Loss: 0.000968
Validation Loss: 0.00092163
Epoch [5/300], Train Loss: 0.000950
Validation Loss: 0.00091562
Epoch [6/300], Train Loss: 0.000951
Validation Loss: 0.00090858
Epoch [7/300], Train Loss: 0.000939
Validation Loss: 0.00089947
Epoch [8/300], Train Loss: 0.000927
Validation Loss: 0.00088599
Epoch [9/300], Train Loss: 0.000917
Validation Loss: 0.00086461
Epoch [10/300], Train Loss: 0.000891
Validation Loss: 0.00082917
Epoch [11/300], Train Loss: 0.000851
Validation Loss: 0.00079153
Epoch [12/300], Train Loss: 0.000815
Validation Loss: 0.00076323
Epoch [13/300], Train Loss: 0.000795
Validation Loss: 0.00075184
Epoch [14/300], Train Loss: 0.000751
Validation Loss: 0.00069765
Epoch [15/300], Train Loss: 0.000722
Validation Loss: 0.00067270
Epoch [16/300], Train Loss: 0.000698
Validation Loss: 0.00064996
Epoch [17/300], Train Loss: 0.000685
Validation Loss: 0.00063842
Epoch [18/300], Train Loss: 0.000677
Validation Loss: 0.00062851
Epoch [19/300], Train Loss: 0.000663
Validation Loss: 0.00062361
Epoch [20/300], Train Loss: 0.000651
Validation Loss: 0.00062294
Epoch [21/300], Train Loss: 0.000646
Validation Loss: 0.00060683
Epoch [22/300], Train Loss: 0.000632
Validation Loss: 0.00058945
Epoch [23/300], Train Loss: 0.000654
Validation Loss: 0.00060523
Epoch [24/300], Train Loss: 0.000637
Validation Loss: 0.00060685
Epoch [25/300], Train Loss: 0.000617
Validation Loss: 0.00059606
Epoch [26/300], Train Loss: 0.000605
Validation Loss: 0.00059175
Epoch [27/300], Train Loss: 0.000610
Validation Loss: 0.00059678
Epoch [28/300], Train Loss: 0.000609
Validation Loss: 0.00058896
Epoch [29/300], Train Loss: 0.000597
Validation Loss: 0.00057850
Epoch [30/300], Train Loss: 0.000586
Validation Loss: 0.00056772
Epoch [31/300], Train Loss: 0.000582
Validation Loss: 0.00056691
Epoch [32/300], Train Loss: 0.000569
Validation Loss: 0.00056253
Epoch [33/300], Train Loss: 0.000573
Validation Loss: 0.00055409
Epoch [34/300], Train Loss: 0.000570
Validation Loss: 0.00054564
Epoch [35/300], Train Loss: 0.000560
Validation Loss: 0.00053839
Epoch [36/300], Train Loss: 0.000563
Validation Loss: 0.00053913
Epoch [37/300], Train Loss: 0.000548
Validation Loss: 0.00053451
Epoch [38/300], Train Loss: 0.000544
Validation Loss: 0.00052077
Epoch [39/300], Train Loss: 0.000537
Validation Loss: 0.00051879
Epoch [40/300], Train Loss: 0.000534
Validation Loss: 0.00051565
Epoch [41/300], Train Loss: 0.000552
Validation Loss: 0.00054583
Epoch [42/300], Train Loss: 0.000535
Validation Loss: 0.00050989
Epoch [43/300], Train Loss: 0.000519
Validation Loss: 0.00052548
Epoch [44/300], Train Loss: 0.000524
Validation Loss: 0.00050696
Epoch [45/300], Train Loss: 0.000522
Validation Loss: 0.00050999
Epoch [46/300], Train Loss: 0.000519
Validation Loss: 0.00050384
Epoch [47/300], Train Loss: 0.000512
Validation Loss: 0.00051350
Epoch [48/300], Train Loss: 0.000519
Validation Loss: 0.00050682
Epoch [49/300], Train Loss: 0.000507
Validation Loss: 0.00048900
Epoch [50/300], Train Loss: 0.000503
Validation Loss: 0.00049058
Epoch [51/300], Train Loss: 0.000501
Validation Loss: 0.00048759
Epoch [52/300], Train Loss: 0.000495
Validation Loss: 0.00049247
Epoch [53/300], Train Loss: 0.000497
Validation Loss: 0.00048845
Epoch [54/300], Train Loss: 0.000495
Validation Loss: 0.00048302
Epoch [55/300], Train Loss: 0.000493
Validation Loss: 0.00049233
Epoch [56/300], Train Loss: 0.000488
Validation Loss: 0.00052222
Epoch [57/300], Train Loss: 0.000495
Validation Loss: 0.00048899
Epoch [58/300], Train Loss: 0.000479
Validation Loss: 0.00046910
Epoch [59/300], Train Loss: 0.000473
Validation Loss: 0.00046204
Epoch [60/300], Train Loss: 0.000468
Validation Loss: 0.00046333
Epoch [61/300], Train Loss: 0.000468
Validation Loss: 0.00046288
Epoch [62/300], Train Loss: 0.000461
Validation Loss: 0.00045827
Epoch [63/300], Train Loss: 0.000456
Validation Loss: 0.00045039
Epoch [64/300], Train Loss: 0.000456
Validation Loss: 0.00044914
Epoch [65/300], Train Loss: 0.000456
Validation Loss: 0.00046268
Epoch [66/300], Train Loss: 0.000452
Validation Loss: 0.00047344
Epoch [67/300], Train Loss: 0.000458
Validation Loss: 0.00045182
Epoch [68/300], Train Loss: 0.000450
Validation Loss: 0.00043930
Epoch [69/300], Train Loss: 0.000438
Validation Loss: 0.00043542
Epoch [70/300], Train Loss: 0.000438
Validation Loss: 0.00042928
Epoch [71/300], Train Loss: 0.000439
Validation Loss: 0.00043630
Epoch [72/300], Train Loss: 0.000430
Validation Loss: 0.00041805
Epoch [73/300], Train Loss: 0.000433
Validation Loss: 0.00042873
Epoch [74/300], Train Loss: 0.000421
Validation Loss: 0.00041294
Epoch [75/300], Train Loss: 0.000418
Validation Loss: 0.00042568
Epoch [76/300], Train Loss: 0.000417
Validation Loss: 0.00042122
Epoch [77/300], Train Loss: 0.000419
Validation Loss: 0.00041192
Epoch [78/300], Train Loss: 0.000410
Validation Loss: 0.00041695
Epoch [79/300], Train Loss: 0.000427
Validation Loss: 0.00041616
Epoch [80/300], Train Loss: 0.000419
Validation Loss: 0.00040493
Epoch [81/300], Train Loss: 0.000407
Validation Loss: 0.00039143
Epoch [82/300], Train Loss: 0.000402
Validation Loss: 0.00040045
Epoch [83/300], Train Loss: 0.000401
Validation Loss: 0.00038746
Epoch [84/300], Train Loss: 0.000397
Validation Loss: 0.00039709
Epoch [85/300], Train Loss: 0.000395
Validation Loss: 0.00039130
Epoch [86/300], Train Loss: 0.000392
Validation Loss: 0.00038641
Epoch [87/300], Train Loss: 0.000395
Validation Loss: 0.00041448
Epoch [88/300], Train Loss: 0.000387
Validation Loss: 0.00038395
Epoch [89/300], Train Loss: 0.000389
Validation Loss: 0.00038102
Epoch [90/300], Train Loss: 0.000382
Validation Loss: 0.00038748
Epoch [91/300], Train Loss: 0.000382
Validation Loss: 0.00037486
Epoch [92/300], Train Loss: 0.000379
Validation Loss: 0.00038948
Epoch [93/300], Train Loss: 0.000387
Validation Loss: 0.00038791
Epoch [94/300], Train Loss: 0.000372
Validation Loss: 0.00037276
Epoch [95/300], Train Loss: 0.000374
Validation Loss: 0.00049705
Epoch [96/300], Train Loss: 0.000389
Validation Loss: 0.00037282
Epoch [97/300], Train Loss: 0.000372
Validation Loss: 0.00037853
Epoch [98/300], Train Loss: 0.000367
Validation Loss: 0.00037472
Epoch [99/300], Train Loss: 0.000369
Validation Loss: 0.00038321
Epoch [100/300], Train Loss: 0.000377
Validation Loss: 0.00036358
Epoch [101/300], Train Loss: 0.000359
Validation Loss: 0.00036695
Epoch [102/300], Train Loss: 0.000359
Validation Loss: 0.00035823
Epoch [103/300], Train Loss: 0.000360
Validation Loss: 0.00037153
Epoch [104/300], Train Loss: 0.000360
Validation Loss: 0.00035683
Epoch [105/300], Train Loss: 0.000351
Validation Loss: 0.00035571
Epoch [106/300], Train Loss: 0.000361
Validation Loss: 0.00035025
Epoch [107/300], Train Loss: 0.000353
Validation Loss: 0.00035566
Epoch [108/300], Train Loss: 0.000351
Validation Loss: 0.00035324
Epoch [109/300], Train Loss: 0.000352
Validation Loss: 0.00035613
Epoch [110/300], Train Loss: 0.000351
Validation Loss: 0.00038020
Epoch [111/300], Train Loss: 0.000354
Validation Loss: 0.00034619
Epoch [112/300], Train Loss: 0.000343
Validation Loss: 0.00033765
Epoch [113/300], Train Loss: 0.000342
Validation Loss: 0.00034028
Epoch [114/300], Train Loss: 0.000342
Validation Loss: 0.00034371
Epoch [115/300], Train Loss: 0.000355
Validation Loss: 0.00034165
Epoch [116/300], Train Loss: 0.000344
Validation Loss: 0.00034455
Epoch [117/300], Train Loss: 0.000338
Validation Loss: 0.00033804
Epoch [118/300], Train Loss: 0.000337
Validation Loss: 0.00033205
Epoch [119/300], Train Loss: 0.000335
Validation Loss: 0.00033930
Epoch [120/300], Train Loss: 0.000335
Validation Loss: 0.00033199
Epoch [121/300], Train Loss: 0.000330
Validation Loss: 0.00034116
Epoch [122/300], Train Loss: 0.000328
Validation Loss: 0.00032839
Epoch [123/300], Train Loss: 0.000327
Validation Loss: 0.00032912
Epoch [124/300], Train Loss: 0.000329
Validation Loss: 0.00032707
Epoch [125/300], Train Loss: 0.000331
Validation Loss: 0.00032600
Epoch [126/300], Train Loss: 0.000324
Validation Loss: 0.00033326
Epoch [127/300], Train Loss: 0.000325
Validation Loss: 0.00032451
Epoch [128/300], Train Loss: 0.000326
Validation Loss: 0.00032778
Epoch [129/300], Train Loss: 0.000335
Validation Loss: 0.00032305
Epoch [130/300], Train Loss: 0.000319
Validation Loss: 0.00032981
Epoch [131/300], Train Loss: 0.000332
Validation Loss: 0.00032384
Epoch [132/300], Train Loss: 0.000330
Validation Loss: 0.00032077
Epoch [133/300], Train Loss: 0.000328
Validation Loss: 0.00037098
Epoch [134/300], Train Loss: 0.000323
Validation Loss: 0.00032383
Epoch [135/300], Train Loss: 0.000324
Validation Loss: 0.00032092
Epoch [136/300], Train Loss: 0.000313
Validation Loss: 0.00031397
Epoch [137/300], Train Loss: 0.000309
Validation Loss: 0.00031755
Epoch [138/300], Train Loss: 0.000309
Validation Loss: 0.00031129
Epoch [139/300], Train Loss: 0.000310
Validation Loss: 0.00031912
Epoch [140/300], Train Loss: 0.000305
Validation Loss: 0.00031060
Epoch [141/300], Train Loss: 0.000305
Validation Loss: 0.00031782
Epoch [142/300], Train Loss: 0.000312
Validation Loss: 0.00032515
Epoch [143/300], Train Loss: 0.000309
Validation Loss: 0.00031066
Epoch [144/300], Train Loss: 0.000302
Validation Loss: 0.00031183
Epoch [145/300], Train Loss: 0.000313
Validation Loss: 0.00031272
Epoch [146/300], Train Loss: 0.000301
Validation Loss: 0.00031797
Epoch [147/300], Train Loss: 0.000309
Validation Loss: 0.00030267
Epoch [148/300], Train Loss: 0.000304
Validation Loss: 0.00030340
Epoch [149/300], Train Loss: 0.000299
Validation Loss: 0.00030269
Epoch [150/300], Train Loss: 0.000298
Validation Loss: 0.00030450
Epoch [151/300], Train Loss: 0.000296
Validation Loss: 0.00030107
Epoch [152/300], Train Loss: 0.000304
Validation Loss: 0.00031442
Epoch [153/300], Train Loss: 0.000302
Validation Loss: 0.00031688
Epoch [154/300], Train Loss: 0.000297
Validation Loss: 0.00030438
Epoch [155/300], Train Loss: 0.000299
Validation Loss: 0.00029858
Epoch [156/300], Train Loss: 0.000297
Validation Loss: 0.00029840
Epoch [157/300], Train Loss: 0.000299
Validation Loss: 0.00030035
Epoch [158/300], Train Loss: 0.000293
Validation Loss: 0.00029990
Epoch [159/300], Train Loss: 0.000292
Validation Loss: 0.00029742
Epoch [160/300], Train Loss: 0.000295
Validation Loss: 0.00030622
Epoch [161/300], Train Loss: 0.000304
Validation Loss: 0.00029797
Epoch [162/300], Train Loss: 0.000291
Validation Loss: 0.00029177
Epoch [163/300], Train Loss: 0.000291
Validation Loss: 0.00029896
Epoch [164/300], Train Loss: 0.000287
Validation Loss: 0.00029096
Epoch [165/300], Train Loss: 0.000291
Validation Loss: 0.00029702
Epoch [166/300], Train Loss: 0.000287
Validation Loss: 0.00030114
Epoch [167/300], Train Loss: 0.000295
Validation Loss: 0.00029183
Epoch [168/300], Train Loss: 0.000287
Validation Loss: 0.00029242
Epoch [169/300], Train Loss: 0.000287
Validation Loss: 0.00030726
Epoch [170/300], Train Loss: 0.000289
Validation Loss: 0.00029220
Epoch [171/300], Train Loss: 0.000287
Validation Loss: 0.00028862
Epoch [172/300], Train Loss: 0.000290
Validation Loss: 0.00029720
Epoch [173/300], Train Loss: 0.000281
Validation Loss: 0.00028497
Epoch [174/300], Train Loss: 0.000287
Validation Loss: 0.00028919
Epoch [175/300], Train Loss: 0.000288
Validation Loss: 0.00028764
Epoch [176/300], Train Loss: 0.000285
Validation Loss: 0.00029119
Epoch [177/300], Train Loss: 0.000285
Validation Loss: 0.00028626
Epoch [178/300], Train Loss: 0.000280
Validation Loss: 0.00028463
Epoch [179/300], Train Loss: 0.000280
Validation Loss: 0.00029180
Epoch [180/300], Train Loss: 0.000280
Validation Loss: 0.00028373
Epoch [181/300], Train Loss: 0.000280
Validation Loss: 0.00029113
Epoch [182/300], Train Loss: 0.000284
Validation Loss: 0.00027970
Epoch [183/300], Train Loss: 0.000277
Validation Loss: 0.00028304
Epoch [184/300], Train Loss: 0.000276
Validation Loss: 0.00027856
Epoch [185/300], Train Loss: 0.000276
Validation Loss: 0.00027884
Epoch [186/300], Train Loss: 0.000278
Validation Loss: 0.00028487
Epoch [187/300], Train Loss: 0.000284
Validation Loss: 0.00029132
Epoch [188/300], Train Loss: 0.000280
Validation Loss: 0.00028063
Epoch [189/300], Train Loss: 0.000282
Validation Loss: 0.00029645
Epoch [190/300], Train Loss: 0.000275
Validation Loss: 0.00028528
Epoch [191/300], Train Loss: 0.000276
Validation Loss: 0.00027787
Epoch [192/300], Train Loss: 0.000276
Validation Loss: 0.00029968
Epoch [193/300], Train Loss: 0.000274
Validation Loss: 0.00028056
Epoch [194/300], Train Loss: 0.000273
Validation Loss: 0.00027659
Epoch [195/300], Train Loss: 0.000276
Validation Loss: 0.00028372
Epoch [196/300], Train Loss: 0.000272
Validation Loss: 0.00027131
Epoch [197/300], Train Loss: 0.000269
Validation Loss: 0.00027531
Epoch [198/300], Train Loss: 0.000271
Validation Loss: 0.00027309
Epoch [199/300], Train Loss: 0.000273
Validation Loss: 0.00027451
Epoch [200/300], Train Loss: 0.000271
Validation Loss: 0.00027304
Epoch [201/300], Train Loss: 0.000274
Validation Loss: 0.00027091
Epoch [202/300], Train Loss: 0.000277
Validation Loss: 0.00028877
Epoch [203/300], Train Loss: 0.000273
Validation Loss: 0.00028648
Epoch [204/300], Train Loss: 0.000277
Validation Loss: 0.00027185
Epoch [205/300], Train Loss: 0.000268
Validation Loss: 0.00026890
Epoch [206/300], Train Loss: 0.000267
Validation Loss: 0.00027329
Epoch [207/300], Train Loss: 0.000266
Validation Loss: 0.00027340
Epoch [208/300], Train Loss: 0.000264
Validation Loss: 0.00027864
Epoch [209/300], Train Loss: 0.000268
Validation Loss: 0.00027675
Epoch [210/300], Train Loss: 0.000265
Validation Loss: 0.00027086
Epoch [211/300], Train Loss: 0.000265
Validation Loss: 0.00027098
Epoch [212/300], Train Loss: 0.000265
Validation Loss: 0.00026838
Epoch [213/300], Train Loss: 0.000271
Validation Loss: 0.00027281
Epoch [214/300], Train Loss: 0.000262
Validation Loss: 0.00026989
Epoch [215/300], Train Loss: 0.000264
Validation Loss: 0.00027203
Epoch [216/300], Train Loss: 0.000264
Validation Loss: 0.00026661
Epoch [217/300], Train Loss: 0.000267
Validation Loss: 0.00027318
Epoch [218/300], Train Loss: 0.000271
Validation Loss: 0.00027504
Epoch [219/300], Train Loss: 0.000264
Validation Loss: 0.00027143
Epoch [220/300], Train Loss: 0.000267
Validation Loss: 0.00026581
Epoch [221/300], Train Loss: 0.000262
Validation Loss: 0.00026767
Epoch [222/300], Train Loss: 0.000259
Validation Loss: 0.00026720
Epoch [223/300], Train Loss: 0.000258
Validation Loss: 0.00026337
Epoch [224/300], Train Loss: 0.000263
Validation Loss: 0.00026799
Epoch [225/300], Train Loss: 0.000264
Validation Loss: 0.00026909
Epoch [226/300], Train Loss: 0.000258
Validation Loss: 0.00026999
Epoch [227/300], Train Loss: 0.000261
Validation Loss: 0.00026210
Epoch [228/300], Train Loss: 0.000258
Validation Loss: 0.00026708
Epoch [229/300], Train Loss: 0.000266
Validation Loss: 0.00026188
Epoch [230/300], Train Loss: 0.000259
Validation Loss: 0.00026328
Epoch [231/300], Train Loss: 0.000259
Validation Loss: 0.00026201
Epoch [232/300], Train Loss: 0.000258
Validation Loss: 0.00026960
Epoch [233/300], Train Loss: 0.000255
Validation Loss: 0.00026190
Epoch [234/300], Train Loss: 0.000259
Validation Loss: 0.00026519
Epoch [235/300], Train Loss: 0.000258
Validation Loss: 0.00026979
Epoch [236/300], Train Loss: 0.000258
Validation Loss: 0.00026072
Epoch [237/300], Train Loss: 0.000256
Validation Loss: 0.00026382
Epoch [238/300], Train Loss: 0.000255
Validation Loss: 0.00026227
Epoch [239/300], Train Loss: 0.000257
Validation Loss: 0.00026297
Epoch [240/300], Train Loss: 0.000260
Validation Loss: 0.00026248
Epoch [241/300], Train Loss: 0.000257
Validation Loss: 0.00026457
Epoch [242/300], Train Loss: 0.000261
Validation Loss: 0.00026535
Epoch [243/300], Train Loss: 0.000254
Validation Loss: 0.00026073
Epoch [244/300], Train Loss: 0.000255
Validation Loss: 0.00026236
Epoch [245/300], Train Loss: 0.000253
Validation Loss: 0.00026440
Epoch [246/300], Train Loss: 0.000256
Validation Loss: 0.00026278
Early stopping triggered

Evaluating model for: Coffee Machine
Run 5/72 completed in 6041.55 seconds with: {'MAE': np.float32(3.750927), 'MSE': np.float32(957.394), 'RMSE': np.float32(30.941784), 'SAE': np.float32(0.03192919), 'NDE': np.float32(0.50008625)}

Run 6/72: hidden=128, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Coffee Machine
Dataset length: 18100 windows

Epoch [1/300], Train Loss: 0.001262
Validation Loss: 0.00096600
Epoch [2/300], Train Loss: 0.001016
Validation Loss: 0.00095917
Epoch [3/300], Train Loss: 0.001025
Validation Loss: 0.00095287
Epoch [4/300], Train Loss: 0.001007
Validation Loss: 0.00094683
Epoch [5/300], Train Loss: 0.000987
Validation Loss: 0.00094271
Epoch [6/300], Train Loss: 0.000989
Validation Loss: 0.00093965
Epoch [7/300], Train Loss: 0.000979
Validation Loss: 0.00093717
Epoch [8/300], Train Loss: 0.000975
Validation Loss: 0.00093517
Epoch [9/300], Train Loss: 0.000981
Validation Loss: 0.00093187
Epoch [10/300], Train Loss: 0.000975
Validation Loss: 0.00092682
Epoch [11/300], Train Loss: 0.000961
Validation Loss: 0.00091747
Epoch [12/300], Train Loss: 0.000952
Validation Loss: 0.00090839
Epoch [13/300], Train Loss: 0.000961
Validation Loss: 0.00089435
Epoch [14/300], Train Loss: 0.000927
Validation Loss: 0.00086638
Epoch [15/300], Train Loss: 0.000877
Validation Loss: 0.00081520
Epoch [16/300], Train Loss: 0.000813
Validation Loss: 0.00077320
Epoch [17/300], Train Loss: 0.000771
Validation Loss: 0.00074163
Epoch [18/300], Train Loss: 0.000746
Validation Loss: 0.00073539
Epoch [19/300], Train Loss: 0.000716
Validation Loss: 0.00073134
Epoch [20/300], Train Loss: 0.000692
Validation Loss: 0.00068172
Epoch [21/300], Train Loss: 0.000679
Validation Loss: 0.00067413
Epoch [22/300], Train Loss: 0.000664
Validation Loss: 0.00068122
Epoch [23/300], Train Loss: 0.000676
Validation Loss: 0.00065719
Epoch [24/300], Train Loss: 0.000654
Validation Loss: 0.00064585
Epoch [25/300], Train Loss: 0.000627
Validation Loss: 0.00063319
Epoch [26/300], Train Loss: 0.000619
Validation Loss: 0.00062428
Epoch [27/300], Train Loss: 0.000620
Validation Loss: 0.00062121
Epoch [28/300], Train Loss: 0.000620
Validation Loss: 0.00061114
Epoch [29/300], Train Loss: 0.000612
Validation Loss: 0.00061033
Epoch [30/300], Train Loss: 0.000598
Validation Loss: 0.00060647
Epoch [31/300], Train Loss: 0.000590
Validation Loss: 0.00058788
Epoch [32/300], Train Loss: 0.000578
Validation Loss: 0.00058217
Epoch [33/300], Train Loss: 0.000581
Validation Loss: 0.00059092
Epoch [34/300], Train Loss: 0.000579
Validation Loss: 0.00060325
Epoch [35/300], Train Loss: 0.000570
Validation Loss: 0.00057419
Epoch [36/300], Train Loss: 0.000574
Validation Loss: 0.00057988
Epoch [37/300], Train Loss: 0.000557
Validation Loss: 0.00055611
Epoch [38/300], Train Loss: 0.000562
Validation Loss: 0.00058750
Epoch [39/300], Train Loss: 0.000558
Validation Loss: 0.00056297
Epoch [40/300], Train Loss: 0.000551
Validation Loss: 0.00055253
Epoch [41/300], Train Loss: 0.000544
Validation Loss: 0.00053438
Epoch [42/300], Train Loss: 0.000539
Validation Loss: 0.00053684
Epoch [43/300], Train Loss: 0.000531
Validation Loss: 0.00053287
Epoch [44/300], Train Loss: 0.000531
Validation Loss: 0.00052511
Epoch [45/300], Train Loss: 0.000527
Validation Loss: 0.00054443
Epoch [46/300], Train Loss: 0.000525
Validation Loss: 0.00052024
Epoch [47/300], Train Loss: 0.000528
Validation Loss: 0.00059910
Epoch [48/300], Train Loss: 0.000553
Validation Loss: 0.00052141
Epoch [49/300], Train Loss: 0.000530
Validation Loss: 0.00051280
Epoch [50/300], Train Loss: 0.000520
Validation Loss: 0.00051202
Epoch [51/300], Train Loss: 0.000515
Validation Loss: 0.00050176
Epoch [52/300], Train Loss: 0.000514
Validation Loss: 0.00050500
Epoch [53/300], Train Loss: 0.000519
Validation Loss: 0.00052214
Epoch [54/300], Train Loss: 0.000505
Validation Loss: 0.00051267
Epoch [55/300], Train Loss: 0.000504
Validation Loss: 0.00051156
Epoch [56/300], Train Loss: 0.000493
Validation Loss: 0.00050872
Epoch [57/300], Train Loss: 0.000527
Validation Loss: 0.00055882
Epoch [58/300], Train Loss: 0.000516
Validation Loss: 0.00049998
Epoch [59/300], Train Loss: 0.000484
Validation Loss: 0.00048828
Epoch [60/300], Train Loss: 0.000522
Validation Loss: 0.00050712
Epoch [61/300], Train Loss: 0.000490
Validation Loss: 0.00049784
Epoch [62/300], Train Loss: 0.000475
Validation Loss: 0.00049181
Epoch [63/300], Train Loss: 0.000468
Validation Loss: 0.00048098
Epoch [64/300], Train Loss: 0.000464
Validation Loss: 0.00048376
Epoch [65/300], Train Loss: 0.000488
Validation Loss: 0.00049055
Epoch [66/300], Train Loss: 0.000477
Validation Loss: 0.00047726
Epoch [67/300], Train Loss: 0.000463
Validation Loss: 0.00047981
Epoch [68/300], Train Loss: 0.000466
Validation Loss: 0.00047676
Epoch [69/300], Train Loss: 0.000454
Validation Loss: 0.00047418
Epoch [70/300], Train Loss: 0.000457
Validation Loss: 0.00050400
Epoch [71/300], Train Loss: 0.000460
Validation Loss: 0.00047122
Epoch [72/300], Train Loss: 0.000453
Validation Loss: 0.00047107
Epoch [73/300], Train Loss: 0.000448
Validation Loss: 0.00046595
Epoch [74/300], Train Loss: 0.000453
Validation Loss: 0.00049468
Epoch [75/300], Train Loss: 0.000452
Validation Loss: 0.00046055
Epoch [76/300], Train Loss: 0.000437
Validation Loss: 0.00045538
Epoch [77/300], Train Loss: 0.000446
Validation Loss: 0.00045780
Epoch [78/300], Train Loss: 0.000433
Validation Loss: 0.00045312
Epoch [79/300], Train Loss: 0.000435
Validation Loss: 0.00045939
Epoch [80/300], Train Loss: 0.000465
Validation Loss: 0.00047325
Epoch [81/300], Train Loss: 0.000436
Validation Loss: 0.00044896
Epoch [82/300], Train Loss: 0.000477
Validation Loss: 0.00051150
Epoch [83/300], Train Loss: 0.000490
Validation Loss: 0.00048747
Epoch [84/300], Train Loss: 0.000455
Validation Loss: 0.00046764
Epoch [85/300], Train Loss: 0.000438
Validation Loss: 0.00045503
Epoch [86/300], Train Loss: 0.000436
Validation Loss: 0.00044702
Epoch [87/300], Train Loss: 0.000424
Validation Loss: 0.00044858
Epoch [88/300], Train Loss: 0.000420
Validation Loss: 0.00044524
Epoch [89/300], Train Loss: 0.000417
Validation Loss: 0.00044123
Epoch [90/300], Train Loss: 0.000418
Validation Loss: 0.00043730
Epoch [91/300], Train Loss: 0.000419
Validation Loss: 0.00043708
Epoch [92/300], Train Loss: 0.000414
Validation Loss: 0.00043715
Epoch [93/300], Train Loss: 0.000422
Validation Loss: 0.00044097
Epoch [94/300], Train Loss: 0.000410
Validation Loss: 0.00043803
Epoch [95/300], Train Loss: 0.000406
Validation Loss: 0.00043033
Epoch [96/300], Train Loss: 0.000406
Validation Loss: 0.00043091
Epoch [97/300], Train Loss: 0.000402
Validation Loss: 0.00042626
Epoch [98/300], Train Loss: 0.000405
Validation Loss: 0.00042030
Epoch [99/300], Train Loss: 0.000415
Validation Loss: 0.00041887
Epoch [100/300], Train Loss: 0.000407
Validation Loss: 0.00042082
Epoch [101/300], Train Loss: 0.000398
Validation Loss: 0.00043039
Epoch [102/300], Train Loss: 0.000401
Validation Loss: 0.00042345
Epoch [103/300], Train Loss: 0.000402
Validation Loss: 0.00044723
Epoch [104/300], Train Loss: 0.000393
Validation Loss: 0.00042170
Epoch [105/300], Train Loss: 0.000391
Validation Loss: 0.00041514
Epoch [106/300], Train Loss: 0.000394
Validation Loss: 0.00040926
Epoch [107/300], Train Loss: 0.000388
Validation Loss: 0.00040874
Epoch [108/300], Train Loss: 0.000413
Validation Loss: 0.00041027
Epoch [109/300], Train Loss: 0.000402
Validation Loss: 0.00040281
Epoch [110/300], Train Loss: 0.000401
Validation Loss: 0.00040004
Epoch [111/300], Train Loss: 0.000385
Validation Loss: 0.00039943
Epoch [112/300], Train Loss: 0.000383
Validation Loss: 0.00039738
Epoch [113/300], Train Loss: 0.000380
Validation Loss: 0.00040198
Epoch [114/300], Train Loss: 0.000377
Validation Loss: 0.00039896
Epoch [115/300], Train Loss: 0.000391
Validation Loss: 0.00040661
Epoch [116/300], Train Loss: 0.000384
Validation Loss: 0.00045542
Epoch [117/300], Train Loss: 0.000385
Validation Loss: 0.00039741
Epoch [118/300], Train Loss: 0.000370
Validation Loss: 0.00038964
Epoch [119/300], Train Loss: 0.000366
Validation Loss: 0.00039788
Epoch [120/300], Train Loss: 0.000367
Validation Loss: 0.00038828
Epoch [121/300], Train Loss: 0.000365
Validation Loss: 0.00039332
Epoch [122/300], Train Loss: 0.000361
Validation Loss: 0.00038452
Epoch [123/300], Train Loss: 0.000363
Validation Loss: 0.00038243
Epoch [124/300], Train Loss: 0.000361
Validation Loss: 0.00039118
Epoch [125/300], Train Loss: 0.000358
Validation Loss: 0.00039040
Epoch [126/300], Train Loss: 0.000358
Validation Loss: 0.00040321
Epoch [127/300], Train Loss: 0.000359
Validation Loss: 0.00037633
Epoch [128/300], Train Loss: 0.000356
Validation Loss: 0.00036863
Epoch [129/300], Train Loss: 0.000357
Validation Loss: 0.00037161
Epoch [130/300], Train Loss: 0.000348
Validation Loss: 0.00036680
Epoch [131/300], Train Loss: 0.000359
Validation Loss: 0.00037591
Epoch [132/300], Train Loss: 0.000354
Validation Loss: 0.00036344
Epoch [133/300], Train Loss: 0.000345
Validation Loss: 0.00037124
Epoch [134/300], Train Loss: 0.000343
Validation Loss: 0.00036215
Epoch [135/300], Train Loss: 0.000347
Validation Loss: 0.00036624
Epoch [136/300], Train Loss: 0.000341
Validation Loss: 0.00035331
Epoch [137/300], Train Loss: 0.000335
Validation Loss: 0.00036203
Epoch [138/300], Train Loss: 0.000337
Validation Loss: 0.00034877
Epoch [139/300], Train Loss: 0.000332
Validation Loss: 0.00035735
Epoch [140/300], Train Loss: 0.000327
Validation Loss: 0.00035958
Epoch [141/300], Train Loss: 0.000327
Validation Loss: 0.00035520
Epoch [142/300], Train Loss: 0.000329
Validation Loss: 0.00037176
Epoch [143/300], Train Loss: 0.000326
Validation Loss: 0.00035122
Epoch [144/300], Train Loss: 0.000320
Validation Loss: 0.00035962
Epoch [145/300], Train Loss: 0.000325
Validation Loss: 0.00035109
Epoch [146/300], Train Loss: 0.000317
Validation Loss: 0.00034292
Epoch [147/300], Train Loss: 0.000344
Validation Loss: 0.00036807
Epoch [148/300], Train Loss: 0.000334
Validation Loss: 0.00034945
Epoch [149/300], Train Loss: 0.000323
Validation Loss: 0.00034008
Epoch [150/300], Train Loss: 0.000318
Validation Loss: 0.00034661
Epoch [151/300], Train Loss: 0.000316
Validation Loss: 0.00034315
Epoch [152/300], Train Loss: 0.000320
Validation Loss: 0.00033913
Epoch [153/300], Train Loss: 0.000308
Validation Loss: 0.00034154
Epoch [154/300], Train Loss: 0.000309
Validation Loss: 0.00034219
Epoch [155/300], Train Loss: 0.000305
Validation Loss: 0.00033011
Epoch [156/300], Train Loss: 0.000307
Validation Loss: 0.00033956
Epoch [157/300], Train Loss: 0.000302
Validation Loss: 0.00033986
Epoch [158/300], Train Loss: 0.000301
Validation Loss: 0.00033075
Epoch [159/300], Train Loss: 0.000300
Validation Loss: 0.00031676
Epoch [160/300], Train Loss: 0.000304
Validation Loss: 0.00033030
Epoch [161/300], Train Loss: 0.000305
Validation Loss: 0.00032467
Epoch [162/300], Train Loss: 0.000296
Validation Loss: 0.00033690
Epoch [163/300], Train Loss: 0.000301
Validation Loss: 0.00031498
Epoch [164/300], Train Loss: 0.000294
Validation Loss: 0.00032103
Epoch [165/300], Train Loss: 0.000293
Validation Loss: 0.00032042
Epoch [166/300], Train Loss: 0.000291
Validation Loss: 0.00031656
Epoch [167/300], Train Loss: 0.000293
Validation Loss: 0.00031601
Epoch [168/300], Train Loss: 0.000322
Validation Loss: 0.00031850
Epoch [169/300], Train Loss: 0.000303
Validation Loss: 0.00031091
Epoch [170/300], Train Loss: 0.000302
Validation Loss: 0.00030932
Epoch [171/300], Train Loss: 0.000295
Validation Loss: 0.00030577
Epoch [172/300], Train Loss: 0.000289
Validation Loss: 0.00030448
Epoch [173/300], Train Loss: 0.000288
Validation Loss: 0.00030628
Epoch [174/300], Train Loss: 0.000285
Validation Loss: 0.00030895
Epoch [175/300], Train Loss: 0.000290
Validation Loss: 0.00030359
Epoch [176/300], Train Loss: 0.000285
Validation Loss: 0.00030620
Epoch [177/300], Train Loss: 0.000282
Validation Loss: 0.00030164
Epoch [178/300], Train Loss: 0.000283
Validation Loss: 0.00030097
Epoch [179/300], Train Loss: 0.000283
Validation Loss: 0.00029985
Epoch [180/300], Train Loss: 0.000282
Validation Loss: 0.00030764
Epoch [181/300], Train Loss: 0.000281
Validation Loss: 0.00031164
Epoch [182/300], Train Loss: 0.000285
Validation Loss: 0.00030799
Epoch [183/300], Train Loss: 0.000278
Validation Loss: 0.00030853
Epoch [184/300], Train Loss: 0.000276
Validation Loss: 0.00030670
Epoch [185/300], Train Loss: 0.000279
Validation Loss: 0.00030869
Epoch [186/300], Train Loss: 0.000287
Validation Loss: 0.00030010
Epoch [187/300], Train Loss: 0.000280
Validation Loss: 0.00032346
Epoch [188/300], Train Loss: 0.000278
Validation Loss: 0.00029797
Epoch [189/300], Train Loss: 0.000276
Validation Loss: 0.00031470
Epoch [190/300], Train Loss: 0.000271
Validation Loss: 0.00030428
Epoch [191/300], Train Loss: 0.000270
Validation Loss: 0.00030372
Epoch [192/300], Train Loss: 0.000276
Validation Loss: 0.00030472
Epoch [193/300], Train Loss: 0.000274
Validation Loss: 0.00029843
Epoch [194/300], Train Loss: 0.000272
Validation Loss: 0.00030096
Epoch [195/300], Train Loss: 0.000272
Validation Loss: 0.00030248
Epoch [196/300], Train Loss: 0.000278
Validation Loss: 0.00029916
Epoch [197/300], Train Loss: 0.000266
Validation Loss: 0.00029774
Epoch [198/300], Train Loss: 0.000268
Validation Loss: 0.00031007
Epoch [199/300], Train Loss: 0.000268
Validation Loss: 0.00029596
Epoch [200/300], Train Loss: 0.000265
Validation Loss: 0.00032721
Epoch [201/300], Train Loss: 0.000274
Validation Loss: 0.00029780
Epoch [202/300], Train Loss: 0.000269
Validation Loss: 0.00030706
Epoch [203/300], Train Loss: 0.000282
Validation Loss: 0.00028660
Epoch [204/300], Train Loss: 0.000277
Validation Loss: 0.00028660
Epoch [205/300], Train Loss: 0.000265
Validation Loss: 0.00028981
Epoch [206/300], Train Loss: 0.000261
Validation Loss: 0.00028305
Epoch [207/300], Train Loss: 0.000265
Validation Loss: 0.00029895
Epoch [208/300], Train Loss: 0.000263
Validation Loss: 0.00029248
Epoch [209/300], Train Loss: 0.000261
Validation Loss: 0.00029365
Epoch [210/300], Train Loss: 0.000258
Validation Loss: 0.00029276
Epoch [211/300], Train Loss: 0.000258
Validation Loss: 0.00029308
Epoch [212/300], Train Loss: 0.000257
Validation Loss: 0.00029350
Epoch [213/300], Train Loss: 0.000264
Validation Loss: 0.00029342
Epoch [214/300], Train Loss: 0.000256
Validation Loss: 0.00028848
Epoch [215/300], Train Loss: 0.000261
Validation Loss: 0.00029327
Epoch [216/300], Train Loss: 0.000258
Validation Loss: 0.00028832
Early stopping triggered

Evaluating model for: Coffee Machine
Run 6/72 completed in 5173.10 seconds with: {'MAE': np.float32(3.4951835), 'MSE': np.float32(1005.6028), 'RMSE': np.float32(31.71124), 'SAE': np.float32(0.10001137), 'NDE': np.float32(0.51252186)}

Run 7/72: hidden=128, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Coffee Machine
Dataset length: 18100 windows

Epoch [1/300], Train Loss: 0.001045
Validation Loss: 0.00094020
Epoch [2/300], Train Loss: 0.000979
Validation Loss: 0.00093786
Epoch [3/300], Train Loss: 0.000994
Validation Loss: 0.00093675
Epoch [4/300], Train Loss: 0.000983
Validation Loss: 0.00093614
Epoch [5/300], Train Loss: 0.000969
Validation Loss: 0.00093514
Epoch [6/300], Train Loss: 0.000973
Validation Loss: 0.00093380
Epoch [7/300], Train Loss: 0.000966
Validation Loss: 0.00093249
Epoch [8/300], Train Loss: 0.000964
Validation Loss: 0.00093011
Epoch [9/300], Train Loss: 0.000969
Validation Loss: 0.00092681
Epoch [10/300], Train Loss: 0.000964
Validation Loss: 0.00092321
Epoch [11/300], Train Loss: 0.000954
Validation Loss: 0.00091740
Epoch [12/300], Train Loss: 0.000947
Validation Loss: 0.00090819
Epoch [13/300], Train Loss: 0.000959
Validation Loss: 0.00089875
Epoch [14/300], Train Loss: 0.000927
Validation Loss: 0.00087153
Epoch [15/300], Train Loss: 0.000881
Validation Loss: 0.00081987
Epoch [16/300], Train Loss: 0.000823
Validation Loss: 0.00078473
Epoch [17/300], Train Loss: 0.000784
Validation Loss: 0.00075527
Epoch [18/300], Train Loss: 0.000759
Validation Loss: 0.00074095
Epoch [19/300], Train Loss: 0.000728
Validation Loss: 0.00074256
Epoch [20/300], Train Loss: 0.000708
Validation Loss: 0.00070204
Epoch [21/300], Train Loss: 0.000690
Validation Loss: 0.00068861
Epoch [22/300], Train Loss: 0.000669
Validation Loss: 0.00069672
Epoch [23/300], Train Loss: 0.000690
Validation Loss: 0.00068211
Epoch [24/300], Train Loss: 0.000663
Validation Loss: 0.00067742
Epoch [25/300], Train Loss: 0.000639
Validation Loss: 0.00065044
Epoch [26/300], Train Loss: 0.000619
Validation Loss: 0.00063958
Epoch [27/300], Train Loss: 0.000629
Validation Loss: 0.00063487
Epoch [28/300], Train Loss: 0.000624
Validation Loss: 0.00061636
Epoch [29/300], Train Loss: 0.000625
Validation Loss: 0.00062110
Epoch [30/300], Train Loss: 0.000596
Validation Loss: 0.00062580
Epoch [31/300], Train Loss: 0.000593
Validation Loss: 0.00061423
Epoch [32/300], Train Loss: 0.000576
Validation Loss: 0.00061284
Epoch [33/300], Train Loss: 0.000579
Validation Loss: 0.00060610
Epoch [34/300], Train Loss: 0.000576
Validation Loss: 0.00062119
Epoch [35/300], Train Loss: 0.000561
Validation Loss: 0.00058899
Epoch [36/300], Train Loss: 0.000576
Validation Loss: 0.00064088
Epoch [37/300], Train Loss: 0.000571
Validation Loss: 0.00061593
Epoch [38/300], Train Loss: 0.000559
Validation Loss: 0.00058951
Epoch [39/300], Train Loss: 0.000552
Validation Loss: 0.00056259
Epoch [40/300], Train Loss: 0.000548
Validation Loss: 0.00057427
Epoch [41/300], Train Loss: 0.000535
Validation Loss: 0.00055474
Epoch [42/300], Train Loss: 0.000527
Validation Loss: 0.00054509
Epoch [43/300], Train Loss: 0.000542
Validation Loss: 0.00052306
Epoch [44/300], Train Loss: 0.000522
Validation Loss: 0.00051150
Epoch [45/300], Train Loss: 0.000489
Validation Loss: 0.00051089
Epoch [46/300], Train Loss: 0.000474
Validation Loss: 0.00045388
Epoch [47/300], Train Loss: 0.000458
Validation Loss: 0.00047192
Epoch [48/300], Train Loss: 0.000454
Validation Loss: 0.00042753
Epoch [49/300], Train Loss: 0.000440
Validation Loss: 0.00042992
Epoch [50/300], Train Loss: 0.000432
Validation Loss: 0.00041949
Epoch [51/300], Train Loss: 0.000421
Validation Loss: 0.00043219
Epoch [52/300], Train Loss: 0.000409
Validation Loss: 0.00040506
Epoch [53/300], Train Loss: 0.000415
Validation Loss: 0.00039659
Epoch [54/300], Train Loss: 0.000406
Validation Loss: 0.00039059
Epoch [55/300], Train Loss: 0.000406
Validation Loss: 0.00036588
Epoch [56/300], Train Loss: 0.000397
Validation Loss: 0.00037175
Epoch [57/300], Train Loss: 0.000388
Validation Loss: 0.00037182
Epoch [58/300], Train Loss: 0.000391
Validation Loss: 0.00037869
Epoch [59/300], Train Loss: 0.000377
Validation Loss: 0.00034372
Epoch [60/300], Train Loss: 0.000376
Validation Loss: 0.00037275
Epoch [61/300], Train Loss: 0.000374
Validation Loss: 0.00035534
Epoch [62/300], Train Loss: 0.000361
Validation Loss: 0.00033645
Epoch [63/300], Train Loss: 0.000361
Validation Loss: 0.00033584
Epoch [64/300], Train Loss: 0.000361
Validation Loss: 0.00033726
Epoch [65/300], Train Loss: 0.000362
Validation Loss: 0.00032497
Epoch [66/300], Train Loss: 0.000353
Validation Loss: 0.00035120
Epoch [67/300], Train Loss: 0.000357
Validation Loss: 0.00033225
Epoch [68/300], Train Loss: 0.000353
Validation Loss: 0.00032967
Epoch [69/300], Train Loss: 0.000349
Validation Loss: 0.00031782
Epoch [70/300], Train Loss: 0.000346
Validation Loss: 0.00032339
Epoch [71/300], Train Loss: 0.000343
Validation Loss: 0.00032172
Epoch [72/300], Train Loss: 0.000342
Validation Loss: 0.00033347
Epoch [73/300], Train Loss: 0.000335
Validation Loss: 0.00033783
Epoch [74/300], Train Loss: 0.000337
Validation Loss: 0.00032122
Epoch [75/300], Train Loss: 0.000332
Validation Loss: 0.00031361
Epoch [76/300], Train Loss: 0.000327
Validation Loss: 0.00031950
Epoch [77/300], Train Loss: 0.000328
Validation Loss: 0.00031917
Epoch [78/300], Train Loss: 0.000329
Validation Loss: 0.00031451
Epoch [79/300], Train Loss: 0.000334
Validation Loss: 0.00030943
Epoch [80/300], Train Loss: 0.000345
Validation Loss: 0.00031128
Epoch [81/300], Train Loss: 0.000323
Validation Loss: 0.00031296
Epoch [82/300], Train Loss: 0.000325
Validation Loss: 0.00031745
Epoch [83/300], Train Loss: 0.000323
Validation Loss: 0.00030629
Epoch [84/300], Train Loss: 0.000320
Validation Loss: 0.00031025
Epoch [85/300], Train Loss: 0.000314
Validation Loss: 0.00030984
Epoch [86/300], Train Loss: 0.000313
Validation Loss: 0.00031705
Epoch [87/300], Train Loss: 0.000307
Validation Loss: 0.00031772
Epoch [88/300], Train Loss: 0.000313
Validation Loss: 0.00030587
Epoch [89/300], Train Loss: 0.000321
Validation Loss: 0.00031383
Epoch [90/300], Train Loss: 0.000318
Validation Loss: 0.00030928
Epoch [91/300], Train Loss: 0.000302
Validation Loss: 0.00030733
Epoch [92/300], Train Loss: 0.000302
Validation Loss: 0.00031003
Epoch [93/300], Train Loss: 0.000314
Validation Loss: 0.00029633
Epoch [94/300], Train Loss: 0.000301
Validation Loss: 0.00031756
Epoch [95/300], Train Loss: 0.000298
Validation Loss: 0.00030275
Epoch [96/300], Train Loss: 0.000301
Validation Loss: 0.00030130
Epoch [97/300], Train Loss: 0.000296
Validation Loss: 0.00030718
Epoch [98/300], Train Loss: 0.000299
Validation Loss: 0.00031177
Epoch [99/300], Train Loss: 0.000301
Validation Loss: 0.00030189
Epoch [100/300], Train Loss: 0.000310
Validation Loss: 0.00029945
Epoch [101/300], Train Loss: 0.000297
Validation Loss: 0.00031199
Epoch [102/300], Train Loss: 0.000288
Validation Loss: 0.00030495
Epoch [103/300], Train Loss: 0.000292
Validation Loss: 0.00030418
Early stopping triggered

Evaluating model for: Coffee Machine
Run 7/72 completed in 2549.84 seconds with: {'MAE': np.float32(3.45314), 'MSE': np.float32(1095.3287), 'RMSE': np.float32(33.095753), 'SAE': np.float32(0.054262564), 'NDE': np.float32(0.534899)}

Run 8/72: hidden=128, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Coffee Machine
Dataset length: 18100 windows

Epoch [1/300], Train Loss: 0.000995
Validation Loss: 0.00093498
Epoch [2/300], Train Loss: 0.000973
Validation Loss: 0.00093397
Epoch [3/300], Train Loss: 0.000989
Validation Loss: 0.00093386
Epoch [4/300], Train Loss: 0.000980
Validation Loss: 0.00093421
Epoch [5/300], Train Loss: 0.000967
Validation Loss: 0.00093379
Epoch [6/300], Train Loss: 0.000972
Validation Loss: 0.00093332
Epoch [7/300], Train Loss: 0.000966
Validation Loss: 0.00093312
Epoch [8/300], Train Loss: 0.000965
Validation Loss: 0.00093373
Epoch [9/300], Train Loss: 0.000973
Validation Loss: 0.00093186
Epoch [10/300], Train Loss: 0.000970
Validation Loss: 0.00093021
Epoch [11/300], Train Loss: 0.000961
Validation Loss: 0.00092708
Epoch [12/300], Train Loss: 0.000959
Validation Loss: 0.00092362
Epoch [13/300], Train Loss: 0.000976
Validation Loss: 0.00091761
Epoch [14/300], Train Loss: 0.000935
Validation Loss: 0.00086493
Epoch [15/300], Train Loss: 0.000844
Validation Loss: 0.00078301
Epoch [16/300], Train Loss: 0.000765
Validation Loss: 0.00074400
Epoch [17/300], Train Loss: 0.000723
Validation Loss: 0.00073433
Epoch [18/300], Train Loss: 0.000704
Validation Loss: 0.00070716
Epoch [19/300], Train Loss: 0.000673
Validation Loss: 0.00071479
Epoch [20/300], Train Loss: 0.000658
Validation Loss: 0.00067543
Epoch [21/300], Train Loss: 0.000641
Validation Loss: 0.00067265
Epoch [22/300], Train Loss: 0.000619
Validation Loss: 0.00065002
Epoch [23/300], Train Loss: 0.000652
Validation Loss: 0.00065436
Epoch [24/300], Train Loss: 0.000605
Validation Loss: 0.00062874
Epoch [25/300], Train Loss: 0.000593
Validation Loss: 0.00059176
Epoch [26/300], Train Loss: 0.000593
Validation Loss: 0.00058322
Epoch [27/300], Train Loss: 0.000593
Validation Loss: 0.00058850
Epoch [28/300], Train Loss: 0.000617
Validation Loss: 0.00060006
Epoch [29/300], Train Loss: 0.000586
Validation Loss: 0.00058833
Epoch [30/300], Train Loss: 0.000557
Validation Loss: 0.00062130
Epoch [31/300], Train Loss: 0.000562
Validation Loss: 0.00056344
Epoch [32/300], Train Loss: 0.000542
Validation Loss: 0.00056873
Epoch [33/300], Train Loss: 0.000547
Validation Loss: 0.00054203
Epoch [34/300], Train Loss: 0.000538
Validation Loss: 0.00055253
Epoch [35/300], Train Loss: 0.000541
Validation Loss: 0.00054692
Epoch [36/300], Train Loss: 0.000545
Validation Loss: 0.00058998
Epoch [37/300], Train Loss: 0.000524
Validation Loss: 0.00054708
Epoch [38/300], Train Loss: 0.000521
Validation Loss: 0.00052475
Epoch [39/300], Train Loss: 0.000513
Validation Loss: 0.00053387
Epoch [40/300], Train Loss: 0.000508
Validation Loss: 0.00054279
Epoch [41/300], Train Loss: 0.000499
Validation Loss: 0.00054446
Epoch [42/300], Train Loss: 0.000496
Validation Loss: 0.00053661
Epoch [43/300], Train Loss: 0.000504
Validation Loss: 0.00049808
Epoch [44/300], Train Loss: 0.000490
Validation Loss: 0.00049953
Epoch [45/300], Train Loss: 0.000484
Validation Loss: 0.00053604
Epoch [46/300], Train Loss: 0.000487
Validation Loss: 0.00048558
Epoch [47/300], Train Loss: 0.000474
Validation Loss: 0.00053514
Epoch [48/300], Train Loss: 0.000477
Validation Loss: 0.00046957
Epoch [49/300], Train Loss: 0.000461
Validation Loss: 0.00046917
Epoch [50/300], Train Loss: 0.000459
Validation Loss: 0.00047736
Epoch [51/300], Train Loss: 0.000443
Validation Loss: 0.00045797
Epoch [52/300], Train Loss: 0.000439
Validation Loss: 0.00044894
Epoch [53/300], Train Loss: 0.000439
Validation Loss: 0.00044245
Epoch [54/300], Train Loss: 0.000426
Validation Loss: 0.00042832
Epoch [55/300], Train Loss: 0.000433
Validation Loss: 0.00041763
Epoch [56/300], Train Loss: 0.000414
Validation Loss: 0.00043030
Epoch [57/300], Train Loss: 0.000409
Validation Loss: 0.00041298
Epoch [58/300], Train Loss: 0.000403
Validation Loss: 0.00042860
Epoch [59/300], Train Loss: 0.000404
Validation Loss: 0.00040359
Epoch [60/300], Train Loss: 0.000390
Validation Loss: 0.00039783
Epoch [61/300], Train Loss: 0.000391
Validation Loss: 0.00041094
Epoch [62/300], Train Loss: 0.000376
Validation Loss: 0.00038404
Epoch [63/300], Train Loss: 0.000380
Validation Loss: 0.00037034
Epoch [64/300], Train Loss: 0.000370
Validation Loss: 0.00038223
Epoch [65/300], Train Loss: 0.000369
Validation Loss: 0.00038050
Epoch [66/300], Train Loss: 0.000367
Validation Loss: 0.00037247
Epoch [67/300], Train Loss: 0.000375
Validation Loss: 0.00037505
Epoch [68/300], Train Loss: 0.000362
Validation Loss: 0.00038041
Epoch [69/300], Train Loss: 0.000357
Validation Loss: 0.00037307
Epoch [70/300], Train Loss: 0.000354
Validation Loss: 0.00037391
Epoch [71/300], Train Loss: 0.000354
Validation Loss: 0.00036465
Epoch [72/300], Train Loss: 0.000357
Validation Loss: 0.00037295
Epoch [73/300], Train Loss: 0.000350
Validation Loss: 0.00037168
Epoch [74/300], Train Loss: 0.000357
Validation Loss: 0.00035974
Epoch [75/300], Train Loss: 0.000338
Validation Loss: 0.00033492
Epoch [76/300], Train Loss: 0.000336
Validation Loss: 0.00034582
Epoch [77/300], Train Loss: 0.000343
Validation Loss: 0.00035857
Epoch [78/300], Train Loss: 0.000338
Validation Loss: 0.00035477
Epoch [79/300], Train Loss: 0.000333
Validation Loss: 0.00036346
Epoch [80/300], Train Loss: 0.000336
Validation Loss: 0.00033941
Epoch [81/300], Train Loss: 0.000331
Validation Loss: 0.00034663
Epoch [82/300], Train Loss: 0.000331
Validation Loss: 0.00035392
Epoch [83/300], Train Loss: 0.000324
Validation Loss: 0.00033516
Epoch [84/300], Train Loss: 0.000320
Validation Loss: 0.00034849
Epoch [85/300], Train Loss: 0.000332
Validation Loss: 0.00033641
Early stopping triggered

Evaluating model for: Coffee Machine
Run 8/72 completed in 2102.65 seconds with: {'MAE': np.float32(3.9579794), 'MSE': np.float32(1168.4932), 'RMSE': np.float32(34.183228), 'SAE': np.float32(0.0032492694), 'NDE': np.float32(0.5524755)}

Run 9/72: hidden=128, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Coffee Machine
Dataset length: 11964 windows

Epoch [1/300], Train Loss: 0.000961
Validation Loss: 0.00102716
Epoch [2/300], Train Loss: 0.000947
Validation Loss: 0.00102536
Epoch [3/300], Train Loss: 0.000943
Validation Loss: 0.00102362
Epoch [4/300], Train Loss: 0.000939
Validation Loss: 0.00102165
Epoch [5/300], Train Loss: 0.000936
Validation Loss: 0.00102026
Epoch [6/300], Train Loss: 0.000930
Validation Loss: 0.00101318
Epoch [7/300], Train Loss: 0.000926
Validation Loss: 0.00100897
Epoch [8/300], Train Loss: 0.000921
Validation Loss: 0.00100433
Epoch [9/300], Train Loss: 0.000918
Validation Loss: 0.00099813
Epoch [10/300], Train Loss: 0.000913
Validation Loss: 0.00098981
Epoch [11/300], Train Loss: 0.000904
Validation Loss: 0.00097685
Epoch [12/300], Train Loss: 0.000893
Validation Loss: 0.00096195
Epoch [13/300], Train Loss: 0.000881
Validation Loss: 0.00094133
Epoch [14/300], Train Loss: 0.000859
Validation Loss: 0.00090842
Epoch [15/300], Train Loss: 0.000834
Validation Loss: 0.00088542
Epoch [16/300], Train Loss: 0.000803
Validation Loss: 0.00084541
Epoch [17/300], Train Loss: 0.000774
Validation Loss: 0.00082259
Epoch [18/300], Train Loss: 0.000751
Validation Loss: 0.00078636
Epoch [19/300], Train Loss: 0.000726
Validation Loss: 0.00075795
Epoch [20/300], Train Loss: 0.000706
Validation Loss: 0.00074281
Epoch [21/300], Train Loss: 0.000691
Validation Loss: 0.00072423
Epoch [22/300], Train Loss: 0.000677
Validation Loss: 0.00071559
Epoch [23/300], Train Loss: 0.000664
Validation Loss: 0.00069961
Epoch [24/300], Train Loss: 0.000642
Validation Loss: 0.00068614
Epoch [25/300], Train Loss: 0.000634
Validation Loss: 0.00068348
Epoch [26/300], Train Loss: 0.000621
Validation Loss: 0.00064995
Epoch [27/300], Train Loss: 0.000614
Validation Loss: 0.00064150
Epoch [28/300], Train Loss: 0.000603
Validation Loss: 0.00063845
Epoch [29/300], Train Loss: 0.000592
Validation Loss: 0.00062149
Epoch [30/300], Train Loss: 0.000582
Validation Loss: 0.00061049
Epoch [31/300], Train Loss: 0.000575
Validation Loss: 0.00061508
Epoch [32/300], Train Loss: 0.000564
Validation Loss: 0.00060669
Epoch [33/300], Train Loss: 0.000564
Validation Loss: 0.00059909
Epoch [34/300], Train Loss: 0.000559
Validation Loss: 0.00058654
Epoch [35/300], Train Loss: 0.000547
Validation Loss: 0.00058626
Epoch [36/300], Train Loss: 0.000539
Validation Loss: 0.00059263
Epoch [37/300], Train Loss: 0.000532
Validation Loss: 0.00056785
Epoch [38/300], Train Loss: 0.000524
Validation Loss: 0.00056618
Epoch [39/300], Train Loss: 0.000519
Validation Loss: 0.00056022
Epoch [40/300], Train Loss: 0.000515
Validation Loss: 0.00055864
Epoch [41/300], Train Loss: 0.000514
Validation Loss: 0.00054833
Epoch [42/300], Train Loss: 0.000508
Validation Loss: 0.00055023
Epoch [43/300], Train Loss: 0.000547
Validation Loss: 0.00061514
Epoch [44/300], Train Loss: 0.000537
Validation Loss: 0.00055300
Epoch [45/300], Train Loss: 0.000511
Validation Loss: 0.00055190
Epoch [46/300], Train Loss: 0.000503
Validation Loss: 0.00053589
Epoch [47/300], Train Loss: 0.000500
Validation Loss: 0.00053443
Epoch [48/300], Train Loss: 0.000491
Validation Loss: 0.00052898
Epoch [49/300], Train Loss: 0.000491
Validation Loss: 0.00053857
Epoch [50/300], Train Loss: 0.000485
Validation Loss: 0.00055559
Epoch [51/300], Train Loss: 0.000484
Validation Loss: 0.00052790
Epoch [52/300], Train Loss: 0.000479
Validation Loss: 0.00052333
Epoch [53/300], Train Loss: 0.000479
Validation Loss: 0.00051990
Epoch [54/300], Train Loss: 0.000473
Validation Loss: 0.00052013
Epoch [55/300], Train Loss: 0.000471
Validation Loss: 0.00051421
Epoch [56/300], Train Loss: 0.000468
Validation Loss: 0.00050917
Epoch [57/300], Train Loss: 0.000477
Validation Loss: 0.00050949
Epoch [58/300], Train Loss: 0.000466
Validation Loss: 0.00050659
Epoch [59/300], Train Loss: 0.000460
Validation Loss: 0.00050357
Epoch [60/300], Train Loss: 0.000459
Validation Loss: 0.00050466
Epoch [61/300], Train Loss: 0.000455
Validation Loss: 0.00050015
Epoch [62/300], Train Loss: 0.000448
Validation Loss: 0.00049825
Epoch [63/300], Train Loss: 0.000454
Validation Loss: 0.00049122
Epoch [64/300], Train Loss: 0.000451
Validation Loss: 0.00050099
Epoch [65/300], Train Loss: 0.000447
Validation Loss: 0.00048541
Epoch [66/300], Train Loss: 0.000441
Validation Loss: 0.00048293
Epoch [67/300], Train Loss: 0.000441
Validation Loss: 0.00047662
Epoch [68/300], Train Loss: 0.000436
Validation Loss: 0.00047409
Epoch [69/300], Train Loss: 0.000442
Validation Loss: 0.00048557
Epoch [70/300], Train Loss: 0.000432
Validation Loss: 0.00047676
Epoch [71/300], Train Loss: 0.000430
Validation Loss: 0.00046454
Epoch [72/300], Train Loss: 0.000428
Validation Loss: 0.00046218
Epoch [73/300], Train Loss: 0.000423
Validation Loss: 0.00046541
Epoch [74/300], Train Loss: 0.000420
Validation Loss: 0.00047141
Epoch [75/300], Train Loss: 0.000426
Validation Loss: 0.00045849
Epoch [76/300], Train Loss: 0.000416
Validation Loss: 0.00044515
Epoch [77/300], Train Loss: 0.000414
Validation Loss: 0.00044195
Epoch [78/300], Train Loss: 0.000412
Validation Loss: 0.00044394
Epoch [79/300], Train Loss: 0.000407
Validation Loss: 0.00043931
Epoch [80/300], Train Loss: 0.000408
Validation Loss: 0.00043332
Epoch [81/300], Train Loss: 0.000402
Validation Loss: 0.00044076
Epoch [82/300], Train Loss: 0.000400
Validation Loss: 0.00042817
Epoch [83/300], Train Loss: 0.000399
Validation Loss: 0.00042682
Epoch [84/300], Train Loss: 0.000392
Validation Loss: 0.00043305
Epoch [85/300], Train Loss: 0.000394
Validation Loss: 0.00043114
Epoch [86/300], Train Loss: 0.000391
Validation Loss: 0.00042203
Epoch [87/300], Train Loss: 0.000392
Validation Loss: 0.00041791
Epoch [88/300], Train Loss: 0.000385
Validation Loss: 0.00041784
Epoch [89/300], Train Loss: 0.000384
Validation Loss: 0.00041304
Epoch [90/300], Train Loss: 0.000378
Validation Loss: 0.00041551
Epoch [91/300], Train Loss: 0.000373
Validation Loss: 0.00040370
Epoch [92/300], Train Loss: 0.000367
Validation Loss: 0.00040937
Epoch [93/300], Train Loss: 0.000364
Validation Loss: 0.00040224
Epoch [94/300], Train Loss: 0.000365
Validation Loss: 0.00039247
Epoch [95/300], Train Loss: 0.000363
Validation Loss: 0.00039048
Epoch [96/300], Train Loss: 0.000357
Validation Loss: 0.00039120
Epoch [97/300], Train Loss: 0.000366
Validation Loss: 0.00038543
Epoch [98/300], Train Loss: 0.000352
Validation Loss: 0.00038083
Epoch [99/300], Train Loss: 0.000351
Validation Loss: 0.00038381
Epoch [100/300], Train Loss: 0.000356
Validation Loss: 0.00037421
Epoch [101/300], Train Loss: 0.000346
Validation Loss: 0.00037251
Epoch [102/300], Train Loss: 0.000341
Validation Loss: 0.00036738
Epoch [103/300], Train Loss: 0.000433
Validation Loss: 0.00051001
Epoch [104/300], Train Loss: 0.000433
Validation Loss: 0.00044513
Epoch [105/300], Train Loss: 0.000406
Validation Loss: 0.00041963
Epoch [106/300], Train Loss: 0.000393
Validation Loss: 0.00040102
Epoch [107/300], Train Loss: 0.000384
Validation Loss: 0.00039703
Epoch [108/300], Train Loss: 0.000374
Validation Loss: 0.00038451
Epoch [109/300], Train Loss: 0.000370
Validation Loss: 0.00037841
Epoch [110/300], Train Loss: 0.000366
Validation Loss: 0.00037611
Epoch [111/300], Train Loss: 0.000361
Validation Loss: 0.00036900
Epoch [112/300], Train Loss: 0.000351
Validation Loss: 0.00036459
Epoch [113/300], Train Loss: 0.000348
Validation Loss: 0.00036384
Epoch [114/300], Train Loss: 0.000346
Validation Loss: 0.00036090
Epoch [115/300], Train Loss: 0.000345
Validation Loss: 0.00035502
Epoch [116/300], Train Loss: 0.000340
Validation Loss: 0.00035286
Epoch [117/300], Train Loss: 0.000339
Validation Loss: 0.00035118
Epoch [118/300], Train Loss: 0.000338
Validation Loss: 0.00034942
Epoch [119/300], Train Loss: 0.000335
Validation Loss: 0.00034452
Epoch [120/300], Train Loss: 0.000333
Validation Loss: 0.00034833
Epoch [121/300], Train Loss: 0.000334
Validation Loss: 0.00034365
Epoch [122/300], Train Loss: 0.000332
Validation Loss: 0.00033987
Epoch [123/300], Train Loss: 0.000330
Validation Loss: 0.00033824
Epoch [124/300], Train Loss: 0.000330
Validation Loss: 0.00033794
Epoch [125/300], Train Loss: 0.000331
Validation Loss: 0.00033686
Epoch [126/300], Train Loss: 0.000328
Validation Loss: 0.00033832
Epoch [127/300], Train Loss: 0.000326
Validation Loss: 0.00033673
Epoch [128/300], Train Loss: 0.000327
Validation Loss: 0.00033381
Epoch [129/300], Train Loss: 0.000324
Validation Loss: 0.00033336
Epoch [130/300], Train Loss: 0.000324
Validation Loss: 0.00033293
Epoch [131/300], Train Loss: 0.000322
Validation Loss: 0.00032907
Epoch [132/300], Train Loss: 0.000324
Validation Loss: 0.00032830
Epoch [133/300], Train Loss: 0.000320
Validation Loss: 0.00032812
Epoch [134/300], Train Loss: 0.000317
Validation Loss: 0.00032655
Epoch [135/300], Train Loss: 0.000317
Validation Loss: 0.00032519
Epoch [136/300], Train Loss: 0.000318
Validation Loss: 0.00032307
Epoch [137/300], Train Loss: 0.000316
Validation Loss: 0.00032428
Epoch [138/300], Train Loss: 0.000312
Validation Loss: 0.00032435
Epoch [139/300], Train Loss: 0.000313
Validation Loss: 0.00032551
Epoch [140/300], Train Loss: 0.000315
Validation Loss: 0.00032247
Epoch [141/300], Train Loss: 0.000313
Validation Loss: 0.00032060
Epoch [142/300], Train Loss: 0.000311
Validation Loss: 0.00032241
Epoch [143/300], Train Loss: 0.000311
Validation Loss: 0.00031675
Epoch [144/300], Train Loss: 0.000312
Validation Loss: 0.00031593
Epoch [145/300], Train Loss: 0.000312
Validation Loss: 0.00035978
Epoch [146/300], Train Loss: 0.000315
Validation Loss: 0.00031673
Epoch [147/300], Train Loss: 0.000307
Validation Loss: 0.00031118
Epoch [148/300], Train Loss: 0.000315
Validation Loss: 0.00031353
Epoch [149/300], Train Loss: 0.000305
Validation Loss: 0.00032039
Epoch [150/300], Train Loss: 0.000305
Validation Loss: 0.00031022
Epoch [151/300], Train Loss: 0.000306
Validation Loss: 0.00030455
Epoch [152/300], Train Loss: 0.000303
Validation Loss: 0.00031193
Epoch [153/300], Train Loss: 0.000301
Validation Loss: 0.00031209
Epoch [154/300], Train Loss: 0.000300
Validation Loss: 0.00030376
Epoch [155/300], Train Loss: 0.000298
Validation Loss: 0.00030444
Epoch [156/300], Train Loss: 0.000299
Validation Loss: 0.00030351
Epoch [157/300], Train Loss: 0.000304
Validation Loss: 0.00036329
Epoch [158/300], Train Loss: 0.000363
Validation Loss: 0.00032078
Epoch [159/300], Train Loss: 0.000317
Validation Loss: 0.00031434
Epoch [160/300], Train Loss: 0.000310
Validation Loss: 0.00030960
Epoch [161/300], Train Loss: 0.000305
Validation Loss: 0.00030496
Epoch [162/300], Train Loss: 0.000305
Validation Loss: 0.00030388
Epoch [163/300], Train Loss: 0.000300
Validation Loss: 0.00030358
Epoch [164/300], Train Loss: 0.000296
Validation Loss: 0.00030090
Epoch [165/300], Train Loss: 0.000295
Validation Loss: 0.00029625
Epoch [166/300], Train Loss: 0.000293
Validation Loss: 0.00029557
Epoch [167/300], Train Loss: 0.000291
Validation Loss: 0.00029467
Epoch [168/300], Train Loss: 0.000290
Validation Loss: 0.00029819
Epoch [169/300], Train Loss: 0.000291
Validation Loss: 0.00029400
Epoch [170/300], Train Loss: 0.000289
Validation Loss: 0.00028875
Epoch [171/300], Train Loss: 0.000289
Validation Loss: 0.00029024
Epoch [172/300], Train Loss: 0.000289
Validation Loss: 0.00028742
Epoch [173/300], Train Loss: 0.000286
Validation Loss: 0.00029354
Epoch [174/300], Train Loss: 0.000286
Validation Loss: 0.00028695
Epoch [175/300], Train Loss: 0.000288
Validation Loss: 0.00028357
Epoch [176/300], Train Loss: 0.000286
Validation Loss: 0.00028429
Epoch [177/300], Train Loss: 0.000283
Validation Loss: 0.00028408
Epoch [178/300], Train Loss: 0.000285
Validation Loss: 0.00028343
Epoch [179/300], Train Loss: 0.000283
Validation Loss: 0.00028514
Epoch [180/300], Train Loss: 0.000282
Validation Loss: 0.00028115
Epoch [181/300], Train Loss: 0.000284
Validation Loss: 0.00027531
Epoch [182/300], Train Loss: 0.000281
Validation Loss: 0.00028437
Epoch [183/300], Train Loss: 0.000280
Validation Loss: 0.00027943
Epoch [184/300], Train Loss: 0.000279
Validation Loss: 0.00027424
Epoch [185/300], Train Loss: 0.000278
Validation Loss: 0.00027329
Epoch [186/300], Train Loss: 0.000279
Validation Loss: 0.00027220
Epoch [187/300], Train Loss: 0.000278
Validation Loss: 0.00029098
Epoch [188/300], Train Loss: 0.000280
Validation Loss: 0.00027240
Epoch [189/300], Train Loss: 0.000275
Validation Loss: 0.00027446
Epoch [190/300], Train Loss: 0.000277
Validation Loss: 0.00026731
Epoch [191/300], Train Loss: 0.000278
Validation Loss: 0.00027597
Epoch [192/300], Train Loss: 0.000279
Validation Loss: 0.00027097
Epoch [193/300], Train Loss: 0.000280
Validation Loss: 0.00027484
Epoch [194/300], Train Loss: 0.000272
Validation Loss: 0.00028612
Epoch [195/300], Train Loss: 0.000272
Validation Loss: 0.00028575
Epoch [196/300], Train Loss: 0.000269
Validation Loss: 0.00026776
Epoch [197/300], Train Loss: 0.000272
Validation Loss: 0.00026633
Epoch [198/300], Train Loss: 0.000272
Validation Loss: 0.00028114
Epoch [199/300], Train Loss: 0.000269
Validation Loss: 0.00026817
Epoch [200/300], Train Loss: 0.000271
Validation Loss: 0.00026285
Epoch [201/300], Train Loss: 0.000284
Validation Loss: 0.00031503
Epoch [202/300], Train Loss: 0.000285
Validation Loss: 0.00027677
Epoch [203/300], Train Loss: 0.000276
Validation Loss: 0.00027622
Epoch [204/300], Train Loss: 0.000272
Validation Loss: 0.00027025
Epoch [205/300], Train Loss: 0.000272
Validation Loss: 0.00026594
Epoch [206/300], Train Loss: 0.000270
Validation Loss: 0.00026532
Epoch [207/300], Train Loss: 0.000267
Validation Loss: 0.00026157
Epoch [208/300], Train Loss: 0.000267
Validation Loss: 0.00026846
Epoch [209/300], Train Loss: 0.000265
Validation Loss: 0.00026254
Epoch [210/300], Train Loss: 0.000263
Validation Loss: 0.00026234
Epoch [211/300], Train Loss: 0.000262
Validation Loss: 0.00026530
Epoch [212/300], Train Loss: 0.000262
Validation Loss: 0.00026312
Epoch [213/300], Train Loss: 0.000263
Validation Loss: 0.00026278
Epoch [214/300], Train Loss: 0.000260
Validation Loss: 0.00025782
Epoch [215/300], Train Loss: 0.000259
Validation Loss: 0.00026252
Epoch [216/300], Train Loss: 0.000266
Validation Loss: 0.00027389
Epoch [217/300], Train Loss: 0.000260
Validation Loss: 0.00026055
Epoch [218/300], Train Loss: 0.000258
Validation Loss: 0.00031650
Epoch [219/300], Train Loss: 0.000267
Validation Loss: 0.00025856
Epoch [220/300], Train Loss: 0.000258
Validation Loss: 0.00025667
Epoch [221/300], Train Loss: 0.000257
Validation Loss: 0.00026480
Epoch [222/300], Train Loss: 0.000256
Validation Loss: 0.00025680
Epoch [223/300], Train Loss: 0.000278
Validation Loss: 0.00034436
Epoch [224/300], Train Loss: 0.000277
Validation Loss: 0.00027070
Epoch [225/300], Train Loss: 0.000262
Validation Loss: 0.00026518
Epoch [226/300], Train Loss: 0.000265
Validation Loss: 0.00026298
Epoch [227/300], Train Loss: 0.000257
Validation Loss: 0.00025430
Epoch [228/300], Train Loss: 0.000255
Validation Loss: 0.00025548
Epoch [229/300], Train Loss: 0.000256
Validation Loss: 0.00025368
Epoch [230/300], Train Loss: 0.000254
Validation Loss: 0.00025545
Epoch [231/300], Train Loss: 0.000254
Validation Loss: 0.00025531
Epoch [232/300], Train Loss: 0.000252
Validation Loss: 0.00026129
Epoch [233/300], Train Loss: 0.000255
Validation Loss: 0.00025308
Epoch [234/300], Train Loss: 0.000279
Validation Loss: 0.00039363
Epoch [235/300], Train Loss: 0.000332
Validation Loss: 0.00029622
Epoch [236/300], Train Loss: 0.000280
Validation Loss: 0.00026362
Epoch [237/300], Train Loss: 0.000260
Validation Loss: 0.00026614
Epoch [238/300], Train Loss: 0.000257
Validation Loss: 0.00026739
Epoch [239/300], Train Loss: 0.000255
Validation Loss: 0.00026363
Epoch [240/300], Train Loss: 0.000254
Validation Loss: 0.00026108
Epoch [241/300], Train Loss: 0.000251
Validation Loss: 0.00026081
Epoch [242/300], Train Loss: 0.000252
Validation Loss: 0.00025557
Epoch [243/300], Train Loss: 0.000254
Validation Loss: 0.00025864
Early stopping triggered

Evaluating model for: Coffee Machine
Run 9/72 completed in 4176.10 seconds with: {'MAE': np.float32(4.0564885), 'MSE': np.float32(1209.67), 'RMSE': np.float32(34.78031), 'SAE': np.float32(0.062823676), 'NDE': np.float32(0.4833913)}

Run 10/72: hidden=128, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Coffee Machine
Dataset length: 11964 windows

Epoch [1/300], Train Loss: 0.000964
Validation Loss: 0.00102858
Epoch [2/300], Train Loss: 0.000947
Validation Loss: 0.00102762
Epoch [3/300], Train Loss: 0.000944
Validation Loss: 0.00102631
Epoch [4/300], Train Loss: 0.000941
Validation Loss: 0.00102471
Epoch [5/300], Train Loss: 0.000940
Validation Loss: 0.00102443
Epoch [6/300], Train Loss: 0.000937
Validation Loss: 0.00102148
Epoch [7/300], Train Loss: 0.000935
Validation Loss: 0.00101713
Epoch [8/300], Train Loss: 0.000929
Validation Loss: 0.00101202
Epoch [9/300], Train Loss: 0.000925
Validation Loss: 0.00100456
Epoch [10/300], Train Loss: 0.000917
Validation Loss: 0.00099061
Epoch [11/300], Train Loss: 0.000899
Validation Loss: 0.00096193
Epoch [12/300], Train Loss: 0.000869
Validation Loss: 0.00091559
Epoch [13/300], Train Loss: 0.000822
Validation Loss: 0.00085088
Epoch [14/300], Train Loss: 0.000770
Validation Loss: 0.00080398
Epoch [15/300], Train Loss: 0.000737
Validation Loss: 0.00082068
Epoch [16/300], Train Loss: 0.000709
Validation Loss: 0.00075058
Epoch [17/300], Train Loss: 0.000687
Validation Loss: 0.00072681
Epoch [18/300], Train Loss: 0.000680
Validation Loss: 0.00072145
Epoch [19/300], Train Loss: 0.000663
Validation Loss: 0.00070464
Epoch [20/300], Train Loss: 0.000647
Validation Loss: 0.00068622
Epoch [21/300], Train Loss: 0.000635
Validation Loss: 0.00068565
Epoch [22/300], Train Loss: 0.000623
Validation Loss: 0.00066016
Epoch [23/300], Train Loss: 0.000622
Validation Loss: 0.00065853
Epoch [24/300], Train Loss: 0.000598
Validation Loss: 0.00063878
Epoch [25/300], Train Loss: 0.000585
Validation Loss: 0.00062385
Epoch [26/300], Train Loss: 0.000577
Validation Loss: 0.00061528
Epoch [27/300], Train Loss: 0.000571
Validation Loss: 0.00060536
Epoch [28/300], Train Loss: 0.000560
Validation Loss: 0.00059468
Epoch [29/300], Train Loss: 0.000556
Validation Loss: 0.00059220
Epoch [30/300], Train Loss: 0.000545
Validation Loss: 0.00057263
Epoch [31/300], Train Loss: 0.000543
Validation Loss: 0.00056815
Epoch [32/300], Train Loss: 0.000531
Validation Loss: 0.00058367
Epoch [33/300], Train Loss: 0.000528
Validation Loss: 0.00056259
Epoch [34/300], Train Loss: 0.000526
Validation Loss: 0.00054747
Epoch [35/300], Train Loss: 0.000513
Validation Loss: 0.00054817
Epoch [36/300], Train Loss: 0.000504
Validation Loss: 0.00055269
Epoch [37/300], Train Loss: 0.000501
Validation Loss: 0.00052502
Epoch [38/300], Train Loss: 0.000492
Validation Loss: 0.00051836
Epoch [39/300], Train Loss: 0.000485
Validation Loss: 0.00050840
Epoch [40/300], Train Loss: 0.000481
Validation Loss: 0.00051846
Epoch [41/300], Train Loss: 0.000481
Validation Loss: 0.00050614
Epoch [42/300], Train Loss: 0.000477
Validation Loss: 0.00050288
Epoch [43/300], Train Loss: 0.000466
Validation Loss: 0.00050120
Epoch [44/300], Train Loss: 0.000454
Validation Loss: 0.00049669
Epoch [45/300], Train Loss: 0.000458
Validation Loss: 0.00049409
Epoch [46/300], Train Loss: 0.000450
Validation Loss: 0.00048803
Epoch [47/300], Train Loss: 0.000446
Validation Loss: 0.00047608
Epoch [48/300], Train Loss: 0.000438
Validation Loss: 0.00046963
Epoch [49/300], Train Loss: 0.000434
Validation Loss: 0.00046765
Epoch [50/300], Train Loss: 0.000429
Validation Loss: 0.00050117
Epoch [51/300], Train Loss: 0.000428
Validation Loss: 0.00045823
Epoch [52/300], Train Loss: 0.000418
Validation Loss: 0.00045146
Epoch [53/300], Train Loss: 0.000413
Validation Loss: 0.00043742
Epoch [54/300], Train Loss: 0.000447
Validation Loss: 0.00044248
Epoch [55/300], Train Loss: 0.000410
Validation Loss: 0.00044742
Epoch [56/300], Train Loss: 0.000402
Validation Loss: 0.00043032
Epoch [57/300], Train Loss: 0.000402
Validation Loss: 0.00042705
Epoch [58/300], Train Loss: 0.000391
Validation Loss: 0.00041848
Epoch [59/300], Train Loss: 0.000388
Validation Loss: 0.00041839
Epoch [60/300], Train Loss: 0.000382
Validation Loss: 0.00042053
Epoch [61/300], Train Loss: 0.000373
Validation Loss: 0.00039897
Epoch [62/300], Train Loss: 0.000368
Validation Loss: 0.00039598
Epoch [63/300], Train Loss: 0.000406
Validation Loss: 0.00043009
Epoch [64/300], Train Loss: 0.000405
Validation Loss: 0.00040444
Epoch [65/300], Train Loss: 0.000385
Validation Loss: 0.00039899
Epoch [66/300], Train Loss: 0.000367
Validation Loss: 0.00038322
Epoch [67/300], Train Loss: 0.000361
Validation Loss: 0.00038294
Epoch [68/300], Train Loss: 0.000354
Validation Loss: 0.00038235
Epoch [69/300], Train Loss: 0.000352
Validation Loss: 0.00037143
Epoch [70/300], Train Loss: 0.000344
Validation Loss: 0.00037437
Epoch [71/300], Train Loss: 0.000337
Validation Loss: 0.00035453
Epoch [72/300], Train Loss: 0.000332
Validation Loss: 0.00035381
Epoch [73/300], Train Loss: 0.000328
Validation Loss: 0.00034564
Epoch [74/300], Train Loss: 0.000325
Validation Loss: 0.00034348
Epoch [75/300], Train Loss: 0.000321
Validation Loss: 0.00033568
Epoch [76/300], Train Loss: 0.000317
Validation Loss: 0.00033895
Epoch [77/300], Train Loss: 0.000316
Validation Loss: 0.00032949
Epoch [78/300], Train Loss: 0.000314
Validation Loss: 0.00033902
Epoch [79/300], Train Loss: 0.000306
Validation Loss: 0.00031862
Epoch [80/300], Train Loss: 0.000301
Validation Loss: 0.00031807
Epoch [81/300], Train Loss: 0.000297
Validation Loss: 0.00031555
Epoch [82/300], Train Loss: 0.000301
Validation Loss: 0.00031262
Epoch [83/300], Train Loss: 0.000292
Validation Loss: 0.00030876
Epoch [84/300], Train Loss: 0.000293
Validation Loss: 0.00030837
Epoch [85/300], Train Loss: 0.000289
Validation Loss: 0.00030243
Epoch [86/300], Train Loss: 0.000287
Validation Loss: 0.00029967
Epoch [87/300], Train Loss: 0.000286
Validation Loss: 0.00029768
Epoch [88/300], Train Loss: 0.000283
Validation Loss: 0.00030069
Epoch [89/300], Train Loss: 0.000284
Validation Loss: 0.00029863
Epoch [90/300], Train Loss: 0.000282
Validation Loss: 0.00031055
Epoch [91/300], Train Loss: 0.000278
Validation Loss: 0.00029617
Epoch [92/300], Train Loss: 0.000294
Validation Loss: 0.00031981
Epoch [93/300], Train Loss: 0.000293
Validation Loss: 0.00031003
Epoch [94/300], Train Loss: 0.000283
Validation Loss: 0.00029190
Epoch [95/300], Train Loss: 0.000282
Validation Loss: 0.00029181
Epoch [96/300], Train Loss: 0.000277
Validation Loss: 0.00028468
Epoch [97/300], Train Loss: 0.000272
Validation Loss: 0.00028958
Epoch [98/300], Train Loss: 0.000271
Validation Loss: 0.00027904
Epoch [99/300], Train Loss: 0.000262
Validation Loss: 0.00028038
Epoch [100/300], Train Loss: 0.000258
Validation Loss: 0.00027574
Epoch [101/300], Train Loss: 0.000258
Validation Loss: 0.00027327
Epoch [102/300], Train Loss: 0.000260
Validation Loss: 0.00028029
Epoch [103/300], Train Loss: 0.000253
Validation Loss: 0.00027222
Epoch [104/300], Train Loss: 0.000251
Validation Loss: 0.00027306
Epoch [105/300], Train Loss: 0.000254
Validation Loss: 0.00027492
Epoch [106/300], Train Loss: 0.000248
Validation Loss: 0.00026669
Epoch [107/300], Train Loss: 0.000247
Validation Loss: 0.00026821
Epoch [108/300], Train Loss: 0.000249
Validation Loss: 0.00026040
Epoch [109/300], Train Loss: 0.000247
Validation Loss: 0.00026193
Epoch [110/300], Train Loss: 0.000244
Validation Loss: 0.00026685
Epoch [111/300], Train Loss: 0.000245
Validation Loss: 0.00027635
Epoch [112/300], Train Loss: 0.000244
Validation Loss: 0.00026433
Epoch [113/300], Train Loss: 0.000247
Validation Loss: 0.00026164
Epoch [114/300], Train Loss: 0.000241
Validation Loss: 0.00026047
Epoch [115/300], Train Loss: 0.000241
Validation Loss: 0.00025943
Epoch [116/300], Train Loss: 0.000238
Validation Loss: 0.00025613
Epoch [117/300], Train Loss: 0.000239
Validation Loss: 0.00025185
Epoch [118/300], Train Loss: 0.000236
Validation Loss: 0.00026394
Epoch [119/300], Train Loss: 0.000236
Validation Loss: 0.00025600
Epoch [120/300], Train Loss: 0.000231
Validation Loss: 0.00025652
Epoch [121/300], Train Loss: 0.000233
Validation Loss: 0.00024867
Epoch [122/300], Train Loss: 0.000254
Validation Loss: 0.00025331
Epoch [123/300], Train Loss: 0.000231
Validation Loss: 0.00025010
Epoch [124/300], Train Loss: 0.000230
Validation Loss: 0.00025209
Epoch [125/300], Train Loss: 0.000231
Validation Loss: 0.00025209
Epoch [126/300], Train Loss: 0.000228
Validation Loss: 0.00024934
Epoch [127/300], Train Loss: 0.000229
Validation Loss: 0.00024622
Epoch [128/300], Train Loss: 0.000224
Validation Loss: 0.00025170
Epoch [129/300], Train Loss: 0.000230
Validation Loss: 0.00024730
Epoch [130/300], Train Loss: 0.000223
Validation Loss: 0.00025403
Epoch [131/300], Train Loss: 0.000225
Validation Loss: 0.00024847
Epoch [132/300], Train Loss: 0.000226
Validation Loss: 0.00024879
Epoch [133/300], Train Loss: 0.000223
Validation Loss: 0.00023991
Epoch [134/300], Train Loss: 0.000219
Validation Loss: 0.00024359
Epoch [135/300], Train Loss: 0.000222
Validation Loss: 0.00023985
Epoch [136/300], Train Loss: 0.000219
Validation Loss: 0.00024829
Epoch [137/300], Train Loss: 0.000217
Validation Loss: 0.00024972
Epoch [138/300], Train Loss: 0.000215
Validation Loss: 0.00024005
Epoch [139/300], Train Loss: 0.000216
Validation Loss: 0.00024708
Epoch [140/300], Train Loss: 0.000220
Validation Loss: 0.00023974
Epoch [141/300], Train Loss: 0.000213
Validation Loss: 0.00024136
Epoch [142/300], Train Loss: 0.000227
Validation Loss: 0.00028318
Epoch [143/300], Train Loss: 0.000234
Validation Loss: 0.00024162
Epoch [144/300], Train Loss: 0.000216
Validation Loss: 0.00023509
Epoch [145/300], Train Loss: 0.000217
Validation Loss: 0.00023621
Epoch [146/300], Train Loss: 0.000213
Validation Loss: 0.00023640
Epoch [147/300], Train Loss: 0.000210
Validation Loss: 0.00024080
Epoch [148/300], Train Loss: 0.000210
Validation Loss: 0.00023505
Epoch [149/300], Train Loss: 0.000241
Validation Loss: 0.00025024
Epoch [150/300], Train Loss: 0.000226
Validation Loss: 0.00024738
Epoch [151/300], Train Loss: 0.000219
Validation Loss: 0.00023763
Epoch [152/300], Train Loss: 0.000216
Validation Loss: 0.00023524
Epoch [153/300], Train Loss: 0.000214
Validation Loss: 0.00023455
Epoch [154/300], Train Loss: 0.000214
Validation Loss: 0.00023507
Epoch [155/300], Train Loss: 0.000214
Validation Loss: 0.00024159
Epoch [156/300], Train Loss: 0.000212
Validation Loss: 0.00023703
Epoch [157/300], Train Loss: 0.000220
Validation Loss: 0.00023326
Epoch [158/300], Train Loss: 0.000214
Validation Loss: 0.00023612
Epoch [159/300], Train Loss: 0.000211
Validation Loss: 0.00022919
Epoch [160/300], Train Loss: 0.000210
Validation Loss: 0.00023335
Epoch [161/300], Train Loss: 0.000210
Validation Loss: 0.00023341
Epoch [162/300], Train Loss: 0.000208
Validation Loss: 0.00024488
Epoch [163/300], Train Loss: 0.000206
Validation Loss: 0.00022496
Epoch [164/300], Train Loss: 0.000209
Validation Loss: 0.00022816
Epoch [165/300], Train Loss: 0.000205
Validation Loss: 0.00023096
Epoch [166/300], Train Loss: 0.000201
Validation Loss: 0.00022764
Epoch [167/300], Train Loss: 0.000200
Validation Loss: 0.00022848
Epoch [168/300], Train Loss: 0.000202
Validation Loss: 0.00023482
Epoch [169/300], Train Loss: 0.000204
Validation Loss: 0.00023375
Epoch [170/300], Train Loss: 0.000203
Validation Loss: 0.00022806
Epoch [171/300], Train Loss: 0.000201
Validation Loss: 0.00023097
Epoch [172/300], Train Loss: 0.000201
Validation Loss: 0.00024382
Epoch [173/300], Train Loss: 0.000209
Validation Loss: 0.00023497
Early stopping triggered

Evaluating model for: Coffee Machine
Run 10/72 completed in 2926.74 seconds with: {'MAE': np.float32(3.7112005), 'MSE': np.float32(941.8842), 'RMSE': np.float32(30.690132), 'SAE': np.float32(0.02493714), 'NDE': np.float32(0.42654645)}

Run 11/72: hidden=128, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Coffee Machine
Dataset length: 11964 windows

Epoch [1/300], Train Loss: 0.000947
Validation Loss: 0.00102756
Epoch [2/300], Train Loss: 0.000942
Validation Loss: 0.00102717
Epoch [3/300], Train Loss: 0.000940
Validation Loss: 0.00102669
Epoch [4/300], Train Loss: 0.000939
Validation Loss: 0.00102631
Epoch [5/300], Train Loss: 0.000940
Validation Loss: 0.00102676
Epoch [6/300], Train Loss: 0.000938
Validation Loss: 0.00102547
Epoch [7/300], Train Loss: 0.000938
Validation Loss: 0.00102459
Epoch [8/300], Train Loss: 0.000935
Validation Loss: 0.00102302
Epoch [9/300], Train Loss: 0.000933
Validation Loss: 0.00101871
Epoch [10/300], Train Loss: 0.000931
Validation Loss: 0.00101481
Epoch [11/300], Train Loss: 0.000926
Validation Loss: 0.00100608
Epoch [12/300], Train Loss: 0.000915
Validation Loss: 0.00098325
Epoch [13/300], Train Loss: 0.000884
Validation Loss: 0.00092203
Epoch [14/300], Train Loss: 0.000825
Validation Loss: 0.00084558
Epoch [15/300], Train Loss: 0.000767
Validation Loss: 0.00081671
Epoch [16/300], Train Loss: 0.000714
Validation Loss: 0.00075628
Epoch [17/300], Train Loss: 0.000683
Validation Loss: 0.00071315
Epoch [18/300], Train Loss: 0.000657
Validation Loss: 0.00069922
Epoch [19/300], Train Loss: 0.000633
Validation Loss: 0.00066077
Epoch [20/300], Train Loss: 0.000622
Validation Loss: 0.00064479
Epoch [21/300], Train Loss: 0.000602
Validation Loss: 0.00064416
Epoch [22/300], Train Loss: 0.000588
Validation Loss: 0.00061154
Epoch [23/300], Train Loss: 0.000583
Validation Loss: 0.00061956
Epoch [24/300], Train Loss: 0.000559
Validation Loss: 0.00057717
Epoch [25/300], Train Loss: 0.000549
Validation Loss: 0.00057066
Epoch [26/300], Train Loss: 0.000536
Validation Loss: 0.00056612
Epoch [27/300], Train Loss: 0.000535
Validation Loss: 0.00055911
Epoch [28/300], Train Loss: 0.000525
Validation Loss: 0.00055066
Epoch [29/300], Train Loss: 0.000516
Validation Loss: 0.00055025
Epoch [30/300], Train Loss: 0.000510
Validation Loss: 0.00054008
Epoch [31/300], Train Loss: 0.000505
Validation Loss: 0.00052363
Epoch [32/300], Train Loss: 0.000496
Validation Loss: 0.00054416
Epoch [33/300], Train Loss: 0.000493
Validation Loss: 0.00051616
Epoch [34/300], Train Loss: 0.000487
Validation Loss: 0.00050891
Epoch [35/300], Train Loss: 0.000488
Validation Loss: 0.00050251
Epoch [36/300], Train Loss: 0.000474
Validation Loss: 0.00049296
Epoch [37/300], Train Loss: 0.000469
Validation Loss: 0.00050827
Epoch [38/300], Train Loss: 0.000461
Validation Loss: 0.00049209
Epoch [39/300], Train Loss: 0.000455
Validation Loss: 0.00047623
Epoch [40/300], Train Loss: 0.000453
Validation Loss: 0.00048154
Epoch [41/300], Train Loss: 0.000448
Validation Loss: 0.00047210
Epoch [42/300], Train Loss: 0.000445
Validation Loss: 0.00046688
Epoch [43/300], Train Loss: 0.000442
Validation Loss: 0.00047098
Epoch [44/300], Train Loss: 0.000436
Validation Loss: 0.00052405
Epoch [45/300], Train Loss: 0.000447
Validation Loss: 0.00047227
Epoch [46/300], Train Loss: 0.000431
Validation Loss: 0.00046736
Epoch [47/300], Train Loss: 0.000425
Validation Loss: 0.00045545
Epoch [48/300], Train Loss: 0.000418
Validation Loss: 0.00044539
Epoch [49/300], Train Loss: 0.000410
Validation Loss: 0.00042338
Epoch [50/300], Train Loss: 0.000405
Validation Loss: 0.00043253
Epoch [51/300], Train Loss: 0.000397
Validation Loss: 0.00041651
Epoch [52/300], Train Loss: 0.000390
Validation Loss: 0.00040730
Epoch [53/300], Train Loss: 0.000384
Validation Loss: 0.00040251
Epoch [54/300], Train Loss: 0.000376
Validation Loss: 0.00039770
Epoch [55/300], Train Loss: 0.000372
Validation Loss: 0.00039348
Epoch [56/300], Train Loss: 0.000366
Validation Loss: 0.00039864
Epoch [57/300], Train Loss: 0.000366
Validation Loss: 0.00040150
Epoch [58/300], Train Loss: 0.000353
Validation Loss: 0.00037410
Epoch [59/300], Train Loss: 0.000355
Validation Loss: 0.00038632
Epoch [60/300], Train Loss: 0.000346
Validation Loss: 0.00036970
Epoch [61/300], Train Loss: 0.000341
Validation Loss: 0.00037476
Epoch [62/300], Train Loss: 0.000334
Validation Loss: 0.00038105
Epoch [63/300], Train Loss: 0.000334
Validation Loss: 0.00036410
Epoch [64/300], Train Loss: 0.000325
Validation Loss: 0.00036077
Epoch [65/300], Train Loss: 0.000328
Validation Loss: 0.00035701
Epoch [66/300], Train Loss: 0.000320
Validation Loss: 0.00034315
Epoch [67/300], Train Loss: 0.000315
Validation Loss: 0.00034868
Epoch [68/300], Train Loss: 0.000312
Validation Loss: 0.00035195
Epoch [69/300], Train Loss: 0.000314
Validation Loss: 0.00033598
Epoch [70/300], Train Loss: 0.000310
Validation Loss: 0.00033638
Epoch [71/300], Train Loss: 0.000313
Validation Loss: 0.00033734
Epoch [72/300], Train Loss: 0.000306
Validation Loss: 0.00033611
Epoch [73/300], Train Loss: 0.000300
Validation Loss: 0.00033971
Epoch [74/300], Train Loss: 0.000300
Validation Loss: 0.00032097
Epoch [75/300], Train Loss: 0.000300
Validation Loss: 0.00032163
Epoch [76/300], Train Loss: 0.000293
Validation Loss: 0.00031976
Epoch [77/300], Train Loss: 0.000305
Validation Loss: 0.00033566
Epoch [78/300], Train Loss: 0.000295
Validation Loss: 0.00031509
Epoch [79/300], Train Loss: 0.000289
Validation Loss: 0.00031912
Epoch [80/300], Train Loss: 0.000282
Validation Loss: 0.00031530
Epoch [81/300], Train Loss: 0.000280
Validation Loss: 0.00030160
Epoch [82/300], Train Loss: 0.000279
Validation Loss: 0.00030353
Epoch [83/300], Train Loss: 0.000289
Validation Loss: 0.00030086
Epoch [84/300], Train Loss: 0.000288
Validation Loss: 0.00031649
Epoch [85/300], Train Loss: 0.000277
Validation Loss: 0.00029880
Epoch [86/300], Train Loss: 0.000274
Validation Loss: 0.00029355
Epoch [87/300], Train Loss: 0.000271
Validation Loss: 0.00029079
Epoch [88/300], Train Loss: 0.000273
Validation Loss: 0.00030729
Epoch [89/300], Train Loss: 0.000267
Validation Loss: 0.00028882
Epoch [90/300], Train Loss: 0.000283
Validation Loss: 0.00028791
Epoch [91/300], Train Loss: 0.000265
Validation Loss: 0.00029877
Epoch [92/300], Train Loss: 0.000264
Validation Loss: 0.00028792
Epoch [93/300], Train Loss: 0.000260
Validation Loss: 0.00028312
Epoch [94/300], Train Loss: 0.000263
Validation Loss: 0.00028065
Epoch [95/300], Train Loss: 0.000260
Validation Loss: 0.00028302
Epoch [96/300], Train Loss: 0.000259
Validation Loss: 0.00029127
Epoch [97/300], Train Loss: 0.000260
Validation Loss: 0.00029269
Epoch [98/300], Train Loss: 0.000263
Validation Loss: 0.00028576
Epoch [99/300], Train Loss: 0.000253
Validation Loss: 0.00027413
Epoch [100/300], Train Loss: 0.000250
Validation Loss: 0.00026668
Epoch [101/300], Train Loss: 0.000250
Validation Loss: 0.00027895
Epoch [102/300], Train Loss: 0.000258
Validation Loss: 0.00026906
Epoch [103/300], Train Loss: 0.000252
Validation Loss: 0.00026679
Epoch [104/300], Train Loss: 0.000246
Validation Loss: 0.00026880
Epoch [105/300], Train Loss: 0.000246
Validation Loss: 0.00027988
Epoch [106/300], Train Loss: 0.000256
Validation Loss: 0.00027686
Epoch [107/300], Train Loss: 0.000251
Validation Loss: 0.00026493
Epoch [108/300], Train Loss: 0.000246
Validation Loss: 0.00026618
Epoch [109/300], Train Loss: 0.000246
Validation Loss: 0.00027538
Epoch [110/300], Train Loss: 0.000242
Validation Loss: 0.00025769
Epoch [111/300], Train Loss: 0.000251
Validation Loss: 0.00033243
Epoch [112/300], Train Loss: 0.000268
Validation Loss: 0.00028314
Epoch [113/300], Train Loss: 0.000244
Validation Loss: 0.00025462
Epoch [114/300], Train Loss: 0.000242
Validation Loss: 0.00027067
Epoch [115/300], Train Loss: 0.000238
Validation Loss: 0.00026488
Epoch [116/300], Train Loss: 0.000244
Validation Loss: 0.00025778
Epoch [117/300], Train Loss: 0.000237
Validation Loss: 0.00025570
Epoch [118/300], Train Loss: 0.000246
Validation Loss: 0.00026890
Epoch [119/300], Train Loss: 0.000248
Validation Loss: 0.00026224
Epoch [120/300], Train Loss: 0.000239
Validation Loss: 0.00027246
Epoch [121/300], Train Loss: 0.000232
Validation Loss: 0.00024820
Epoch [122/300], Train Loss: 0.000230
Validation Loss: 0.00024918
Epoch [123/300], Train Loss: 0.000230
Validation Loss: 0.00025916
Epoch [124/300], Train Loss: 0.000229
Validation Loss: 0.00025094
Epoch [125/300], Train Loss: 0.000232
Validation Loss: 0.00025215
Epoch [126/300], Train Loss: 0.000228
Validation Loss: 0.00025513
Epoch [127/300], Train Loss: 0.000228
Validation Loss: 0.00024856
Epoch [128/300], Train Loss: 0.000226
Validation Loss: 0.00025589
Epoch [129/300], Train Loss: 0.000226
Validation Loss: 0.00024455
Epoch [130/300], Train Loss: 0.000226
Validation Loss: 0.00025536
Epoch [131/300], Train Loss: 0.000242
Validation Loss: 0.00029152
Epoch [132/300], Train Loss: 0.000233
Validation Loss: 0.00025566
Epoch [133/300], Train Loss: 0.000223
Validation Loss: 0.00024266
Epoch [134/300], Train Loss: 0.000221
Validation Loss: 0.00024457
Epoch [135/300], Train Loss: 0.000223
Validation Loss: 0.00024608
Epoch [136/300], Train Loss: 0.000224
Validation Loss: 0.00024572
Epoch [137/300], Train Loss: 0.000219
Validation Loss: 0.00026983
Epoch [138/300], Train Loss: 0.000240
Validation Loss: 0.00024740
Epoch [139/300], Train Loss: 0.000222
Validation Loss: 0.00023772
Epoch [140/300], Train Loss: 0.000219
Validation Loss: 0.00023936
Epoch [141/300], Train Loss: 0.000219
Validation Loss: 0.00024381
Epoch [142/300], Train Loss: 0.000224
Validation Loss: 0.00024702
Epoch [143/300], Train Loss: 0.000220
Validation Loss: 0.00024115
Epoch [144/300], Train Loss: 0.000216
Validation Loss: 0.00024096
Epoch [145/300], Train Loss: 0.000216
Validation Loss: 0.00024141
Epoch [146/300], Train Loss: 0.000216
Validation Loss: 0.00024086
Epoch [147/300], Train Loss: 0.000215
Validation Loss: 0.00024080
Epoch [148/300], Train Loss: 0.000215
Validation Loss: 0.00023818
Epoch [149/300], Train Loss: 0.000210
Validation Loss: 0.00023638
Epoch [150/300], Train Loss: 0.000227
Validation Loss: 0.00024287
Epoch [151/300], Train Loss: 0.000214
Validation Loss: 0.00023539
Epoch [152/300], Train Loss: 0.000214
Validation Loss: 0.00023874
Epoch [153/300], Train Loss: 0.000221
Validation Loss: 0.00024998
Epoch [154/300], Train Loss: 0.000216
Validation Loss: 0.00023784
Epoch [155/300], Train Loss: 0.000220
Validation Loss: 0.00024476
Epoch [156/300], Train Loss: 0.000211
Validation Loss: 0.00023421
Epoch [157/300], Train Loss: 0.000210
Validation Loss: 0.00024219
Epoch [158/300], Train Loss: 0.000222
Validation Loss: 0.00024653
Epoch [159/300], Train Loss: 0.000212
Validation Loss: 0.00023880
Epoch [160/300], Train Loss: 0.000208
Validation Loss: 0.00023799
Epoch [161/300], Train Loss: 0.000208
Validation Loss: 0.00023399
Epoch [162/300], Train Loss: 0.000209
Validation Loss: 0.00023775
Epoch [163/300], Train Loss: 0.000211
Validation Loss: 0.00023284
Epoch [164/300], Train Loss: 0.000207
Validation Loss: 0.00023514
Epoch [165/300], Train Loss: 0.000207
Validation Loss: 0.00023497
Epoch [166/300], Train Loss: 0.000207
Validation Loss: 0.00022922
Epoch [167/300], Train Loss: 0.000206
Validation Loss: 0.00023055
Epoch [168/300], Train Loss: 0.000204
Validation Loss: 0.00023313
Epoch [169/300], Train Loss: 0.000204
Validation Loss: 0.00023118
Epoch [170/300], Train Loss: 0.000205
Validation Loss: 0.00023054
Epoch [171/300], Train Loss: 0.000205
Validation Loss: 0.00022679
Epoch [172/300], Train Loss: 0.000203
Validation Loss: 0.00023734
Epoch [173/300], Train Loss: 0.000202
Validation Loss: 0.00024105
Epoch [174/300], Train Loss: 0.000205
Validation Loss: 0.00022705
Epoch [175/300], Train Loss: 0.000201
Validation Loss: 0.00023043
Epoch [176/300], Train Loss: 0.000205
Validation Loss: 0.00023198
Epoch [177/300], Train Loss: 0.000208
Validation Loss: 0.00028004
Epoch [178/300], Train Loss: 0.000219
Validation Loss: 0.00022964
Epoch [179/300], Train Loss: 0.000205
Validation Loss: 0.00023634
Epoch [180/300], Train Loss: 0.000207
Validation Loss: 0.00022682
Epoch [181/300], Train Loss: 0.000203
Validation Loss: 0.00022452
Epoch [182/300], Train Loss: 0.000199
Validation Loss: 0.00022714
Epoch [183/300], Train Loss: 0.000202
Validation Loss: 0.00023886
Epoch [184/300], Train Loss: 0.000205
Validation Loss: 0.00022156
Epoch [185/300], Train Loss: 0.000199
Validation Loss: 0.00022293
Epoch [186/300], Train Loss: 0.000198
Validation Loss: 0.00022668
Epoch [187/300], Train Loss: 0.000197
Validation Loss: 0.00022609
Epoch [188/300], Train Loss: 0.000201
Validation Loss: 0.00022667
Epoch [189/300], Train Loss: 0.000198
Validation Loss: 0.00022362
Epoch [190/300], Train Loss: 0.000195
Validation Loss: 0.00022654
Epoch [191/300], Train Loss: 0.000197
Validation Loss: 0.00022295
Epoch [192/300], Train Loss: 0.000197
Validation Loss: 0.00022309
Epoch [193/300], Train Loss: 0.000198
Validation Loss: 0.00022329
Epoch [194/300], Train Loss: 0.000196
Validation Loss: 0.00022670
Early stopping triggered

Evaluating model for: Coffee Machine
Run 11/72 completed in 3394.49 seconds with: {'MAE': np.float32(3.3337631), 'MSE': np.float32(916.08325), 'RMSE': np.float32(30.266867), 'SAE': np.float32(0.03123745), 'NDE': np.float32(0.42066172)}

Run 12/72: hidden=128, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Coffee Machine
Dataset length: 11964 windows

Epoch [1/300], Train Loss: 0.001294
Validation Loss: 0.00104053
Epoch [2/300], Train Loss: 0.000977
Validation Loss: 0.00103990
Epoch [3/300], Train Loss: 0.000974
Validation Loss: 0.00103923
Epoch [4/300], Train Loss: 0.000969
Validation Loss: 0.00103845
Epoch [5/300], Train Loss: 0.000966
Validation Loss: 0.00103722
Epoch [6/300], Train Loss: 0.000961
Validation Loss: 0.00103630
Epoch [7/300], Train Loss: 0.000958
Validation Loss: 0.00103523
Epoch [8/300], Train Loss: 0.000955
Validation Loss: 0.00103465
Epoch [9/300], Train Loss: 0.000955
Validation Loss: 0.00103395
Epoch [10/300], Train Loss: 0.000955
Validation Loss: 0.00103393
Epoch [11/300], Train Loss: 0.000953
Validation Loss: 0.00103253
Epoch [12/300], Train Loss: 0.000952
Validation Loss: 0.00103227
Epoch [13/300], Train Loss: 0.000953
Validation Loss: 0.00103198
Epoch [14/300], Train Loss: 0.000951
Validation Loss: 0.00103103
Epoch [15/300], Train Loss: 0.000951
Validation Loss: 0.00103137
Epoch [16/300], Train Loss: 0.000950
Validation Loss: 0.00102978
Epoch [17/300], Train Loss: 0.000948
Validation Loss: 0.00102924
Epoch [18/300], Train Loss: 0.000948
Validation Loss: 0.00102871
Epoch [19/300], Train Loss: 0.000949
Validation Loss: 0.00102797
Epoch [20/300], Train Loss: 0.000945
Validation Loss: 0.00102780
Epoch [21/300], Train Loss: 0.000945
Validation Loss: 0.00102679
Epoch [22/300], Train Loss: 0.000946
Validation Loss: 0.00102654
Epoch [23/300], Train Loss: 0.000946
Validation Loss: 0.00102530
Epoch [24/300], Train Loss: 0.000943
Validation Loss: 0.00102542
Epoch [25/300], Train Loss: 0.000941
Validation Loss: 0.00102294
Epoch [26/300], Train Loss: 0.000940
Validation Loss: 0.00101899
Epoch [27/300], Train Loss: 0.000937
Validation Loss: 0.00101217
Epoch [28/300], Train Loss: 0.000927
Validation Loss: 0.00099901
Epoch [29/300], Train Loss: 0.000910
Validation Loss: 0.00096080
Epoch [30/300], Train Loss: 0.000862
Validation Loss: 0.00087984
Epoch [31/300], Train Loss: 0.000794
Validation Loss: 0.00083467
Epoch [32/300], Train Loss: 0.000754
Validation Loss: 0.00080361
Epoch [33/300], Train Loss: 0.000722
Validation Loss: 0.00075833
Epoch [34/300], Train Loss: 0.000702
Validation Loss: 0.00074816
Epoch [35/300], Train Loss: 0.000688
Validation Loss: 0.00070383
Epoch [36/300], Train Loss: 0.000658
Validation Loss: 0.00070546
Epoch [37/300], Train Loss: 0.000636
Validation Loss: 0.00068224
Epoch [38/300], Train Loss: 0.000621
Validation Loss: 0.00065042
Epoch [39/300], Train Loss: 0.000603
Validation Loss: 0.00063855
Epoch [40/300], Train Loss: 0.000608
Validation Loss: 0.00064114
Epoch [41/300], Train Loss: 0.000589
Validation Loss: 0.00060878
Epoch [42/300], Train Loss: 0.000583
Validation Loss: 0.00068678
Epoch [43/300], Train Loss: 0.000613
Validation Loss: 0.00063080
Epoch [44/300], Train Loss: 0.000559
Validation Loss: 0.00061705
Epoch [45/300], Train Loss: 0.000550
Validation Loss: 0.00059813
Epoch [46/300], Train Loss: 0.000542
Validation Loss: 0.00061735
Epoch [47/300], Train Loss: 0.000542
Validation Loss: 0.00058710
Epoch [48/300], Train Loss: 0.000531
Validation Loss: 0.00057644
Epoch [49/300], Train Loss: 0.000532
Validation Loss: 0.00058411
Epoch [50/300], Train Loss: 0.000523
Validation Loss: 0.00058149
Epoch [51/300], Train Loss: 0.000527
Validation Loss: 0.00062362
Epoch [52/300], Train Loss: 0.000510
Validation Loss: 0.00056599
Epoch [53/300], Train Loss: 0.000508
Validation Loss: 0.00055572
Epoch [54/300], Train Loss: 0.000515
Validation Loss: 0.00054778
Epoch [55/300], Train Loss: 0.000494
Validation Loss: 0.00055090
Epoch [56/300], Train Loss: 0.000514
Validation Loss: 0.00054603
Epoch [57/300], Train Loss: 0.000506
Validation Loss: 0.00054587
Epoch [58/300], Train Loss: 0.000487
Validation Loss: 0.00055340
Epoch [59/300], Train Loss: 0.000493
Validation Loss: 0.00053228
Epoch [60/300], Train Loss: 0.000481
Validation Loss: 0.00056847
Epoch [61/300], Train Loss: 0.000491
Validation Loss: 0.00054254
Epoch [62/300], Train Loss: 0.000482
Validation Loss: 0.00053663
Epoch [63/300], Train Loss: 0.000480
Validation Loss: 0.00053783
Epoch [64/300], Train Loss: 0.000487
Validation Loss: 0.00055341
Epoch [65/300], Train Loss: 0.000510
Validation Loss: 0.00052981
Epoch [66/300], Train Loss: 0.000485
Validation Loss: 0.00052880
Epoch [67/300], Train Loss: 0.000475
Validation Loss: 0.00051603
Epoch [68/300], Train Loss: 0.000461
Validation Loss: 0.00050754
Epoch [69/300], Train Loss: 0.000457
Validation Loss: 0.00051029
Epoch [70/300], Train Loss: 0.000455
Validation Loss: 0.00051692
Epoch [71/300], Train Loss: 0.000450
Validation Loss: 0.00049765
Epoch [72/300], Train Loss: 0.000446
Validation Loss: 0.00050268
Epoch [73/300], Train Loss: 0.000446
Validation Loss: 0.00049816
Epoch [74/300], Train Loss: 0.000440
Validation Loss: 0.00049918
Epoch [75/300], Train Loss: 0.000453
Validation Loss: 0.00051450
Epoch [76/300], Train Loss: 0.000444
Validation Loss: 0.00048754
Epoch [77/300], Train Loss: 0.000433
Validation Loss: 0.00048726
Epoch [78/300], Train Loss: 0.000629
Validation Loss: 0.00097756
Epoch [79/300], Train Loss: 0.000799
Validation Loss: 0.00075708
Epoch [80/300], Train Loss: 0.000577
Validation Loss: 0.00061353
Epoch [81/300], Train Loss: 0.000524
Validation Loss: 0.00057425
Epoch [82/300], Train Loss: 0.000509
Validation Loss: 0.00056794
Epoch [83/300], Train Loss: 0.000496
Validation Loss: 0.00055052
Epoch [84/300], Train Loss: 0.000483
Validation Loss: 0.00053623
Epoch [85/300], Train Loss: 0.000473
Validation Loss: 0.00052416
Epoch [86/300], Train Loss: 0.000467
Validation Loss: 0.00052487
Epoch [87/300], Train Loss: 0.000461
Validation Loss: 0.00050890
Early stopping triggered

Evaluating model for: Coffee Machine
Run 12/72 completed in 1614.44 seconds with: {'MAE': np.float32(6.1140156), 'MSE': np.float32(2304.3848), 'RMSE': np.float32(48.00401), 'SAE': np.float32(0.10151422), 'NDE': np.float32(0.6671852)}

Run 13/72: hidden=128, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Coffee Machine
Dataset length: 6004 windows

Epoch [1/300], Train Loss: 0.001112
Validation Loss: 0.00097296
Epoch [2/300], Train Loss: 0.000982
Validation Loss: 0.00097208
Epoch [3/300], Train Loss: 0.000984
Validation Loss: 0.00097168
Epoch [4/300], Train Loss: 0.000982
Validation Loss: 0.00097127
Epoch [5/300], Train Loss: 0.000983
Validation Loss: 0.00097123
Epoch [6/300], Train Loss: 0.000981
Validation Loss: 0.00097036
Epoch [7/300], Train Loss: 0.000973
Validation Loss: 0.00096992
Epoch [8/300], Train Loss: 0.000970
Validation Loss: 0.00096908
Epoch [9/300], Train Loss: 0.000978
Validation Loss: 0.00096858
Epoch [10/300], Train Loss: 0.000964
Validation Loss: 0.00096783
Epoch [11/300], Train Loss: 0.000976
Validation Loss: 0.00096736
Epoch [12/300], Train Loss: 0.000970
Validation Loss: 0.00096680
Epoch [13/300], Train Loss: 0.000966
Validation Loss: 0.00096571
Epoch [14/300], Train Loss: 0.000963
Validation Loss: 0.00096453
Epoch [15/300], Train Loss: 0.000961
Validation Loss: 0.00096300
Epoch [16/300], Train Loss: 0.000954
Validation Loss: 0.00096119
Epoch [17/300], Train Loss: 0.000956
Validation Loss: 0.00095898
Epoch [18/300], Train Loss: 0.000956
Validation Loss: 0.00095690
Epoch [19/300], Train Loss: 0.000953
Validation Loss: 0.00095545
Epoch [20/300], Train Loss: 0.000948
Validation Loss: 0.00095368
Epoch [21/300], Train Loss: 0.000960
Validation Loss: 0.00095228
Epoch [22/300], Train Loss: 0.000947
Validation Loss: 0.00095080
Epoch [23/300], Train Loss: 0.000945
Validation Loss: 0.00094899
Epoch [24/300], Train Loss: 0.000950
Validation Loss: 0.00094670
Epoch [25/300], Train Loss: 0.000943
Validation Loss: 0.00094357
Epoch [26/300], Train Loss: 0.000941
Validation Loss: 0.00094046
Epoch [27/300], Train Loss: 0.000932
Validation Loss: 0.00093614
Epoch [28/300], Train Loss: 0.000932
Validation Loss: 0.00093059
Epoch [29/300], Train Loss: 0.000924
Validation Loss: 0.00092360
Epoch [30/300], Train Loss: 0.000913
Validation Loss: 0.00091705
Epoch [31/300], Train Loss: 0.000902
Validation Loss: 0.00090837
Epoch [32/300], Train Loss: 0.000897
Validation Loss: 0.00089791
Epoch [33/300], Train Loss: 0.000882
Validation Loss: 0.00088929
Epoch [34/300], Train Loss: 0.000871
Validation Loss: 0.00087580
Epoch [35/300], Train Loss: 0.000860
Validation Loss: 0.00086423
Epoch [36/300], Train Loss: 0.000848
Validation Loss: 0.00084893
Epoch [37/300], Train Loss: 0.000833
Validation Loss: 0.00083932
Epoch [38/300], Train Loss: 0.000816
Validation Loss: 0.00082341
Epoch [39/300], Train Loss: 0.000807
Validation Loss: 0.00081459
Epoch [40/300], Train Loss: 0.000797
Validation Loss: 0.00080058
Epoch [41/300], Train Loss: 0.000784
Validation Loss: 0.00079598
Epoch [42/300], Train Loss: 0.000770
Validation Loss: 0.00077521
Epoch [43/300], Train Loss: 0.000760
Validation Loss: 0.00075974
Epoch [44/300], Train Loss: 0.000741
Validation Loss: 0.00075011
Epoch [45/300], Train Loss: 0.000731
Validation Loss: 0.00073635
Epoch [46/300], Train Loss: 0.000728
Validation Loss: 0.00073582
Epoch [47/300], Train Loss: 0.000711
Validation Loss: 0.00072794
Epoch [48/300], Train Loss: 0.000713
Validation Loss: 0.00073335
Epoch [49/300], Train Loss: 0.000706
Validation Loss: 0.00070368
Epoch [50/300], Train Loss: 0.000699
Validation Loss: 0.00069911
Epoch [51/300], Train Loss: 0.000688
Validation Loss: 0.00069072
Epoch [52/300], Train Loss: 0.000677
Validation Loss: 0.00069804
Epoch [53/300], Train Loss: 0.000671
Validation Loss: 0.00069642
Epoch [54/300], Train Loss: 0.000666
Validation Loss: 0.00067423
Epoch [55/300], Train Loss: 0.000659
Validation Loss: 0.00067326
Epoch [56/300], Train Loss: 0.000659
Validation Loss: 0.00066835
Epoch [57/300], Train Loss: 0.000651
Validation Loss: 0.00066415
Epoch [58/300], Train Loss: 0.000646
Validation Loss: 0.00066231
Epoch [59/300], Train Loss: 0.000644
Validation Loss: 0.00065281
Epoch [60/300], Train Loss: 0.000635
Validation Loss: 0.00065878
Epoch [61/300], Train Loss: 0.000629
Validation Loss: 0.00064506
Epoch [62/300], Train Loss: 0.000623
Validation Loss: 0.00064420
Epoch [63/300], Train Loss: 0.000624
Validation Loss: 0.00064669
Epoch [64/300], Train Loss: 0.000613
Validation Loss: 0.00062926
Epoch [65/300], Train Loss: 0.000606
Validation Loss: 0.00064025
Epoch [66/300], Train Loss: 0.000626
Validation Loss: 0.00062780
Epoch [67/300], Train Loss: 0.000606
Validation Loss: 0.00061669
Epoch [68/300], Train Loss: 0.000599
Validation Loss: 0.00062728
Epoch [69/300], Train Loss: 0.000596
Validation Loss: 0.00061798
Epoch [70/300], Train Loss: 0.000595
Validation Loss: 0.00062182
Epoch [71/300], Train Loss: 0.000586
Validation Loss: 0.00061594
Epoch [72/300], Train Loss: 0.000582
Validation Loss: 0.00061400
Epoch [73/300], Train Loss: 0.000583
Validation Loss: 0.00060004
Epoch [74/300], Train Loss: 0.000583
Validation Loss: 0.00060001
Epoch [75/300], Train Loss: 0.000574
Validation Loss: 0.00059711
Epoch [76/300], Train Loss: 0.000577
Validation Loss: 0.00060436
Epoch [77/300], Train Loss: 0.000570
Validation Loss: 0.00060690
Epoch [78/300], Train Loss: 0.000571
Validation Loss: 0.00059138
Epoch [79/300], Train Loss: 0.000567
Validation Loss: 0.00059626
Epoch [80/300], Train Loss: 0.000569
Validation Loss: 0.00058463
Epoch [81/300], Train Loss: 0.000564
Validation Loss: 0.00059491
Epoch [82/300], Train Loss: 0.000568
Validation Loss: 0.00057960
Epoch [83/300], Train Loss: 0.000558
Validation Loss: 0.00058745
Epoch [84/300], Train Loss: 0.000556
Validation Loss: 0.00057670
Epoch [85/300], Train Loss: 0.000558
Validation Loss: 0.00057763
Epoch [86/300], Train Loss: 0.000558
Validation Loss: 0.00057787
Epoch [87/300], Train Loss: 0.000555
Validation Loss: 0.00057658
Epoch [88/300], Train Loss: 0.000547
Validation Loss: 0.00056916
Epoch [89/300], Train Loss: 0.000547
Validation Loss: 0.00058096
Epoch [90/300], Train Loss: 0.000545
Validation Loss: 0.00057117
Epoch [91/300], Train Loss: 0.000547
Validation Loss: 0.00056579
Epoch [92/300], Train Loss: 0.000537
Validation Loss: 0.00056314
Epoch [93/300], Train Loss: 0.000540
Validation Loss: 0.00056727
Epoch [94/300], Train Loss: 0.000551
Validation Loss: 0.00056887
Epoch [95/300], Train Loss: 0.000538
Validation Loss: 0.00057258
Epoch [96/300], Train Loss: 0.000533
Validation Loss: 0.00056646
Epoch [97/300], Train Loss: 0.000536
Validation Loss: 0.00056210
Epoch [98/300], Train Loss: 0.000540
Validation Loss: 0.00057548
Epoch [99/300], Train Loss: 0.000530
Validation Loss: 0.00057142
Epoch [100/300], Train Loss: 0.000528
Validation Loss: 0.00057106
Epoch [101/300], Train Loss: 0.000531
Validation Loss: 0.00055299
Epoch [102/300], Train Loss: 0.000529
Validation Loss: 0.00054693
Epoch [103/300], Train Loss: 0.000525
Validation Loss: 0.00056534
Epoch [104/300], Train Loss: 0.000531
Validation Loss: 0.00054828
Epoch [105/300], Train Loss: 0.000526
Validation Loss: 0.00054118
Epoch [106/300], Train Loss: 0.000523
Validation Loss: 0.00054159
Epoch [107/300], Train Loss: 0.000515
Validation Loss: 0.00055888
Epoch [108/300], Train Loss: 0.000516
Validation Loss: 0.00054515
Epoch [109/300], Train Loss: 0.000518
Validation Loss: 0.00054397
Epoch [110/300], Train Loss: 0.000515
Validation Loss: 0.00057526
Epoch [111/300], Train Loss: 0.000517
Validation Loss: 0.00054630
Epoch [112/300], Train Loss: 0.000515
Validation Loss: 0.00054406
Epoch [113/300], Train Loss: 0.000510
Validation Loss: 0.00053507
Epoch [114/300], Train Loss: 0.000516
Validation Loss: 0.00053372
Epoch [115/300], Train Loss: 0.000506
Validation Loss: 0.00056179
Epoch [116/300], Train Loss: 0.000517
Validation Loss: 0.00053240
Epoch [117/300], Train Loss: 0.000514
Validation Loss: 0.00053420
Epoch [118/300], Train Loss: 0.000497
Validation Loss: 0.00052546
Epoch [119/300], Train Loss: 0.000509
Validation Loss: 0.00052531
Epoch [120/300], Train Loss: 0.000505
Validation Loss: 0.00052483
Epoch [121/300], Train Loss: 0.000499
Validation Loss: 0.00054327
Epoch [122/300], Train Loss: 0.000501
Validation Loss: 0.00053346
Epoch [123/300], Train Loss: 0.000492
Validation Loss: 0.00053416
Epoch [124/300], Train Loss: 0.000504
Validation Loss: 0.00052949
Epoch [125/300], Train Loss: 0.000496
Validation Loss: 0.00053716
Epoch [126/300], Train Loss: 0.000503
Validation Loss: 0.00055125
Epoch [127/300], Train Loss: 0.000497
Validation Loss: 0.00054761
Epoch [128/300], Train Loss: 0.000496
Validation Loss: 0.00051921
Epoch [129/300], Train Loss: 0.000494
Validation Loss: 0.00055904
Epoch [130/300], Train Loss: 0.000493
Validation Loss: 0.00051907
Epoch [131/300], Train Loss: 0.000494
Validation Loss: 0.00051223
Epoch [132/300], Train Loss: 0.000495
Validation Loss: 0.00051405
Epoch [133/300], Train Loss: 0.000482
Validation Loss: 0.00051269
Epoch [134/300], Train Loss: 0.000490
Validation Loss: 0.00051052
Epoch [135/300], Train Loss: 0.000479
Validation Loss: 0.00052804
Epoch [136/300], Train Loss: 0.000487
Validation Loss: 0.00051516
Epoch [137/300], Train Loss: 0.000484
Validation Loss: 0.00053774
Epoch [138/300], Train Loss: 0.000484
Validation Loss: 0.00050480
Epoch [139/300], Train Loss: 0.000487
Validation Loss: 0.00053363
Epoch [140/300], Train Loss: 0.000478
Validation Loss: 0.00050858
Epoch [141/300], Train Loss: 0.000482
Validation Loss: 0.00051068
Epoch [142/300], Train Loss: 0.000480
Validation Loss: 0.00051845
Epoch [143/300], Train Loss: 0.000480
Validation Loss: 0.00051370
Epoch [144/300], Train Loss: 0.000484
Validation Loss: 0.00051867
Epoch [145/300], Train Loss: 0.000476
Validation Loss: 0.00052659
Epoch [146/300], Train Loss: 0.000483
Validation Loss: 0.00050830
Epoch [147/300], Train Loss: 0.000484
Validation Loss: 0.00051427
Epoch [148/300], Train Loss: 0.000477
Validation Loss: 0.00049847
Epoch [149/300], Train Loss: 0.000466
Validation Loss: 0.00051541
Epoch [150/300], Train Loss: 0.000468
Validation Loss: 0.00049654
Epoch [151/300], Train Loss: 0.000464
Validation Loss: 0.00050890
Epoch [152/300], Train Loss: 0.000468
Validation Loss: 0.00048709
Epoch [153/300], Train Loss: 0.000462
Validation Loss: 0.00052416
Epoch [154/300], Train Loss: 0.000467
Validation Loss: 0.00048863
Epoch [155/300], Train Loss: 0.000464
Validation Loss: 0.00048788
Epoch [156/300], Train Loss: 0.000463
Validation Loss: 0.00051036
Epoch [157/300], Train Loss: 0.000465
Validation Loss: 0.00049305
Epoch [158/300], Train Loss: 0.000466
Validation Loss: 0.00048472
Epoch [159/300], Train Loss: 0.000476
Validation Loss: 0.00057093
Epoch [160/300], Train Loss: 0.000511
Validation Loss: 0.00051637
Epoch [161/300], Train Loss: 0.000488
Validation Loss: 0.00050154
Epoch [162/300], Train Loss: 0.000489
Validation Loss: 0.00049441
Epoch [163/300], Train Loss: 0.000481
Validation Loss: 0.00050572
Epoch [164/300], Train Loss: 0.000483
Validation Loss: 0.00048883
Epoch [165/300], Train Loss: 0.000477
Validation Loss: 0.00049322
Epoch [166/300], Train Loss: 0.000472
Validation Loss: 0.00049018
Epoch [167/300], Train Loss: 0.000467
Validation Loss: 0.00050131
Epoch [168/300], Train Loss: 0.000474
Validation Loss: 0.00048599
Early stopping triggered

Evaluating model for: Coffee Machine
Run 13/72 completed in 1429.64 seconds with: {'MAE': np.float32(6.678108), 'MSE': np.float32(2601.8708), 'RMSE': np.float32(51.008537), 'SAE': np.float32(0.20755808), 'NDE': np.float32(0.7930388)}

Run 14/72: hidden=128, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Coffee Machine
Dataset length: 6004 windows

Epoch [1/300], Train Loss: 0.001044
Validation Loss: 0.00097689
Epoch [2/300], Train Loss: 0.000981
Validation Loss: 0.00097282
Epoch [3/300], Train Loss: 0.000983
Validation Loss: 0.00097250
Epoch [4/300], Train Loss: 0.000980
Validation Loss: 0.00097217
Epoch [5/300], Train Loss: 0.000981
Validation Loss: 0.00097236
Epoch [6/300], Train Loss: 0.000979
Validation Loss: 0.00097154
Epoch [7/300], Train Loss: 0.000971
Validation Loss: 0.00097123
Epoch [8/300], Train Loss: 0.000968
Validation Loss: 0.00097071
Epoch [9/300], Train Loss: 0.000977
Validation Loss: 0.00097044
Epoch [10/300], Train Loss: 0.000963
Validation Loss: 0.00096966
Epoch [11/300], Train Loss: 0.000976
Validation Loss: 0.00096907
Epoch [12/300], Train Loss: 0.000971
Validation Loss: 0.00096822
Epoch [13/300], Train Loss: 0.000966
Validation Loss: 0.00096685
Epoch [14/300], Train Loss: 0.000963
Validation Loss: 0.00096551
Epoch [15/300], Train Loss: 0.000961
Validation Loss: 0.00096369
Epoch [16/300], Train Loss: 0.000954
Validation Loss: 0.00096171
Epoch [17/300], Train Loss: 0.000957
Validation Loss: 0.00095997
Epoch [18/300], Train Loss: 0.000957
Validation Loss: 0.00095820
Epoch [19/300], Train Loss: 0.000954
Validation Loss: 0.00095702
Epoch [20/300], Train Loss: 0.000949
Validation Loss: 0.00095503
Epoch [21/300], Train Loss: 0.000961
Validation Loss: 0.00095220
Epoch [22/300], Train Loss: 0.000946
Validation Loss: 0.00094883
Epoch [23/300], Train Loss: 0.000943
Validation Loss: 0.00094488
Epoch [24/300], Train Loss: 0.000944
Validation Loss: 0.00093868
Epoch [25/300], Train Loss: 0.000932
Validation Loss: 0.00093143
Epoch [26/300], Train Loss: 0.000923
Validation Loss: 0.00092235
Epoch [27/300], Train Loss: 0.000905
Validation Loss: 0.00090817
Epoch [28/300], Train Loss: 0.000893
Validation Loss: 0.00089022
Epoch [29/300], Train Loss: 0.000868
Validation Loss: 0.00086680
Epoch [30/300], Train Loss: 0.000846
Validation Loss: 0.00085011
Epoch [31/300], Train Loss: 0.000818
Validation Loss: 0.00082567
Epoch [32/300], Train Loss: 0.000795
Validation Loss: 0.00080109
Epoch [33/300], Train Loss: 0.000769
Validation Loss: 0.00078555
Epoch [34/300], Train Loss: 0.000751
Validation Loss: 0.00075875
Epoch [35/300], Train Loss: 0.000727
Validation Loss: 0.00075709
Epoch [36/300], Train Loss: 0.000715
Validation Loss: 0.00072197
Epoch [37/300], Train Loss: 0.000701
Validation Loss: 0.00071455
Epoch [38/300], Train Loss: 0.000684
Validation Loss: 0.00069443
Epoch [39/300], Train Loss: 0.000708
Validation Loss: 0.00071640
Epoch [40/300], Train Loss: 0.000674
Validation Loss: 0.00069910
Epoch [41/300], Train Loss: 0.000675
Validation Loss: 0.00070756
Epoch [42/300], Train Loss: 0.000650
Validation Loss: 0.00067070
Epoch [43/300], Train Loss: 0.000669
Validation Loss: 0.00068873
Epoch [44/300], Train Loss: 0.000653
Validation Loss: 0.00067140
Epoch [45/300], Train Loss: 0.000634
Validation Loss: 0.00064792
Epoch [46/300], Train Loss: 0.000634
Validation Loss: 0.00065296
Epoch [47/300], Train Loss: 0.000619
Validation Loss: 0.00064352
Epoch [48/300], Train Loss: 0.000626
Validation Loss: 0.00064126
Epoch [49/300], Train Loss: 0.000611
Validation Loss: 0.00065214
Epoch [50/300], Train Loss: 0.000605
Validation Loss: 0.00066426
Epoch [51/300], Train Loss: 0.000607
Validation Loss: 0.00063421
Epoch [52/300], Train Loss: 0.000597
Validation Loss: 0.00063854
Epoch [53/300], Train Loss: 0.000602
Validation Loss: 0.00062455
Epoch [54/300], Train Loss: 0.000583
Validation Loss: 0.00060661
Epoch [55/300], Train Loss: 0.000585
Validation Loss: 0.00061425
Epoch [56/300], Train Loss: 0.000591
Validation Loss: 0.00060891
Epoch [57/300], Train Loss: 0.000588
Validation Loss: 0.00060123
Epoch [58/300], Train Loss: 0.000575
Validation Loss: 0.00060151
Epoch [59/300], Train Loss: 0.000571
Validation Loss: 0.00058833
Epoch [60/300], Train Loss: 0.000566
Validation Loss: 0.00057828
Epoch [61/300], Train Loss: 0.000570
Validation Loss: 0.00059257
Epoch [62/300], Train Loss: 0.000555
Validation Loss: 0.00057985
Epoch [63/300], Train Loss: 0.000556
Validation Loss: 0.00057557
Epoch [64/300], Train Loss: 0.000550
Validation Loss: 0.00057421
Epoch [65/300], Train Loss: 0.000542
Validation Loss: 0.00057389
Epoch [66/300], Train Loss: 0.000553
Validation Loss: 0.00056900
Epoch [67/300], Train Loss: 0.000540
Validation Loss: 0.00056068
Epoch [68/300], Train Loss: 0.000542
Validation Loss: 0.00056155
Epoch [69/300], Train Loss: 0.000539
Validation Loss: 0.00054957
Epoch [70/300], Train Loss: 0.000537
Validation Loss: 0.00055753
Epoch [71/300], Train Loss: 0.000531
Validation Loss: 0.00056045
Epoch [72/300], Train Loss: 0.000527
Validation Loss: 0.00054407
Epoch [73/300], Train Loss: 0.000530
Validation Loss: 0.00055319
Epoch [74/300], Train Loss: 0.000527
Validation Loss: 0.00056103
Epoch [75/300], Train Loss: 0.000523
Validation Loss: 0.00053074
Epoch [76/300], Train Loss: 0.000528
Validation Loss: 0.00055562
Epoch [77/300], Train Loss: 0.000531
Validation Loss: 0.00053643
Epoch [78/300], Train Loss: 0.000527
Validation Loss: 0.00054418
Epoch [79/300], Train Loss: 0.000519
Validation Loss: 0.00054360
Epoch [80/300], Train Loss: 0.000518
Validation Loss: 0.00052273
Epoch [81/300], Train Loss: 0.000511
Validation Loss: 0.00052191
Epoch [82/300], Train Loss: 0.000516
Validation Loss: 0.00053085
Epoch [83/300], Train Loss: 0.000510
Validation Loss: 0.00052354
Epoch [84/300], Train Loss: 0.000514
Validation Loss: 0.00052377
Epoch [85/300], Train Loss: 0.000513
Validation Loss: 0.00051675
Epoch [86/300], Train Loss: 0.000508
Validation Loss: 0.00052127
Epoch [87/300], Train Loss: 0.000511
Validation Loss: 0.00052456
Epoch [88/300], Train Loss: 0.000499
Validation Loss: 0.00051468
Epoch [89/300], Train Loss: 0.000501
Validation Loss: 0.00052093
Epoch [90/300], Train Loss: 0.000498
Validation Loss: 0.00050009
Epoch [91/300], Train Loss: 0.000500
Validation Loss: 0.00051246
Epoch [92/300], Train Loss: 0.000513
Validation Loss: 0.00053395
Epoch [93/300], Train Loss: 0.000510
Validation Loss: 0.00049773
Epoch [94/300], Train Loss: 0.000498
Validation Loss: 0.00053136
Epoch [95/300], Train Loss: 0.000496
Validation Loss: 0.00050614
Epoch [96/300], Train Loss: 0.000493
Validation Loss: 0.00049672
Epoch [97/300], Train Loss: 0.000488
Validation Loss: 0.00049582
Epoch [98/300], Train Loss: 0.000493
Validation Loss: 0.00050019
Epoch [99/300], Train Loss: 0.000491
Validation Loss: 0.00048719
Epoch [100/300], Train Loss: 0.000482
Validation Loss: 0.00048744
Epoch [101/300], Train Loss: 0.000491
Validation Loss: 0.00049635
Epoch [102/300], Train Loss: 0.000485
Validation Loss: 0.00049102
Epoch [103/300], Train Loss: 0.000478
Validation Loss: 0.00048757
Epoch [104/300], Train Loss: 0.000479
Validation Loss: 0.00048732
Epoch [105/300], Train Loss: 0.000475
Validation Loss: 0.00050779
Epoch [106/300], Train Loss: 0.000480
Validation Loss: 0.00049336
Epoch [107/300], Train Loss: 0.000475
Validation Loss: 0.00050779
Epoch [108/300], Train Loss: 0.000469
Validation Loss: 0.00048377
Epoch [109/300], Train Loss: 0.000469
Validation Loss: 0.00048680
Epoch [110/300], Train Loss: 0.000467
Validation Loss: 0.00049837
Epoch [111/300], Train Loss: 0.000467
Validation Loss: 0.00047598
Epoch [112/300], Train Loss: 0.000465
Validation Loss: 0.00048816
Epoch [113/300], Train Loss: 0.000466
Validation Loss: 0.00048325
Epoch [114/300], Train Loss: 0.000470
Validation Loss: 0.00047988
Epoch [115/300], Train Loss: 0.000461
Validation Loss: 0.00047899
Epoch [116/300], Train Loss: 0.000462
Validation Loss: 0.00047008
Epoch [117/300], Train Loss: 0.000454
Validation Loss: 0.00051471
Epoch [118/300], Train Loss: 0.000453
Validation Loss: 0.00047680
Epoch [119/300], Train Loss: 0.000459
Validation Loss: 0.00046605
Epoch [120/300], Train Loss: 0.000454
Validation Loss: 0.00046201
Epoch [121/300], Train Loss: 0.000451
Validation Loss: 0.00046213
Epoch [122/300], Train Loss: 0.000447
Validation Loss: 0.00046921
Epoch [123/300], Train Loss: 0.000444
Validation Loss: 0.00045981
Epoch [124/300], Train Loss: 0.000468
Validation Loss: 0.00047691
Epoch [125/300], Train Loss: 0.000450
Validation Loss: 0.00046056
Epoch [126/300], Train Loss: 0.000475
Validation Loss: 0.00048114
Epoch [127/300], Train Loss: 0.000457
Validation Loss: 0.00047372
Epoch [128/300], Train Loss: 0.000451
Validation Loss: 0.00045212
Epoch [129/300], Train Loss: 0.000446
Validation Loss: 0.00046192
Epoch [130/300], Train Loss: 0.000450
Validation Loss: 0.00045868
Epoch [131/300], Train Loss: 0.000437
Validation Loss: 0.00045912
Epoch [132/300], Train Loss: 0.000438
Validation Loss: 0.00048946
Epoch [133/300], Train Loss: 0.000464
Validation Loss: 0.00047351
Epoch [134/300], Train Loss: 0.000464
Validation Loss: 0.00045764
Epoch [135/300], Train Loss: 0.000452
Validation Loss: 0.00046292
Epoch [136/300], Train Loss: 0.000451
Validation Loss: 0.00046219
Epoch [137/300], Train Loss: 0.000448
Validation Loss: 0.00045126
Epoch [138/300], Train Loss: 0.000446
Validation Loss: 0.00045954
Epoch [139/300], Train Loss: 0.000446
Validation Loss: 0.00044517
Epoch [140/300], Train Loss: 0.000438
Validation Loss: 0.00045094
Epoch [141/300], Train Loss: 0.000445
Validation Loss: 0.00043734
Epoch [142/300], Train Loss: 0.000433
Validation Loss: 0.00044557
Epoch [143/300], Train Loss: 0.000436
Validation Loss: 0.00043970
Epoch [144/300], Train Loss: 0.000428
Validation Loss: 0.00044849
Epoch [145/300], Train Loss: 0.000422
Validation Loss: 0.00044389
Epoch [146/300], Train Loss: 0.000424
Validation Loss: 0.00043974
Epoch [147/300], Train Loss: 0.000445
Validation Loss: 0.00046500
Epoch [148/300], Train Loss: 0.000449
Validation Loss: 0.00045949
Epoch [149/300], Train Loss: 0.000428
Validation Loss: 0.00044267
Epoch [150/300], Train Loss: 0.000446
Validation Loss: 0.00045639
Epoch [151/300], Train Loss: 0.000429
Validation Loss: 0.00044327
Early stopping triggered

Evaluating model for: Coffee Machine
Run 14/72 completed in 1289.58 seconds with: {'MAE': np.float32(5.6296773), 'MSE': np.float32(2305.1384), 'RMSE': np.float32(48.011856), 'SAE': np.float32(0.1258403), 'NDE': np.float32(0.7464487)}

Run 15/72: hidden=128, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Coffee Machine
Dataset length: 6004 windows

Epoch [1/300], Train Loss: 0.001450
Validation Loss: 0.00100368
Epoch [2/300], Train Loss: 0.001003
Validation Loss: 0.00098183
Epoch [3/300], Train Loss: 0.001003
Validation Loss: 0.00098126
Epoch [4/300], Train Loss: 0.001000
Validation Loss: 0.00098080
Epoch [5/300], Train Loss: 0.001002
Validation Loss: 0.00098044
Epoch [6/300], Train Loss: 0.000999
Validation Loss: 0.00097975
Epoch [7/300], Train Loss: 0.000991
Validation Loss: 0.00097945
Epoch [8/300], Train Loss: 0.000988
Validation Loss: 0.00097883
Epoch [9/300], Train Loss: 0.000995
Validation Loss: 0.00097824
Epoch [10/300], Train Loss: 0.000982
Validation Loss: 0.00097773
Epoch [11/300], Train Loss: 0.000994
Validation Loss: 0.00097750
Epoch [12/300], Train Loss: 0.000988
Validation Loss: 0.00097703
Epoch [13/300], Train Loss: 0.000983
Validation Loss: 0.00097666
Epoch [14/300], Train Loss: 0.000980
Validation Loss: 0.00097575
Epoch [15/300], Train Loss: 0.000979
Validation Loss: 0.00097515
Epoch [16/300], Train Loss: 0.000973
Validation Loss: 0.00097469
Epoch [17/300], Train Loss: 0.000977
Validation Loss: 0.00097423
Epoch [18/300], Train Loss: 0.000978
Validation Loss: 0.00097397
Epoch [19/300], Train Loss: 0.000976
Validation Loss: 0.00097344
Epoch [20/300], Train Loss: 0.000972
Validation Loss: 0.00097284
Epoch [21/300], Train Loss: 0.000986
Validation Loss: 0.00097245
Epoch [22/300], Train Loss: 0.000973
Validation Loss: 0.00097239
Epoch [23/300], Train Loss: 0.000973
Validation Loss: 0.00097165
Epoch [24/300], Train Loss: 0.000979
Validation Loss: 0.00097133
Epoch [25/300], Train Loss: 0.000974
Validation Loss: 0.00097080
Epoch [26/300], Train Loss: 0.000974
Validation Loss: 0.00097088
Epoch [27/300], Train Loss: 0.000969
Validation Loss: 0.00096985
Epoch [28/300], Train Loss: 0.000973
Validation Loss: 0.00096927
Epoch [29/300], Train Loss: 0.000971
Validation Loss: 0.00096872
Epoch [30/300], Train Loss: 0.000966
Validation Loss: 0.00096793
Epoch [31/300], Train Loss: 0.000964
Validation Loss: 0.00096661
Epoch [32/300], Train Loss: 0.000967
Validation Loss: 0.00096494
Epoch [33/300], Train Loss: 0.000961
Validation Loss: 0.00096375
Epoch [34/300], Train Loss: 0.000960
Validation Loss: 0.00096075
Epoch [35/300], Train Loss: 0.000961
Validation Loss: 0.00095856
Epoch [36/300], Train Loss: 0.000961
Validation Loss: 0.00095577
Epoch [37/300], Train Loss: 0.000957
Validation Loss: 0.00095240
Epoch [38/300], Train Loss: 0.000946
Validation Loss: 0.00094850
Epoch [39/300], Train Loss: 0.000943
Validation Loss: 0.00094143
Epoch [40/300], Train Loss: 0.000934
Validation Loss: 0.00092944
Epoch [41/300], Train Loss: 0.000916
Validation Loss: 0.00091812
Epoch [42/300], Train Loss: 0.000887
Validation Loss: 0.00088172
Epoch [43/300], Train Loss: 0.000856
Validation Loss: 0.00085590
Epoch [44/300], Train Loss: 0.000818
Validation Loss: 0.00081164
Epoch [45/300], Train Loss: 0.000790
Validation Loss: 0.00078537
Epoch [46/300], Train Loss: 0.000779
Validation Loss: 0.00077678
Epoch [47/300], Train Loss: 0.000744
Validation Loss: 0.00075880
Epoch [48/300], Train Loss: 0.000746
Validation Loss: 0.00078528
Epoch [49/300], Train Loss: 0.000732
Validation Loss: 0.00071779
Epoch [50/300], Train Loss: 0.000712
Validation Loss: 0.00073411
Epoch [51/300], Train Loss: 0.000705
Validation Loss: 0.00070045
Epoch [52/300], Train Loss: 0.000691
Validation Loss: 0.00072381
Epoch [53/300], Train Loss: 0.000699
Validation Loss: 0.00067737
Epoch [54/300], Train Loss: 0.000671
Validation Loss: 0.00065756
Epoch [55/300], Train Loss: 0.000668
Validation Loss: 0.00067320
Epoch [56/300], Train Loss: 0.000661
Validation Loss: 0.00065169
Epoch [57/300], Train Loss: 0.000661
Validation Loss: 0.00065092
Epoch [58/300], Train Loss: 0.000644
Validation Loss: 0.00064555
Epoch [59/300], Train Loss: 0.000640
Validation Loss: 0.00064906
Epoch [60/300], Train Loss: 0.000632
Validation Loss: 0.00064067
Epoch [61/300], Train Loss: 0.000626
Validation Loss: 0.00063854
Epoch [62/300], Train Loss: 0.000617
Validation Loss: 0.00062600
Epoch [63/300], Train Loss: 0.000622
Validation Loss: 0.00064240
Epoch [64/300], Train Loss: 0.000614
Validation Loss: 0.00062243
Epoch [65/300], Train Loss: 0.000604
Validation Loss: 0.00061202
Epoch [66/300], Train Loss: 0.000621
Validation Loss: 0.00062321
Epoch [67/300], Train Loss: 0.000604
Validation Loss: 0.00060917
Epoch [68/300], Train Loss: 0.000597
Validation Loss: 0.00059894
Epoch [69/300], Train Loss: 0.000605
Validation Loss: 0.00061613
Epoch [70/300], Train Loss: 0.000603
Validation Loss: 0.00060035
Epoch [71/300], Train Loss: 0.000591
Validation Loss: 0.00058825
Epoch [72/300], Train Loss: 0.000589
Validation Loss: 0.00059241
Epoch [73/300], Train Loss: 0.000588
Validation Loss: 0.00059712
Epoch [74/300], Train Loss: 0.000582
Validation Loss: 0.00060157
Epoch [75/300], Train Loss: 0.000577
Validation Loss: 0.00059977
Epoch [76/300], Train Loss: 0.000580
Validation Loss: 0.00058967
Epoch [77/300], Train Loss: 0.000570
Validation Loss: 0.00058513
Epoch [78/300], Train Loss: 0.000562
Validation Loss: 0.00058272
Epoch [79/300], Train Loss: 0.000560
Validation Loss: 0.00059200
Epoch [80/300], Train Loss: 0.000565
Validation Loss: 0.00058234
Epoch [81/300], Train Loss: 0.000563
Validation Loss: 0.00058847
Epoch [82/300], Train Loss: 0.000551
Validation Loss: 0.00055466
Epoch [83/300], Train Loss: 0.000557
Validation Loss: 0.00057147
Epoch [84/300], Train Loss: 0.000574
Validation Loss: 0.00056731
Epoch [85/300], Train Loss: 0.000577
Validation Loss: 0.00058270
Epoch [86/300], Train Loss: 0.000573
Validation Loss: 0.00056747
Epoch [87/300], Train Loss: 0.000554
Validation Loss: 0.00056297
Epoch [88/300], Train Loss: 0.000546
Validation Loss: 0.00055915
Epoch [89/300], Train Loss: 0.000548
Validation Loss: 0.00056954
Epoch [90/300], Train Loss: 0.000552
Validation Loss: 0.00056761
Epoch [91/300], Train Loss: 0.000541
Validation Loss: 0.00057741
Epoch [92/300], Train Loss: 0.000546
Validation Loss: 0.00058154
Early stopping triggered

Evaluating model for: Coffee Machine
Run 15/72 completed in 834.33 seconds with: {'MAE': np.float32(6.4711585), 'MSE': np.float32(2789.4473), 'RMSE': np.float32(52.81522), 'SAE': np.float32(0.03145501), 'NDE': np.float32(0.82112795)}

Run 16/72: hidden=128, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Coffee Machine
Dataset length: 6004 windows

Epoch [1/300], Train Loss: 0.000981
Validation Loss: 0.00097148
Epoch [2/300], Train Loss: 0.000972
Validation Loss: 0.00097141
Epoch [3/300], Train Loss: 0.000975
Validation Loss: 0.00097159
Epoch [4/300], Train Loss: 0.000974
Validation Loss: 0.00097150
Epoch [5/300], Train Loss: 0.000976
Validation Loss: 0.00097167
Epoch [6/300], Train Loss: 0.000974
Validation Loss: 0.00097168
Epoch [7/300], Train Loss: 0.000968
Validation Loss: 0.00097144
Epoch [8/300], Train Loss: 0.000966
Validation Loss: 0.00097141
Epoch [9/300], Train Loss: 0.000975
Validation Loss: 0.00097143
Epoch [10/300], Train Loss: 0.000963
Validation Loss: 0.00097139
Epoch [11/300], Train Loss: 0.000977
Validation Loss: 0.00097149
Epoch [12/300], Train Loss: 0.000972
Validation Loss: 0.00097146
Epoch [13/300], Train Loss: 0.000969
Validation Loss: 0.00097143
Epoch [14/300], Train Loss: 0.000967
Validation Loss: 0.00097136
Epoch [15/300], Train Loss: 0.000966
Validation Loss: 0.00097142
Epoch [16/300], Train Loss: 0.000961
Validation Loss: 0.00097168
Epoch [17/300], Train Loss: 0.000966
Validation Loss: 0.00097141
Epoch [18/300], Train Loss: 0.000968
Validation Loss: 0.00097138
Epoch [19/300], Train Loss: 0.000967
Validation Loss: 0.00097135
Epoch [20/300], Train Loss: 0.000963
Validation Loss: 0.00097138
Epoch [21/300], Train Loss: 0.000978
Validation Loss: 0.00097128
Epoch [22/300], Train Loss: 0.000966
Validation Loss: 0.00097118
Epoch [23/300], Train Loss: 0.000966
Validation Loss: 0.00097113
Epoch [24/300], Train Loss: 0.000973
Validation Loss: 0.00097079
Epoch [25/300], Train Loss: 0.000968
Validation Loss: 0.00097003
Epoch [26/300], Train Loss: 0.000968
Validation Loss: 0.00096850
Epoch [27/300], Train Loss: 0.000961
Validation Loss: 0.00096671
Epoch [28/300], Train Loss: 0.000965
Validation Loss: 0.00096540
Epoch [29/300], Train Loss: 0.000962
Validation Loss: 0.00096408
Epoch [30/300], Train Loss: 0.000958
Validation Loss: 0.00096269
Epoch [31/300], Train Loss: 0.000954
Validation Loss: 0.00096141
Epoch [32/300], Train Loss: 0.000957
Validation Loss: 0.00095853
Epoch [33/300], Train Loss: 0.000950
Validation Loss: 0.00095508
Epoch [34/300], Train Loss: 0.000945
Validation Loss: 0.00094693
Epoch [35/300], Train Loss: 0.000939
Validation Loss: 0.00093900
Epoch [36/300], Train Loss: 0.000928
Validation Loss: 0.00091914
Epoch [37/300], Train Loss: 0.000902
Validation Loss: 0.00089171
Epoch [38/300], Train Loss: 0.000860
Validation Loss: 0.00086088
Epoch [39/300], Train Loss: 0.000825
Validation Loss: 0.00082260
Epoch [40/300], Train Loss: 0.000780
Validation Loss: 0.00077722
Epoch [41/300], Train Loss: 0.000752
Validation Loss: 0.00075238
Epoch [42/300], Train Loss: 0.000711
Validation Loss: 0.00072160
Epoch [43/300], Train Loss: 0.000704
Validation Loss: 0.00071268
Epoch [44/300], Train Loss: 0.000682
Validation Loss: 0.00069433
Epoch [45/300], Train Loss: 0.000659
Validation Loss: 0.00066985
Epoch [46/300], Train Loss: 0.000666
Validation Loss: 0.00068527
Epoch [47/300], Train Loss: 0.000645
Validation Loss: 0.00065000
Epoch [48/300], Train Loss: 0.000644
Validation Loss: 0.00063645
Epoch [49/300], Train Loss: 0.000635
Validation Loss: 0.00062916
Epoch [50/300], Train Loss: 0.000617
Validation Loss: 0.00063751
Epoch [51/300], Train Loss: 0.000621
Validation Loss: 0.00061585
Epoch [52/300], Train Loss: 0.000598
Validation Loss: 0.00061770
Epoch [53/300], Train Loss: 0.000598
Validation Loss: 0.00059602
Epoch [54/300], Train Loss: 0.000580
Validation Loss: 0.00057296
Epoch [55/300], Train Loss: 0.000579
Validation Loss: 0.00056612
Epoch [56/300], Train Loss: 0.000578
Validation Loss: 0.00057498
Epoch [57/300], Train Loss: 0.000572
Validation Loss: 0.00055970
Epoch [58/300], Train Loss: 0.000559
Validation Loss: 0.00055045
Epoch [59/300], Train Loss: 0.000555
Validation Loss: 0.00053666
Epoch [60/300], Train Loss: 0.000545
Validation Loss: 0.00052211
Epoch [61/300], Train Loss: 0.000538
Validation Loss: 0.00051286
Epoch [62/300], Train Loss: 0.000533
Validation Loss: 0.00050531
Epoch [63/300], Train Loss: 0.000533
Validation Loss: 0.00052219
Epoch [64/300], Train Loss: 0.000523
Validation Loss: 0.00049528
Epoch [65/300], Train Loss: 0.000514
Validation Loss: 0.00049990
Epoch [66/300], Train Loss: 0.000517
Validation Loss: 0.00048950
Epoch [67/300], Train Loss: 0.000520
Validation Loss: 0.00053553
Epoch [68/300], Train Loss: 0.000511
Validation Loss: 0.00050028
Epoch [69/300], Train Loss: 0.000508
Validation Loss: 0.00050670
Epoch [70/300], Train Loss: 0.000503
Validation Loss: 0.00047953
Epoch [71/300], Train Loss: 0.000500
Validation Loss: 0.00048533
Epoch [72/300], Train Loss: 0.000498
Validation Loss: 0.00049918
Epoch [73/300], Train Loss: 0.000507
Validation Loss: 0.00048995
Epoch [74/300], Train Loss: 0.000491
Validation Loss: 0.00047684
Epoch [75/300], Train Loss: 0.000489
Validation Loss: 0.00046514
Epoch [76/300], Train Loss: 0.000487
Validation Loss: 0.00047664
Epoch [77/300], Train Loss: 0.000483
Validation Loss: 0.00045796
Epoch [78/300], Train Loss: 0.000479
Validation Loss: 0.00045991
Epoch [79/300], Train Loss: 0.000481
Validation Loss: 0.00045806
Epoch [80/300], Train Loss: 0.000478
Validation Loss: 0.00045215
Epoch [81/300], Train Loss: 0.000468
Validation Loss: 0.00045391
Epoch [82/300], Train Loss: 0.000470
Validation Loss: 0.00046766
Epoch [83/300], Train Loss: 0.000475
Validation Loss: 0.00045034
Epoch [84/300], Train Loss: 0.000460
Validation Loss: 0.00045054
Epoch [85/300], Train Loss: 0.000466
Validation Loss: 0.00045635
Epoch [86/300], Train Loss: 0.000472
Validation Loss: 0.00044997
Epoch [87/300], Train Loss: 0.000466
Validation Loss: 0.00044374
Epoch [88/300], Train Loss: 0.000493
Validation Loss: 0.00045323
Epoch [89/300], Train Loss: 0.000471
Validation Loss: 0.00044540
Epoch [90/300], Train Loss: 0.000453
Validation Loss: 0.00044224
Epoch [91/300], Train Loss: 0.000452
Validation Loss: 0.00044274
Epoch [92/300], Train Loss: 0.000450
Validation Loss: 0.00043142
Epoch [93/300], Train Loss: 0.000455
Validation Loss: 0.00043385
Epoch [94/300], Train Loss: 0.000451
Validation Loss: 0.00044980
Epoch [95/300], Train Loss: 0.000444
Validation Loss: 0.00043123
Epoch [96/300], Train Loss: 0.000448
Validation Loss: 0.00042945
Epoch [97/300], Train Loss: 0.000446
Validation Loss: 0.00044421
Epoch [98/300], Train Loss: 0.000454
Validation Loss: 0.00042450
Epoch [99/300], Train Loss: 0.000437
Validation Loss: 0.00045637
Epoch [100/300], Train Loss: 0.000439
Validation Loss: 0.00043683
Epoch [101/300], Train Loss: 0.000441
Validation Loss: 0.00043038
Epoch [102/300], Train Loss: 0.000431
Validation Loss: 0.00042118
Epoch [103/300], Train Loss: 0.000428
Validation Loss: 0.00045379
Epoch [104/300], Train Loss: 0.000440
Validation Loss: 0.00041673
Epoch [105/300], Train Loss: 0.000425
Validation Loss: 0.00041882
Epoch [106/300], Train Loss: 0.000422
Validation Loss: 0.00042251
Epoch [107/300], Train Loss: 0.000423
Validation Loss: 0.00041347
Epoch [108/300], Train Loss: 0.000422
Validation Loss: 0.00042752
Epoch [109/300], Train Loss: 0.000422
Validation Loss: 0.00040010
Epoch [110/300], Train Loss: 0.000417
Validation Loss: 0.00040053
Epoch [111/300], Train Loss: 0.000413
Validation Loss: 0.00040436
Epoch [112/300], Train Loss: 0.000417
Validation Loss: 0.00040386
Epoch [113/300], Train Loss: 0.000405
Validation Loss: 0.00039554
Epoch [114/300], Train Loss: 0.000413
Validation Loss: 0.00040775
Epoch [115/300], Train Loss: 0.000483
Validation Loss: 0.00048284
Epoch [116/300], Train Loss: 0.000484
Validation Loss: 0.00044861
Epoch [117/300], Train Loss: 0.000451
Validation Loss: 0.00043091
Epoch [118/300], Train Loss: 0.000438
Validation Loss: 0.00041246
Epoch [119/300], Train Loss: 0.000431
Validation Loss: 0.00040266
Epoch [120/300], Train Loss: 0.000425
Validation Loss: 0.00042085
Epoch [121/300], Train Loss: 0.000421
Validation Loss: 0.00040527
Epoch [122/300], Train Loss: 0.000417
Validation Loss: 0.00040877
Epoch [123/300], Train Loss: 0.000412
Validation Loss: 0.00039884
Early stopping triggered

Evaluating model for: Coffee Machine
Run 16/72 completed in 1153.11 seconds with: {'MAE': np.float32(5.396203), 'MSE': np.float32(2165.4375), 'RMSE': np.float32(46.53426), 'SAE': np.float32(0.040767148), 'NDE': np.float32(0.72347647)}

Run 17/72: hidden=128, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Coffee Machine
Dataset length: 5916 windows

Epoch [1/300], Train Loss: 0.001250
Validation Loss: 0.00102172
Epoch [2/300], Train Loss: 0.000993
Validation Loss: 0.00100568
Epoch [3/300], Train Loss: 0.000990
Validation Loss: 0.00100542
Epoch [4/300], Train Loss: 0.000990
Validation Loss: 0.00100503
Epoch [5/300], Train Loss: 0.000989
Validation Loss: 0.00100479
Epoch [6/300], Train Loss: 0.000988
Validation Loss: 0.00100435
Epoch [7/300], Train Loss: 0.000987
Validation Loss: 0.00100398
Epoch [8/300], Train Loss: 0.000987
Validation Loss: 0.00100360
Epoch [9/300], Train Loss: 0.000985
Validation Loss: 0.00100312
Epoch [10/300], Train Loss: 0.000984
Validation Loss: 0.00100264
Epoch [11/300], Train Loss: 0.000984
Validation Loss: 0.00100204
Epoch [12/300], Train Loss: 0.000983
Validation Loss: 0.00100158
Epoch [13/300], Train Loss: 0.000982
Validation Loss: 0.00100071
Epoch [14/300], Train Loss: 0.000981
Validation Loss: 0.00099970
Epoch [15/300], Train Loss: 0.000980
Validation Loss: 0.00099854
Epoch [16/300], Train Loss: 0.000978
Validation Loss: 0.00099729
Epoch [17/300], Train Loss: 0.000976
Validation Loss: 0.00099574
Epoch [18/300], Train Loss: 0.000975
Validation Loss: 0.00099385
Epoch [19/300], Train Loss: 0.000973
Validation Loss: 0.00099120
Epoch [20/300], Train Loss: 0.000970
Validation Loss: 0.00098869
Epoch [21/300], Train Loss: 0.000968
Validation Loss: 0.00098624
Epoch [22/300], Train Loss: 0.000966
Validation Loss: 0.00098424
Epoch [23/300], Train Loss: 0.000964
Validation Loss: 0.00098204
Epoch [24/300], Train Loss: 0.000963
Validation Loss: 0.00097989
Epoch [25/300], Train Loss: 0.000961
Validation Loss: 0.00097707
Epoch [26/300], Train Loss: 0.000958
Validation Loss: 0.00097458
Epoch [27/300], Train Loss: 0.000955
Validation Loss: 0.00096970
Epoch [28/300], Train Loss: 0.000950
Validation Loss: 0.00096380
Epoch [29/300], Train Loss: 0.000943
Validation Loss: 0.00095454
Epoch [30/300], Train Loss: 0.000934
Validation Loss: 0.00094278
Epoch [31/300], Train Loss: 0.000920
Validation Loss: 0.00092613
Epoch [32/300], Train Loss: 0.000905
Validation Loss: 0.00090982
Epoch [33/300], Train Loss: 0.000888
Validation Loss: 0.00089872
Epoch [34/300], Train Loss: 0.000872
Validation Loss: 0.00087405
Epoch [35/300], Train Loss: 0.000852
Validation Loss: 0.00085948
Epoch [36/300], Train Loss: 0.000834
Validation Loss: 0.00083916
Epoch [37/300], Train Loss: 0.000816
Validation Loss: 0.00082363
Epoch [38/300], Train Loss: 0.000799
Validation Loss: 0.00080613
Epoch [39/300], Train Loss: 0.000784
Validation Loss: 0.00079956
Epoch [40/300], Train Loss: 0.000769
Validation Loss: 0.00078230
Epoch [41/300], Train Loss: 0.000755
Validation Loss: 0.00076652
Epoch [42/300], Train Loss: 0.000750
Validation Loss: 0.00077247
Epoch [43/300], Train Loss: 0.000735
Validation Loss: 0.00074730
Epoch [44/300], Train Loss: 0.000725
Validation Loss: 0.00073871
Epoch [45/300], Train Loss: 0.000715
Validation Loss: 0.00073517
Epoch [46/300], Train Loss: 0.000714
Validation Loss: 0.00072618
Epoch [47/300], Train Loss: 0.000700
Validation Loss: 0.00073935
Epoch [48/300], Train Loss: 0.000702
Validation Loss: 0.00071046
Epoch [49/300], Train Loss: 0.000690
Validation Loss: 0.00070218
Epoch [50/300], Train Loss: 0.000682
Validation Loss: 0.00069895
Epoch [51/300], Train Loss: 0.000683
Validation Loss: 0.00069776
Epoch [52/300], Train Loss: 0.000672
Validation Loss: 0.00068333
Epoch [53/300], Train Loss: 0.000660
Validation Loss: 0.00068576
Epoch [54/300], Train Loss: 0.000662
Validation Loss: 0.00067377
Epoch [55/300], Train Loss: 0.000651
Validation Loss: 0.00067021
Epoch [56/300], Train Loss: 0.000652
Validation Loss: 0.00066325
Epoch [57/300], Train Loss: 0.000646
Validation Loss: 0.00066041
Epoch [58/300], Train Loss: 0.000639
Validation Loss: 0.00065755
Epoch [59/300], Train Loss: 0.000633
Validation Loss: 0.00065129
Epoch [60/300], Train Loss: 0.000630
Validation Loss: 0.00065192
Epoch [61/300], Train Loss: 0.000628
Validation Loss: 0.00064480
Epoch [62/300], Train Loss: 0.000623
Validation Loss: 0.00064292
Epoch [63/300], Train Loss: 0.000617
Validation Loss: 0.00064286
Epoch [64/300], Train Loss: 0.000620
Validation Loss: 0.00064006
Epoch [65/300], Train Loss: 0.000617
Validation Loss: 0.00064331
Epoch [66/300], Train Loss: 0.000615
Validation Loss: 0.00063408
Epoch [67/300], Train Loss: 0.000609
Validation Loss: 0.00062805
Epoch [68/300], Train Loss: 0.000607
Validation Loss: 0.00062444
Epoch [69/300], Train Loss: 0.000603
Validation Loss: 0.00062234
Epoch [70/300], Train Loss: 0.000599
Validation Loss: 0.00061712
Epoch [71/300], Train Loss: 0.000596
Validation Loss: 0.00061467
Epoch [72/300], Train Loss: 0.000601
Validation Loss: 0.00061661
Epoch [73/300], Train Loss: 0.000592
Validation Loss: 0.00061412
Epoch [74/300], Train Loss: 0.000590
Validation Loss: 0.00061693
Epoch [75/300], Train Loss: 0.000590
Validation Loss: 0.00060889
Epoch [76/300], Train Loss: 0.000585
Validation Loss: 0.00060270
Epoch [77/300], Train Loss: 0.000585
Validation Loss: 0.00060868
Epoch [78/300], Train Loss: 0.000586
Validation Loss: 0.00060185
Epoch [79/300], Train Loss: 0.000580
Validation Loss: 0.00060410
Epoch [80/300], Train Loss: 0.000578
Validation Loss: 0.00059829
Epoch [81/300], Train Loss: 0.000575
Validation Loss: 0.00059713
Epoch [82/300], Train Loss: 0.000575
Validation Loss: 0.00059363
Epoch [83/300], Train Loss: 0.000573
Validation Loss: 0.00058891
Epoch [84/300], Train Loss: 0.000570
Validation Loss: 0.00059202
Epoch [85/300], Train Loss: 0.000576
Validation Loss: 0.00058474
Epoch [86/300], Train Loss: 0.000570
Validation Loss: 0.00058430
Epoch [87/300], Train Loss: 0.000567
Validation Loss: 0.00058136
Epoch [88/300], Train Loss: 0.000562
Validation Loss: 0.00058262
Epoch [89/300], Train Loss: 0.000564
Validation Loss: 0.00057875
Epoch [90/300], Train Loss: 0.000563
Validation Loss: 0.00057977
Epoch [91/300], Train Loss: 0.000560
Validation Loss: 0.00059541
Epoch [92/300], Train Loss: 0.000559
Validation Loss: 0.00057448
Epoch [93/300], Train Loss: 0.000551
Validation Loss: 0.00056821
Epoch [94/300], Train Loss: 0.000551
Validation Loss: 0.00056930
Epoch [95/300], Train Loss: 0.000554
Validation Loss: 0.00056585
Epoch [96/300], Train Loss: 0.000554
Validation Loss: 0.00056338
Epoch [97/300], Train Loss: 0.000547
Validation Loss: 0.00056355
Epoch [98/300], Train Loss: 0.000543
Validation Loss: 0.00056278
Epoch [99/300], Train Loss: 0.000547
Validation Loss: 0.00055827
Epoch [100/300], Train Loss: 0.000545
Validation Loss: 0.00055722
Epoch [101/300], Train Loss: 0.000544
Validation Loss: 0.00055904
Epoch [102/300], Train Loss: 0.000542
Validation Loss: 0.00055608
Epoch [103/300], Train Loss: 0.000537
Validation Loss: 0.00055755
Epoch [104/300], Train Loss: 0.000534
Validation Loss: 0.00055432
Epoch [105/300], Train Loss: 0.000535
Validation Loss: 0.00056346
Epoch [106/300], Train Loss: 0.000541
Validation Loss: 0.00054812
Epoch [107/300], Train Loss: 0.000532
Validation Loss: 0.00055972
Epoch [108/300], Train Loss: 0.000538
Validation Loss: 0.00054717
Epoch [109/300], Train Loss: 0.000530
Validation Loss: 0.00055104
Epoch [110/300], Train Loss: 0.000525
Validation Loss: 0.00054655
Epoch [111/300], Train Loss: 0.000520
Validation Loss: 0.00054024
Epoch [112/300], Train Loss: 0.000517
Validation Loss: 0.00054350
Epoch [113/300], Train Loss: 0.000518
Validation Loss: 0.00053976
Epoch [114/300], Train Loss: 0.000522
Validation Loss: 0.00054458
Epoch [115/300], Train Loss: 0.000520
Validation Loss: 0.00053462
Epoch [116/300], Train Loss: 0.000518
Validation Loss: 0.00053384
Epoch [117/300], Train Loss: 0.000517
Validation Loss: 0.00053386
Epoch [118/300], Train Loss: 0.000513
Validation Loss: 0.00053218
Epoch [119/300], Train Loss: 0.000517
Validation Loss: 0.00053479
Epoch [120/300], Train Loss: 0.000510
Validation Loss: 0.00052785
Epoch [121/300], Train Loss: 0.000509
Validation Loss: 0.00053166
Epoch [122/300], Train Loss: 0.000501
Validation Loss: 0.00055724
Epoch [123/300], Train Loss: 0.000514
Validation Loss: 0.00052766
Epoch [124/300], Train Loss: 0.000508
Validation Loss: 0.00053375
Epoch [125/300], Train Loss: 0.000499
Validation Loss: 0.00053080
Epoch [126/300], Train Loss: 0.000500
Validation Loss: 0.00052683
Epoch [127/300], Train Loss: 0.000498
Validation Loss: 0.00052387
Epoch [128/300], Train Loss: 0.000501
Validation Loss: 0.00052161
Epoch [129/300], Train Loss: 0.000498
Validation Loss: 0.00052349
Epoch [130/300], Train Loss: 0.000495
Validation Loss: 0.00052525
Epoch [131/300], Train Loss: 0.000496
Validation Loss: 0.00052358
Epoch [132/300], Train Loss: 0.000495
Validation Loss: 0.00051843
Epoch [133/300], Train Loss: 0.000494
Validation Loss: 0.00052265
Epoch [134/300], Train Loss: 0.000503
Validation Loss: 0.00051701
Epoch [135/300], Train Loss: 0.000496
Validation Loss: 0.00051772
Epoch [136/300], Train Loss: 0.000495
Validation Loss: 0.00052051
Epoch [137/300], Train Loss: 0.000498
Validation Loss: 0.00052083
Epoch [138/300], Train Loss: 0.000487
Validation Loss: 0.00051732
Epoch [139/300], Train Loss: 0.000488
Validation Loss: 0.00051287
Epoch [140/300], Train Loss: 0.000487
Validation Loss: 0.00051739
Epoch [141/300], Train Loss: 0.000488
Validation Loss: 0.00051136
Epoch [142/300], Train Loss: 0.000483
Validation Loss: 0.00051234
Epoch [143/300], Train Loss: 0.000484
Validation Loss: 0.00051410
Epoch [144/300], Train Loss: 0.000488
Validation Loss: 0.00051546
Epoch [145/300], Train Loss: 0.000489
Validation Loss: 0.00050757
Epoch [146/300], Train Loss: 0.000479
Validation Loss: 0.00050539
Epoch [147/300], Train Loss: 0.000485
Validation Loss: 0.00051168
Epoch [148/300], Train Loss: 0.000486
Validation Loss: 0.00050441
Epoch [149/300], Train Loss: 0.000478
Validation Loss: 0.00050591
Epoch [150/300], Train Loss: 0.000476
Validation Loss: 0.00050415
Epoch [151/300], Train Loss: 0.000474
Validation Loss: 0.00050283
Epoch [152/300], Train Loss: 0.000517
Validation Loss: 0.00051594
Epoch [153/300], Train Loss: 0.000501
Validation Loss: 0.00050939
Epoch [154/300], Train Loss: 0.000488
Validation Loss: 0.00050261
Epoch [155/300], Train Loss: 0.000478
Validation Loss: 0.00049957
Epoch [156/300], Train Loss: 0.000474
Validation Loss: 0.00049753
Epoch [157/300], Train Loss: 0.000470
Validation Loss: 0.00049988
Epoch [158/300], Train Loss: 0.000487
Validation Loss: 0.00060382
Epoch [159/300], Train Loss: 0.000528
Validation Loss: 0.00051405
Epoch [160/300], Train Loss: 0.000490
Validation Loss: 0.00050389
Epoch [161/300], Train Loss: 0.000474
Validation Loss: 0.00050038
Epoch [162/300], Train Loss: 0.000474
Validation Loss: 0.00050158
Epoch [163/300], Train Loss: 0.000471
Validation Loss: 0.00049858
Epoch [164/300], Train Loss: 0.000465
Validation Loss: 0.00049556
Epoch [165/300], Train Loss: 0.000466
Validation Loss: 0.00049815
Epoch [166/300], Train Loss: 0.000468
Validation Loss: 0.00049151
Epoch [167/300], Train Loss: 0.000462
Validation Loss: 0.00049108
Epoch [168/300], Train Loss: 0.000461
Validation Loss: 0.00049815
Epoch [169/300], Train Loss: 0.000467
Validation Loss: 0.00049218
Epoch [170/300], Train Loss: 0.000462
Validation Loss: 0.00049507
Epoch [171/300], Train Loss: 0.000463
Validation Loss: 0.00048741
Epoch [172/300], Train Loss: 0.000484
Validation Loss: 0.00053852
Epoch [173/300], Train Loss: 0.000506
Validation Loss: 0.00050050
Epoch [174/300], Train Loss: 0.000488
Validation Loss: 0.00049606
Epoch [175/300], Train Loss: 0.000479
Validation Loss: 0.00049207
Epoch [176/300], Train Loss: 0.000474
Validation Loss: 0.00049238
Epoch [177/300], Train Loss: 0.000478
Validation Loss: 0.00048805
Epoch [178/300], Train Loss: 0.000460
Validation Loss: 0.00048675
Epoch [179/300], Train Loss: 0.000458
Validation Loss: 0.00048405
Epoch [180/300], Train Loss: 0.000456
Validation Loss: 0.00048535
Epoch [181/300], Train Loss: 0.000457
Validation Loss: 0.00048154
Epoch [182/300], Train Loss: 0.000454
Validation Loss: 0.00049137
Epoch [183/300], Train Loss: 0.000463
Validation Loss: 0.00048672
Epoch [184/300], Train Loss: 0.000459
Validation Loss: 0.00048300
Epoch [185/300], Train Loss: 0.000454
Validation Loss: 0.00048280
Epoch [186/300], Train Loss: 0.000456
Validation Loss: 0.00047707
Epoch [187/300], Train Loss: 0.000453
Validation Loss: 0.00047817
Epoch [188/300], Train Loss: 0.000454
Validation Loss: 0.00047799
Epoch [189/300], Train Loss: 0.000453
Validation Loss: 0.00048266
Epoch [190/300], Train Loss: 0.000453
Validation Loss: 0.00047614
Epoch [191/300], Train Loss: 0.000450
Validation Loss: 0.00047738
Epoch [192/300], Train Loss: 0.000456
Validation Loss: 0.00047453
Epoch [193/300], Train Loss: 0.000451
Validation Loss: 0.00047472
Epoch [194/300], Train Loss: 0.000452
Validation Loss: 0.00047827
Epoch [195/300], Train Loss: 0.000450
Validation Loss: 0.00047891
Epoch [196/300], Train Loss: 0.000451
Validation Loss: 0.00047485
Epoch [197/300], Train Loss: 0.000451
Validation Loss: 0.00047149
Epoch [198/300], Train Loss: 0.000449
Validation Loss: 0.00047351
Epoch [199/300], Train Loss: 0.000447
Validation Loss: 0.00047031
Epoch [200/300], Train Loss: 0.000448
Validation Loss: 0.00048679
Epoch [201/300], Train Loss: 0.000460
Validation Loss: 0.00047284
Epoch [202/300], Train Loss: 0.000447
Validation Loss: 0.00047138
Epoch [203/300], Train Loss: 0.000444
Validation Loss: 0.00046989
Epoch [204/300], Train Loss: 0.000443
Validation Loss: 0.00046939
Epoch [205/300], Train Loss: 0.000451
Validation Loss: 0.00047203
Epoch [206/300], Train Loss: 0.000445
Validation Loss: 0.00046856
Epoch [207/300], Train Loss: 0.000442
Validation Loss: 0.00047792
Epoch [208/300], Train Loss: 0.000445
Validation Loss: 0.00047036
Epoch [209/300], Train Loss: 0.000445
Validation Loss: 0.00046623
Epoch [210/300], Train Loss: 0.000439
Validation Loss: 0.00046702
Epoch [211/300], Train Loss: 0.000442
Validation Loss: 0.00047061
Epoch [212/300], Train Loss: 0.000442
Validation Loss: 0.00046469
Epoch [213/300], Train Loss: 0.000439
Validation Loss: 0.00046372
Epoch [214/300], Train Loss: 0.000439
Validation Loss: 0.00046246
Epoch [215/300], Train Loss: 0.000436
Validation Loss: 0.00046260
Epoch [216/300], Train Loss: 0.000437
Validation Loss: 0.00045939
Epoch [217/300], Train Loss: 0.000438
Validation Loss: 0.00046131
Epoch [218/300], Train Loss: 0.000438
Validation Loss: 0.00046049
Epoch [219/300], Train Loss: 0.000434
Validation Loss: 0.00046557
Epoch [220/300], Train Loss: 0.000440
Validation Loss: 0.00045968
Epoch [221/300], Train Loss: 0.000436
Validation Loss: 0.00045793
Epoch [222/300], Train Loss: 0.000434
Validation Loss: 0.00045657
Epoch [223/300], Train Loss: 0.000435
Validation Loss: 0.00045941
Epoch [224/300], Train Loss: 0.000436
Validation Loss: 0.00045571
Epoch [225/300], Train Loss: 0.000433
Validation Loss: 0.00045641
Epoch [226/300], Train Loss: 0.000432
Validation Loss: 0.00045680
Epoch [227/300], Train Loss: 0.000433
Validation Loss: 0.00045847
Epoch [228/300], Train Loss: 0.000431
Validation Loss: 0.00045653
Epoch [229/300], Train Loss: 0.000432
Validation Loss: 0.00046081
Epoch [230/300], Train Loss: 0.000439
Validation Loss: 0.00045497
Epoch [231/300], Train Loss: 0.000431
Validation Loss: 0.00045301
Epoch [232/300], Train Loss: 0.000434
Validation Loss: 0.00045155
Epoch [233/300], Train Loss: 0.000430
Validation Loss: 0.00045251
Epoch [234/300], Train Loss: 0.000429
Validation Loss: 0.00045144
Epoch [235/300], Train Loss: 0.000430
Validation Loss: 0.00045739
Epoch [236/300], Train Loss: 0.000444
Validation Loss: 0.00045496
Epoch [237/300], Train Loss: 0.000432
Validation Loss: 0.00045390
Epoch [238/300], Train Loss: 0.000427
Validation Loss: 0.00045416
Epoch [239/300], Train Loss: 0.000430
Validation Loss: 0.00045096
Epoch [240/300], Train Loss: 0.000425
Validation Loss: 0.00044809
Epoch [241/300], Train Loss: 0.000427
Validation Loss: 0.00044770
Epoch [242/300], Train Loss: 0.000423
Validation Loss: 0.00044749
Epoch [243/300], Train Loss: 0.000423
Validation Loss: 0.00045006
Epoch [244/300], Train Loss: 0.000428
Validation Loss: 0.00044965
Epoch [245/300], Train Loss: 0.000426
Validation Loss: 0.00045202
Epoch [246/300], Train Loss: 0.000426
Validation Loss: 0.00044791
Epoch [247/300], Train Loss: 0.000426
Validation Loss: 0.00047798
Epoch [248/300], Train Loss: 0.000450
Validation Loss: 0.00045721
Epoch [249/300], Train Loss: 0.000435
Validation Loss: 0.00045078
Epoch [250/300], Train Loss: 0.000443
Validation Loss: 0.00047544
Epoch [251/300], Train Loss: 0.000457
Validation Loss: 0.00045573
Epoch [252/300], Train Loss: 0.000427
Validation Loss: 0.00044817
Early stopping triggered

Evaluating model for: Coffee Machine
Run 17/72 completed in 2167.17 seconds with: {'MAE': np.float32(5.252666), 'MSE': np.float32(1910.763), 'RMSE': np.float32(43.712273), 'SAE': np.float32(0.024325859), 'NDE': np.float32(0.67333406)}

Run 18/72: hidden=128, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Coffee Machine
Dataset length: 5916 windows

Epoch [1/300], Train Loss: 0.001007
Validation Loss: 0.00100792
Epoch [2/300], Train Loss: 0.000993
Validation Loss: 0.00100571
Epoch [3/300], Train Loss: 0.000991
Validation Loss: 0.00100574
Epoch [4/300], Train Loss: 0.000989
Validation Loss: 0.00100499
Epoch [5/300], Train Loss: 0.000987
Validation Loss: 0.00100444
Epoch [6/300], Train Loss: 0.000985
Validation Loss: 0.00100374
Epoch [7/300], Train Loss: 0.000984
Validation Loss: 0.00100321
Epoch [8/300], Train Loss: 0.000983
Validation Loss: 0.00100222
Epoch [9/300], Train Loss: 0.000981
Validation Loss: 0.00100231
Epoch [10/300], Train Loss: 0.000980
Validation Loss: 0.00100029
Epoch [11/300], Train Loss: 0.000979
Validation Loss: 0.00099855
Epoch [12/300], Train Loss: 0.000978
Validation Loss: 0.00099689
Epoch [13/300], Train Loss: 0.000976
Validation Loss: 0.00099498
Epoch [14/300], Train Loss: 0.000973
Validation Loss: 0.00099175
Epoch [15/300], Train Loss: 0.000970
Validation Loss: 0.00098797
Epoch [16/300], Train Loss: 0.000967
Validation Loss: 0.00098536
Epoch [17/300], Train Loss: 0.000962
Validation Loss: 0.00097918
Epoch [18/300], Train Loss: 0.000956
Validation Loss: 0.00097094
Epoch [19/300], Train Loss: 0.000947
Validation Loss: 0.00095850
Epoch [20/300], Train Loss: 0.000935
Validation Loss: 0.00094427
Epoch [21/300], Train Loss: 0.000918
Validation Loss: 0.00092198
Epoch [22/300], Train Loss: 0.000894
Validation Loss: 0.00089505
Epoch [23/300], Train Loss: 0.000868
Validation Loss: 0.00087109
Epoch [24/300], Train Loss: 0.000843
Validation Loss: 0.00084628
Epoch [25/300], Train Loss: 0.000815
Validation Loss: 0.00081914
Epoch [26/300], Train Loss: 0.000791
Validation Loss: 0.00079789
Epoch [27/300], Train Loss: 0.000770
Validation Loss: 0.00077121
Epoch [28/300], Train Loss: 0.000748
Validation Loss: 0.00075709
Epoch [29/300], Train Loss: 0.000729
Validation Loss: 0.00074254
Epoch [30/300], Train Loss: 0.000706
Validation Loss: 0.00072836
Epoch [31/300], Train Loss: 0.000696
Validation Loss: 0.00072001
Epoch [32/300], Train Loss: 0.000677
Validation Loss: 0.00069865
Epoch [33/300], Train Loss: 0.000666
Validation Loss: 0.00071007
Epoch [34/300], Train Loss: 0.000662
Validation Loss: 0.00068171
Epoch [35/300], Train Loss: 0.000659
Validation Loss: 0.00069022
Epoch [36/300], Train Loss: 0.000648
Validation Loss: 0.00066969
Epoch [37/300], Train Loss: 0.000634
Validation Loss: 0.00066181
Epoch [38/300], Train Loss: 0.000639
Validation Loss: 0.00066070
Epoch [39/300], Train Loss: 0.000626
Validation Loss: 0.00064726
Epoch [40/300], Train Loss: 0.000632
Validation Loss: 0.00068054
Epoch [41/300], Train Loss: 0.000619
Validation Loss: 0.00063896
Epoch [42/300], Train Loss: 0.000614
Validation Loss: 0.00063409
Epoch [43/300], Train Loss: 0.000605
Validation Loss: 0.00062799
Epoch [44/300], Train Loss: 0.000604
Validation Loss: 0.00065008
Epoch [45/300], Train Loss: 0.000606
Validation Loss: 0.00062488
Epoch [46/300], Train Loss: 0.000596
Validation Loss: 0.00061583
Epoch [47/300], Train Loss: 0.000592
Validation Loss: 0.00061394
Epoch [48/300], Train Loss: 0.000590
Validation Loss: 0.00061184
Epoch [49/300], Train Loss: 0.000585
Validation Loss: 0.00060463
Epoch [50/300], Train Loss: 0.000580
Validation Loss: 0.00059905
Epoch [51/300], Train Loss: 0.000582
Validation Loss: 0.00061465
Epoch [52/300], Train Loss: 0.000577
Validation Loss: 0.00059219
Epoch [53/300], Train Loss: 0.000568
Validation Loss: 0.00058759
Epoch [54/300], Train Loss: 0.000567
Validation Loss: 0.00058487
Epoch [55/300], Train Loss: 0.000561
Validation Loss: 0.00058726
Epoch [56/300], Train Loss: 0.000560
Validation Loss: 0.00057754
Epoch [57/300], Train Loss: 0.000557
Validation Loss: 0.00057321
Epoch [58/300], Train Loss: 0.000551
Validation Loss: 0.00057114
Epoch [59/300], Train Loss: 0.000547
Validation Loss: 0.00056317
Epoch [60/300], Train Loss: 0.000550
Validation Loss: 0.00056949
Epoch [61/300], Train Loss: 0.000550
Validation Loss: 0.00056046
Epoch [62/300], Train Loss: 0.000543
Validation Loss: 0.00055536
Epoch [63/300], Train Loss: 0.000534
Validation Loss: 0.00055776
Epoch [64/300], Train Loss: 0.000554
Validation Loss: 0.00055809
Epoch [65/300], Train Loss: 0.000547
Validation Loss: 0.00056737
Epoch [66/300], Train Loss: 0.000538
Validation Loss: 0.00054437
Epoch [67/300], Train Loss: 0.000529
Validation Loss: 0.00053955
Epoch [68/300], Train Loss: 0.000525
Validation Loss: 0.00053475
Epoch [69/300], Train Loss: 0.000522
Validation Loss: 0.00053630
Epoch [70/300], Train Loss: 0.000521
Validation Loss: 0.00053076
Epoch [71/300], Train Loss: 0.000516
Validation Loss: 0.00053706
Epoch [72/300], Train Loss: 0.000512
Validation Loss: 0.00052279
Epoch [73/300], Train Loss: 0.000523
Validation Loss: 0.00053557
Epoch [74/300], Train Loss: 0.000521
Validation Loss: 0.00052116
Epoch [75/300], Train Loss: 0.000513
Validation Loss: 0.00051667
Epoch [76/300], Train Loss: 0.000512
Validation Loss: 0.00051103
Epoch [77/300], Train Loss: 0.000513
Validation Loss: 0.00051283
Epoch [78/300], Train Loss: 0.000509
Validation Loss: 0.00050941
Epoch [79/300], Train Loss: 0.000503
Validation Loss: 0.00050947
Epoch [80/300], Train Loss: 0.000500
Validation Loss: 0.00051471
Epoch [81/300], Train Loss: 0.000497
Validation Loss: 0.00050123
Epoch [82/300], Train Loss: 0.000493
Validation Loss: 0.00050034
Epoch [83/300], Train Loss: 0.000494
Validation Loss: 0.00049984
Epoch [84/300], Train Loss: 0.000492
Validation Loss: 0.00049991
Epoch [85/300], Train Loss: 0.000491
Validation Loss: 0.00048951
Epoch [86/300], Train Loss: 0.000484
Validation Loss: 0.00048595
Epoch [87/300], Train Loss: 0.000475
Validation Loss: 0.00048901
Epoch [88/300], Train Loss: 0.000476
Validation Loss: 0.00048293
Epoch [89/300], Train Loss: 0.000482
Validation Loss: 0.00049798
Epoch [90/300], Train Loss: 0.000476
Validation Loss: 0.00048387
Epoch [91/300], Train Loss: 0.000470
Validation Loss: 0.00047335
Epoch [92/300], Train Loss: 0.000462
Validation Loss: 0.00048147
Epoch [93/300], Train Loss: 0.000463
Validation Loss: 0.00046944
Epoch [94/300], Train Loss: 0.000458
Validation Loss: 0.00047903
Epoch [95/300], Train Loss: 0.000457
Validation Loss: 0.00047424
Epoch [96/300], Train Loss: 0.000459
Validation Loss: 0.00046732
Epoch [97/300], Train Loss: 0.000453
Validation Loss: 0.00045991
Epoch [98/300], Train Loss: 0.000457
Validation Loss: 0.00046008
Epoch [99/300], Train Loss: 0.000456
Validation Loss: 0.00046398
Epoch [100/300], Train Loss: 0.000455
Validation Loss: 0.00045365
Epoch [101/300], Train Loss: 0.000464
Validation Loss: 0.00046289
Epoch [102/300], Train Loss: 0.000460
Validation Loss: 0.00046465
Epoch [103/300], Train Loss: 0.000455
Validation Loss: 0.00045552
Epoch [104/300], Train Loss: 0.000447
Validation Loss: 0.00045069
Epoch [105/300], Train Loss: 0.000439
Validation Loss: 0.00045327
Epoch [106/300], Train Loss: 0.000447
Validation Loss: 0.00044314
Epoch [107/300], Train Loss: 0.000447
Validation Loss: 0.00045919
Epoch [108/300], Train Loss: 0.000449
Validation Loss: 0.00044913
Epoch [109/300], Train Loss: 0.000437
Validation Loss: 0.00043863
Epoch [110/300], Train Loss: 0.000501
Validation Loss: 0.00045882
Epoch [111/300], Train Loss: 0.000467
Validation Loss: 0.00044791
Epoch [112/300], Train Loss: 0.000453
Validation Loss: 0.00044327
Epoch [113/300], Train Loss: 0.000444
Validation Loss: 0.00044607
Epoch [114/300], Train Loss: 0.000446
Validation Loss: 0.00043370
Epoch [115/300], Train Loss: 0.000438
Validation Loss: 0.00044146
Epoch [116/300], Train Loss: 0.000441
Validation Loss: 0.00043979
Epoch [117/300], Train Loss: 0.000436
Validation Loss: 0.00043177
Epoch [118/300], Train Loss: 0.000437
Validation Loss: 0.00042641
Epoch [119/300], Train Loss: 0.000431
Validation Loss: 0.00043470
Epoch [120/300], Train Loss: 0.000432
Validation Loss: 0.00043549
Epoch [121/300], Train Loss: 0.000427
Validation Loss: 0.00042355
Epoch [122/300], Train Loss: 0.000423
Validation Loss: 0.00042534
Epoch [123/300], Train Loss: 0.000424
Validation Loss: 0.00042209
Epoch [124/300], Train Loss: 0.000421
Validation Loss: 0.00042057
Epoch [125/300], Train Loss: 0.000419
Validation Loss: 0.00041743
Epoch [126/300], Train Loss: 0.000419
Validation Loss: 0.00041762
Epoch [127/300], Train Loss: 0.000418
Validation Loss: 0.00042432
Epoch [128/300], Train Loss: 0.000413
Validation Loss: 0.00041770
Epoch [129/300], Train Loss: 0.000413
Validation Loss: 0.00041944
Epoch [130/300], Train Loss: 0.000415
Validation Loss: 0.00040887
Epoch [131/300], Train Loss: 0.000412
Validation Loss: 0.00041181
Epoch [132/300], Train Loss: 0.000415
Validation Loss: 0.00041659
Epoch [133/300], Train Loss: 0.000413
Validation Loss: 0.00041600
Epoch [134/300], Train Loss: 0.000408
Validation Loss: 0.00040293
Epoch [135/300], Train Loss: 0.000407
Validation Loss: 0.00040472
Epoch [136/300], Train Loss: 0.000403
Validation Loss: 0.00039976
Epoch [137/300], Train Loss: 0.000401
Validation Loss: 0.00040070
Epoch [138/300], Train Loss: 0.000406
Validation Loss: 0.00040825
Epoch [139/300], Train Loss: 0.000402
Validation Loss: 0.00040084
Epoch [140/300], Train Loss: 0.000410
Validation Loss: 0.00041066
Epoch [141/300], Train Loss: 0.000410
Validation Loss: 0.00040558
Epoch [142/300], Train Loss: 0.000398
Validation Loss: 0.00039266
Epoch [143/300], Train Loss: 0.000391
Validation Loss: 0.00038982
Epoch [144/300], Train Loss: 0.000396
Validation Loss: 0.00038939
Epoch [145/300], Train Loss: 0.000401
Validation Loss: 0.00039836
Epoch [146/300], Train Loss: 0.000391
Validation Loss: 0.00039243
Epoch [147/300], Train Loss: 0.000393
Validation Loss: 0.00039576
Epoch [148/300], Train Loss: 0.000395
Validation Loss: 0.00038934
Epoch [149/300], Train Loss: 0.000388
Validation Loss: 0.00039276
Epoch [150/300], Train Loss: 0.000394
Validation Loss: 0.00038118
Epoch [151/300], Train Loss: 0.000388
Validation Loss: 0.00038578
Epoch [152/300], Train Loss: 0.000382
Validation Loss: 0.00037770
Epoch [153/300], Train Loss: 0.000379
Validation Loss: 0.00037738
Epoch [154/300], Train Loss: 0.000377
Validation Loss: 0.00037721
Epoch [155/300], Train Loss: 0.000399
Validation Loss: 0.00041818
Epoch [156/300], Train Loss: 0.000400
Validation Loss: 0.00038742
Epoch [157/300], Train Loss: 0.000384
Validation Loss: 0.00037800
Epoch [158/300], Train Loss: 0.000373
Validation Loss: 0.00037681
Epoch [159/300], Train Loss: 0.000370
Validation Loss: 0.00037080
Epoch [160/300], Train Loss: 0.000369
Validation Loss: 0.00036950
Epoch [161/300], Train Loss: 0.000367
Validation Loss: 0.00036969
Epoch [162/300], Train Loss: 0.000366
Validation Loss: 0.00040207
Epoch [163/300], Train Loss: 0.000390
Validation Loss: 0.00038065
Epoch [164/300], Train Loss: 0.000376
Validation Loss: 0.00036817
Epoch [165/300], Train Loss: 0.000375
Validation Loss: 0.00038354
Epoch [166/300], Train Loss: 0.000384
Validation Loss: 0.00037398
Epoch [167/300], Train Loss: 0.000378
Validation Loss: 0.00037502
Epoch [168/300], Train Loss: 0.000371
Validation Loss: 0.00036791
Epoch [169/300], Train Loss: 0.000372
Validation Loss: 0.00036761
Epoch [170/300], Train Loss: 0.000366
Validation Loss: 0.00036947
Epoch [171/300], Train Loss: 0.000368
Validation Loss: 0.00036500
Epoch [172/300], Train Loss: 0.000365
Validation Loss: 0.00036297
Epoch [173/300], Train Loss: 0.000364
Validation Loss: 0.00036288
Epoch [174/300], Train Loss: 0.000362
Validation Loss: 0.00035916
Epoch [175/300], Train Loss: 0.000358
Validation Loss: 0.00035920
Epoch [176/300], Train Loss: 0.000387
Validation Loss: 0.00038514
Epoch [177/300], Train Loss: 0.000381
Validation Loss: 0.00037788
Epoch [178/300], Train Loss: 0.000371
Validation Loss: 0.00038002
Epoch [179/300], Train Loss: 0.000367
Validation Loss: 0.00037018
Epoch [180/300], Train Loss: 0.000363
Validation Loss: 0.00037374
Epoch [181/300], Train Loss: 0.000361
Validation Loss: 0.00036408
Epoch [182/300], Train Loss: 0.000362
Validation Loss: 0.00036106
Epoch [183/300], Train Loss: 0.000357
Validation Loss: 0.00036376
Epoch [184/300], Train Loss: 0.000356
Validation Loss: 0.00035536
Epoch [185/300], Train Loss: 0.000354
Validation Loss: 0.00035660
Epoch [186/300], Train Loss: 0.000357
Validation Loss: 0.00035754
Epoch [187/300], Train Loss: 0.000353
Validation Loss: 0.00035339
Epoch [188/300], Train Loss: 0.000350
Validation Loss: 0.00035330
Epoch [189/300], Train Loss: 0.000348
Validation Loss: 0.00034974
Epoch [190/300], Train Loss: 0.000349
Validation Loss: 0.00035802
Epoch [191/300], Train Loss: 0.000349
Validation Loss: 0.00035218
Epoch [192/300], Train Loss: 0.000346
Validation Loss: 0.00034777
Epoch [193/300], Train Loss: 0.000344
Validation Loss: 0.00034930
Epoch [194/300], Train Loss: 0.000345
Validation Loss: 0.00034378
Epoch [195/300], Train Loss: 0.000343
Validation Loss: 0.00034584
Epoch [196/300], Train Loss: 0.000339
Validation Loss: 0.00034190
Epoch [197/300], Train Loss: 0.000339
Validation Loss: 0.00034249
Epoch [198/300], Train Loss: 0.000341
Validation Loss: 0.00034745
Epoch [199/300], Train Loss: 0.000342
Validation Loss: 0.00034007
Epoch [200/300], Train Loss: 0.000341
Validation Loss: 0.00034121
Epoch [201/300], Train Loss: 0.000340
Validation Loss: 0.00034338
Epoch [202/300], Train Loss: 0.000337
Validation Loss: 0.00034154
Epoch [203/300], Train Loss: 0.000338
Validation Loss: 0.00034226
Epoch [204/300], Train Loss: 0.000338
Validation Loss: 0.00033751
Epoch [205/300], Train Loss: 0.000337
Validation Loss: 0.00033971
Epoch [206/300], Train Loss: 0.000335
Validation Loss: 0.00033790
Epoch [207/300], Train Loss: 0.000333
Validation Loss: 0.00033457
Epoch [208/300], Train Loss: 0.000332
Validation Loss: 0.00033673
Epoch [209/300], Train Loss: 0.000330
Validation Loss: 0.00033372
Epoch [210/300], Train Loss: 0.000333
Validation Loss: 0.00034268
Epoch [211/300], Train Loss: 0.000332
Validation Loss: 0.00032934
Epoch [212/300], Train Loss: 0.000330
Validation Loss: 0.00033191
Epoch [213/300], Train Loss: 0.000330
Validation Loss: 0.00032887
Epoch [214/300], Train Loss: 0.000327
Validation Loss: 0.00032689
Epoch [215/300], Train Loss: 0.000325
Validation Loss: 0.00032698
Epoch [216/300], Train Loss: 0.000325
Validation Loss: 0.00032948
Epoch [217/300], Train Loss: 0.000320
Validation Loss: 0.00032781
Epoch [218/300], Train Loss: 0.000322
Validation Loss: 0.00032803
Epoch [219/300], Train Loss: 0.000320
Validation Loss: 0.00032878
Epoch [220/300], Train Loss: 0.000325
Validation Loss: 0.00032616
Epoch [221/300], Train Loss: 0.000319
Validation Loss: 0.00032509
Epoch [222/300], Train Loss: 0.000323
Validation Loss: 0.00032055
Epoch [223/300], Train Loss: 0.000318
Validation Loss: 0.00032766
Epoch [224/300], Train Loss: 0.000320
Validation Loss: 0.00031737
Epoch [225/300], Train Loss: 0.000317
Validation Loss: 0.00031774
Epoch [226/300], Train Loss: 0.000313
Validation Loss: 0.00032030
Epoch [227/300], Train Loss: 0.000313
Validation Loss: 0.00031505
Epoch [228/300], Train Loss: 0.000314
Validation Loss: 0.00031469
Epoch [229/300], Train Loss: 0.000313
Validation Loss: 0.00031518
Epoch [230/300], Train Loss: 0.000311
Validation Loss: 0.00031696
Epoch [231/300], Train Loss: 0.000313
Validation Loss: 0.00031576
Epoch [232/300], Train Loss: 0.000310
Validation Loss: 0.00031343
Epoch [233/300], Train Loss: 0.000310
Validation Loss: 0.00031473
Epoch [234/300], Train Loss: 0.000307
Validation Loss: 0.00031613
Epoch [235/300], Train Loss: 0.000332
Validation Loss: 0.00032064
Epoch [236/300], Train Loss: 0.000315
Validation Loss: 0.00031595
Epoch [237/300], Train Loss: 0.000355
Validation Loss: 0.00037041
Epoch [238/300], Train Loss: 0.000338
Validation Loss: 0.00032035
Epoch [239/300], Train Loss: 0.000316
Validation Loss: 0.00031518
Epoch [240/300], Train Loss: 0.000314
Validation Loss: 0.00030891
Epoch [241/300], Train Loss: 0.000308
Validation Loss: 0.00030587
Epoch [242/300], Train Loss: 0.000308
Validation Loss: 0.00030477
Epoch [243/300], Train Loss: 0.000303
Validation Loss: 0.00030840
Epoch [244/300], Train Loss: 0.000304
Validation Loss: 0.00030675
Epoch [245/300], Train Loss: 0.000303
Validation Loss: 0.00030463
Epoch [246/300], Train Loss: 0.000304
Validation Loss: 0.00030727
Epoch [247/300], Train Loss: 0.000328
Validation Loss: 0.00032361
Epoch [248/300], Train Loss: 0.000316
Validation Loss: 0.00031499
Epoch [249/300], Train Loss: 0.000307
Validation Loss: 0.00031119
Epoch [250/300], Train Loss: 0.000304
Validation Loss: 0.00030771
Epoch [251/300], Train Loss: 0.000301
Validation Loss: 0.00030793
Epoch [252/300], Train Loss: 0.000306
Validation Loss: 0.00031130
Epoch [253/300], Train Loss: 0.000301
Validation Loss: 0.00030831
Epoch [254/300], Train Loss: 0.000298
Validation Loss: 0.00030385
Epoch [255/300], Train Loss: 0.000298
Validation Loss: 0.00030265
Epoch [256/300], Train Loss: 0.000297
Validation Loss: 0.00030653
Epoch [257/300], Train Loss: 0.000297
Validation Loss: 0.00030398
Epoch [258/300], Train Loss: 0.000295
Validation Loss: 0.00030454
Epoch [259/300], Train Loss: 0.000293
Validation Loss: 0.00030100
Epoch [260/300], Train Loss: 0.000292
Validation Loss: 0.00030058
Epoch [261/300], Train Loss: 0.000292
Validation Loss: 0.00030097
Epoch [262/300], Train Loss: 0.000297
Validation Loss: 0.00030052
Epoch [263/300], Train Loss: 0.000294
Validation Loss: 0.00029603
Epoch [264/300], Train Loss: 0.000293
Validation Loss: 0.00029548
Epoch [265/300], Train Loss: 0.000292
Validation Loss: 0.00029709
Epoch [266/300], Train Loss: 0.000292
Validation Loss: 0.00029365
Epoch [267/300], Train Loss: 0.000288
Validation Loss: 0.00029569
Epoch [268/300], Train Loss: 0.000287
Validation Loss: 0.00029829
Epoch [269/300], Train Loss: 0.000297
Validation Loss: 0.00031006
Epoch [270/300], Train Loss: 0.000299
Validation Loss: 0.00029629
Epoch [271/300], Train Loss: 0.000288
Validation Loss: 0.00029437
Epoch [272/300], Train Loss: 0.000287
Validation Loss: 0.00029451
Epoch [273/300], Train Loss: 0.000289
Validation Loss: 0.00030597
Epoch [274/300], Train Loss: 0.000290
Validation Loss: 0.00029741
Epoch [275/300], Train Loss: 0.000290
Validation Loss: 0.00029297
Epoch [276/300], Train Loss: 0.000289
Validation Loss: 0.00030059
Epoch [277/300], Train Loss: 0.000290
Validation Loss: 0.00029226
Epoch [278/300], Train Loss: 0.000285
Validation Loss: 0.00028952
Epoch [279/300], Train Loss: 0.000284
Validation Loss: 0.00028692
Epoch [280/300], Train Loss: 0.000286
Validation Loss: 0.00029430
Epoch [281/300], Train Loss: 0.000285
Validation Loss: 0.00028717
Epoch [282/300], Train Loss: 0.000283
Validation Loss: 0.00028829
Epoch [283/300], Train Loss: 0.000283
Validation Loss: 0.00028571
Epoch [284/300], Train Loss: 0.000291
Validation Loss: 0.00029631
Epoch [285/300], Train Loss: 0.000289
Validation Loss: 0.00033308
Epoch [286/300], Train Loss: 0.000302
Validation Loss: 0.00029096
Epoch [287/300], Train Loss: 0.000285
Validation Loss: 0.00028273
Epoch [288/300], Train Loss: 0.000279
Validation Loss: 0.00028608
Epoch [289/300], Train Loss: 0.000280
Validation Loss: 0.00028562
Epoch [290/300], Train Loss: 0.000280
Validation Loss: 0.00028350
Epoch [291/300], Train Loss: 0.000290
Validation Loss: 0.00029174
Epoch [292/300], Train Loss: 0.000290
Validation Loss: 0.00029226
Epoch [293/300], Train Loss: 0.000285
Validation Loss: 0.00029291
Epoch [294/300], Train Loss: 0.000284
Validation Loss: 0.00029014
Epoch [295/300], Train Loss: 0.000284
Validation Loss: 0.00028842
Epoch [296/300], Train Loss: 0.000290
Validation Loss: 0.00029166
Epoch [297/300], Train Loss: 0.000281
Validation Loss: 0.00028894
Early stopping triggered

Evaluating model for: Coffee Machine
Run 18/72 completed in 2852.77 seconds with: {'MAE': np.float32(4.393672), 'MSE': np.float32(1304.8372), 'RMSE': np.float32(36.122528), 'SAE': np.float32(0.03168399), 'NDE': np.float32(0.5564241)}

Run 19/72: hidden=128, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Coffee Machine
Dataset length: 5916 windows

Epoch [1/300], Train Loss: 0.001050
Validation Loss: 0.00101108
Epoch [2/300], Train Loss: 0.000998
Validation Loss: 0.00100750
Epoch [3/300], Train Loss: 0.000995
Validation Loss: 0.00100740
Epoch [4/300], Train Loss: 0.000994
Validation Loss: 0.00100739
Epoch [5/300], Train Loss: 0.000993
Validation Loss: 0.00100719
Epoch [6/300], Train Loss: 0.000991
Validation Loss: 0.00100713
Epoch [7/300], Train Loss: 0.000990
Validation Loss: 0.00100687
Epoch [8/300], Train Loss: 0.000990
Validation Loss: 0.00100689
Epoch [9/300], Train Loss: 0.000988
Validation Loss: 0.00100679
Epoch [10/300], Train Loss: 0.000988
Validation Loss: 0.00100653
Epoch [11/300], Train Loss: 0.000987
Validation Loss: 0.00100611
Epoch [12/300], Train Loss: 0.000987
Validation Loss: 0.00100574
Epoch [13/300], Train Loss: 0.000986
Validation Loss: 0.00100539
Epoch [14/300], Train Loss: 0.000985
Validation Loss: 0.00100497
Epoch [15/300], Train Loss: 0.000985
Validation Loss: 0.00100454
Epoch [16/300], Train Loss: 0.000985
Validation Loss: 0.00100384
Epoch [17/300], Train Loss: 0.000983
Validation Loss: 0.00100332
Epoch [18/300], Train Loss: 0.000982
Validation Loss: 0.00100143
Epoch [19/300], Train Loss: 0.000981
Validation Loss: 0.00099937
Epoch [20/300], Train Loss: 0.000979
Validation Loss: 0.00099845
Epoch [21/300], Train Loss: 0.000977
Validation Loss: 0.00099582
Epoch [22/300], Train Loss: 0.000976
Validation Loss: 0.00099359
Epoch [23/300], Train Loss: 0.000973
Validation Loss: 0.00099112
Epoch [24/300], Train Loss: 0.000971
Validation Loss: 0.00098790
Epoch [25/300], Train Loss: 0.000967
Validation Loss: 0.00098238
Epoch [26/300], Train Loss: 0.000961
Validation Loss: 0.00097543
Epoch [27/300], Train Loss: 0.000953
Validation Loss: 0.00096659
Epoch [28/300], Train Loss: 0.000945
Validation Loss: 0.00095770
Epoch [29/300], Train Loss: 0.000937
Validation Loss: 0.00094976
Epoch [30/300], Train Loss: 0.000929
Validation Loss: 0.00094004
Epoch [31/300], Train Loss: 0.000919
Validation Loss: 0.00092703
Epoch [32/300], Train Loss: 0.000904
Validation Loss: 0.00090906
Epoch [33/300], Train Loss: 0.000881
Validation Loss: 0.00088028
Epoch [34/300], Train Loss: 0.000853
Validation Loss: 0.00085188
Epoch [35/300], Train Loss: 0.000822
Validation Loss: 0.00082298
Epoch [36/300], Train Loss: 0.000792
Validation Loss: 0.00078559
Epoch [37/300], Train Loss: 0.000765
Validation Loss: 0.00075823
Epoch [38/300], Train Loss: 0.000741
Validation Loss: 0.00073043
Epoch [39/300], Train Loss: 0.000726
Validation Loss: 0.00072784
Epoch [40/300], Train Loss: 0.000707
Validation Loss: 0.00073469
Epoch [41/300], Train Loss: 0.000720
Validation Loss: 0.00074199
Epoch [42/300], Train Loss: 0.000700
Validation Loss: 0.00070678
Epoch [43/300], Train Loss: 0.000677
Validation Loss: 0.00066881
Epoch [44/300], Train Loss: 0.000664
Validation Loss: 0.00066497
Epoch [45/300], Train Loss: 0.000656
Validation Loss: 0.00068635
Epoch [46/300], Train Loss: 0.000658
Validation Loss: 0.00067192
Epoch [47/300], Train Loss: 0.000653
Validation Loss: 0.00068927
Epoch [48/300], Train Loss: 0.000653
Validation Loss: 0.00066007
Epoch [49/300], Train Loss: 0.000635
Validation Loss: 0.00063442
Epoch [50/300], Train Loss: 0.000629
Validation Loss: 0.00062090
Epoch [51/300], Train Loss: 0.000635
Validation Loss: 0.00064371
Epoch [52/300], Train Loss: 0.000633
Validation Loss: 0.00062639
Epoch [53/300], Train Loss: 0.000619
Validation Loss: 0.00061786
Epoch [54/300], Train Loss: 0.000610
Validation Loss: 0.00061823
Epoch [55/300], Train Loss: 0.000612
Validation Loss: 0.00061224
Epoch [56/300], Train Loss: 0.000602
Validation Loss: 0.00060945
Epoch [57/300], Train Loss: 0.000602
Validation Loss: 0.00060548
Epoch [58/300], Train Loss: 0.000594
Validation Loss: 0.00060371
Epoch [59/300], Train Loss: 0.000589
Validation Loss: 0.00060269
Epoch [60/300], Train Loss: 0.000599
Validation Loss: 0.00061317
Epoch [61/300], Train Loss: 0.000590
Validation Loss: 0.00059732
Epoch [62/300], Train Loss: 0.000582
Validation Loss: 0.00059230
Epoch [63/300], Train Loss: 0.000578
Validation Loss: 0.00059771
Epoch [64/300], Train Loss: 0.000584
Validation Loss: 0.00059638
Epoch [65/300], Train Loss: 0.000574
Validation Loss: 0.00059300
Epoch [66/300], Train Loss: 0.000571
Validation Loss: 0.00058509
Epoch [67/300], Train Loss: 0.000564
Validation Loss: 0.00057722
Epoch [68/300], Train Loss: 0.000557
Validation Loss: 0.00058039
Epoch [69/300], Train Loss: 0.000558
Validation Loss: 0.00057158
Epoch [70/300], Train Loss: 0.000563
Validation Loss: 0.00060344
Epoch [71/300], Train Loss: 0.000564
Validation Loss: 0.00057886
Epoch [72/300], Train Loss: 0.000553
Validation Loss: 0.00056975
Epoch [73/300], Train Loss: 0.000544
Validation Loss: 0.00057718
Epoch [74/300], Train Loss: 0.000549
Validation Loss: 0.00056642
Epoch [75/300], Train Loss: 0.000540
Validation Loss: 0.00055692
Epoch [76/300], Train Loss: 0.000541
Validation Loss: 0.00055000
Epoch [77/300], Train Loss: 0.000542
Validation Loss: 0.00056255
Epoch [78/300], Train Loss: 0.000544
Validation Loss: 0.00055368
Epoch [79/300], Train Loss: 0.000531
Validation Loss: 0.00054790
Epoch [80/300], Train Loss: 0.000534
Validation Loss: 0.00053929
Epoch [81/300], Train Loss: 0.000522
Validation Loss: 0.00053638
Epoch [82/300], Train Loss: 0.000580
Validation Loss: 0.00059617
Epoch [83/300], Train Loss: 0.000549
Validation Loss: 0.00055195
Epoch [84/300], Train Loss: 0.000530
Validation Loss: 0.00054123
Epoch [85/300], Train Loss: 0.000532
Validation Loss: 0.00053044
Epoch [86/300], Train Loss: 0.000521
Validation Loss: 0.00052815
Epoch [87/300], Train Loss: 0.000510
Validation Loss: 0.00053082
Epoch [88/300], Train Loss: 0.000507
Validation Loss: 0.00055632
Epoch [89/300], Train Loss: 0.000510
Validation Loss: 0.00051668
Epoch [90/300], Train Loss: 0.000503
Validation Loss: 0.00051742
Epoch [91/300], Train Loss: 0.000494
Validation Loss: 0.00048914
Epoch [92/300], Train Loss: 0.000485
Validation Loss: 0.00048156
Epoch [93/300], Train Loss: 0.000481
Validation Loss: 0.00047281
Epoch [94/300], Train Loss: 0.000486
Validation Loss: 0.00048731
Epoch [95/300], Train Loss: 0.000482
Validation Loss: 0.00049166
Epoch [96/300], Train Loss: 0.000475
Validation Loss: 0.00047836
Epoch [97/300], Train Loss: 0.000465
Validation Loss: 0.00045696
Epoch [98/300], Train Loss: 0.000470
Validation Loss: 0.00045394
Epoch [99/300], Train Loss: 0.000469
Validation Loss: 0.00045395
Epoch [100/300], Train Loss: 0.000460
Validation Loss: 0.00044363
Epoch [101/300], Train Loss: 0.000453
Validation Loss: 0.00043947
Epoch [102/300], Train Loss: 0.000450
Validation Loss: 0.00043093
Epoch [103/300], Train Loss: 0.000449
Validation Loss: 0.00044493
Epoch [104/300], Train Loss: 0.000449
Validation Loss: 0.00042219
Epoch [105/300], Train Loss: 0.000439
Validation Loss: 0.00041954
Epoch [106/300], Train Loss: 0.000437
Validation Loss: 0.00042387
Epoch [107/300], Train Loss: 0.000431
Validation Loss: 0.00042194
Epoch [108/300], Train Loss: 0.000553
Validation Loss: 0.00051399
Epoch [109/300], Train Loss: 0.000472
Validation Loss: 0.00046086
Epoch [110/300], Train Loss: 0.000446
Validation Loss: 0.00042326
Epoch [111/300], Train Loss: 0.000427
Validation Loss: 0.00040981
Epoch [112/300], Train Loss: 0.000418
Validation Loss: 0.00039911
Epoch [113/300], Train Loss: 0.000411
Validation Loss: 0.00038606
Epoch [114/300], Train Loss: 0.000400
Validation Loss: 0.00037976
Epoch [115/300], Train Loss: 0.000396
Validation Loss: 0.00037778
Epoch [116/300], Train Loss: 0.000389
Validation Loss: 0.00037131
Epoch [117/300], Train Loss: 0.000379
Validation Loss: 0.00036009
Epoch [118/300], Train Loss: 0.000371
Validation Loss: 0.00035335
Epoch [119/300], Train Loss: 0.000364
Validation Loss: 0.00034871
Epoch [120/300], Train Loss: 0.000357
Validation Loss: 0.00034686
Epoch [121/300], Train Loss: 0.000351
Validation Loss: 0.00033584
Epoch [122/300], Train Loss: 0.000344
Validation Loss: 0.00033608
Epoch [123/300], Train Loss: 0.000340
Validation Loss: 0.00033263
Epoch [124/300], Train Loss: 0.000343
Validation Loss: 0.00034258
Epoch [125/300], Train Loss: 0.000347
Validation Loss: 0.00032418
Epoch [126/300], Train Loss: 0.000333
Validation Loss: 0.00031860
Epoch [127/300], Train Loss: 0.000327
Validation Loss: 0.00031663
Epoch [128/300], Train Loss: 0.000322
Validation Loss: 0.00031409
Epoch [129/300], Train Loss: 0.000322
Validation Loss: 0.00032357
Epoch [130/300], Train Loss: 0.000335
Validation Loss: 0.00031587
Epoch [131/300], Train Loss: 0.000317
Validation Loss: 0.00030421
Epoch [132/300], Train Loss: 0.000310
Validation Loss: 0.00030649
Epoch [133/300], Train Loss: 0.000308
Validation Loss: 0.00029717
Epoch [134/300], Train Loss: 0.000307
Validation Loss: 0.00029768
Epoch [135/300], Train Loss: 0.000303
Validation Loss: 0.00030059
Epoch [136/300], Train Loss: 0.000298
Validation Loss: 0.00029235
Epoch [137/300], Train Loss: 0.000312
Validation Loss: 0.00029944
Epoch [138/300], Train Loss: 0.000309
Validation Loss: 0.00029519
Epoch [139/300], Train Loss: 0.000295
Validation Loss: 0.00028956
Epoch [140/300], Train Loss: 0.000319
Validation Loss: 0.00031310
Epoch [141/300], Train Loss: 0.000314
Validation Loss: 0.00030192
Epoch [142/300], Train Loss: 0.000310
Validation Loss: 0.00029781
Epoch [143/300], Train Loss: 0.000305
Validation Loss: 0.00029260
Epoch [144/300], Train Loss: 0.000317
Validation Loss: 0.00029973
Epoch [145/300], Train Loss: 0.000305
Validation Loss: 0.00028900
Epoch [146/300], Train Loss: 0.000297
Validation Loss: 0.00028917
Epoch [147/300], Train Loss: 0.000297
Validation Loss: 0.00028694
Epoch [148/300], Train Loss: 0.000294
Validation Loss: 0.00028272
Epoch [149/300], Train Loss: 0.000293
Validation Loss: 0.00028159
Epoch [150/300], Train Loss: 0.000289
Validation Loss: 0.00028501
Epoch [151/300], Train Loss: 0.000309
Validation Loss: 0.00029717
Epoch [152/300], Train Loss: 0.000305
Validation Loss: 0.00028527
Epoch [153/300], Train Loss: 0.000298
Validation Loss: 0.00028312
Epoch [154/300], Train Loss: 0.000296
Validation Loss: 0.00028179
Epoch [155/300], Train Loss: 0.000292
Validation Loss: 0.00027896
Epoch [156/300], Train Loss: 0.000291
Validation Loss: 0.00027764
Epoch [157/300], Train Loss: 0.000289
Validation Loss: 0.00027519
Epoch [158/300], Train Loss: 0.000290
Validation Loss: 0.00027507
Epoch [159/300], Train Loss: 0.000285
Validation Loss: 0.00027318
Epoch [160/300], Train Loss: 0.000288
Validation Loss: 0.00027741
Epoch [161/300], Train Loss: 0.000282
Validation Loss: 0.00027398
Epoch [162/300], Train Loss: 0.000279
Validation Loss: 0.00027258
Epoch [163/300], Train Loss: 0.000283
Validation Loss: 0.00027225
Epoch [164/300], Train Loss: 0.000280
Validation Loss: 0.00027318
Epoch [165/300], Train Loss: 0.000280
Validation Loss: 0.00027837
Epoch [166/300], Train Loss: 0.000277
Validation Loss: 0.00027211
Epoch [167/300], Train Loss: 0.000279
Validation Loss: 0.00026986
Epoch [168/300], Train Loss: 0.000275
Validation Loss: 0.00026750
Epoch [169/300], Train Loss: 0.000272
Validation Loss: 0.00026708
Epoch [170/300], Train Loss: 0.000268
Validation Loss: 0.00026578
Epoch [171/300], Train Loss: 0.000273
Validation Loss: 0.00026103
Epoch [172/300], Train Loss: 0.000269
Validation Loss: 0.00026575
Epoch [173/300], Train Loss: 0.000268
Validation Loss: 0.00026601
Epoch [174/300], Train Loss: 0.000275
Validation Loss: 0.00027154
Epoch [175/300], Train Loss: 0.000269
Validation Loss: 0.00027028
Epoch [176/300], Train Loss: 0.000269
Validation Loss: 0.00027134
Epoch [177/300], Train Loss: 0.000268
Validation Loss: 0.00026282
Epoch [178/300], Train Loss: 0.000261
Validation Loss: 0.00026275
Epoch [179/300], Train Loss: 0.000264
Validation Loss: 0.00026200
Epoch [180/300], Train Loss: 0.000261
Validation Loss: 0.00026525
Epoch [181/300], Train Loss: 0.000262
Validation Loss: 0.00026602
Early stopping triggered

Evaluating model for: Coffee Machine
Run 19/72 completed in 1844.33 seconds with: {'MAE': np.float32(4.044268), 'MSE': np.float32(1226.4727), 'RMSE': np.float32(35.02103), 'SAE': np.float32(0.017464096), 'NDE': np.float32(0.5394562)}

Run 20/72: hidden=128, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Coffee Machine
Dataset length: 5916 windows

Epoch [1/300], Train Loss: 0.001022
Validation Loss: 0.00100802
Epoch [2/300], Train Loss: 0.000992
Validation Loss: 0.00100604
Epoch [3/300], Train Loss: 0.000989
Validation Loss: 0.00100609
Epoch [4/300], Train Loss: 0.000988
Validation Loss: 0.00100607
Epoch [5/300], Train Loss: 0.000987
Validation Loss: 0.00100600
Epoch [6/300], Train Loss: 0.000985
Validation Loss: 0.00100605
Epoch [7/300], Train Loss: 0.000984
Validation Loss: 0.00100597
Epoch [8/300], Train Loss: 0.000984
Validation Loss: 0.00100619
Epoch [9/300], Train Loss: 0.000983
Validation Loss: 0.00100599
Epoch [10/300], Train Loss: 0.000983
Validation Loss: 0.00100591
Epoch [11/300], Train Loss: 0.000983
Validation Loss: 0.00100597
Epoch [12/300], Train Loss: 0.000983
Validation Loss: 0.00100608
Epoch [13/300], Train Loss: 0.000983
Validation Loss: 0.00100592
Epoch [14/300], Train Loss: 0.000982
Validation Loss: 0.00100596
Epoch [15/300], Train Loss: 0.000982
Validation Loss: 0.00100589
Epoch [16/300], Train Loss: 0.000983
Validation Loss: 0.00100583
Epoch [17/300], Train Loss: 0.000982
Validation Loss: 0.00100581
Epoch [18/300], Train Loss: 0.000982
Validation Loss: 0.00100573
Epoch [19/300], Train Loss: 0.000982
Validation Loss: 0.00100559
Epoch [20/300], Train Loss: 0.000982
Validation Loss: 0.00100531
Epoch [21/300], Train Loss: 0.000982
Validation Loss: 0.00100499
Epoch [22/300], Train Loss: 0.000982
Validation Loss: 0.00100478
Epoch [23/300], Train Loss: 0.000981
Validation Loss: 0.00100369
Epoch [24/300], Train Loss: 0.000980
Validation Loss: 0.00100276
Epoch [25/300], Train Loss: 0.000979
Validation Loss: 0.00100183
Epoch [26/300], Train Loss: 0.000978
Validation Loss: 0.00100134
Epoch [27/300], Train Loss: 0.000978
Validation Loss: 0.00099977
Epoch [28/300], Train Loss: 0.000976
Validation Loss: 0.00099822
Epoch [29/300], Train Loss: 0.000975
Validation Loss: 0.00099618
Epoch [30/300], Train Loss: 0.000973
Validation Loss: 0.00099410
Epoch [31/300], Train Loss: 0.000970
Validation Loss: 0.00098910
Epoch [32/300], Train Loss: 0.000964
Validation Loss: 0.00098205
Epoch [33/300], Train Loss: 0.000953
Validation Loss: 0.00096627
Epoch [34/300], Train Loss: 0.000932
Validation Loss: 0.00093826
Epoch [35/300], Train Loss: 0.000893
Validation Loss: 0.00090154
Epoch [36/300], Train Loss: 0.000842
Validation Loss: 0.00084290
Epoch [37/300], Train Loss: 0.000793
Validation Loss: 0.00080102
Epoch [38/300], Train Loss: 0.000751
Validation Loss: 0.00075881
Epoch [39/300], Train Loss: 0.000726
Validation Loss: 0.00073864
Epoch [40/300], Train Loss: 0.000717
Validation Loss: 0.00072904
Epoch [41/300], Train Loss: 0.000693
Validation Loss: 0.00072180
Epoch [42/300], Train Loss: 0.000684
Validation Loss: 0.00068929
Epoch [43/300], Train Loss: 0.000670
Validation Loss: 0.00070899
Epoch [44/300], Train Loss: 0.000671
Validation Loss: 0.00067342
Epoch [45/300], Train Loss: 0.000647
Validation Loss: 0.00065736
Epoch [46/300], Train Loss: 0.000633
Validation Loss: 0.00064434
Epoch [47/300], Train Loss: 0.000629
Validation Loss: 0.00068836
Epoch [48/300], Train Loss: 0.000635
Validation Loss: 0.00063364
Epoch [49/300], Train Loss: 0.000606
Validation Loss: 0.00062257
Epoch [50/300], Train Loss: 0.000598
Validation Loss: 0.00061426
Epoch [51/300], Train Loss: 0.000596
Validation Loss: 0.00060599
Epoch [52/300], Train Loss: 0.000583
Validation Loss: 0.00061567
Epoch [53/300], Train Loss: 0.000577
Validation Loss: 0.00060063
Epoch [54/300], Train Loss: 0.000572
Validation Loss: 0.00059084
Epoch [55/300], Train Loss: 0.000560
Validation Loss: 0.00057182
Epoch [56/300], Train Loss: 0.000555
Validation Loss: 0.00056602
Epoch [57/300], Train Loss: 0.000558
Validation Loss: 0.00056383
Epoch [58/300], Train Loss: 0.000552
Validation Loss: 0.00055269
Epoch [59/300], Train Loss: 0.000539
Validation Loss: 0.00055080
Epoch [60/300], Train Loss: 0.000533
Validation Loss: 0.00053322
Epoch [61/300], Train Loss: 0.000525
Validation Loss: 0.00051569
Epoch [62/300], Train Loss: 0.000514
Validation Loss: 0.00051727
Epoch [63/300], Train Loss: 0.000502
Validation Loss: 0.00050348
Epoch [64/300], Train Loss: 0.000492
Validation Loss: 0.00049019
Epoch [65/300], Train Loss: 0.000490
Validation Loss: 0.00048741
Epoch [66/300], Train Loss: 0.000488
Validation Loss: 0.00048035
Epoch [67/300], Train Loss: 0.000472
Validation Loss: 0.00045753
Epoch [68/300], Train Loss: 0.000461
Validation Loss: 0.00044175
Epoch [69/300], Train Loss: 0.000456
Validation Loss: 0.00044590
Epoch [70/300], Train Loss: 0.000454
Validation Loss: 0.00042850
Epoch [71/300], Train Loss: 0.000430
Validation Loss: 0.00042044
Epoch [72/300], Train Loss: 0.000420
Validation Loss: 0.00040765
Epoch [73/300], Train Loss: 0.000415
Validation Loss: 0.00040906
Epoch [74/300], Train Loss: 0.000407
Validation Loss: 0.00043833
Epoch [75/300], Train Loss: 0.000402
Validation Loss: 0.00038541
Epoch [76/300], Train Loss: 0.000384
Validation Loss: 0.00036980
Epoch [77/300], Train Loss: 0.000377
Validation Loss: 0.00036557
Epoch [78/300], Train Loss: 0.000378
Validation Loss: 0.00036868
Epoch [79/300], Train Loss: 0.000364
Validation Loss: 0.00036202
Epoch [80/300], Train Loss: 0.000365
Validation Loss: 0.00035559
Epoch [81/300], Train Loss: 0.000356
Validation Loss: 0.00035184
Epoch [82/300], Train Loss: 0.000346
Validation Loss: 0.00034266
Epoch [83/300], Train Loss: 0.000339
Validation Loss: 0.00033917
Epoch [84/300], Train Loss: 0.000335
Validation Loss: 0.00034481
Epoch [85/300], Train Loss: 0.000338
Validation Loss: 0.00033925
Epoch [86/300], Train Loss: 0.000347
Validation Loss: 0.00033963
Epoch [87/300], Train Loss: 0.000333
Validation Loss: 0.00033049
Epoch [88/300], Train Loss: 0.000325
Validation Loss: 0.00032822
Epoch [89/300], Train Loss: 0.000323
Validation Loss: 0.00032232
Epoch [90/300], Train Loss: 0.000320
Validation Loss: 0.00032455
Epoch [91/300], Train Loss: 0.000321
Validation Loss: 0.00033759
Epoch [92/300], Train Loss: 0.000327
Validation Loss: 0.00032080
Epoch [93/300], Train Loss: 0.000316
Validation Loss: 0.00032345
Epoch [94/300], Train Loss: 0.000310
Validation Loss: 0.00031526
Epoch [95/300], Train Loss: 0.000308
Validation Loss: 0.00031882
Epoch [96/300], Train Loss: 0.000303
Validation Loss: 0.00031488
Epoch [97/300], Train Loss: 0.000334
Validation Loss: 0.00031896
Epoch [98/300], Train Loss: 0.000317
Validation Loss: 0.00031653
Epoch [99/300], Train Loss: 0.000309
Validation Loss: 0.00032631
Epoch [100/300], Train Loss: 0.000309
Validation Loss: 0.00030628
Epoch [101/300], Train Loss: 0.000300
Validation Loss: 0.00030535
Epoch [102/300], Train Loss: 0.000296
Validation Loss: 0.00030047
Epoch [103/300], Train Loss: 0.000298
Validation Loss: 0.00030106
Epoch [104/300], Train Loss: 0.000294
Validation Loss: 0.00029766
Epoch [105/300], Train Loss: 0.000295
Validation Loss: 0.00031649
Epoch [106/300], Train Loss: 0.000304
Validation Loss: 0.00030538
Epoch [107/300], Train Loss: 0.000293
Validation Loss: 0.00029177
Epoch [108/300], Train Loss: 0.000286
Validation Loss: 0.00029646
Epoch [109/300], Train Loss: 0.000280
Validation Loss: 0.00030102
Epoch [110/300], Train Loss: 0.000282
Validation Loss: 0.00029582
Epoch [111/300], Train Loss: 0.000279
Validation Loss: 0.00028820
Epoch [112/300], Train Loss: 0.000292
Validation Loss: 0.00029762
Epoch [113/300], Train Loss: 0.000286
Validation Loss: 0.00028719
Epoch [114/300], Train Loss: 0.000279
Validation Loss: 0.00028327
Epoch [115/300], Train Loss: 0.000294
Validation Loss: 0.00032763
Epoch [116/300], Train Loss: 0.000319
Validation Loss: 0.00030160
Epoch [117/300], Train Loss: 0.000294
Validation Loss: 0.00030744
Epoch [118/300], Train Loss: 0.000292
Validation Loss: 0.00029248
Epoch [119/300], Train Loss: 0.000295
Validation Loss: 0.00029712
Epoch [120/300], Train Loss: 0.000287
Validation Loss: 0.00029487
Epoch [121/300], Train Loss: 0.000279
Validation Loss: 0.00028203
Epoch [122/300], Train Loss: 0.000278
Validation Loss: 0.00028373
Epoch [123/300], Train Loss: 0.000275
Validation Loss: 0.00028261
Epoch [124/300], Train Loss: 0.000274
Validation Loss: 0.00028245
Epoch [125/300], Train Loss: 0.000271
Validation Loss: 0.00027592
Epoch [126/300], Train Loss: 0.000268
Validation Loss: 0.00027548
Epoch [127/300], Train Loss: 0.000267
Validation Loss: 0.00027142
Epoch [128/300], Train Loss: 0.000264
Validation Loss: 0.00027471
Epoch [129/300], Train Loss: 0.000267
Validation Loss: 0.00027031
Epoch [130/300], Train Loss: 0.000263
Validation Loss: 0.00027248
Epoch [131/300], Train Loss: 0.000264
Validation Loss: 0.00027200
Epoch [132/300], Train Loss: 0.000258
Validation Loss: 0.00026679
Epoch [133/300], Train Loss: 0.000257
Validation Loss: 0.00026860
Epoch [134/300], Train Loss: 0.000256
Validation Loss: 0.00027798
Epoch [135/300], Train Loss: 0.000255
Validation Loss: 0.00026408
Epoch [136/300], Train Loss: 0.000254
Validation Loss: 0.00026171
Epoch [137/300], Train Loss: 0.000251
Validation Loss: 0.00027313
Epoch [138/300], Train Loss: 0.000253
Validation Loss: 0.00026142
Epoch [139/300], Train Loss: 0.000251
Validation Loss: 0.00026211
Epoch [140/300], Train Loss: 0.000253
Validation Loss: 0.00028603
Epoch [141/300], Train Loss: 0.000268
Validation Loss: 0.00026882
Epoch [142/300], Train Loss: 0.000255
Validation Loss: 0.00026098
Epoch [143/300], Train Loss: 0.000253
Validation Loss: 0.00025752
Epoch [144/300], Train Loss: 0.000250
Validation Loss: 0.00025946
Epoch [145/300], Train Loss: 0.000254
Validation Loss: 0.00025874
Epoch [146/300], Train Loss: 0.000247
Validation Loss: 0.00026143
Epoch [147/300], Train Loss: 0.000248
Validation Loss: 0.00025265
Epoch [148/300], Train Loss: 0.000244
Validation Loss: 0.00025456
Epoch [149/300], Train Loss: 0.000240
Validation Loss: 0.00025411
Epoch [150/300], Train Loss: 0.000243
Validation Loss: 0.00025776
Epoch [151/300], Train Loss: 0.000247
Validation Loss: 0.00027605
Epoch [152/300], Train Loss: 0.000250
Validation Loss: 0.00025597
Epoch [153/300], Train Loss: 0.000242
Validation Loss: 0.00025349
Epoch [154/300], Train Loss: 0.000240
Validation Loss: 0.00025109
Epoch [155/300], Train Loss: 0.000251
Validation Loss: 0.00026745
Epoch [156/300], Train Loss: 0.000246
Validation Loss: 0.00025260
Epoch [157/300], Train Loss: 0.000243
Validation Loss: 0.00025129
Epoch [158/300], Train Loss: 0.000236
Validation Loss: 0.00024838
Epoch [159/300], Train Loss: 0.000234
Validation Loss: 0.00025434
Epoch [160/300], Train Loss: 0.000235
Validation Loss: 0.00025233
Epoch [161/300], Train Loss: 0.000233
Validation Loss: 0.00025364
Epoch [162/300], Train Loss: 0.000237
Validation Loss: 0.00024542
Epoch [163/300], Train Loss: 0.000235
Validation Loss: 0.00024476
Epoch [164/300], Train Loss: 0.000238
Validation Loss: 0.00024299
Epoch [165/300], Train Loss: 0.000237
Validation Loss: 0.00025458
Epoch [166/300], Train Loss: 0.000235
Validation Loss: 0.00024707
Epoch [167/300], Train Loss: 0.000229
Validation Loss: 0.00024111
Epoch [168/300], Train Loss: 0.000246
Validation Loss: 0.00025985
Epoch [169/300], Train Loss: 0.000234
Validation Loss: 0.00024602
Epoch [170/300], Train Loss: 0.000230
Validation Loss: 0.00024293
Epoch [171/300], Train Loss: 0.000238
Validation Loss: 0.00024652
Epoch [172/300], Train Loss: 0.000227
Validation Loss: 0.00024022
Epoch [173/300], Train Loss: 0.000228
Validation Loss: 0.00024006
Epoch [174/300], Train Loss: 0.000227
Validation Loss: 0.00024809
Epoch [175/300], Train Loss: 0.000243
Validation Loss: 0.00026219
Epoch [176/300], Train Loss: 0.000246
Validation Loss: 0.00024503
Epoch [177/300], Train Loss: 0.000231
Validation Loss: 0.00025024
Epoch [178/300], Train Loss: 0.000237
Validation Loss: 0.00024456
Epoch [179/300], Train Loss: 0.000231
Validation Loss: 0.00024130
Epoch [180/300], Train Loss: 0.000225
Validation Loss: 0.00024434
Epoch [181/300], Train Loss: 0.000322
Validation Loss: 0.00036460
Epoch [182/300], Train Loss: 0.000341
Validation Loss: 0.00032468
Epoch [183/300], Train Loss: 0.000311
Validation Loss: 0.00030263
Early stopping triggered

Evaluating model for: Coffee Machine
Run 20/72 completed in 1903.91 seconds with: {'MAE': np.float32(3.6345615), 'MSE': np.float32(1341.1644), 'RMSE': np.float32(36.62191), 'SAE': np.float32(0.107276894), 'NDE': np.float32(0.5641131)}

Run 21/72: hidden=128, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Coffee Machine
Dataset length: 2980 windows

Epoch [1/300], Train Loss: 0.001859
Validation Loss: 0.00103576
Epoch [2/300], Train Loss: 0.001018
Validation Loss: 0.00094770
Epoch [3/300], Train Loss: 0.001005
Validation Loss: 0.00092464
Epoch [4/300], Train Loss: 0.000999
Validation Loss: 0.00092140
Epoch [5/300], Train Loss: 0.000999
Validation Loss: 0.00092123
Epoch [6/300], Train Loss: 0.000996
Validation Loss: 0.00092101
Epoch [7/300], Train Loss: 0.000995
Validation Loss: 0.00092061
Epoch [8/300], Train Loss: 0.000999
Validation Loss: 0.00092040
Epoch [9/300], Train Loss: 0.001003
Validation Loss: 0.00092018
Epoch [10/300], Train Loss: 0.001003
Validation Loss: 0.00091984
Epoch [11/300], Train Loss: 0.000985
Validation Loss: 0.00091971
Epoch [12/300], Train Loss: 0.000994
Validation Loss: 0.00091930
Epoch [13/300], Train Loss: 0.000996
Validation Loss: 0.00091899
Epoch [14/300], Train Loss: 0.000997
Validation Loss: 0.00091871
Epoch [15/300], Train Loss: 0.000983
Validation Loss: 0.00091856
Epoch [16/300], Train Loss: 0.000990
Validation Loss: 0.00091812
Epoch [17/300], Train Loss: 0.000996
Validation Loss: 0.00091786
Epoch [18/300], Train Loss: 0.000992
Validation Loss: 0.00091758
Epoch [19/300], Train Loss: 0.000992
Validation Loss: 0.00091728
Epoch [20/300], Train Loss: 0.000981
Validation Loss: 0.00091731
Epoch [21/300], Train Loss: 0.000992
Validation Loss: 0.00091666
Epoch [22/300], Train Loss: 0.000978
Validation Loss: 0.00091633
Epoch [23/300], Train Loss: 0.000991
Validation Loss: 0.00091632
Epoch [24/300], Train Loss: 0.000982
Validation Loss: 0.00091553
Epoch [25/300], Train Loss: 0.000984
Validation Loss: 0.00091510
Epoch [26/300], Train Loss: 0.000987
Validation Loss: 0.00091468
Epoch [27/300], Train Loss: 0.000985
Validation Loss: 0.00091421
Epoch [28/300], Train Loss: 0.000976
Validation Loss: 0.00091361
Epoch [29/300], Train Loss: 0.000983
Validation Loss: 0.00091309
Epoch [30/300], Train Loss: 0.000981
Validation Loss: 0.00091233
Epoch [31/300], Train Loss: 0.000977
Validation Loss: 0.00091169
Epoch [32/300], Train Loss: 0.000980
Validation Loss: 0.00091151
Epoch [33/300], Train Loss: 0.000980
Validation Loss: 0.00091009
Epoch [34/300], Train Loss: 0.000978
Validation Loss: 0.00090916
Epoch [35/300], Train Loss: 0.000972
Validation Loss: 0.00090842
Epoch [36/300], Train Loss: 0.000984
Validation Loss: 0.00090758
Epoch [37/300], Train Loss: 0.000991
Validation Loss: 0.00090674
Epoch [38/300], Train Loss: 0.000977
Validation Loss: 0.00090535
Epoch [39/300], Train Loss: 0.000979
Validation Loss: 0.00090402
Epoch [40/300], Train Loss: 0.000972
Validation Loss: 0.00090359
Epoch [41/300], Train Loss: 0.000977
Validation Loss: 0.00090249
Epoch [42/300], Train Loss: 0.000980
Validation Loss: 0.00090140
Epoch [43/300], Train Loss: 0.000976
Validation Loss: 0.00090028
Epoch [44/300], Train Loss: 0.000965
Validation Loss: 0.00089937
Epoch [45/300], Train Loss: 0.000961
Validation Loss: 0.00089847
Epoch [46/300], Train Loss: 0.000969
Validation Loss: 0.00089773
Epoch [47/300], Train Loss: 0.000970
Validation Loss: 0.00089699
Epoch [48/300], Train Loss: 0.000966
Validation Loss: 0.00089614
Epoch [49/300], Train Loss: 0.000963
Validation Loss: 0.00089574
Epoch [50/300], Train Loss: 0.000965
Validation Loss: 0.00089485
Epoch [51/300], Train Loss: 0.000968
Validation Loss: 0.00089386
Epoch [52/300], Train Loss: 0.000961
Validation Loss: 0.00089283
Epoch [53/300], Train Loss: 0.000961
Validation Loss: 0.00089186
Epoch [54/300], Train Loss: 0.000967
Validation Loss: 0.00089103
Epoch [55/300], Train Loss: 0.000957
Validation Loss: 0.00088970
Epoch [56/300], Train Loss: 0.000965
Validation Loss: 0.00088900
Epoch [57/300], Train Loss: 0.000970
Validation Loss: 0.00088738
Epoch [58/300], Train Loss: 0.000953
Validation Loss: 0.00088606
Epoch [59/300], Train Loss: 0.000955
Validation Loss: 0.00088483
Epoch [60/300], Train Loss: 0.000968
Validation Loss: 0.00088330
Epoch [61/300], Train Loss: 0.000953
Validation Loss: 0.00088127
Epoch [62/300], Train Loss: 0.000950
Validation Loss: 0.00088079
Epoch [63/300], Train Loss: 0.000952
Validation Loss: 0.00087810
Epoch [64/300], Train Loss: 0.000941
Validation Loss: 0.00087622
Epoch [65/300], Train Loss: 0.000953
Validation Loss: 0.00087457
Epoch [66/300], Train Loss: 0.000948
Validation Loss: 0.00087082
Epoch [67/300], Train Loss: 0.000944
Validation Loss: 0.00086791
Epoch [68/300], Train Loss: 0.000945
Validation Loss: 0.00086516
Epoch [69/300], Train Loss: 0.000943
Validation Loss: 0.00086129
Epoch [70/300], Train Loss: 0.000938
Validation Loss: 0.00085814
Epoch [71/300], Train Loss: 0.000926
Validation Loss: 0.00085421
Epoch [72/300], Train Loss: 0.000930
Validation Loss: 0.00085034
Epoch [73/300], Train Loss: 0.000924
Validation Loss: 0.00084654
Epoch [74/300], Train Loss: 0.000915
Validation Loss: 0.00084153
Epoch [75/300], Train Loss: 0.000921
Validation Loss: 0.00083719
Epoch [76/300], Train Loss: 0.000912
Validation Loss: 0.00083230
Epoch [77/300], Train Loss: 0.000918
Validation Loss: 0.00082769
Epoch [78/300], Train Loss: 0.000911
Validation Loss: 0.00082301
Epoch [79/300], Train Loss: 0.000907
Validation Loss: 0.00081750
Epoch [80/300], Train Loss: 0.000895
Validation Loss: 0.00081268
Epoch [81/300], Train Loss: 0.000895
Validation Loss: 0.00080826
Epoch [82/300], Train Loss: 0.000885
Validation Loss: 0.00080152
Epoch [83/300], Train Loss: 0.000886
Validation Loss: 0.00079462
Epoch [84/300], Train Loss: 0.000879
Validation Loss: 0.00078859
Epoch [85/300], Train Loss: 0.000885
Validation Loss: 0.00078173
Epoch [86/300], Train Loss: 0.000864
Validation Loss: 0.00077381
Epoch [87/300], Train Loss: 0.000864
Validation Loss: 0.00076988
Epoch [88/300], Train Loss: 0.000857
Validation Loss: 0.00076186
Epoch [89/300], Train Loss: 0.000849
Validation Loss: 0.00075460
Epoch [90/300], Train Loss: 0.000842
Validation Loss: 0.00074839
Epoch [91/300], Train Loss: 0.000837
Validation Loss: 0.00074275
Epoch [92/300], Train Loss: 0.000831
Validation Loss: 0.00073836
Epoch [93/300], Train Loss: 0.000823
Validation Loss: 0.00073327
Epoch [94/300], Train Loss: 0.000822
Validation Loss: 0.00072732
Epoch [95/300], Train Loss: 0.000806
Validation Loss: 0.00072264
Epoch [96/300], Train Loss: 0.000813
Validation Loss: 0.00071773
Epoch [97/300], Train Loss: 0.000800
Validation Loss: 0.00071368
Epoch [98/300], Train Loss: 0.000802
Validation Loss: 0.00070554
Epoch [99/300], Train Loss: 0.000789
Validation Loss: 0.00070050
Epoch [100/300], Train Loss: 0.000784
Validation Loss: 0.00069671
Epoch [101/300], Train Loss: 0.000782
Validation Loss: 0.00069131
Epoch [102/300], Train Loss: 0.000781
Validation Loss: 0.00068376
Epoch [103/300], Train Loss: 0.000769
Validation Loss: 0.00067877
Epoch [104/300], Train Loss: 0.000765
Validation Loss: 0.00067318
Epoch [105/300], Train Loss: 0.000757
Validation Loss: 0.00067185
Epoch [106/300], Train Loss: 0.000757
Validation Loss: 0.00066486
Epoch [107/300], Train Loss: 0.000753
Validation Loss: 0.00065925
Epoch [108/300], Train Loss: 0.000741
Validation Loss: 0.00065789
Epoch [109/300], Train Loss: 0.000744
Validation Loss: 0.00065350
Epoch [110/300], Train Loss: 0.000739
Validation Loss: 0.00064912
Epoch [111/300], Train Loss: 0.000736
Validation Loss: 0.00065150
Epoch [112/300], Train Loss: 0.000732
Validation Loss: 0.00064259
Epoch [113/300], Train Loss: 0.000728
Validation Loss: 0.00063800
Epoch [114/300], Train Loss: 0.000724
Validation Loss: 0.00063562
Epoch [115/300], Train Loss: 0.000727
Validation Loss: 0.00063420
Epoch [116/300], Train Loss: 0.000723
Validation Loss: 0.00062705
Epoch [117/300], Train Loss: 0.000712
Validation Loss: 0.00063056
Epoch [118/300], Train Loss: 0.000718
Validation Loss: 0.00062090
Epoch [119/300], Train Loss: 0.000712
Validation Loss: 0.00061811
Epoch [120/300], Train Loss: 0.000710
Validation Loss: 0.00062196
Epoch [121/300], Train Loss: 0.000704
Validation Loss: 0.00061656
Epoch [122/300], Train Loss: 0.000702
Validation Loss: 0.00060922
Epoch [123/300], Train Loss: 0.000696
Validation Loss: 0.00061896
Epoch [124/300], Train Loss: 0.000703
Validation Loss: 0.00060425
Epoch [125/300], Train Loss: 0.000686
Validation Loss: 0.00060517
Epoch [126/300], Train Loss: 0.000688
Validation Loss: 0.00060202
Epoch [127/300], Train Loss: 0.000682
Validation Loss: 0.00059832
Epoch [128/300], Train Loss: 0.000679
Validation Loss: 0.00059688
Epoch [129/300], Train Loss: 0.000682
Validation Loss: 0.00060711
Epoch [130/300], Train Loss: 0.000683
Validation Loss: 0.00059438
Epoch [131/300], Train Loss: 0.000676
Validation Loss: 0.00059324
Epoch [132/300], Train Loss: 0.000681
Validation Loss: 0.00058903
Epoch [133/300], Train Loss: 0.000679
Validation Loss: 0.00058873
Epoch [134/300], Train Loss: 0.000671
Validation Loss: 0.00059025
Epoch [135/300], Train Loss: 0.000672
Validation Loss: 0.00058222
Epoch [136/300], Train Loss: 0.000665
Validation Loss: 0.00058369
Epoch [137/300], Train Loss: 0.000666
Validation Loss: 0.00058059
Epoch [138/300], Train Loss: 0.000660
Validation Loss: 0.00058142
Epoch [139/300], Train Loss: 0.000664
Validation Loss: 0.00059269
Epoch [140/300], Train Loss: 0.000662
Validation Loss: 0.00058078
Epoch [141/300], Train Loss: 0.000660
Validation Loss: 0.00057417
Epoch [142/300], Train Loss: 0.000653
Validation Loss: 0.00058418
Epoch [143/300], Train Loss: 0.000661
Validation Loss: 0.00057844
Epoch [144/300], Train Loss: 0.000646
Validation Loss: 0.00056968
Epoch [145/300], Train Loss: 0.000648
Validation Loss: 0.00056745
Epoch [146/300], Train Loss: 0.000651
Validation Loss: 0.00056700
Epoch [147/300], Train Loss: 0.000652
Validation Loss: 0.00056420
Epoch [148/300], Train Loss: 0.000649
Validation Loss: 0.00056802
Epoch [149/300], Train Loss: 0.000641
Validation Loss: 0.00056260
Epoch [150/300], Train Loss: 0.000643
Validation Loss: 0.00056038
Epoch [151/300], Train Loss: 0.000646
Validation Loss: 0.00056089
Epoch [152/300], Train Loss: 0.000637
Validation Loss: 0.00055822
Epoch [153/300], Train Loss: 0.000637
Validation Loss: 0.00055916
Epoch [154/300], Train Loss: 0.000641
Validation Loss: 0.00055588
Epoch [155/300], Train Loss: 0.000636
Validation Loss: 0.00056178
Epoch [156/300], Train Loss: 0.000637
Validation Loss: 0.00055836
Epoch [157/300], Train Loss: 0.000638
Validation Loss: 0.00055280
Epoch [158/300], Train Loss: 0.000638
Validation Loss: 0.00054941
Epoch [159/300], Train Loss: 0.000635
Validation Loss: 0.00054789
Epoch [160/300], Train Loss: 0.000635
Validation Loss: 0.00054827
Epoch [161/300], Train Loss: 0.000631
Validation Loss: 0.00055391
Epoch [162/300], Train Loss: 0.000629
Validation Loss: 0.00054672
Epoch [163/300], Train Loss: 0.000628
Validation Loss: 0.00054343
Epoch [164/300], Train Loss: 0.000626
Validation Loss: 0.00054235
Epoch [165/300], Train Loss: 0.000626
Validation Loss: 0.00054210
Epoch [166/300], Train Loss: 0.000625
Validation Loss: 0.00054297
Epoch [167/300], Train Loss: 0.000628
Validation Loss: 0.00053965
Epoch [168/300], Train Loss: 0.000624
Validation Loss: 0.00054032
Epoch [169/300], Train Loss: 0.000621
Validation Loss: 0.00053728
Epoch [170/300], Train Loss: 0.000618
Validation Loss: 0.00053783
Epoch [171/300], Train Loss: 0.000625
Validation Loss: 0.00053566
Epoch [172/300], Train Loss: 0.000617
Validation Loss: 0.00053653
Epoch [173/300], Train Loss: 0.000613
Validation Loss: 0.00053403
Epoch [174/300], Train Loss: 0.000625
Validation Loss: 0.00053213
Epoch [175/300], Train Loss: 0.000615
Validation Loss: 0.00053241
Epoch [176/300], Train Loss: 0.000614
Validation Loss: 0.00053490
Epoch [177/300], Train Loss: 0.000618
Validation Loss: 0.00054485
Epoch [178/300], Train Loss: 0.000618
Validation Loss: 0.00052962
Epoch [179/300], Train Loss: 0.000611
Validation Loss: 0.00053081
Epoch [180/300], Train Loss: 0.000616
Validation Loss: 0.00052703
Epoch [181/300], Train Loss: 0.000605
Validation Loss: 0.00053069
Epoch [182/300], Train Loss: 0.000610
Validation Loss: 0.00052681
Epoch [183/300], Train Loss: 0.000610
Validation Loss: 0.00052923
Epoch [184/300], Train Loss: 0.000618
Validation Loss: 0.00052472
Epoch [185/300], Train Loss: 0.000600
Validation Loss: 0.00052417
Epoch [186/300], Train Loss: 0.000609
Validation Loss: 0.00052621
Epoch [187/300], Train Loss: 0.000603
Validation Loss: 0.00052039
Epoch [188/300], Train Loss: 0.000599
Validation Loss: 0.00052445
Epoch [189/300], Train Loss: 0.000607
Validation Loss: 0.00052462
Epoch [190/300], Train Loss: 0.000603
Validation Loss: 0.00052074
Epoch [191/300], Train Loss: 0.000598
Validation Loss: 0.00052028
Epoch [192/300], Train Loss: 0.000600
Validation Loss: 0.00051709
Epoch [193/300], Train Loss: 0.000599
Validation Loss: 0.00051605
Epoch [194/300], Train Loss: 0.000605
Validation Loss: 0.00051512
Epoch [195/300], Train Loss: 0.000600
Validation Loss: 0.00051476
Epoch [196/300], Train Loss: 0.000598
Validation Loss: 0.00051753
Epoch [197/300], Train Loss: 0.000602
Validation Loss: 0.00051309
Epoch [198/300], Train Loss: 0.000597
Validation Loss: 0.00051507
Epoch [199/300], Train Loss: 0.000596
Validation Loss: 0.00051295
Epoch [200/300], Train Loss: 0.000597
Validation Loss: 0.00051209
Epoch [201/300], Train Loss: 0.000591
Validation Loss: 0.00051177
Epoch [202/300], Train Loss: 0.000603
Validation Loss: 0.00051067
Epoch [203/300], Train Loss: 0.000594
Validation Loss: 0.00050927
Epoch [204/300], Train Loss: 0.000589
Validation Loss: 0.00050843
Epoch [205/300], Train Loss: 0.000592
Validation Loss: 0.00050991
Epoch [206/300], Train Loss: 0.000594
Validation Loss: 0.00050862
Epoch [207/300], Train Loss: 0.000595
Validation Loss: 0.00050649
Epoch [208/300], Train Loss: 0.000592
Validation Loss: 0.00051162
Epoch [209/300], Train Loss: 0.000595
Validation Loss: 0.00051158
Epoch [210/300], Train Loss: 0.000594
Validation Loss: 0.00050565
Epoch [211/300], Train Loss: 0.000591
Validation Loss: 0.00050673
Epoch [212/300], Train Loss: 0.000591
Validation Loss: 0.00050398
Epoch [213/300], Train Loss: 0.000593
Validation Loss: 0.00050388
Epoch [214/300], Train Loss: 0.000588
Validation Loss: 0.00050575
Epoch [215/300], Train Loss: 0.000588
Validation Loss: 0.00050311
Epoch [216/300], Train Loss: 0.000589
Validation Loss: 0.00050213
Epoch [217/300], Train Loss: 0.000584
Validation Loss: 0.00050341
Epoch [218/300], Train Loss: 0.000581
Validation Loss: 0.00050011
Epoch [219/300], Train Loss: 0.000585
Validation Loss: 0.00050142
Epoch [220/300], Train Loss: 0.000582
Validation Loss: 0.00050151
Epoch [221/300], Train Loss: 0.000587
Validation Loss: 0.00050628
Epoch [222/300], Train Loss: 0.000582
Validation Loss: 0.00049874
Epoch [223/300], Train Loss: 0.000583
Validation Loss: 0.00050149
Epoch [224/300], Train Loss: 0.000579
Validation Loss: 0.00049918
Epoch [225/300], Train Loss: 0.000584
Validation Loss: 0.00049808
Epoch [226/300], Train Loss: 0.000588
Validation Loss: 0.00049694
Epoch [227/300], Train Loss: 0.000583
Validation Loss: 0.00049805
Epoch [228/300], Train Loss: 0.000577
Validation Loss: 0.00049727
Epoch [229/300], Train Loss: 0.000581
Validation Loss: 0.00049630
Epoch [230/300], Train Loss: 0.000584
Validation Loss: 0.00049604
Epoch [231/300], Train Loss: 0.000583
Validation Loss: 0.00049592
Epoch [232/300], Train Loss: 0.000577
Validation Loss: 0.00050038
Epoch [233/300], Train Loss: 0.000580
Validation Loss: 0.00049515
Epoch [234/300], Train Loss: 0.000584
Validation Loss: 0.00049541
Epoch [235/300], Train Loss: 0.000579
Validation Loss: 0.00049433
Epoch [236/300], Train Loss: 0.000583
Validation Loss: 0.00049518
Epoch [237/300], Train Loss: 0.000579
Validation Loss: 0.00049383
Epoch [238/300], Train Loss: 0.000580
Validation Loss: 0.00049450
Epoch [239/300], Train Loss: 0.000584
Validation Loss: 0.00050062
Epoch [240/300], Train Loss: 0.000579
Validation Loss: 0.00049318
Epoch [241/300], Train Loss: 0.000576
Validation Loss: 0.00049173
Epoch [242/300], Train Loss: 0.000571
Validation Loss: 0.00049308
Epoch [243/300], Train Loss: 0.000571
Validation Loss: 0.00049269
Epoch [244/300], Train Loss: 0.000570
Validation Loss: 0.00049143
Epoch [245/300], Train Loss: 0.000575
Validation Loss: 0.00049179
Epoch [246/300], Train Loss: 0.000568
Validation Loss: 0.00048978
Epoch [247/300], Train Loss: 0.000565
Validation Loss: 0.00049089
Epoch [248/300], Train Loss: 0.000563
Validation Loss: 0.00049042
Epoch [249/300], Train Loss: 0.000570
Validation Loss: 0.00048900
Epoch [250/300], Train Loss: 0.000569
Validation Loss: 0.00049106
Epoch [251/300], Train Loss: 0.000578
Validation Loss: 0.00049085
Epoch [252/300], Train Loss: 0.000574
Validation Loss: 0.00048888
Epoch [253/300], Train Loss: 0.000576
Validation Loss: 0.00049173
Epoch [254/300], Train Loss: 0.000573
Validation Loss: 0.00048945
Epoch [255/300], Train Loss: 0.000566
Validation Loss: 0.00048944
Epoch [256/300], Train Loss: 0.000569
Validation Loss: 0.00048769
Epoch [257/300], Train Loss: 0.000565
Validation Loss: 0.00048772
Epoch [258/300], Train Loss: 0.000568
Validation Loss: 0.00048715
Epoch [259/300], Train Loss: 0.000564
Validation Loss: 0.00048627
Epoch [260/300], Train Loss: 0.000570
Validation Loss: 0.00048658
Epoch [261/300], Train Loss: 0.000563
Validation Loss: 0.00048567
Epoch [262/300], Train Loss: 0.000564
Validation Loss: 0.00048635
Epoch [263/300], Train Loss: 0.000564
Validation Loss: 0.00048511
Epoch [264/300], Train Loss: 0.000569
Validation Loss: 0.00048595
Epoch [265/300], Train Loss: 0.000568
Validation Loss: 0.00048563
Epoch [266/300], Train Loss: 0.000562
Validation Loss: 0.00048979
Epoch [267/300], Train Loss: 0.000572
Validation Loss: 0.00048483
Epoch [268/300], Train Loss: 0.000569
Validation Loss: 0.00048405
Epoch [269/300], Train Loss: 0.000564
Validation Loss: 0.00048625
Epoch [270/300], Train Loss: 0.000567
Validation Loss: 0.00048405
Epoch [271/300], Train Loss: 0.000566
Validation Loss: 0.00048453
Epoch [272/300], Train Loss: 0.000561
Validation Loss: 0.00048515
Epoch [273/300], Train Loss: 0.000564
Validation Loss: 0.00048342
Epoch [274/300], Train Loss: 0.000559
Validation Loss: 0.00048467
Epoch [275/300], Train Loss: 0.000573
Validation Loss: 0.00048294
Epoch [276/300], Train Loss: 0.000568
Validation Loss: 0.00048367
Epoch [277/300], Train Loss: 0.000562
Validation Loss: 0.00048601
Epoch [278/300], Train Loss: 0.000565
Validation Loss: 0.00048269
Epoch [279/300], Train Loss: 0.000561
Validation Loss: 0.00048309
Epoch [280/300], Train Loss: 0.000567
Validation Loss: 0.00048312
Epoch [281/300], Train Loss: 0.000561
Validation Loss: 0.00048220
Epoch [282/300], Train Loss: 0.000561
Validation Loss: 0.00048151
Epoch [283/300], Train Loss: 0.000561
Validation Loss: 0.00048301
Epoch [284/300], Train Loss: 0.000559
Validation Loss: 0.00048227
Epoch [285/300], Train Loss: 0.000563
Validation Loss: 0.00048067
Epoch [286/300], Train Loss: 0.000556
Validation Loss: 0.00048322
Epoch [287/300], Train Loss: 0.000560
Validation Loss: 0.00048150
Epoch [288/300], Train Loss: 0.000555
Validation Loss: 0.00048179
Epoch [289/300], Train Loss: 0.000558
Validation Loss: 0.00048178
Epoch [290/300], Train Loss: 0.000561
Validation Loss: 0.00048243
Epoch [291/300], Train Loss: 0.000558
Validation Loss: 0.00048070
Epoch [292/300], Train Loss: 0.000561
Validation Loss: 0.00048076
Epoch [293/300], Train Loss: 0.000558
Validation Loss: 0.00048156
Epoch [294/300], Train Loss: 0.000560
Validation Loss: 0.00048054
Epoch [295/300], Train Loss: 0.000559
Validation Loss: 0.00048045
Epoch [296/300], Train Loss: 0.000569
Validation Loss: 0.00048035
Epoch [297/300], Train Loss: 0.000569
Validation Loss: 0.00048192
Epoch [298/300], Train Loss: 0.000562
Validation Loss: 0.00048273
Epoch [299/300], Train Loss: 0.000556
Validation Loss: 0.00047979
Epoch [300/300], Train Loss: 0.000555
Validation Loss: 0.00047905

Evaluating model for: Coffee Machine
Run 21/72 completed in 1349.33 seconds with: {'MAE': np.float32(7.0138283), 'MSE': np.float32(2726.296), 'RMSE': np.float32(52.213943), 'SAE': np.float32(0.074184924), 'NDE': np.float32(0.79386336)}

Run 22/72: hidden=128, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Coffee Machine
Dataset length: 2980 windows

Epoch [1/300], Train Loss: 0.001480
Validation Loss: 0.00092444
Epoch [2/300], Train Loss: 0.000999
Validation Loss: 0.00092596
Epoch [3/300], Train Loss: 0.000993
Validation Loss: 0.00092024
Epoch [4/300], Train Loss: 0.000992
Validation Loss: 0.00091896
Epoch [5/300], Train Loss: 0.000993
Validation Loss: 0.00091842
Epoch [6/300], Train Loss: 0.000990
Validation Loss: 0.00091835
Epoch [7/300], Train Loss: 0.000990
Validation Loss: 0.00091821
Epoch [8/300], Train Loss: 0.000993
Validation Loss: 0.00091813
Epoch [9/300], Train Loss: 0.000997
Validation Loss: 0.00091800
Epoch [10/300], Train Loss: 0.000997
Validation Loss: 0.00091789
Epoch [11/300], Train Loss: 0.000980
Validation Loss: 0.00091771
Epoch [12/300], Train Loss: 0.000988
Validation Loss: 0.00091762
Epoch [13/300], Train Loss: 0.000990
Validation Loss: 0.00091743
Epoch [14/300], Train Loss: 0.000991
Validation Loss: 0.00091727
Epoch [15/300], Train Loss: 0.000978
Validation Loss: 0.00091737
Epoch [16/300], Train Loss: 0.000985
Validation Loss: 0.00091699
Epoch [17/300], Train Loss: 0.000991
Validation Loss: 0.00091684
Epoch [18/300], Train Loss: 0.000987
Validation Loss: 0.00091675
Epoch [19/300], Train Loss: 0.000987
Validation Loss: 0.00091664
Epoch [20/300], Train Loss: 0.000976
Validation Loss: 0.00091652
Epoch [21/300], Train Loss: 0.000987
Validation Loss: 0.00091625
Epoch [22/300], Train Loss: 0.000973
Validation Loss: 0.00091603
Epoch [23/300], Train Loss: 0.000987
Validation Loss: 0.00091600
Epoch [24/300], Train Loss: 0.000978
Validation Loss: 0.00091569
Epoch [25/300], Train Loss: 0.000981
Validation Loss: 0.00091573
Epoch [26/300], Train Loss: 0.000984
Validation Loss: 0.00091531
Epoch [27/300], Train Loss: 0.000982
Validation Loss: 0.00091523
Epoch [28/300], Train Loss: 0.000973
Validation Loss: 0.00091524
Epoch [29/300], Train Loss: 0.000981
Validation Loss: 0.00091490
Epoch [30/300], Train Loss: 0.000979
Validation Loss: 0.00091444
Epoch [31/300], Train Loss: 0.000976
Validation Loss: 0.00091425
Epoch [32/300], Train Loss: 0.000979
Validation Loss: 0.00091432
Epoch [33/300], Train Loss: 0.000980
Validation Loss: 0.00091386
Epoch [34/300], Train Loss: 0.000979
Validation Loss: 0.00091344
Epoch [35/300], Train Loss: 0.000973
Validation Loss: 0.00091309
Epoch [36/300], Train Loss: 0.000986
Validation Loss: 0.00091261
Epoch [37/300], Train Loss: 0.000994
Validation Loss: 0.00091384
Epoch [38/300], Train Loss: 0.000980
Validation Loss: 0.00091174
Epoch [39/300], Train Loss: 0.000983
Validation Loss: 0.00091109
Epoch [40/300], Train Loss: 0.000977
Validation Loss: 0.00091119
Epoch [41/300], Train Loss: 0.000982
Validation Loss: 0.00090999
Epoch [42/300], Train Loss: 0.000984
Validation Loss: 0.00090924
Epoch [43/300], Train Loss: 0.000981
Validation Loss: 0.00090805
Epoch [44/300], Train Loss: 0.000970
Validation Loss: 0.00090694
Epoch [45/300], Train Loss: 0.000965
Validation Loss: 0.00090585
Epoch [46/300], Train Loss: 0.000974
Validation Loss: 0.00090473
Epoch [47/300], Train Loss: 0.000975
Validation Loss: 0.00090363
Epoch [48/300], Train Loss: 0.000970
Validation Loss: 0.00090246
Epoch [49/300], Train Loss: 0.000967
Validation Loss: 0.00090169
Epoch [50/300], Train Loss: 0.000969
Validation Loss: 0.00089993
Epoch [51/300], Train Loss: 0.000972
Validation Loss: 0.00089857
Epoch [52/300], Train Loss: 0.000964
Validation Loss: 0.00089733
Epoch [53/300], Train Loss: 0.000965
Validation Loss: 0.00089616
Epoch [54/300], Train Loss: 0.000970
Validation Loss: 0.00089461
Epoch [55/300], Train Loss: 0.000959
Validation Loss: 0.00089302
Epoch [56/300], Train Loss: 0.000967
Validation Loss: 0.00089143
Epoch [57/300], Train Loss: 0.000972
Validation Loss: 0.00088889
Epoch [58/300], Train Loss: 0.000954
Validation Loss: 0.00088687
Epoch [59/300], Train Loss: 0.000955
Validation Loss: 0.00088319
Epoch [60/300], Train Loss: 0.000966
Validation Loss: 0.00088055
Epoch [61/300], Train Loss: 0.000950
Validation Loss: 0.00087821
Epoch [62/300], Train Loss: 0.000946
Validation Loss: 0.00087181
Epoch [63/300], Train Loss: 0.000944
Validation Loss: 0.00086702
Epoch [64/300], Train Loss: 0.000932
Validation Loss: 0.00086176
Epoch [65/300], Train Loss: 0.000942
Validation Loss: 0.00085597
Epoch [66/300], Train Loss: 0.000934
Validation Loss: 0.00084989
Epoch [67/300], Train Loss: 0.000927
Validation Loss: 0.00084210
Epoch [68/300], Train Loss: 0.000925
Validation Loss: 0.00083496
Epoch [69/300], Train Loss: 0.000920
Validation Loss: 0.00082651
Epoch [70/300], Train Loss: 0.000910
Validation Loss: 0.00081983
Epoch [71/300], Train Loss: 0.000892
Validation Loss: 0.00080884
Epoch [72/300], Train Loss: 0.000890
Validation Loss: 0.00079617
Epoch [73/300], Train Loss: 0.000877
Validation Loss: 0.00078265
Epoch [74/300], Train Loss: 0.000862
Validation Loss: 0.00077336
Epoch [75/300], Train Loss: 0.000860
Validation Loss: 0.00076047
Epoch [76/300], Train Loss: 0.000845
Validation Loss: 0.00074810
Epoch [77/300], Train Loss: 0.000842
Validation Loss: 0.00073983
Epoch [78/300], Train Loss: 0.000830
Validation Loss: 0.00073332
Epoch [79/300], Train Loss: 0.000818
Validation Loss: 0.00071678
Epoch [80/300], Train Loss: 0.000800
Validation Loss: 0.00070571
Epoch [81/300], Train Loss: 0.000799
Validation Loss: 0.00069760
Epoch [82/300], Train Loss: 0.000784
Validation Loss: 0.00069185
Epoch [83/300], Train Loss: 0.000779
Validation Loss: 0.00068343
Epoch [84/300], Train Loss: 0.000769
Validation Loss: 0.00066763
Epoch [85/300], Train Loss: 0.000769
Validation Loss: 0.00065587
Epoch [86/300], Train Loss: 0.000750
Validation Loss: 0.00065107
Epoch [87/300], Train Loss: 0.000764
Validation Loss: 0.00067393
Epoch [88/300], Train Loss: 0.000752
Validation Loss: 0.00064382
Epoch [89/300], Train Loss: 0.000737
Validation Loss: 0.00063669
Epoch [90/300], Train Loss: 0.000727
Validation Loss: 0.00062925
Epoch [91/300], Train Loss: 0.000721
Validation Loss: 0.00061939
Epoch [92/300], Train Loss: 0.000720
Validation Loss: 0.00061485
Epoch [93/300], Train Loss: 0.000714
Validation Loss: 0.00060672
Epoch [94/300], Train Loss: 0.000707
Validation Loss: 0.00060467
Epoch [95/300], Train Loss: 0.000710
Validation Loss: 0.00063323
Epoch [96/300], Train Loss: 0.000710
Validation Loss: 0.00060488
Epoch [97/300], Train Loss: 0.000692
Validation Loss: 0.00060588
Epoch [98/300], Train Loss: 0.000696
Validation Loss: 0.00059075
Epoch [99/300], Train Loss: 0.000691
Validation Loss: 0.00059280
Epoch [100/300], Train Loss: 0.000685
Validation Loss: 0.00058754
Epoch [101/300], Train Loss: 0.000688
Validation Loss: 0.00059281
Epoch [102/300], Train Loss: 0.000680
Validation Loss: 0.00057466
Epoch [103/300], Train Loss: 0.000673
Validation Loss: 0.00057540
Epoch [104/300], Train Loss: 0.000677
Validation Loss: 0.00057432
Epoch [105/300], Train Loss: 0.000664
Validation Loss: 0.00056243
Epoch [106/300], Train Loss: 0.000659
Validation Loss: 0.00056408
Epoch [107/300], Train Loss: 0.000657
Validation Loss: 0.00055174
Epoch [108/300], Train Loss: 0.000648
Validation Loss: 0.00055926
Epoch [109/300], Train Loss: 0.000655
Validation Loss: 0.00055356
Epoch [110/300], Train Loss: 0.000644
Validation Loss: 0.00055102
Epoch [111/300], Train Loss: 0.000646
Validation Loss: 0.00055310
Epoch [112/300], Train Loss: 0.000650
Validation Loss: 0.00054339
Epoch [113/300], Train Loss: 0.000641
Validation Loss: 0.00054169
Epoch [114/300], Train Loss: 0.000639
Validation Loss: 0.00055283
Epoch [115/300], Train Loss: 0.000653
Validation Loss: 0.00054981
Epoch [116/300], Train Loss: 0.000641
Validation Loss: 0.00054017
Epoch [117/300], Train Loss: 0.000630
Validation Loss: 0.00055212
Epoch [118/300], Train Loss: 0.000638
Validation Loss: 0.00052948
Epoch [119/300], Train Loss: 0.000627
Validation Loss: 0.00052677
Epoch [120/300], Train Loss: 0.000635
Validation Loss: 0.00053270
Epoch [121/300], Train Loss: 0.000635
Validation Loss: 0.00053017
Epoch [122/300], Train Loss: 0.000625
Validation Loss: 0.00052295
Epoch [123/300], Train Loss: 0.000619
Validation Loss: 0.00053752
Epoch [124/300], Train Loss: 0.000624
Validation Loss: 0.00052195
Epoch [125/300], Train Loss: 0.000612
Validation Loss: 0.00051891
Epoch [126/300], Train Loss: 0.000611
Validation Loss: 0.00051761
Epoch [127/300], Train Loss: 0.000617
Validation Loss: 0.00051671
Epoch [128/300], Train Loss: 0.000610
Validation Loss: 0.00051543
Epoch [129/300], Train Loss: 0.000617
Validation Loss: 0.00053738
Epoch [130/300], Train Loss: 0.000610
Validation Loss: 0.00051266
Epoch [131/300], Train Loss: 0.000605
Validation Loss: 0.00051694
Epoch [132/300], Train Loss: 0.000612
Validation Loss: 0.00050924
Epoch [133/300], Train Loss: 0.000611
Validation Loss: 0.00051118
Epoch [134/300], Train Loss: 0.000602
Validation Loss: 0.00051296
Epoch [135/300], Train Loss: 0.000599
Validation Loss: 0.00050478
Epoch [136/300], Train Loss: 0.000605
Validation Loss: 0.00051663
Epoch [137/300], Train Loss: 0.000600
Validation Loss: 0.00051060
Epoch [138/300], Train Loss: 0.000597
Validation Loss: 0.00051174
Epoch [139/300], Train Loss: 0.000604
Validation Loss: 0.00054345
Epoch [140/300], Train Loss: 0.000600
Validation Loss: 0.00052040
Epoch [141/300], Train Loss: 0.000593
Validation Loss: 0.00050194
Epoch [142/300], Train Loss: 0.000583
Validation Loss: 0.00052151
Epoch [143/300], Train Loss: 0.000593
Validation Loss: 0.00051296
Epoch [144/300], Train Loss: 0.000586
Validation Loss: 0.00049607
Epoch [145/300], Train Loss: 0.000584
Validation Loss: 0.00049361
Epoch [146/300], Train Loss: 0.000585
Validation Loss: 0.00049684
Epoch [147/300], Train Loss: 0.000587
Validation Loss: 0.00049748
Epoch [148/300], Train Loss: 0.000580
Validation Loss: 0.00049954
Epoch [149/300], Train Loss: 0.000574
Validation Loss: 0.00049474
Epoch [150/300], Train Loss: 0.000579
Validation Loss: 0.00049052
Epoch [151/300], Train Loss: 0.000583
Validation Loss: 0.00048717
Epoch [152/300], Train Loss: 0.000571
Validation Loss: 0.00049005
Epoch [153/300], Train Loss: 0.000572
Validation Loss: 0.00048369
Epoch [154/300], Train Loss: 0.000575
Validation Loss: 0.00049521
Epoch [155/300], Train Loss: 0.000575
Validation Loss: 0.00050283
Epoch [156/300], Train Loss: 0.000576
Validation Loss: 0.00049259
Epoch [157/300], Train Loss: 0.000572
Validation Loss: 0.00048335
Epoch [158/300], Train Loss: 0.000576
Validation Loss: 0.00048283
Epoch [159/300], Train Loss: 0.000570
Validation Loss: 0.00047824
Epoch [160/300], Train Loss: 0.000575
Validation Loss: 0.00047771
Epoch [161/300], Train Loss: 0.000570
Validation Loss: 0.00049992
Epoch [162/300], Train Loss: 0.000571
Validation Loss: 0.00048505
Epoch [163/300], Train Loss: 0.000570
Validation Loss: 0.00047953
Epoch [164/300], Train Loss: 0.000567
Validation Loss: 0.00047945
Epoch [165/300], Train Loss: 0.000562
Validation Loss: 0.00048635
Epoch [166/300], Train Loss: 0.000566
Validation Loss: 0.00047632
Epoch [167/300], Train Loss: 0.000562
Validation Loss: 0.00047736
Epoch [168/300], Train Loss: 0.000566
Validation Loss: 0.00047636
Epoch [169/300], Train Loss: 0.000562
Validation Loss: 0.00047449
Epoch [170/300], Train Loss: 0.000557
Validation Loss: 0.00048056
Epoch [171/300], Train Loss: 0.000565
Validation Loss: 0.00047549
Epoch [172/300], Train Loss: 0.000559
Validation Loss: 0.00047910
Epoch [173/300], Train Loss: 0.000556
Validation Loss: 0.00046975
Epoch [174/300], Train Loss: 0.000568
Validation Loss: 0.00046936
Epoch [175/300], Train Loss: 0.000555
Validation Loss: 0.00046937
Epoch [176/300], Train Loss: 0.000552
Validation Loss: 0.00047083
Epoch [177/300], Train Loss: 0.000558
Validation Loss: 0.00048196
Epoch [178/300], Train Loss: 0.000562
Validation Loss: 0.00047632
Epoch [179/300], Train Loss: 0.000558
Validation Loss: 0.00047466
Epoch [180/300], Train Loss: 0.000556
Validation Loss: 0.00047370
Epoch [181/300], Train Loss: 0.000550
Validation Loss: 0.00047798
Epoch [182/300], Train Loss: 0.000553
Validation Loss: 0.00047370
Epoch [183/300], Train Loss: 0.000553
Validation Loss: 0.00047625
Epoch [184/300], Train Loss: 0.000557
Validation Loss: 0.00046759
Epoch [185/300], Train Loss: 0.000544
Validation Loss: 0.00047074
Epoch [186/300], Train Loss: 0.000547
Validation Loss: 0.00046657
Epoch [187/300], Train Loss: 0.000547
Validation Loss: 0.00046291
Epoch [188/300], Train Loss: 0.000545
Validation Loss: 0.00047564
Epoch [189/300], Train Loss: 0.000551
Validation Loss: 0.00047125
Epoch [190/300], Train Loss: 0.000550
Validation Loss: 0.00046288
Epoch [191/300], Train Loss: 0.000541
Validation Loss: 0.00046287
Epoch [192/300], Train Loss: 0.000544
Validation Loss: 0.00046134
Epoch [193/300], Train Loss: 0.000543
Validation Loss: 0.00046266
Epoch [194/300], Train Loss: 0.000547
Validation Loss: 0.00046168
Epoch [195/300], Train Loss: 0.000546
Validation Loss: 0.00046154
Epoch [196/300], Train Loss: 0.000543
Validation Loss: 0.00050487
Epoch [197/300], Train Loss: 0.000576
Validation Loss: 0.00047051
Epoch [198/300], Train Loss: 0.000550
Validation Loss: 0.00046603
Epoch [199/300], Train Loss: 0.000542
Validation Loss: 0.00046408
Epoch [200/300], Train Loss: 0.000543
Validation Loss: 0.00045989
Epoch [201/300], Train Loss: 0.000539
Validation Loss: 0.00045900
Epoch [202/300], Train Loss: 0.000547
Validation Loss: 0.00046034
Epoch [203/300], Train Loss: 0.000539
Validation Loss: 0.00046049
Epoch [204/300], Train Loss: 0.000533
Validation Loss: 0.00045742
Epoch [205/300], Train Loss: 0.000537
Validation Loss: 0.00045882
Epoch [206/300], Train Loss: 0.000537
Validation Loss: 0.00045749
Epoch [207/300], Train Loss: 0.000541
Validation Loss: 0.00045648
Epoch [208/300], Train Loss: 0.000539
Validation Loss: 0.00046340
Epoch [209/300], Train Loss: 0.000542
Validation Loss: 0.00046352
Epoch [210/300], Train Loss: 0.000541
Validation Loss: 0.00046006
Epoch [211/300], Train Loss: 0.000537
Validation Loss: 0.00045653
Epoch [212/300], Train Loss: 0.000535
Validation Loss: 0.00045549
Epoch [213/300], Train Loss: 0.000541
Validation Loss: 0.00045420
Epoch [214/300], Train Loss: 0.000537
Validation Loss: 0.00046015
Epoch [215/300], Train Loss: 0.000535
Validation Loss: 0.00045623
Epoch [216/300], Train Loss: 0.000537
Validation Loss: 0.00045404
Epoch [217/300], Train Loss: 0.000529
Validation Loss: 0.00045472
Epoch [218/300], Train Loss: 0.000525
Validation Loss: 0.00045458
Epoch [219/300], Train Loss: 0.000529
Validation Loss: 0.00045136
Epoch [220/300], Train Loss: 0.000529
Validation Loss: 0.00045189
Epoch [221/300], Train Loss: 0.000531
Validation Loss: 0.00045835
Epoch [222/300], Train Loss: 0.000529
Validation Loss: 0.00045670
Epoch [223/300], Train Loss: 0.000537
Validation Loss: 0.00045558
Epoch [224/300], Train Loss: 0.000528
Validation Loss: 0.00045395
Epoch [225/300], Train Loss: 0.000528
Validation Loss: 0.00045186
Epoch [226/300], Train Loss: 0.000536
Validation Loss: 0.00045022
Epoch [227/300], Train Loss: 0.000525
Validation Loss: 0.00045178
Epoch [228/300], Train Loss: 0.000520
Validation Loss: 0.00045087
Epoch [229/300], Train Loss: 0.000527
Validation Loss: 0.00044979
Epoch [230/300], Train Loss: 0.000529
Validation Loss: 0.00045187
Epoch [231/300], Train Loss: 0.000530
Validation Loss: 0.00045163
Epoch [232/300], Train Loss: 0.000524
Validation Loss: 0.00045883
Epoch [233/300], Train Loss: 0.000525
Validation Loss: 0.00045234
Epoch [234/300], Train Loss: 0.000533
Validation Loss: 0.00044963
Epoch [235/300], Train Loss: 0.000526
Validation Loss: 0.00044879
Epoch [236/300], Train Loss: 0.000532
Validation Loss: 0.00044993
Epoch [237/300], Train Loss: 0.000529
Validation Loss: 0.00045305
Epoch [238/300], Train Loss: 0.000528
Validation Loss: 0.00045036
Epoch [239/300], Train Loss: 0.000528
Validation Loss: 0.00045523
Epoch [240/300], Train Loss: 0.000528
Validation Loss: 0.00044925
Epoch [241/300], Train Loss: 0.000523
Validation Loss: 0.00044820
Epoch [242/300], Train Loss: 0.000515
Validation Loss: 0.00044763
Epoch [243/300], Train Loss: 0.000519
Validation Loss: 0.00044972
Epoch [244/300], Train Loss: 0.000521
Validation Loss: 0.00044667
Epoch [245/300], Train Loss: 0.000524
Validation Loss: 0.00044740
Epoch [246/300], Train Loss: 0.000518
Validation Loss: 0.00044598
Epoch [247/300], Train Loss: 0.000517
Validation Loss: 0.00044721
Epoch [248/300], Train Loss: 0.000513
Validation Loss: 0.00044736
Epoch [249/300], Train Loss: 0.000519
Validation Loss: 0.00044750
Epoch [250/300], Train Loss: 0.000519
Validation Loss: 0.00044829
Epoch [251/300], Train Loss: 0.000522
Validation Loss: 0.00044731
Epoch [252/300], Train Loss: 0.000521
Validation Loss: 0.00044615
Epoch [253/300], Train Loss: 0.000518
Validation Loss: 0.00044878
Epoch [254/300], Train Loss: 0.000522
Validation Loss: 0.00044684
Epoch [255/300], Train Loss: 0.000515
Validation Loss: 0.00044978
Epoch [256/300], Train Loss: 0.000516
Validation Loss: 0.00044774
Early stopping triggered

Evaluating model for: Coffee Machine
Run 22/72 completed in 1220.78 seconds with: {'MAE': np.float32(6.02213), 'MSE': np.float32(2602.9978), 'RMSE': np.float32(51.01958), 'SAE': np.float32(0.0833825), 'NDE': np.float32(0.77570367)}

Run 23/72: hidden=128, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Coffee Machine
Dataset length: 2980 windows

Epoch [1/300], Train Loss: 0.001165
Validation Loss: 0.00094011
Epoch [2/300], Train Loss: 0.000990
Validation Loss: 0.00091821
Epoch [3/300], Train Loss: 0.000986
Validation Loss: 0.00091707
Epoch [4/300], Train Loss: 0.000986
Validation Loss: 0.00091684
Epoch [5/300], Train Loss: 0.000986
Validation Loss: 0.00091689
Epoch [6/300], Train Loss: 0.000984
Validation Loss: 0.00091676
Epoch [7/300], Train Loss: 0.000983
Validation Loss: 0.00091671
Epoch [8/300], Train Loss: 0.000987
Validation Loss: 0.00091676
Epoch [9/300], Train Loss: 0.000991
Validation Loss: 0.00091666
Epoch [10/300], Train Loss: 0.000991
Validation Loss: 0.00091659
Epoch [11/300], Train Loss: 0.000973
Validation Loss: 0.00091656
Epoch [12/300], Train Loss: 0.000982
Validation Loss: 0.00091655
Epoch [13/300], Train Loss: 0.000984
Validation Loss: 0.00091642
Epoch [14/300], Train Loss: 0.000985
Validation Loss: 0.00091635
Epoch [15/300], Train Loss: 0.000972
Validation Loss: 0.00091664
Epoch [16/300], Train Loss: 0.000979
Validation Loss: 0.00091621
Epoch [17/300], Train Loss: 0.000986
Validation Loss: 0.00091618
Epoch [18/300], Train Loss: 0.000982
Validation Loss: 0.00091604
Epoch [19/300], Train Loss: 0.000982
Validation Loss: 0.00091599
Epoch [20/300], Train Loss: 0.000971
Validation Loss: 0.00091612
Epoch [21/300], Train Loss: 0.000983
Validation Loss: 0.00091579
Epoch [22/300], Train Loss: 0.000969
Validation Loss: 0.00091556
Epoch [23/300], Train Loss: 0.000983
Validation Loss: 0.00091554
Epoch [24/300], Train Loss: 0.000974
Validation Loss: 0.00091519
Epoch [25/300], Train Loss: 0.000977
Validation Loss: 0.00091519
Epoch [26/300], Train Loss: 0.000980
Validation Loss: 0.00091484
Epoch [27/300], Train Loss: 0.000978
Validation Loss: 0.00091468
Epoch [28/300], Train Loss: 0.000970
Validation Loss: 0.00091454
Epoch [29/300], Train Loss: 0.000978
Validation Loss: 0.00091399
Epoch [30/300], Train Loss: 0.000975
Validation Loss: 0.00091356
Epoch [31/300], Train Loss: 0.000972
Validation Loss: 0.00091310
Epoch [32/300], Train Loss: 0.000975
Validation Loss: 0.00091292
Epoch [33/300], Train Loss: 0.000976
Validation Loss: 0.00091235
Epoch [34/300], Train Loss: 0.000975
Validation Loss: 0.00091137
Epoch [35/300], Train Loss: 0.000969
Validation Loss: 0.00091072
Epoch [36/300], Train Loss: 0.000981
Validation Loss: 0.00090958
Epoch [37/300], Train Loss: 0.000989
Validation Loss: 0.00091067
Epoch [38/300], Train Loss: 0.000975
Validation Loss: 0.00090861
Epoch [39/300], Train Loss: 0.000978
Validation Loss: 0.00090734
Epoch [40/300], Train Loss: 0.000971
Validation Loss: 0.00090665
Epoch [41/300], Train Loss: 0.000976
Validation Loss: 0.00090621
Epoch [42/300], Train Loss: 0.000979
Validation Loss: 0.00090566
Epoch [43/300], Train Loss: 0.000975
Validation Loss: 0.00090418
Epoch [44/300], Train Loss: 0.000965
Validation Loss: 0.00090291
Epoch [45/300], Train Loss: 0.000960
Validation Loss: 0.00090195
Epoch [46/300], Train Loss: 0.000968
Validation Loss: 0.00090082
Epoch [47/300], Train Loss: 0.000969
Validation Loss: 0.00089970
Epoch [48/300], Train Loss: 0.000964
Validation Loss: 0.00089834
Epoch [49/300], Train Loss: 0.000961
Validation Loss: 0.00089686
Epoch [50/300], Train Loss: 0.000962
Validation Loss: 0.00089440
Epoch [51/300], Train Loss: 0.000964
Validation Loss: 0.00089160
Epoch [52/300], Train Loss: 0.000955
Validation Loss: 0.00088825
Epoch [53/300], Train Loss: 0.000954
Validation Loss: 0.00088413
Epoch [54/300], Train Loss: 0.000957
Validation Loss: 0.00087869
Epoch [55/300], Train Loss: 0.000943
Validation Loss: 0.00087178
Epoch [56/300], Train Loss: 0.000947
Validation Loss: 0.00086410
Epoch [57/300], Train Loss: 0.000945
Validation Loss: 0.00085446
Epoch [58/300], Train Loss: 0.000923
Validation Loss: 0.00084562
Epoch [59/300], Train Loss: 0.000917
Validation Loss: 0.00083328
Epoch [60/300], Train Loss: 0.000917
Validation Loss: 0.00081808
Epoch [61/300], Train Loss: 0.000895
Validation Loss: 0.00081150
Epoch [62/300], Train Loss: 0.000882
Validation Loss: 0.00079143
Epoch [63/300], Train Loss: 0.000868
Validation Loss: 0.00077530
Epoch [64/300], Train Loss: 0.000846
Validation Loss: 0.00075914
Epoch [65/300], Train Loss: 0.000844
Validation Loss: 0.00074247
Epoch [66/300], Train Loss: 0.000823
Validation Loss: 0.00072406
Epoch [67/300], Train Loss: 0.000807
Validation Loss: 0.00070303
Epoch [68/300], Train Loss: 0.000792
Validation Loss: 0.00069702
Epoch [69/300], Train Loss: 0.000783
Validation Loss: 0.00067348
Epoch [70/300], Train Loss: 0.000761
Validation Loss: 0.00066392
Epoch [71/300], Train Loss: 0.000743
Validation Loss: 0.00066139
Epoch [72/300], Train Loss: 0.000738
Validation Loss: 0.00064271
Epoch [73/300], Train Loss: 0.000730
Validation Loss: 0.00063489
Epoch [74/300], Train Loss: 0.000714
Validation Loss: 0.00063267
Epoch [75/300], Train Loss: 0.000723
Validation Loss: 0.00062260
Epoch [76/300], Train Loss: 0.000707
Validation Loss: 0.00061922
Epoch [77/300], Train Loss: 0.000697
Validation Loss: 0.00060387
Epoch [78/300], Train Loss: 0.000686
Validation Loss: 0.00062993
Epoch [79/300], Train Loss: 0.000691
Validation Loss: 0.00059440
Epoch [80/300], Train Loss: 0.000677
Validation Loss: 0.00059049
Epoch [81/300], Train Loss: 0.000670
Validation Loss: 0.00058503
Epoch [82/300], Train Loss: 0.000655
Validation Loss: 0.00057378
Epoch [83/300], Train Loss: 0.000658
Validation Loss: 0.00058144
Epoch [84/300], Train Loss: 0.000653
Validation Loss: 0.00056911
Epoch [85/300], Train Loss: 0.000668
Validation Loss: 0.00056317
Epoch [86/300], Train Loss: 0.000644
Validation Loss: 0.00056501
Epoch [87/300], Train Loss: 0.000653
Validation Loss: 0.00058790
Epoch [88/300], Train Loss: 0.000645
Validation Loss: 0.00056254
Epoch [89/300], Train Loss: 0.000633
Validation Loss: 0.00055167
Epoch [90/300], Train Loss: 0.000639
Validation Loss: 0.00054747
Epoch [91/300], Train Loss: 0.000634
Validation Loss: 0.00054894
Epoch [92/300], Train Loss: 0.000635
Validation Loss: 0.00054558
Epoch [93/300], Train Loss: 0.000624
Validation Loss: 0.00054087
Epoch [94/300], Train Loss: 0.000623
Validation Loss: 0.00053876
Epoch [95/300], Train Loss: 0.000619
Validation Loss: 0.00054196
Epoch [96/300], Train Loss: 0.000618
Validation Loss: 0.00053939
Epoch [97/300], Train Loss: 0.000618
Validation Loss: 0.00053937
Epoch [98/300], Train Loss: 0.000625
Validation Loss: 0.00053780
Epoch [99/300], Train Loss: 0.000617
Validation Loss: 0.00052840
Epoch [100/300], Train Loss: 0.000608
Validation Loss: 0.00052718
Epoch [101/300], Train Loss: 0.000621
Validation Loss: 0.00053746
Epoch [102/300], Train Loss: 0.000610
Validation Loss: 0.00052521
Epoch [103/300], Train Loss: 0.000610
Validation Loss: 0.00052065
Epoch [104/300], Train Loss: 0.000608
Validation Loss: 0.00052308
Epoch [105/300], Train Loss: 0.000599
Validation Loss: 0.00051957
Epoch [106/300], Train Loss: 0.000600
Validation Loss: 0.00051921
Epoch [107/300], Train Loss: 0.000600
Validation Loss: 0.00051781
Epoch [108/300], Train Loss: 0.000588
Validation Loss: 0.00051572
Epoch [109/300], Train Loss: 0.000597
Validation Loss: 0.00051107
Epoch [110/300], Train Loss: 0.000592
Validation Loss: 0.00051031
Epoch [111/300], Train Loss: 0.000593
Validation Loss: 0.00052477
Epoch [112/300], Train Loss: 0.000601
Validation Loss: 0.00050825
Epoch [113/300], Train Loss: 0.000596
Validation Loss: 0.00050737
Epoch [114/300], Train Loss: 0.000599
Validation Loss: 0.00051206
Epoch [115/300], Train Loss: 0.000610
Validation Loss: 0.00050596
Epoch [116/300], Train Loss: 0.000591
Validation Loss: 0.00050473
Epoch [117/300], Train Loss: 0.000589
Validation Loss: 0.00050814
Epoch [118/300], Train Loss: 0.000588
Validation Loss: 0.00050341
Epoch [119/300], Train Loss: 0.000582
Validation Loss: 0.00050494
Epoch [120/300], Train Loss: 0.000586
Validation Loss: 0.00049679
Epoch [121/300], Train Loss: 0.000582
Validation Loss: 0.00049875
Epoch [122/300], Train Loss: 0.000579
Validation Loss: 0.00049805
Epoch [123/300], Train Loss: 0.000577
Validation Loss: 0.00050366
Epoch [124/300], Train Loss: 0.000578
Validation Loss: 0.00049800
Epoch [125/300], Train Loss: 0.000565
Validation Loss: 0.00049319
Epoch [126/300], Train Loss: 0.000571
Validation Loss: 0.00049165
Epoch [127/300], Train Loss: 0.000568
Validation Loss: 0.00048859
Epoch [128/300], Train Loss: 0.000568
Validation Loss: 0.00049059
Epoch [129/300], Train Loss: 0.000569
Validation Loss: 0.00049682
Epoch [130/300], Train Loss: 0.000564
Validation Loss: 0.00048395
Epoch [131/300], Train Loss: 0.000561
Validation Loss: 0.00049032
Epoch [132/300], Train Loss: 0.000569
Validation Loss: 0.00048878
Epoch [133/300], Train Loss: 0.000561
Validation Loss: 0.00049061
Epoch [134/300], Train Loss: 0.000564
Validation Loss: 0.00048922
Epoch [135/300], Train Loss: 0.000558
Validation Loss: 0.00047799
Epoch [136/300], Train Loss: 0.000557
Validation Loss: 0.00048323
Epoch [137/300], Train Loss: 0.000553
Validation Loss: 0.00047296
Epoch [138/300], Train Loss: 0.000550
Validation Loss: 0.00048226
Epoch [139/300], Train Loss: 0.000559
Validation Loss: 0.00050928
Epoch [140/300], Train Loss: 0.000559
Validation Loss: 0.00049613
Epoch [141/300], Train Loss: 0.000558
Validation Loss: 0.00047907
Epoch [142/300], Train Loss: 0.000550
Validation Loss: 0.00048530
Epoch [143/300], Train Loss: 0.000555
Validation Loss: 0.00048920
Epoch [144/300], Train Loss: 0.000545
Validation Loss: 0.00047078
Epoch [145/300], Train Loss: 0.000540
Validation Loss: 0.00046622
Epoch [146/300], Train Loss: 0.000541
Validation Loss: 0.00046545
Epoch [147/300], Train Loss: 0.000546
Validation Loss: 0.00046853
Epoch [148/300], Train Loss: 0.000539
Validation Loss: 0.00047210
Epoch [149/300], Train Loss: 0.000531
Validation Loss: 0.00047127
Epoch [150/300], Train Loss: 0.000542
Validation Loss: 0.00046900
Epoch [151/300], Train Loss: 0.000535
Validation Loss: 0.00046218
Epoch [152/300], Train Loss: 0.000532
Validation Loss: 0.00046642
Epoch [153/300], Train Loss: 0.000533
Validation Loss: 0.00045760
Epoch [154/300], Train Loss: 0.000542
Validation Loss: 0.00051823
Epoch [155/300], Train Loss: 0.000574
Validation Loss: 0.00049189
Epoch [156/300], Train Loss: 0.000552
Validation Loss: 0.00047815
Epoch [157/300], Train Loss: 0.000549
Validation Loss: 0.00046632
Epoch [158/300], Train Loss: 0.000547
Validation Loss: 0.00045973
Epoch [159/300], Train Loss: 0.000544
Validation Loss: 0.00045893
Epoch [160/300], Train Loss: 0.000545
Validation Loss: 0.00046675
Epoch [161/300], Train Loss: 0.000542
Validation Loss: 0.00047376
Epoch [162/300], Train Loss: 0.000536
Validation Loss: 0.00045985
Epoch [163/300], Train Loss: 0.000535
Validation Loss: 0.00044937
Epoch [164/300], Train Loss: 0.000538
Validation Loss: 0.00045483
Epoch [165/300], Train Loss: 0.000543
Validation Loss: 0.00045759
Epoch [166/300], Train Loss: 0.000531
Validation Loss: 0.00044213
Epoch [167/300], Train Loss: 0.000527
Validation Loss: 0.00044778
Epoch [168/300], Train Loss: 0.000530
Validation Loss: 0.00044246
Epoch [169/300], Train Loss: 0.000522
Validation Loss: 0.00043662
Epoch [170/300], Train Loss: 0.000519
Validation Loss: 0.00043003
Epoch [171/300], Train Loss: 0.000520
Validation Loss: 0.00044334
Epoch [172/300], Train Loss: 0.000516
Validation Loss: 0.00044082
Epoch [173/300], Train Loss: 0.000520
Validation Loss: 0.00042652
Epoch [174/300], Train Loss: 0.000529
Validation Loss: 0.00042493
Epoch [175/300], Train Loss: 0.000514
Validation Loss: 0.00041884
Epoch [176/300], Train Loss: 0.000515
Validation Loss: 0.00041262
Epoch [177/300], Train Loss: 0.000514
Validation Loss: 0.00041712
Epoch [178/300], Train Loss: 0.000519
Validation Loss: 0.00045251
Epoch [179/300], Train Loss: 0.000520
Validation Loss: 0.00042899
Epoch [180/300], Train Loss: 0.000522
Validation Loss: 0.00043445
Epoch [181/300], Train Loss: 0.000560
Validation Loss: 0.00047631
Epoch [182/300], Train Loss: 0.000564
Validation Loss: 0.00044986
Epoch [183/300], Train Loss: 0.000535
Validation Loss: 0.00045177
Epoch [184/300], Train Loss: 0.000535
Validation Loss: 0.00044531
Epoch [185/300], Train Loss: 0.000522
Validation Loss: 0.00044273
Epoch [186/300], Train Loss: 0.000526
Validation Loss: 0.00044199
Early stopping triggered

Evaluating model for: Coffee Machine
Run 23/72 completed in 927.66 seconds with: {'MAE': np.float32(5.7098346), 'MSE': np.float32(2602.144), 'RMSE': np.float32(51.011215), 'SAE': np.float32(0.20868896), 'NDE': np.float32(0.7755759)}

Run 24/72: hidden=128, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Coffee Machine
Dataset length: 2980 windows

Epoch [1/300], Train Loss: 0.002082
Validation Loss: 0.00102368
Epoch [2/300], Train Loss: 0.001030
Validation Loss: 0.00094660
Epoch [3/300], Train Loss: 0.001009
Validation Loss: 0.00092645
Epoch [4/300], Train Loss: 0.001005
Validation Loss: 0.00092199
Epoch [5/300], Train Loss: 0.001005
Validation Loss: 0.00092203
Epoch [6/300], Train Loss: 0.001001
Validation Loss: 0.00092203
Epoch [7/300], Train Loss: 0.001001
Validation Loss: 0.00092186
Epoch [8/300], Train Loss: 0.001004
Validation Loss: 0.00092188
Epoch [9/300], Train Loss: 0.001008
Validation Loss: 0.00092187
Epoch [10/300], Train Loss: 0.001007
Validation Loss: 0.00092168
Epoch [11/300], Train Loss: 0.000990
Validation Loss: 0.00092182
Epoch [12/300], Train Loss: 0.000998
Validation Loss: 0.00092161
Epoch [13/300], Train Loss: 0.000999
Validation Loss: 0.00092154
Epoch [14/300], Train Loss: 0.001001
Validation Loss: 0.00092146
Epoch [15/300], Train Loss: 0.000986
Validation Loss: 0.00092156
Epoch [16/300], Train Loss: 0.000994
Validation Loss: 0.00092130
Epoch [17/300], Train Loss: 0.000999
Validation Loss: 0.00092122
Epoch [18/300], Train Loss: 0.000995
Validation Loss: 0.00092122
Epoch [19/300], Train Loss: 0.000995
Validation Loss: 0.00092107
Epoch [20/300], Train Loss: 0.000983
Validation Loss: 0.00092108
Epoch [21/300], Train Loss: 0.000994
Validation Loss: 0.00092082
Epoch [22/300], Train Loss: 0.000980
Validation Loss: 0.00092072
Epoch [23/300], Train Loss: 0.000993
Validation Loss: 0.00092078
Epoch [24/300], Train Loss: 0.000985
Validation Loss: 0.00092053
Epoch [25/300], Train Loss: 0.000987
Validation Loss: 0.00092049
Epoch [26/300], Train Loss: 0.000991
Validation Loss: 0.00092038
Epoch [27/300], Train Loss: 0.000989
Validation Loss: 0.00092042
Epoch [28/300], Train Loss: 0.000980
Validation Loss: 0.00092039
Epoch [29/300], Train Loss: 0.000988
Validation Loss: 0.00092031
Epoch [30/300], Train Loss: 0.000986
Validation Loss: 0.00092005
Epoch [31/300], Train Loss: 0.000983
Validation Loss: 0.00091999
Epoch [32/300], Train Loss: 0.000987
Validation Loss: 0.00092024
Epoch [33/300], Train Loss: 0.000987
Validation Loss: 0.00091991
Epoch [34/300], Train Loss: 0.000986
Validation Loss: 0.00091984
Epoch [35/300], Train Loss: 0.000981
Validation Loss: 0.00091980
Epoch [36/300], Train Loss: 0.000994
Validation Loss: 0.00091978
Epoch [37/300], Train Loss: 0.001003
Validation Loss: 0.00092076
Epoch [38/300], Train Loss: 0.000988
Validation Loss: 0.00091974
Epoch [39/300], Train Loss: 0.000992
Validation Loss: 0.00091965
Epoch [40/300], Train Loss: 0.000986
Validation Loss: 0.00092062
Epoch [41/300], Train Loss: 0.000991
Validation Loss: 0.00091951
Epoch [42/300], Train Loss: 0.000995
Validation Loss: 0.00091978
Epoch [43/300], Train Loss: 0.000992
Validation Loss: 0.00091936
Epoch [44/300], Train Loss: 0.000982
Validation Loss: 0.00091933
Epoch [45/300], Train Loss: 0.000978
Validation Loss: 0.00091928
Epoch [46/300], Train Loss: 0.000987
Validation Loss: 0.00091935
Epoch [47/300], Train Loss: 0.000988
Validation Loss: 0.00091943
Epoch [48/300], Train Loss: 0.000985
Validation Loss: 0.00091959
Epoch [49/300], Train Loss: 0.000983
Validation Loss: 0.00091911
Epoch [50/300], Train Loss: 0.000985
Validation Loss: 0.00091916
Epoch [51/300], Train Loss: 0.000989
Validation Loss: 0.00091956
Epoch [52/300], Train Loss: 0.000982
Validation Loss: 0.00091905
Epoch [53/300], Train Loss: 0.000984
Validation Loss: 0.00091893
Epoch [54/300], Train Loss: 0.000991
Validation Loss: 0.00091885
Epoch [55/300], Train Loss: 0.000981
Validation Loss: 0.00091892
Epoch [56/300], Train Loss: 0.000990
Validation Loss: 0.00091917
Epoch [57/300], Train Loss: 0.000996
Validation Loss: 0.00091918
Epoch [58/300], Train Loss: 0.000980
Validation Loss: 0.00091949
Epoch [59/300], Train Loss: 0.000983
Validation Loss: 0.00091870
Epoch [60/300], Train Loss: 0.000998
Validation Loss: 0.00091880
Epoch [61/300], Train Loss: 0.000984
Validation Loss: 0.00091911
Epoch [62/300], Train Loss: 0.000982
Validation Loss: 0.00091843
Epoch [63/300], Train Loss: 0.000985
Validation Loss: 0.00091838
Epoch [64/300], Train Loss: 0.000975
Validation Loss: 0.00091833
Epoch [65/300], Train Loss: 0.000990
Validation Loss: 0.00091883
Epoch [66/300], Train Loss: 0.000986
Validation Loss: 0.00091957
Epoch [67/300], Train Loss: 0.000985
Validation Loss: 0.00091823
Epoch [68/300], Train Loss: 0.000988
Validation Loss: 0.00091807
Epoch [69/300], Train Loss: 0.000989
Validation Loss: 0.00091800
Epoch [70/300], Train Loss: 0.000986
Validation Loss: 0.00091794
Epoch [71/300], Train Loss: 0.000976
Validation Loss: 0.00091799
Epoch [72/300], Train Loss: 0.000983
Validation Loss: 0.00091808
Epoch [73/300], Train Loss: 0.000981
Validation Loss: 0.00091791
Epoch [74/300], Train Loss: 0.000975
Validation Loss: 0.00091840
Epoch [75/300], Train Loss: 0.000984
Validation Loss: 0.00091792
Epoch [76/300], Train Loss: 0.000978
Validation Loss: 0.00091737
Epoch [77/300], Train Loss: 0.000989
Validation Loss: 0.00091731
Epoch [78/300], Train Loss: 0.000984
Validation Loss: 0.00091731
Epoch [79/300], Train Loss: 0.000984
Validation Loss: 0.00091704
Epoch [80/300], Train Loss: 0.000976
Validation Loss: 0.00091693
Epoch [81/300], Train Loss: 0.000981
Validation Loss: 0.00091686
Epoch [82/300], Train Loss: 0.000976
Validation Loss: 0.00091676
Epoch [83/300], Train Loss: 0.000982
Validation Loss: 0.00091734
Epoch [84/300], Train Loss: 0.000980
Validation Loss: 0.00091648
Epoch [85/300], Train Loss: 0.000994
Validation Loss: 0.00091739
Epoch [86/300], Train Loss: 0.000976
Validation Loss: 0.00091621
Epoch [87/300], Train Loss: 0.000982
Validation Loss: 0.00091617
Epoch [88/300], Train Loss: 0.000981
Validation Loss: 0.00091620
Epoch [89/300], Train Loss: 0.000980
Validation Loss: 0.00091563
Epoch [90/300], Train Loss: 0.000978
Validation Loss: 0.00091585
Epoch [91/300], Train Loss: 0.000981
Validation Loss: 0.00091468
Epoch [92/300], Train Loss: 0.000982
Validation Loss: 0.00091451
Epoch [93/300], Train Loss: 0.000976
Validation Loss: 0.00091420
Epoch [94/300], Train Loss: 0.000982
Validation Loss: 0.00091349
Epoch [95/300], Train Loss: 0.000966
Validation Loss: 0.00091306
Epoch [96/300], Train Loss: 0.000985
Validation Loss: 0.00091265
Epoch [97/300], Train Loss: 0.000974
Validation Loss: 0.00091232
Epoch [98/300], Train Loss: 0.000986
Validation Loss: 0.00091209
Epoch [99/300], Train Loss: 0.000971
Validation Loss: 0.00091183
Epoch [100/300], Train Loss: 0.000973
Validation Loss: 0.00091161
Epoch [101/300], Train Loss: 0.000978
Validation Loss: 0.00091132
Epoch [102/300], Train Loss: 0.000983
Validation Loss: 0.00091118
Epoch [103/300], Train Loss: 0.000978
Validation Loss: 0.00091141
Epoch [104/300], Train Loss: 0.000977
Validation Loss: 0.00091054
Epoch [105/300], Train Loss: 0.000974
Validation Loss: 0.00091059
Epoch [106/300], Train Loss: 0.000978
Validation Loss: 0.00091021
Epoch [107/300], Train Loss: 0.000979
Validation Loss: 0.00090984
Epoch [108/300], Train Loss: 0.000971
Validation Loss: 0.00090958
Epoch [109/300], Train Loss: 0.000978
Validation Loss: 0.00090965
Epoch [110/300], Train Loss: 0.000977
Validation Loss: 0.00090897
Epoch [111/300], Train Loss: 0.000972
Validation Loss: 0.00090874
Epoch [112/300], Train Loss: 0.000974
Validation Loss: 0.00090874
Epoch [113/300], Train Loss: 0.000975
Validation Loss: 0.00090857
Epoch [114/300], Train Loss: 0.000978
Validation Loss: 0.00090769
Epoch [115/300], Train Loss: 0.000974
Validation Loss: 0.00090728
Epoch [116/300], Train Loss: 0.000985
Validation Loss: 0.00090736
Epoch [117/300], Train Loss: 0.000974
Validation Loss: 0.00090633
Epoch [118/300], Train Loss: 0.000977
Validation Loss: 0.00090630
Epoch [119/300], Train Loss: 0.000973
Validation Loss: 0.00090515
Epoch [120/300], Train Loss: 0.000977
Validation Loss: 0.00090465
Epoch [121/300], Train Loss: 0.000969
Validation Loss: 0.00090397
Epoch [122/300], Train Loss: 0.000974
Validation Loss: 0.00090353
Epoch [123/300], Train Loss: 0.000969
Validation Loss: 0.00090275
Epoch [124/300], Train Loss: 0.000979
Validation Loss: 0.00090180
Epoch [125/300], Train Loss: 0.000962
Validation Loss: 0.00090085
Epoch [126/300], Train Loss: 0.000972
Validation Loss: 0.00089983
Epoch [127/300], Train Loss: 0.000964
Validation Loss: 0.00089866
Epoch [128/300], Train Loss: 0.000961
Validation Loss: 0.00089734
Epoch [129/300], Train Loss: 0.000966
Validation Loss: 0.00089605
Epoch [130/300], Train Loss: 0.000957
Validation Loss: 0.00089579
Epoch [131/300], Train Loss: 0.000961
Validation Loss: 0.00089331
Epoch [132/300], Train Loss: 0.000969
Validation Loss: 0.00089195
Epoch [133/300], Train Loss: 0.000963
Validation Loss: 0.00088993
Epoch [134/300], Train Loss: 0.000958
Validation Loss: 0.00088799
Epoch [135/300], Train Loss: 0.000958
Validation Loss: 0.00088654
Epoch [136/300], Train Loss: 0.000954
Validation Loss: 0.00088478
Epoch [137/300], Train Loss: 0.000957
Validation Loss: 0.00088258
Epoch [138/300], Train Loss: 0.000952
Validation Loss: 0.00088079
Epoch [139/300], Train Loss: 0.000948
Validation Loss: 0.00087875
Epoch [140/300], Train Loss: 0.000945
Validation Loss: 0.00087595
Epoch [141/300], Train Loss: 0.000949
Validation Loss: 0.00087358
Epoch [142/300], Train Loss: 0.000944
Validation Loss: 0.00087132
Epoch [143/300], Train Loss: 0.000946
Validation Loss: 0.00086810
Epoch [144/300], Train Loss: 0.000931
Validation Loss: 0.00086495
Epoch [145/300], Train Loss: 0.000933
Validation Loss: 0.00086086
Epoch [146/300], Train Loss: 0.000935
Validation Loss: 0.00085740
Epoch [147/300], Train Loss: 0.000932
Validation Loss: 0.00085278
Epoch [148/300], Train Loss: 0.000926
Validation Loss: 0.00084907
Epoch [149/300], Train Loss: 0.000917
Validation Loss: 0.00084349
Epoch [150/300], Train Loss: 0.000913
Validation Loss: 0.00083789
Epoch [151/300], Train Loss: 0.000919
Validation Loss: 0.00083185
Epoch [152/300], Train Loss: 0.000906
Validation Loss: 0.00082486
Epoch [153/300], Train Loss: 0.000899
Validation Loss: 0.00081850
Epoch [154/300], Train Loss: 0.000897
Validation Loss: 0.00081247
Epoch [155/300], Train Loss: 0.000888
Validation Loss: 0.00080688
Epoch [156/300], Train Loss: 0.000885
Validation Loss: 0.00079831
Epoch [157/300], Train Loss: 0.000880
Validation Loss: 0.00079129
Epoch [158/300], Train Loss: 0.000878
Validation Loss: 0.00078109
Epoch [159/300], Train Loss: 0.000869
Validation Loss: 0.00077555
Epoch [160/300], Train Loss: 0.000853
Validation Loss: 0.00077007
Epoch [161/300], Train Loss: 0.000850
Validation Loss: 0.00075861
Epoch [162/300], Train Loss: 0.000838
Validation Loss: 0.00075239
Epoch [163/300], Train Loss: 0.000831
Validation Loss: 0.00074330
Epoch [164/300], Train Loss: 0.000826
Validation Loss: 0.00073767
Epoch [165/300], Train Loss: 0.000816
Validation Loss: 0.00072852
Epoch [166/300], Train Loss: 0.000808
Validation Loss: 0.00072292
Epoch [167/300], Train Loss: 0.000804
Validation Loss: 0.00071428
Epoch [168/300], Train Loss: 0.000802
Validation Loss: 0.00070861
Epoch [169/300], Train Loss: 0.000796
Validation Loss: 0.00070274
Epoch [170/300], Train Loss: 0.000784
Validation Loss: 0.00069606
Epoch [171/300], Train Loss: 0.000784
Validation Loss: 0.00068575
Epoch [172/300], Train Loss: 0.000773
Validation Loss: 0.00068061
Epoch [173/300], Train Loss: 0.000768
Validation Loss: 0.00067719
Epoch [174/300], Train Loss: 0.000772
Validation Loss: 0.00066829
Epoch [175/300], Train Loss: 0.000756
Validation Loss: 0.00067211
Epoch [176/300], Train Loss: 0.000755
Validation Loss: 0.00066227
Epoch [177/300], Train Loss: 0.000757
Validation Loss: 0.00066304
Epoch [178/300], Train Loss: 0.000751
Validation Loss: 0.00065201
Epoch [179/300], Train Loss: 0.000739
Validation Loss: 0.00064587
Epoch [180/300], Train Loss: 0.000741
Validation Loss: 0.00063817
Epoch [181/300], Train Loss: 0.000734
Validation Loss: 0.00064026
Epoch [182/300], Train Loss: 0.000727
Validation Loss: 0.00062892
Epoch [183/300], Train Loss: 0.000734
Validation Loss: 0.00063630
Epoch [184/300], Train Loss: 0.000732
Validation Loss: 0.00061860
Epoch [185/300], Train Loss: 0.000709
Validation Loss: 0.00061768
Epoch [186/300], Train Loss: 0.000714
Validation Loss: 0.00061319
Epoch [187/300], Train Loss: 0.000706
Validation Loss: 0.00060580
Epoch [188/300], Train Loss: 0.000710
Validation Loss: 0.00062375
Epoch [189/300], Train Loss: 0.000717
Validation Loss: 0.00061842
Epoch [190/300], Train Loss: 0.000710
Validation Loss: 0.00059568
Epoch [191/300], Train Loss: 0.000690
Validation Loss: 0.00059391
Epoch [192/300], Train Loss: 0.000691
Validation Loss: 0.00058978
Epoch [193/300], Train Loss: 0.000698
Validation Loss: 0.00059411
Epoch [194/300], Train Loss: 0.000695
Validation Loss: 0.00058627
Epoch [195/300], Train Loss: 0.000696
Validation Loss: 0.00059954
Epoch [196/300], Train Loss: 0.000706
Validation Loss: 0.00059003
Epoch [197/300], Train Loss: 0.000696
Validation Loss: 0.00058486
Epoch [198/300], Train Loss: 0.000680
Validation Loss: 0.00057939
Epoch [199/300], Train Loss: 0.000673
Validation Loss: 0.00057782
Epoch [200/300], Train Loss: 0.000674
Validation Loss: 0.00057085
Epoch [201/300], Train Loss: 0.000670
Validation Loss: 0.00057003
Epoch [202/300], Train Loss: 0.000676
Validation Loss: 0.00056406
Epoch [203/300], Train Loss: 0.000663
Validation Loss: 0.00055965
Epoch [204/300], Train Loss: 0.000661
Validation Loss: 0.00056274
Epoch [205/300], Train Loss: 0.000665
Validation Loss: 0.00055794
Epoch [206/300], Train Loss: 0.000663
Validation Loss: 0.00055611
Epoch [207/300], Train Loss: 0.000668
Validation Loss: 0.00055580
Epoch [208/300], Train Loss: 0.000659
Validation Loss: 0.00054989
Epoch [209/300], Train Loss: 0.000657
Validation Loss: 0.00055587
Epoch [210/300], Train Loss: 0.000663
Validation Loss: 0.00054861
Epoch [211/300], Train Loss: 0.000653
Validation Loss: 0.00054999
Epoch [212/300], Train Loss: 0.000655
Validation Loss: 0.00054050
Epoch [213/300], Train Loss: 0.000658
Validation Loss: 0.00055266
Epoch [214/300], Train Loss: 0.000655
Validation Loss: 0.00053778
Epoch [215/300], Train Loss: 0.000646
Validation Loss: 0.00053808
Epoch [216/300], Train Loss: 0.000647
Validation Loss: 0.00053707
Epoch [217/300], Train Loss: 0.000643
Validation Loss: 0.00054993
Epoch [218/300], Train Loss: 0.000638
Validation Loss: 0.00052870
Epoch [219/300], Train Loss: 0.000639
Validation Loss: 0.00052787
Epoch [220/300], Train Loss: 0.000639
Validation Loss: 0.00053273
Epoch [221/300], Train Loss: 0.000643
Validation Loss: 0.00052984
Epoch [222/300], Train Loss: 0.000635
Validation Loss: 0.00052428
Epoch [223/300], Train Loss: 0.000643
Validation Loss: 0.00052283
Epoch [224/300], Train Loss: 0.000635
Validation Loss: 0.00052336
Epoch [225/300], Train Loss: 0.000635
Validation Loss: 0.00052516
Epoch [226/300], Train Loss: 0.000636
Validation Loss: 0.00051859
Epoch [227/300], Train Loss: 0.000628
Validation Loss: 0.00051726
Epoch [228/300], Train Loss: 0.000625
Validation Loss: 0.00051743
Epoch [229/300], Train Loss: 0.000626
Validation Loss: 0.00051384
Epoch [230/300], Train Loss: 0.000625
Validation Loss: 0.00051292
Epoch [231/300], Train Loss: 0.000633
Validation Loss: 0.00051286
Epoch [232/300], Train Loss: 0.000626
Validation Loss: 0.00051927
Epoch [233/300], Train Loss: 0.000620
Validation Loss: 0.00050830
Epoch [234/300], Train Loss: 0.000632
Validation Loss: 0.00050652
Epoch [235/300], Train Loss: 0.000626
Validation Loss: 0.00051053
Epoch [236/300], Train Loss: 0.000628
Validation Loss: 0.00051114
Epoch [237/300], Train Loss: 0.000622
Validation Loss: 0.00050915
Epoch [238/300], Train Loss: 0.000622
Validation Loss: 0.00049976
Epoch [239/300], Train Loss: 0.000625
Validation Loss: 0.00050895
Epoch [240/300], Train Loss: 0.000619
Validation Loss: 0.00050406
Epoch [241/300], Train Loss: 0.000619
Validation Loss: 0.00050151
Epoch [242/300], Train Loss: 0.000607
Validation Loss: 0.00050546
Epoch [243/300], Train Loss: 0.000610
Validation Loss: 0.00051011
Epoch [244/300], Train Loss: 0.000610
Validation Loss: 0.00050627
Epoch [245/300], Train Loss: 0.000616
Validation Loss: 0.00050678
Epoch [246/300], Train Loss: 0.000609
Validation Loss: 0.00050214
Epoch [247/300], Train Loss: 0.000604
Validation Loss: 0.00050001
Epoch [248/300], Train Loss: 0.000598
Validation Loss: 0.00049808
Epoch [249/300], Train Loss: 0.000608
Validation Loss: 0.00049932
Epoch [250/300], Train Loss: 0.000605
Validation Loss: 0.00050466
Epoch [251/300], Train Loss: 0.000609
Validation Loss: 0.00049306
Epoch [252/300], Train Loss: 0.000610
Validation Loss: 0.00049298
Epoch [253/300], Train Loss: 0.000610
Validation Loss: 0.00049565
Epoch [254/300], Train Loss: 0.000610
Validation Loss: 0.00049640
Epoch [255/300], Train Loss: 0.000606
Validation Loss: 0.00049335
Epoch [256/300], Train Loss: 0.000602
Validation Loss: 0.00049121
Epoch [257/300], Train Loss: 0.000596
Validation Loss: 0.00049288
Epoch [258/300], Train Loss: 0.000599
Validation Loss: 0.00049208
Epoch [259/300], Train Loss: 0.000594
Validation Loss: 0.00048997
Epoch [260/300], Train Loss: 0.000600
Validation Loss: 0.00049444
Epoch [261/300], Train Loss: 0.000593
Validation Loss: 0.00049538
Epoch [262/300], Train Loss: 0.000596
Validation Loss: 0.00049476
Epoch [263/300], Train Loss: 0.000593
Validation Loss: 0.00048585
Epoch [264/300], Train Loss: 0.000593
Validation Loss: 0.00048574
Epoch [265/300], Train Loss: 0.000603
Validation Loss: 0.00048422
Epoch [266/300], Train Loss: 0.000594
Validation Loss: 0.00049369
Epoch [267/300], Train Loss: 0.000596
Validation Loss: 0.00048951
Epoch [268/300], Train Loss: 0.000597
Validation Loss: 0.00049057
Epoch [269/300], Train Loss: 0.000588
Validation Loss: 0.00050558
Epoch [270/300], Train Loss: 0.000607
Validation Loss: 0.00049029
Epoch [271/300], Train Loss: 0.000595
Validation Loss: 0.00048458
Epoch [272/300], Train Loss: 0.000586
Validation Loss: 0.00048218
Epoch [273/300], Train Loss: 0.000589
Validation Loss: 0.00049000
Epoch [274/300], Train Loss: 0.000589
Validation Loss: 0.00049437
Epoch [275/300], Train Loss: 0.000600
Validation Loss: 0.00048063
Epoch [276/300], Train Loss: 0.000593
Validation Loss: 0.00048371
Epoch [277/300], Train Loss: 0.000585
Validation Loss: 0.00048296
Epoch [278/300], Train Loss: 0.000585
Validation Loss: 0.00048348
Epoch [279/300], Train Loss: 0.000584
Validation Loss: 0.00048608
Epoch [280/300], Train Loss: 0.000592
Validation Loss: 0.00048171
Epoch [281/300], Train Loss: 0.000590
Validation Loss: 0.00048019
Epoch [282/300], Train Loss: 0.000578
Validation Loss: 0.00047576
Epoch [283/300], Train Loss: 0.000586
Validation Loss: 0.00049139
Epoch [284/300], Train Loss: 0.000588
Validation Loss: 0.00047980
Epoch [285/300], Train Loss: 0.000586
Validation Loss: 0.00047658
Epoch [286/300], Train Loss: 0.000580
Validation Loss: 0.00047977
Epoch [287/300], Train Loss: 0.000582
Validation Loss: 0.00048570
Epoch [288/300], Train Loss: 0.000578
Validation Loss: 0.00048132
Epoch [289/300], Train Loss: 0.000579
Validation Loss: 0.00048543
Epoch [290/300], Train Loss: 0.000589
Validation Loss: 0.00048034
Epoch [291/300], Train Loss: 0.000579
Validation Loss: 0.00048225
Epoch [292/300], Train Loss: 0.000578
Validation Loss: 0.00048339
Early stopping triggered

Evaluating model for: Coffee Machine
Run 24/72 completed in 1526.06 seconds with: {'MAE': np.float32(6.341186), 'MSE': np.float32(2754.854), 'RMSE': np.float32(52.486702), 'SAE': np.float32(0.23398681), 'NDE': np.float32(0.79801)}

Run 25/72: hidden=256, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Coffee Machine
Dataset length: 36156 windows

Epoch [1/300], Train Loss: 0.001048
Validation Loss: 0.00095814
Epoch [2/300], Train Loss: 0.000990
Validation Loss: 0.00094565
Epoch [3/300], Train Loss: 0.000974
Validation Loss: 0.00093086
Epoch [4/300], Train Loss: 0.000959
Validation Loss: 0.00091322
Epoch [5/300], Train Loss: 0.000931
Validation Loss: 0.00088270
Epoch [6/300], Train Loss: 0.000859
Validation Loss: 0.00077878
Epoch [7/300], Train Loss: 0.000764
Validation Loss: 0.00072276
Epoch [8/300], Train Loss: 0.000709
Validation Loss: 0.00068628
Epoch [9/300], Train Loss: 0.000674
Validation Loss: 0.00065650
Epoch [10/300], Train Loss: 0.000639
Validation Loss: 0.00062545
Epoch [11/300], Train Loss: 0.000619
Validation Loss: 0.00060372
Epoch [12/300], Train Loss: 0.000596
Validation Loss: 0.00060568
Epoch [13/300], Train Loss: 0.000573
Validation Loss: 0.00058448
Epoch [14/300], Train Loss: 0.000554
Validation Loss: 0.00056613
Epoch [15/300], Train Loss: 0.000533
Validation Loss: 0.00052685
Epoch [16/300], Train Loss: 0.000514
Validation Loss: 0.00052883
Epoch [17/300], Train Loss: 0.000506
Validation Loss: 0.00049968
Epoch [18/300], Train Loss: 0.000476
Validation Loss: 0.00045262
Epoch [19/300], Train Loss: 0.000456
Validation Loss: 0.00045667
Epoch [20/300], Train Loss: 0.000434
Validation Loss: 0.00039933
Epoch [21/300], Train Loss: 0.000416
Validation Loss: 0.00040046
Epoch [22/300], Train Loss: 0.000404
Validation Loss: 0.00037742
Epoch [23/300], Train Loss: 0.000386
Validation Loss: 0.00034999
Epoch [24/300], Train Loss: 0.000372
Validation Loss: 0.00037154
Epoch [25/300], Train Loss: 0.000367
Validation Loss: 0.00032761
Epoch [26/300], Train Loss: 0.000347
Validation Loss: 0.00033385
Epoch [27/300], Train Loss: 0.000342
Validation Loss: 0.00033337
Epoch [28/300], Train Loss: 0.000334
Validation Loss: 0.00029364
Epoch [29/300], Train Loss: 0.000322
Validation Loss: 0.00030313
Epoch [30/300], Train Loss: 0.000316
Validation Loss: 0.00028360
Epoch [31/300], Train Loss: 0.000308
Validation Loss: 0.00027390
Epoch [32/300], Train Loss: 0.000301
Validation Loss: 0.00027393
Epoch [33/300], Train Loss: 0.000296
Validation Loss: 0.00024636
Epoch [34/300], Train Loss: 0.000300
Validation Loss: 0.00027229
Epoch [35/300], Train Loss: 0.000284
Validation Loss: 0.00025789
Epoch [36/300], Train Loss: 0.000283
Validation Loss: 0.00024287
Epoch [37/300], Train Loss: 0.000278
Validation Loss: 0.00024468
Epoch [38/300], Train Loss: 0.000271
Validation Loss: 0.00024181
Epoch [39/300], Train Loss: 0.000265
Validation Loss: 0.00022336
Epoch [40/300], Train Loss: 0.000268
Validation Loss: 0.00023194
Epoch [41/300], Train Loss: 0.000270
Validation Loss: 0.00024743
Epoch [42/300], Train Loss: 0.000262
Validation Loss: 0.00022130
Epoch [43/300], Train Loss: 0.000261
Validation Loss: 0.00022906
Epoch [44/300], Train Loss: 0.000253
Validation Loss: 0.00025810
Epoch [45/300], Train Loss: 0.000248
Validation Loss: 0.00022137
Epoch [46/300], Train Loss: 0.000245
Validation Loss: 0.00023354
Epoch [47/300], Train Loss: 0.000249
Validation Loss: 0.00021870
Epoch [48/300], Train Loss: 0.000240
Validation Loss: 0.00021435
Epoch [49/300], Train Loss: 0.000234
Validation Loss: 0.00020819
Epoch [50/300], Train Loss: 0.000234
Validation Loss: 0.00020185
Epoch [51/300], Train Loss: 0.000228
Validation Loss: 0.00021685
Epoch [52/300], Train Loss: 0.000227
Validation Loss: 0.00020853
Epoch [53/300], Train Loss: 0.000235
Validation Loss: 0.00024313
Epoch [54/300], Train Loss: 0.000233
Validation Loss: 0.00019945
Epoch [55/300], Train Loss: 0.000225
Validation Loss: 0.00020346
Epoch [56/300], Train Loss: 0.000220
Validation Loss: 0.00021312
Epoch [57/300], Train Loss: 0.000218
Validation Loss: 0.00020221
Epoch [58/300], Train Loss: 0.000215
Validation Loss: 0.00019689
Epoch [59/300], Train Loss: 0.000222
Validation Loss: 0.00019374
Epoch [60/300], Train Loss: 0.000214
Validation Loss: 0.00018621
Epoch [61/300], Train Loss: 0.000210
Validation Loss: 0.00019416
Epoch [62/300], Train Loss: 0.000211
Validation Loss: 0.00018734
Epoch [63/300], Train Loss: 0.000211
Validation Loss: 0.00019756
Epoch [64/300], Train Loss: 0.000209
Validation Loss: 0.00018401
Epoch [65/300], Train Loss: 0.000222
Validation Loss: 0.00024704
Epoch [66/300], Train Loss: 0.000217
Validation Loss: 0.00018982
Epoch [67/300], Train Loss: 0.000207
Validation Loss: 0.00018158
Epoch [68/300], Train Loss: 0.000203
Validation Loss: 0.00018149
Epoch [69/300], Train Loss: 0.000203
Validation Loss: 0.00017571
Epoch [70/300], Train Loss: 0.000199
Validation Loss: 0.00018091
Epoch [71/300], Train Loss: 0.000198
Validation Loss: 0.00018365
Epoch [72/300], Train Loss: 0.000198
Validation Loss: 0.00017257
Epoch [73/300], Train Loss: 0.000194
Validation Loss: 0.00016972
Epoch [74/300], Train Loss: 0.000193
Validation Loss: 0.00017772
Epoch [75/300], Train Loss: 0.000190
Validation Loss: 0.00017135
Epoch [76/300], Train Loss: 0.000185
Validation Loss: 0.00017101
Epoch [77/300], Train Loss: 0.000186
Validation Loss: 0.00016615
Epoch [78/300], Train Loss: 0.000188
Validation Loss: 0.00018237
Epoch [79/300], Train Loss: 0.000195
Validation Loss: 0.00016590
Epoch [80/300], Train Loss: 0.000183
Validation Loss: 0.00016944
Epoch [81/300], Train Loss: 0.000184
Validation Loss: 0.00017336
Epoch [82/300], Train Loss: 0.000184
Validation Loss: 0.00016548
Epoch [83/300], Train Loss: 0.000178
Validation Loss: 0.00016572
Epoch [84/300], Train Loss: 0.000179
Validation Loss: 0.00016986
Epoch [85/300], Train Loss: 0.000178
Validation Loss: 0.00016125
Epoch [86/300], Train Loss: 0.000175
Validation Loss: 0.00016185
Epoch [87/300], Train Loss: 0.000175
Validation Loss: 0.00016189
Epoch [88/300], Train Loss: 0.000175
Validation Loss: 0.00017032
Epoch [89/300], Train Loss: 0.000176
Validation Loss: 0.00017642
Epoch [90/300], Train Loss: 0.000172
Validation Loss: 0.00017921
Epoch [91/300], Train Loss: 0.000175
Validation Loss: 0.00015878
Epoch [92/300], Train Loss: 0.000168
Validation Loss: 0.00016073
Epoch [93/300], Train Loss: 0.000168
Validation Loss: 0.00015506
Epoch [94/300], Train Loss: 0.000166
Validation Loss: 0.00015712
Epoch [95/300], Train Loss: 0.000167
Validation Loss: 0.00015678
Epoch [96/300], Train Loss: 0.000165
Validation Loss: 0.00015689
Epoch [97/300], Train Loss: 0.000163
Validation Loss: 0.00015757
Epoch [98/300], Train Loss: 0.000165
Validation Loss: 0.00016857
Epoch [99/300], Train Loss: 0.000178
Validation Loss: 0.00015890
Epoch [100/300], Train Loss: 0.000180
Validation Loss: 0.00017632
Epoch [101/300], Train Loss: 0.000178
Validation Loss: 0.00016237
Epoch [102/300], Train Loss: 0.000165
Validation Loss: 0.00014458
Epoch [103/300], Train Loss: 0.000161
Validation Loss: 0.00014170
Epoch [104/300], Train Loss: 0.000159
Validation Loss: 0.00014805
Epoch [105/300], Train Loss: 0.000159
Validation Loss: 0.00014142
Epoch [106/300], Train Loss: 0.000158
Validation Loss: 0.00014593
Epoch [107/300], Train Loss: 0.000156
Validation Loss: 0.00014348
Epoch [108/300], Train Loss: 0.000156
Validation Loss: 0.00014907
Epoch [109/300], Train Loss: 0.000155
Validation Loss: 0.00015044
Epoch [110/300], Train Loss: 0.000160
Validation Loss: 0.00014794
Epoch [111/300], Train Loss: 0.000154
Validation Loss: 0.00014363
Epoch [112/300], Train Loss: 0.000154
Validation Loss: 0.00014860
Epoch [113/300], Train Loss: 0.000153
Validation Loss: 0.00014094
Epoch [114/300], Train Loss: 0.000153
Validation Loss: 0.00014079
Epoch [115/300], Train Loss: 0.000154
Validation Loss: 0.00013974
Epoch [116/300], Train Loss: 0.000150
Validation Loss: 0.00013846
Epoch [117/300], Train Loss: 0.000151
Validation Loss: 0.00013748
Epoch [118/300], Train Loss: 0.000151
Validation Loss: 0.00014113
Epoch [119/300], Train Loss: 0.000152
Validation Loss: 0.00013950
Epoch [120/300], Train Loss: 0.000149
Validation Loss: 0.00013916
Epoch [121/300], Train Loss: 0.000147
Validation Loss: 0.00014237
Epoch [122/300], Train Loss: 0.000146
Validation Loss: 0.00014179
Epoch [123/300], Train Loss: 0.000145
Validation Loss: 0.00013831
Epoch [124/300], Train Loss: 0.000145
Validation Loss: 0.00013853
Epoch [125/300], Train Loss: 0.000144
Validation Loss: 0.00013432
Epoch [126/300], Train Loss: 0.000143
Validation Loss: 0.00013288
Epoch [127/300], Train Loss: 0.000143
Validation Loss: 0.00013823
Epoch [128/300], Train Loss: 0.000143
Validation Loss: 0.00013727
Epoch [129/300], Train Loss: 0.000143
Validation Loss: 0.00013754
Epoch [130/300], Train Loss: 0.000141
Validation Loss: 0.00013740
Epoch [131/300], Train Loss: 0.000140
Validation Loss: 0.00013245
Epoch [132/300], Train Loss: 0.000139
Validation Loss: 0.00013327
Epoch [133/300], Train Loss: 0.000137
Validation Loss: 0.00013607
Epoch [134/300], Train Loss: 0.000138
Validation Loss: 0.00013143
Epoch [135/300], Train Loss: 0.000138
Validation Loss: 0.00013426
Epoch [136/300], Train Loss: 0.000136
Validation Loss: 0.00013283
Epoch [137/300], Train Loss: 0.000136
Validation Loss: 0.00013391
Epoch [138/300], Train Loss: 0.000136
Validation Loss: 0.00013142
Epoch [139/300], Train Loss: 0.000137
Validation Loss: 0.00013510
Epoch [140/300], Train Loss: 0.000134
Validation Loss: 0.00013188
Epoch [141/300], Train Loss: 0.000134
Validation Loss: 0.00012875
Epoch [142/300], Train Loss: 0.000134
Validation Loss: 0.00013543
Epoch [143/300], Train Loss: 0.000141
Validation Loss: 0.00013219
Epoch [144/300], Train Loss: 0.000132
Validation Loss: 0.00012597
Epoch [145/300], Train Loss: 0.000132
Validation Loss: 0.00013252
Epoch [146/300], Train Loss: 0.000132
Validation Loss: 0.00013158
Epoch [147/300], Train Loss: 0.000130
Validation Loss: 0.00013787
Epoch [148/300], Train Loss: 0.000130
Validation Loss: 0.00012945
Epoch [149/300], Train Loss: 0.000128
Validation Loss: 0.00013623
Epoch [150/300], Train Loss: 0.000129
Validation Loss: 0.00012776
Epoch [151/300], Train Loss: 0.000134
Validation Loss: 0.00012721
Epoch [152/300], Train Loss: 0.000128
Validation Loss: 0.00013114
Epoch [153/300], Train Loss: 0.000127
Validation Loss: 0.00013038
Epoch [154/300], Train Loss: 0.000127
Validation Loss: 0.00012719
Early stopping triggered

Evaluating model for: Coffee Machine
Run 25/72 completed in 8192.99 seconds with: {'MAE': np.float32(2.6920323), 'MSE': np.float32(579.67145), 'RMSE': np.float32(24.076366), 'SAE': np.float32(0.0358071), 'NDE': np.float32(0.38901526)}

Run 26/72: hidden=256, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Coffee Machine
Dataset length: 36156 windows

Epoch [1/300], Train Loss: 0.001011
Validation Loss: 0.00095307
Epoch [2/300], Train Loss: 0.000985
Validation Loss: 0.00094736
Epoch [3/300], Train Loss: 0.000976
Validation Loss: 0.00093390
Epoch [4/300], Train Loss: 0.000957
Validation Loss: 0.00090716
Epoch [5/300], Train Loss: 0.000895
Validation Loss: 0.00081258
Epoch [6/300], Train Loss: 0.000771
Validation Loss: 0.00071386
Epoch [7/300], Train Loss: 0.000682
Validation Loss: 0.00066188
Epoch [8/300], Train Loss: 0.000638
Validation Loss: 0.00064745
Epoch [9/300], Train Loss: 0.000609
Validation Loss: 0.00060597
Epoch [10/300], Train Loss: 0.000571
Validation Loss: 0.00056600
Epoch [11/300], Train Loss: 0.000557
Validation Loss: 0.00055927
Epoch [12/300], Train Loss: 0.000542
Validation Loss: 0.00059285
Epoch [13/300], Train Loss: 0.000530
Validation Loss: 0.00052409
Epoch [14/300], Train Loss: 0.000513
Validation Loss: 0.00051631
Epoch [15/300], Train Loss: 0.000499
Validation Loss: 0.00049500
Epoch [16/300], Train Loss: 0.000483
Validation Loss: 0.00049531
Epoch [17/300], Train Loss: 0.000473
Validation Loss: 0.00045795
Epoch [18/300], Train Loss: 0.000458
Validation Loss: 0.00044263
Epoch [19/300], Train Loss: 0.000443
Validation Loss: 0.00044511
Epoch [20/300], Train Loss: 0.000426
Validation Loss: 0.00041117
Epoch [21/300], Train Loss: 0.000408
Validation Loss: 0.00038993
Epoch [22/300], Train Loss: 0.000394
Validation Loss: 0.00035929
Epoch [23/300], Train Loss: 0.000378
Validation Loss: 0.00035246
Epoch [24/300], Train Loss: 0.000359
Validation Loss: 0.00034133
Epoch [25/300], Train Loss: 0.000345
Validation Loss: 0.00031839
Epoch [26/300], Train Loss: 0.000335
Validation Loss: 0.00030861
Epoch [27/300], Train Loss: 0.000330
Validation Loss: 0.00032549
Epoch [28/300], Train Loss: 0.000318
Validation Loss: 0.00029657
Epoch [29/300], Train Loss: 0.000309
Validation Loss: 0.00027645
Epoch [30/300], Train Loss: 0.000302
Validation Loss: 0.00027318
Epoch [31/300], Train Loss: 0.000292
Validation Loss: 0.00026824
Epoch [32/300], Train Loss: 0.000287
Validation Loss: 0.00027299
Epoch [33/300], Train Loss: 0.000282
Validation Loss: 0.00024900
Epoch [34/300], Train Loss: 0.000274
Validation Loss: 0.00024811
Epoch [35/300], Train Loss: 0.000270
Validation Loss: 0.00024350
Epoch [36/300], Train Loss: 0.000263
Validation Loss: 0.00024543
Epoch [37/300], Train Loss: 0.000259
Validation Loss: 0.00022541
Epoch [38/300], Train Loss: 0.000254
Validation Loss: 0.00022922
Epoch [39/300], Train Loss: 0.000247
Validation Loss: 0.00021790
Epoch [40/300], Train Loss: 0.000279
Validation Loss: 0.00025517
Epoch [41/300], Train Loss: 0.000257
Validation Loss: 0.00023407
Epoch [42/300], Train Loss: 0.000242
Validation Loss: 0.00021973
Epoch [43/300], Train Loss: 0.000235
Validation Loss: 0.00020921
Epoch [44/300], Train Loss: 0.000237
Validation Loss: 0.00025397
Epoch [45/300], Train Loss: 0.000233
Validation Loss: 0.00021100
Epoch [46/300], Train Loss: 0.000224
Validation Loss: 0.00021868
Epoch [47/300], Train Loss: 0.000222
Validation Loss: 0.00019904
Epoch [48/300], Train Loss: 0.000217
Validation Loss: 0.00020022
Epoch [49/300], Train Loss: 0.000213
Validation Loss: 0.00019004
Epoch [50/300], Train Loss: 0.000212
Validation Loss: 0.00018324
Epoch [51/300], Train Loss: 0.000210
Validation Loss: 0.00018696
Epoch [52/300], Train Loss: 0.000209
Validation Loss: 0.00018942
Epoch [53/300], Train Loss: 0.000204
Validation Loss: 0.00017793
Epoch [54/300], Train Loss: 0.000208
Validation Loss: 0.00017477
Epoch [55/300], Train Loss: 0.000200
Validation Loss: 0.00018114
Epoch [56/300], Train Loss: 0.000201
Validation Loss: 0.00017542
Epoch [57/300], Train Loss: 0.000193
Validation Loss: 0.00017302
Epoch [58/300], Train Loss: 0.000210
Validation Loss: 0.00019629
Epoch [59/300], Train Loss: 0.000205
Validation Loss: 0.00018043
Epoch [60/300], Train Loss: 0.000194
Validation Loss: 0.00016856
Epoch [61/300], Train Loss: 0.000187
Validation Loss: 0.00016286
Epoch [62/300], Train Loss: 0.000200
Validation Loss: 0.00018432
Epoch [63/300], Train Loss: 0.000194
Validation Loss: 0.00016196
Epoch [64/300], Train Loss: 0.000181
Validation Loss: 0.00015765
Epoch [65/300], Train Loss: 0.000178
Validation Loss: 0.00015743
Epoch [66/300], Train Loss: 0.000188
Validation Loss: 0.00017078
Epoch [67/300], Train Loss: 0.000175
Validation Loss: 0.00015421
Epoch [68/300], Train Loss: 0.000174
Validation Loss: 0.00015554
Epoch [69/300], Train Loss: 0.000178
Validation Loss: 0.00016613
Epoch [70/300], Train Loss: 0.000173
Validation Loss: 0.00015730
Epoch [71/300], Train Loss: 0.000168
Validation Loss: 0.00015495
Epoch [72/300], Train Loss: 0.000168
Validation Loss: 0.00014671
Epoch [73/300], Train Loss: 0.000166
Validation Loss: 0.00015112
Epoch [74/300], Train Loss: 0.000170
Validation Loss: 0.00017475
Epoch [75/300], Train Loss: 0.000167
Validation Loss: 0.00014589
Epoch [76/300], Train Loss: 0.000162
Validation Loss: 0.00014391
Epoch [77/300], Train Loss: 0.000162
Validation Loss: 0.00014436
Epoch [78/300], Train Loss: 0.000160
Validation Loss: 0.00013933
Epoch [79/300], Train Loss: 0.000157
Validation Loss: 0.00014087
Epoch [80/300], Train Loss: 0.000157
Validation Loss: 0.00014686
Epoch [81/300], Train Loss: 0.000155
Validation Loss: 0.00014076
Epoch [82/300], Train Loss: 0.000157
Validation Loss: 0.00014412
Epoch [83/300], Train Loss: 0.000153
Validation Loss: 0.00013952
Epoch [84/300], Train Loss: 0.000150
Validation Loss: 0.00014190
Epoch [85/300], Train Loss: 0.000151
Validation Loss: 0.00013683
Epoch [86/300], Train Loss: 0.000150
Validation Loss: 0.00013370
Epoch [87/300], Train Loss: 0.000148
Validation Loss: 0.00013779
Epoch [88/300], Train Loss: 0.000150
Validation Loss: 0.00014088
Epoch [89/300], Train Loss: 0.000157
Validation Loss: 0.00014230
Epoch [90/300], Train Loss: 0.000151
Validation Loss: 0.00013777
Epoch [91/300], Train Loss: 0.000150
Validation Loss: 0.00013173
Epoch [92/300], Train Loss: 0.000141
Validation Loss: 0.00013152
Epoch [93/300], Train Loss: 0.000141
Validation Loss: 0.00013030
Epoch [94/300], Train Loss: 0.000139
Validation Loss: 0.00012901
Epoch [95/300], Train Loss: 0.000140
Validation Loss: 0.00013066
Epoch [96/300], Train Loss: 0.000139
Validation Loss: 0.00012668
Epoch [97/300], Train Loss: 0.000140
Validation Loss: 0.00012705
Epoch [98/300], Train Loss: 0.000137
Validation Loss: 0.00012582
Epoch [99/300], Train Loss: 0.000138
Validation Loss: 0.00012763
Epoch [100/300], Train Loss: 0.000135
Validation Loss: 0.00012594
Epoch [101/300], Train Loss: 0.000136
Validation Loss: 0.00012906
Epoch [102/300], Train Loss: 0.000135
Validation Loss: 0.00012624
Epoch [103/300], Train Loss: 0.000134
Validation Loss: 0.00012292
Epoch [104/300], Train Loss: 0.000131
Validation Loss: 0.00012472
Epoch [105/300], Train Loss: 0.000130
Validation Loss: 0.00012552
Epoch [106/300], Train Loss: 0.000128
Validation Loss: 0.00012255
Epoch [107/300], Train Loss: 0.000128
Validation Loss: 0.00012376
Epoch [108/300], Train Loss: 0.000129
Validation Loss: 0.00012474
Epoch [109/300], Train Loss: 0.000126
Validation Loss: 0.00012666
Epoch [110/300], Train Loss: 0.000140
Validation Loss: 0.00012523
Epoch [111/300], Train Loss: 0.000131
Validation Loss: 0.00012379
Epoch [112/300], Train Loss: 0.000125
Validation Loss: 0.00012071
Epoch [113/300], Train Loss: 0.000123
Validation Loss: 0.00011834
Epoch [114/300], Train Loss: 0.000122
Validation Loss: 0.00011877
Epoch [115/300], Train Loss: 0.000126
Validation Loss: 0.00012061
Epoch [116/300], Train Loss: 0.000123
Validation Loss: 0.00011764
Epoch [117/300], Train Loss: 0.000122
Validation Loss: 0.00011871
Epoch [118/300], Train Loss: 0.000122
Validation Loss: 0.00012025
Epoch [119/300], Train Loss: 0.000122
Validation Loss: 0.00012019
Epoch [120/300], Train Loss: 0.000124
Validation Loss: 0.00011885
Epoch [121/300], Train Loss: 0.000132
Validation Loss: 0.00011758
Epoch [122/300], Train Loss: 0.000118
Validation Loss: 0.00011544
Epoch [123/300], Train Loss: 0.000117
Validation Loss: 0.00011337
Epoch [124/300], Train Loss: 0.000116
Validation Loss: 0.00011458
Epoch [125/300], Train Loss: 0.000115
Validation Loss: 0.00011281
Epoch [126/300], Train Loss: 0.000114
Validation Loss: 0.00011350
Epoch [127/300], Train Loss: 0.000114
Validation Loss: 0.00011625
Epoch [128/300], Train Loss: 0.000114
Validation Loss: 0.00011880
Epoch [129/300], Train Loss: 0.000115
Validation Loss: 0.00011518
Epoch [130/300], Train Loss: 0.000113
Validation Loss: 0.00011749
Epoch [131/300], Train Loss: 0.000113
Validation Loss: 0.00011454
Epoch [132/300], Train Loss: 0.000113
Validation Loss: 0.00011596
Epoch [133/300], Train Loss: 0.000113
Validation Loss: 0.00011667
Epoch [134/300], Train Loss: 0.000114
Validation Loss: 0.00011269
Epoch [135/300], Train Loss: 0.000112
Validation Loss: 0.00011698
Epoch [136/300], Train Loss: 0.000109
Validation Loss: 0.00011501
Epoch [137/300], Train Loss: 0.000109
Validation Loss: 0.00011351
Epoch [138/300], Train Loss: 0.000108
Validation Loss: 0.00011410
Epoch [139/300], Train Loss: 0.000109
Validation Loss: 0.00011805
Epoch [140/300], Train Loss: 0.000107
Validation Loss: 0.00011266
Epoch [141/300], Train Loss: 0.000107
Validation Loss: 0.00011583
Epoch [142/300], Train Loss: 0.000107
Validation Loss: 0.00011573
Epoch [143/300], Train Loss: 0.000107
Validation Loss: 0.00011296
Epoch [144/300], Train Loss: 0.000107
Validation Loss: 0.00011211
Epoch [145/300], Train Loss: 0.000104
Validation Loss: 0.00011144
Epoch [146/300], Train Loss: 0.000106
Validation Loss: 0.00011704
Epoch [147/300], Train Loss: 0.000104
Validation Loss: 0.00011237
Epoch [148/300], Train Loss: 0.000104
Validation Loss: 0.00011336
Epoch [149/300], Train Loss: 0.000103
Validation Loss: 0.00011058
Epoch [150/300], Train Loss: 0.000101
Validation Loss: 0.00011215
Epoch [151/300], Train Loss: 0.000103
Validation Loss: 0.00011530
Epoch [152/300], Train Loss: 0.000101
Validation Loss: 0.00011062
Epoch [153/300], Train Loss: 0.000100
Validation Loss: 0.00011080
Epoch [154/300], Train Loss: 0.000101
Validation Loss: 0.00011208
Epoch [155/300], Train Loss: 0.000101
Validation Loss: 0.00011382
Epoch [156/300], Train Loss: 0.000101
Validation Loss: 0.00010815
Epoch [157/300], Train Loss: 0.000101
Validation Loss: 0.00012200
Epoch [158/300], Train Loss: 0.000100
Validation Loss: 0.00011256
Epoch [159/300], Train Loss: 0.000098
Validation Loss: 0.00010805
Epoch [160/300], Train Loss: 0.000098
Validation Loss: 0.00011070
Epoch [161/300], Train Loss: 0.000097
Validation Loss: 0.00010994
Epoch [162/300], Train Loss: 0.000097
Validation Loss: 0.00010822
Epoch [163/300], Train Loss: 0.000095
Validation Loss: 0.00011185
Epoch [164/300], Train Loss: 0.000096
Validation Loss: 0.00010875
Epoch [165/300], Train Loss: 0.000095
Validation Loss: 0.00011504
Epoch [166/300], Train Loss: 0.000095
Validation Loss: 0.00010862
Epoch [167/300], Train Loss: 0.000095
Validation Loss: 0.00010691
Epoch [168/300], Train Loss: 0.000094
Validation Loss: 0.00010646
Epoch [169/300], Train Loss: 0.000093
Validation Loss: 0.00010880
Epoch [170/300], Train Loss: 0.000095
Validation Loss: 0.00011192
Epoch [171/300], Train Loss: 0.000093
Validation Loss: 0.00010995
Epoch [172/300], Train Loss: 0.000093
Validation Loss: 0.00010803
Epoch [173/300], Train Loss: 0.000092
Validation Loss: 0.00010706
Epoch [174/300], Train Loss: 0.000091
Validation Loss: 0.00011005
Epoch [175/300], Train Loss: 0.000091
Validation Loss: 0.00010632
Epoch [176/300], Train Loss: 0.000091
Validation Loss: 0.00010681
Epoch [177/300], Train Loss: 0.000093
Validation Loss: 0.00010834
Epoch [178/300], Train Loss: 0.000091
Validation Loss: 0.00010557
Epoch [179/300], Train Loss: 0.000091
Validation Loss: 0.00010666
Epoch [180/300], Train Loss: 0.000091
Validation Loss: 0.00010990
Epoch [181/300], Train Loss: 0.000088
Validation Loss: 0.00010762
Epoch [182/300], Train Loss: 0.000089
Validation Loss: 0.00010685
Epoch [183/300], Train Loss: 0.000097
Validation Loss: 0.00010665
Epoch [184/300], Train Loss: 0.000088
Validation Loss: 0.00010428
Epoch [185/300], Train Loss: 0.000087
Validation Loss: 0.00010633
Epoch [186/300], Train Loss: 0.000088
Validation Loss: 0.00010755
Epoch [187/300], Train Loss: 0.000089
Validation Loss: 0.00010862
Epoch [188/300], Train Loss: 0.000087
Validation Loss: 0.00010667
Epoch [189/300], Train Loss: 0.000087
Validation Loss: 0.00010609
Epoch [190/300], Train Loss: 0.000086
Validation Loss: 0.00010702
Epoch [191/300], Train Loss: 0.000086
Validation Loss: 0.00010369
Epoch [192/300], Train Loss: 0.000086
Validation Loss: 0.00010634
Epoch [193/300], Train Loss: 0.000085
Validation Loss: 0.00010729
Epoch [194/300], Train Loss: 0.000085
Validation Loss: 0.00010516
Epoch [195/300], Train Loss: 0.000085
Validation Loss: 0.00010786
Epoch [196/300], Train Loss: 0.000086
Validation Loss: 0.00010489
Epoch [197/300], Train Loss: 0.000085
Validation Loss: 0.00010491
Epoch [198/300], Train Loss: 0.000084
Validation Loss: 0.00010492
Epoch [199/300], Train Loss: 0.000086
Validation Loss: 0.00012088
Epoch [200/300], Train Loss: 0.000088
Validation Loss: 0.00010497
Epoch [201/300], Train Loss: 0.000083
Validation Loss: 0.00010199
Epoch [202/300], Train Loss: 0.000083
Validation Loss: 0.00010260
Epoch [203/300], Train Loss: 0.000082
Validation Loss: 0.00010168
Epoch [204/300], Train Loss: 0.000081
Validation Loss: 0.00010357
Epoch [205/300], Train Loss: 0.000084
Validation Loss: 0.00010548
Epoch [206/300], Train Loss: 0.000124
Validation Loss: 0.00010771
Epoch [207/300], Train Loss: 0.000090
Validation Loss: 0.00010187
Epoch [208/300], Train Loss: 0.000084
Validation Loss: 0.00010106
Epoch [209/300], Train Loss: 0.000082
Validation Loss: 0.00010140
Epoch [210/300], Train Loss: 0.000081
Validation Loss: 0.00010025
Epoch [211/300], Train Loss: 0.000081
Validation Loss: 0.00010116
Epoch [212/300], Train Loss: 0.000081
Validation Loss: 0.00010084
Epoch [213/300], Train Loss: 0.000080
Validation Loss: 0.00010134
Epoch [214/300], Train Loss: 0.000080
Validation Loss: 0.00010383
Epoch [215/300], Train Loss: 0.000080
Validation Loss: 0.00010035
Epoch [216/300], Train Loss: 0.000080
Validation Loss: 0.00010144
Epoch [217/300], Train Loss: 0.000079
Validation Loss: 0.00010154
Epoch [218/300], Train Loss: 0.000082
Validation Loss: 0.00010289
Epoch [219/300], Train Loss: 0.000079
Validation Loss: 0.00010165
Epoch [220/300], Train Loss: 0.000079
Validation Loss: 0.00010095
Early stopping triggered

Evaluating model for: Coffee Machine
Run 26/72 completed in 12089.76 seconds with: {'MAE': np.float32(2.1483319), 'MSE': np.float32(435.75467), 'RMSE': np.float32(20.874737), 'SAE': np.float32(0.036278456), 'NDE': np.float32(0.3372843)}

Run 27/72: hidden=256, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Coffee Machine
Dataset length: 36156 windows

Epoch [1/300], Train Loss: 0.000995
Validation Loss: 0.00094940
Epoch [2/300], Train Loss: 0.000982
Validation Loss: 0.00094389
Epoch [3/300], Train Loss: 0.000969
Validation Loss: 0.00092314
Epoch [4/300], Train Loss: 0.000919
Validation Loss: 0.00082960
Epoch [5/300], Train Loss: 0.000785
Validation Loss: 0.00074007
Epoch [6/300], Train Loss: 0.000685
Validation Loss: 0.00066364
Epoch [7/300], Train Loss: 0.000653
Validation Loss: 0.00063846
Epoch [8/300], Train Loss: 0.000619
Validation Loss: 0.00062742
Epoch [9/300], Train Loss: 0.000592
Validation Loss: 0.00059178
Epoch [10/300], Train Loss: 0.000576
Validation Loss: 0.00057881
Epoch [11/300], Train Loss: 0.000562
Validation Loss: 0.00055618
Epoch [12/300], Train Loss: 0.000548
Validation Loss: 0.00055225
Epoch [13/300], Train Loss: 0.000493
Validation Loss: 0.00042287
Epoch [14/300], Train Loss: 0.000431
Validation Loss: 0.00039209
Epoch [15/300], Train Loss: 0.000402
Validation Loss: 0.00037208
Epoch [16/300], Train Loss: 0.000384
Validation Loss: 0.00038804
Epoch [17/300], Train Loss: 0.000374
Validation Loss: 0.00033572
Epoch [18/300], Train Loss: 0.000368
Validation Loss: 0.00033322
Epoch [19/300], Train Loss: 0.000352
Validation Loss: 0.00031868
Epoch [20/300], Train Loss: 0.000342
Validation Loss: 0.00031894
Epoch [21/300], Train Loss: 0.000342
Validation Loss: 0.00032050
Epoch [22/300], Train Loss: 0.000333
Validation Loss: 0.00030434
Epoch [23/300], Train Loss: 0.000328
Validation Loss: 0.00031025
Epoch [24/300], Train Loss: 0.000320
Validation Loss: 0.00029677
Epoch [25/300], Train Loss: 0.000314
Validation Loss: 0.00031984
Epoch [26/300], Train Loss: 0.000314
Validation Loss: 0.00030190
Epoch [27/300], Train Loss: 0.000303
Validation Loss: 0.00028640
Epoch [28/300], Train Loss: 0.000298
Validation Loss: 0.00030138
Epoch [29/300], Train Loss: 0.000305
Validation Loss: 0.00027017
Epoch [30/300], Train Loss: 0.000289
Validation Loss: 0.00026550
Epoch [31/300], Train Loss: 0.000281
Validation Loss: 0.00026155
Epoch [32/300], Train Loss: 0.000278
Validation Loss: 0.00026966
Epoch [33/300], Train Loss: 0.000275
Validation Loss: 0.00025521
Epoch [34/300], Train Loss: 0.000273
Validation Loss: 0.00026321
Epoch [35/300], Train Loss: 0.000265
Validation Loss: 0.00024382
Epoch [36/300], Train Loss: 0.000263
Validation Loss: 0.00024853
Epoch [37/300], Train Loss: 0.000256
Validation Loss: 0.00024340
Epoch [38/300], Train Loss: 0.000254
Validation Loss: 0.00023666
Epoch [39/300], Train Loss: 0.000254
Validation Loss: 0.00023081
Epoch [40/300], Train Loss: 0.000247
Validation Loss: 0.00023421
Epoch [41/300], Train Loss: 0.000244
Validation Loss: 0.00023272
Epoch [42/300], Train Loss: 0.000239
Validation Loss: 0.00022625
Epoch [43/300], Train Loss: 0.000238
Validation Loss: 0.00022315
Epoch [44/300], Train Loss: 0.000229
Validation Loss: 0.00023092
Epoch [45/300], Train Loss: 0.000235
Validation Loss: 0.00022473
Epoch [46/300], Train Loss: 0.000224
Validation Loss: 0.00023107
Epoch [47/300], Train Loss: 0.000228
Validation Loss: 0.00020588
Epoch [48/300], Train Loss: 0.000216
Validation Loss: 0.00020834
Epoch [49/300], Train Loss: 0.000212
Validation Loss: 0.00020517
Epoch [50/300], Train Loss: 0.000213
Validation Loss: 0.00019702
Epoch [51/300], Train Loss: 0.000209
Validation Loss: 0.00021944
Epoch [52/300], Train Loss: 0.000209
Validation Loss: 0.00020433
Epoch [53/300], Train Loss: 0.000202
Validation Loss: 0.00019690
Epoch [54/300], Train Loss: 0.000204
Validation Loss: 0.00019089
Epoch [55/300], Train Loss: 0.000213
Validation Loss: 0.00020314
Epoch [56/300], Train Loss: 0.000198
Validation Loss: 0.00018816
Epoch [57/300], Train Loss: 0.000194
Validation Loss: 0.00019007
Epoch [58/300], Train Loss: 0.000193
Validation Loss: 0.00019118
Epoch [59/300], Train Loss: 0.000192
Validation Loss: 0.00019382
Epoch [60/300], Train Loss: 0.000191
Validation Loss: 0.00025463
Epoch [61/300], Train Loss: 0.000185
Validation Loss: 0.00019097
Epoch [62/300], Train Loss: 0.000182
Validation Loss: 0.00018301
Epoch [63/300], Train Loss: 0.000181
Validation Loss: 0.00018471
Epoch [64/300], Train Loss: 0.000182
Validation Loss: 0.00017530
Epoch [65/300], Train Loss: 0.000183
Validation Loss: 0.00017761
Epoch [66/300], Train Loss: 0.000181
Validation Loss: 0.00017163
Epoch [67/300], Train Loss: 0.000174
Validation Loss: 0.00017330
Epoch [68/300], Train Loss: 0.000195
Validation Loss: 0.00017997
Epoch [69/300], Train Loss: 0.000170
Validation Loss: 0.00017029
Epoch [70/300], Train Loss: 0.000170
Validation Loss: 0.00029114
Epoch [71/300], Train Loss: 0.000215
Validation Loss: 0.00019262
Epoch [72/300], Train Loss: 0.000173
Validation Loss: 0.00016805
Epoch [73/300], Train Loss: 0.000167
Validation Loss: 0.00017477
Epoch [74/300], Train Loss: 0.000166
Validation Loss: 0.00017243
Epoch [75/300], Train Loss: 0.000162
Validation Loss: 0.00016646
Epoch [76/300], Train Loss: 0.000161
Validation Loss: 0.00018313
Epoch [77/300], Train Loss: 0.000163
Validation Loss: 0.00015945
Epoch [78/300], Train Loss: 0.000161
Validation Loss: 0.00018437
Epoch [79/300], Train Loss: 0.000158
Validation Loss: 0.00016220
Epoch [80/300], Train Loss: 0.000158
Validation Loss: 0.00017485
Epoch [81/300], Train Loss: 0.000155
Validation Loss: 0.00016381
Epoch [82/300], Train Loss: 0.000153
Validation Loss: 0.00016056
Epoch [83/300], Train Loss: 0.000153
Validation Loss: 0.00016228
Epoch [84/300], Train Loss: 0.000176
Validation Loss: 0.00016706
Epoch [85/300], Train Loss: 0.000156
Validation Loss: 0.00015525
Epoch [86/300], Train Loss: 0.000152
Validation Loss: 0.00016298
Epoch [87/300], Train Loss: 0.000151
Validation Loss: 0.00015843
Epoch [88/300], Train Loss: 0.000149
Validation Loss: 0.00015481
Epoch [89/300], Train Loss: 0.000148
Validation Loss: 0.00015936
Epoch [90/300], Train Loss: 0.000149
Validation Loss: 0.00017989
Epoch [91/300], Train Loss: 0.000148
Validation Loss: 0.00015874
Epoch [92/300], Train Loss: 0.000145
Validation Loss: 0.00015645
Epoch [93/300], Train Loss: 0.000142
Validation Loss: 0.00015443
Epoch [94/300], Train Loss: 0.000143
Validation Loss: 0.00015394
Epoch [95/300], Train Loss: 0.000143
Validation Loss: 0.00015534
Epoch [96/300], Train Loss: 0.000142
Validation Loss: 0.00016184
Epoch [97/300], Train Loss: 0.000141
Validation Loss: 0.00015130
Epoch [98/300], Train Loss: 0.000138
Validation Loss: 0.00015514
Epoch [99/300], Train Loss: 0.000141
Validation Loss: 0.00016543
Epoch [100/300], Train Loss: 0.000143
Validation Loss: 0.00016106
Epoch [101/300], Train Loss: 0.000138
Validation Loss: 0.00014962
Epoch [102/300], Train Loss: 0.000136
Validation Loss: 0.00014987
Epoch [103/300], Train Loss: 0.000137
Validation Loss: 0.00015343
Epoch [104/300], Train Loss: 0.000134
Validation Loss: 0.00015100
Epoch [105/300], Train Loss: 0.000132
Validation Loss: 0.00015366
Epoch [106/300], Train Loss: 0.000133
Validation Loss: 0.00014627
Epoch [107/300], Train Loss: 0.000133
Validation Loss: 0.00014695
Epoch [108/300], Train Loss: 0.000129
Validation Loss: 0.00015420
Epoch [109/300], Train Loss: 0.000130
Validation Loss: 0.00014976
Epoch [110/300], Train Loss: 0.000128
Validation Loss: 0.00014675
Epoch [111/300], Train Loss: 0.000128
Validation Loss: 0.00014818
Epoch [112/300], Train Loss: 0.000125
Validation Loss: 0.00014439
Epoch [113/300], Train Loss: 0.000126
Validation Loss: 0.00014620
Epoch [114/300], Train Loss: 0.000126
Validation Loss: 0.00014207
Epoch [115/300], Train Loss: 0.000124
Validation Loss: 0.00014785
Epoch [116/300], Train Loss: 0.000135
Validation Loss: 0.00014399
Epoch [117/300], Train Loss: 0.000124
Validation Loss: 0.00014552
Epoch [118/300], Train Loss: 0.000125
Validation Loss: 0.00014205
Epoch [119/300], Train Loss: 0.000119
Validation Loss: 0.00014287
Epoch [120/300], Train Loss: 0.000120
Validation Loss: 0.00014139
Epoch [121/300], Train Loss: 0.000117
Validation Loss: 0.00014430
Epoch [122/300], Train Loss: 0.000117
Validation Loss: 0.00014555
Epoch [123/300], Train Loss: 0.000118
Validation Loss: 0.00014307
Epoch [124/300], Train Loss: 0.000117
Validation Loss: 0.00014287
Epoch [125/300], Train Loss: 0.000120
Validation Loss: 0.00015142
Epoch [126/300], Train Loss: 0.000118
Validation Loss: 0.00014003
Epoch [127/300], Train Loss: 0.000113
Validation Loss: 0.00013925
Epoch [128/300], Train Loss: 0.000115
Validation Loss: 0.00014644
Epoch [129/300], Train Loss: 0.000112
Validation Loss: 0.00013868
Epoch [130/300], Train Loss: 0.000114
Validation Loss: 0.00014006
Epoch [131/300], Train Loss: 0.000111
Validation Loss: 0.00013456
Epoch [132/300], Train Loss: 0.000111
Validation Loss: 0.00013840
Epoch [133/300], Train Loss: 0.000109
Validation Loss: 0.00014110
Epoch [134/300], Train Loss: 0.000111
Validation Loss: 0.00014332
Epoch [135/300], Train Loss: 0.000109
Validation Loss: 0.00013807
Epoch [136/300], Train Loss: 0.000109
Validation Loss: 0.00013321
Epoch [137/300], Train Loss: 0.000107
Validation Loss: 0.00013817
Epoch [138/300], Train Loss: 0.000106
Validation Loss: 0.00013777
Epoch [139/300], Train Loss: 0.000106
Validation Loss: 0.00014316
Epoch [140/300], Train Loss: 0.000105
Validation Loss: 0.00013755
Epoch [141/300], Train Loss: 0.000104
Validation Loss: 0.00013766
Epoch [142/300], Train Loss: 0.000103
Validation Loss: 0.00013750
Epoch [143/300], Train Loss: 0.000103
Validation Loss: 0.00014096
Epoch [144/300], Train Loss: 0.000112
Validation Loss: 0.00015980
Epoch [145/300], Train Loss: 0.000104
Validation Loss: 0.00014208
Epoch [146/300], Train Loss: 0.000102
Validation Loss: 0.00014891
Early stopping triggered

Evaluating model for: Coffee Machine
Run 27/72 completed in 8094.96 seconds with: {'MAE': np.float32(2.4367318), 'MSE': np.float32(579.8017), 'RMSE': np.float32(24.079071), 'SAE': np.float32(0.0056328964), 'NDE': np.float32(0.3890585)}

Run 28/72: hidden=256, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Coffee Machine
Dataset length: 36156 windows

Epoch [1/300], Train Loss: 0.001003
Validation Loss: 0.00095149
Epoch [2/300], Train Loss: 0.000985
Validation Loss: 0.00094973
Epoch [3/300], Train Loss: 0.000982
Validation Loss: 0.00094913
Epoch [4/300], Train Loss: 0.000981
Validation Loss: 0.00094626
Epoch [5/300], Train Loss: 0.000974
Validation Loss: 0.00093386
Epoch [6/300], Train Loss: 0.000908
Validation Loss: 0.00079789
Epoch [7/300], Train Loss: 0.000754
Validation Loss: 0.00071847
Epoch [8/300], Train Loss: 0.000689
Validation Loss: 0.00070586
Epoch [9/300], Train Loss: 0.000649
Validation Loss: 0.00064694
Epoch [10/300], Train Loss: 0.000621
Validation Loss: 0.00061961
Epoch [11/300], Train Loss: 0.000585
Validation Loss: 0.00054122
Epoch [12/300], Train Loss: 0.000511
Validation Loss: 0.00048787
Epoch [13/300], Train Loss: 0.000459
Validation Loss: 0.00041977
Epoch [14/300], Train Loss: 0.000423
Validation Loss: 0.00040091
Epoch [15/300], Train Loss: 0.000401
Validation Loss: 0.00035931
Epoch [16/300], Train Loss: 0.000378
Validation Loss: 0.00038430
Epoch [17/300], Train Loss: 0.000372
Validation Loss: 0.00031749
Epoch [18/300], Train Loss: 0.000358
Validation Loss: 0.00031765
Epoch [19/300], Train Loss: 0.000343
Validation Loss: 0.00031643
Epoch [20/300], Train Loss: 0.000339
Validation Loss: 0.00032534
Epoch [21/300], Train Loss: 0.000337
Validation Loss: 0.00029327
Epoch [22/300], Train Loss: 0.000321
Validation Loss: 0.00030027
Epoch [23/300], Train Loss: 0.000320
Validation Loss: 0.00028745
Epoch [24/300], Train Loss: 0.000306
Validation Loss: 0.00028117
Epoch [25/300], Train Loss: 0.000296
Validation Loss: 0.00027830
Epoch [26/300], Train Loss: 0.000297
Validation Loss: 0.00026595
Epoch [27/300], Train Loss: 0.000292
Validation Loss: 0.00027265
Epoch [28/300], Train Loss: 0.000286
Validation Loss: 0.00028873
Epoch [29/300], Train Loss: 0.000283
Validation Loss: 0.00027164
Epoch [30/300], Train Loss: 0.000279
Validation Loss: 0.00026665
Epoch [31/300], Train Loss: 0.000274
Validation Loss: 0.00025932
Epoch [32/300], Train Loss: 0.000265
Validation Loss: 0.00025886
Epoch [33/300], Train Loss: 0.000265
Validation Loss: 0.00024351
Epoch [34/300], Train Loss: 0.000261
Validation Loss: 0.00024644
Epoch [35/300], Train Loss: 0.000261
Validation Loss: 0.00024038
Epoch [36/300], Train Loss: 0.000257
Validation Loss: 0.00024229
Epoch [37/300], Train Loss: 0.000252
Validation Loss: 0.00024075
Epoch [38/300], Train Loss: 0.000255
Validation Loss: 0.00024244
Epoch [39/300], Train Loss: 0.000249
Validation Loss: 0.00022940
Epoch [40/300], Train Loss: 0.000248
Validation Loss: 0.00024514
Epoch [41/300], Train Loss: 0.000246
Validation Loss: 0.00023926
Epoch [42/300], Train Loss: 0.000240
Validation Loss: 0.00022817
Epoch [43/300], Train Loss: 0.000236
Validation Loss: 0.00023233
Epoch [44/300], Train Loss: 0.000241
Validation Loss: 0.00021906
Epoch [45/300], Train Loss: 0.000225
Validation Loss: 0.00021733
Epoch [46/300], Train Loss: 0.000224
Validation Loss: 0.00021483
Epoch [47/300], Train Loss: 0.000223
Validation Loss: 0.00020882
Epoch [48/300], Train Loss: 0.000228
Validation Loss: 0.00020508
Epoch [49/300], Train Loss: 0.000216
Validation Loss: 0.00020611
Epoch [50/300], Train Loss: 0.000215
Validation Loss: 0.00020403
Epoch [51/300], Train Loss: 0.000226
Validation Loss: 0.00028591
Epoch [52/300], Train Loss: 0.000228
Validation Loss: 0.00020750
Epoch [53/300], Train Loss: 0.000213
Validation Loss: 0.00020253
Epoch [54/300], Train Loss: 0.000207
Validation Loss: 0.00019431
Epoch [55/300], Train Loss: 0.000208
Validation Loss: 0.00019618
Epoch [56/300], Train Loss: 0.000202
Validation Loss: 0.00019125
Epoch [57/300], Train Loss: 0.000204
Validation Loss: 0.00019698
Epoch [58/300], Train Loss: 0.000198
Validation Loss: 0.00018873
Epoch [59/300], Train Loss: 0.000196
Validation Loss: 0.00018983
Epoch [60/300], Train Loss: 0.000198
Validation Loss: 0.00018707
Epoch [61/300], Train Loss: 0.000194
Validation Loss: 0.00018651
Epoch [62/300], Train Loss: 0.000191
Validation Loss: 0.00018819
Epoch [63/300], Train Loss: 0.000195
Validation Loss: 0.00018166
Epoch [64/300], Train Loss: 0.000184
Validation Loss: 0.00018638
Epoch [65/300], Train Loss: 0.000188
Validation Loss: 0.00019995
Epoch [66/300], Train Loss: 0.000183
Validation Loss: 0.00017690
Epoch [67/300], Train Loss: 0.000182
Validation Loss: 0.00018556
Epoch [68/300], Train Loss: 0.000187
Validation Loss: 0.00019301
Epoch [69/300], Train Loss: 0.000178
Validation Loss: 0.00017358
Epoch [70/300], Train Loss: 0.000188
Validation Loss: 0.00017862
Epoch [71/300], Train Loss: 0.000179
Validation Loss: 0.00019298
Epoch [72/300], Train Loss: 0.000176
Validation Loss: 0.00019022
Epoch [73/300], Train Loss: 0.000200
Validation Loss: 0.00019122
Epoch [74/300], Train Loss: 0.000177
Validation Loss: 0.00017720
Epoch [75/300], Train Loss: 0.000173
Validation Loss: 0.00017424
Epoch [76/300], Train Loss: 0.000174
Validation Loss: 0.00016987
Epoch [77/300], Train Loss: 0.000168
Validation Loss: 0.00016659
Epoch [78/300], Train Loss: 0.000166
Validation Loss: 0.00018077
Epoch [79/300], Train Loss: 0.000168
Validation Loss: 0.00016772
Epoch [80/300], Train Loss: 0.000164
Validation Loss: 0.00016980
Epoch [81/300], Train Loss: 0.000164
Validation Loss: 0.00016269
Epoch [82/300], Train Loss: 0.000161
Validation Loss: 0.00016315
Epoch [83/300], Train Loss: 0.000174
Validation Loss: 0.00016371
Epoch [84/300], Train Loss: 0.000162
Validation Loss: 0.00016942
Epoch [85/300], Train Loss: 0.000159
Validation Loss: 0.00016519
Epoch [86/300], Train Loss: 0.000160
Validation Loss: 0.00016323
Epoch [87/300], Train Loss: 0.000160
Validation Loss: 0.00016012
Epoch [88/300], Train Loss: 0.000157
Validation Loss: 0.00016137
Epoch [89/300], Train Loss: 0.000158
Validation Loss: 0.00016501
Epoch [90/300], Train Loss: 0.000155
Validation Loss: 0.00016221
Epoch [91/300], Train Loss: 0.000151
Validation Loss: 0.00016029
Epoch [92/300], Train Loss: 0.000148
Validation Loss: 0.00016430
Epoch [93/300], Train Loss: 0.000150
Validation Loss: 0.00015695
Epoch [94/300], Train Loss: 0.000158
Validation Loss: 0.00015812
Epoch [95/300], Train Loss: 0.000153
Validation Loss: 0.00016852
Epoch [96/300], Train Loss: 0.000157
Validation Loss: 0.00015610
Epoch [97/300], Train Loss: 0.000146
Validation Loss: 0.00015338
Epoch [98/300], Train Loss: 0.000149
Validation Loss: 0.00015884
Epoch [99/300], Train Loss: 0.000143
Validation Loss: 0.00015314
Epoch [100/300], Train Loss: 0.000143
Validation Loss: 0.00015630
Epoch [101/300], Train Loss: 0.000143
Validation Loss: 0.00015191
Epoch [102/300], Train Loss: 0.000145
Validation Loss: 0.00015466
Epoch [103/300], Train Loss: 0.000149
Validation Loss: 0.00016852
Epoch [104/300], Train Loss: 0.000142
Validation Loss: 0.00016097
Epoch [105/300], Train Loss: 0.000149
Validation Loss: 0.00015649
Epoch [106/300], Train Loss: 0.000138
Validation Loss: 0.00014750
Epoch [107/300], Train Loss: 0.000138
Validation Loss: 0.00015562
Epoch [108/300], Train Loss: 0.000139
Validation Loss: 0.00015373
Epoch [109/300], Train Loss: 0.000141
Validation Loss: 0.00014776
Epoch [110/300], Train Loss: 0.000134
Validation Loss: 0.00015178
Epoch [111/300], Train Loss: 0.000133
Validation Loss: 0.00014731
Epoch [112/300], Train Loss: 0.000134
Validation Loss: 0.00014365
Epoch [113/300], Train Loss: 0.000136
Validation Loss: 0.00014947
Epoch [114/300], Train Loss: 0.000139
Validation Loss: 0.00014432
Epoch [115/300], Train Loss: 0.000138
Validation Loss: 0.00014560
Epoch [116/300], Train Loss: 0.000132
Validation Loss: 0.00014286
Epoch [117/300], Train Loss: 0.000135
Validation Loss: 0.00014524
Epoch [118/300], Train Loss: 0.000129
Validation Loss: 0.00014263
Epoch [119/300], Train Loss: 0.000128
Validation Loss: 0.00014254
Epoch [120/300], Train Loss: 0.000128
Validation Loss: 0.00014505
Epoch [121/300], Train Loss: 0.000127
Validation Loss: 0.00014178
Epoch [122/300], Train Loss: 0.000126
Validation Loss: 0.00015213
Epoch [123/300], Train Loss: 0.000126
Validation Loss: 0.00014551
Epoch [124/300], Train Loss: 0.000124
Validation Loss: 0.00014677
Epoch [125/300], Train Loss: 0.000122
Validation Loss: 0.00014733
Epoch [126/300], Train Loss: 0.000124
Validation Loss: 0.00014012
Epoch [127/300], Train Loss: 0.000122
Validation Loss: 0.00014283
Epoch [128/300], Train Loss: 0.000123
Validation Loss: 0.00014782
Epoch [129/300], Train Loss: 0.000123
Validation Loss: 0.00014107
Epoch [130/300], Train Loss: 0.000121
Validation Loss: 0.00013961
Epoch [131/300], Train Loss: 0.000120
Validation Loss: 0.00014153
Epoch [132/300], Train Loss: 0.000119
Validation Loss: 0.00014555
Epoch [133/300], Train Loss: 0.000121
Validation Loss: 0.00014534
Epoch [134/300], Train Loss: 0.000129
Validation Loss: 0.00015063
Epoch [135/300], Train Loss: 0.000119
Validation Loss: 0.00014077
Epoch [136/300], Train Loss: 0.000116
Validation Loss: 0.00013686
Epoch [137/300], Train Loss: 0.000115
Validation Loss: 0.00013860
Epoch [138/300], Train Loss: 0.000115
Validation Loss: 0.00013980
Epoch [139/300], Train Loss: 0.000118
Validation Loss: 0.00013953
Epoch [140/300], Train Loss: 0.000115
Validation Loss: 0.00014208
Epoch [141/300], Train Loss: 0.000114
Validation Loss: 0.00013489
Epoch [142/300], Train Loss: 0.000114
Validation Loss: 0.00013850
Epoch [143/300], Train Loss: 0.000114
Validation Loss: 0.00014266
Epoch [144/300], Train Loss: 0.000114
Validation Loss: 0.00013719
Epoch [145/300], Train Loss: 0.000113
Validation Loss: 0.00013856
Epoch [146/300], Train Loss: 0.000112
Validation Loss: 0.00014022
Epoch [147/300], Train Loss: 0.000129
Validation Loss: 0.00013835
Epoch [148/300], Train Loss: 0.000112
Validation Loss: 0.00013370
Epoch [149/300], Train Loss: 0.000109
Validation Loss: 0.00013783
Epoch [150/300], Train Loss: 0.000110
Validation Loss: 0.00013274
Epoch [151/300], Train Loss: 0.000109
Validation Loss: 0.00014063
Epoch [152/300], Train Loss: 0.000110
Validation Loss: 0.00013776
Epoch [153/300], Train Loss: 0.000108
Validation Loss: 0.00013595
Epoch [154/300], Train Loss: 0.000109
Validation Loss: 0.00013935
Epoch [155/300], Train Loss: 0.000108
Validation Loss: 0.00013516
Epoch [156/300], Train Loss: 0.000108
Validation Loss: 0.00013525
Epoch [157/300], Train Loss: 0.000108
Validation Loss: 0.00013536
Epoch [158/300], Train Loss: 0.000106
Validation Loss: 0.00013663
Epoch [159/300], Train Loss: 0.000106
Validation Loss: 0.00013506
Epoch [160/300], Train Loss: 0.000106
Validation Loss: 0.00013488
Early stopping triggered

Evaluating model for: Coffee Machine
Run 28/72 completed in 9842.89 seconds with: {'MAE': np.float32(2.2745528), 'MSE': np.float32(673.7028), 'RMSE': np.float32(25.955786), 'SAE': np.float32(0.14159828), 'NDE': np.float32(0.41938105)}

Run 29/72: hidden=256, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Coffee Machine
Dataset length: 18100 windows

Epoch [1/300], Train Loss: 0.000984
Validation Loss: 0.00093101
Epoch [2/300], Train Loss: 0.000965
Validation Loss: 0.00092894
Epoch [3/300], Train Loss: 0.000980
Validation Loss: 0.00092400
Epoch [4/300], Train Loss: 0.000967
Validation Loss: 0.00091990
Epoch [5/300], Train Loss: 0.000947
Validation Loss: 0.00090839
Epoch [6/300], Train Loss: 0.000943
Validation Loss: 0.00089499
Epoch [7/300], Train Loss: 0.000919
Validation Loss: 0.00086786
Epoch [8/300], Train Loss: 0.000885
Validation Loss: 0.00082645
Epoch [9/300], Train Loss: 0.000853
Validation Loss: 0.00079500
Epoch [10/300], Train Loss: 0.000810
Validation Loss: 0.00073862
Epoch [11/300], Train Loss: 0.000761
Validation Loss: 0.00070067
Epoch [12/300], Train Loss: 0.000734
Validation Loss: 0.00067961
Epoch [13/300], Train Loss: 0.000719
Validation Loss: 0.00067054
Epoch [14/300], Train Loss: 0.000690
Validation Loss: 0.00065251
Epoch [15/300], Train Loss: 0.000700
Validation Loss: 0.00064658
Epoch [16/300], Train Loss: 0.000666
Validation Loss: 0.00063181
Epoch [17/300], Train Loss: 0.000648
Validation Loss: 0.00061929
Epoch [18/300], Train Loss: 0.000659
Validation Loss: 0.00060971
Epoch [19/300], Train Loss: 0.000624
Validation Loss: 0.00059791
Epoch [20/300], Train Loss: 0.000617
Validation Loss: 0.00059395
Epoch [21/300], Train Loss: 0.000607
Validation Loss: 0.00056992
Epoch [22/300], Train Loss: 0.000601
Validation Loss: 0.00054755
Epoch [23/300], Train Loss: 0.000635
Validation Loss: 0.00055598
Epoch [24/300], Train Loss: 0.000589
Validation Loss: 0.00054673
Epoch [25/300], Train Loss: 0.000572
Validation Loss: 0.00053954
Epoch [26/300], Train Loss: 0.000564
Validation Loss: 0.00052583
Epoch [27/300], Train Loss: 0.000574
Validation Loss: 0.00053181
Epoch [28/300], Train Loss: 0.000575
Validation Loss: 0.00051794
Epoch [29/300], Train Loss: 0.000562
Validation Loss: 0.00054464
Epoch [30/300], Train Loss: 0.000551
Validation Loss: 0.00052305
Epoch [31/300], Train Loss: 0.000540
Validation Loss: 0.00051287
Epoch [32/300], Train Loss: 0.000531
Validation Loss: 0.00052151
Epoch [33/300], Train Loss: 0.000531
Validation Loss: 0.00049584
Epoch [34/300], Train Loss: 0.000531
Validation Loss: 0.00050153
Epoch [35/300], Train Loss: 0.000519
Validation Loss: 0.00048821
Epoch [36/300], Train Loss: 0.000521
Validation Loss: 0.00054843
Epoch [37/300], Train Loss: 0.000518
Validation Loss: 0.00053307
Epoch [38/300], Train Loss: 0.000511
Validation Loss: 0.00051247
Epoch [39/300], Train Loss: 0.000500
Validation Loss: 0.00049001
Epoch [40/300], Train Loss: 0.000492
Validation Loss: 0.00047762
Epoch [41/300], Train Loss: 0.000490
Validation Loss: 0.00047660
Epoch [42/300], Train Loss: 0.000480
Validation Loss: 0.00047524
Epoch [43/300], Train Loss: 0.000473
Validation Loss: 0.00047837
Epoch [44/300], Train Loss: 0.000474
Validation Loss: 0.00046079
Epoch [45/300], Train Loss: 0.000470
Validation Loss: 0.00046183
Epoch [46/300], Train Loss: 0.000469
Validation Loss: 0.00050131
Epoch [47/300], Train Loss: 0.000467
Validation Loss: 0.00049266
Epoch [48/300], Train Loss: 0.000455
Validation Loss: 0.00048644
Epoch [49/300], Train Loss: 0.000444
Validation Loss: 0.00044195
Epoch [50/300], Train Loss: 0.000438
Validation Loss: 0.00044049
Epoch [51/300], Train Loss: 0.000428
Validation Loss: 0.00043881
Epoch [52/300], Train Loss: 0.000429
Validation Loss: 0.00042374
Epoch [53/300], Train Loss: 0.000421
Validation Loss: 0.00041303
Epoch [54/300], Train Loss: 0.000412
Validation Loss: 0.00039403
Epoch [55/300], Train Loss: 0.000404
Validation Loss: 0.00039127
Epoch [56/300], Train Loss: 0.000394
Validation Loss: 0.00040409
Epoch [57/300], Train Loss: 0.000393
Validation Loss: 0.00037570
Epoch [58/300], Train Loss: 0.000377
Validation Loss: 0.00039467
Epoch [59/300], Train Loss: 0.000384
Validation Loss: 0.00037943
Epoch [60/300], Train Loss: 0.000373
Validation Loss: 0.00037251
Epoch [61/300], Train Loss: 0.000369
Validation Loss: 0.00037471
Epoch [62/300], Train Loss: 0.000357
Validation Loss: 0.00036773
Epoch [63/300], Train Loss: 0.000350
Validation Loss: 0.00035451
Epoch [64/300], Train Loss: 0.000354
Validation Loss: 0.00035326
Epoch [65/300], Train Loss: 0.000347
Validation Loss: 0.00035760
Epoch [66/300], Train Loss: 0.000340
Validation Loss: 0.00034650
Epoch [67/300], Train Loss: 0.000345
Validation Loss: 0.00035460
Epoch [68/300], Train Loss: 0.000350
Validation Loss: 0.00034672
Epoch [69/300], Train Loss: 0.000337
Validation Loss: 0.00033753
Epoch [70/300], Train Loss: 0.000330
Validation Loss: 0.00033524
Epoch [71/300], Train Loss: 0.000325
Validation Loss: 0.00033194
Epoch [72/300], Train Loss: 0.000318
Validation Loss: 0.00032644
Epoch [73/300], Train Loss: 0.000323
Validation Loss: 0.00034247
Epoch [74/300], Train Loss: 0.000329
Validation Loss: 0.00033342
Epoch [75/300], Train Loss: 0.000316
Validation Loss: 0.00031828
Epoch [76/300], Train Loss: 0.000310
Validation Loss: 0.00031484
Epoch [77/300], Train Loss: 0.000312
Validation Loss: 0.00031980
Epoch [78/300], Train Loss: 0.000307
Validation Loss: 0.00030950
Epoch [79/300], Train Loss: 0.000306
Validation Loss: 0.00031499
Epoch [80/300], Train Loss: 0.000311
Validation Loss: 0.00030320
Epoch [81/300], Train Loss: 0.000312
Validation Loss: 0.00030142
Epoch [82/300], Train Loss: 0.000297
Validation Loss: 0.00030807
Epoch [83/300], Train Loss: 0.000290
Validation Loss: 0.00030423
Epoch [84/300], Train Loss: 0.000288
Validation Loss: 0.00029284
Epoch [85/300], Train Loss: 0.000289
Validation Loss: 0.00029785
Epoch [86/300], Train Loss: 0.000288
Validation Loss: 0.00030463
Epoch [87/300], Train Loss: 0.000286
Validation Loss: 0.00029543
Epoch [88/300], Train Loss: 0.000289
Validation Loss: 0.00028748
Epoch [89/300], Train Loss: 0.000280
Validation Loss: 0.00029399
Epoch [90/300], Train Loss: 0.000289
Validation Loss: 0.00028901
Epoch [91/300], Train Loss: 0.000281
Validation Loss: 0.00028224
Epoch [92/300], Train Loss: 0.000273
Validation Loss: 0.00028283
Epoch [93/300], Train Loss: 0.000288
Validation Loss: 0.00028704
Epoch [94/300], Train Loss: 0.000267
Validation Loss: 0.00027883
Epoch [95/300], Train Loss: 0.000264
Validation Loss: 0.00028429
Epoch [96/300], Train Loss: 0.000263
Validation Loss: 0.00028132
Epoch [97/300], Train Loss: 0.000257
Validation Loss: 0.00027450
Epoch [98/300], Train Loss: 0.000260
Validation Loss: 0.00027613
Epoch [99/300], Train Loss: 0.000261
Validation Loss: 0.00027675
Epoch [100/300], Train Loss: 0.000262
Validation Loss: 0.00027692
Epoch [101/300], Train Loss: 0.000260
Validation Loss: 0.00026597
Epoch [102/300], Train Loss: 0.000261
Validation Loss: 0.00026335
Epoch [103/300], Train Loss: 0.000260
Validation Loss: 0.00028431
Epoch [104/300], Train Loss: 0.000256
Validation Loss: 0.00026674
Epoch [105/300], Train Loss: 0.000247
Validation Loss: 0.00025658
Epoch [106/300], Train Loss: 0.000253
Validation Loss: 0.00027021
Epoch [107/300], Train Loss: 0.000250
Validation Loss: 0.00025681
Epoch [108/300], Train Loss: 0.000250
Validation Loss: 0.00025615
Epoch [109/300], Train Loss: 0.000246
Validation Loss: 0.00025410
Epoch [110/300], Train Loss: 0.000247
Validation Loss: 0.00026743
Epoch [111/300], Train Loss: 0.000245
Validation Loss: 0.00025105
Epoch [112/300], Train Loss: 0.000238
Validation Loss: 0.00024708
Epoch [113/300], Train Loss: 0.000239
Validation Loss: 0.00025151
Epoch [114/300], Train Loss: 0.000235
Validation Loss: 0.00025279
Epoch [115/300], Train Loss: 0.000275
Validation Loss: 0.00027469
Epoch [116/300], Train Loss: 0.000244
Validation Loss: 0.00025167
Epoch [117/300], Train Loss: 0.000236
Validation Loss: 0.00024646
Epoch [118/300], Train Loss: 0.000244
Validation Loss: 0.00024656
Epoch [119/300], Train Loss: 0.000241
Validation Loss: 0.00025433
Epoch [120/300], Train Loss: 0.000243
Validation Loss: 0.00025741
Epoch [121/300], Train Loss: 0.000238
Validation Loss: 0.00024681
Epoch [122/300], Train Loss: 0.000229
Validation Loss: 0.00024768
Epoch [123/300], Train Loss: 0.000227
Validation Loss: 0.00024427
Epoch [124/300], Train Loss: 0.000227
Validation Loss: 0.00023879
Epoch [125/300], Train Loss: 0.000227
Validation Loss: 0.00024041
Epoch [126/300], Train Loss: 0.000230
Validation Loss: 0.00024450
Epoch [127/300], Train Loss: 0.000225
Validation Loss: 0.00023614
Epoch [128/300], Train Loss: 0.000223
Validation Loss: 0.00023985
Epoch [129/300], Train Loss: 0.000221
Validation Loss: 0.00024722
Epoch [130/300], Train Loss: 0.000221
Validation Loss: 0.00024398
Epoch [131/300], Train Loss: 0.000224
Validation Loss: 0.00024522
Epoch [132/300], Train Loss: 0.000224
Validation Loss: 0.00024028
Epoch [133/300], Train Loss: 0.000216
Validation Loss: 0.00023773
Epoch [134/300], Train Loss: 0.000226
Validation Loss: 0.00025228
Epoch [135/300], Train Loss: 0.000225
Validation Loss: 0.00024236
Epoch [136/300], Train Loss: 0.000213
Validation Loss: 0.00023915
Epoch [137/300], Train Loss: 0.000214
Validation Loss: 0.00023797
Early stopping triggered

Evaluating model for: Coffee Machine
Run 29/72 completed in 3363.70 seconds with: {'MAE': np.float32(3.7846708), 'MSE': np.float32(869.0766), 'RMSE': np.float32(29.480104), 'SAE': np.float32(0.04369701), 'NDE': np.float32(0.4764628)}

Run 30/72: hidden=256, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Coffee Machine
Dataset length: 18100 windows

Epoch [1/300], Train Loss: 0.001053
Validation Loss: 0.00094382
Epoch [2/300], Train Loss: 0.000978
Validation Loss: 0.00093978
Epoch [3/300], Train Loss: 0.000993
Validation Loss: 0.00093645
Epoch [4/300], Train Loss: 0.000981
Validation Loss: 0.00093370
Epoch [5/300], Train Loss: 0.000967
Validation Loss: 0.00093416
Epoch [6/300], Train Loss: 0.000970
Validation Loss: 0.00092853
Epoch [7/300], Train Loss: 0.000961
Validation Loss: 0.00092362
Epoch [8/300], Train Loss: 0.000952
Validation Loss: 0.00091044
Epoch [9/300], Train Loss: 0.000944
Validation Loss: 0.00089307
Epoch [10/300], Train Loss: 0.000914
Validation Loss: 0.00085033
Epoch [11/300], Train Loss: 0.000844
Validation Loss: 0.00079188
Epoch [12/300], Train Loss: 0.000787
Validation Loss: 0.00076044
Epoch [13/300], Train Loss: 0.000765
Validation Loss: 0.00075989
Epoch [14/300], Train Loss: 0.000734
Validation Loss: 0.00072124
Epoch [15/300], Train Loss: 0.000700
Validation Loss: 0.00070388
Epoch [16/300], Train Loss: 0.000679
Validation Loss: 0.00068190
Epoch [17/300], Train Loss: 0.000673
Validation Loss: 0.00067113
Epoch [18/300], Train Loss: 0.000677
Validation Loss: 0.00067627
Epoch [19/300], Train Loss: 0.000642
Validation Loss: 0.00063531
Epoch [20/300], Train Loss: 0.000619
Validation Loss: 0.00062192
Epoch [21/300], Train Loss: 0.000605
Validation Loss: 0.00060901
Epoch [22/300], Train Loss: 0.000591
Validation Loss: 0.00063838
Epoch [23/300], Train Loss: 0.000620
Validation Loss: 0.00060366
Epoch [24/300], Train Loss: 0.000589
Validation Loss: 0.00061534
Epoch [25/300], Train Loss: 0.000579
Validation Loss: 0.00058166
Epoch [26/300], Train Loss: 0.000562
Validation Loss: 0.00058087
Epoch [27/300], Train Loss: 0.000568
Validation Loss: 0.00057378
Epoch [28/300], Train Loss: 0.000566
Validation Loss: 0.00054353
Epoch [29/300], Train Loss: 0.000564
Validation Loss: 0.00054472
Epoch [30/300], Train Loss: 0.000539
Validation Loss: 0.00054498
Epoch [31/300], Train Loss: 0.000542
Validation Loss: 0.00054589
Epoch [32/300], Train Loss: 0.000529
Validation Loss: 0.00051460
Epoch [33/300], Train Loss: 0.000529
Validation Loss: 0.00052572
Epoch [34/300], Train Loss: 0.000518
Validation Loss: 0.00052135
Epoch [35/300], Train Loss: 0.000512
Validation Loss: 0.00049658
Epoch [36/300], Train Loss: 0.000542
Validation Loss: 0.00053311
Epoch [37/300], Train Loss: 0.000507
Validation Loss: 0.00049887
Epoch [38/300], Train Loss: 0.000509
Validation Loss: 0.00048376
Epoch [39/300], Train Loss: 0.000482
Validation Loss: 0.00047249
Epoch [40/300], Train Loss: 0.000479
Validation Loss: 0.00046788
Epoch [41/300], Train Loss: 0.000471
Validation Loss: 0.00047928
Epoch [42/300], Train Loss: 0.000459
Validation Loss: 0.00043938
Epoch [43/300], Train Loss: 0.000441
Validation Loss: 0.00043485
Epoch [44/300], Train Loss: 0.000432
Validation Loss: 0.00040885
Epoch [45/300], Train Loss: 0.000420
Validation Loss: 0.00040263
Epoch [46/300], Train Loss: 0.000431
Validation Loss: 0.00037534
Epoch [47/300], Train Loss: 0.000406
Validation Loss: 0.00040717
Epoch [48/300], Train Loss: 0.000403
Validation Loss: 0.00036927
Epoch [49/300], Train Loss: 0.000392
Validation Loss: 0.00034763
Epoch [50/300], Train Loss: 0.000379
Validation Loss: 0.00034694
Epoch [51/300], Train Loss: 0.000376
Validation Loss: 0.00034966
Epoch [52/300], Train Loss: 0.000361
Validation Loss: 0.00033133
Epoch [53/300], Train Loss: 0.000359
Validation Loss: 0.00032553
Epoch [54/300], Train Loss: 0.000370
Validation Loss: 0.00035983
Epoch [55/300], Train Loss: 0.000360
Validation Loss: 0.00032606
Epoch [56/300], Train Loss: 0.000345
Validation Loss: 0.00035265
Epoch [57/300], Train Loss: 0.000340
Validation Loss: 0.00040268
Epoch [58/300], Train Loss: 0.000343
Validation Loss: 0.00032987
Epoch [59/300], Train Loss: 0.000339
Validation Loss: 0.00030560
Epoch [60/300], Train Loss: 0.000326
Validation Loss: 0.00033269
Epoch [61/300], Train Loss: 0.000317
Validation Loss: 0.00031312
Epoch [62/300], Train Loss: 0.000315
Validation Loss: 0.00030511
Epoch [63/300], Train Loss: 0.000312
Validation Loss: 0.00029784
Epoch [64/300], Train Loss: 0.000314
Validation Loss: 0.00029181
Epoch [65/300], Train Loss: 0.000312
Validation Loss: 0.00032101
Epoch [66/300], Train Loss: 0.000312
Validation Loss: 0.00031872
Epoch [67/300], Train Loss: 0.000306
Validation Loss: 0.00029490
Epoch [68/300], Train Loss: 0.000311
Validation Loss: 0.00031182
Epoch [69/300], Train Loss: 0.000298
Validation Loss: 0.00028497
Epoch [70/300], Train Loss: 0.000302
Validation Loss: 0.00028781
Epoch [71/300], Train Loss: 0.000293
Validation Loss: 0.00029108
Epoch [72/300], Train Loss: 0.000295
Validation Loss: 0.00030285
Epoch [73/300], Train Loss: 0.000294
Validation Loss: 0.00028450
Epoch [74/300], Train Loss: 0.000286
Validation Loss: 0.00027650
Epoch [75/300], Train Loss: 0.000292
Validation Loss: 0.00028280
Epoch [76/300], Train Loss: 0.000283
Validation Loss: 0.00028872
Epoch [77/300], Train Loss: 0.000284
Validation Loss: 0.00027608
Epoch [78/300], Train Loss: 0.000274
Validation Loss: 0.00028146
Epoch [79/300], Train Loss: 0.000268
Validation Loss: 0.00027142
Epoch [80/300], Train Loss: 0.000281
Validation Loss: 0.00027597
Epoch [81/300], Train Loss: 0.000305
Validation Loss: 0.00027752
Epoch [82/300], Train Loss: 0.000268
Validation Loss: 0.00027372
Epoch [83/300], Train Loss: 0.000262
Validation Loss: 0.00026604
Epoch [84/300], Train Loss: 0.000278
Validation Loss: 0.00029135
Epoch [85/300], Train Loss: 0.000265
Validation Loss: 0.00028086
Epoch [86/300], Train Loss: 0.000264
Validation Loss: 0.00027858
Epoch [87/300], Train Loss: 0.000259
Validation Loss: 0.00026829
Epoch [88/300], Train Loss: 0.000258
Validation Loss: 0.00027244
Epoch [89/300], Train Loss: 0.000293
Validation Loss: 0.00027963
Epoch [90/300], Train Loss: 0.000258
Validation Loss: 0.00026453
Epoch [91/300], Train Loss: 0.000250
Validation Loss: 0.00026282
Epoch [92/300], Train Loss: 0.000255
Validation Loss: 0.00027004
Epoch [93/300], Train Loss: 0.000271
Validation Loss: 0.00025251
Epoch [94/300], Train Loss: 0.000260
Validation Loss: 0.00025643
Epoch [95/300], Train Loss: 0.000252
Validation Loss: 0.00028259
Epoch [96/300], Train Loss: 0.000258
Validation Loss: 0.00026098
Epoch [97/300], Train Loss: 0.000245
Validation Loss: 0.00025459
Epoch [98/300], Train Loss: 0.000244
Validation Loss: 0.00027280
Epoch [99/300], Train Loss: 0.000253
Validation Loss: 0.00026984
Epoch [100/300], Train Loss: 0.000246
Validation Loss: 0.00025415
Epoch [101/300], Train Loss: 0.000243
Validation Loss: 0.00025109
Epoch [102/300], Train Loss: 0.000235
Validation Loss: 0.00031088
Epoch [103/300], Train Loss: 0.000267
Validation Loss: 0.00025747
Epoch [104/300], Train Loss: 0.000239
Validation Loss: 0.00025240
Epoch [105/300], Train Loss: 0.000233
Validation Loss: 0.00024905
Epoch [106/300], Train Loss: 0.000263
Validation Loss: 0.00032018
Epoch [107/300], Train Loss: 0.000258
Validation Loss: 0.00026113
Epoch [108/300], Train Loss: 0.000237
Validation Loss: 0.00025202
Epoch [109/300], Train Loss: 0.000228
Validation Loss: 0.00025387
Epoch [110/300], Train Loss: 0.000232
Validation Loss: 0.00025402
Epoch [111/300], Train Loss: 0.000226
Validation Loss: 0.00024960
Epoch [112/300], Train Loss: 0.000225
Validation Loss: 0.00025379
Epoch [113/300], Train Loss: 0.000247
Validation Loss: 0.00025202
Epoch [114/300], Train Loss: 0.000224
Validation Loss: 0.00024914
Epoch [115/300], Train Loss: 0.000228
Validation Loss: 0.00025527
Early stopping triggered

Evaluating model for: Coffee Machine
Run 30/72 completed in 2972.60 seconds with: {'MAE': np.float32(3.5708103), 'MSE': np.float32(976.4321), 'RMSE': np.float32(31.247913), 'SAE': np.float32(0.08418482), 'NDE': np.float32(0.50503397)}

Run 31/72: hidden=256, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Coffee Machine
Dataset length: 18100 windows

Epoch [1/300], Train Loss: 0.000979
Validation Loss: 0.00093391
Epoch [2/300], Train Loss: 0.000966
Validation Loss: 0.00093409
Epoch [3/300], Train Loss: 0.000985
Validation Loss: 0.00093218
Epoch [4/300], Train Loss: 0.000975
Validation Loss: 0.00093271
Epoch [5/300], Train Loss: 0.000960
Validation Loss: 0.00092510
Epoch [6/300], Train Loss: 0.000961
Validation Loss: 0.00091866
Epoch [7/300], Train Loss: 0.000941
Validation Loss: 0.00089473
Epoch [8/300], Train Loss: 0.000906
Validation Loss: 0.00084556
Epoch [9/300], Train Loss: 0.000842
Validation Loss: 0.00077926
Epoch [10/300], Train Loss: 0.000779
Validation Loss: 0.00073448
Epoch [11/300], Train Loss: 0.000722
Validation Loss: 0.00074713
Epoch [12/300], Train Loss: 0.000704
Validation Loss: 0.00069351
Epoch [13/300], Train Loss: 0.000704
Validation Loss: 0.00073422
Epoch [14/300], Train Loss: 0.000652
Validation Loss: 0.00067373
Epoch [15/300], Train Loss: 0.000639
Validation Loss: 0.00064966
Epoch [16/300], Train Loss: 0.000620
Validation Loss: 0.00062769
Epoch [17/300], Train Loss: 0.000604
Validation Loss: 0.00060952
Epoch [18/300], Train Loss: 0.000627
Validation Loss: 0.00063114
Epoch [19/300], Train Loss: 0.000587
Validation Loss: 0.00060612
Epoch [20/300], Train Loss: 0.000565
Validation Loss: 0.00055209
Epoch [21/300], Train Loss: 0.000555
Validation Loss: 0.00053914
Epoch [22/300], Train Loss: 0.000525
Validation Loss: 0.00050756
Epoch [23/300], Train Loss: 0.000541
Validation Loss: 0.00050759
Epoch [24/300], Train Loss: 0.000499
Validation Loss: 0.00048258
Epoch [25/300], Train Loss: 0.000475
Validation Loss: 0.00046170
Epoch [26/300], Train Loss: 0.000450
Validation Loss: 0.00044600
Epoch [27/300], Train Loss: 0.000444
Validation Loss: 0.00044806
Epoch [28/300], Train Loss: 0.000438
Validation Loss: 0.00043214
Epoch [29/300], Train Loss: 0.000414
Validation Loss: 0.00042237
Epoch [30/300], Train Loss: 0.000401
Validation Loss: 0.00042054
Epoch [31/300], Train Loss: 0.000402
Validation Loss: 0.00041677
Epoch [32/300], Train Loss: 0.000384
Validation Loss: 0.00040326
Epoch [33/300], Train Loss: 0.000393
Validation Loss: 0.00042667
Epoch [34/300], Train Loss: 0.000368
Validation Loss: 0.00040674
Epoch [35/300], Train Loss: 0.000366
Validation Loss: 0.00038510
Epoch [36/300], Train Loss: 0.000367
Validation Loss: 0.00037639
Epoch [37/300], Train Loss: 0.000351
Validation Loss: 0.00037735
Epoch [38/300], Train Loss: 0.000358
Validation Loss: 0.00039230
Epoch [39/300], Train Loss: 0.000340
Validation Loss: 0.00036765
Epoch [40/300], Train Loss: 0.000337
Validation Loss: 0.00037421
Epoch [41/300], Train Loss: 0.000338
Validation Loss: 0.00035465
Epoch [42/300], Train Loss: 0.000328
Validation Loss: 0.00035250
Epoch [43/300], Train Loss: 0.000324
Validation Loss: 0.00035133
Epoch [44/300], Train Loss: 0.000344
Validation Loss: 0.00038767
Epoch [45/300], Train Loss: 0.000347
Validation Loss: 0.00039606
Epoch [46/300], Train Loss: 0.000340
Validation Loss: 0.00035453
Epoch [47/300], Train Loss: 0.000327
Validation Loss: 0.00036605
Epoch [48/300], Train Loss: 0.000328
Validation Loss: 0.00033852
Epoch [49/300], Train Loss: 0.000312
Validation Loss: 0.00031335
Epoch [50/300], Train Loss: 0.000318
Validation Loss: 0.00031547
Epoch [51/300], Train Loss: 0.000306
Validation Loss: 0.00030010
Epoch [52/300], Train Loss: 0.000301
Validation Loss: 0.00030783
Epoch [53/300], Train Loss: 0.000303
Validation Loss: 0.00034144
Epoch [54/300], Train Loss: 0.000306
Validation Loss: 0.00030451
Epoch [55/300], Train Loss: 0.000297
Validation Loss: 0.00031392
Epoch [56/300], Train Loss: 0.000288
Validation Loss: 0.00030441
Epoch [57/300], Train Loss: 0.000296
Validation Loss: 0.00029970
Epoch [58/300], Train Loss: 0.000296
Validation Loss: 0.00031442
Epoch [59/300], Train Loss: 0.000286
Validation Loss: 0.00029664
Epoch [60/300], Train Loss: 0.000276
Validation Loss: 0.00032642
Epoch [61/300], Train Loss: 0.000278
Validation Loss: 0.00032698
Epoch [62/300], Train Loss: 0.000277
Validation Loss: 0.00029917
Epoch [63/300], Train Loss: 0.000278
Validation Loss: 0.00032192
Epoch [64/300], Train Loss: 0.000273
Validation Loss: 0.00031368
Epoch [65/300], Train Loss: 0.000275
Validation Loss: 0.00029112
Epoch [66/300], Train Loss: 0.000280
Validation Loss: 0.00030826
Epoch [67/300], Train Loss: 0.000270
Validation Loss: 0.00030205
Epoch [68/300], Train Loss: 0.000272
Validation Loss: 0.00029005
Epoch [69/300], Train Loss: 0.000288
Validation Loss: 0.00033010
Epoch [70/300], Train Loss: 0.000273
Validation Loss: 0.00028826
Epoch [71/300], Train Loss: 0.000265
Validation Loss: 0.00032570
Epoch [72/300], Train Loss: 0.000266
Validation Loss: 0.00029135
Epoch [73/300], Train Loss: 0.000256
Validation Loss: 0.00028910
Epoch [74/300], Train Loss: 0.000256
Validation Loss: 0.00029334
Epoch [75/300], Train Loss: 0.000256
Validation Loss: 0.00032515
Epoch [76/300], Train Loss: 0.000245
Validation Loss: 0.00033944
Epoch [77/300], Train Loss: 0.000277
Validation Loss: 0.00031820
Epoch [78/300], Train Loss: 0.000254
Validation Loss: 0.00029077
Epoch [79/300], Train Loss: 0.000248
Validation Loss: 0.00031805
Epoch [80/300], Train Loss: 0.000249
Validation Loss: 0.00031539
Early stopping triggered

Evaluating model for: Coffee Machine
Run 31/72 completed in 2205.62 seconds with: {'MAE': np.float32(3.5863488), 'MSE': np.float32(1166.3475), 'RMSE': np.float32(34.15183), 'SAE': np.float32(0.04474291), 'NDE': np.float32(0.5519671)}

Run 32/72: hidden=256, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Coffee Machine
Dataset length: 18100 windows

Epoch [1/300], Train Loss: 0.001080
Validation Loss: 0.00094518
Epoch [2/300], Train Loss: 0.000983
Validation Loss: 0.00094135
Epoch [3/300], Train Loss: 0.000997
Validation Loss: 0.00093886
Epoch [4/300], Train Loss: 0.000986
Validation Loss: 0.00093772
Epoch [5/300], Train Loss: 0.000972
Validation Loss: 0.00093908
Epoch [6/300], Train Loss: 0.000977
Validation Loss: 0.00093576
Epoch [7/300], Train Loss: 0.000969
Validation Loss: 0.00093500
Epoch [8/300], Train Loss: 0.000968
Validation Loss: 0.00093431
Epoch [9/300], Train Loss: 0.000975
Validation Loss: 0.00093314
Epoch [10/300], Train Loss: 0.000972
Validation Loss: 0.00093003
Epoch [11/300], Train Loss: 0.000962
Validation Loss: 0.00092767
Epoch [12/300], Train Loss: 0.000956
Validation Loss: 0.00091722
Epoch [13/300], Train Loss: 0.000962
Validation Loss: 0.00089009
Epoch [14/300], Train Loss: 0.000892
Validation Loss: 0.00082714
Epoch [15/300], Train Loss: 0.000800
Validation Loss: 0.00076661
Epoch [16/300], Train Loss: 0.000737
Validation Loss: 0.00074640
Epoch [17/300], Train Loss: 0.000701
Validation Loss: 0.00071935
Epoch [18/300], Train Loss: 0.000693
Validation Loss: 0.00072810
Epoch [19/300], Train Loss: 0.000645
Validation Loss: 0.00069681
Epoch [20/300], Train Loss: 0.000626
Validation Loss: 0.00064479
Epoch [21/300], Train Loss: 0.000627
Validation Loss: 0.00064567
Epoch [22/300], Train Loss: 0.000605
Validation Loss: 0.00063145
Epoch [23/300], Train Loss: 0.000628
Validation Loss: 0.00061977
Epoch [24/300], Train Loss: 0.000581
Validation Loss: 0.00056930
Epoch [25/300], Train Loss: 0.000550
Validation Loss: 0.00051337
Epoch [26/300], Train Loss: 0.000488
Validation Loss: 0.00045897
Epoch [27/300], Train Loss: 0.000459
Validation Loss: 0.00044020
Epoch [28/300], Train Loss: 0.000461
Validation Loss: 0.00041335
Epoch [29/300], Train Loss: 0.000424
Validation Loss: 0.00038281
Epoch [30/300], Train Loss: 0.000404
Validation Loss: 0.00037054
Epoch [31/300], Train Loss: 0.000398
Validation Loss: 0.00035148
Epoch [32/300], Train Loss: 0.000379
Validation Loss: 0.00036543
Epoch [33/300], Train Loss: 0.000386
Validation Loss: 0.00034239
Epoch [34/300], Train Loss: 0.000359
Validation Loss: 0.00034687
Epoch [35/300], Train Loss: 0.000364
Validation Loss: 0.00032971
Epoch [36/300], Train Loss: 0.000365
Validation Loss: 0.00032502
Epoch [37/300], Train Loss: 0.000349
Validation Loss: 0.00034040
Epoch [38/300], Train Loss: 0.000352
Validation Loss: 0.00035988
Epoch [39/300], Train Loss: 0.000340
Validation Loss: 0.00031314
Epoch [40/300], Train Loss: 0.000334
Validation Loss: 0.00031564
Epoch [41/300], Train Loss: 0.000334
Validation Loss: 0.00031663
Epoch [42/300], Train Loss: 0.000357
Validation Loss: 0.00032905
Epoch [43/300], Train Loss: 0.000338
Validation Loss: 0.00032618
Epoch [44/300], Train Loss: 0.000330
Validation Loss: 0.00031202
Epoch [45/300], Train Loss: 0.000317
Validation Loss: 0.00034638
Epoch [46/300], Train Loss: 0.000317
Validation Loss: 0.00030622
Epoch [47/300], Train Loss: 0.000310
Validation Loss: 0.00030358
Epoch [48/300], Train Loss: 0.000318
Validation Loss: 0.00030807
Epoch [49/300], Train Loss: 0.000313
Validation Loss: 0.00031076
Epoch [50/300], Train Loss: 0.000300
Validation Loss: 0.00030382
Epoch [51/300], Train Loss: 0.000298
Validation Loss: 0.00031801
Epoch [52/300], Train Loss: 0.000300
Validation Loss: 0.00030368
Epoch [53/300], Train Loss: 0.000291
Validation Loss: 0.00030062
Epoch [54/300], Train Loss: 0.000290
Validation Loss: 0.00029742
Epoch [55/300], Train Loss: 0.000290
Validation Loss: 0.00032614
Epoch [56/300], Train Loss: 0.000288
Validation Loss: 0.00029428
Epoch [57/300], Train Loss: 0.000292
Validation Loss: 0.00029593
Epoch [58/300], Train Loss: 0.000279
Validation Loss: 0.00029465
Epoch [59/300], Train Loss: 0.000274
Validation Loss: 0.00029392
Epoch [60/300], Train Loss: 0.000277
Validation Loss: 0.00029323
Epoch [61/300], Train Loss: 0.000273
Validation Loss: 0.00029449
Epoch [62/300], Train Loss: 0.000273
Validation Loss: 0.00029876
Epoch [63/300], Train Loss: 0.000271
Validation Loss: 0.00029300
Epoch [64/300], Train Loss: 0.000262
Validation Loss: 0.00030322
Epoch [65/300], Train Loss: 0.000261
Validation Loss: 0.00029479
Epoch [66/300], Train Loss: 0.000261
Validation Loss: 0.00028831
Epoch [67/300], Train Loss: 0.000259
Validation Loss: 0.00029214
Epoch [68/300], Train Loss: 0.000261
Validation Loss: 0.00029886
Epoch [69/300], Train Loss: 0.000256
Validation Loss: 0.00029536
Epoch [70/300], Train Loss: 0.000257
Validation Loss: 0.00028584
Epoch [71/300], Train Loss: 0.000247
Validation Loss: 0.00028481
Epoch [72/300], Train Loss: 0.000245
Validation Loss: 0.00030511
Epoch [73/300], Train Loss: 0.000244
Validation Loss: 0.00029065
Epoch [74/300], Train Loss: 0.000247
Validation Loss: 0.00028743
Epoch [75/300], Train Loss: 0.000248
Validation Loss: 0.00029282
Epoch [76/300], Train Loss: 0.000241
Validation Loss: 0.00030151
Epoch [77/300], Train Loss: 0.000243
Validation Loss: 0.00028395
Epoch [78/300], Train Loss: 0.000236
Validation Loss: 0.00028541
Epoch [79/300], Train Loss: 0.000236
Validation Loss: 0.00028490
Epoch [80/300], Train Loss: 0.000242
Validation Loss: 0.00029507
Epoch [81/300], Train Loss: 0.000268
Validation Loss: 0.00028813
Epoch [82/300], Train Loss: 0.000235
Validation Loss: 0.00028881
Epoch [83/300], Train Loss: 0.000228
Validation Loss: 0.00027427
Epoch [84/300], Train Loss: 0.000234
Validation Loss: 0.00027042
Epoch [85/300], Train Loss: 0.000221
Validation Loss: 0.00028720
Epoch [86/300], Train Loss: 0.000223
Validation Loss: 0.00027333
Epoch [87/300], Train Loss: 0.000217
Validation Loss: 0.00028297
Epoch [88/300], Train Loss: 0.000229
Validation Loss: 0.00028969
Epoch [89/300], Train Loss: 0.000227
Validation Loss: 0.00030411
Epoch [90/300], Train Loss: 0.000221
Validation Loss: 0.00030904
Epoch [91/300], Train Loss: 0.000227
Validation Loss: 0.00028871
Epoch [92/300], Train Loss: 0.000215
Validation Loss: 0.00029055
Epoch [93/300], Train Loss: 0.000220
Validation Loss: 0.00028634
Epoch [94/300], Train Loss: 0.000216
Validation Loss: 0.00029077
Early stopping triggered

Evaluating model for: Coffee Machine
Run 32/72 completed in 2921.00 seconds with: {'MAE': np.float32(3.3207562), 'MSE': np.float32(1064.6863), 'RMSE': np.float32(32.62953), 'SAE': np.float32(0.0925406), 'NDE': np.float32(0.52736366)}

Run 33/72: hidden=256, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Coffee Machine
Dataset length: 11964 windows

Epoch [1/300], Train Loss: 0.000991
Validation Loss: 0.00102778
Epoch [2/300], Train Loss: 0.000945
Validation Loss: 0.00102589
Epoch [3/300], Train Loss: 0.000942
Validation Loss: 0.00102390
Epoch [4/300], Train Loss: 0.000939
Validation Loss: 0.00102134
Epoch [5/300], Train Loss: 0.000937
Validation Loss: 0.00101966
Epoch [6/300], Train Loss: 0.000931
Validation Loss: 0.00101262
Epoch [7/300], Train Loss: 0.000925
Validation Loss: 0.00100557
Epoch [8/300], Train Loss: 0.000915
Validation Loss: 0.00099291
Epoch [9/300], Train Loss: 0.000905
Validation Loss: 0.00097904
Epoch [10/300], Train Loss: 0.000891
Validation Loss: 0.00095476
Epoch [11/300], Train Loss: 0.000866
Validation Loss: 0.00092388
Epoch [12/300], Train Loss: 0.000835
Validation Loss: 0.00087950
Epoch [13/300], Train Loss: 0.000798
Validation Loss: 0.00083626
Epoch [14/300], Train Loss: 0.000758
Validation Loss: 0.00079010
Epoch [15/300], Train Loss: 0.000727
Validation Loss: 0.00079383
Epoch [16/300], Train Loss: 0.000702
Validation Loss: 0.00074303
Epoch [17/300], Train Loss: 0.000675
Validation Loss: 0.00072117
Epoch [18/300], Train Loss: 0.000659
Validation Loss: 0.00069976
Epoch [19/300], Train Loss: 0.000640
Validation Loss: 0.00067751
Epoch [20/300], Train Loss: 0.000624
Validation Loss: 0.00067013
Epoch [21/300], Train Loss: 0.000616
Validation Loss: 0.00065388
Epoch [22/300], Train Loss: 0.000594
Validation Loss: 0.00064401
Epoch [23/300], Train Loss: 0.000587
Validation Loss: 0.00063085
Epoch [24/300], Train Loss: 0.000575
Validation Loss: 0.00062105
Epoch [25/300], Train Loss: 0.000562
Validation Loss: 0.00060163
Epoch [26/300], Train Loss: 0.000552
Validation Loss: 0.00059824
Epoch [27/300], Train Loss: 0.000553
Validation Loss: 0.00058760
Epoch [28/300], Train Loss: 0.000537
Validation Loss: 0.00058720
Epoch [29/300], Train Loss: 0.000538
Validation Loss: 0.00056998
Epoch [30/300], Train Loss: 0.000522
Validation Loss: 0.00055844
Epoch [31/300], Train Loss: 0.000519
Validation Loss: 0.00055974
Epoch [32/300], Train Loss: 0.000510
Validation Loss: 0.00055814
Epoch [33/300], Train Loss: 0.000503
Validation Loss: 0.00053132
Epoch [34/300], Train Loss: 0.000502
Validation Loss: 0.00053552
Epoch [35/300], Train Loss: 0.000496
Validation Loss: 0.00053013
Epoch [36/300], Train Loss: 0.000488
Validation Loss: 0.00053939
Epoch [37/300], Train Loss: 0.000486
Validation Loss: 0.00050753
Epoch [38/300], Train Loss: 0.000472
Validation Loss: 0.00050606
Epoch [39/300], Train Loss: 0.000469
Validation Loss: 0.00052178
Epoch [40/300], Train Loss: 0.000470
Validation Loss: 0.00049559
Epoch [41/300], Train Loss: 0.000462
Validation Loss: 0.00048122
Epoch [42/300], Train Loss: 0.000454
Validation Loss: 0.00048157
Epoch [43/300], Train Loss: 0.000452
Validation Loss: 0.00048023
Epoch [44/300], Train Loss: 0.000441
Validation Loss: 0.00050275
Epoch [45/300], Train Loss: 0.000442
Validation Loss: 0.00048594
Epoch [46/300], Train Loss: 0.000431
Validation Loss: 0.00046039
Epoch [47/300], Train Loss: 0.000432
Validation Loss: 0.00045224
Epoch [48/300], Train Loss: 0.000422
Validation Loss: 0.00044532
Epoch [49/300], Train Loss: 0.000416
Validation Loss: 0.00044155
Epoch [50/300], Train Loss: 0.000409
Validation Loss: 0.00045016
Epoch [51/300], Train Loss: 0.000412
Validation Loss: 0.00043784
Epoch [52/300], Train Loss: 0.000404
Validation Loss: 0.00043028
Epoch [53/300], Train Loss: 0.000397
Validation Loss: 0.00042555
Epoch [54/300], Train Loss: 0.000396
Validation Loss: 0.00041273
Epoch [55/300], Train Loss: 0.000393
Validation Loss: 0.00041708
Epoch [56/300], Train Loss: 0.000386
Validation Loss: 0.00042205
Epoch [57/300], Train Loss: 0.000383
Validation Loss: 0.00041535
Epoch [58/300], Train Loss: 0.000373
Validation Loss: 0.00039433
Epoch [59/300], Train Loss: 0.000380
Validation Loss: 0.00042864
Epoch [60/300], Train Loss: 0.000371
Validation Loss: 0.00039032
Epoch [61/300], Train Loss: 0.000362
Validation Loss: 0.00039176
Epoch [62/300], Train Loss: 0.000356
Validation Loss: 0.00039121
Epoch [63/300], Train Loss: 0.000360
Validation Loss: 0.00037889
Epoch [64/300], Train Loss: 0.000348
Validation Loss: 0.00037987
Epoch [65/300], Train Loss: 0.000348
Validation Loss: 0.00038873
Epoch [66/300], Train Loss: 0.000341
Validation Loss: 0.00036939
Epoch [67/300], Train Loss: 0.000337
Validation Loss: 0.00038081
Epoch [68/300], Train Loss: 0.000336
Validation Loss: 0.00035834
Epoch [69/300], Train Loss: 0.000329
Validation Loss: 0.00035556
Epoch [70/300], Train Loss: 0.000362
Validation Loss: 0.00038087
Epoch [71/300], Train Loss: 0.000366
Validation Loss: 0.00037872
Epoch [72/300], Train Loss: 0.000344
Validation Loss: 0.00035846
Epoch [73/300], Train Loss: 0.000374
Validation Loss: 0.00037280
Epoch [74/300], Train Loss: 0.000347
Validation Loss: 0.00036697
Epoch [75/300], Train Loss: 0.000339
Validation Loss: 0.00035555
Epoch [76/300], Train Loss: 0.000328
Validation Loss: 0.00034958
Epoch [77/300], Train Loss: 0.000329
Validation Loss: 0.00036846
Epoch [78/300], Train Loss: 0.000319
Validation Loss: 0.00035071
Epoch [79/300], Train Loss: 0.000323
Validation Loss: 0.00033839
Epoch [80/300], Train Loss: 0.000313
Validation Loss: 0.00033884
Epoch [81/300], Train Loss: 0.000303
Validation Loss: 0.00032369
Epoch [82/300], Train Loss: 0.000300
Validation Loss: 0.00032253
Epoch [83/300], Train Loss: 0.000300
Validation Loss: 0.00031676
Epoch [84/300], Train Loss: 0.000292
Validation Loss: 0.00033034
Epoch [85/300], Train Loss: 0.000290
Validation Loss: 0.00032648
Epoch [86/300], Train Loss: 0.000291
Validation Loss: 0.00030353
Epoch [87/300], Train Loss: 0.000281
Validation Loss: 0.00030726
Epoch [88/300], Train Loss: 0.000287
Validation Loss: 0.00032058
Epoch [89/300], Train Loss: 0.000294
Validation Loss: 0.00030589
Epoch [90/300], Train Loss: 0.000274
Validation Loss: 0.00029843
Epoch [91/300], Train Loss: 0.000270
Validation Loss: 0.00029677
Epoch [92/300], Train Loss: 0.000269
Validation Loss: 0.00028922
Epoch [93/300], Train Loss: 0.000266
Validation Loss: 0.00029175
Epoch [94/300], Train Loss: 0.000266
Validation Loss: 0.00029108
Epoch [95/300], Train Loss: 0.000265
Validation Loss: 0.00028303
Epoch [96/300], Train Loss: 0.000267
Validation Loss: 0.00029238
Epoch [97/300], Train Loss: 0.000266
Validation Loss: 0.00028465
Epoch [98/300], Train Loss: 0.000256
Validation Loss: 0.00031063
Epoch [99/300], Train Loss: 0.000259
Validation Loss: 0.00028048
Epoch [100/300], Train Loss: 0.000248
Validation Loss: 0.00027246
Epoch [101/300], Train Loss: 0.000251
Validation Loss: 0.00026722
Epoch [102/300], Train Loss: 0.000253
Validation Loss: 0.00027793
Epoch [103/300], Train Loss: 0.000244
Validation Loss: 0.00025828
Epoch [104/300], Train Loss: 0.000245
Validation Loss: 0.00026888
Epoch [105/300], Train Loss: 0.000249
Validation Loss: 0.00025328
Epoch [106/300], Train Loss: 0.000238
Validation Loss: 0.00026146
Epoch [107/300], Train Loss: 0.000238
Validation Loss: 0.00026267
Epoch [108/300], Train Loss: 0.000236
Validation Loss: 0.00025344
Epoch [109/300], Train Loss: 0.000237
Validation Loss: 0.00024868
Epoch [110/300], Train Loss: 0.000232
Validation Loss: 0.00026779
Epoch [111/300], Train Loss: 0.000242
Validation Loss: 0.00025867
Epoch [112/300], Train Loss: 0.000229
Validation Loss: 0.00025123
Epoch [113/300], Train Loss: 0.000229
Validation Loss: 0.00024860
Epoch [114/300], Train Loss: 0.000231
Validation Loss: 0.00024680
Epoch [115/300], Train Loss: 0.000226
Validation Loss: 0.00024243
Epoch [116/300], Train Loss: 0.000229
Validation Loss: 0.00025973
Epoch [117/300], Train Loss: 0.000238
Validation Loss: 0.00023795
Epoch [118/300], Train Loss: 0.000226
Validation Loss: 0.00023869
Epoch [119/300], Train Loss: 0.000220
Validation Loss: 0.00023079
Epoch [120/300], Train Loss: 0.000218
Validation Loss: 0.00023593
Epoch [121/300], Train Loss: 0.000222
Validation Loss: 0.00023898
Epoch [122/300], Train Loss: 0.000215
Validation Loss: 0.00022200
Epoch [123/300], Train Loss: 0.000216
Validation Loss: 0.00023558
Epoch [124/300], Train Loss: 0.000215
Validation Loss: 0.00023227
Epoch [125/300], Train Loss: 0.000219
Validation Loss: 0.00024875
Epoch [126/300], Train Loss: 0.000214
Validation Loss: 0.00022955
Epoch [127/300], Train Loss: 0.000214
Validation Loss: 0.00026666
Epoch [128/300], Train Loss: 0.000226
Validation Loss: 0.00024616
Epoch [129/300], Train Loss: 0.000214
Validation Loss: 0.00022341
Epoch [130/300], Train Loss: 0.000210
Validation Loss: 0.00024989
Epoch [131/300], Train Loss: 0.000212
Validation Loss: 0.00023279
Epoch [132/300], Train Loss: 0.000208
Validation Loss: 0.00022675
Early stopping triggered

Evaluating model for: Coffee Machine
Run 33/72 completed in 2770.38 seconds with: {'MAE': np.float32(4.2416763), 'MSE': np.float32(975.306), 'RMSE': np.float32(31.22989), 'SAE': np.float32(0.055171262), 'NDE': np.float32(0.43404877)}

Run 34/72: hidden=256, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Coffee Machine
Dataset length: 11964 windows

Epoch [1/300], Train Loss: 0.000961
Validation Loss: 0.00102755
Epoch [2/300], Train Loss: 0.000945
Validation Loss: 0.00102685
Epoch [3/300], Train Loss: 0.000942
Validation Loss: 0.00102587
Epoch [4/300], Train Loss: 0.000939
Validation Loss: 0.00102494
Epoch [5/300], Train Loss: 0.000938
Validation Loss: 0.00102399
Epoch [6/300], Train Loss: 0.000935
Validation Loss: 0.00101897
Epoch [7/300], Train Loss: 0.000931
Validation Loss: 0.00101581
Epoch [8/300], Train Loss: 0.000922
Validation Loss: 0.00100212
Epoch [9/300], Train Loss: 0.000911
Validation Loss: 0.00098417
Epoch [10/300], Train Loss: 0.000893
Validation Loss: 0.00095042
Epoch [11/300], Train Loss: 0.000854
Validation Loss: 0.00089140
Epoch [12/300], Train Loss: 0.000808
Validation Loss: 0.00083499
Epoch [13/300], Train Loss: 0.000762
Validation Loss: 0.00079011
Epoch [14/300], Train Loss: 0.000726
Validation Loss: 0.00075147
Epoch [15/300], Train Loss: 0.000707
Validation Loss: 0.00080582
Epoch [16/300], Train Loss: 0.000688
Validation Loss: 0.00074928
Epoch [17/300], Train Loss: 0.000660
Validation Loss: 0.00070025
Epoch [18/300], Train Loss: 0.000649
Validation Loss: 0.00067483
Epoch [19/300], Train Loss: 0.000630
Validation Loss: 0.00068246
Epoch [20/300], Train Loss: 0.000608
Validation Loss: 0.00064935
Epoch [21/300], Train Loss: 0.000596
Validation Loss: 0.00062513
Epoch [22/300], Train Loss: 0.000589
Validation Loss: 0.00062507
Epoch [23/300], Train Loss: 0.000575
Validation Loss: 0.00061044
Epoch [24/300], Train Loss: 0.000557
Validation Loss: 0.00060141
Epoch [25/300], Train Loss: 0.000548
Validation Loss: 0.00057781
Epoch [26/300], Train Loss: 0.000538
Validation Loss: 0.00057227
Epoch [27/300], Train Loss: 0.000534
Validation Loss: 0.00058366
Epoch [28/300], Train Loss: 0.000533
Validation Loss: 0.00057174
Epoch [29/300], Train Loss: 0.000524
Validation Loss: 0.00054441
Epoch [30/300], Train Loss: 0.000510
Validation Loss: 0.00054395
Epoch [31/300], Train Loss: 0.000507
Validation Loss: 0.00053810
Epoch [32/300], Train Loss: 0.000489
Validation Loss: 0.00052863
Epoch [33/300], Train Loss: 0.000483
Validation Loss: 0.00051189
Epoch [34/300], Train Loss: 0.000482
Validation Loss: 0.00051172
Epoch [35/300], Train Loss: 0.000480
Validation Loss: 0.00049844
Epoch [36/300], Train Loss: 0.000467
Validation Loss: 0.00050457
Epoch [37/300], Train Loss: 0.000461
Validation Loss: 0.00050428
Epoch [38/300], Train Loss: 0.000464
Validation Loss: 0.00050005
Epoch [39/300], Train Loss: 0.000457
Validation Loss: 0.00049246
Epoch [40/300], Train Loss: 0.000492
Validation Loss: 0.00052423
Epoch [41/300], Train Loss: 0.000473
Validation Loss: 0.00048456
Epoch [42/300], Train Loss: 0.000458
Validation Loss: 0.00052799
Epoch [43/300], Train Loss: 0.000472
Validation Loss: 0.00049360
Epoch [44/300], Train Loss: 0.000449
Validation Loss: 0.00048855
Epoch [45/300], Train Loss: 0.000439
Validation Loss: 0.00046754
Epoch [46/300], Train Loss: 0.000427
Validation Loss: 0.00047048
Epoch [47/300], Train Loss: 0.000437
Validation Loss: 0.00044743
Epoch [48/300], Train Loss: 0.000406
Validation Loss: 0.00043046
Epoch [49/300], Train Loss: 0.000397
Validation Loss: 0.00040961
Epoch [50/300], Train Loss: 0.000379
Validation Loss: 0.00039621
Epoch [51/300], Train Loss: 0.000371
Validation Loss: 0.00037573
Epoch [52/300], Train Loss: 0.000361
Validation Loss: 0.00039508
Epoch [53/300], Train Loss: 0.000353
Validation Loss: 0.00037646
Epoch [54/300], Train Loss: 0.000341
Validation Loss: 0.00034767
Epoch [55/300], Train Loss: 0.000336
Validation Loss: 0.00034460
Epoch [56/300], Train Loss: 0.000347
Validation Loss: 0.00035238
Epoch [57/300], Train Loss: 0.000341
Validation Loss: 0.00034766
Epoch [58/300], Train Loss: 0.000330
Validation Loss: 0.00032893
Epoch [59/300], Train Loss: 0.000331
Validation Loss: 0.00036370
Epoch [60/300], Train Loss: 0.000317
Validation Loss: 0.00033367
Epoch [61/300], Train Loss: 0.000307
Validation Loss: 0.00033119
Epoch [62/300], Train Loss: 0.000300
Validation Loss: 0.00032036
Epoch [63/300], Train Loss: 0.000297
Validation Loss: 0.00031747
Epoch [64/300], Train Loss: 0.000311
Validation Loss: 0.00032385
Epoch [65/300], Train Loss: 0.000297
Validation Loss: 0.00031260
Epoch [66/300], Train Loss: 0.000290
Validation Loss: 0.00029471
Epoch [67/300], Train Loss: 0.000282
Validation Loss: 0.00029577
Epoch [68/300], Train Loss: 0.000283
Validation Loss: 0.00029606
Epoch [69/300], Train Loss: 0.000279
Validation Loss: 0.00028600
Epoch [70/300], Train Loss: 0.000279
Validation Loss: 0.00031126
Epoch [71/300], Train Loss: 0.000287
Validation Loss: 0.00028694
Epoch [72/300], Train Loss: 0.000284
Validation Loss: 0.00030206
Epoch [73/300], Train Loss: 0.000289
Validation Loss: 0.00032614
Epoch [74/300], Train Loss: 0.000280
Validation Loss: 0.00028809
Epoch [75/300], Train Loss: 0.000258
Validation Loss: 0.00027391
Epoch [76/300], Train Loss: 0.000251
Validation Loss: 0.00027936
Epoch [77/300], Train Loss: 0.000252
Validation Loss: 0.00027141
Epoch [78/300], Train Loss: 0.000255
Validation Loss: 0.00028510
Epoch [79/300], Train Loss: 0.000253
Validation Loss: 0.00025690
Epoch [80/300], Train Loss: 0.000271
Validation Loss: 0.00030783
Epoch [81/300], Train Loss: 0.000256
Validation Loss: 0.00026956
Epoch [82/300], Train Loss: 0.000245
Validation Loss: 0.00026600
Epoch [83/300], Train Loss: 0.000235
Validation Loss: 0.00025580
Epoch [84/300], Train Loss: 0.000243
Validation Loss: 0.00029917
Epoch [85/300], Train Loss: 0.000237
Validation Loss: 0.00025765
Epoch [86/300], Train Loss: 0.000241
Validation Loss: 0.00024755
Epoch [87/300], Train Loss: 0.000226
Validation Loss: 0.00025825
Epoch [88/300], Train Loss: 0.000236
Validation Loss: 0.00025326
Epoch [89/300], Train Loss: 0.000229
Validation Loss: 0.00024069
Epoch [90/300], Train Loss: 0.000233
Validation Loss: 0.00025405
Epoch [91/300], Train Loss: 0.000222
Validation Loss: 0.00024109
Epoch [92/300], Train Loss: 0.000217
Validation Loss: 0.00023385
Epoch [93/300], Train Loss: 0.000215
Validation Loss: 0.00023855
Epoch [94/300], Train Loss: 0.000225
Validation Loss: 0.00025367
Epoch [95/300], Train Loss: 0.000218
Validation Loss: 0.00022894
Epoch [96/300], Train Loss: 0.000212
Validation Loss: 0.00023826
Epoch [97/300], Train Loss: 0.000217
Validation Loss: 0.00024359
Epoch [98/300], Train Loss: 0.000212
Validation Loss: 0.00023617
Epoch [99/300], Train Loss: 0.000210
Validation Loss: 0.00022906
Epoch [100/300], Train Loss: 0.000207
Validation Loss: 0.00023537
Epoch [101/300], Train Loss: 0.000204
Validation Loss: 0.00023136
Epoch [102/300], Train Loss: 0.000205
Validation Loss: 0.00023053
Epoch [103/300], Train Loss: 0.000203
Validation Loss: 0.00023307
Epoch [104/300], Train Loss: 0.000199
Validation Loss: 0.00021939
Epoch [105/300], Train Loss: 0.000215
Validation Loss: 0.00022636
Epoch [106/300], Train Loss: 0.000201
Validation Loss: 0.00022595
Epoch [107/300], Train Loss: 0.000210
Validation Loss: 0.00023075
Epoch [108/300], Train Loss: 0.000198
Validation Loss: 0.00022169
Epoch [109/300], Train Loss: 0.000198
Validation Loss: 0.00021254
Epoch [110/300], Train Loss: 0.000192
Validation Loss: 0.00022558
Epoch [111/300], Train Loss: 0.000193
Validation Loss: 0.00021332
Epoch [112/300], Train Loss: 0.000192
Validation Loss: 0.00022133
Epoch [113/300], Train Loss: 0.000191
Validation Loss: 0.00021196
Epoch [114/300], Train Loss: 0.000189
Validation Loss: 0.00021292
Epoch [115/300], Train Loss: 0.000186
Validation Loss: 0.00021241
Epoch [116/300], Train Loss: 0.000185
Validation Loss: 0.00021121
Epoch [117/300], Train Loss: 0.000185
Validation Loss: 0.00021256
Epoch [118/300], Train Loss: 0.000181
Validation Loss: 0.00020635
Epoch [119/300], Train Loss: 0.000183
Validation Loss: 0.00020739
Epoch [120/300], Train Loss: 0.000182
Validation Loss: 0.00021204
Epoch [121/300], Train Loss: 0.000199
Validation Loss: 0.00021141
Epoch [122/300], Train Loss: 0.000183
Validation Loss: 0.00020591
Epoch [123/300], Train Loss: 0.000178
Validation Loss: 0.00021414
Epoch [124/300], Train Loss: 0.000178
Validation Loss: 0.00022212
Epoch [125/300], Train Loss: 0.000183
Validation Loss: 0.00021097
Epoch [126/300], Train Loss: 0.000177
Validation Loss: 0.00020359
Epoch [127/300], Train Loss: 0.000173
Validation Loss: 0.00019857
Epoch [128/300], Train Loss: 0.000184
Validation Loss: 0.00020226
Epoch [129/300], Train Loss: 0.000178
Validation Loss: 0.00019871
Epoch [130/300], Train Loss: 0.000175
Validation Loss: 0.00019249
Epoch [131/300], Train Loss: 0.000170
Validation Loss: 0.00019637
Epoch [132/300], Train Loss: 0.000172
Validation Loss: 0.00019427
Epoch [133/300], Train Loss: 0.000176
Validation Loss: 0.00019238
Epoch [134/300], Train Loss: 0.000170
Validation Loss: 0.00019487
Epoch [135/300], Train Loss: 0.000167
Validation Loss: 0.00019201
Epoch [136/300], Train Loss: 0.000167
Validation Loss: 0.00019204
Epoch [137/300], Train Loss: 0.000165
Validation Loss: 0.00018773
Epoch [138/300], Train Loss: 0.000165
Validation Loss: 0.00018909
Epoch [139/300], Train Loss: 0.000165
Validation Loss: 0.00018598
Epoch [140/300], Train Loss: 0.000164
Validation Loss: 0.00018749
Epoch [141/300], Train Loss: 0.000162
Validation Loss: 0.00018526
Epoch [142/300], Train Loss: 0.000163
Validation Loss: 0.00020778
Epoch [143/300], Train Loss: 0.000165
Validation Loss: 0.00018671
Epoch [144/300], Train Loss: 0.000160
Validation Loss: 0.00018325
Epoch [145/300], Train Loss: 0.000157
Validation Loss: 0.00018261
Epoch [146/300], Train Loss: 0.000159
Validation Loss: 0.00018382
Epoch [147/300], Train Loss: 0.000161
Validation Loss: 0.00018065
Epoch [148/300], Train Loss: 0.000158
Validation Loss: 0.00017846
Epoch [149/300], Train Loss: 0.000158
Validation Loss: 0.00018037
Epoch [150/300], Train Loss: 0.000154
Validation Loss: 0.00017822
Epoch [151/300], Train Loss: 0.000154
Validation Loss: 0.00018640
Epoch [152/300], Train Loss: 0.000155
Validation Loss: 0.00017890
Epoch [153/300], Train Loss: 0.000153
Validation Loss: 0.00017926
Epoch [154/300], Train Loss: 0.000154
Validation Loss: 0.00017686
Epoch [155/300], Train Loss: 0.000154
Validation Loss: 0.00018262
Epoch [156/300], Train Loss: 0.000157
Validation Loss: 0.00019235
Epoch [157/300], Train Loss: 0.000154
Validation Loss: 0.00018333
Epoch [158/300], Train Loss: 0.000153
Validation Loss: 0.00017817
Epoch [159/300], Train Loss: 0.000157
Validation Loss: 0.00023996
Epoch [160/300], Train Loss: 0.000181
Validation Loss: 0.00018783
Epoch [161/300], Train Loss: 0.000153
Validation Loss: 0.00018158
Epoch [162/300], Train Loss: 0.000154
Validation Loss: 0.00017244
Epoch [163/300], Train Loss: 0.000149
Validation Loss: 0.00017645
Epoch [164/300], Train Loss: 0.000147
Validation Loss: 0.00017719
Epoch [165/300], Train Loss: 0.000146
Validation Loss: 0.00017664
Epoch [166/300], Train Loss: 0.000145
Validation Loss: 0.00017428
Epoch [167/300], Train Loss: 0.000143
Validation Loss: 0.00017466
Epoch [168/300], Train Loss: 0.000144
Validation Loss: 0.00017651
Epoch [169/300], Train Loss: 0.000143
Validation Loss: 0.00017657
Epoch [170/300], Train Loss: 0.000143
Validation Loss: 0.00017588
Epoch [171/300], Train Loss: 0.000142
Validation Loss: 0.00017704
Epoch [172/300], Train Loss: 0.000142
Validation Loss: 0.00017180
Epoch [173/300], Train Loss: 0.000141
Validation Loss: 0.00017167
Epoch [174/300], Train Loss: 0.000140
Validation Loss: 0.00017110
Epoch [175/300], Train Loss: 0.000142
Validation Loss: 0.00017393
Epoch [176/300], Train Loss: 0.000142
Validation Loss: 0.00016728
Epoch [177/300], Train Loss: 0.000139
Validation Loss: 0.00016732
Epoch [178/300], Train Loss: 0.000140
Validation Loss: 0.00017109
Epoch [179/300], Train Loss: 0.000141
Validation Loss: 0.00016846
Epoch [180/300], Train Loss: 0.000138
Validation Loss: 0.00016487
Epoch [181/300], Train Loss: 0.000137
Validation Loss: 0.00016553
Epoch [182/300], Train Loss: 0.000136
Validation Loss: 0.00016854
Epoch [183/300], Train Loss: 0.000136
Validation Loss: 0.00016838
Epoch [184/300], Train Loss: 0.000138
Validation Loss: 0.00016460
Epoch [185/300], Train Loss: 0.000137
Validation Loss: 0.00016666
Epoch [186/300], Train Loss: 0.000137
Validation Loss: 0.00016605
Epoch [187/300], Train Loss: 0.000135
Validation Loss: 0.00016285
Epoch [188/300], Train Loss: 0.000134
Validation Loss: 0.00016437
Epoch [189/300], Train Loss: 0.000134
Validation Loss: 0.00016822
Epoch [190/300], Train Loss: 0.000133
Validation Loss: 0.00016760
Epoch [191/300], Train Loss: 0.000134
Validation Loss: 0.00016664
Epoch [192/300], Train Loss: 0.000133
Validation Loss: 0.00016491
Epoch [193/300], Train Loss: 0.000132
Validation Loss: 0.00016187
Epoch [194/300], Train Loss: 0.000135
Validation Loss: 0.00016581
Epoch [195/300], Train Loss: 0.000132
Validation Loss: 0.00015910
Epoch [196/300], Train Loss: 0.000130
Validation Loss: 0.00015929
Epoch [197/300], Train Loss: 0.000130
Validation Loss: 0.00015633
Epoch [198/300], Train Loss: 0.000128
Validation Loss: 0.00015857
Epoch [199/300], Train Loss: 0.000128
Validation Loss: 0.00016345
Epoch [200/300], Train Loss: 0.000129
Validation Loss: 0.00015684
Epoch [201/300], Train Loss: 0.000129
Validation Loss: 0.00016146
Epoch [202/300], Train Loss: 0.000128
Validation Loss: 0.00015807
Epoch [203/300], Train Loss: 0.000127
Validation Loss: 0.00015861
Epoch [204/300], Train Loss: 0.000127
Validation Loss: 0.00016131
Epoch [205/300], Train Loss: 0.000127
Validation Loss: 0.00015686
Epoch [206/300], Train Loss: 0.000128
Validation Loss: 0.00016002
Epoch [207/300], Train Loss: 0.000129
Validation Loss: 0.00016364
Early stopping triggered

Evaluating model for: Coffee Machine
Run 34/72 completed in 4964.16 seconds with: {'MAE': np.float32(2.78941), 'MSE': np.float32(690.32446), 'RMSE': np.float32(26.274027), 'SAE': np.float32(0.1008495), 'NDE': np.float32(0.36516783)}

Run 35/72: hidden=256, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Coffee Machine
Dataset length: 11964 windows

Epoch [1/300], Train Loss: 0.000984
Validation Loss: 0.00103034
Epoch [2/300], Train Loss: 0.000948
Validation Loss: 0.00102970
Epoch [3/300], Train Loss: 0.000946
Validation Loss: 0.00102911
Epoch [4/300], Train Loss: 0.000944
Validation Loss: 0.00102875
Epoch [5/300], Train Loss: 0.000944
Validation Loss: 0.00102998
Epoch [6/300], Train Loss: 0.000941
Validation Loss: 0.00102731
Epoch [7/300], Train Loss: 0.000941
Validation Loss: 0.00102633
Epoch [8/300], Train Loss: 0.000938
Validation Loss: 0.00102534
Epoch [9/300], Train Loss: 0.000938
Validation Loss: 0.00102322
Epoch [10/300], Train Loss: 0.000937
Validation Loss: 0.00101867
Epoch [11/300], Train Loss: 0.000931
Validation Loss: 0.00101212
Epoch [12/300], Train Loss: 0.000922
Validation Loss: 0.00099670
Epoch [13/300], Train Loss: 0.000906
Validation Loss: 0.00096381
Epoch [14/300], Train Loss: 0.000862
Validation Loss: 0.00089243
Epoch [15/300], Train Loss: 0.000801
Validation Loss: 0.00084574
Epoch [16/300], Train Loss: 0.000759
Validation Loss: 0.00080950
Epoch [17/300], Train Loss: 0.000744
Validation Loss: 0.00075463
Epoch [18/300], Train Loss: 0.000694
Validation Loss: 0.00071901
Epoch [19/300], Train Loss: 0.000673
Validation Loss: 0.00070453
Epoch [20/300], Train Loss: 0.000658
Validation Loss: 0.00069289
Epoch [21/300], Train Loss: 0.000631
Validation Loss: 0.00065315
Epoch [22/300], Train Loss: 0.000617
Validation Loss: 0.00064418
Epoch [23/300], Train Loss: 0.000601
Validation Loss: 0.00064476
Epoch [24/300], Train Loss: 0.000572
Validation Loss: 0.00059471
Epoch [25/300], Train Loss: 0.000560
Validation Loss: 0.00061682
Epoch [26/300], Train Loss: 0.000551
Validation Loss: 0.00057818
Epoch [27/300], Train Loss: 0.000541
Validation Loss: 0.00057076
Epoch [28/300], Train Loss: 0.000532
Validation Loss: 0.00058113
Epoch [29/300], Train Loss: 0.000532
Validation Loss: 0.00056375
Epoch [30/300], Train Loss: 0.000517
Validation Loss: 0.00054302
Epoch [31/300], Train Loss: 0.000511
Validation Loss: 0.00054228
Epoch [32/300], Train Loss: 0.000498
Validation Loss: 0.00053220
Epoch [33/300], Train Loss: 0.000493
Validation Loss: 0.00050875
Epoch [34/300], Train Loss: 0.000488
Validation Loss: 0.00050658
Epoch [35/300], Train Loss: 0.000483
Validation Loss: 0.00052277
Epoch [36/300], Train Loss: 0.000478
Validation Loss: 0.00048715
Epoch [37/300], Train Loss: 0.000460
Validation Loss: 0.00050266
Epoch [38/300], Train Loss: 0.000466
Validation Loss: 0.00049814
Epoch [39/300], Train Loss: 0.000464
Validation Loss: 0.00048504
Epoch [40/300], Train Loss: 0.000451
Validation Loss: 0.00051578
Epoch [41/300], Train Loss: 0.000538
Validation Loss: 0.00058468
Epoch [42/300], Train Loss: 0.000491
Validation Loss: 0.00050363
Epoch [43/300], Train Loss: 0.000462
Validation Loss: 0.00047742
Epoch [44/300], Train Loss: 0.000446
Validation Loss: 0.00050095
Epoch [45/300], Train Loss: 0.000439
Validation Loss: 0.00046569
Epoch [46/300], Train Loss: 0.000426
Validation Loss: 0.00044627
Epoch [47/300], Train Loss: 0.000414
Validation Loss: 0.00043013
Epoch [48/300], Train Loss: 0.000413
Validation Loss: 0.00041886
Epoch [49/300], Train Loss: 0.000398
Validation Loss: 0.00041304
Epoch [50/300], Train Loss: 0.000383
Validation Loss: 0.00038872
Epoch [51/300], Train Loss: 0.000373
Validation Loss: 0.00037539
Epoch [52/300], Train Loss: 0.000360
Validation Loss: 0.00035994
Epoch [53/300], Train Loss: 0.000351
Validation Loss: 0.00034645
Epoch [54/300], Train Loss: 0.000339
Validation Loss: 0.00032785
Epoch [55/300], Train Loss: 0.000328
Validation Loss: 0.00031675
Epoch [56/300], Train Loss: 0.000319
Validation Loss: 0.00031927
Epoch [57/300], Train Loss: 0.000314
Validation Loss: 0.00030905
Epoch [58/300], Train Loss: 0.000299
Validation Loss: 0.00029393
Epoch [59/300], Train Loss: 0.000294
Validation Loss: 0.00027378
Epoch [60/300], Train Loss: 0.000287
Validation Loss: 0.00026691
Epoch [61/300], Train Loss: 0.000274
Validation Loss: 0.00025974
Epoch [62/300], Train Loss: 0.000269
Validation Loss: 0.00026290
Epoch [63/300], Train Loss: 0.000260
Validation Loss: 0.00024641
Epoch [64/300], Train Loss: 0.000256
Validation Loss: 0.00025038
Epoch [65/300], Train Loss: 0.000264
Validation Loss: 0.00026699
Epoch [66/300], Train Loss: 0.000252
Validation Loss: 0.00024978
Epoch [67/300], Train Loss: 0.000250
Validation Loss: 0.00024198
Epoch [68/300], Train Loss: 0.000250
Validation Loss: 0.00024175
Epoch [69/300], Train Loss: 0.000240
Validation Loss: 0.00023390
Epoch [70/300], Train Loss: 0.000247
Validation Loss: 0.00025916
Epoch [71/300], Train Loss: 0.000234
Validation Loss: 0.00022828
Epoch [72/300], Train Loss: 0.000227
Validation Loss: 0.00022056
Epoch [73/300], Train Loss: 0.000228
Validation Loss: 0.00024100
Epoch [74/300], Train Loss: 0.000225
Validation Loss: 0.00022275
Epoch [75/300], Train Loss: 0.000228
Validation Loss: 0.00022051
Epoch [76/300], Train Loss: 0.000222
Validation Loss: 0.00021205
Epoch [77/300], Train Loss: 0.000223
Validation Loss: 0.00021416
Epoch [78/300], Train Loss: 0.000223
Validation Loss: 0.00022828
Epoch [79/300], Train Loss: 0.000214
Validation Loss: 0.00021619
Epoch [80/300], Train Loss: 0.000219
Validation Loss: 0.00020726
Epoch [81/300], Train Loss: 0.000215
Validation Loss: 0.00020636
Epoch [82/300], Train Loss: 0.000207
Validation Loss: 0.00021098
Epoch [83/300], Train Loss: 0.000210
Validation Loss: 0.00020495
Epoch [84/300], Train Loss: 0.000207
Validation Loss: 0.00020308
Epoch [85/300], Train Loss: 0.000203
Validation Loss: 0.00021154
Epoch [86/300], Train Loss: 0.000200
Validation Loss: 0.00019715
Epoch [87/300], Train Loss: 0.000201
Validation Loss: 0.00021207
Epoch [88/300], Train Loss: 0.000203
Validation Loss: 0.00021023
Epoch [89/300], Train Loss: 0.000221
Validation Loss: 0.00024852
Epoch [90/300], Train Loss: 0.000214
Validation Loss: 0.00020265
Epoch [91/300], Train Loss: 0.000201
Validation Loss: 0.00019748
Epoch [92/300], Train Loss: 0.000193
Validation Loss: 0.00019178
Epoch [93/300], Train Loss: 0.000189
Validation Loss: 0.00019142
Epoch [94/300], Train Loss: 0.000192
Validation Loss: 0.00020182
Epoch [95/300], Train Loss: 0.000192
Validation Loss: 0.00018999
Epoch [96/300], Train Loss: 0.000189
Validation Loss: 0.00021013
Epoch [97/300], Train Loss: 0.000190
Validation Loss: 0.00020217
Epoch [98/300], Train Loss: 0.000190
Validation Loss: 0.00019794
Epoch [99/300], Train Loss: 0.000185
Validation Loss: 0.00018879
Epoch [100/300], Train Loss: 0.000182
Validation Loss: 0.00018412
Epoch [101/300], Train Loss: 0.000183
Validation Loss: 0.00018919
Epoch [102/300], Train Loss: 0.000186
Validation Loss: 0.00019058
Epoch [103/300], Train Loss: 0.000185
Validation Loss: 0.00019287
Epoch [104/300], Train Loss: 0.000180
Validation Loss: 0.00018271
Epoch [105/300], Train Loss: 0.000179
Validation Loss: 0.00018138
Epoch [106/300], Train Loss: 0.000175
Validation Loss: 0.00019872
Epoch [107/300], Train Loss: 0.000177
Validation Loss: 0.00018372
Epoch [108/300], Train Loss: 0.000183
Validation Loss: 0.00018483
Epoch [109/300], Train Loss: 0.000174
Validation Loss: 0.00017840
Epoch [110/300], Train Loss: 0.000173
Validation Loss: 0.00018282
Epoch [111/300], Train Loss: 0.000173
Validation Loss: 0.00017774
Epoch [112/300], Train Loss: 0.000171
Validation Loss: 0.00019971
Epoch [113/300], Train Loss: 0.000174
Validation Loss: 0.00017654
Epoch [114/300], Train Loss: 0.000167
Validation Loss: 0.00017909
Epoch [115/300], Train Loss: 0.000176
Validation Loss: 0.00018058
Epoch [116/300], Train Loss: 0.000169
Validation Loss: 0.00018355
Epoch [117/300], Train Loss: 0.000168
Validation Loss: 0.00017543
Epoch [118/300], Train Loss: 0.000165
Validation Loss: 0.00017922
Epoch [119/300], Train Loss: 0.000166
Validation Loss: 0.00017287
Epoch [120/300], Train Loss: 0.000164
Validation Loss: 0.00017269
Epoch [121/300], Train Loss: 0.000163
Validation Loss: 0.00017340
Epoch [122/300], Train Loss: 0.000163
Validation Loss: 0.00017269
Epoch [123/300], Train Loss: 0.000160
Validation Loss: 0.00017760
Epoch [124/300], Train Loss: 0.000160
Validation Loss: 0.00017020
Epoch [125/300], Train Loss: 0.000160
Validation Loss: 0.00017269
Epoch [126/300], Train Loss: 0.000159
Validation Loss: 0.00016850
Epoch [127/300], Train Loss: 0.000157
Validation Loss: 0.00016679
Epoch [128/300], Train Loss: 0.000157
Validation Loss: 0.00017835
Epoch [129/300], Train Loss: 0.000160
Validation Loss: 0.00017500
Epoch [130/300], Train Loss: 0.000159
Validation Loss: 0.00016739
Epoch [131/300], Train Loss: 0.000155
Validation Loss: 0.00016940
Epoch [132/300], Train Loss: 0.000153
Validation Loss: 0.00016707
Epoch [133/300], Train Loss: 0.000154
Validation Loss: 0.00016443
Epoch [134/300], Train Loss: 0.000154
Validation Loss: 0.00016116
Epoch [135/300], Train Loss: 0.000155
Validation Loss: 0.00016995
Epoch [136/300], Train Loss: 0.000153
Validation Loss: 0.00016695
Epoch [137/300], Train Loss: 0.000150
Validation Loss: 0.00016410
Epoch [138/300], Train Loss: 0.000150
Validation Loss: 0.00016404
Epoch [139/300], Train Loss: 0.000148
Validation Loss: 0.00016211
Epoch [140/300], Train Loss: 0.000166
Validation Loss: 0.00016343
Epoch [141/300], Train Loss: 0.000148
Validation Loss: 0.00016280
Epoch [142/300], Train Loss: 0.000146
Validation Loss: 0.00016673
Epoch [143/300], Train Loss: 0.000145
Validation Loss: 0.00015990
Epoch [144/300], Train Loss: 0.000145
Validation Loss: 0.00015990
Epoch [145/300], Train Loss: 0.000146
Validation Loss: 0.00016158
Epoch [146/300], Train Loss: 0.000145
Validation Loss: 0.00016287
Epoch [147/300], Train Loss: 0.000143
Validation Loss: 0.00015945
Epoch [148/300], Train Loss: 0.000143
Validation Loss: 0.00016109
Epoch [149/300], Train Loss: 0.000145
Validation Loss: 0.00016410
Epoch [150/300], Train Loss: 0.000141
Validation Loss: 0.00016078
Epoch [151/300], Train Loss: 0.000140
Validation Loss: 0.00015785
Epoch [152/300], Train Loss: 0.000140
Validation Loss: 0.00015904
Epoch [153/300], Train Loss: 0.000140
Validation Loss: 0.00015806
Epoch [154/300], Train Loss: 0.000138
Validation Loss: 0.00015748
Epoch [155/300], Train Loss: 0.000136
Validation Loss: 0.00015838
Epoch [156/300], Train Loss: 0.000143
Validation Loss: 0.00017749
Epoch [157/300], Train Loss: 0.000152
Validation Loss: 0.00016095
Epoch [158/300], Train Loss: 0.000143
Validation Loss: 0.00015840
Epoch [159/300], Train Loss: 0.000141
Validation Loss: 0.00015451
Epoch [160/300], Train Loss: 0.000136
Validation Loss: 0.00015600
Epoch [161/300], Train Loss: 0.000135
Validation Loss: 0.00015757
Epoch [162/300], Train Loss: 0.000135
Validation Loss: 0.00015931
Epoch [163/300], Train Loss: 0.000139
Validation Loss: 0.00015725
Epoch [164/300], Train Loss: 0.000134
Validation Loss: 0.00015234
Epoch [165/300], Train Loss: 0.000133
Validation Loss: 0.00015241
Epoch [166/300], Train Loss: 0.000131
Validation Loss: 0.00015622
Epoch [167/300], Train Loss: 0.000131
Validation Loss: 0.00015444
Epoch [168/300], Train Loss: 0.000129
Validation Loss: 0.00015521
Epoch [169/300], Train Loss: 0.000134
Validation Loss: 0.00015215
Epoch [170/300], Train Loss: 0.000130
Validation Loss: 0.00015563
Epoch [171/300], Train Loss: 0.000129
Validation Loss: 0.00015489
Epoch [172/300], Train Loss: 0.000128
Validation Loss: 0.00015868
Epoch [173/300], Train Loss: 0.000128
Validation Loss: 0.00015198
Epoch [174/300], Train Loss: 0.000127
Validation Loss: 0.00015715
Epoch [175/300], Train Loss: 0.000130
Validation Loss: 0.00015448
Epoch [176/300], Train Loss: 0.000126
Validation Loss: 0.00015277
Epoch [177/300], Train Loss: 0.000126
Validation Loss: 0.00015541
Epoch [178/300], Train Loss: 0.000130
Validation Loss: 0.00015346
Epoch [179/300], Train Loss: 0.000140
Validation Loss: 0.00015626
Epoch [180/300], Train Loss: 0.000130
Validation Loss: 0.00015614
Epoch [181/300], Train Loss: 0.000127
Validation Loss: 0.00014968
Epoch [182/300], Train Loss: 0.000125
Validation Loss: 0.00015044
Epoch [183/300], Train Loss: 0.000126
Validation Loss: 0.00015183
Epoch [184/300], Train Loss: 0.000124
Validation Loss: 0.00015192
Epoch [185/300], Train Loss: 0.000124
Validation Loss: 0.00014949
Epoch [186/300], Train Loss: 0.000124
Validation Loss: 0.00015165
Epoch [187/300], Train Loss: 0.000122
Validation Loss: 0.00015218
Epoch [188/300], Train Loss: 0.000122
Validation Loss: 0.00015045
Epoch [189/300], Train Loss: 0.000122
Validation Loss: 0.00015039
Epoch [190/300], Train Loss: 0.000123
Validation Loss: 0.00014936
Epoch [191/300], Train Loss: 0.000121
Validation Loss: 0.00014772
Epoch [192/300], Train Loss: 0.000121
Validation Loss: 0.00014922
Epoch [193/300], Train Loss: 0.000121
Validation Loss: 0.00014858
Epoch [194/300], Train Loss: 0.000121
Validation Loss: 0.00014838
Epoch [195/300], Train Loss: 0.000121
Validation Loss: 0.00015018
Epoch [196/300], Train Loss: 0.000137
Validation Loss: 0.00016417
Epoch [197/300], Train Loss: 0.000132
Validation Loss: 0.00015355
Epoch [198/300], Train Loss: 0.000123
Validation Loss: 0.00014836
Epoch [199/300], Train Loss: 0.000121
Validation Loss: 0.00014700
Epoch [200/300], Train Loss: 0.000120
Validation Loss: 0.00014547
Epoch [201/300], Train Loss: 0.000118
Validation Loss: 0.00014731
Epoch [202/300], Train Loss: 0.000120
Validation Loss: 0.00015347
Epoch [203/300], Train Loss: 0.000120
Validation Loss: 0.00014748
Epoch [204/300], Train Loss: 0.000121
Validation Loss: 0.00014966
Epoch [205/300], Train Loss: 0.000118
Validation Loss: 0.00014837
Epoch [206/300], Train Loss: 0.000118
Validation Loss: 0.00014607
Epoch [207/300], Train Loss: 0.000117
Validation Loss: 0.00014586
Epoch [208/300], Train Loss: 0.000116
Validation Loss: 0.00014557
Epoch [209/300], Train Loss: 0.000116
Validation Loss: 0.00014834
Epoch [210/300], Train Loss: 0.000117
Validation Loss: 0.00014474
Epoch [211/300], Train Loss: 0.000116
Validation Loss: 0.00014591
Epoch [212/300], Train Loss: 0.000116
Validation Loss: 0.00014485
Epoch [213/300], Train Loss: 0.000116
Validation Loss: 0.00014339
Epoch [214/300], Train Loss: 0.000115
Validation Loss: 0.00014516
Epoch [215/300], Train Loss: 0.000115
Validation Loss: 0.00014483
Epoch [216/300], Train Loss: 0.000115
Validation Loss: 0.00014314
Epoch [217/300], Train Loss: 0.000114
Validation Loss: 0.00014213
Epoch [218/300], Train Loss: 0.000114
Validation Loss: 0.00014462
Epoch [219/300], Train Loss: 0.000114
Validation Loss: 0.00014409
Epoch [220/300], Train Loss: 0.000114
Validation Loss: 0.00014185
Epoch [221/300], Train Loss: 0.000116
Validation Loss: 0.00014546
Epoch [222/300], Train Loss: 0.000114
Validation Loss: 0.00014246
Epoch [223/300], Train Loss: 0.000113
Validation Loss: 0.00014064
Epoch [224/300], Train Loss: 0.000113
Validation Loss: 0.00014521
Epoch [225/300], Train Loss: 0.000112
Validation Loss: 0.00014376
Epoch [226/300], Train Loss: 0.000112
Validation Loss: 0.00014250
Epoch [227/300], Train Loss: 0.000112
Validation Loss: 0.00014054
Epoch [228/300], Train Loss: 0.000112
Validation Loss: 0.00013972
Epoch [229/300], Train Loss: 0.000112
Validation Loss: 0.00013979
Epoch [230/300], Train Loss: 0.000111
Validation Loss: 0.00014035
Epoch [231/300], Train Loss: 0.000112
Validation Loss: 0.00013888
Epoch [232/300], Train Loss: 0.000111
Validation Loss: 0.00013814
Epoch [233/300], Train Loss: 0.000111
Validation Loss: 0.00013878
Epoch [234/300], Train Loss: 0.000110
Validation Loss: 0.00013855
Epoch [235/300], Train Loss: 0.000110
Validation Loss: 0.00013888
Epoch [236/300], Train Loss: 0.000109
Validation Loss: 0.00013937
Epoch [237/300], Train Loss: 0.000109
Validation Loss: 0.00013953
Epoch [238/300], Train Loss: 0.000113
Validation Loss: 0.00013796
Epoch [239/300], Train Loss: 0.000109
Validation Loss: 0.00013867
Epoch [240/300], Train Loss: 0.000109
Validation Loss: 0.00013894
Epoch [241/300], Train Loss: 0.000109
Validation Loss: 0.00013568
Epoch [242/300], Train Loss: 0.000107
Validation Loss: 0.00013434
Epoch [243/300], Train Loss: 0.000108
Validation Loss: 0.00013713
Epoch [244/300], Train Loss: 0.000109
Validation Loss: 0.00013933
Epoch [245/300], Train Loss: 0.000108
Validation Loss: 0.00013593
Epoch [246/300], Train Loss: 0.000108
Validation Loss: 0.00013746
Epoch [247/300], Train Loss: 0.000108
Validation Loss: 0.00013767
Epoch [248/300], Train Loss: 0.000107
Validation Loss: 0.00013563
Epoch [249/300], Train Loss: 0.000106
Validation Loss: 0.00013693
Epoch [250/300], Train Loss: 0.000107
Validation Loss: 0.00013818
Epoch [251/300], Train Loss: 0.000106
Validation Loss: 0.00013572
Epoch [252/300], Train Loss: 0.000113
Validation Loss: 0.00014466
Early stopping triggered

Evaluating model for: Coffee Machine
Run 35/72 completed in 6653.26 seconds with: {'MAE': np.float32(3.264496), 'MSE': np.float32(564.0811), 'RMSE': np.float32(23.750391), 'SAE': np.float32(0.12042156), 'NDE': np.float32(0.3300954)}

Run 36/72: hidden=256, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Coffee Machine
Dataset length: 11964 windows

Epoch [1/300], Train Loss: 0.001054
Validation Loss: 0.00103192
Epoch [2/300], Train Loss: 0.000951
Validation Loss: 0.00103147
Epoch [3/300], Train Loss: 0.000949
Validation Loss: 0.00103095
Epoch [4/300], Train Loss: 0.000947
Validation Loss: 0.00103047
Epoch [5/300], Train Loss: 0.000948
Validation Loss: 0.00103095
Epoch [6/300], Train Loss: 0.000945
Validation Loss: 0.00102955
Epoch [7/300], Train Loss: 0.000945
Validation Loss: 0.00102898
Epoch [8/300], Train Loss: 0.000943
Validation Loss: 0.00102865
Epoch [9/300], Train Loss: 0.000943
Validation Loss: 0.00102826
Epoch [10/300], Train Loss: 0.000944
Validation Loss: 0.00102858
Epoch [11/300], Train Loss: 0.000942
Validation Loss: 0.00102713
Epoch [12/300], Train Loss: 0.000941
Validation Loss: 0.00102631
Epoch [13/300], Train Loss: 0.000942
Validation Loss: 0.00102620
Epoch [14/300], Train Loss: 0.000940
Validation Loss: 0.00102393
Epoch [15/300], Train Loss: 0.000940
Validation Loss: 0.00102165
Epoch [16/300], Train Loss: 0.000935
Validation Loss: 0.00101732
Epoch [17/300], Train Loss: 0.000927
Validation Loss: 0.00100791
Epoch [18/300], Train Loss: 0.000917
Validation Loss: 0.00098922
Epoch [19/300], Train Loss: 0.000900
Validation Loss: 0.00095614
Epoch [20/300], Train Loss: 0.000858
Validation Loss: 0.00089606
Epoch [21/300], Train Loss: 0.000800
Validation Loss: 0.00081689
Epoch [22/300], Train Loss: 0.000740
Validation Loss: 0.00075452
Epoch [23/300], Train Loss: 0.000697
Validation Loss: 0.00072254
Epoch [24/300], Train Loss: 0.000655
Validation Loss: 0.00067897
Epoch [25/300], Train Loss: 0.000630
Validation Loss: 0.00066897
Epoch [26/300], Train Loss: 0.000607
Validation Loss: 0.00062342
Epoch [27/300], Train Loss: 0.000596
Validation Loss: 0.00063998
Epoch [28/300], Train Loss: 0.000574
Validation Loss: 0.00063082
Epoch [29/300], Train Loss: 0.000560
Validation Loss: 0.00059151
Epoch [30/300], Train Loss: 0.000523
Validation Loss: 0.00054523
Epoch [31/300], Train Loss: 0.000492
Validation Loss: 0.00052292
Epoch [32/300], Train Loss: 0.000449
Validation Loss: 0.00046095
Epoch [33/300], Train Loss: 0.000419
Validation Loss: 0.00042755
Epoch [34/300], Train Loss: 0.000390
Validation Loss: 0.00038878
Epoch [35/300], Train Loss: 0.000378
Validation Loss: 0.00039755
Epoch [36/300], Train Loss: 0.000364
Validation Loss: 0.00037230
Epoch [37/300], Train Loss: 0.000355
Validation Loss: 0.00034064
Epoch [38/300], Train Loss: 0.000345
Validation Loss: 0.00034339
Epoch [39/300], Train Loss: 0.000345
Validation Loss: 0.00034337
Epoch [40/300], Train Loss: 0.000335
Validation Loss: 0.00034108
Epoch [41/300], Train Loss: 0.000325
Validation Loss: 0.00033506
Epoch [42/300], Train Loss: 0.000324
Validation Loss: 0.00031268
Epoch [43/300], Train Loss: 0.000317
Validation Loss: 0.00031941
Epoch [44/300], Train Loss: 0.000307
Validation Loss: 0.00029954
Epoch [45/300], Train Loss: 0.000301
Validation Loss: 0.00030148
Epoch [46/300], Train Loss: 0.000297
Validation Loss: 0.00028805
Epoch [47/300], Train Loss: 0.000296
Validation Loss: 0.00028881
Epoch [48/300], Train Loss: 0.000287
Validation Loss: 0.00029259
Epoch [49/300], Train Loss: 0.000281
Validation Loss: 0.00027564
Epoch [50/300], Train Loss: 0.000288
Validation Loss: 0.00031330
Epoch [51/300], Train Loss: 0.000284
Validation Loss: 0.00026635
Epoch [52/300], Train Loss: 0.000273
Validation Loss: 0.00025282
Epoch [53/300], Train Loss: 0.000263
Validation Loss: 0.00025932
Epoch [54/300], Train Loss: 0.000259
Validation Loss: 0.00024978
Epoch [55/300], Train Loss: 0.000262
Validation Loss: 0.00024110
Epoch [56/300], Train Loss: 0.000251
Validation Loss: 0.00023371
Epoch [57/300], Train Loss: 0.000249
Validation Loss: 0.00024757
Epoch [58/300], Train Loss: 0.000245
Validation Loss: 0.00023788
Epoch [59/300], Train Loss: 0.000240
Validation Loss: 0.00021809
Epoch [60/300], Train Loss: 0.000234
Validation Loss: 0.00023073
Epoch [61/300], Train Loss: 0.000229
Validation Loss: 0.00022019
Epoch [62/300], Train Loss: 0.000225
Validation Loss: 0.00022842
Epoch [63/300], Train Loss: 0.000224
Validation Loss: 0.00022213
Epoch [64/300], Train Loss: 0.000217
Validation Loss: 0.00020434
Epoch [65/300], Train Loss: 0.000219
Validation Loss: 0.00020590
Epoch [66/300], Train Loss: 0.000212
Validation Loss: 0.00019956
Epoch [67/300], Train Loss: 0.000207
Validation Loss: 0.00020121
Epoch [68/300], Train Loss: 0.000204
Validation Loss: 0.00021363
Epoch [69/300], Train Loss: 0.000203
Validation Loss: 0.00019629
Epoch [70/300], Train Loss: 0.000205
Validation Loss: 0.00020867
Epoch [71/300], Train Loss: 0.000205
Validation Loss: 0.00020139
Epoch [72/300], Train Loss: 0.000198
Validation Loss: 0.00020343
Epoch [73/300], Train Loss: 0.000197
Validation Loss: 0.00020098
Epoch [74/300], Train Loss: 0.000198
Validation Loss: 0.00020807
Epoch [75/300], Train Loss: 0.000204
Validation Loss: 0.00018604
Epoch [76/300], Train Loss: 0.000189
Validation Loss: 0.00019455
Epoch [77/300], Train Loss: 0.000244
Validation Loss: 0.00028007
Epoch [78/300], Train Loss: 0.000250
Validation Loss: 0.00023209
Epoch [79/300], Train Loss: 0.000213
Validation Loss: 0.00020333
Epoch [80/300], Train Loss: 0.000203
Validation Loss: 0.00020279
Epoch [81/300], Train Loss: 0.000199
Validation Loss: 0.00019092
Epoch [82/300], Train Loss: 0.000192
Validation Loss: 0.00018724
Epoch [83/300], Train Loss: 0.000191
Validation Loss: 0.00020074
Epoch [84/300], Train Loss: 0.000193
Validation Loss: 0.00018634
Epoch [85/300], Train Loss: 0.000189
Validation Loss: 0.00019639
Early stopping triggered

Evaluating model for: Coffee Machine
Run 36/72 completed in 2732.96 seconds with: {'MAE': np.float32(3.35534), 'MSE': np.float32(851.72626), 'RMSE': np.float32(29.18435), 'SAE': np.float32(0.017128745), 'NDE': np.float32(0.40561792)}

Run 37/72: hidden=256, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Coffee Machine
Dataset length: 6004 windows

Epoch [1/300], Train Loss: 0.000999
Validation Loss: 0.00097130
Epoch [2/300], Train Loss: 0.000975
Validation Loss: 0.00096993
Epoch [3/300], Train Loss: 0.000977
Validation Loss: 0.00096866
Epoch [4/300], Train Loss: 0.000973
Validation Loss: 0.00096735
Epoch [5/300], Train Loss: 0.000973
Validation Loss: 0.00096547
Epoch [6/300], Train Loss: 0.000969
Validation Loss: 0.00096274
Epoch [7/300], Train Loss: 0.000959
Validation Loss: 0.00095858
Epoch [8/300], Train Loss: 0.000953
Validation Loss: 0.00095548
Epoch [9/300], Train Loss: 0.000959
Validation Loss: 0.00095274
Epoch [10/300], Train Loss: 0.000945
Validation Loss: 0.00095390
Epoch [11/300], Train Loss: 0.000954
Validation Loss: 0.00094655
Epoch [12/300], Train Loss: 0.000945
Validation Loss: 0.00094210
Epoch [13/300], Train Loss: 0.000936
Validation Loss: 0.00093499
Epoch [14/300], Train Loss: 0.000928
Validation Loss: 0.00092912
Epoch [15/300], Train Loss: 0.000920
Validation Loss: 0.00092176
Epoch [16/300], Train Loss: 0.000906
Validation Loss: 0.00091487
Epoch [17/300], Train Loss: 0.000901
Validation Loss: 0.00090389
Epoch [18/300], Train Loss: 0.000891
Validation Loss: 0.00089355
Epoch [19/300], Train Loss: 0.000877
Validation Loss: 0.00088114
Epoch [20/300], Train Loss: 0.000858
Validation Loss: 0.00086844
Epoch [21/300], Train Loss: 0.000853
Validation Loss: 0.00085119
Epoch [22/300], Train Loss: 0.000829
Validation Loss: 0.00083821
Epoch [23/300], Train Loss: 0.000814
Validation Loss: 0.00083252
Epoch [24/300], Train Loss: 0.000800
Validation Loss: 0.00080788
Epoch [25/300], Train Loss: 0.000780
Validation Loss: 0.00079840
Epoch [26/300], Train Loss: 0.000765
Validation Loss: 0.00077543
Epoch [27/300], Train Loss: 0.000751
Validation Loss: 0.00075977
Epoch [28/300], Train Loss: 0.000738
Validation Loss: 0.00074633
Epoch [29/300], Train Loss: 0.000723
Validation Loss: 0.00073188
Epoch [30/300], Train Loss: 0.000711
Validation Loss: 0.00073628
Epoch [31/300], Train Loss: 0.000699
Validation Loss: 0.00072580
Epoch [32/300], Train Loss: 0.000696
Validation Loss: 0.00073937
Epoch [33/300], Train Loss: 0.000687
Validation Loss: 0.00070769
Epoch [34/300], Train Loss: 0.000677
Validation Loss: 0.00069405
Epoch [35/300], Train Loss: 0.000665
Validation Loss: 0.00069880
Epoch [36/300], Train Loss: 0.000660
Validation Loss: 0.00069223
Epoch [37/300], Train Loss: 0.000646
Validation Loss: 0.00069602
Epoch [38/300], Train Loss: 0.000639
Validation Loss: 0.00068522
Epoch [39/300], Train Loss: 0.000649
Validation Loss: 0.00071108
Epoch [40/300], Train Loss: 0.000645
Validation Loss: 0.00068342
Epoch [41/300], Train Loss: 0.000634
Validation Loss: 0.00068630
Epoch [42/300], Train Loss: 0.000613
Validation Loss: 0.00067621
Epoch [43/300], Train Loss: 0.000627
Validation Loss: 0.00066159
Epoch [44/300], Train Loss: 0.000614
Validation Loss: 0.00064117
Epoch [45/300], Train Loss: 0.000599
Validation Loss: 0.00063326
Epoch [46/300], Train Loss: 0.000601
Validation Loss: 0.00064838
Epoch [47/300], Train Loss: 0.000582
Validation Loss: 0.00064388
Epoch [48/300], Train Loss: 0.000595
Validation Loss: 0.00066978
Epoch [49/300], Train Loss: 0.000590
Validation Loss: 0.00062775
Epoch [50/300], Train Loss: 0.000580
Validation Loss: 0.00062988
Epoch [51/300], Train Loss: 0.000572
Validation Loss: 0.00061411
Epoch [52/300], Train Loss: 0.000561
Validation Loss: 0.00061417
Epoch [53/300], Train Loss: 0.000568
Validation Loss: 0.00061154
Epoch [54/300], Train Loss: 0.000554
Validation Loss: 0.00058994
Epoch [55/300], Train Loss: 0.000554
Validation Loss: 0.00061151
Epoch [56/300], Train Loss: 0.000556
Validation Loss: 0.00058827
Epoch [57/300], Train Loss: 0.000551
Validation Loss: 0.00060176
Epoch [58/300], Train Loss: 0.000543
Validation Loss: 0.00059091
Epoch [59/300], Train Loss: 0.000543
Validation Loss: 0.00058011
Epoch [60/300], Train Loss: 0.000534
Validation Loss: 0.00058324
Epoch [61/300], Train Loss: 0.000533
Validation Loss: 0.00057612
Epoch [62/300], Train Loss: 0.000525
Validation Loss: 0.00058911
Epoch [63/300], Train Loss: 0.000538
Validation Loss: 0.00061532
Epoch [64/300], Train Loss: 0.000534
Validation Loss: 0.00055706
Epoch [65/300], Train Loss: 0.000516
Validation Loss: 0.00057369
Epoch [66/300], Train Loss: 0.000527
Validation Loss: 0.00056607
Epoch [67/300], Train Loss: 0.000515
Validation Loss: 0.00056052
Epoch [68/300], Train Loss: 0.000510
Validation Loss: 0.00056538
Epoch [69/300], Train Loss: 0.000513
Validation Loss: 0.00056522
Epoch [70/300], Train Loss: 0.000508
Validation Loss: 0.00055128
Epoch [71/300], Train Loss: 0.000502
Validation Loss: 0.00055417
Epoch [72/300], Train Loss: 0.000501
Validation Loss: 0.00055938
Epoch [73/300], Train Loss: 0.000499
Validation Loss: 0.00054002
Epoch [74/300], Train Loss: 0.000502
Validation Loss: 0.00054180
Epoch [75/300], Train Loss: 0.000497
Validation Loss: 0.00054972
Epoch [76/300], Train Loss: 0.000494
Validation Loss: 0.00054368
Epoch [77/300], Train Loss: 0.000489
Validation Loss: 0.00054283
Epoch [78/300], Train Loss: 0.000488
Validation Loss: 0.00052573
Epoch [79/300], Train Loss: 0.000486
Validation Loss: 0.00052227
Epoch [80/300], Train Loss: 0.000483
Validation Loss: 0.00052636
Epoch [81/300], Train Loss: 0.000479
Validation Loss: 0.00053779
Epoch [82/300], Train Loss: 0.000481
Validation Loss: 0.00052307
Epoch [83/300], Train Loss: 0.000477
Validation Loss: 0.00051804
Epoch [84/300], Train Loss: 0.000471
Validation Loss: 0.00051427
Epoch [85/300], Train Loss: 0.000474
Validation Loss: 0.00053767
Epoch [86/300], Train Loss: 0.000469
Validation Loss: 0.00053378
Epoch [87/300], Train Loss: 0.000468
Validation Loss: 0.00050770
Epoch [88/300], Train Loss: 0.000461
Validation Loss: 0.00050076
Epoch [89/300], Train Loss: 0.000458
Validation Loss: 0.00050338
Epoch [90/300], Train Loss: 0.000453
Validation Loss: 0.00050015
Epoch [91/300], Train Loss: 0.000458
Validation Loss: 0.00049162
Epoch [92/300], Train Loss: 0.000456
Validation Loss: 0.00048839
Epoch [93/300], Train Loss: 0.000448
Validation Loss: 0.00050311
Epoch [94/300], Train Loss: 0.000461
Validation Loss: 0.00054157
Epoch [95/300], Train Loss: 0.000449
Validation Loss: 0.00051078
Epoch [96/300], Train Loss: 0.000447
Validation Loss: 0.00046493
Epoch [97/300], Train Loss: 0.000439
Validation Loss: 0.00046967
Epoch [98/300], Train Loss: 0.000440
Validation Loss: 0.00049100
Epoch [99/300], Train Loss: 0.000527
Validation Loss: 0.00056106
Epoch [100/300], Train Loss: 0.000474
Validation Loss: 0.00051856
Epoch [101/300], Train Loss: 0.000459
Validation Loss: 0.00050303
Epoch [102/300], Train Loss: 0.000446
Validation Loss: 0.00048937
Epoch [103/300], Train Loss: 0.000437
Validation Loss: 0.00049448
Epoch [104/300], Train Loss: 0.000440
Validation Loss: 0.00047367
Epoch [105/300], Train Loss: 0.000433
Validation Loss: 0.00049152
Epoch [106/300], Train Loss: 0.000430
Validation Loss: 0.00048427
Early stopping triggered

Evaluating model for: Coffee Machine
Run 37/72 completed in 1142.16 seconds with: {'MAE': np.float32(6.192004), 'MSE': np.float32(2303.8562), 'RMSE': np.float32(47.9985), 'SAE': np.float32(0.063745804), 'NDE': np.float32(0.746241)}

Run 38/72: hidden=256, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Coffee Machine
Dataset length: 6004 windows

Epoch [1/300], Train Loss: 0.001157
Validation Loss: 0.00098287
Epoch [2/300], Train Loss: 0.000983
Validation Loss: 0.00097557
Epoch [3/300], Train Loss: 0.000985
Validation Loss: 0.00097528
Epoch [4/300], Train Loss: 0.000984
Validation Loss: 0.00097483
Epoch [5/300], Train Loss: 0.000985
Validation Loss: 0.00097489
Epoch [6/300], Train Loss: 0.000983
Validation Loss: 0.00097401
Epoch [7/300], Train Loss: 0.000975
Validation Loss: 0.00097341
Epoch [8/300], Train Loss: 0.000972
Validation Loss: 0.00097282
Epoch [9/300], Train Loss: 0.000981
Validation Loss: 0.00097228
Epoch [10/300], Train Loss: 0.000967
Validation Loss: 0.00097169
Epoch [11/300], Train Loss: 0.000980
Validation Loss: 0.00097075
Epoch [12/300], Train Loss: 0.000974
Validation Loss: 0.00097024
Epoch [13/300], Train Loss: 0.000969
Validation Loss: 0.00096889
Epoch [14/300], Train Loss: 0.000967
Validation Loss: 0.00096747
Epoch [15/300], Train Loss: 0.000964
Validation Loss: 0.00096543
Epoch [16/300], Train Loss: 0.000956
Validation Loss: 0.00096259
Epoch [17/300], Train Loss: 0.000958
Validation Loss: 0.00095973
Epoch [18/300], Train Loss: 0.000957
Validation Loss: 0.00095839
Epoch [19/300], Train Loss: 0.000952
Validation Loss: 0.00095326
Epoch [20/300], Train Loss: 0.000944
Validation Loss: 0.00094855
Epoch [21/300], Train Loss: 0.000950
Validation Loss: 0.00094851
Epoch [22/300], Train Loss: 0.000930
Validation Loss: 0.00093216
Epoch [23/300], Train Loss: 0.000917
Validation Loss: 0.00092441
Epoch [24/300], Train Loss: 0.000907
Validation Loss: 0.00090550
Epoch [25/300], Train Loss: 0.000879
Validation Loss: 0.00088253
Epoch [26/300], Train Loss: 0.000853
Validation Loss: 0.00085929
Epoch [27/300], Train Loss: 0.000825
Validation Loss: 0.00083031
Epoch [28/300], Train Loss: 0.000804
Validation Loss: 0.00080652
Epoch [29/300], Train Loss: 0.000775
Validation Loss: 0.00078502
Epoch [30/300], Train Loss: 0.000763
Validation Loss: 0.00077666
Epoch [31/300], Train Loss: 0.000740
Validation Loss: 0.00075653
Epoch [32/300], Train Loss: 0.000729
Validation Loss: 0.00075346
Epoch [33/300], Train Loss: 0.000713
Validation Loss: 0.00075951
Epoch [34/300], Train Loss: 0.000702
Validation Loss: 0.00071701
Epoch [35/300], Train Loss: 0.000699
Validation Loss: 0.00070130
Epoch [36/300], Train Loss: 0.000680
Validation Loss: 0.00070118
Epoch [37/300], Train Loss: 0.000676
Validation Loss: 0.00068860
Epoch [38/300], Train Loss: 0.000665
Validation Loss: 0.00068696
Epoch [39/300], Train Loss: 0.000676
Validation Loss: 0.00070190
Epoch [40/300], Train Loss: 0.000656
Validation Loss: 0.00066698
Epoch [41/300], Train Loss: 0.000652
Validation Loss: 0.00066905
Epoch [42/300], Train Loss: 0.000634
Validation Loss: 0.00063305
Epoch [43/300], Train Loss: 0.000651
Validation Loss: 0.00065715
Epoch [44/300], Train Loss: 0.000630
Validation Loss: 0.00065435
Epoch [45/300], Train Loss: 0.000619
Validation Loss: 0.00061986
Epoch [46/300], Train Loss: 0.000618
Validation Loss: 0.00062938
Epoch [47/300], Train Loss: 0.000602
Validation Loss: 0.00061113
Epoch [48/300], Train Loss: 0.000606
Validation Loss: 0.00062111
Epoch [49/300], Train Loss: 0.000603
Validation Loss: 0.00062897
Epoch [50/300], Train Loss: 0.000585
Validation Loss: 0.00064609
Epoch [51/300], Train Loss: 0.000586
Validation Loss: 0.00059278
Epoch [52/300], Train Loss: 0.000577
Validation Loss: 0.00059498
Epoch [53/300], Train Loss: 0.000585
Validation Loss: 0.00059716
Epoch [54/300], Train Loss: 0.000567
Validation Loss: 0.00057310
Epoch [55/300], Train Loss: 0.000571
Validation Loss: 0.00059322
Epoch [56/300], Train Loss: 0.000571
Validation Loss: 0.00058665
Epoch [57/300], Train Loss: 0.000569
Validation Loss: 0.00059501
Epoch [58/300], Train Loss: 0.000563
Validation Loss: 0.00059762
Epoch [59/300], Train Loss: 0.000578
Validation Loss: 0.00056956
Epoch [60/300], Train Loss: 0.000553
Validation Loss: 0.00059031
Epoch [61/300], Train Loss: 0.000554
Validation Loss: 0.00057663
Epoch [62/300], Train Loss: 0.000551
Validation Loss: 0.00057449
Epoch [63/300], Train Loss: 0.000539
Validation Loss: 0.00057354
Epoch [64/300], Train Loss: 0.000543
Validation Loss: 0.00055014
Epoch [65/300], Train Loss: 0.000556
Validation Loss: 0.00057012
Epoch [66/300], Train Loss: 0.000553
Validation Loss: 0.00055981
Epoch [67/300], Train Loss: 0.000540
Validation Loss: 0.00054839
Epoch [68/300], Train Loss: 0.000537
Validation Loss: 0.00056733
Epoch [69/300], Train Loss: 0.000532
Validation Loss: 0.00055672
Epoch [70/300], Train Loss: 0.000531
Validation Loss: 0.00054605
Epoch [71/300], Train Loss: 0.000515
Validation Loss: 0.00054144
Epoch [72/300], Train Loss: 0.000516
Validation Loss: 0.00055132
Epoch [73/300], Train Loss: 0.000527
Validation Loss: 0.00053012
Epoch [74/300], Train Loss: 0.000512
Validation Loss: 0.00053184
Epoch [75/300], Train Loss: 0.000499
Validation Loss: 0.00051467
Epoch [76/300], Train Loss: 0.000499
Validation Loss: 0.00052902
Epoch [77/300], Train Loss: 0.000493
Validation Loss: 0.00052359
Epoch [78/300], Train Loss: 0.000494
Validation Loss: 0.00054730
Epoch [79/300], Train Loss: 0.000508
Validation Loss: 0.00053140
Epoch [80/300], Train Loss: 0.000548
Validation Loss: 0.00057740
Epoch [81/300], Train Loss: 0.000517
Validation Loss: 0.00051985
Epoch [82/300], Train Loss: 0.000493
Validation Loss: 0.00051425
Epoch [83/300], Train Loss: 0.000485
Validation Loss: 0.00049799
Epoch [84/300], Train Loss: 0.000534
Validation Loss: 0.00052894
Epoch [85/300], Train Loss: 0.000515
Validation Loss: 0.00052362
Epoch [86/300], Train Loss: 0.000510
Validation Loss: 0.00050526
Epoch [87/300], Train Loss: 0.000501
Validation Loss: 0.00051737
Epoch [88/300], Train Loss: 0.000486
Validation Loss: 0.00051626
Epoch [89/300], Train Loss: 0.000488
Validation Loss: 0.00049253
Epoch [90/300], Train Loss: 0.000472
Validation Loss: 0.00049034
Epoch [91/300], Train Loss: 0.000475
Validation Loss: 0.00048151
Epoch [92/300], Train Loss: 0.000471
Validation Loss: 0.00048732
Epoch [93/300], Train Loss: 0.000471
Validation Loss: 0.00064921
Epoch [94/300], Train Loss: 0.000578
Validation Loss: 0.00057355
Epoch [95/300], Train Loss: 0.000519
Validation Loss: 0.00053449
Epoch [96/300], Train Loss: 0.000499
Validation Loss: 0.00051489
Epoch [97/300], Train Loss: 0.000509
Validation Loss: 0.00052416
Epoch [98/300], Train Loss: 0.000495
Validation Loss: 0.00051315
Epoch [99/300], Train Loss: 0.000484
Validation Loss: 0.00049256
Epoch [100/300], Train Loss: 0.000475
Validation Loss: 0.00049804
Epoch [101/300], Train Loss: 0.000478
Validation Loss: 0.00049369
Early stopping triggered

Evaluating model for: Coffee Machine
Run 38/72 completed in 1179.62 seconds with: {'MAE': np.float32(5.944492), 'MSE': np.float32(2551.6606), 'RMSE': np.float32(50.513966), 'SAE': np.float32(0.071558826), 'NDE': np.float32(0.78534836)}

Run 39/72: hidden=256, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Coffee Machine
Dataset length: 6004 windows

Epoch [1/300], Train Loss: 0.001133
Validation Loss: 0.00098070
Epoch [2/300], Train Loss: 0.000981
Validation Loss: 0.00097519
Epoch [3/300], Train Loss: 0.000984
Validation Loss: 0.00097506
Epoch [4/300], Train Loss: 0.000982
Validation Loss: 0.00097485
Epoch [5/300], Train Loss: 0.000984
Validation Loss: 0.00097511
Epoch [6/300], Train Loss: 0.000982
Validation Loss: 0.00097443
Epoch [7/300], Train Loss: 0.000975
Validation Loss: 0.00097424
Epoch [8/300], Train Loss: 0.000973
Validation Loss: 0.00097397
Epoch [9/300], Train Loss: 0.000981
Validation Loss: 0.00097397
Epoch [10/300], Train Loss: 0.000968
Validation Loss: 0.00097346
Epoch [11/300], Train Loss: 0.000981
Validation Loss: 0.00097323
Epoch [12/300], Train Loss: 0.000976
Validation Loss: 0.00097309
Epoch [13/300], Train Loss: 0.000972
Validation Loss: 0.00097269
Epoch [14/300], Train Loss: 0.000970
Validation Loss: 0.00097254
Epoch [15/300], Train Loss: 0.000969
Validation Loss: 0.00097209
Epoch [16/300], Train Loss: 0.000964
Validation Loss: 0.00097175
Epoch [17/300], Train Loss: 0.000968
Validation Loss: 0.00097139
Epoch [18/300], Train Loss: 0.000970
Validation Loss: 0.00097109
Epoch [19/300], Train Loss: 0.000968
Validation Loss: 0.00097155
Epoch [20/300], Train Loss: 0.000964
Validation Loss: 0.00097112
Epoch [21/300], Train Loss: 0.000978
Validation Loss: 0.00096938
Epoch [22/300], Train Loss: 0.000965
Validation Loss: 0.00096852
Epoch [23/300], Train Loss: 0.000965
Validation Loss: 0.00096746
Epoch [24/300], Train Loss: 0.000969
Validation Loss: 0.00096541
Epoch [25/300], Train Loss: 0.000962
Validation Loss: 0.00096293
Epoch [26/300], Train Loss: 0.000960
Validation Loss: 0.00096075
Epoch [27/300], Train Loss: 0.000953
Validation Loss: 0.00095582
Epoch [28/300], Train Loss: 0.000954
Validation Loss: 0.00095065
Epoch [29/300], Train Loss: 0.000945
Validation Loss: 0.00094313
Epoch [30/300], Train Loss: 0.000933
Validation Loss: 0.00093911
Epoch [31/300], Train Loss: 0.000919
Validation Loss: 0.00092276
Epoch [32/300], Train Loss: 0.000906
Validation Loss: 0.00090357
Epoch [33/300], Train Loss: 0.000878
Validation Loss: 0.00087921
Epoch [34/300], Train Loss: 0.000849
Validation Loss: 0.00085291
Epoch [35/300], Train Loss: 0.000821
Validation Loss: 0.00082764
Epoch [36/300], Train Loss: 0.000788
Validation Loss: 0.00078461
Epoch [37/300], Train Loss: 0.000769
Validation Loss: 0.00076824
Epoch [38/300], Train Loss: 0.000729
Validation Loss: 0.00073004
Epoch [39/300], Train Loss: 0.000718
Validation Loss: 0.00072084
Epoch [40/300], Train Loss: 0.000700
Validation Loss: 0.00071118
Epoch [41/300], Train Loss: 0.000690
Validation Loss: 0.00073059
Epoch [42/300], Train Loss: 0.000669
Validation Loss: 0.00066891
Epoch [43/300], Train Loss: 0.000671
Validation Loss: 0.00069486
Epoch [44/300], Train Loss: 0.000656
Validation Loss: 0.00065765
Epoch [45/300], Train Loss: 0.000638
Validation Loss: 0.00062735
Epoch [46/300], Train Loss: 0.000637
Validation Loss: 0.00064609
Epoch [47/300], Train Loss: 0.000614
Validation Loss: 0.00062520
Epoch [48/300], Train Loss: 0.000621
Validation Loss: 0.00062948
Epoch [49/300], Train Loss: 0.000610
Validation Loss: 0.00060192
Epoch [50/300], Train Loss: 0.000596
Validation Loss: 0.00062492
Epoch [51/300], Train Loss: 0.000606
Validation Loss: 0.00058852
Epoch [52/300], Train Loss: 0.000585
Validation Loss: 0.00060463
Epoch [53/300], Train Loss: 0.000580
Validation Loss: 0.00063394
Epoch [54/300], Train Loss: 0.000576
Validation Loss: 0.00058655
Epoch [55/300], Train Loss: 0.000576
Validation Loss: 0.00056553
Epoch [56/300], Train Loss: 0.000562
Validation Loss: 0.00056307
Epoch [57/300], Train Loss: 0.000566
Validation Loss: 0.00059009
Epoch [58/300], Train Loss: 0.000564
Validation Loss: 0.00054823
Epoch [59/300], Train Loss: 0.000544
Validation Loss: 0.00055189
Epoch [60/300], Train Loss: 0.000543
Validation Loss: 0.00058684
Epoch [61/300], Train Loss: 0.000537
Validation Loss: 0.00054747
Epoch [62/300], Train Loss: 0.000530
Validation Loss: 0.00053938
Epoch [63/300], Train Loss: 0.000535
Validation Loss: 0.00055543
Epoch [64/300], Train Loss: 0.000523
Validation Loss: 0.00054820
Epoch [65/300], Train Loss: 0.000522
Validation Loss: 0.00054834
Epoch [66/300], Train Loss: 0.000532
Validation Loss: 0.00051173
Epoch [67/300], Train Loss: 0.000515
Validation Loss: 0.00051012
Epoch [68/300], Train Loss: 0.000501
Validation Loss: 0.00048936
Epoch [69/300], Train Loss: 0.000490
Validation Loss: 0.00050283
Epoch [70/300], Train Loss: 0.000480
Validation Loss: 0.00050928
Epoch [71/300], Train Loss: 0.000462
Validation Loss: 0.00046125
Epoch [72/300], Train Loss: 0.000450
Validation Loss: 0.00043441
Epoch [73/300], Train Loss: 0.000432
Validation Loss: 0.00042887
Epoch [74/300], Train Loss: 0.000417
Validation Loss: 0.00041126
Epoch [75/300], Train Loss: 0.000402
Validation Loss: 0.00038520
Epoch [76/300], Train Loss: 0.000507
Validation Loss: 0.00041859
Epoch [77/300], Train Loss: 0.000403
Validation Loss: 0.00038184
Epoch [78/300], Train Loss: 0.000387
Validation Loss: 0.00036434
Epoch [79/300], Train Loss: 0.000379
Validation Loss: 0.00036247
Epoch [80/300], Train Loss: 0.000379
Validation Loss: 0.00035690
Epoch [81/300], Train Loss: 0.000368
Validation Loss: 0.00036590
Epoch [82/300], Train Loss: 0.000366
Validation Loss: 0.00036399
Epoch [83/300], Train Loss: 0.000357
Validation Loss: 0.00033969
Epoch [84/300], Train Loss: 0.000355
Validation Loss: 0.00032073
Epoch [85/300], Train Loss: 0.000352
Validation Loss: 0.00033918
Epoch [86/300], Train Loss: 0.000352
Validation Loss: 0.00033916
Epoch [87/300], Train Loss: 0.000352
Validation Loss: 0.00034023
Epoch [88/300], Train Loss: 0.000339
Validation Loss: 0.00032759
Epoch [89/300], Train Loss: 0.000343
Validation Loss: 0.00032030
Epoch [90/300], Train Loss: 0.000335
Validation Loss: 0.00033859
Epoch [91/300], Train Loss: 0.000336
Validation Loss: 0.00033126
Epoch [92/300], Train Loss: 0.000333
Validation Loss: 0.00031380
Epoch [93/300], Train Loss: 0.000337
Validation Loss: 0.00031862
Epoch [94/300], Train Loss: 0.000333
Validation Loss: 0.00031786
Epoch [95/300], Train Loss: 0.000322
Validation Loss: 0.00029990
Epoch [96/300], Train Loss: 0.000322
Validation Loss: 0.00029850
Epoch [97/300], Train Loss: 0.000328
Validation Loss: 0.00031049
Epoch [98/300], Train Loss: 0.000328
Validation Loss: 0.00027792
Epoch [99/300], Train Loss: 0.000319
Validation Loss: 0.00028302
Epoch [100/300], Train Loss: 0.000318
Validation Loss: 0.00027995
Epoch [101/300], Train Loss: 0.000314
Validation Loss: 0.00026674
Epoch [102/300], Train Loss: 0.000306
Validation Loss: 0.00026924
Epoch [103/300], Train Loss: 0.000298
Validation Loss: 0.00025826
Epoch [104/300], Train Loss: 0.000302
Validation Loss: 0.00025665
Epoch [105/300], Train Loss: 0.000295
Validation Loss: 0.00026548
Epoch [106/300], Train Loss: 0.000317
Validation Loss: 0.00047896
Epoch [107/300], Train Loss: 0.000393
Validation Loss: 0.00030184
Epoch [108/300], Train Loss: 0.000335
Validation Loss: 0.00027973
Epoch [109/300], Train Loss: 0.000333
Validation Loss: 0.00027163
Epoch [110/300], Train Loss: 0.000313
Validation Loss: 0.00027325
Epoch [111/300], Train Loss: 0.000306
Validation Loss: 0.00027196
Epoch [112/300], Train Loss: 0.000298
Validation Loss: 0.00025611
Epoch [113/300], Train Loss: 0.000293
Validation Loss: 0.00025546
Epoch [114/300], Train Loss: 0.000302
Validation Loss: 0.00025481
Epoch [115/300], Train Loss: 0.000294
Validation Loss: 0.00027098
Epoch [116/300], Train Loss: 0.000295
Validation Loss: 0.00026238
Epoch [117/300], Train Loss: 0.000289
Validation Loss: 0.00025503
Epoch [118/300], Train Loss: 0.000279
Validation Loss: 0.00026491
Epoch [119/300], Train Loss: 0.000286
Validation Loss: 0.00025188
Epoch [120/300], Train Loss: 0.000283
Validation Loss: 0.00024379
Epoch [121/300], Train Loss: 0.000284
Validation Loss: 0.00025103
Epoch [122/300], Train Loss: 0.000290
Validation Loss: 0.00026799
Epoch [123/300], Train Loss: 0.000281
Validation Loss: 0.00025451
Epoch [124/300], Train Loss: 0.000282
Validation Loss: 0.00026001
Epoch [125/300], Train Loss: 0.000279
Validation Loss: 0.00024966
Epoch [126/300], Train Loss: 0.000280
Validation Loss: 0.00024317
Epoch [127/300], Train Loss: 0.000267
Validation Loss: 0.00027163
Epoch [128/300], Train Loss: 0.000281
Validation Loss: 0.00025091
Epoch [129/300], Train Loss: 0.000279
Validation Loss: 0.00025283
Epoch [130/300], Train Loss: 0.000275
Validation Loss: 0.00023574
Epoch [131/300], Train Loss: 0.000271
Validation Loss: 0.00022597
Epoch [132/300], Train Loss: 0.000266
Validation Loss: 0.00023637
Epoch [133/300], Train Loss: 0.000265
Validation Loss: 0.00024501
Epoch [134/300], Train Loss: 0.000268
Validation Loss: 0.00022970
Epoch [135/300], Train Loss: 0.000255
Validation Loss: 0.00023060
Epoch [136/300], Train Loss: 0.000255
Validation Loss: 0.00025387
Epoch [137/300], Train Loss: 0.000254
Validation Loss: 0.00024436
Epoch [138/300], Train Loss: 0.000257
Validation Loss: 0.00022870
Epoch [139/300], Train Loss: 0.000266
Validation Loss: 0.00024865
Epoch [140/300], Train Loss: 0.000255
Validation Loss: 0.00023691
Epoch [141/300], Train Loss: 0.000258
Validation Loss: 0.00027863
Early stopping triggered

Evaluating model for: Coffee Machine
Run 39/72 completed in 1811.26 seconds with: {'MAE': np.float32(4.452892), 'MSE': np.float32(1699.6589), 'RMSE': np.float32(41.22692), 'SAE': np.float32(0.014554609), 'NDE': np.float32(0.64096206)}

Run 40/72: hidden=256, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Coffee Machine
Dataset length: 6004 windows

Epoch [1/300], Train Loss: 0.001004
Validation Loss: 0.00097387
Epoch [2/300], Train Loss: 0.000974
Validation Loss: 0.00097192
Epoch [3/300], Train Loss: 0.000977
Validation Loss: 0.00097167
Epoch [4/300], Train Loss: 0.000976
Validation Loss: 0.00097170
Epoch [5/300], Train Loss: 0.000978
Validation Loss: 0.00097198
Epoch [6/300], Train Loss: 0.000976
Validation Loss: 0.00097182
Epoch [7/300], Train Loss: 0.000969
Validation Loss: 0.00097151
Epoch [8/300], Train Loss: 0.000967
Validation Loss: 0.00097155
Epoch [9/300], Train Loss: 0.000976
Validation Loss: 0.00097137
Epoch [10/300], Train Loss: 0.000963
Validation Loss: 0.00097155
Epoch [11/300], Train Loss: 0.000977
Validation Loss: 0.00097131
Epoch [12/300], Train Loss: 0.000972
Validation Loss: 0.00097133
Epoch [13/300], Train Loss: 0.000969
Validation Loss: 0.00097108
Epoch [14/300], Train Loss: 0.000967
Validation Loss: 0.00097115
Epoch [15/300], Train Loss: 0.000966
Validation Loss: 0.00097041
Epoch [16/300], Train Loss: 0.000960
Validation Loss: 0.00096944
Epoch [17/300], Train Loss: 0.000964
Validation Loss: 0.00096767
Epoch [18/300], Train Loss: 0.000964
Validation Loss: 0.00096725
Epoch [19/300], Train Loss: 0.000961
Validation Loss: 0.00096423
Epoch [20/300], Train Loss: 0.000955
Validation Loss: 0.00096274
Epoch [21/300], Train Loss: 0.000967
Validation Loss: 0.00096099
Epoch [22/300], Train Loss: 0.000950
Validation Loss: 0.00095098
Epoch [23/300], Train Loss: 0.000940
Validation Loss: 0.00094039
Epoch [24/300], Train Loss: 0.000929
Validation Loss: 0.00092041
Epoch [25/300], Train Loss: 0.000891
Validation Loss: 0.00088967
Epoch [26/300], Train Loss: 0.000848
Validation Loss: 0.00084648
Epoch [27/300], Train Loss: 0.000795
Validation Loss: 0.00079788
Epoch [28/300], Train Loss: 0.000751
Validation Loss: 0.00075535
Epoch [29/300], Train Loss: 0.000714
Validation Loss: 0.00072267
Epoch [30/300], Train Loss: 0.000695
Validation Loss: 0.00070754
Epoch [31/300], Train Loss: 0.000665
Validation Loss: 0.00068865
Epoch [32/300], Train Loss: 0.000657
Validation Loss: 0.00068134
Epoch [33/300], Train Loss: 0.000656
Validation Loss: 0.00073639
Epoch [34/300], Train Loss: 0.000698
Validation Loss: 0.00067006
Epoch [35/300], Train Loss: 0.000648
Validation Loss: 0.00064993
Epoch [36/300], Train Loss: 0.000631
Validation Loss: 0.00063459
Epoch [37/300], Train Loss: 0.000619
Validation Loss: 0.00063103
Epoch [38/300], Train Loss: 0.000608
Validation Loss: 0.00062260
Epoch [39/300], Train Loss: 0.000617
Validation Loss: 0.00064416
Epoch [40/300], Train Loss: 0.000604
Validation Loss: 0.00060846
Epoch [41/300], Train Loss: 0.000601
Validation Loss: 0.00062385
Epoch [42/300], Train Loss: 0.000578
Validation Loss: 0.00060148
Epoch [43/300], Train Loss: 0.000584
Validation Loss: 0.00057177
Epoch [44/300], Train Loss: 0.000576
Validation Loss: 0.00060807
Epoch [45/300], Train Loss: 0.000565
Validation Loss: 0.00056366
Epoch [46/300], Train Loss: 0.000564
Validation Loss: 0.00057119
Epoch [47/300], Train Loss: 0.000552
Validation Loss: 0.00057922
Epoch [48/300], Train Loss: 0.000552
Validation Loss: 0.00056815
Epoch [49/300], Train Loss: 0.000549
Validation Loss: 0.00054985
Epoch [50/300], Train Loss: 0.000534
Validation Loss: 0.00055374
Epoch [51/300], Train Loss: 0.000529
Validation Loss: 0.00053116
Epoch [52/300], Train Loss: 0.000517
Validation Loss: 0.00053140
Epoch [53/300], Train Loss: 0.000523
Validation Loss: 0.00052587
Epoch [54/300], Train Loss: 0.000506
Validation Loss: 0.00050683
Epoch [55/300], Train Loss: 0.000498
Validation Loss: 0.00050200
Epoch [56/300], Train Loss: 0.000492
Validation Loss: 0.00050118
Epoch [57/300], Train Loss: 0.000487
Validation Loss: 0.00050671
Epoch [58/300], Train Loss: 0.000477
Validation Loss: 0.00047795
Epoch [59/300], Train Loss: 0.000469
Validation Loss: 0.00048670
Epoch [60/300], Train Loss: 0.000462
Validation Loss: 0.00048939
Epoch [61/300], Train Loss: 0.000456
Validation Loss: 0.00044118
Epoch [62/300], Train Loss: 0.000446
Validation Loss: 0.00043782
Epoch [63/300], Train Loss: 0.000442
Validation Loss: 0.00043464
Epoch [64/300], Train Loss: 0.000429
Validation Loss: 0.00040863
Epoch [65/300], Train Loss: 0.000410
Validation Loss: 0.00038998
Epoch [66/300], Train Loss: 0.000402
Validation Loss: 0.00036858
Epoch [67/300], Train Loss: 0.000399
Validation Loss: 0.00038214
Epoch [68/300], Train Loss: 0.000393
Validation Loss: 0.00035430
Epoch [69/300], Train Loss: 0.000383
Validation Loss: 0.00035849
Epoch [70/300], Train Loss: 0.000387
Validation Loss: 0.00033396
Epoch [71/300], Train Loss: 0.000362
Validation Loss: 0.00033395
Epoch [72/300], Train Loss: 0.000358
Validation Loss: 0.00030949
Epoch [73/300], Train Loss: 0.000359
Validation Loss: 0.00033333
Epoch [74/300], Train Loss: 0.000347
Validation Loss: 0.00030735
Epoch [75/300], Train Loss: 0.000338
Validation Loss: 0.00030285
Epoch [76/300], Train Loss: 0.000340
Validation Loss: 0.00028660
Epoch [77/300], Train Loss: 0.000338
Validation Loss: 0.00040559
Epoch [78/300], Train Loss: 0.000455
Validation Loss: 0.00041825
Epoch [79/300], Train Loss: 0.000382
Validation Loss: 0.00031013
Epoch [80/300], Train Loss: 0.000341
Validation Loss: 0.00032193
Epoch [81/300], Train Loss: 0.000347
Validation Loss: 0.00035156
Epoch [82/300], Train Loss: 0.000362
Validation Loss: 0.00030434
Epoch [83/300], Train Loss: 0.000342
Validation Loss: 0.00029852
Epoch [84/300], Train Loss: 0.000329
Validation Loss: 0.00028605
Epoch [85/300], Train Loss: 0.000318
Validation Loss: 0.00027991
Epoch [86/300], Train Loss: 0.000318
Validation Loss: 0.00027443
Epoch [87/300], Train Loss: 0.000330
Validation Loss: 0.00028644
Epoch [88/300], Train Loss: 0.000317
Validation Loss: 0.00028008
Epoch [89/300], Train Loss: 0.000316
Validation Loss: 0.00027046
Epoch [90/300], Train Loss: 0.000305
Validation Loss: 0.00027558
Epoch [91/300], Train Loss: 0.000301
Validation Loss: 0.00026135
Epoch [92/300], Train Loss: 0.000305
Validation Loss: 0.00025771
Epoch [93/300], Train Loss: 0.000300
Validation Loss: 0.00025958
Epoch [94/300], Train Loss: 0.000304
Validation Loss: 0.00026702
Epoch [95/300], Train Loss: 0.000299
Validation Loss: 0.00029679
Epoch [96/300], Train Loss: 0.000312
Validation Loss: 0.00024869
Epoch [97/300], Train Loss: 0.000296
Validation Loss: 0.00024715
Epoch [98/300], Train Loss: 0.000297
Validation Loss: 0.00024115
Epoch [99/300], Train Loss: 0.000288
Validation Loss: 0.00024421
Epoch [100/300], Train Loss: 0.000320
Validation Loss: 0.00027616
Epoch [101/300], Train Loss: 0.000305
Validation Loss: 0.00024565
Epoch [102/300], Train Loss: 0.000289
Validation Loss: 0.00024163
Epoch [103/300], Train Loss: 0.000289
Validation Loss: 0.00023810
Epoch [104/300], Train Loss: 0.000285
Validation Loss: 0.00023974
Epoch [105/300], Train Loss: 0.000276
Validation Loss: 0.00023820
Epoch [106/300], Train Loss: 0.000277
Validation Loss: 0.00023467
Epoch [107/300], Train Loss: 0.000275
Validation Loss: 0.00023273
Epoch [108/300], Train Loss: 0.001231
Validation Loss: 0.00068881
Epoch [109/300], Train Loss: 0.000591
Validation Loss: 0.00057173
Epoch [110/300], Train Loss: 0.000531
Validation Loss: 0.00053475
Epoch [111/300], Train Loss: 0.000502
Validation Loss: 0.00050998
Epoch [112/300], Train Loss: 0.000485
Validation Loss: 0.00049247
Epoch [113/300], Train Loss: 0.000469
Validation Loss: 0.00047670
Epoch [114/300], Train Loss: 0.000463
Validation Loss: 0.00046352
Epoch [115/300], Train Loss: 0.000448
Validation Loss: 0.00045086
Epoch [116/300], Train Loss: 0.000441
Validation Loss: 0.00044075
Epoch [117/300], Train Loss: 0.000434
Validation Loss: 0.00043126
Early stopping triggered

Evaluating model for: Coffee Machine
Run 40/72 completed in 1831.64 seconds with: {'MAE': np.float32(6.2142186), 'MSE': np.float32(2191.8384), 'RMSE': np.float32(46.817074), 'SAE': np.float32(0.009829441), 'NDE': np.float32(0.72787285)}

Run 41/72: hidden=256, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Coffee Machine
Dataset length: 5916 windows

Epoch [1/300], Train Loss: 0.000991
Validation Loss: 0.00100421
Epoch [2/300], Train Loss: 0.000986
Validation Loss: 0.00100476
Epoch [3/300], Train Loss: 0.000984
Validation Loss: 0.00100098
Epoch [4/300], Train Loss: 0.000981
Validation Loss: 0.00099899
Epoch [5/300], Train Loss: 0.000978
Validation Loss: 0.00099602
Epoch [6/300], Train Loss: 0.000973
Validation Loss: 0.00099151
Epoch [7/300], Train Loss: 0.000970
Validation Loss: 0.00098850
Epoch [8/300], Train Loss: 0.000967
Validation Loss: 0.00098467
Epoch [9/300], Train Loss: 0.000962
Validation Loss: 0.00098084
Epoch [10/300], Train Loss: 0.000958
Validation Loss: 0.00097465
Epoch [11/300], Train Loss: 0.000952
Validation Loss: 0.00097176
Epoch [12/300], Train Loss: 0.000947
Validation Loss: 0.00095923
Epoch [13/300], Train Loss: 0.000937
Validation Loss: 0.00095052
Epoch [14/300], Train Loss: 0.000928
Validation Loss: 0.00094073
Epoch [15/300], Train Loss: 0.000918
Validation Loss: 0.00092965
Epoch [16/300], Train Loss: 0.000906
Validation Loss: 0.00091631
Epoch [17/300], Train Loss: 0.000891
Validation Loss: 0.00090264
Epoch [18/300], Train Loss: 0.000874
Validation Loss: 0.00088297
Epoch [19/300], Train Loss: 0.000856
Validation Loss: 0.00086290
Epoch [20/300], Train Loss: 0.000836
Validation Loss: 0.00084607
Epoch [21/300], Train Loss: 0.000818
Validation Loss: 0.00082798
Epoch [22/300], Train Loss: 0.000799
Validation Loss: 0.00080843
Epoch [23/300], Train Loss: 0.000779
Validation Loss: 0.00079270
Epoch [24/300], Train Loss: 0.000766
Validation Loss: 0.00079037
Epoch [25/300], Train Loss: 0.000752
Validation Loss: 0.00077638
Epoch [26/300], Train Loss: 0.000739
Validation Loss: 0.00080730
Epoch [27/300], Train Loss: 0.000734
Validation Loss: 0.00074644
Epoch [28/300], Train Loss: 0.000714
Validation Loss: 0.00074108
Epoch [29/300], Train Loss: 0.000710
Validation Loss: 0.00074080
Epoch [30/300], Train Loss: 0.000699
Validation Loss: 0.00071852
Epoch [31/300], Train Loss: 0.000693
Validation Loss: 0.00072074
Epoch [32/300], Train Loss: 0.000681
Validation Loss: 0.00071443
Epoch [33/300], Train Loss: 0.000673
Validation Loss: 0.00070599
Epoch [34/300], Train Loss: 0.000668
Validation Loss: 0.00068831
Epoch [35/300], Train Loss: 0.000660
Validation Loss: 0.00069101
Epoch [36/300], Train Loss: 0.000648
Validation Loss: 0.00067631
Epoch [37/300], Train Loss: 0.000638
Validation Loss: 0.00066173
Epoch [38/300], Train Loss: 0.000632
Validation Loss: 0.00066324
Epoch [39/300], Train Loss: 0.000624
Validation Loss: 0.00064629
Epoch [40/300], Train Loss: 0.000612
Validation Loss: 0.00064855
Epoch [41/300], Train Loss: 0.000606
Validation Loss: 0.00061741
Epoch [42/300], Train Loss: 0.000604
Validation Loss: 0.00062111
Epoch [43/300], Train Loss: 0.000590
Validation Loss: 0.00060214
Epoch [44/300], Train Loss: 0.000590
Validation Loss: 0.00061218
Epoch [45/300], Train Loss: 0.000578
Validation Loss: 0.00059078
Epoch [46/300], Train Loss: 0.000577
Validation Loss: 0.00060032
Epoch [47/300], Train Loss: 0.000568
Validation Loss: 0.00058641
Epoch [48/300], Train Loss: 0.000570
Validation Loss: 0.00057166
Epoch [49/300], Train Loss: 0.000556
Validation Loss: 0.00056486
Epoch [50/300], Train Loss: 0.000555
Validation Loss: 0.00057404
Epoch [51/300], Train Loss: 0.000555
Validation Loss: 0.00058185
Epoch [52/300], Train Loss: 0.000545
Validation Loss: 0.00055902
Epoch [53/300], Train Loss: 0.000537
Validation Loss: 0.00055892
Epoch [54/300], Train Loss: 0.000535
Validation Loss: 0.00054844
Epoch [55/300], Train Loss: 0.000529
Validation Loss: 0.00055742
Epoch [56/300], Train Loss: 0.000530
Validation Loss: 0.00054416
Epoch [57/300], Train Loss: 0.000519
Validation Loss: 0.00055324
Epoch [58/300], Train Loss: 0.000521
Validation Loss: 0.00053773
Epoch [59/300], Train Loss: 0.000568
Validation Loss: 0.00057123
Epoch [60/300], Train Loss: 0.000547
Validation Loss: 0.00054013
Epoch [61/300], Train Loss: 0.000530
Validation Loss: 0.00053975
Epoch [62/300], Train Loss: 0.000528
Validation Loss: 0.00053571
Epoch [63/300], Train Loss: 0.000517
Validation Loss: 0.00053755
Epoch [64/300], Train Loss: 0.000513
Validation Loss: 0.00053182
Epoch [65/300], Train Loss: 0.000510
Validation Loss: 0.00051799
Epoch [66/300], Train Loss: 0.000507
Validation Loss: 0.00050787
Epoch [67/300], Train Loss: 0.000503
Validation Loss: 0.00050293
Epoch [68/300], Train Loss: 0.000496
Validation Loss: 0.00049963
Epoch [69/300], Train Loss: 0.000494
Validation Loss: 0.00049724
Epoch [70/300], Train Loss: 0.000489
Validation Loss: 0.00049663
Epoch [71/300], Train Loss: 0.000485
Validation Loss: 0.00049062
Epoch [72/300], Train Loss: 0.000489
Validation Loss: 0.00049021
Epoch [73/300], Train Loss: 0.000483
Validation Loss: 0.00048357
Epoch [74/300], Train Loss: 0.000478
Validation Loss: 0.00048781
Epoch [75/300], Train Loss: 0.000473
Validation Loss: 0.00047785
Epoch [76/300], Train Loss: 0.000471
Validation Loss: 0.00048638
Epoch [77/300], Train Loss: 0.000539
Validation Loss: 0.00053561
Epoch [78/300], Train Loss: 0.000508
Validation Loss: 0.00050382
Epoch [79/300], Train Loss: 0.000487
Validation Loss: 0.00049220
Epoch [80/300], Train Loss: 0.000481
Validation Loss: 0.00049046
Epoch [81/300], Train Loss: 0.000475
Validation Loss: 0.00047537
Epoch [82/300], Train Loss: 0.000467
Validation Loss: 0.00047924
Epoch [83/300], Train Loss: 0.000469
Validation Loss: 0.00047129
Epoch [84/300], Train Loss: 0.000465
Validation Loss: 0.00047895
Epoch [85/300], Train Loss: 0.000467
Validation Loss: 0.00046429
Epoch [86/300], Train Loss: 0.000460
Validation Loss: 0.00046455
Epoch [87/300], Train Loss: 0.000457
Validation Loss: 0.00045988
Epoch [88/300], Train Loss: 0.000453
Validation Loss: 0.00045942
Epoch [89/300], Train Loss: 0.000450
Validation Loss: 0.00045593
Epoch [90/300], Train Loss: 0.000446
Validation Loss: 0.00044973
Epoch [91/300], Train Loss: 0.000439
Validation Loss: 0.00045026
Epoch [92/300], Train Loss: 0.000437
Validation Loss: 0.00044036
Epoch [93/300], Train Loss: 0.000436
Validation Loss: 0.00044032
Epoch [94/300], Train Loss: 0.000434
Validation Loss: 0.00043703
Epoch [95/300], Train Loss: 0.000432
Validation Loss: 0.00043487
Epoch [96/300], Train Loss: 0.000428
Validation Loss: 0.00043023
Epoch [97/300], Train Loss: 0.000424
Validation Loss: 0.00042912
Epoch [98/300], Train Loss: 0.000453
Validation Loss: 0.00043873
Epoch [99/300], Train Loss: 0.000427
Validation Loss: 0.00042280
Epoch [100/300], Train Loss: 0.000418
Validation Loss: 0.00042282
Epoch [101/300], Train Loss: 0.000419
Validation Loss: 0.00042554
Epoch [102/300], Train Loss: 0.000409
Validation Loss: 0.00041592
Epoch [103/300], Train Loss: 0.000405
Validation Loss: 0.00041217
Epoch [104/300], Train Loss: 0.000404
Validation Loss: 0.00040786
Epoch [105/300], Train Loss: 0.000400
Validation Loss: 0.00040022
Epoch [106/300], Train Loss: 0.000451
Validation Loss: 0.00046919
Epoch [107/300], Train Loss: 0.000455
Validation Loss: 0.00046716
Epoch [108/300], Train Loss: 0.000446
Validation Loss: 0.00044204
Epoch [109/300], Train Loss: 0.000421
Validation Loss: 0.00041222
Epoch [110/300], Train Loss: 0.000397
Validation Loss: 0.00040907
Epoch [111/300], Train Loss: 0.000396
Validation Loss: 0.00040504
Epoch [112/300], Train Loss: 0.000392
Validation Loss: 0.00040265
Epoch [113/300], Train Loss: 0.000386
Validation Loss: 0.00040039
Epoch [114/300], Train Loss: 0.000377
Validation Loss: 0.00038590
Epoch [115/300], Train Loss: 0.000397
Validation Loss: 0.00039835
Epoch [116/300], Train Loss: 0.000385
Validation Loss: 0.00038573
Epoch [117/300], Train Loss: 0.000373
Validation Loss: 0.00037754
Epoch [118/300], Train Loss: 0.000376
Validation Loss: 0.00037071
Epoch [119/300], Train Loss: 0.000372
Validation Loss: 0.00037437
Epoch [120/300], Train Loss: 0.000381
Validation Loss: 0.00036985
Epoch [121/300], Train Loss: 0.000369
Validation Loss: 0.00037171
Epoch [122/300], Train Loss: 0.000360
Validation Loss: 0.00036156
Epoch [123/300], Train Loss: 0.000354
Validation Loss: 0.00035815
Epoch [124/300], Train Loss: 0.000351
Validation Loss: 0.00035776
Epoch [125/300], Train Loss: 0.000348
Validation Loss: 0.00034900
Epoch [126/300], Train Loss: 0.000352
Validation Loss: 0.00036069
Epoch [127/300], Train Loss: 0.000346
Validation Loss: 0.00034766
Epoch [128/300], Train Loss: 0.000342
Validation Loss: 0.00034274
Epoch [129/300], Train Loss: 0.000342
Validation Loss: 0.00034537
Epoch [130/300], Train Loss: 0.000338
Validation Loss: 0.00034165
Epoch [131/300], Train Loss: 0.000339
Validation Loss: 0.00035210
Epoch [132/300], Train Loss: 0.000340
Validation Loss: 0.00033586
Epoch [133/300], Train Loss: 0.000335
Validation Loss: 0.00032918
Epoch [134/300], Train Loss: 0.000327
Validation Loss: 0.00033078
Epoch [135/300], Train Loss: 0.000324
Validation Loss: 0.00033095
Epoch [136/300], Train Loss: 0.000331
Validation Loss: 0.00033021
Epoch [137/300], Train Loss: 0.000326
Validation Loss: 0.00032162
Epoch [138/300], Train Loss: 0.000317
Validation Loss: 0.00032402
Epoch [139/300], Train Loss: 0.000320
Validation Loss: 0.00031481
Epoch [140/300], Train Loss: 0.000328
Validation Loss: 0.00032134
Epoch [141/300], Train Loss: 0.000318
Validation Loss: 0.00031457
Epoch [142/300], Train Loss: 0.000314
Validation Loss: 0.00030948
Epoch [143/300], Train Loss: 0.000311
Validation Loss: 0.00030748
Epoch [144/300], Train Loss: 0.000308
Validation Loss: 0.00031714
Epoch [145/300], Train Loss: 0.000312
Validation Loss: 0.00030690
Epoch [146/300], Train Loss: 0.000309
Validation Loss: 0.00030685
Epoch [147/300], Train Loss: 0.000313
Validation Loss: 0.00030601
Epoch [148/300], Train Loss: 0.000304
Validation Loss: 0.00030487
Epoch [149/300], Train Loss: 0.000302
Validation Loss: 0.00030212
Epoch [150/300], Train Loss: 0.000301
Validation Loss: 0.00029528
Epoch [151/300], Train Loss: 0.000301
Validation Loss: 0.00029504
Epoch [152/300], Train Loss: 0.000297
Validation Loss: 0.00029621
Epoch [153/300], Train Loss: 0.000295
Validation Loss: 0.00029133
Epoch [154/300], Train Loss: 0.000292
Validation Loss: 0.00029837
Epoch [155/300], Train Loss: 0.000290
Validation Loss: 0.00028944
Epoch [156/300], Train Loss: 0.000292
Validation Loss: 0.00028720
Epoch [157/300], Train Loss: 0.000289
Validation Loss: 0.00028610
Epoch [158/300], Train Loss: 0.000287
Validation Loss: 0.00029017
Epoch [159/300], Train Loss: 0.000285
Validation Loss: 0.00029714
Epoch [160/300], Train Loss: 0.000292
Validation Loss: 0.00028470
Epoch [161/300], Train Loss: 0.000280
Validation Loss: 0.00028052
Epoch [162/300], Train Loss: 0.000291
Validation Loss: 0.00029929
Epoch [163/300], Train Loss: 0.000289
Validation Loss: 0.00028587
Epoch [164/300], Train Loss: 0.000288
Validation Loss: 0.00029724
Epoch [165/300], Train Loss: 0.000281
Validation Loss: 0.00028170
Epoch [166/300], Train Loss: 0.000277
Validation Loss: 0.00027849
Epoch [167/300], Train Loss: 0.000277
Validation Loss: 0.00027574
Epoch [168/300], Train Loss: 0.000276
Validation Loss: 0.00027933
Epoch [169/300], Train Loss: 0.000279
Validation Loss: 0.00027193
Epoch [170/300], Train Loss: 0.000271
Validation Loss: 0.00026964
Epoch [171/300], Train Loss: 0.000267
Validation Loss: 0.00026973
Epoch [172/300], Train Loss: 0.000290
Validation Loss: 0.00028178
Epoch [173/300], Train Loss: 0.000274
Validation Loss: 0.00026966
Epoch [174/300], Train Loss: 0.000267
Validation Loss: 0.00026345
Epoch [175/300], Train Loss: 0.000267
Validation Loss: 0.00028053
Epoch [176/300], Train Loss: 0.000267
Validation Loss: 0.00026758
Epoch [177/300], Train Loss: 0.000278
Validation Loss: 0.00027272
Epoch [178/300], Train Loss: 0.000263
Validation Loss: 0.00026421
Epoch [179/300], Train Loss: 0.000269
Validation Loss: 0.00030278
Epoch [180/300], Train Loss: 0.000261
Validation Loss: 0.00026381
Epoch [181/300], Train Loss: 0.000258
Validation Loss: 0.00026075
Epoch [182/300], Train Loss: 0.000258
Validation Loss: 0.00025994
Epoch [183/300], Train Loss: 0.000264
Validation Loss: 0.00027606
Epoch [184/300], Train Loss: 0.000259
Validation Loss: 0.00025614
Epoch [185/300], Train Loss: 0.000256
Validation Loss: 0.00025579
Epoch [186/300], Train Loss: 0.000253
Validation Loss: 0.00025957
Epoch [187/300], Train Loss: 0.000254
Validation Loss: 0.00025491
Epoch [188/300], Train Loss: 0.000254
Validation Loss: 0.00025285
Epoch [189/300], Train Loss: 0.000257
Validation Loss: 0.00028093
Epoch [190/300], Train Loss: 0.000260
Validation Loss: 0.00026069
Epoch [191/300], Train Loss: 0.000252
Validation Loss: 0.00026962
Epoch [192/300], Train Loss: 0.000254
Validation Loss: 0.00026142
Epoch [193/300], Train Loss: 0.000257
Validation Loss: 0.00026733
Epoch [194/300], Train Loss: 0.000256
Validation Loss: 0.00025898
Epoch [195/300], Train Loss: 0.000253
Validation Loss: 0.00031412
Epoch [196/300], Train Loss: 0.000254
Validation Loss: 0.00025555
Epoch [197/300], Train Loss: 0.000248
Validation Loss: 0.00024939
Epoch [198/300], Train Loss: 0.000248
Validation Loss: 0.00025581
Epoch [199/300], Train Loss: 0.000246
Validation Loss: 0.00024979
Epoch [200/300], Train Loss: 0.000247
Validation Loss: 0.00025420
Epoch [201/300], Train Loss: 0.000252
Validation Loss: 0.00025325
Epoch [202/300], Train Loss: 0.000244
Validation Loss: 0.00025111
Epoch [203/300], Train Loss: 0.000248
Validation Loss: 0.00025609
Epoch [204/300], Train Loss: 0.000244
Validation Loss: 0.00025207
Epoch [205/300], Train Loss: 0.000248
Validation Loss: 0.00025092
Epoch [206/300], Train Loss: 0.000242
Validation Loss: 0.00024730
Epoch [207/300], Train Loss: 0.000243
Validation Loss: 0.00024514
Epoch [208/300], Train Loss: 0.000245
Validation Loss: 0.00025575
Epoch [209/300], Train Loss: 0.000245
Validation Loss: 0.00024732
Epoch [210/300], Train Loss: 0.000251
Validation Loss: 0.00026642
Epoch [211/300], Train Loss: 0.000247
Validation Loss: 0.00025257
Epoch [212/300], Train Loss: 0.000243
Validation Loss: 0.00024895
Epoch [213/300], Train Loss: 0.000240
Validation Loss: 0.00024785
Epoch [214/300], Train Loss: 0.000246
Validation Loss: 0.00025927
Epoch [215/300], Train Loss: 0.000242
Validation Loss: 0.00025030
Epoch [216/300], Train Loss: 0.000240
Validation Loss: 0.00025472
Epoch [217/300], Train Loss: 0.000239
Validation Loss: 0.00024924
Early stopping triggered

Evaluating model for: Coffee Machine
Run 41/72 completed in 2745.63 seconds with: {'MAE': np.float32(3.95972), 'MSE': np.float32(1112.545), 'RMSE': np.float32(33.354836), 'SAE': np.float32(0.000400652), 'NDE': np.float32(0.51379055)}

Run 42/72: hidden=256, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Coffee Machine
Dataset length: 5916 windows

Epoch [1/300], Train Loss: 0.001182
Validation Loss: 0.00102044
Epoch [2/300], Train Loss: 0.000994
Validation Loss: 0.00100850
Epoch [3/300], Train Loss: 0.000991
Validation Loss: 0.00100828
Epoch [4/300], Train Loss: 0.000991
Validation Loss: 0.00100814
Epoch [5/300], Train Loss: 0.000990
Validation Loss: 0.00100797
Epoch [6/300], Train Loss: 0.000989
Validation Loss: 0.00100787
Epoch [7/300], Train Loss: 0.000989
Validation Loss: 0.00100760
Epoch [8/300], Train Loss: 0.000988
Validation Loss: 0.00100732
Epoch [9/300], Train Loss: 0.000987
Validation Loss: 0.00100719
Epoch [10/300], Train Loss: 0.000987
Validation Loss: 0.00100671
Epoch [11/300], Train Loss: 0.000986
Validation Loss: 0.00100631
Epoch [12/300], Train Loss: 0.000985
Validation Loss: 0.00100570
Epoch [13/300], Train Loss: 0.000984
Validation Loss: 0.00100494
Epoch [14/300], Train Loss: 0.000983
Validation Loss: 0.00100404
Epoch [15/300], Train Loss: 0.000983
Validation Loss: 0.00100295
Epoch [16/300], Train Loss: 0.000982
Validation Loss: 0.00100182
Epoch [17/300], Train Loss: 0.000980
Validation Loss: 0.00100094
Epoch [18/300], Train Loss: 0.000978
Validation Loss: 0.00099768
Epoch [19/300], Train Loss: 0.000975
Validation Loss: 0.00099378
Epoch [20/300], Train Loss: 0.000972
Validation Loss: 0.00099269
Epoch [21/300], Train Loss: 0.000968
Validation Loss: 0.00098513
Epoch [22/300], Train Loss: 0.000963
Validation Loss: 0.00097957
Epoch [23/300], Train Loss: 0.000955
Validation Loss: 0.00096880
Epoch [24/300], Train Loss: 0.000944
Validation Loss: 0.00095605
Epoch [25/300], Train Loss: 0.000926
Validation Loss: 0.00093375
Epoch [26/300], Train Loss: 0.000904
Validation Loss: 0.00091184
Epoch [27/300], Train Loss: 0.000876
Validation Loss: 0.00087927
Epoch [28/300], Train Loss: 0.000844
Validation Loss: 0.00084791
Epoch [29/300], Train Loss: 0.000814
Validation Loss: 0.00082027
Epoch [30/300], Train Loss: 0.000786
Validation Loss: 0.00078945
Epoch [31/300], Train Loss: 0.000764
Validation Loss: 0.00076950
Epoch [32/300], Train Loss: 0.000739
Validation Loss: 0.00075625
Epoch [33/300], Train Loss: 0.000723
Validation Loss: 0.00075958
Epoch [34/300], Train Loss: 0.000717
Validation Loss: 0.00072396
Epoch [35/300], Train Loss: 0.000700
Validation Loss: 0.00072605
Epoch [36/300], Train Loss: 0.000688
Validation Loss: 0.00069642
Epoch [37/300], Train Loss: 0.000667
Validation Loss: 0.00067944
Epoch [38/300], Train Loss: 0.000661
Validation Loss: 0.00066439
Epoch [39/300], Train Loss: 0.000641
Validation Loss: 0.00065378
Epoch [40/300], Train Loss: 0.000644
Validation Loss: 0.00069715
Epoch [41/300], Train Loss: 0.000622
Validation Loss: 0.00063641
Epoch [42/300], Train Loss: 0.000622
Validation Loss: 0.00062273
Epoch [43/300], Train Loss: 0.000600
Validation Loss: 0.00061137
Epoch [44/300], Train Loss: 0.000587
Validation Loss: 0.00060348
Epoch [45/300], Train Loss: 0.000575
Validation Loss: 0.00058487
Epoch [46/300], Train Loss: 0.000580
Validation Loss: 0.00058303
Epoch [47/300], Train Loss: 0.000563
Validation Loss: 0.00059811
Epoch [48/300], Train Loss: 0.000565
Validation Loss: 0.00057943
Epoch [49/300], Train Loss: 0.000552
Validation Loss: 0.00055688
Epoch [50/300], Train Loss: 0.000548
Validation Loss: 0.00055181
Epoch [51/300], Train Loss: 0.000542
Validation Loss: 0.00055441
Epoch [52/300], Train Loss: 0.000530
Validation Loss: 0.00053764
Epoch [53/300], Train Loss: 0.000532
Validation Loss: 0.00053421
Epoch [54/300], Train Loss: 0.000522
Validation Loss: 0.00051783
Epoch [55/300], Train Loss: 0.000512
Validation Loss: 0.00051748
Epoch [56/300], Train Loss: 0.000509
Validation Loss: 0.00051565
Epoch [57/300], Train Loss: 0.000504
Validation Loss: 0.00050100
Epoch [58/300], Train Loss: 0.000497
Validation Loss: 0.00049638
Epoch [59/300], Train Loss: 0.000490
Validation Loss: 0.00048436
Epoch [60/300], Train Loss: 0.000493
Validation Loss: 0.00048426
Epoch [61/300], Train Loss: 0.000481
Validation Loss: 0.00047098
Epoch [62/300], Train Loss: 0.000473
Validation Loss: 0.00046900
Epoch [63/300], Train Loss: 0.000461
Validation Loss: 0.00047078
Epoch [64/300], Train Loss: 0.000487
Validation Loss: 0.00046524
Epoch [65/300], Train Loss: 0.000462
Validation Loss: 0.00047171
Epoch [66/300], Train Loss: 0.000483
Validation Loss: 0.00045464
Epoch [67/300], Train Loss: 0.000459
Validation Loss: 0.00044062
Epoch [68/300], Train Loss: 0.000444
Validation Loss: 0.00042827
Epoch [69/300], Train Loss: 0.000434
Validation Loss: 0.00041677
Epoch [70/300], Train Loss: 0.000430
Validation Loss: 0.00041703
Epoch [71/300], Train Loss: 0.000422
Validation Loss: 0.00041187
Epoch [72/300], Train Loss: 0.000417
Validation Loss: 0.00039894
Epoch [73/300], Train Loss: 0.000407
Validation Loss: 0.00039869
Epoch [74/300], Train Loss: 0.000406
Validation Loss: 0.00039695
Epoch [75/300], Train Loss: 0.000400
Validation Loss: 0.00039049
Epoch [76/300], Train Loss: 0.000384
Validation Loss: 0.00036521
Epoch [77/300], Train Loss: 0.000375
Validation Loss: 0.00037963
Epoch [78/300], Train Loss: 0.000384
Validation Loss: 0.00038291
Epoch [79/300], Train Loss: 0.000378
Validation Loss: 0.00035844
Epoch [80/300], Train Loss: 0.000365
Validation Loss: 0.00035533
Epoch [81/300], Train Loss: 0.000356
Validation Loss: 0.00034194
Epoch [82/300], Train Loss: 0.000359
Validation Loss: 0.00035841
Epoch [83/300], Train Loss: 0.000380
Validation Loss: 0.00037413
Epoch [84/300], Train Loss: 0.000372
Validation Loss: 0.00036138
Epoch [85/300], Train Loss: 0.000359
Validation Loss: 0.00034242
Epoch [86/300], Train Loss: 0.000352
Validation Loss: 0.00033247
Epoch [87/300], Train Loss: 0.000349
Validation Loss: 0.00039302
Epoch [88/300], Train Loss: 0.000350
Validation Loss: 0.00033356
Epoch [89/300], Train Loss: 0.000334
Validation Loss: 0.00033032
Epoch [90/300], Train Loss: 0.000336
Validation Loss: 0.00033048
Epoch [91/300], Train Loss: 0.000329
Validation Loss: 0.00033592
Epoch [92/300], Train Loss: 0.000326
Validation Loss: 0.00032408
Epoch [93/300], Train Loss: 0.000319
Validation Loss: 0.00032102
Epoch [94/300], Train Loss: 0.000321
Validation Loss: 0.00033004
Epoch [95/300], Train Loss: 0.000326
Validation Loss: 0.00033215
Epoch [96/300], Train Loss: 0.000311
Validation Loss: 0.00029711
Epoch [97/300], Train Loss: 0.000310
Validation Loss: 0.00030141
Epoch [98/300], Train Loss: 0.000312
Validation Loss: 0.00030862
Epoch [99/300], Train Loss: 0.000299
Validation Loss: 0.00029539
Epoch [100/300], Train Loss: 0.000292
Validation Loss: 0.00029424
Epoch [101/300], Train Loss: 0.000292
Validation Loss: 0.00029837
Epoch [102/300], Train Loss: 0.000289
Validation Loss: 0.00028824
Epoch [103/300], Train Loss: 0.000288
Validation Loss: 0.00029449
Epoch [104/300], Train Loss: 0.000303
Validation Loss: 0.00031062
Epoch [105/300], Train Loss: 0.000312
Validation Loss: 0.00029756
Epoch [106/300], Train Loss: 0.000300
Validation Loss: 0.00029461
Epoch [107/300], Train Loss: 0.000292
Validation Loss: 0.00028460
Epoch [108/300], Train Loss: 0.000297
Validation Loss: 0.00029110
Epoch [109/300], Train Loss: 0.000288
Validation Loss: 0.00027749
Epoch [110/300], Train Loss: 0.000300
Validation Loss: 0.00029852
Epoch [111/300], Train Loss: 0.000289
Validation Loss: 0.00028629
Epoch [112/300], Train Loss: 0.000285
Validation Loss: 0.00029203
Epoch [113/300], Train Loss: 0.000285
Validation Loss: 0.00028717
Epoch [114/300], Train Loss: 0.000279
Validation Loss: 0.00028985
Epoch [115/300], Train Loss: 0.000273
Validation Loss: 0.00028573
Epoch [116/300], Train Loss: 0.000273
Validation Loss: 0.00027998
Epoch [117/300], Train Loss: 0.000273
Validation Loss: 0.00028188
Epoch [118/300], Train Loss: 0.000273
Validation Loss: 0.00027478
Epoch [119/300], Train Loss: 0.000302
Validation Loss: 0.00032938
Epoch [120/300], Train Loss: 0.000324
Validation Loss: 0.00031001
Epoch [121/300], Train Loss: 0.000290
Validation Loss: 0.00028830
Epoch [122/300], Train Loss: 0.000277
Validation Loss: 0.00028158
Epoch [123/300], Train Loss: 0.000273
Validation Loss: 0.00027085
Epoch [124/300], Train Loss: 0.000265
Validation Loss: 0.00027271
Epoch [125/300], Train Loss: 0.000259
Validation Loss: 0.00026546
Epoch [126/300], Train Loss: 0.000259
Validation Loss: 0.00026771
Epoch [127/300], Train Loss: 0.000258
Validation Loss: 0.00026102
Epoch [128/300], Train Loss: 0.000251
Validation Loss: 0.00026629
Epoch [129/300], Train Loss: 0.000251
Validation Loss: 0.00025543
Epoch [130/300], Train Loss: 0.000252
Validation Loss: 0.00025316
Epoch [131/300], Train Loss: 0.000248
Validation Loss: 0.00026252
Epoch [132/300], Train Loss: 0.000286
Validation Loss: 0.00027992
Epoch [133/300], Train Loss: 0.000282
Validation Loss: 0.00028372
Epoch [134/300], Train Loss: 0.000275
Validation Loss: 0.00025939
Epoch [135/300], Train Loss: 0.000269
Validation Loss: 0.00026617
Epoch [136/300], Train Loss: 0.000252
Validation Loss: 0.00025642
Epoch [137/300], Train Loss: 0.000248
Validation Loss: 0.00025164
Epoch [138/300], Train Loss: 0.000245
Validation Loss: 0.00024670
Epoch [139/300], Train Loss: 0.000243
Validation Loss: 0.00024598
Epoch [140/300], Train Loss: 0.000242
Validation Loss: 0.00024313
Epoch [141/300], Train Loss: 0.000243
Validation Loss: 0.00025125
Epoch [142/300], Train Loss: 0.000247
Validation Loss: 0.00026332
Epoch [143/300], Train Loss: 0.000245
Validation Loss: 0.00024747
Epoch [144/300], Train Loss: 0.000243
Validation Loss: 0.00025029
Epoch [145/300], Train Loss: 0.000245
Validation Loss: 0.00024951
Epoch [146/300], Train Loss: 0.000240
Validation Loss: 0.00024511
Epoch [147/300], Train Loss: 0.000239
Validation Loss: 0.00023886
Epoch [148/300], Train Loss: 0.000236
Validation Loss: 0.00024067
Epoch [149/300], Train Loss: 0.000234
Validation Loss: 0.00025002
Epoch [150/300], Train Loss: 0.000244
Validation Loss: 0.00023927
Epoch [151/300], Train Loss: 0.000235
Validation Loss: 0.00024316
Epoch [152/300], Train Loss: 0.000234
Validation Loss: 0.00023652
Epoch [153/300], Train Loss: 0.000233
Validation Loss: 0.00023695
Epoch [154/300], Train Loss: 0.000237
Validation Loss: 0.00028578
Epoch [155/300], Train Loss: 0.000247
Validation Loss: 0.00024755
Epoch [156/300], Train Loss: 0.000237
Validation Loss: 0.00025896
Epoch [157/300], Train Loss: 0.000239
Validation Loss: 0.00025152
Epoch [158/300], Train Loss: 0.000238
Validation Loss: 0.00024792
Epoch [159/300], Train Loss: 0.000233
Validation Loss: 0.00023560
Epoch [160/300], Train Loss: 0.000231
Validation Loss: 0.00023844
Epoch [161/300], Train Loss: 0.000229
Validation Loss: 0.00023865
Epoch [162/300], Train Loss: 0.000232
Validation Loss: 0.00023642
Epoch [163/300], Train Loss: 0.000224
Validation Loss: 0.00024304
Epoch [164/300], Train Loss: 0.000224
Validation Loss: 0.00023079
Epoch [165/300], Train Loss: 0.000229
Validation Loss: 0.00022821
Epoch [166/300], Train Loss: 0.000223
Validation Loss: 0.00022927
Epoch [167/300], Train Loss: 0.000224
Validation Loss: 0.00023485
Epoch [168/300], Train Loss: 0.000221
Validation Loss: 0.00022553
Epoch [169/300], Train Loss: 0.000224
Validation Loss: 0.00022500
Epoch [170/300], Train Loss: 0.000223
Validation Loss: 0.00023037
Epoch [171/300], Train Loss: 0.000220
Validation Loss: 0.00023077
Epoch [172/300], Train Loss: 0.000220
Validation Loss: 0.00023210
Epoch [173/300], Train Loss: 0.000219
Validation Loss: 0.00022744
Epoch [174/300], Train Loss: 0.000222
Validation Loss: 0.00023520
Epoch [175/300], Train Loss: 0.000230
Validation Loss: 0.00023279
Epoch [176/300], Train Loss: 0.000230
Validation Loss: 0.00023332
Epoch [177/300], Train Loss: 0.000226
Validation Loss: 0.00023126
Epoch [178/300], Train Loss: 0.000222
Validation Loss: 0.00022887
Epoch [179/300], Train Loss: 0.000221
Validation Loss: 0.00022533
Early stopping triggered

Evaluating model for: Coffee Machine
Run 42/72 completed in 2815.15 seconds with: {'MAE': np.float32(3.694399), 'MSE': np.float32(1053.603), 'RMSE': np.float32(32.45925), 'SAE': np.float32(0.027012061), 'NDE': np.float32(0.49999526)}

Run 43/72: hidden=256, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Coffee Machine
Dataset length: 5916 windows

Epoch [1/300], Train Loss: 0.000992
Validation Loss: 0.00100676
Epoch [2/300], Train Loss: 0.000987
Validation Loss: 0.00100630
Epoch [3/300], Train Loss: 0.000986
Validation Loss: 0.00100602
Epoch [4/300], Train Loss: 0.000985
Validation Loss: 0.00100579
Epoch [5/300], Train Loss: 0.000984
Validation Loss: 0.00100504
Epoch [6/300], Train Loss: 0.000982
Validation Loss: 0.00100409
Epoch [7/300], Train Loss: 0.000982
Validation Loss: 0.00100300
Epoch [8/300], Train Loss: 0.000981
Validation Loss: 0.00100074
Epoch [9/300], Train Loss: 0.000977
Validation Loss: 0.00099665
Epoch [10/300], Train Loss: 0.000973
Validation Loss: 0.00099335
Epoch [11/300], Train Loss: 0.000970
Validation Loss: 0.00098871
Epoch [12/300], Train Loss: 0.000963
Validation Loss: 0.00097735
Epoch [13/300], Train Loss: 0.000951
Validation Loss: 0.00096087
Epoch [14/300], Train Loss: 0.000930
Validation Loss: 0.00093824
Epoch [15/300], Train Loss: 0.000901
Validation Loss: 0.00090547
Epoch [16/300], Train Loss: 0.000861
Validation Loss: 0.00086326
Epoch [17/300], Train Loss: 0.000818
Validation Loss: 0.00082432
Epoch [18/300], Train Loss: 0.000780
Validation Loss: 0.00078490
Epoch [19/300], Train Loss: 0.000752
Validation Loss: 0.00076273
Epoch [20/300], Train Loss: 0.000721
Validation Loss: 0.00074018
Epoch [21/300], Train Loss: 0.000703
Validation Loss: 0.00071175
Epoch [22/300], Train Loss: 0.000680
Validation Loss: 0.00070308
Epoch [23/300], Train Loss: 0.000658
Validation Loss: 0.00069191
Epoch [24/300], Train Loss: 0.000659
Validation Loss: 0.00071139
Epoch [25/300], Train Loss: 0.000637
Validation Loss: 0.00065001
Epoch [26/300], Train Loss: 0.000627
Validation Loss: 0.00066557
Epoch [27/300], Train Loss: 0.000607
Validation Loss: 0.00062326
Epoch [28/300], Train Loss: 0.000591
Validation Loss: 0.00062119
Epoch [29/300], Train Loss: 0.000611
Validation Loss: 0.00062261
Epoch [30/300], Train Loss: 0.000593
Validation Loss: 0.00060350
Epoch [31/300], Train Loss: 0.000580
Validation Loss: 0.00060599
Epoch [32/300], Train Loss: 0.000566
Validation Loss: 0.00057333
Epoch [33/300], Train Loss: 0.000558
Validation Loss: 0.00057716
Epoch [34/300], Train Loss: 0.000550
Validation Loss: 0.00055116
Epoch [35/300], Train Loss: 0.000554
Validation Loss: 0.00059584
Epoch [36/300], Train Loss: 0.000541
Validation Loss: 0.00055086
Epoch [37/300], Train Loss: 0.000536
Validation Loss: 0.00059761
Epoch [38/300], Train Loss: 0.000531
Validation Loss: 0.00054410
Epoch [39/300], Train Loss: 0.000525
Validation Loss: 0.00052094
Epoch [40/300], Train Loss: 0.000518
Validation Loss: 0.00052498
Epoch [41/300], Train Loss: 0.000506
Validation Loss: 0.00051019
Epoch [42/300], Train Loss: 0.000504
Validation Loss: 0.00052154
Epoch [43/300], Train Loss: 0.000509
Validation Loss: 0.00050129
Epoch [44/300], Train Loss: 0.000518
Validation Loss: 0.00052763
Epoch [45/300], Train Loss: 0.000499
Validation Loss: 0.00049779
Epoch [46/300], Train Loss: 0.000478
Validation Loss: 0.00048847
Epoch [47/300], Train Loss: 0.000476
Validation Loss: 0.00047217
Epoch [48/300], Train Loss: 0.000476
Validation Loss: 0.00049216
Epoch [49/300], Train Loss: 0.000493
Validation Loss: 0.00050576
Epoch [50/300], Train Loss: 0.000477
Validation Loss: 0.00046948
Epoch [51/300], Train Loss: 0.000468
Validation Loss: 0.00046689
Epoch [52/300], Train Loss: 0.000461
Validation Loss: 0.00045217
Epoch [53/300], Train Loss: 0.000449
Validation Loss: 0.00044396
Epoch [54/300], Train Loss: 0.000450
Validation Loss: 0.00044646
Epoch [55/300], Train Loss: 0.000444
Validation Loss: 0.00046686
Epoch [56/300], Train Loss: 0.000433
Validation Loss: 0.00042269
Epoch [57/300], Train Loss: 0.000422
Validation Loss: 0.00042439
Epoch [58/300], Train Loss: 0.000417
Validation Loss: 0.00041974
Epoch [59/300], Train Loss: 0.000421
Validation Loss: 0.00043372
Epoch [60/300], Train Loss: 0.000408
Validation Loss: 0.00040355
Epoch [61/300], Train Loss: 0.000412
Validation Loss: 0.00041276
Epoch [62/300], Train Loss: 0.000393
Validation Loss: 0.00041111
Epoch [63/300], Train Loss: 0.000390
Validation Loss: 0.00039299
Epoch [64/300], Train Loss: 0.000372
Validation Loss: 0.00036500
Epoch [65/300], Train Loss: 0.000350
Validation Loss: 0.00035821
Epoch [66/300], Train Loss: 0.000342
Validation Loss: 0.00034599
Epoch [67/300], Train Loss: 0.000328
Validation Loss: 0.00033351
Epoch [68/300], Train Loss: 0.000331
Validation Loss: 0.00036281
Epoch [69/300], Train Loss: 0.000337
Validation Loss: 0.00033393
Epoch [70/300], Train Loss: 0.000315
Validation Loss: 0.00031900
Epoch [71/300], Train Loss: 0.000314
Validation Loss: 0.00031358
Epoch [72/300], Train Loss: 0.000311
Validation Loss: 0.00031814
Epoch [73/300], Train Loss: 0.000310
Validation Loss: 0.00031885
Epoch [74/300], Train Loss: 0.000300
Validation Loss: 0.00031336
Epoch [75/300], Train Loss: 0.000293
Validation Loss: 0.00029369
Epoch [76/300], Train Loss: 0.000337
Validation Loss: 0.00033725
Epoch [77/300], Train Loss: 0.000324
Validation Loss: 0.00032245
Epoch [78/300], Train Loss: 0.000311
Validation Loss: 0.00031137
Epoch [79/300], Train Loss: 0.000301
Validation Loss: 0.00031388
Epoch [80/300], Train Loss: 0.000290
Validation Loss: 0.00029795
Epoch [81/300], Train Loss: 0.000427
Validation Loss: 0.00038958
Epoch [82/300], Train Loss: 0.000350
Validation Loss: 0.00032661
Epoch [83/300], Train Loss: 0.000315
Validation Loss: 0.00031238
Epoch [84/300], Train Loss: 0.000301
Validation Loss: 0.00030533
Epoch [85/300], Train Loss: 0.000297
Validation Loss: 0.00030675
Early stopping triggered

Evaluating model for: Coffee Machine
Run 43/72 completed in 1560.70 seconds with: {'MAE': np.float32(4.2804027), 'MSE': np.float32(1450.8441), 'RMSE': np.float32(38.089947), 'SAE': np.float32(0.19113238), 'NDE': np.float32(0.58672905)}

Run 44/72: hidden=256, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Coffee Machine
Dataset length: 5916 windows

Epoch [1/300], Train Loss: 0.001397
Validation Loss: 0.00102131
Epoch [2/300], Train Loss: 0.000998
Validation Loss: 0.00100957
Epoch [3/300], Train Loss: 0.000995
Validation Loss: 0.00100918
Epoch [4/300], Train Loss: 0.000995
Validation Loss: 0.00100914
Epoch [5/300], Train Loss: 0.000994
Validation Loss: 0.00100905
Epoch [6/300], Train Loss: 0.000993
Validation Loss: 0.00100897
Epoch [7/300], Train Loss: 0.000993
Validation Loss: 0.00100883
Epoch [8/300], Train Loss: 0.000993
Validation Loss: 0.00100871
Epoch [9/300], Train Loss: 0.000991
Validation Loss: 0.00100869
Epoch [10/300], Train Loss: 0.000991
Validation Loss: 0.00100848
Epoch [11/300], Train Loss: 0.000991
Validation Loss: 0.00100835
Epoch [12/300], Train Loss: 0.000990
Validation Loss: 0.00100846
Epoch [13/300], Train Loss: 0.000990
Validation Loss: 0.00100831
Epoch [14/300], Train Loss: 0.000989
Validation Loss: 0.00100798
Epoch [15/300], Train Loss: 0.000989
Validation Loss: 0.00100802
Epoch [16/300], Train Loss: 0.000988
Validation Loss: 0.00100775
Epoch [17/300], Train Loss: 0.000987
Validation Loss: 0.00100779
Epoch [18/300], Train Loss: 0.000988
Validation Loss: 0.00100760
Epoch [19/300], Train Loss: 0.000987
Validation Loss: 0.00100750
Epoch [20/300], Train Loss: 0.000987
Validation Loss: 0.00100756
Epoch [21/300], Train Loss: 0.000987
Validation Loss: 0.00100726
Epoch [22/300], Train Loss: 0.000987
Validation Loss: 0.00100688
Epoch [23/300], Train Loss: 0.000986
Validation Loss: 0.00100656
Epoch [24/300], Train Loss: 0.000986
Validation Loss: 0.00100672
Epoch [25/300], Train Loss: 0.000986
Validation Loss: 0.00100589
Epoch [26/300], Train Loss: 0.000985
Validation Loss: 0.00100586
Epoch [27/300], Train Loss: 0.000985
Validation Loss: 0.00100500
Epoch [28/300], Train Loss: 0.000984
Validation Loss: 0.00100475
Epoch [29/300], Train Loss: 0.000984
Validation Loss: 0.00100401
Epoch [30/300], Train Loss: 0.000984
Validation Loss: 0.00100336
Epoch [31/300], Train Loss: 0.000983
Validation Loss: 0.00100242
Epoch [32/300], Train Loss: 0.000982
Validation Loss: 0.00100180
Epoch [33/300], Train Loss: 0.000980
Validation Loss: 0.00100049
Epoch [34/300], Train Loss: 0.000979
Validation Loss: 0.00099805
Epoch [35/300], Train Loss: 0.000977
Validation Loss: 0.00099543
Epoch [36/300], Train Loss: 0.000974
Validation Loss: 0.00099127
Epoch [37/300], Train Loss: 0.000968
Validation Loss: 0.00098425
Epoch [38/300], Train Loss: 0.000961
Validation Loss: 0.00097667
Epoch [39/300], Train Loss: 0.000952
Validation Loss: 0.00096472
Epoch [40/300], Train Loss: 0.000939
Validation Loss: 0.00095092
Epoch [41/300], Train Loss: 0.000921
Validation Loss: 0.00092583
Epoch [42/300], Train Loss: 0.000892
Validation Loss: 0.00089326
Epoch [43/300], Train Loss: 0.000853
Validation Loss: 0.00084860
Epoch [44/300], Train Loss: 0.000811
Validation Loss: 0.00081307
Epoch [45/300], Train Loss: 0.000769
Validation Loss: 0.00076987
Epoch [46/300], Train Loss: 0.000751
Validation Loss: 0.00075169
Epoch [47/300], Train Loss: 0.000720
Validation Loss: 0.00073985
Epoch [48/300], Train Loss: 0.000705
Validation Loss: 0.00070300
Epoch [49/300], Train Loss: 0.000679
Validation Loss: 0.00067185
Epoch [50/300], Train Loss: 0.000663
Validation Loss: 0.00065188
Epoch [51/300], Train Loss: 0.000658
Validation Loss: 0.00064073
Epoch [52/300], Train Loss: 0.000630
Validation Loss: 0.00062636
Epoch [53/300], Train Loss: 0.000657
Validation Loss: 0.00073932
Epoch [54/300], Train Loss: 0.000693
Validation Loss: 0.00069098
Epoch [55/300], Train Loss: 0.000640
Validation Loss: 0.00065445
Epoch [56/300], Train Loss: 0.000625
Validation Loss: 0.00062085
Epoch [57/300], Train Loss: 0.000607
Validation Loss: 0.00062515
Epoch [58/300], Train Loss: 0.000605
Validation Loss: 0.00059900
Epoch [59/300], Train Loss: 0.000572
Validation Loss: 0.00057848
Epoch [60/300], Train Loss: 0.000563
Validation Loss: 0.00054860
Epoch [61/300], Train Loss: 0.000540
Validation Loss: 0.00054654
Epoch [62/300], Train Loss: 0.000531
Validation Loss: 0.00050331
Epoch [63/300], Train Loss: 0.000509
Validation Loss: 0.00049270
Epoch [64/300], Train Loss: 0.000487
Validation Loss: 0.00044230
Epoch [65/300], Train Loss: 0.000447
Validation Loss: 0.00042001
Epoch [66/300], Train Loss: 0.000426
Validation Loss: 0.00039709
Epoch [67/300], Train Loss: 0.000403
Validation Loss: 0.00038136
Epoch [68/300], Train Loss: 0.000398
Validation Loss: 0.00037167
Epoch [69/300], Train Loss: 0.000444
Validation Loss: 0.00050825
Epoch [70/300], Train Loss: 0.000467
Validation Loss: 0.00043698
Epoch [71/300], Train Loss: 0.000404
Validation Loss: 0.00036238
Epoch [72/300], Train Loss: 0.000370
Validation Loss: 0.00036485
Epoch [73/300], Train Loss: 0.000363
Validation Loss: 0.00033136
Epoch [74/300], Train Loss: 0.000360
Validation Loss: 0.00031929
Epoch [75/300], Train Loss: 0.000339
Validation Loss: 0.00032127
Epoch [76/300], Train Loss: 0.000328
Validation Loss: 0.00031348
Epoch [77/300], Train Loss: 0.000338
Validation Loss: 0.00037295
Epoch [78/300], Train Loss: 0.000333
Validation Loss: 0.00030967
Epoch [79/300], Train Loss: 0.000318
Validation Loss: 0.00029695
Epoch [80/300], Train Loss: 0.000313
Validation Loss: 0.00030361
Epoch [81/300], Train Loss: 0.000303
Validation Loss: 0.00030296
Epoch [82/300], Train Loss: 0.000314
Validation Loss: 0.00030266
Epoch [83/300], Train Loss: 0.000313
Validation Loss: 0.00029352
Epoch [84/300], Train Loss: 0.000303
Validation Loss: 0.00029810
Epoch [85/300], Train Loss: 0.000305
Validation Loss: 0.00029134
Epoch [86/300], Train Loss: 0.000292
Validation Loss: 0.00029101
Epoch [87/300], Train Loss: 0.000292
Validation Loss: 0.00030602
Epoch [88/300], Train Loss: 0.000298
Validation Loss: 0.00028521
Epoch [89/300], Train Loss: 0.000294
Validation Loss: 0.00027939
Epoch [90/300], Train Loss: 0.000290
Validation Loss: 0.00029997
Epoch [91/300], Train Loss: 0.000284
Validation Loss: 0.00027915
Epoch [92/300], Train Loss: 0.000282
Validation Loss: 0.00027006
Epoch [93/300], Train Loss: 0.000289
Validation Loss: 0.00028173
Epoch [94/300], Train Loss: 0.000275
Validation Loss: 0.00026615
Epoch [95/300], Train Loss: 0.000267
Validation Loss: 0.00027817
Epoch [96/300], Train Loss: 0.000271
Validation Loss: 0.00026244
Epoch [97/300], Train Loss: 0.000270
Validation Loss: 0.00026043
Epoch [98/300], Train Loss: 0.000264
Validation Loss: 0.00027126
Epoch [99/300], Train Loss: 0.000263
Validation Loss: 0.00025737
Epoch [100/300], Train Loss: 0.000263
Validation Loss: 0.00026264
Epoch [101/300], Train Loss: 0.000262
Validation Loss: 0.00025682
Epoch [102/300], Train Loss: 0.000259
Validation Loss: 0.00026184
Epoch [103/300], Train Loss: 0.000270
Validation Loss: 0.00030996
Epoch [104/300], Train Loss: 0.000280
Validation Loss: 0.00026050
Epoch [105/300], Train Loss: 0.000264
Validation Loss: 0.00025725
Epoch [106/300], Train Loss: 0.000253
Validation Loss: 0.00025498
Epoch [107/300], Train Loss: 0.000246
Validation Loss: 0.00025300
Epoch [108/300], Train Loss: 0.000258
Validation Loss: 0.00024637
Epoch [109/300], Train Loss: 0.000248
Validation Loss: 0.00024378
Epoch [110/300], Train Loss: 0.000246
Validation Loss: 0.00027226
Epoch [111/300], Train Loss: 0.000245
Validation Loss: 0.00024861
Epoch [112/300], Train Loss: 0.000247
Validation Loss: 0.00024014
Epoch [113/300], Train Loss: 0.000242
Validation Loss: 0.00025259
Epoch [114/300], Train Loss: 0.000242
Validation Loss: 0.00024586
Epoch [115/300], Train Loss: 0.000246
Validation Loss: 0.00024425
Epoch [116/300], Train Loss: 0.000242
Validation Loss: 0.00024036
Epoch [117/300], Train Loss: 0.000238
Validation Loss: 0.00025610
Epoch [118/300], Train Loss: 0.000244
Validation Loss: 0.00026833
Epoch [119/300], Train Loss: 0.000238
Validation Loss: 0.00023780
Epoch [120/300], Train Loss: 0.000233
Validation Loss: 0.00022945
Epoch [121/300], Train Loss: 0.000232
Validation Loss: 0.00023277
Epoch [122/300], Train Loss: 0.000228
Validation Loss: 0.00023235
Epoch [123/300], Train Loss: 0.000228
Validation Loss: 0.00022796
Epoch [124/300], Train Loss: 0.000226
Validation Loss: 0.00023428
Epoch [125/300], Train Loss: 0.000226
Validation Loss: 0.00022663
Epoch [126/300], Train Loss: 0.000225
Validation Loss: 0.00023574
Epoch [127/300], Train Loss: 0.000222
Validation Loss: 0.00022094
Epoch [128/300], Train Loss: 0.000219
Validation Loss: 0.00022269
Epoch [129/300], Train Loss: 0.000218
Validation Loss: 0.00022161
Epoch [130/300], Train Loss: 0.000218
Validation Loss: 0.00021661
Epoch [131/300], Train Loss: 0.000218
Validation Loss: 0.00022856
Epoch [132/300], Train Loss: 0.000220
Validation Loss: 0.00022651
Epoch [133/300], Train Loss: 0.000218
Validation Loss: 0.00021538
Epoch [134/300], Train Loss: 0.000217
Validation Loss: 0.00021467
Epoch [135/300], Train Loss: 0.000214
Validation Loss: 0.00021237
Epoch [136/300], Train Loss: 0.000211
Validation Loss: 0.00021036
Epoch [137/300], Train Loss: 0.000212
Validation Loss: 0.00020920
Epoch [138/300], Train Loss: 0.000209
Validation Loss: 0.00020963
Epoch [139/300], Train Loss: 0.000210
Validation Loss: 0.00020928
Epoch [140/300], Train Loss: 0.000228
Validation Loss: 0.00023672
Epoch [141/300], Train Loss: 0.000223
Validation Loss: 0.00020804
Epoch [142/300], Train Loss: 0.000211
Validation Loss: 0.00022139
Epoch [143/300], Train Loss: 0.000228
Validation Loss: 0.00023001
Epoch [144/300], Train Loss: 0.000218
Validation Loss: 0.00020204
Epoch [145/300], Train Loss: 0.000206
Validation Loss: 0.00020555
Epoch [146/300], Train Loss: 0.000206
Validation Loss: 0.00020612
Epoch [147/300], Train Loss: 0.000204
Validation Loss: 0.00020288
Epoch [148/300], Train Loss: 0.000202
Validation Loss: 0.00020465
Epoch [149/300], Train Loss: 0.000200
Validation Loss: 0.00019965
Epoch [150/300], Train Loss: 0.000200
Validation Loss: 0.00019884
Epoch [151/300], Train Loss: 0.000199
Validation Loss: 0.00020250
Epoch [152/300], Train Loss: 0.000195
Validation Loss: 0.00019701
Epoch [153/300], Train Loss: 0.000196
Validation Loss: 0.00020156
Epoch [154/300], Train Loss: 0.000197
Validation Loss: 0.00020532
Epoch [155/300], Train Loss: 0.000204
Validation Loss: 0.00019697
Epoch [156/300], Train Loss: 0.000197
Validation Loss: 0.00019663
Epoch [157/300], Train Loss: 0.000195
Validation Loss: 0.00019966
Epoch [158/300], Train Loss: 0.000189
Validation Loss: 0.00019373
Epoch [159/300], Train Loss: 0.000190
Validation Loss: 0.00019343
Epoch [160/300], Train Loss: 0.000192
Validation Loss: 0.00019159
Epoch [161/300], Train Loss: 0.000186
Validation Loss: 0.00019254
Epoch [162/300], Train Loss: 0.000189
Validation Loss: 0.00019285
Epoch [163/300], Train Loss: 0.000189
Validation Loss: 0.00019124
Epoch [164/300], Train Loss: 0.000188
Validation Loss: 0.00018617
Epoch [165/300], Train Loss: 0.000184
Validation Loss: 0.00018824
Epoch [166/300], Train Loss: 0.000190
Validation Loss: 0.00019121
Epoch [167/300], Train Loss: 0.000181
Validation Loss: 0.00018467
Epoch [168/300], Train Loss: 0.000182
Validation Loss: 0.00018270
Epoch [169/300], Train Loss: 0.000182
Validation Loss: 0.00018503
Epoch [170/300], Train Loss: 0.000183
Validation Loss: 0.00018606
Epoch [171/300], Train Loss: 0.000182
Validation Loss: 0.00018526
Epoch [172/300], Train Loss: 0.000179
Validation Loss: 0.00018131
Epoch [173/300], Train Loss: 0.000178
Validation Loss: 0.00018003
Epoch [174/300], Train Loss: 0.000179
Validation Loss: 0.00018283
Epoch [175/300], Train Loss: 0.000179
Validation Loss: 0.00018265
Epoch [176/300], Train Loss: 0.000181
Validation Loss: 0.00018359
Epoch [177/300], Train Loss: 0.000179
Validation Loss: 0.00018633
Epoch [178/300], Train Loss: 0.000176
Validation Loss: 0.00017696
Epoch [179/300], Train Loss: 0.000175
Validation Loss: 0.00018178
Epoch [180/300], Train Loss: 0.000178
Validation Loss: 0.00017649
Epoch [181/300], Train Loss: 0.000173
Validation Loss: 0.00017824
Epoch [182/300], Train Loss: 0.000178
Validation Loss: 0.00018651
Epoch [183/300], Train Loss: 0.000175
Validation Loss: 0.00018196
Epoch [184/300], Train Loss: 0.000175
Validation Loss: 0.00017715
Epoch [185/300], Train Loss: 0.000173
Validation Loss: 0.00018194
Epoch [186/300], Train Loss: 0.000174
Validation Loss: 0.00017442
Epoch [187/300], Train Loss: 0.000171
Validation Loss: 0.00017271
Epoch [188/300], Train Loss: 0.000169
Validation Loss: 0.00017293
Epoch [189/300], Train Loss: 0.000169
Validation Loss: 0.00017252
Epoch [190/300], Train Loss: 0.000168
Validation Loss: 0.00017243
Epoch [191/300], Train Loss: 0.000171
Validation Loss: 0.00017362
Epoch [192/300], Train Loss: 0.000168
Validation Loss: 0.00017174
Epoch [193/300], Train Loss: 0.000168
Validation Loss: 0.00017570
Epoch [194/300], Train Loss: 0.000172
Validation Loss: 0.00017408
Epoch [195/300], Train Loss: 0.000168
Validation Loss: 0.00017024
Epoch [196/300], Train Loss: 0.000165
Validation Loss: 0.00016935
Epoch [197/300], Train Loss: 0.000166
Validation Loss: 0.00016787
Epoch [198/300], Train Loss: 0.000164
Validation Loss: 0.00016828
Epoch [199/300], Train Loss: 0.000166
Validation Loss: 0.00016725
Epoch [200/300], Train Loss: 0.000166
Validation Loss: 0.00017062
Epoch [201/300], Train Loss: 0.000170
Validation Loss: 0.00017195
Epoch [202/300], Train Loss: 0.000165
Validation Loss: 0.00016980
Epoch [203/300], Train Loss: 0.000165
Validation Loss: 0.00017450
Epoch [204/300], Train Loss: 0.000165
Validation Loss: 0.00016805
Epoch [205/300], Train Loss: 0.000163
Validation Loss: 0.00016337
Epoch [206/300], Train Loss: 0.000163
Validation Loss: 0.00016579
Epoch [207/300], Train Loss: 0.000160
Validation Loss: 0.00016456
Epoch [208/300], Train Loss: 0.000161
Validation Loss: 0.00016135
Epoch [209/300], Train Loss: 0.000161
Validation Loss: 0.00016070
Epoch [210/300], Train Loss: 0.000159
Validation Loss: 0.00016035
Epoch [211/300], Train Loss: 0.000158
Validation Loss: 0.00016180
Epoch [212/300], Train Loss: 0.000161
Validation Loss: 0.00017265
Epoch [213/300], Train Loss: 0.000168
Validation Loss: 0.00016417
Epoch [214/300], Train Loss: 0.000157
Validation Loss: 0.00016041
Epoch [215/300], Train Loss: 0.000159
Validation Loss: 0.00015614
Epoch [216/300], Train Loss: 0.000157
Validation Loss: 0.00015777
Epoch [217/300], Train Loss: 0.000155
Validation Loss: 0.00015654
Epoch [218/300], Train Loss: 0.000156
Validation Loss: 0.00015496
Epoch [219/300], Train Loss: 0.000156
Validation Loss: 0.00015655
Epoch [220/300], Train Loss: 0.000156
Validation Loss: 0.00015248
Epoch [221/300], Train Loss: 0.000157
Validation Loss: 0.00015676
Epoch [222/300], Train Loss: 0.000157
Validation Loss: 0.00016043
Epoch [223/300], Train Loss: 0.000157
Validation Loss: 0.00015424
Epoch [224/300], Train Loss: 0.000156
Validation Loss: 0.00015294
Epoch [225/300], Train Loss: 0.000153
Validation Loss: 0.00015262
Epoch [226/300], Train Loss: 0.000152
Validation Loss: 0.00015032
Epoch [227/300], Train Loss: 0.000153
Validation Loss: 0.00015405
Epoch [228/300], Train Loss: 0.000151
Validation Loss: 0.00014870
Epoch [229/300], Train Loss: 0.000156
Validation Loss: 0.00015610
Epoch [230/300], Train Loss: 0.000153
Validation Loss: 0.00014811
Epoch [231/300], Train Loss: 0.000157
Validation Loss: 0.00015583
Epoch [232/300], Train Loss: 0.000155
Validation Loss: 0.00015282
Epoch [233/300], Train Loss: 0.000151
Validation Loss: 0.00014684
Epoch [234/300], Train Loss: 0.000151
Validation Loss: 0.00014914
Epoch [235/300], Train Loss: 0.000180
Validation Loss: 0.00015925
Epoch [236/300], Train Loss: 0.000151
Validation Loss: 0.00015084
Epoch [237/300], Train Loss: 0.000148
Validation Loss: 0.00014596
Epoch [238/300], Train Loss: 0.000148
Validation Loss: 0.00014842
Epoch [239/300], Train Loss: 0.000149
Validation Loss: 0.00014481
Epoch [240/300], Train Loss: 0.000147
Validation Loss: 0.00014623
Epoch [241/300], Train Loss: 0.000147
Validation Loss: 0.00014460
Epoch [242/300], Train Loss: 0.000146
Validation Loss: 0.00014456
Epoch [243/300], Train Loss: 0.000150
Validation Loss: 0.00014546
Epoch [244/300], Train Loss: 0.000146
Validation Loss: 0.00014255
Epoch [245/300], Train Loss: 0.000150
Validation Loss: 0.00016163
Epoch [246/300], Train Loss: 0.000154
Validation Loss: 0.00015169
Epoch [247/300], Train Loss: 0.000151
Validation Loss: 0.00014629
Epoch [248/300], Train Loss: 0.000147
Validation Loss: 0.00014467
Epoch [249/300], Train Loss: 0.000145
Validation Loss: 0.00014191
Epoch [250/300], Train Loss: 0.000147
Validation Loss: 0.00014353
Epoch [251/300], Train Loss: 0.000144
Validation Loss: 0.00014182
Epoch [252/300], Train Loss: 0.000143
Validation Loss: 0.00014227
Epoch [253/300], Train Loss: 0.000143
Validation Loss: 0.00014171
Epoch [254/300], Train Loss: 0.000143
Validation Loss: 0.00013828
Epoch [255/300], Train Loss: 0.000142
Validation Loss: 0.00013709
Epoch [256/300], Train Loss: 0.000142
Validation Loss: 0.00014072
Epoch [257/300], Train Loss: 0.000142
Validation Loss: 0.00013783
Epoch [258/300], Train Loss: 0.000142
Validation Loss: 0.00013793
Epoch [259/300], Train Loss: 0.000142
Validation Loss: 0.00013793
Epoch [260/300], Train Loss: 0.000140
Validation Loss: 0.00013764
Epoch [261/300], Train Loss: 0.000141
Validation Loss: 0.00013523
Epoch [262/300], Train Loss: 0.000139
Validation Loss: 0.00013694
Epoch [263/300], Train Loss: 0.000139
Validation Loss: 0.00013876
Epoch [264/300], Train Loss: 0.000140
Validation Loss: 0.00013518
Epoch [265/300], Train Loss: 0.000140
Validation Loss: 0.00014746
Epoch [266/300], Train Loss: 0.000140
Validation Loss: 0.00013559
Epoch [267/300], Train Loss: 0.000139
Validation Loss: 0.00013429
Epoch [268/300], Train Loss: 0.000138
Validation Loss: 0.00013500
Epoch [269/300], Train Loss: 0.000141
Validation Loss: 0.00013779
Epoch [270/300], Train Loss: 0.000140
Validation Loss: 0.00013336
Epoch [271/300], Train Loss: 0.000138
Validation Loss: 0.00013420
Epoch [272/300], Train Loss: 0.000138
Validation Loss: 0.00015291
Epoch [273/300], Train Loss: 0.000162
Validation Loss: 0.00014553
Epoch [274/300], Train Loss: 0.000145
Validation Loss: 0.00013847
Epoch [275/300], Train Loss: 0.000142
Validation Loss: 0.00013330
Epoch [276/300], Train Loss: 0.000140
Validation Loss: 0.00013202
Epoch [277/300], Train Loss: 0.000140
Validation Loss: 0.00013153
Epoch [278/300], Train Loss: 0.000140
Validation Loss: 0.00013429
Epoch [279/300], Train Loss: 0.000137
Validation Loss: 0.00013382
Epoch [280/300], Train Loss: 0.000139
Validation Loss: 0.00013193
Epoch [281/300], Train Loss: 0.000137
Validation Loss: 0.00013457
Epoch [282/300], Train Loss: 0.000137
Validation Loss: 0.00013090
Epoch [283/300], Train Loss: 0.000136
Validation Loss: 0.00013091
Epoch [284/300], Train Loss: 0.000135
Validation Loss: 0.00013113
Epoch [285/300], Train Loss: 0.000136
Validation Loss: 0.00013321
Epoch [286/300], Train Loss: 0.000135
Validation Loss: 0.00013121
Epoch [287/300], Train Loss: 0.000134
Validation Loss: 0.00013039
Epoch [288/300], Train Loss: 0.000133
Validation Loss: 0.00013271
Epoch [289/300], Train Loss: 0.000135
Validation Loss: 0.00013149
Epoch [290/300], Train Loss: 0.000133
Validation Loss: 0.00012961
Epoch [291/300], Train Loss: 0.000132
Validation Loss: 0.00012942
Epoch [292/300], Train Loss: 0.000132
Validation Loss: 0.00013137
Epoch [293/300], Train Loss: 0.000133
Validation Loss: 0.00013095
Epoch [294/300], Train Loss: 0.000132
Validation Loss: 0.00012876
Epoch [295/300], Train Loss: 0.000141
Validation Loss: 0.00013217
Epoch [296/300], Train Loss: 0.000133
Validation Loss: 0.00013254
Epoch [297/300], Train Loss: 0.000132
Validation Loss: 0.00013484
Epoch [298/300], Train Loss: 0.000132
Validation Loss: 0.00013042
Epoch [299/300], Train Loss: 0.000134
Validation Loss: 0.00013248
Epoch [300/300], Train Loss: 0.000135
Validation Loss: 0.00013481

Evaluating model for: Coffee Machine
Run 44/72 completed in 7324.45 seconds with: {'MAE': np.float32(3.2176478), 'MSE': np.float32(777.618), 'RMSE': np.float32(27.885803), 'SAE': np.float32(0.022654904), 'NDE': np.float32(0.4295475)}

Run 45/72: hidden=256, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Coffee Machine
Dataset length: 2980 windows

Epoch [1/300], Train Loss: 0.001148
Validation Loss: 0.00095531
Epoch [2/300], Train Loss: 0.000983
Validation Loss: 0.00091979
Epoch [3/300], Train Loss: 0.000983
Validation Loss: 0.00091738
Epoch [4/300], Train Loss: 0.000983
Validation Loss: 0.00091706
Epoch [5/300], Train Loss: 0.000984
Validation Loss: 0.00091669
Epoch [6/300], Train Loss: 0.000981
Validation Loss: 0.00091634
Epoch [7/300], Train Loss: 0.000981
Validation Loss: 0.00091614
Epoch [8/300], Train Loss: 0.000985
Validation Loss: 0.00091582
Epoch [9/300], Train Loss: 0.000989
Validation Loss: 0.00091549
Epoch [10/300], Train Loss: 0.000989
Validation Loss: 0.00091491
Epoch [11/300], Train Loss: 0.000971
Validation Loss: 0.00091446
Epoch [12/300], Train Loss: 0.000980
Validation Loss: 0.00091395
Epoch [13/300], Train Loss: 0.000982
Validation Loss: 0.00091336
Epoch [14/300], Train Loss: 0.000983
Validation Loss: 0.00091274
Epoch [15/300], Train Loss: 0.000969
Validation Loss: 0.00091254
Epoch [16/300], Train Loss: 0.000976
Validation Loss: 0.00091137
Epoch [17/300], Train Loss: 0.000982
Validation Loss: 0.00091072
Epoch [18/300], Train Loss: 0.000977
Validation Loss: 0.00091001
Epoch [19/300], Train Loss: 0.000978
Validation Loss: 0.00090918
Epoch [20/300], Train Loss: 0.000967
Validation Loss: 0.00090840
Epoch [21/300], Train Loss: 0.000977
Validation Loss: 0.00090796
Epoch [22/300], Train Loss: 0.000963
Validation Loss: 0.00090705
Epoch [23/300], Train Loss: 0.000976
Validation Loss: 0.00090643
Epoch [24/300], Train Loss: 0.000968
Validation Loss: 0.00090552
Epoch [25/300], Train Loss: 0.000970
Validation Loss: 0.00090474
Epoch [26/300], Train Loss: 0.000973
Validation Loss: 0.00090364
Epoch [27/300], Train Loss: 0.000970
Validation Loss: 0.00090238
Epoch [28/300], Train Loss: 0.000960
Validation Loss: 0.00090104
Epoch [29/300], Train Loss: 0.000967
Validation Loss: 0.00089905
Epoch [30/300], Train Loss: 0.000963
Validation Loss: 0.00089702
Epoch [31/300], Train Loss: 0.000958
Validation Loss: 0.00089489
Epoch [32/300], Train Loss: 0.000961
Validation Loss: 0.00089304
Epoch [33/300], Train Loss: 0.000960
Validation Loss: 0.00089185
Epoch [34/300], Train Loss: 0.000959
Validation Loss: 0.00088989
Epoch [35/300], Train Loss: 0.000952
Validation Loss: 0.00088800
Epoch [36/300], Train Loss: 0.000963
Validation Loss: 0.00088634
Epoch [37/300], Train Loss: 0.000969
Validation Loss: 0.00088575
Epoch [38/300], Train Loss: 0.000955
Validation Loss: 0.00088318
Epoch [39/300], Train Loss: 0.000956
Validation Loss: 0.00087969
Epoch [40/300], Train Loss: 0.000948
Validation Loss: 0.00087680
Epoch [41/300], Train Loss: 0.000951
Validation Loss: 0.00087409
Epoch [42/300], Train Loss: 0.000951
Validation Loss: 0.00086926
Epoch [43/300], Train Loss: 0.000945
Validation Loss: 0.00086440
Epoch [44/300], Train Loss: 0.000932
Validation Loss: 0.00085889
Epoch [45/300], Train Loss: 0.000923
Validation Loss: 0.00085333
Epoch [46/300], Train Loss: 0.000929
Validation Loss: 0.00084738
Epoch [47/300], Train Loss: 0.000925
Validation Loss: 0.00084152
Epoch [48/300], Train Loss: 0.000918
Validation Loss: 0.00083472
Epoch [49/300], Train Loss: 0.000910
Validation Loss: 0.00082820
Epoch [50/300], Train Loss: 0.000906
Validation Loss: 0.00081866
Epoch [51/300], Train Loss: 0.000903
Validation Loss: 0.00081145
Epoch [52/300], Train Loss: 0.000889
Validation Loss: 0.00080131
Epoch [53/300], Train Loss: 0.000882
Validation Loss: 0.00079075
Epoch [54/300], Train Loss: 0.000877
Validation Loss: 0.00077929
Epoch [55/300], Train Loss: 0.000861
Validation Loss: 0.00077233
Epoch [56/300], Train Loss: 0.000860
Validation Loss: 0.00076691
Epoch [57/300], Train Loss: 0.000854
Validation Loss: 0.00075104
Epoch [58/300], Train Loss: 0.000830
Validation Loss: 0.00074037
Epoch [59/300], Train Loss: 0.000823
Validation Loss: 0.00073113
Epoch [60/300], Train Loss: 0.000822
Validation Loss: 0.00072328
Epoch [61/300], Train Loss: 0.000806
Validation Loss: 0.00072406
Epoch [62/300], Train Loss: 0.000795
Validation Loss: 0.00070180
Epoch [63/300], Train Loss: 0.000786
Validation Loss: 0.00069275
Epoch [64/300], Train Loss: 0.000771
Validation Loss: 0.00068396
Epoch [65/300], Train Loss: 0.000775
Validation Loss: 0.00067611
Epoch [66/300], Train Loss: 0.000767
Validation Loss: 0.00066707
Epoch [67/300], Train Loss: 0.000755
Validation Loss: 0.00065961
Epoch [68/300], Train Loss: 0.000754
Validation Loss: 0.00065809
Epoch [69/300], Train Loss: 0.000746
Validation Loss: 0.00064797
Epoch [70/300], Train Loss: 0.000740
Validation Loss: 0.00064556
Epoch [71/300], Train Loss: 0.000727
Validation Loss: 0.00065836
Epoch [72/300], Train Loss: 0.000729
Validation Loss: 0.00063245
Epoch [73/300], Train Loss: 0.000717
Validation Loss: 0.00062315
Epoch [74/300], Train Loss: 0.000710
Validation Loss: 0.00063044
Epoch [75/300], Train Loss: 0.000713
Validation Loss: 0.00061434
Epoch [76/300], Train Loss: 0.000701
Validation Loss: 0.00061272
Epoch [77/300], Train Loss: 0.000702
Validation Loss: 0.00060876
Epoch [78/300], Train Loss: 0.000694
Validation Loss: 0.00061601
Epoch [79/300], Train Loss: 0.000699
Validation Loss: 0.00059946
Epoch [80/300], Train Loss: 0.000680
Validation Loss: 0.00059562
Epoch [81/300], Train Loss: 0.000682
Validation Loss: 0.00058742
Epoch [82/300], Train Loss: 0.000672
Validation Loss: 0.00058529
Epoch [83/300], Train Loss: 0.000673
Validation Loss: 0.00058514
Epoch [84/300], Train Loss: 0.000666
Validation Loss: 0.00057705
Epoch [85/300], Train Loss: 0.000681
Validation Loss: 0.00057456
Epoch [86/300], Train Loss: 0.000655
Validation Loss: 0.00056699
Epoch [87/300], Train Loss: 0.000664
Validation Loss: 0.00058073
Epoch [88/300], Train Loss: 0.000656
Validation Loss: 0.00057057
Epoch [89/300], Train Loss: 0.000646
Validation Loss: 0.00055227
Epoch [90/300], Train Loss: 0.000646
Validation Loss: 0.00054827
Epoch [91/300], Train Loss: 0.000639
Validation Loss: 0.00054965
Epoch [92/300], Train Loss: 0.000639
Validation Loss: 0.00054491
Epoch [93/300], Train Loss: 0.000633
Validation Loss: 0.00053911
Epoch [94/300], Train Loss: 0.000633
Validation Loss: 0.00053859
Epoch [95/300], Train Loss: 0.000626
Validation Loss: 0.00053941
Epoch [96/300], Train Loss: 0.000628
Validation Loss: 0.00053731
Epoch [97/300], Train Loss: 0.000617
Validation Loss: 0.00054657
Epoch [98/300], Train Loss: 0.000628
Validation Loss: 0.00053078
Epoch [99/300], Train Loss: 0.000623
Validation Loss: 0.00052431
Epoch [100/300], Train Loss: 0.000613
Validation Loss: 0.00052728
Epoch [101/300], Train Loss: 0.000618
Validation Loss: 0.00053145
Epoch [102/300], Train Loss: 0.000612
Validation Loss: 0.00051873
Epoch [103/300], Train Loss: 0.000607
Validation Loss: 0.00051806
Epoch [104/300], Train Loss: 0.000606
Validation Loss: 0.00051433
Epoch [105/300], Train Loss: 0.000596
Validation Loss: 0.00050835
Epoch [106/300], Train Loss: 0.000598
Validation Loss: 0.00051531
Epoch [107/300], Train Loss: 0.000596
Validation Loss: 0.00050434
Epoch [108/300], Train Loss: 0.000586
Validation Loss: 0.00050348
Epoch [109/300], Train Loss: 0.000589
Validation Loss: 0.00049918
Epoch [110/300], Train Loss: 0.000586
Validation Loss: 0.00051098
Epoch [111/300], Train Loss: 0.000590
Validation Loss: 0.00050523
Epoch [112/300], Train Loss: 0.000585
Validation Loss: 0.00050287
Epoch [113/300], Train Loss: 0.000583
Validation Loss: 0.00049249
Epoch [114/300], Train Loss: 0.000577
Validation Loss: 0.00050352
Epoch [115/300], Train Loss: 0.000595
Validation Loss: 0.00050650
Epoch [116/300], Train Loss: 0.000584
Validation Loss: 0.00049079
Epoch [117/300], Train Loss: 0.000574
Validation Loss: 0.00049602
Epoch [118/300], Train Loss: 0.000578
Validation Loss: 0.00048336
Epoch [119/300], Train Loss: 0.000567
Validation Loss: 0.00048475
Epoch [120/300], Train Loss: 0.000573
Validation Loss: 0.00048935
Epoch [121/300], Train Loss: 0.000569
Validation Loss: 0.00048553
Epoch [122/300], Train Loss: 0.000564
Validation Loss: 0.00048181
Epoch [123/300], Train Loss: 0.000564
Validation Loss: 0.00049681
Epoch [124/300], Train Loss: 0.000567
Validation Loss: 0.00047879
Epoch [125/300], Train Loss: 0.000552
Validation Loss: 0.00047618
Epoch [126/300], Train Loss: 0.000555
Validation Loss: 0.00047418
Epoch [127/300], Train Loss: 0.000555
Validation Loss: 0.00046987
Epoch [128/300], Train Loss: 0.000552
Validation Loss: 0.00047222
Epoch [129/300], Train Loss: 0.000553
Validation Loss: 0.00048425
Epoch [130/300], Train Loss: 0.000555
Validation Loss: 0.00048204
Epoch [131/300], Train Loss: 0.000556
Validation Loss: 0.00048291
Epoch [132/300], Train Loss: 0.000556
Validation Loss: 0.00046335
Epoch [133/300], Train Loss: 0.000547
Validation Loss: 0.00046631
Epoch [134/300], Train Loss: 0.000544
Validation Loss: 0.00046673
Epoch [135/300], Train Loss: 0.000544
Validation Loss: 0.00046148
Epoch [136/300], Train Loss: 0.000549
Validation Loss: 0.00046816
Epoch [137/300], Train Loss: 0.000545
Validation Loss: 0.00046143
Epoch [138/300], Train Loss: 0.000537
Validation Loss: 0.00046770
Epoch [139/300], Train Loss: 0.000548
Validation Loss: 0.00048874
Epoch [140/300], Train Loss: 0.000537
Validation Loss: 0.00046866
Epoch [141/300], Train Loss: 0.000537
Validation Loss: 0.00045803
Epoch [142/300], Train Loss: 0.000530
Validation Loss: 0.00046097
Epoch [143/300], Train Loss: 0.000533
Validation Loss: 0.00045836
Epoch [144/300], Train Loss: 0.000530
Validation Loss: 0.00045737
Epoch [145/300], Train Loss: 0.000529
Validation Loss: 0.00044997
Epoch [146/300], Train Loss: 0.000526
Validation Loss: 0.00045232
Epoch [147/300], Train Loss: 0.000529
Validation Loss: 0.00044734
Epoch [148/300], Train Loss: 0.000526
Validation Loss: 0.00045200
Epoch [149/300], Train Loss: 0.000519
Validation Loss: 0.00044767
Epoch [150/300], Train Loss: 0.000523
Validation Loss: 0.00044300
Epoch [151/300], Train Loss: 0.000525
Validation Loss: 0.00044743
Epoch [152/300], Train Loss: 0.000518
Validation Loss: 0.00044217
Epoch [153/300], Train Loss: 0.000515
Validation Loss: 0.00043898
Epoch [154/300], Train Loss: 0.000523
Validation Loss: 0.00044661
Epoch [155/300], Train Loss: 0.000516
Validation Loss: 0.00044462
Epoch [156/300], Train Loss: 0.000514
Validation Loss: 0.00043358
Epoch [157/300], Train Loss: 0.000515
Validation Loss: 0.00043817
Epoch [158/300], Train Loss: 0.000517
Validation Loss: 0.00043476
Epoch [159/300], Train Loss: 0.000515
Validation Loss: 0.00043278
Epoch [160/300], Train Loss: 0.000519
Validation Loss: 0.00043084
Epoch [161/300], Train Loss: 0.000513
Validation Loss: 0.00045090
Epoch [162/300], Train Loss: 0.000515
Validation Loss: 0.00043217
Epoch [163/300], Train Loss: 0.000506
Validation Loss: 0.00043076
Epoch [164/300], Train Loss: 0.000511
Validation Loss: 0.00042831
Epoch [165/300], Train Loss: 0.000503
Validation Loss: 0.00043017
Epoch [166/300], Train Loss: 0.000503
Validation Loss: 0.00042316
Epoch [167/300], Train Loss: 0.000502
Validation Loss: 0.00042518
Epoch [168/300], Train Loss: 0.000504
Validation Loss: 0.00042960
Epoch [169/300], Train Loss: 0.000501
Validation Loss: 0.00041744
Epoch [170/300], Train Loss: 0.000502
Validation Loss: 0.00042874
Epoch [171/300], Train Loss: 0.000505
Validation Loss: 0.00042631
Epoch [172/300], Train Loss: 0.000497
Validation Loss: 0.00042379
Epoch [173/300], Train Loss: 0.000496
Validation Loss: 0.00041627
Epoch [174/300], Train Loss: 0.000504
Validation Loss: 0.00041796
Epoch [175/300], Train Loss: 0.000496
Validation Loss: 0.00041538
Epoch [176/300], Train Loss: 0.000494
Validation Loss: 0.00042301
Epoch [177/300], Train Loss: 0.000505
Validation Loss: 0.00043375
Epoch [178/300], Train Loss: 0.000502
Validation Loss: 0.00042427
Epoch [179/300], Train Loss: 0.000489
Validation Loss: 0.00041331
Epoch [180/300], Train Loss: 0.000492
Validation Loss: 0.00040985
Epoch [181/300], Train Loss: 0.000485
Validation Loss: 0.00042073
Epoch [182/300], Train Loss: 0.000490
Validation Loss: 0.00041822
Epoch [183/300], Train Loss: 0.000491
Validation Loss: 0.00041250
Epoch [184/300], Train Loss: 0.000494
Validation Loss: 0.00040571
Epoch [185/300], Train Loss: 0.000488
Validation Loss: 0.00042111
Epoch [186/300], Train Loss: 0.000493
Validation Loss: 0.00041987
Epoch [187/300], Train Loss: 0.000483
Validation Loss: 0.00040452
Epoch [188/300], Train Loss: 0.000479
Validation Loss: 0.00040970
Epoch [189/300], Train Loss: 0.000482
Validation Loss: 0.00040704
Epoch [190/300], Train Loss: 0.000489
Validation Loss: 0.00040244
Epoch [191/300], Train Loss: 0.000479
Validation Loss: 0.00041138
Epoch [192/300], Train Loss: 0.000481
Validation Loss: 0.00040083
Epoch [193/300], Train Loss: 0.000478
Validation Loss: 0.00040215
Epoch [194/300], Train Loss: 0.000484
Validation Loss: 0.00040071
Epoch [195/300], Train Loss: 0.000482
Validation Loss: 0.00041129
Epoch [196/300], Train Loss: 0.000484
Validation Loss: 0.00041836
Epoch [197/300], Train Loss: 0.000482
Validation Loss: 0.00040362
Epoch [198/300], Train Loss: 0.000470
Validation Loss: 0.00039976
Epoch [199/300], Train Loss: 0.000469
Validation Loss: 0.00039811
Epoch [200/300], Train Loss: 0.000470
Validation Loss: 0.00039264
Epoch [201/300], Train Loss: 0.000470
Validation Loss: 0.00039855
Epoch [202/300], Train Loss: 0.000479
Validation Loss: 0.00039811
Epoch [203/300], Train Loss: 0.000468
Validation Loss: 0.00039543
Epoch [204/300], Train Loss: 0.000466
Validation Loss: 0.00039170
Epoch [205/300], Train Loss: 0.000471
Validation Loss: 0.00039581
Epoch [206/300], Train Loss: 0.000468
Validation Loss: 0.00039229
Epoch [207/300], Train Loss: 0.000471
Validation Loss: 0.00039012
Epoch [208/300], Train Loss: 0.000467
Validation Loss: 0.00039870
Epoch [209/300], Train Loss: 0.000465
Validation Loss: 0.00040672
Epoch [210/300], Train Loss: 0.000471
Validation Loss: 0.00039389
Epoch [211/300], Train Loss: 0.000468
Validation Loss: 0.00039436
Epoch [212/300], Train Loss: 0.000469
Validation Loss: 0.00039057
Epoch [213/300], Train Loss: 0.000474
Validation Loss: 0.00038699
Epoch [214/300], Train Loss: 0.000466
Validation Loss: 0.00039928
Epoch [215/300], Train Loss: 0.000466
Validation Loss: 0.00040742
Epoch [216/300], Train Loss: 0.000493
Validation Loss: 0.00040601
Epoch [217/300], Train Loss: 0.000468
Validation Loss: 0.00040399
Epoch [218/300], Train Loss: 0.000461
Validation Loss: 0.00039179
Epoch [219/300], Train Loss: 0.000464
Validation Loss: 0.00038540
Epoch [220/300], Train Loss: 0.000460
Validation Loss: 0.00039001
Epoch [221/300], Train Loss: 0.000463
Validation Loss: 0.00038984
Epoch [222/300], Train Loss: 0.000457
Validation Loss: 0.00038532
Epoch [223/300], Train Loss: 0.000469
Validation Loss: 0.00039017
Epoch [224/300], Train Loss: 0.000454
Validation Loss: 0.00038783
Epoch [225/300], Train Loss: 0.000458
Validation Loss: 0.00038480
Epoch [226/300], Train Loss: 0.000461
Validation Loss: 0.00038271
Epoch [227/300], Train Loss: 0.000456
Validation Loss: 0.00038636
Epoch [228/300], Train Loss: 0.000450
Validation Loss: 0.00038160
Epoch [229/300], Train Loss: 0.000454
Validation Loss: 0.00037991
Epoch [230/300], Train Loss: 0.000453
Validation Loss: 0.00038116
Epoch [231/300], Train Loss: 0.000454
Validation Loss: 0.00038058
Epoch [232/300], Train Loss: 0.000449
Validation Loss: 0.00038407
Epoch [233/300], Train Loss: 0.000454
Validation Loss: 0.00038261
Epoch [234/300], Train Loss: 0.000454
Validation Loss: 0.00038047
Epoch [235/300], Train Loss: 0.000451
Validation Loss: 0.00037875
Epoch [236/300], Train Loss: 0.000455
Validation Loss: 0.00037987
Epoch [237/300], Train Loss: 0.000451
Validation Loss: 0.00038142
Epoch [238/300], Train Loss: 0.000451
Validation Loss: 0.00037694
Epoch [239/300], Train Loss: 0.000456
Validation Loss: 0.00038652
Epoch [240/300], Train Loss: 0.000449
Validation Loss: 0.00038213
Epoch [241/300], Train Loss: 0.000450
Validation Loss: 0.00037669
Epoch [242/300], Train Loss: 0.000438
Validation Loss: 0.00037655
Epoch [243/300], Train Loss: 0.000443
Validation Loss: 0.00038016
Epoch [244/300], Train Loss: 0.000444
Validation Loss: 0.00037785
Epoch [245/300], Train Loss: 0.000451
Validation Loss: 0.00039554
Epoch [246/300], Train Loss: 0.000444
Validation Loss: 0.00037547
Epoch [247/300], Train Loss: 0.000442
Validation Loss: 0.00037538
Epoch [248/300], Train Loss: 0.000436
Validation Loss: 0.00037389
Epoch [249/300], Train Loss: 0.000439
Validation Loss: 0.00037609
Epoch [250/300], Train Loss: 0.000441
Validation Loss: 0.00037343
Epoch [251/300], Train Loss: 0.000443
Validation Loss: 0.00037982
Epoch [252/300], Train Loss: 0.000442
Validation Loss: 0.00037478
Epoch [253/300], Train Loss: 0.000473
Validation Loss: 0.00044787
Epoch [254/300], Train Loss: 0.000474
Validation Loss: 0.00040224
Epoch [255/300], Train Loss: 0.000450
Validation Loss: 0.00039486
Epoch [256/300], Train Loss: 0.000450
Validation Loss: 0.00038801
Epoch [257/300], Train Loss: 0.000442
Validation Loss: 0.00038093
Epoch [258/300], Train Loss: 0.000440
Validation Loss: 0.00037844
Epoch [259/300], Train Loss: 0.000438
Validation Loss: 0.00037556
Epoch [260/300], Train Loss: 0.000440
Validation Loss: 0.00037182
Epoch [261/300], Train Loss: 0.000434
Validation Loss: 0.00037128
Epoch [262/300], Train Loss: 0.000432
Validation Loss: 0.00037083
Epoch [263/300], Train Loss: 0.000431
Validation Loss: 0.00037153
Epoch [264/300], Train Loss: 0.000434
Validation Loss: 0.00037065
Epoch [265/300], Train Loss: 0.000439
Validation Loss: 0.00037079
Epoch [266/300], Train Loss: 0.000431
Validation Loss: 0.00037331
Epoch [267/300], Train Loss: 0.000434
Validation Loss: 0.00037746
Epoch [268/300], Train Loss: 0.000440
Validation Loss: 0.00036922
Epoch [269/300], Train Loss: 0.000431
Validation Loss: 0.00037811
Epoch [270/300], Train Loss: 0.000433
Validation Loss: 0.00037272
Epoch [271/300], Train Loss: 0.000433
Validation Loss: 0.00036924
Epoch [272/300], Train Loss: 0.000429
Validation Loss: 0.00037011
Epoch [273/300], Train Loss: 0.000427
Validation Loss: 0.00037087
Epoch [274/300], Train Loss: 0.000426
Validation Loss: 0.00037011
Epoch [275/300], Train Loss: 0.000436
Validation Loss: 0.00036623
Epoch [276/300], Train Loss: 0.000436
Validation Loss: 0.00036809
Epoch [277/300], Train Loss: 0.000429
Validation Loss: 0.00036969
Epoch [278/300], Train Loss: 0.000433
Validation Loss: 0.00036599
Epoch [279/300], Train Loss: 0.000428
Validation Loss: 0.00036841
Epoch [280/300], Train Loss: 0.000432
Validation Loss: 0.00036703
Epoch [281/300], Train Loss: 0.000430
Validation Loss: 0.00036661
Epoch [282/300], Train Loss: 0.000431
Validation Loss: 0.00036820
Epoch [283/300], Train Loss: 0.000428
Validation Loss: 0.00036640
Epoch [284/300], Train Loss: 0.000426
Validation Loss: 0.00036503
Epoch [285/300], Train Loss: 0.000424
Validation Loss: 0.00036423
Epoch [286/300], Train Loss: 0.000426
Validation Loss: 0.00036852
Epoch [287/300], Train Loss: 0.000423
Validation Loss: 0.00036450
Epoch [288/300], Train Loss: 0.000423
Validation Loss: 0.00036729
Epoch [289/300], Train Loss: 0.000423
Validation Loss: 0.00036234
Epoch [290/300], Train Loss: 0.000424
Validation Loss: 0.00036602
Epoch [291/300], Train Loss: 0.000423
Validation Loss: 0.00036678
Epoch [292/300], Train Loss: 0.000425
Validation Loss: 0.00036558
Epoch [293/300], Train Loss: 0.000423
Validation Loss: 0.00037139
Epoch [294/300], Train Loss: 0.000424
Validation Loss: 0.00036243
Epoch [295/300], Train Loss: 0.000422
Validation Loss: 0.00036321
Epoch [296/300], Train Loss: 0.000427
Validation Loss: 0.00036270
Epoch [297/300], Train Loss: 0.000424
Validation Loss: 0.00036089
Epoch [298/300], Train Loss: 0.000422
Validation Loss: 0.00036078
Epoch [299/300], Train Loss: 0.000417
Validation Loss: 0.00036584
Epoch [300/300], Train Loss: 0.000418
Validation Loss: 0.00035959

Evaluating model for: Coffee Machine
Run 45/72 completed in 1891.00 seconds with: {'MAE': np.float32(5.670629), 'MSE': np.float32(2114.5786), 'RMSE': np.float32(45.984547), 'SAE': np.float32(0.20719707), 'NDE': np.float32(0.6991512)}

Run 46/72: hidden=256, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Coffee Machine
Dataset length: 2980 windows

Epoch [1/300], Train Loss: 0.001103
Validation Loss: 0.00092152
Epoch [2/300], Train Loss: 0.000982
Validation Loss: 0.00091898
Epoch [3/300], Train Loss: 0.000984
Validation Loss: 0.00091741
Epoch [4/300], Train Loss: 0.000985
Validation Loss: 0.00091700
Epoch [5/300], Train Loss: 0.000986
Validation Loss: 0.00091726
Epoch [6/300], Train Loss: 0.000983
Validation Loss: 0.00091671
Epoch [7/300], Train Loss: 0.000983
Validation Loss: 0.00091674
Epoch [8/300], Train Loss: 0.000986
Validation Loss: 0.00091638
Epoch [9/300], Train Loss: 0.000990
Validation Loss: 0.00091627
Epoch [10/300], Train Loss: 0.000990
Validation Loss: 0.00091592
Epoch [11/300], Train Loss: 0.000973
Validation Loss: 0.00091565
Epoch [12/300], Train Loss: 0.000981
Validation Loss: 0.00091539
Epoch [13/300], Train Loss: 0.000983
Validation Loss: 0.00091504
Epoch [14/300], Train Loss: 0.000984
Validation Loss: 0.00091461
Epoch [15/300], Train Loss: 0.000971
Validation Loss: 0.00091402
Epoch [16/300], Train Loss: 0.000978
Validation Loss: 0.00091385
Epoch [17/300], Train Loss: 0.000984
Validation Loss: 0.00091388
Epoch [18/300], Train Loss: 0.000979
Validation Loss: 0.00091218
Epoch [19/300], Train Loss: 0.000979
Validation Loss: 0.00091141
Epoch [20/300], Train Loss: 0.000967
Validation Loss: 0.00091040
Epoch [21/300], Train Loss: 0.000978
Validation Loss: 0.00090979
Epoch [22/300], Train Loss: 0.000963
Validation Loss: 0.00090743
Epoch [23/300], Train Loss: 0.000975
Validation Loss: 0.00090551
Epoch [24/300], Train Loss: 0.000965
Validation Loss: 0.00090335
Epoch [25/300], Train Loss: 0.000967
Validation Loss: 0.00090143
Epoch [26/300], Train Loss: 0.000970
Validation Loss: 0.00090223
Epoch [27/300], Train Loss: 0.000966
Validation Loss: 0.00089816
Epoch [28/300], Train Loss: 0.000956
Validation Loss: 0.00089659
Epoch [29/300], Train Loss: 0.000963
Validation Loss: 0.00089463
Epoch [30/300], Train Loss: 0.000959
Validation Loss: 0.00089165
Epoch [31/300], Train Loss: 0.000953
Validation Loss: 0.00088898
Epoch [32/300], Train Loss: 0.000954
Validation Loss: 0.00088570
Epoch [33/300], Train Loss: 0.000952
Validation Loss: 0.00088278
Epoch [34/300], Train Loss: 0.000949
Validation Loss: 0.00087737
Epoch [35/300], Train Loss: 0.000942
Validation Loss: 0.00087463
Epoch [36/300], Train Loss: 0.000949
Validation Loss: 0.00086628
Epoch [37/300], Train Loss: 0.000950
Validation Loss: 0.00086133
Epoch [38/300], Train Loss: 0.000933
Validation Loss: 0.00085187
Epoch [39/300], Train Loss: 0.000929
Validation Loss: 0.00084193
Epoch [40/300], Train Loss: 0.000914
Validation Loss: 0.00083033
Epoch [41/300], Train Loss: 0.000910
Validation Loss: 0.00081943
Epoch [42/300], Train Loss: 0.000900
Validation Loss: 0.00080359
Epoch [43/300], Train Loss: 0.000884
Validation Loss: 0.00079078
Epoch [44/300], Train Loss: 0.000863
Validation Loss: 0.00077680
Epoch [45/300], Train Loss: 0.000847
Validation Loss: 0.00076450
Epoch [46/300], Train Loss: 0.000843
Validation Loss: 0.00075277
Epoch [47/300], Train Loss: 0.000832
Validation Loss: 0.00073958
Epoch [48/300], Train Loss: 0.000815
Validation Loss: 0.00072705
Epoch [49/300], Train Loss: 0.000803
Validation Loss: 0.00071584
Epoch [50/300], Train Loss: 0.000795
Validation Loss: 0.00071091
Epoch [51/300], Train Loss: 0.000784
Validation Loss: 0.00068926
Epoch [52/300], Train Loss: 0.000768
Validation Loss: 0.00067877
Epoch [53/300], Train Loss: 0.000757
Validation Loss: 0.00066662
Epoch [54/300], Train Loss: 0.000751
Validation Loss: 0.00065116
Epoch [55/300], Train Loss: 0.000742
Validation Loss: 0.00066399
Epoch [56/300], Train Loss: 0.000742
Validation Loss: 0.00063789
Epoch [57/300], Train Loss: 0.000727
Validation Loss: 0.00062894
Epoch [58/300], Train Loss: 0.000704
Validation Loss: 0.00061442
Epoch [59/300], Train Loss: 0.000696
Validation Loss: 0.00060878
Epoch [60/300], Train Loss: 0.000692
Validation Loss: 0.00060024
Epoch [61/300], Train Loss: 0.000687
Validation Loss: 0.00061075
Epoch [62/300], Train Loss: 0.000672
Validation Loss: 0.00058567
Epoch [63/300], Train Loss: 0.000661
Validation Loss: 0.00057314
Epoch [64/300], Train Loss: 0.000652
Validation Loss: 0.00057618
Epoch [65/300], Train Loss: 0.000654
Validation Loss: 0.00056772
Epoch [66/300], Train Loss: 0.000657
Validation Loss: 0.00055841
Epoch [67/300], Train Loss: 0.000647
Validation Loss: 0.00054424
Epoch [68/300], Train Loss: 0.000643
Validation Loss: 0.00054929
Epoch [69/300], Train Loss: 0.000632
Validation Loss: 0.00053921
Epoch [70/300], Train Loss: 0.000630
Validation Loss: 0.00055312
Epoch [71/300], Train Loss: 0.000622
Validation Loss: 0.00055100
Epoch [72/300], Train Loss: 0.000619
Validation Loss: 0.00053135
Epoch [73/300], Train Loss: 0.000609
Validation Loss: 0.00051565
Epoch [74/300], Train Loss: 0.000600
Validation Loss: 0.00053706
Epoch [75/300], Train Loss: 0.000619
Validation Loss: 0.00053231
Epoch [76/300], Train Loss: 0.000604
Validation Loss: 0.00051578
Epoch [77/300], Train Loss: 0.000596
Validation Loss: 0.00051772
Epoch [78/300], Train Loss: 0.000593
Validation Loss: 0.00054115
Epoch [79/300], Train Loss: 0.000608
Validation Loss: 0.00051641
Epoch [80/300], Train Loss: 0.000588
Validation Loss: 0.00051511
Epoch [81/300], Train Loss: 0.000584
Validation Loss: 0.00049966
Epoch [82/300], Train Loss: 0.000572
Validation Loss: 0.00049890
Epoch [83/300], Train Loss: 0.000575
Validation Loss: 0.00051409
Epoch [84/300], Train Loss: 0.000574
Validation Loss: 0.00049454
Epoch [85/300], Train Loss: 0.000578
Validation Loss: 0.00049449
Epoch [86/300], Train Loss: 0.000559
Validation Loss: 0.00050019
Epoch [87/300], Train Loss: 0.000572
Validation Loss: 0.00049916
Epoch [88/300], Train Loss: 0.000571
Validation Loss: 0.00051013
Epoch [89/300], Train Loss: 0.000557
Validation Loss: 0.00048615
Epoch [90/300], Train Loss: 0.000559
Validation Loss: 0.00048799
Epoch [91/300], Train Loss: 0.000551
Validation Loss: 0.00048341
Epoch [92/300], Train Loss: 0.000547
Validation Loss: 0.00048627
Epoch [93/300], Train Loss: 0.000551
Validation Loss: 0.00048347
Epoch [94/300], Train Loss: 0.000550
Validation Loss: 0.00047893
Epoch [95/300], Train Loss: 0.000544
Validation Loss: 0.00048857
Epoch [96/300], Train Loss: 0.000541
Validation Loss: 0.00048020
Epoch [97/300], Train Loss: 0.000536
Validation Loss: 0.00048345
Epoch [98/300], Train Loss: 0.000541
Validation Loss: 0.00046812
Epoch [99/300], Train Loss: 0.000539
Validation Loss: 0.00048015
Epoch [100/300], Train Loss: 0.000532
Validation Loss: 0.00047682
Epoch [101/300], Train Loss: 0.000540
Validation Loss: 0.00048327
Epoch [102/300], Train Loss: 0.000535
Validation Loss: 0.00047356
Epoch [103/300], Train Loss: 0.000530
Validation Loss: 0.00047343
Epoch [104/300], Train Loss: 0.000528
Validation Loss: 0.00045981
Epoch [105/300], Train Loss: 0.000519
Validation Loss: 0.00046313
Epoch [106/300], Train Loss: 0.000518
Validation Loss: 0.00047254
Epoch [107/300], Train Loss: 0.000517
Validation Loss: 0.00045585
Epoch [108/300], Train Loss: 0.000504
Validation Loss: 0.00045855
Epoch [109/300], Train Loss: 0.000512
Validation Loss: 0.00045194
Epoch [110/300], Train Loss: 0.000507
Validation Loss: 0.00045630
Epoch [111/300], Train Loss: 0.000505
Validation Loss: 0.00045701
Epoch [112/300], Train Loss: 0.000509
Validation Loss: 0.00044935
Epoch [113/300], Train Loss: 0.000504
Validation Loss: 0.00045042
Epoch [114/300], Train Loss: 0.000502
Validation Loss: 0.00044651
Epoch [115/300], Train Loss: 0.000516
Validation Loss: 0.00047094
Epoch [116/300], Train Loss: 0.000507
Validation Loss: 0.00044341
Epoch [117/300], Train Loss: 0.000501
Validation Loss: 0.00044891
Epoch [118/300], Train Loss: 0.000503
Validation Loss: 0.00043904
Epoch [119/300], Train Loss: 0.000496
Validation Loss: 0.00044495
Epoch [120/300], Train Loss: 0.000500
Validation Loss: 0.00044563
Epoch [121/300], Train Loss: 0.000496
Validation Loss: 0.00043992
Epoch [122/300], Train Loss: 0.000488
Validation Loss: 0.00043130
Epoch [123/300], Train Loss: 0.000482
Validation Loss: 0.00044942
Epoch [124/300], Train Loss: 0.000491
Validation Loss: 0.00043681
Epoch [125/300], Train Loss: 0.000480
Validation Loss: 0.00042643
Epoch [126/300], Train Loss: 0.000479
Validation Loss: 0.00042772
Epoch [127/300], Train Loss: 0.000478
Validation Loss: 0.00043467
Epoch [128/300], Train Loss: 0.000480
Validation Loss: 0.00044189
Epoch [129/300], Train Loss: 0.000480
Validation Loss: 0.00043720
Epoch [130/300], Train Loss: 0.000477
Validation Loss: 0.00042823
Epoch [131/300], Train Loss: 0.000476
Validation Loss: 0.00042514
Epoch [132/300], Train Loss: 0.000476
Validation Loss: 0.00042381
Epoch [133/300], Train Loss: 0.000474
Validation Loss: 0.00042324
Epoch [134/300], Train Loss: 0.000472
Validation Loss: 0.00044837
Epoch [135/300], Train Loss: 0.000477
Validation Loss: 0.00042591
Epoch [136/300], Train Loss: 0.000474
Validation Loss: 0.00042657
Epoch [137/300], Train Loss: 0.000468
Validation Loss: 0.00041477
Epoch [138/300], Train Loss: 0.000463
Validation Loss: 0.00042113
Epoch [139/300], Train Loss: 0.000467
Validation Loss: 0.00044026
Epoch [140/300], Train Loss: 0.000464
Validation Loss: 0.00042440
Epoch [141/300], Train Loss: 0.000461
Validation Loss: 0.00042713
Epoch [142/300], Train Loss: 0.000454
Validation Loss: 0.00042438
Epoch [143/300], Train Loss: 0.000465
Validation Loss: 0.00042308
Epoch [144/300], Train Loss: 0.000456
Validation Loss: 0.00042006
Epoch [145/300], Train Loss: 0.000456
Validation Loss: 0.00041947
Epoch [146/300], Train Loss: 0.000452
Validation Loss: 0.00040906
Epoch [147/300], Train Loss: 0.000456
Validation Loss: 0.00041320
Epoch [148/300], Train Loss: 0.000452
Validation Loss: 0.00041112
Epoch [149/300], Train Loss: 0.000445
Validation Loss: 0.00040612
Epoch [150/300], Train Loss: 0.000449
Validation Loss: 0.00041189
Epoch [151/300], Train Loss: 0.000452
Validation Loss: 0.00039989
Epoch [152/300], Train Loss: 0.000449
Validation Loss: 0.00041725
Epoch [153/300], Train Loss: 0.000448
Validation Loss: 0.00040782
Epoch [154/300], Train Loss: 0.000443
Validation Loss: 0.00040476
Epoch [155/300], Train Loss: 0.000443
Validation Loss: 0.00040734
Epoch [156/300], Train Loss: 0.000440
Validation Loss: 0.00040329
Epoch [157/300], Train Loss: 0.000438
Validation Loss: 0.00039702
Epoch [158/300], Train Loss: 0.000442
Validation Loss: 0.00039858
Epoch [159/300], Train Loss: 0.000437
Validation Loss: 0.00039831
Epoch [160/300], Train Loss: 0.000444
Validation Loss: 0.00040225
Epoch [161/300], Train Loss: 0.000440
Validation Loss: 0.00042499
Epoch [162/300], Train Loss: 0.000445
Validation Loss: 0.00039930
Epoch [163/300], Train Loss: 0.000434
Validation Loss: 0.00039086
Epoch [164/300], Train Loss: 0.000436
Validation Loss: 0.00039500
Epoch [165/300], Train Loss: 0.000431
Validation Loss: 0.00039170
Epoch [166/300], Train Loss: 0.000429
Validation Loss: 0.00039111
Epoch [167/300], Train Loss: 0.000424
Validation Loss: 0.00038896
Epoch [168/300], Train Loss: 0.000429
Validation Loss: 0.00039189
Epoch [169/300], Train Loss: 0.000429
Validation Loss: 0.00039138
Epoch [170/300], Train Loss: 0.000420
Validation Loss: 0.00038400
Epoch [171/300], Train Loss: 0.000430
Validation Loss: 0.00039552
Epoch [172/300], Train Loss: 0.000423
Validation Loss: 0.00038865
Epoch [173/300], Train Loss: 0.000425
Validation Loss: 0.00039566
Epoch [174/300], Train Loss: 0.000430
Validation Loss: 0.00038962
Epoch [175/300], Train Loss: 0.000422
Validation Loss: 0.00038763
Epoch [176/300], Train Loss: 0.000421
Validation Loss: 0.00038641
Epoch [177/300], Train Loss: 0.000420
Validation Loss: 0.00039263
Epoch [178/300], Train Loss: 0.000422
Validation Loss: 0.00038888
Epoch [179/300], Train Loss: 0.000411
Validation Loss: 0.00037569
Epoch [180/300], Train Loss: 0.000412
Validation Loss: 0.00037905
Epoch [181/300], Train Loss: 0.000407
Validation Loss: 0.00038457
Epoch [182/300], Train Loss: 0.000414
Validation Loss: 0.00038430
Epoch [183/300], Train Loss: 0.000415
Validation Loss: 0.00037909
Epoch [184/300], Train Loss: 0.000414
Validation Loss: 0.00037230
Epoch [185/300], Train Loss: 0.000402
Validation Loss: 0.00036972
Epoch [186/300], Train Loss: 0.000405
Validation Loss: 0.00036996
Epoch [187/300], Train Loss: 0.000402
Validation Loss: 0.00036942
Epoch [188/300], Train Loss: 0.000395
Validation Loss: 0.00036825
Epoch [189/300], Train Loss: 0.000404
Validation Loss: 0.00037242
Epoch [190/300], Train Loss: 0.000403
Validation Loss: 0.00037004
Epoch [191/300], Train Loss: 0.000404
Validation Loss: 0.00037877
Epoch [192/300], Train Loss: 0.000401
Validation Loss: 0.00036107
Epoch [193/300], Train Loss: 0.000399
Validation Loss: 0.00036341
Epoch [194/300], Train Loss: 0.000401
Validation Loss: 0.00036271
Epoch [195/300], Train Loss: 0.000399
Validation Loss: 0.00036241
Epoch [196/300], Train Loss: 0.000395
Validation Loss: 0.00036328
Epoch [197/300], Train Loss: 0.000395
Validation Loss: 0.00036910
Epoch [198/300], Train Loss: 0.000389
Validation Loss: 0.00036373
Epoch [199/300], Train Loss: 0.000389
Validation Loss: 0.00036001
Epoch [200/300], Train Loss: 0.000389
Validation Loss: 0.00035441
Epoch [201/300], Train Loss: 0.000386
Validation Loss: 0.00035511
Epoch [202/300], Train Loss: 0.000391
Validation Loss: 0.00035494
Epoch [203/300], Train Loss: 0.000388
Validation Loss: 0.00035475
Epoch [204/300], Train Loss: 0.000377
Validation Loss: 0.00035681
Epoch [205/300], Train Loss: 0.000382
Validation Loss: 0.00035174
Epoch [206/300], Train Loss: 0.000380
Validation Loss: 0.00035464
Epoch [207/300], Train Loss: 0.000386
Validation Loss: 0.00035143
Epoch [208/300], Train Loss: 0.000386
Validation Loss: 0.00035981
Epoch [209/300], Train Loss: 0.000377
Validation Loss: 0.00035210
Epoch [210/300], Train Loss: 0.000386
Validation Loss: 0.00035052
Epoch [211/300], Train Loss: 0.000379
Validation Loss: 0.00034145
Epoch [212/300], Train Loss: 0.000375
Validation Loss: 0.00034690
Epoch [213/300], Train Loss: 0.000377
Validation Loss: 0.00035663
Epoch [214/300], Train Loss: 0.000373
Validation Loss: 0.00034152
Epoch [215/300], Train Loss: 0.000367
Validation Loss: 0.00034283
Epoch [216/300], Train Loss: 0.000370
Validation Loss: 0.00033883
Epoch [217/300], Train Loss: 0.000368
Validation Loss: 0.00034666
Epoch [218/300], Train Loss: 0.000365
Validation Loss: 0.00033310
Epoch [219/300], Train Loss: 0.000367
Validation Loss: 0.00033273
Epoch [220/300], Train Loss: 0.000367
Validation Loss: 0.00033263
Epoch [221/300], Train Loss: 0.000367
Validation Loss: 0.00033474
Epoch [222/300], Train Loss: 0.000367
Validation Loss: 0.00034150
Epoch [223/300], Train Loss: 0.000371
Validation Loss: 0.00033145
Epoch [224/300], Train Loss: 0.000358
Validation Loss: 0.00033191
Epoch [225/300], Train Loss: 0.000359
Validation Loss: 0.00032887
Epoch [226/300], Train Loss: 0.000363
Validation Loss: 0.00032874
Epoch [227/300], Train Loss: 0.000355
Validation Loss: 0.00032484
Epoch [228/300], Train Loss: 0.000355
Validation Loss: 0.00033098
Epoch [229/300], Train Loss: 0.000355
Validation Loss: 0.00032339
Epoch [230/300], Train Loss: 0.000356
Validation Loss: 0.00032193
Epoch [231/300], Train Loss: 0.000356
Validation Loss: 0.00032307
Epoch [232/300], Train Loss: 0.000351
Validation Loss: 0.00032226
Epoch [233/300], Train Loss: 0.000352
Validation Loss: 0.00032777
Epoch [234/300], Train Loss: 0.000355
Validation Loss: 0.00032601
Epoch [235/300], Train Loss: 0.000351
Validation Loss: 0.00032011
Epoch [236/300], Train Loss: 0.000352
Validation Loss: 0.00033077
Epoch [237/300], Train Loss: 0.000351
Validation Loss: 0.00031543
Epoch [238/300], Train Loss: 0.000350
Validation Loss: 0.00032749
Epoch [239/300], Train Loss: 0.000351
Validation Loss: 0.00031837
Epoch [240/300], Train Loss: 0.000345
Validation Loss: 0.00032262
Epoch [241/300], Train Loss: 0.000349
Validation Loss: 0.00034411
Epoch [242/300], Train Loss: 0.000342
Validation Loss: 0.00031459
Epoch [243/300], Train Loss: 0.000343
Validation Loss: 0.00031294
Epoch [244/300], Train Loss: 0.000338
Validation Loss: 0.00031676
Epoch [245/300], Train Loss: 0.000340
Validation Loss: 0.00031601
Epoch [246/300], Train Loss: 0.000344
Validation Loss: 0.00031507
Epoch [247/300], Train Loss: 0.000338
Validation Loss: 0.00031657
Epoch [248/300], Train Loss: 0.000337
Validation Loss: 0.00031363
Epoch [249/300], Train Loss: 0.000335
Validation Loss: 0.00030944
Epoch [250/300], Train Loss: 0.000336
Validation Loss: 0.00030986
Epoch [251/300], Train Loss: 0.000337
Validation Loss: 0.00031310
Epoch [252/300], Train Loss: 0.000334
Validation Loss: 0.00030594
Epoch [253/300], Train Loss: 0.000334
Validation Loss: 0.00030441
Epoch [254/300], Train Loss: 0.000333
Validation Loss: 0.00031579
Epoch [255/300], Train Loss: 0.000333
Validation Loss: 0.00030260
Epoch [256/300], Train Loss: 0.000332
Validation Loss: 0.00030711
Epoch [257/300], Train Loss: 0.000335
Validation Loss: 0.00030457
Epoch [258/300], Train Loss: 0.000330
Validation Loss: 0.00030137
Epoch [259/300], Train Loss: 0.000333
Validation Loss: 0.00030397
Epoch [260/300], Train Loss: 0.000332
Validation Loss: 0.00030184
Epoch [261/300], Train Loss: 0.000326
Validation Loss: 0.00030476
Epoch [262/300], Train Loss: 0.000324
Validation Loss: 0.00029609
Epoch [263/300], Train Loss: 0.000322
Validation Loss: 0.00030386
Epoch [264/300], Train Loss: 0.000324
Validation Loss: 0.00030054
Epoch [265/300], Train Loss: 0.000331
Validation Loss: 0.00033141
Epoch [266/300], Train Loss: 0.000326
Validation Loss: 0.00029812
Epoch [267/300], Train Loss: 0.000327
Validation Loss: 0.00030183
Epoch [268/300], Train Loss: 0.000325
Validation Loss: 0.00029793
Epoch [269/300], Train Loss: 0.000320
Validation Loss: 0.00030836
Epoch [270/300], Train Loss: 0.000325
Validation Loss: 0.00029938
Epoch [271/300], Train Loss: 0.000327
Validation Loss: 0.00032528
Epoch [272/300], Train Loss: 0.000327
Validation Loss: 0.00030809
Early stopping triggered

Evaluating model for: Coffee Machine
Run 46/72 completed in 2125.12 seconds with: {'MAE': np.float32(4.994885), 'MSE': np.float32(1722.3846), 'RMSE': np.float32(41.50162), 'SAE': np.float32(0.1533462), 'NDE': np.float32(0.63099265)}

Run 47/72: hidden=256, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Coffee Machine
Dataset length: 2980 windows

Epoch [1/300], Train Loss: 0.001194
Validation Loss: 0.00095701
Epoch [2/300], Train Loss: 0.000984
Validation Loss: 0.00091816
Epoch [3/300], Train Loss: 0.000982
Validation Loss: 0.00091727
Epoch [4/300], Train Loss: 0.000983
Validation Loss: 0.00091750
Epoch [5/300], Train Loss: 0.000985
Validation Loss: 0.00091735
Epoch [6/300], Train Loss: 0.000982
Validation Loss: 0.00091718
Epoch [7/300], Train Loss: 0.000981
Validation Loss: 0.00091722
Epoch [8/300], Train Loss: 0.000986
Validation Loss: 0.00091722
Epoch [9/300], Train Loss: 0.000990
Validation Loss: 0.00091721
Epoch [10/300], Train Loss: 0.000990
Validation Loss: 0.00091703
Epoch [11/300], Train Loss: 0.000973
Validation Loss: 0.00091698
Epoch [12/300], Train Loss: 0.000982
Validation Loss: 0.00091695
Epoch [13/300], Train Loss: 0.000984
Validation Loss: 0.00091694
Epoch [14/300], Train Loss: 0.000986
Validation Loss: 0.00091687
Epoch [15/300], Train Loss: 0.000972
Validation Loss: 0.00091747
Epoch [16/300], Train Loss: 0.000980
Validation Loss: 0.00091680
Epoch [17/300], Train Loss: 0.000986
Validation Loss: 0.00091685
Epoch [18/300], Train Loss: 0.000982
Validation Loss: 0.00091664
Epoch [19/300], Train Loss: 0.000983
Validation Loss: 0.00091655
Epoch [20/300], Train Loss: 0.000972
Validation Loss: 0.00091669
Epoch [21/300], Train Loss: 0.000983
Validation Loss: 0.00091643
Epoch [22/300], Train Loss: 0.000969
Validation Loss: 0.00091631
Epoch [23/300], Train Loss: 0.000983
Validation Loss: 0.00091619
Epoch [24/300], Train Loss: 0.000975
Validation Loss: 0.00091618
Epoch [25/300], Train Loss: 0.000977
Validation Loss: 0.00091595
Epoch [26/300], Train Loss: 0.000981
Validation Loss: 0.00091604
Epoch [27/300], Train Loss: 0.000979
Validation Loss: 0.00091537
Epoch [28/300], Train Loss: 0.000970
Validation Loss: 0.00091519
Epoch [29/300], Train Loss: 0.000978
Validation Loss: 0.00091459
Epoch [30/300], Train Loss: 0.000975
Validation Loss: 0.00091423
Epoch [31/300], Train Loss: 0.000972
Validation Loss: 0.00091344
Epoch [32/300], Train Loss: 0.000975
Validation Loss: 0.00091274
Epoch [33/300], Train Loss: 0.000975
Validation Loss: 0.00091310
Epoch [34/300], Train Loss: 0.000974
Validation Loss: 0.00091105
Epoch [35/300], Train Loss: 0.000968
Validation Loss: 0.00090952
Epoch [36/300], Train Loss: 0.000979
Validation Loss: 0.00090825
Epoch [37/300], Train Loss: 0.000987
Validation Loss: 0.00090909
Epoch [38/300], Train Loss: 0.000973
Validation Loss: 0.00090676
Epoch [39/300], Train Loss: 0.000976
Validation Loss: 0.00090520
Epoch [40/300], Train Loss: 0.000969
Validation Loss: 0.00090441
Epoch [41/300], Train Loss: 0.000974
Validation Loss: 0.00090369
Epoch [42/300], Train Loss: 0.000976
Validation Loss: 0.00090184
Epoch [43/300], Train Loss: 0.000972
Validation Loss: 0.00089964
Epoch [44/300], Train Loss: 0.000960
Validation Loss: 0.00089744
Epoch [45/300], Train Loss: 0.000954
Validation Loss: 0.00089453
Epoch [46/300], Train Loss: 0.000960
Validation Loss: 0.00089122
Epoch [47/300], Train Loss: 0.000959
Validation Loss: 0.00088707
Epoch [48/300], Train Loss: 0.000952
Validation Loss: 0.00088143
Epoch [49/300], Train Loss: 0.000946
Validation Loss: 0.00087598
Epoch [50/300], Train Loss: 0.000944
Validation Loss: 0.00086855
Epoch [51/300], Train Loss: 0.000942
Validation Loss: 0.00086141
Epoch [52/300], Train Loss: 0.000929
Validation Loss: 0.00085262
Epoch [53/300], Train Loss: 0.000921
Validation Loss: 0.00084093
Epoch [54/300], Train Loss: 0.000915
Validation Loss: 0.00082355
Epoch [55/300], Train Loss: 0.000893
Validation Loss: 0.00080857
Epoch [56/300], Train Loss: 0.000887
Validation Loss: 0.00079553
Epoch [57/300], Train Loss: 0.000877
Validation Loss: 0.00077731
Epoch [58/300], Train Loss: 0.000848
Validation Loss: 0.00075852
Epoch [59/300], Train Loss: 0.000834
Validation Loss: 0.00074321
Epoch [60/300], Train Loss: 0.000823
Validation Loss: 0.00072551
Epoch [61/300], Train Loss: 0.000799
Validation Loss: 0.00070712
Epoch [62/300], Train Loss: 0.000786
Validation Loss: 0.00069060
Epoch [63/300], Train Loss: 0.000768
Validation Loss: 0.00067767
Epoch [64/300], Train Loss: 0.000749
Validation Loss: 0.00065879
Epoch [65/300], Train Loss: 0.000754
Validation Loss: 0.00065407
Epoch [66/300], Train Loss: 0.000744
Validation Loss: 0.00064719
Epoch [67/300], Train Loss: 0.000727
Validation Loss: 0.00062413
Epoch [68/300], Train Loss: 0.000721
Validation Loss: 0.00062488
Epoch [69/300], Train Loss: 0.000709
Validation Loss: 0.00060689
Epoch [70/300], Train Loss: 0.000693
Validation Loss: 0.00060194
Epoch [71/300], Train Loss: 0.000679
Validation Loss: 0.00061131
Epoch [72/300], Train Loss: 0.000673
Validation Loss: 0.00059485
Epoch [73/300], Train Loss: 0.000662
Validation Loss: 0.00057076
Epoch [74/300], Train Loss: 0.000660
Validation Loss: 0.00058838
Epoch [75/300], Train Loss: 0.000662
Validation Loss: 0.00058768
Epoch [76/300], Train Loss: 0.000655
Validation Loss: 0.00057779
Epoch [77/300], Train Loss: 0.000642
Validation Loss: 0.00056868
Epoch [78/300], Train Loss: 0.000632
Validation Loss: 0.00058927
Epoch [79/300], Train Loss: 0.000638
Validation Loss: 0.00054314
Epoch [80/300], Train Loss: 0.000609
Validation Loss: 0.00054265
Epoch [81/300], Train Loss: 0.000614
Validation Loss: 0.00053171
Epoch [82/300], Train Loss: 0.000614
Validation Loss: 0.00052755
Epoch [83/300], Train Loss: 0.000607
Validation Loss: 0.00053589
Epoch [84/300], Train Loss: 0.000602
Validation Loss: 0.00051458
Epoch [85/300], Train Loss: 0.000601
Validation Loss: 0.00051881
Epoch [86/300], Train Loss: 0.000598
Validation Loss: 0.00052703
Epoch [87/300], Train Loss: 0.000594
Validation Loss: 0.00052663
Epoch [88/300], Train Loss: 0.000591
Validation Loss: 0.00051624
Epoch [89/300], Train Loss: 0.000593
Validation Loss: 0.00051151
Epoch [90/300], Train Loss: 0.000584
Validation Loss: 0.00051177
Epoch [91/300], Train Loss: 0.000572
Validation Loss: 0.00050913
Epoch [92/300], Train Loss: 0.000572
Validation Loss: 0.00052694
Epoch [93/300], Train Loss: 0.000580
Validation Loss: 0.00049857
Epoch [94/300], Train Loss: 0.000582
Validation Loss: 0.00050164
Epoch [95/300], Train Loss: 0.000566
Validation Loss: 0.00051487
Epoch [96/300], Train Loss: 0.000564
Validation Loss: 0.00049311
Epoch [97/300], Train Loss: 0.000561
Validation Loss: 0.00052011
Epoch [98/300], Train Loss: 0.000572
Validation Loss: 0.00049214
Epoch [99/300], Train Loss: 0.000565
Validation Loss: 0.00049650
Epoch [100/300], Train Loss: 0.000553
Validation Loss: 0.00049178
Epoch [101/300], Train Loss: 0.000557
Validation Loss: 0.00049493
Epoch [102/300], Train Loss: 0.000560
Validation Loss: 0.00050534
Epoch [103/300], Train Loss: 0.000565
Validation Loss: 0.00050138
Epoch [104/300], Train Loss: 0.000561
Validation Loss: 0.00049259
Epoch [105/300], Train Loss: 0.000543
Validation Loss: 0.00047961
Epoch [106/300], Train Loss: 0.000538
Validation Loss: 0.00047880
Epoch [107/300], Train Loss: 0.000537
Validation Loss: 0.00047384
Epoch [108/300], Train Loss: 0.000528
Validation Loss: 0.00047698
Epoch [109/300], Train Loss: 0.000535
Validation Loss: 0.00047579
Epoch [110/300], Train Loss: 0.000530
Validation Loss: 0.00048172
Epoch [111/300], Train Loss: 0.000532
Validation Loss: 0.00048985
Epoch [112/300], Train Loss: 0.000536
Validation Loss: 0.00047357
Epoch [113/300], Train Loss: 0.000525
Validation Loss: 0.00047960
Epoch [114/300], Train Loss: 0.000525
Validation Loss: 0.00047363
Epoch [115/300], Train Loss: 0.000540
Validation Loss: 0.00048156
Epoch [116/300], Train Loss: 0.000521
Validation Loss: 0.00046645
Epoch [117/300], Train Loss: 0.000519
Validation Loss: 0.00047641
Epoch [118/300], Train Loss: 0.000526
Validation Loss: 0.00048353
Epoch [119/300], Train Loss: 0.000536
Validation Loss: 0.00048739
Epoch [120/300], Train Loss: 0.000526
Validation Loss: 0.00046721
Epoch [121/300], Train Loss: 0.000516
Validation Loss: 0.00047340
Epoch [122/300], Train Loss: 0.000515
Validation Loss: 0.00045655
Epoch [123/300], Train Loss: 0.000504
Validation Loss: 0.00046998
Epoch [124/300], Train Loss: 0.000514
Validation Loss: 0.00046535
Epoch [125/300], Train Loss: 0.000501
Validation Loss: 0.00046364
Epoch [126/300], Train Loss: 0.000500
Validation Loss: 0.00045724
Epoch [127/300], Train Loss: 0.000500
Validation Loss: 0.00046498
Epoch [128/300], Train Loss: 0.000495
Validation Loss: 0.00045671
Epoch [129/300], Train Loss: 0.000496
Validation Loss: 0.00045514
Epoch [130/300], Train Loss: 0.000490
Validation Loss: 0.00046762
Epoch [131/300], Train Loss: 0.000498
Validation Loss: 0.00046312
Epoch [132/300], Train Loss: 0.000501
Validation Loss: 0.00046003
Epoch [133/300], Train Loss: 0.000497
Validation Loss: 0.00045920
Epoch [134/300], Train Loss: 0.000489
Validation Loss: 0.00046990
Epoch [135/300], Train Loss: 0.000488
Validation Loss: 0.00046235
Epoch [136/300], Train Loss: 0.000491
Validation Loss: 0.00045928
Epoch [137/300], Train Loss: 0.000487
Validation Loss: 0.00043995
Epoch [138/300], Train Loss: 0.000482
Validation Loss: 0.00046116
Epoch [139/300], Train Loss: 0.000488
Validation Loss: 0.00044297
Epoch [140/300], Train Loss: 0.000479
Validation Loss: 0.00046783
Epoch [141/300], Train Loss: 0.000475
Validation Loss: 0.00044682
Epoch [142/300], Train Loss: 0.000471
Validation Loss: 0.00046379
Epoch [143/300], Train Loss: 0.000481
Validation Loss: 0.00044060
Epoch [144/300], Train Loss: 0.000467
Validation Loss: 0.00043659
Epoch [145/300], Train Loss: 0.000468
Validation Loss: 0.00043818
Epoch [146/300], Train Loss: 0.000474
Validation Loss: 0.00042644
Epoch [147/300], Train Loss: 0.000470
Validation Loss: 0.00044809
Epoch [148/300], Train Loss: 0.000482
Validation Loss: 0.00045854
Epoch [149/300], Train Loss: 0.000461
Validation Loss: 0.00044962
Epoch [150/300], Train Loss: 0.000462
Validation Loss: 0.00043791
Epoch [151/300], Train Loss: 0.000462
Validation Loss: 0.00042565
Epoch [152/300], Train Loss: 0.000468
Validation Loss: 0.00045061
Epoch [153/300], Train Loss: 0.000468
Validation Loss: 0.00044740
Epoch [154/300], Train Loss: 0.000461
Validation Loss: 0.00044511
Epoch [155/300], Train Loss: 0.000461
Validation Loss: 0.00043086
Epoch [156/300], Train Loss: 0.000456
Validation Loss: 0.00044338
Epoch [157/300], Train Loss: 0.000455
Validation Loss: 0.00043250
Epoch [158/300], Train Loss: 0.000458
Validation Loss: 0.00043427
Epoch [159/300], Train Loss: 0.000462
Validation Loss: 0.00042309
Epoch [160/300], Train Loss: 0.000464
Validation Loss: 0.00043772
Epoch [161/300], Train Loss: 0.000462
Validation Loss: 0.00045068
Epoch [162/300], Train Loss: 0.000465
Validation Loss: 0.00042855
Epoch [163/300], Train Loss: 0.000454
Validation Loss: 0.00043286
Epoch [164/300], Train Loss: 0.000450
Validation Loss: 0.00043261
Epoch [165/300], Train Loss: 0.000443
Validation Loss: 0.00042767
Epoch [166/300], Train Loss: 0.000442
Validation Loss: 0.00041130
Epoch [167/300], Train Loss: 0.000441
Validation Loss: 0.00040890
Epoch [168/300], Train Loss: 0.000441
Validation Loss: 0.00042498
Epoch [169/300], Train Loss: 0.000436
Validation Loss: 0.00041958
Epoch [170/300], Train Loss: 0.000440
Validation Loss: 0.00040796
Epoch [171/300], Train Loss: 0.000454
Validation Loss: 0.00042994
Epoch [172/300], Train Loss: 0.000436
Validation Loss: 0.00040833
Epoch [173/300], Train Loss: 0.000441
Validation Loss: 0.00043308
Epoch [174/300], Train Loss: 0.000441
Validation Loss: 0.00040832
Epoch [175/300], Train Loss: 0.000438
Validation Loss: 0.00040678
Epoch [176/300], Train Loss: 0.000437
Validation Loss: 0.00040526
Epoch [177/300], Train Loss: 0.000437
Validation Loss: 0.00040806
Epoch [178/300], Train Loss: 0.000447
Validation Loss: 0.00040745
Epoch [179/300], Train Loss: 0.000432
Validation Loss: 0.00040113
Epoch [180/300], Train Loss: 0.000436
Validation Loss: 0.00042784
Epoch [181/300], Train Loss: 0.000422
Validation Loss: 0.00039839
Epoch [182/300], Train Loss: 0.000431
Validation Loss: 0.00039813
Epoch [183/300], Train Loss: 0.000434
Validation Loss: 0.00039084
Epoch [184/300], Train Loss: 0.000434
Validation Loss: 0.00039218
Epoch [185/300], Train Loss: 0.000422
Validation Loss: 0.00039184
Epoch [186/300], Train Loss: 0.000420
Validation Loss: 0.00039371
Epoch [187/300], Train Loss: 0.000430
Validation Loss: 0.00039492
Epoch [188/300], Train Loss: 0.000420
Validation Loss: 0.00039979
Epoch [189/300], Train Loss: 0.000419
Validation Loss: 0.00038960
Epoch [190/300], Train Loss: 0.000418
Validation Loss: 0.00039134
Epoch [191/300], Train Loss: 0.000410
Validation Loss: 0.00039427
Epoch [192/300], Train Loss: 0.000421
Validation Loss: 0.00040846
Epoch [193/300], Train Loss: 0.000428
Validation Loss: 0.00038542
Epoch [194/300], Train Loss: 0.000423
Validation Loss: 0.00038235
Epoch [195/300], Train Loss: 0.000418
Validation Loss: 0.00038864
Epoch [196/300], Train Loss: 0.000413
Validation Loss: 0.00037932
Epoch [197/300], Train Loss: 0.000414
Validation Loss: 0.00038740
Epoch [198/300], Train Loss: 0.000411
Validation Loss: 0.00037587
Epoch [199/300], Train Loss: 0.000408
Validation Loss: 0.00036720
Epoch [200/300], Train Loss: 0.000411
Validation Loss: 0.00038229
Epoch [201/300], Train Loss: 0.000403
Validation Loss: 0.00037989
Epoch [202/300], Train Loss: 0.000413
Validation Loss: 0.00037836
Epoch [203/300], Train Loss: 0.000406
Validation Loss: 0.00036601
Epoch [204/300], Train Loss: 0.000400
Validation Loss: 0.00036978
Epoch [205/300], Train Loss: 0.000406
Validation Loss: 0.00036617
Epoch [206/300], Train Loss: 0.000401
Validation Loss: 0.00035702
Epoch [207/300], Train Loss: 0.000410
Validation Loss: 0.00036812
Epoch [208/300], Train Loss: 0.000403
Validation Loss: 0.00037044
Epoch [209/300], Train Loss: 0.000401
Validation Loss: 0.00037197
Epoch [210/300], Train Loss: 0.000405
Validation Loss: 0.00036119
Epoch [211/300], Train Loss: 0.000403
Validation Loss: 0.00036388
Epoch [212/300], Train Loss: 0.000398
Validation Loss: 0.00036089
Epoch [213/300], Train Loss: 0.000405
Validation Loss: 0.00036189
Epoch [214/300], Train Loss: 0.000396
Validation Loss: 0.00035846
Epoch [215/300], Train Loss: 0.000393
Validation Loss: 0.00034991
Epoch [216/300], Train Loss: 0.000391
Validation Loss: 0.00035199
Epoch [217/300], Train Loss: 0.000388
Validation Loss: 0.00035004
Epoch [218/300], Train Loss: 0.000395
Validation Loss: 0.00035205
Epoch [219/300], Train Loss: 0.000394
Validation Loss: 0.00035480
Epoch [220/300], Train Loss: 0.000387
Validation Loss: 0.00035346
Epoch [221/300], Train Loss: 0.000388
Validation Loss: 0.00035075
Epoch [222/300], Train Loss: 0.000388
Validation Loss: 0.00035917
Epoch [223/300], Train Loss: 0.000391
Validation Loss: 0.00035070
Epoch [224/300], Train Loss: 0.000384
Validation Loss: 0.00035421
Epoch [225/300], Train Loss: 0.000387
Validation Loss: 0.00035249
Early stopping triggered

Evaluating model for: Coffee Machine
Run 47/72 completed in 2072.17 seconds with: {'MAE': np.float32(5.0567183), 'MSE': np.float32(2139.0132), 'RMSE': np.float32(46.249466), 'SAE': np.float32(0.28780425), 'NDE': np.float32(0.7031781)}

Run 48/72: hidden=256, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Coffee Machine
Dataset length: 2980 windows

Epoch [1/300], Train Loss: 0.000997
Validation Loss: 0.00091642
Epoch [2/300], Train Loss: 0.000971
Validation Loss: 0.00091689
Epoch [3/300], Train Loss: 0.000977
Validation Loss: 0.00091681
Epoch [4/300], Train Loss: 0.000978
Validation Loss: 0.00091630
Epoch [5/300], Train Loss: 0.000979
Validation Loss: 0.00091639
Epoch [6/300], Train Loss: 0.000976
Validation Loss: 0.00091649
Epoch [7/300], Train Loss: 0.000976
Validation Loss: 0.00091657
Epoch [8/300], Train Loss: 0.000980
Validation Loss: 0.00091625
Epoch [9/300], Train Loss: 0.000984
Validation Loss: 0.00091667
Epoch [10/300], Train Loss: 0.000985
Validation Loss: 0.00091616
Epoch [11/300], Train Loss: 0.000968
Validation Loss: 0.00091615
Epoch [12/300], Train Loss: 0.000977
Validation Loss: 0.00091674
Epoch [13/300], Train Loss: 0.000979
Validation Loss: 0.00091609
Epoch [14/300], Train Loss: 0.000981
Validation Loss: 0.00091608
Epoch [15/300], Train Loss: 0.000968
Validation Loss: 0.00091645
Epoch [16/300], Train Loss: 0.000976
Validation Loss: 0.00091623
Epoch [17/300], Train Loss: 0.000982
Validation Loss: 0.00091685
Epoch [18/300], Train Loss: 0.000978
Validation Loss: 0.00091599
Epoch [19/300], Train Loss: 0.000979
Validation Loss: 0.00091587
Epoch [20/300], Train Loss: 0.000968
Validation Loss: 0.00091579
Epoch [21/300], Train Loss: 0.000980
Validation Loss: 0.00091569
Epoch [22/300], Train Loss: 0.000966
Validation Loss: 0.00091541
Epoch [23/300], Train Loss: 0.000980
Validation Loss: 0.00091547
Epoch [24/300], Train Loss: 0.000971
Validation Loss: 0.00091463
Epoch [25/300], Train Loss: 0.000974
Validation Loss: 0.00091394
Epoch [26/300], Train Loss: 0.000977
Validation Loss: 0.00091469
Epoch [27/300], Train Loss: 0.000975
Validation Loss: 0.00091220
Epoch [28/300], Train Loss: 0.000966
Validation Loss: 0.00091110
Epoch [29/300], Train Loss: 0.000973
Validation Loss: 0.00091078
Epoch [30/300], Train Loss: 0.000971
Validation Loss: 0.00090958
Epoch [31/300], Train Loss: 0.000967
Validation Loss: 0.00090886
Epoch [32/300], Train Loss: 0.000970
Validation Loss: 0.00090872
Epoch [33/300], Train Loss: 0.000971
Validation Loss: 0.00090992
Epoch [34/300], Train Loss: 0.000970
Validation Loss: 0.00090813
Epoch [35/300], Train Loss: 0.000964
Validation Loss: 0.00090549
Epoch [36/300], Train Loss: 0.000975
Validation Loss: 0.00090437
Epoch [37/300], Train Loss: 0.000982
Validation Loss: 0.00090368
Epoch [38/300], Train Loss: 0.000967
Validation Loss: 0.00089999
Epoch [39/300], Train Loss: 0.000968
Validation Loss: 0.00089655
Epoch [40/300], Train Loss: 0.000959
Validation Loss: 0.00089155
Epoch [41/300], Train Loss: 0.000960
Validation Loss: 0.00088602
Epoch [42/300], Train Loss: 0.000957
Validation Loss: 0.00087614
Epoch [43/300], Train Loss: 0.000947
Validation Loss: 0.00086479
Epoch [44/300], Train Loss: 0.000927
Validation Loss: 0.00084957
Epoch [45/300], Train Loss: 0.000910
Validation Loss: 0.00083121
Epoch [46/300], Train Loss: 0.000901
Validation Loss: 0.00080940
Epoch [47/300], Train Loss: 0.000884
Validation Loss: 0.00078890
Epoch [48/300], Train Loss: 0.000860
Validation Loss: 0.00076705
Epoch [49/300], Train Loss: 0.000837
Validation Loss: 0.00074312
Epoch [50/300], Train Loss: 0.000819
Validation Loss: 0.00072187
Epoch [51/300], Train Loss: 0.000801
Validation Loss: 0.00069830
Epoch [52/300], Train Loss: 0.000776
Validation Loss: 0.00068095
Epoch [53/300], Train Loss: 0.000763
Validation Loss: 0.00066210
Epoch [54/300], Train Loss: 0.000750
Validation Loss: 0.00064691
Epoch [55/300], Train Loss: 0.000730
Validation Loss: 0.00063141
Epoch [56/300], Train Loss: 0.000726
Validation Loss: 0.00062969
Epoch [57/300], Train Loss: 0.000710
Validation Loss: 0.00061708
Epoch [58/300], Train Loss: 0.000687
Validation Loss: 0.00060307
Epoch [59/300], Train Loss: 0.000678
Validation Loss: 0.00062293
Epoch [60/300], Train Loss: 0.000677
Validation Loss: 0.00059572
Epoch [61/300], Train Loss: 0.000662
Validation Loss: 0.00058005
Epoch [62/300], Train Loss: 0.000645
Validation Loss: 0.00057723
Epoch [63/300], Train Loss: 0.000632
Validation Loss: 0.00055563
Epoch [64/300], Train Loss: 0.000627
Validation Loss: 0.00057161
Epoch [65/300], Train Loss: 0.000629
Validation Loss: 0.00055078
Epoch [66/300], Train Loss: 0.000632
Validation Loss: 0.00055385
Epoch [67/300], Train Loss: 0.000614
Validation Loss: 0.00054401
Epoch [68/300], Train Loss: 0.000625
Validation Loss: 0.00054283
Epoch [69/300], Train Loss: 0.000609
Validation Loss: 0.00052918
Epoch [70/300], Train Loss: 0.000603
Validation Loss: 0.00052879
Epoch [71/300], Train Loss: 0.000596
Validation Loss: 0.00051955
Epoch [72/300], Train Loss: 0.000593
Validation Loss: 0.00053995
Epoch [73/300], Train Loss: 0.000587
Validation Loss: 0.00051767
Epoch [74/300], Train Loss: 0.000586
Validation Loss: 0.00051483
Epoch [75/300], Train Loss: 0.000582
Validation Loss: 0.00051273
Epoch [76/300], Train Loss: 0.000578
Validation Loss: 0.00050997
Epoch [77/300], Train Loss: 0.000571
Validation Loss: 0.00051534
Epoch [78/300], Train Loss: 0.000572
Validation Loss: 0.00052370
Epoch [79/300], Train Loss: 0.000580
Validation Loss: 0.00050720
Epoch [80/300], Train Loss: 0.000562
Validation Loss: 0.00049722
Epoch [81/300], Train Loss: 0.000553
Validation Loss: 0.00049839
Epoch [82/300], Train Loss: 0.000547
Validation Loss: 0.00048547
Epoch [83/300], Train Loss: 0.000542
Validation Loss: 0.00050948
Epoch [84/300], Train Loss: 0.000552
Validation Loss: 0.00048399
Epoch [85/300], Train Loss: 0.000541
Validation Loss: 0.00046903
Epoch [86/300], Train Loss: 0.000525
Validation Loss: 0.00045868
Epoch [87/300], Train Loss: 0.000530
Validation Loss: 0.00046825
Epoch [88/300], Train Loss: 0.000534
Validation Loss: 0.00046779
Epoch [89/300], Train Loss: 0.000519
Validation Loss: 0.00044141
Epoch [90/300], Train Loss: 0.000516
Validation Loss: 0.00046204
Epoch [91/300], Train Loss: 0.000519
Validation Loss: 0.00045484
Epoch [92/300], Train Loss: 0.000509
Validation Loss: 0.00044184
Epoch [93/300], Train Loss: 0.000494
Validation Loss: 0.00043339
Epoch [94/300], Train Loss: 0.000500
Validation Loss: 0.00043337
Epoch [95/300], Train Loss: 0.000482
Validation Loss: 0.00042758
Epoch [96/300], Train Loss: 0.000478
Validation Loss: 0.00042139
Epoch [97/300], Train Loss: 0.000478
Validation Loss: 0.00042091
Epoch [98/300], Train Loss: 0.000468
Validation Loss: 0.00040032
Epoch [99/300], Train Loss: 0.000460
Validation Loss: 0.00040020
Epoch [100/300], Train Loss: 0.000463
Validation Loss: 0.00038345
Epoch [101/300], Train Loss: 0.000451
Validation Loss: 0.00036773
Epoch [102/300], Train Loss: 0.000433
Validation Loss: 0.00038530
Epoch [103/300], Train Loss: 0.000425
Validation Loss: 0.00034426
Epoch [104/300], Train Loss: 0.000405
Validation Loss: 0.00034321
Epoch [105/300], Train Loss: 0.000393
Validation Loss: 0.00032233
Epoch [106/300], Train Loss: 0.000389
Validation Loss: 0.00032570
Epoch [107/300], Train Loss: 0.000373
Validation Loss: 0.00030881
Epoch [108/300], Train Loss: 0.000366
Validation Loss: 0.00030837
Epoch [109/300], Train Loss: 0.000365
Validation Loss: 0.00029715
Epoch [110/300], Train Loss: 0.000356
Validation Loss: 0.00029807
Epoch [111/300], Train Loss: 0.000354
Validation Loss: 0.00030905
Epoch [112/300], Train Loss: 0.000356
Validation Loss: 0.00029204
Epoch [113/300], Train Loss: 0.000356
Validation Loss: 0.00029622
Epoch [114/300], Train Loss: 0.000345
Validation Loss: 0.00028358
Epoch [115/300], Train Loss: 0.000348
Validation Loss: 0.00028568
Epoch [116/300], Train Loss: 0.000338
Validation Loss: 0.00026876
Epoch [117/300], Train Loss: 0.000335
Validation Loss: 0.00028898
Epoch [118/300], Train Loss: 0.000418
Validation Loss: 0.00033110
Epoch [119/300], Train Loss: 0.000380
Validation Loss: 0.00031042
Epoch [120/300], Train Loss: 0.000362
Validation Loss: 0.00029913
Epoch [121/300], Train Loss: 0.000344
Validation Loss: 0.00029385
Epoch [122/300], Train Loss: 0.000342
Validation Loss: 0.00028636
Epoch [123/300], Train Loss: 0.000335
Validation Loss: 0.00028767
Epoch [124/300], Train Loss: 0.000338
Validation Loss: 0.00029564
Epoch [125/300], Train Loss: 0.000327
Validation Loss: 0.00028580
Epoch [126/300], Train Loss: 0.000330
Validation Loss: 0.00028538
Early stopping triggered

Evaluating model for: Coffee Machine
Run 48/72 completed in 1553.51 seconds with: {'MAE': np.float32(4.6951413), 'MSE': np.float32(1836.9722), 'RMSE': np.float32(42.859913), 'SAE': np.float32(0.07291579), 'NDE': np.float32(0.65164465)}

Run 49/72: hidden=512, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Coffee Machine
Dataset length: 36156 windows

Epoch [1/300], Train Loss: 0.000981
Validation Loss: 0.00093873
Epoch [2/300], Train Loss: 0.000952
Validation Loss: 0.00090271
Epoch [3/300], Train Loss: 0.000898
Validation Loss: 0.00082310
Epoch [4/300], Train Loss: 0.000813
Validation Loss: 0.00075498
Epoch [5/300], Train Loss: 0.000752
Validation Loss: 0.00073745
Epoch [6/300], Train Loss: 0.000706
Validation Loss: 0.00069208
Epoch [7/300], Train Loss: 0.000659
Validation Loss: 0.00064096
Epoch [8/300], Train Loss: 0.000629
Validation Loss: 0.00062016
Epoch [9/300], Train Loss: 0.000598
Validation Loss: 0.00060671
Epoch [10/300], Train Loss: 0.000572
Validation Loss: 0.00056844
Epoch [11/300], Train Loss: 0.000555
Validation Loss: 0.00054428
Epoch [12/300], Train Loss: 0.000531
Validation Loss: 0.00057228
Epoch [13/300], Train Loss: 0.000517
Validation Loss: 0.00051893
Epoch [14/300], Train Loss: 0.000497
Validation Loss: 0.00051441
Epoch [15/300], Train Loss: 0.000475
Validation Loss: 0.00045794
Epoch [16/300], Train Loss: 0.000441
Validation Loss: 0.00041735
Epoch [17/300], Train Loss: 0.000412
Validation Loss: 0.00042859
Epoch [18/300], Train Loss: 0.000388
Validation Loss: 0.00035802
Epoch [19/300], Train Loss: 0.000372
Validation Loss: 0.00035947
Epoch [20/300], Train Loss: 0.000356
Validation Loss: 0.00031221
Epoch [21/300], Train Loss: 0.000341
Validation Loss: 0.00034487
Epoch [22/300], Train Loss: 0.000335
Validation Loss: 0.00031531
Epoch [23/300], Train Loss: 0.000328
Validation Loss: 0.00028559
Epoch [24/300], Train Loss: 0.000308
Validation Loss: 0.00028250
Epoch [25/300], Train Loss: 0.000307
Validation Loss: 0.00029732
Epoch [26/300], Train Loss: 0.000295
Validation Loss: 0.00029054
Epoch [27/300], Train Loss: 0.000294
Validation Loss: 0.00028487
Epoch [28/300], Train Loss: 0.000284
Validation Loss: 0.00025619
Epoch [29/300], Train Loss: 0.000279
Validation Loss: 0.00027169
Epoch [30/300], Train Loss: 0.000269
Validation Loss: 0.00025907
Epoch [31/300], Train Loss: 0.000262
Validation Loss: 0.00024038
Epoch [32/300], Train Loss: 0.000255
Validation Loss: 0.00026654
Epoch [33/300], Train Loss: 0.000265
Validation Loss: 0.00022810
Epoch [34/300], Train Loss: 0.000248
Validation Loss: 0.00025023
Epoch [35/300], Train Loss: 0.000250
Validation Loss: 0.00024575
Epoch [36/300], Train Loss: 0.000265
Validation Loss: 0.00029597
Epoch [37/300], Train Loss: 0.000278
Validation Loss: 0.00023810
Epoch [38/300], Train Loss: 0.000245
Validation Loss: 0.00023572
Epoch [39/300], Train Loss: 0.000237
Validation Loss: 0.00022161
Epoch [40/300], Train Loss: 0.000231
Validation Loss: 0.00021971
Epoch [41/300], Train Loss: 0.000227
Validation Loss: 0.00021745
Epoch [42/300], Train Loss: 0.000221
Validation Loss: 0.00023678
Epoch [43/300], Train Loss: 0.000223
Validation Loss: 0.00020652
Epoch [44/300], Train Loss: 0.000217
Validation Loss: 0.00020853
Epoch [45/300], Train Loss: 0.000223
Validation Loss: 0.00020925
Epoch [46/300], Train Loss: 0.000210
Validation Loss: 0.00018268
Epoch [47/300], Train Loss: 0.000203
Validation Loss: 0.00017676
Epoch [48/300], Train Loss: 0.000210
Validation Loss: 0.00018144
Epoch [49/300], Train Loss: 0.000203
Validation Loss: 0.00018854
Epoch [50/300], Train Loss: 0.000197
Validation Loss: 0.00018869
Epoch [51/300], Train Loss: 0.000200
Validation Loss: 0.00020589
Epoch [52/300], Train Loss: 0.000191
Validation Loss: 0.00018331
Epoch [53/300], Train Loss: 0.000200
Validation Loss: 0.00019879
Epoch [54/300], Train Loss: 0.000197
Validation Loss: 0.00017800
Epoch [55/300], Train Loss: 0.000188
Validation Loss: 0.00017490
Epoch [56/300], Train Loss: 0.000185
Validation Loss: 0.00015830
Epoch [57/300], Train Loss: 0.000180
Validation Loss: 0.00016207
Epoch [58/300], Train Loss: 0.000195
Validation Loss: 0.00016578
Epoch [59/300], Train Loss: 0.000182
Validation Loss: 0.00015927
Epoch [60/300], Train Loss: 0.000179
Validation Loss: 0.00015625
Epoch [61/300], Train Loss: 0.000172
Validation Loss: 0.00016844
Epoch [62/300], Train Loss: 0.000171
Validation Loss: 0.00015233
Epoch [63/300], Train Loss: 0.000177
Validation Loss: 0.00015531
Epoch [64/300], Train Loss: 0.000173
Validation Loss: 0.00014871
Epoch [65/300], Train Loss: 0.000167
Validation Loss: 0.00016122
Epoch [66/300], Train Loss: 0.000165
Validation Loss: 0.00014367
Epoch [67/300], Train Loss: 0.000161
Validation Loss: 0.00013946
Epoch [68/300], Train Loss: 0.000159
Validation Loss: 0.00014967
Epoch [69/300], Train Loss: 0.000171
Validation Loss: 0.00014214
Epoch [70/300], Train Loss: 0.000170
Validation Loss: 0.00013624
Epoch [71/300], Train Loss: 0.000158
Validation Loss: 0.00013953
Epoch [72/300], Train Loss: 0.000157
Validation Loss: 0.00013859
Epoch [73/300], Train Loss: 0.000155
Validation Loss: 0.00014988
Epoch [74/300], Train Loss: 0.000160
Validation Loss: 0.00013333
Epoch [75/300], Train Loss: 0.000151
Validation Loss: 0.00012924
Epoch [76/300], Train Loss: 0.000149
Validation Loss: 0.00012850
Epoch [77/300], Train Loss: 0.000149
Validation Loss: 0.00012925
Epoch [78/300], Train Loss: 0.000151
Validation Loss: 0.00014305
Epoch [79/300], Train Loss: 0.000148
Validation Loss: 0.00013627
Epoch [80/300], Train Loss: 0.000148
Validation Loss: 0.00019314
Epoch [81/300], Train Loss: 0.000156
Validation Loss: 0.00015257
Epoch [82/300], Train Loss: 0.000151
Validation Loss: 0.00012532
Epoch [83/300], Train Loss: 0.000141
Validation Loss: 0.00013529
Epoch [84/300], Train Loss: 0.000140
Validation Loss: 0.00012632
Epoch [85/300], Train Loss: 0.000139
Validation Loss: 0.00012438
Epoch [86/300], Train Loss: 0.000139
Validation Loss: 0.00012254
Epoch [87/300], Train Loss: 0.000137
Validation Loss: 0.00013048
Epoch [88/300], Train Loss: 0.000135
Validation Loss: 0.00013497
Epoch [89/300], Train Loss: 0.000134
Validation Loss: 0.00013378
Epoch [90/300], Train Loss: 0.000138
Validation Loss: 0.00013926
Epoch [91/300], Train Loss: 0.000145
Validation Loss: 0.00012465
Epoch [92/300], Train Loss: 0.000132
Validation Loss: 0.00013030
Epoch [93/300], Train Loss: 0.000130
Validation Loss: 0.00012023
Epoch [94/300], Train Loss: 0.000128
Validation Loss: 0.00012233
Epoch [95/300], Train Loss: 0.000128
Validation Loss: 0.00011870
Epoch [96/300], Train Loss: 0.000127
Validation Loss: 0.00011688
Epoch [97/300], Train Loss: 0.000132
Validation Loss: 0.00012553
Epoch [98/300], Train Loss: 0.000123
Validation Loss: 0.00014904
Epoch [99/300], Train Loss: 0.000137
Validation Loss: 0.00011663
Epoch [100/300], Train Loss: 0.000126
Validation Loss: 0.00011966
Epoch [101/300], Train Loss: 0.000128
Validation Loss: 0.00015644
Epoch [102/300], Train Loss: 0.000125
Validation Loss: 0.00011397
Epoch [103/300], Train Loss: 0.000121
Validation Loss: 0.00011087
Epoch [104/300], Train Loss: 0.000120
Validation Loss: 0.00011135
Epoch [105/300], Train Loss: 0.000120
Validation Loss: 0.00011364
Epoch [106/300], Train Loss: 0.000118
Validation Loss: 0.00010962
Epoch [107/300], Train Loss: 0.000116
Validation Loss: 0.00010997
Epoch [108/300], Train Loss: 0.000115
Validation Loss: 0.00011263
Epoch [109/300], Train Loss: 0.000114
Validation Loss: 0.00011159
Epoch [110/300], Train Loss: 0.000112
Validation Loss: 0.00010720
Epoch [111/300], Train Loss: 0.000113
Validation Loss: 0.00013243
Epoch [112/300], Train Loss: 0.000122
Validation Loss: 0.00010853
Epoch [113/300], Train Loss: 0.000109
Validation Loss: 0.00010852
Epoch [114/300], Train Loss: 0.000113
Validation Loss: 0.00010987
Epoch [115/300], Train Loss: 0.000112
Validation Loss: 0.00010761
Epoch [116/300], Train Loss: 0.000106
Validation Loss: 0.00010817
Epoch [117/300], Train Loss: 0.000105
Validation Loss: 0.00011367
Epoch [118/300], Train Loss: 0.000105
Validation Loss: 0.00010726
Epoch [119/300], Train Loss: 0.000105
Validation Loss: 0.00010939
Epoch [120/300], Train Loss: 0.000103
Validation Loss: 0.00010829
Early stopping triggered

Evaluating model for: Coffee Machine
Run 49/72 completed in 6476.62 seconds with: {'MAE': np.float32(3.1325984), 'MSE': np.float32(503.06226), 'RMSE': np.float32(22.429049), 'SAE': np.float32(0.09278323), 'NDE': np.float32(0.3623993)}

Run 50/72: hidden=512, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Coffee Machine
Dataset length: 36156 windows

Epoch [1/300], Train Loss: 0.000986
Validation Loss: 0.00094749
Epoch [2/300], Train Loss: 0.000974
Validation Loss: 0.00093115
Epoch [3/300], Train Loss: 0.000936
Validation Loss: 0.00086150
Epoch [4/300], Train Loss: 0.000825
Validation Loss: 0.00075274
Epoch [5/300], Train Loss: 0.000734
Validation Loss: 0.00073712
Epoch [6/300], Train Loss: 0.000673
Validation Loss: 0.00066404
Epoch [7/300], Train Loss: 0.000623
Validation Loss: 0.00063329
Epoch [8/300], Train Loss: 0.000597
Validation Loss: 0.00059884
Epoch [9/300], Train Loss: 0.000570
Validation Loss: 0.00060133
Epoch [10/300], Train Loss: 0.000557
Validation Loss: 0.00054913
Epoch [11/300], Train Loss: 0.000543
Validation Loss: 0.00054183
Epoch [12/300], Train Loss: 0.000542
Validation Loss: 0.00058786
Epoch [13/300], Train Loss: 0.000565
Validation Loss: 0.00058045
Epoch [14/300], Train Loss: 0.000530
Validation Loss: 0.00054797
Epoch [15/300], Train Loss: 0.000508
Validation Loss: 0.00051036
Epoch [16/300], Train Loss: 0.000512
Validation Loss: 0.00051157
Epoch [17/300], Train Loss: 0.000493
Validation Loss: 0.00048709
Epoch [18/300], Train Loss: 0.000477
Validation Loss: 0.00046001
Epoch [19/300], Train Loss: 0.000460
Validation Loss: 0.00044326
Epoch [20/300], Train Loss: 0.000439
Validation Loss: 0.00040916
Epoch [21/300], Train Loss: 0.000406
Validation Loss: 0.00038247
Epoch [22/300], Train Loss: 0.000386
Validation Loss: 0.00035531
Epoch [23/300], Train Loss: 0.000362
Validation Loss: 0.00033394
Epoch [24/300], Train Loss: 0.000344
Validation Loss: 0.00032082
Epoch [25/300], Train Loss: 0.000327
Validation Loss: 0.00029559
Epoch [26/300], Train Loss: 0.000314
Validation Loss: 0.00027550
Epoch [27/300], Train Loss: 0.000309
Validation Loss: 0.00027082
Epoch [28/300], Train Loss: 0.000292
Validation Loss: 0.00025824
Epoch [29/300], Train Loss: 0.000287
Validation Loss: 0.00027485
Epoch [30/300], Train Loss: 0.000277
Validation Loss: 0.00024818
Epoch [31/300], Train Loss: 0.000267
Validation Loss: 0.00023407
Epoch [32/300], Train Loss: 0.000261
Validation Loss: 0.00024517
Epoch [33/300], Train Loss: 0.000265
Validation Loss: 0.00022169
Epoch [34/300], Train Loss: 0.000251
Validation Loss: 0.00022280
Epoch [35/300], Train Loss: 0.000248
Validation Loss: 0.00021876
Epoch [36/300], Train Loss: 0.000253
Validation Loss: 0.00022671
Epoch [37/300], Train Loss: 0.000253
Validation Loss: 0.00020561
Epoch [38/300], Train Loss: 0.000233
Validation Loss: 0.00021018
Epoch [39/300], Train Loss: 0.000230
Validation Loss: 0.00019805
Epoch [40/300], Train Loss: 0.000228
Validation Loss: 0.00019654
Epoch [41/300], Train Loss: 0.000223
Validation Loss: 0.00019930
Epoch [42/300], Train Loss: 0.000219
Validation Loss: 0.00018620
Epoch [43/300], Train Loss: 0.000215
Validation Loss: 0.00020170
Epoch [44/300], Train Loss: 0.000214
Validation Loss: 0.00021146
Epoch [45/300], Train Loss: 0.000207
Validation Loss: 0.00018757
Epoch [46/300], Train Loss: 0.000200
Validation Loss: 0.00018009
Epoch [47/300], Train Loss: 0.000205
Validation Loss: 0.00020387
Epoch [48/300], Train Loss: 0.000214
Validation Loss: 0.00018482
Epoch [49/300], Train Loss: 0.000202
Validation Loss: 0.00018289
Epoch [50/300], Train Loss: 0.000190
Validation Loss: 0.00016426
Epoch [51/300], Train Loss: 0.000183
Validation Loss: 0.00015584
Epoch [52/300], Train Loss: 0.000183
Validation Loss: 0.00016079
Epoch [53/300], Train Loss: 0.000186
Validation Loss: 0.00015907
Epoch [54/300], Train Loss: 0.000181
Validation Loss: 0.00015448
Epoch [55/300], Train Loss: 0.000194
Validation Loss: 0.00019576
Epoch [56/300], Train Loss: 0.000180
Validation Loss: 0.00015023
Epoch [57/300], Train Loss: 0.000169
Validation Loss: 0.00014688
Epoch [58/300], Train Loss: 0.000167
Validation Loss: 0.00015244
Epoch [59/300], Train Loss: 0.000169
Validation Loss: 0.00014318
Epoch [60/300], Train Loss: 0.000164
Validation Loss: 0.00015426
Epoch [61/300], Train Loss: 0.000161
Validation Loss: 0.00013995
Epoch [62/300], Train Loss: 0.000159
Validation Loss: 0.00014500
Epoch [63/300], Train Loss: 0.000160
Validation Loss: 0.00014061
Epoch [64/300], Train Loss: 0.000156
Validation Loss: 0.00013522
Epoch [65/300], Train Loss: 0.000165
Validation Loss: 0.00019240
Epoch [66/300], Train Loss: 0.000164
Validation Loss: 0.00014389
Epoch [67/300], Train Loss: 0.000156
Validation Loss: 0.00013394
Epoch [68/300], Train Loss: 0.000151
Validation Loss: 0.00013283
Epoch [69/300], Train Loss: 0.000160
Validation Loss: 0.00013543
Epoch [70/300], Train Loss: 0.000148
Validation Loss: 0.00013204
Epoch [71/300], Train Loss: 0.000153
Validation Loss: 0.00012635
Epoch [72/300], Train Loss: 0.000156
Validation Loss: 0.00012744
Epoch [73/300], Train Loss: 0.000143
Validation Loss: 0.00013105
Epoch [74/300], Train Loss: 0.000140
Validation Loss: 0.00012581
Epoch [75/300], Train Loss: 0.000146
Validation Loss: 0.00012996
Epoch [76/300], Train Loss: 0.000138
Validation Loss: 0.00012039
Epoch [77/300], Train Loss: 0.000136
Validation Loss: 0.00011953
Epoch [78/300], Train Loss: 0.000135
Validation Loss: 0.00011827
Epoch [79/300], Train Loss: 0.000136
Validation Loss: 0.00017164
Epoch [80/300], Train Loss: 0.000134
Validation Loss: 0.00011956
Epoch [81/300], Train Loss: 0.000131
Validation Loss: 0.00011871
Epoch [82/300], Train Loss: 0.000134
Validation Loss: 0.00012584
Epoch [83/300], Train Loss: 0.000132
Validation Loss: 0.00011496
Epoch [84/300], Train Loss: 0.000127
Validation Loss: 0.00011499
Epoch [85/300], Train Loss: 0.000127
Validation Loss: 0.00011304
Epoch [86/300], Train Loss: 0.000131
Validation Loss: 0.00011744
Epoch [87/300], Train Loss: 0.000124
Validation Loss: 0.00011591
Epoch [88/300], Train Loss: 0.000124
Validation Loss: 0.00011330
Epoch [89/300], Train Loss: 0.000122
Validation Loss: 0.00011415
Epoch [90/300], Train Loss: 0.000126
Validation Loss: 0.00019619
Epoch [91/300], Train Loss: 0.000144
Validation Loss: 0.00011365
Epoch [92/300], Train Loss: 0.000121
Validation Loss: 0.00011028
Epoch [93/300], Train Loss: 0.000117
Validation Loss: 0.00010826
Epoch [94/300], Train Loss: 0.000115
Validation Loss: 0.00010760
Epoch [95/300], Train Loss: 0.000114
Validation Loss: 0.00010434
Epoch [96/300], Train Loss: 0.000114
Validation Loss: 0.00010622
Epoch [97/300], Train Loss: 0.000114
Validation Loss: 0.00011107
Epoch [98/300], Train Loss: 0.000111
Validation Loss: 0.00011023
Epoch [99/300], Train Loss: 0.000112
Validation Loss: 0.00010454
Epoch [100/300], Train Loss: 0.000109
Validation Loss: 0.00010907
Epoch [101/300], Train Loss: 0.000108
Validation Loss: 0.00011268
Epoch [102/300], Train Loss: 0.000117
Validation Loss: 0.00011883
Epoch [103/300], Train Loss: 0.000113
Validation Loss: 0.00010357
Epoch [104/300], Train Loss: 0.000107
Validation Loss: 0.00010539
Epoch [105/300], Train Loss: 0.000104
Validation Loss: 0.00010991
Epoch [106/300], Train Loss: 0.000102
Validation Loss: 0.00010189
Epoch [107/300], Train Loss: 0.000100
Validation Loss: 0.00010175
Epoch [108/300], Train Loss: 0.000101
Validation Loss: 0.00011819
Epoch [109/300], Train Loss: 0.000100
Validation Loss: 0.00011501
Epoch [110/300], Train Loss: 0.000098
Validation Loss: 0.00009458
Epoch [111/300], Train Loss: 0.000099
Validation Loss: 0.00009640
Epoch [112/300], Train Loss: 0.000096
Validation Loss: 0.00011056
Epoch [113/300], Train Loss: 0.000097
Validation Loss: 0.00009633
Epoch [114/300], Train Loss: 0.000097
Validation Loss: 0.00009713
Epoch [115/300], Train Loss: 0.000093
Validation Loss: 0.00009837
Epoch [116/300], Train Loss: 0.000094
Validation Loss: 0.00010086
Epoch [117/300], Train Loss: 0.000094
Validation Loss: 0.00011044
Epoch [118/300], Train Loss: 0.000091
Validation Loss: 0.00011035
Epoch [119/300], Train Loss: 0.000091
Validation Loss: 0.00009658
Epoch [120/300], Train Loss: 0.000092
Validation Loss: 0.00021539
Early stopping triggered

Evaluating model for: Coffee Machine
Run 50/72 completed in 7058.40 seconds with: {'MAE': np.float32(2.9895825), 'MSE': np.float32(603.2938), 'RMSE': np.float32(24.56204), 'SAE': np.float32(0.0097216545), 'NDE': np.float32(0.3968634)}

Run 51/72: hidden=512, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Coffee Machine
Dataset length: 36156 windows

Epoch [1/300], Train Loss: 0.000984
Validation Loss: 0.00095005
Epoch [2/300], Train Loss: 0.000977
Validation Loss: 0.00093772
Epoch [3/300], Train Loss: 0.000941
Validation Loss: 0.00085727
Epoch [4/300], Train Loss: 0.000806
Validation Loss: 0.00075414
Epoch [5/300], Train Loss: 0.000721
Validation Loss: 0.00070527
Epoch [6/300], Train Loss: 0.000677
Validation Loss: 0.00065665
Epoch [7/300], Train Loss: 0.000618
Validation Loss: 0.00060696
Epoch [8/300], Train Loss: 0.000581
Validation Loss: 0.00053558
Epoch [9/300], Train Loss: 0.000521
Validation Loss: 0.00052829
Epoch [10/300], Train Loss: 0.000467
Validation Loss: 0.00044026
Epoch [11/300], Train Loss: 0.000452
Validation Loss: 0.00042185
Epoch [12/300], Train Loss: 0.000440
Validation Loss: 0.00042053
Epoch [13/300], Train Loss: 0.000404
Validation Loss: 0.00035717
Epoch [14/300], Train Loss: 0.000385
Validation Loss: 0.00033833
Epoch [15/300], Train Loss: 0.000375
Validation Loss: 0.00032541
Epoch [16/300], Train Loss: 0.000355
Validation Loss: 0.00031898
Epoch [17/300], Train Loss: 0.000350
Validation Loss: 0.00030691
Epoch [18/300], Train Loss: 0.000348
Validation Loss: 0.00030859
Epoch [19/300], Train Loss: 0.000332
Validation Loss: 0.00029681
Epoch [20/300], Train Loss: 0.000321
Validation Loss: 0.00030203
Epoch [21/300], Train Loss: 0.000321
Validation Loss: 0.00030433
Epoch [22/300], Train Loss: 0.000309
Validation Loss: 0.00028889
Epoch [23/300], Train Loss: 0.000300
Validation Loss: 0.00031189
Epoch [24/300], Train Loss: 0.000299
Validation Loss: 0.00028390
Epoch [25/300], Train Loss: 0.000295
Validation Loss: 0.00029149
Epoch [26/300], Train Loss: 0.000294
Validation Loss: 0.00027730
Epoch [27/300], Train Loss: 0.000287
Validation Loss: 0.00028921
Epoch [28/300], Train Loss: 0.000277
Validation Loss: 0.00027058
Epoch [29/300], Train Loss: 0.000272
Validation Loss: 0.00028175
Epoch [30/300], Train Loss: 0.000264
Validation Loss: 0.00026497
Epoch [31/300], Train Loss: 0.000260
Validation Loss: 0.00024431
Epoch [32/300], Train Loss: 0.000248
Validation Loss: 0.00025415
Epoch [33/300], Train Loss: 0.000249
Validation Loss: 0.00024833
Epoch [34/300], Train Loss: 0.000245
Validation Loss: 0.00024108
Epoch [35/300], Train Loss: 0.000237
Validation Loss: 0.00023218
Epoch [36/300], Train Loss: 0.000238
Validation Loss: 0.00023824
Epoch [37/300], Train Loss: 0.000226
Validation Loss: 0.00026348
Epoch [38/300], Train Loss: 0.000237
Validation Loss: 0.00023447
Epoch [39/300], Train Loss: 0.000223
Validation Loss: 0.00021826
Epoch [40/300], Train Loss: 0.000214
Validation Loss: 0.00021565
Epoch [41/300], Train Loss: 0.000214
Validation Loss: 0.00021229
Epoch [42/300], Train Loss: 0.000209
Validation Loss: 0.00020154
Epoch [43/300], Train Loss: 0.000202
Validation Loss: 0.00019517
Epoch [44/300], Train Loss: 0.000201
Validation Loss: 0.00021049
Epoch [45/300], Train Loss: 0.000196
Validation Loss: 0.00020680
Epoch [46/300], Train Loss: 0.000200
Validation Loss: 0.00020504
Epoch [47/300], Train Loss: 0.000192
Validation Loss: 0.00019524
Epoch [48/300], Train Loss: 0.000197
Validation Loss: 0.00020834
Epoch [49/300], Train Loss: 0.000186
Validation Loss: 0.00018217
Epoch [50/300], Train Loss: 0.000176
Validation Loss: 0.00017500
Epoch [51/300], Train Loss: 0.000172
Validation Loss: 0.00017985
Epoch [52/300], Train Loss: 0.000171
Validation Loss: 0.00017725
Epoch [53/300], Train Loss: 0.000182
Validation Loss: 0.00018187
Epoch [54/300], Train Loss: 0.000174
Validation Loss: 0.00018293
Epoch [55/300], Train Loss: 0.000166
Validation Loss: 0.00015873
Epoch [56/300], Train Loss: 0.000160
Validation Loss: 0.00015312
Epoch [57/300], Train Loss: 0.000158
Validation Loss: 0.00015725
Epoch [58/300], Train Loss: 0.000167
Validation Loss: 0.00016589
Epoch [59/300], Train Loss: 0.000159
Validation Loss: 0.00014882
Epoch [60/300], Train Loss: 0.000152
Validation Loss: 0.00015983
Epoch [61/300], Train Loss: 0.000162
Validation Loss: 0.00017556
Epoch [62/300], Train Loss: 0.000150
Validation Loss: 0.00015454
Epoch [63/300], Train Loss: 0.000150
Validation Loss: 0.00014511
Epoch [64/300], Train Loss: 0.000142
Validation Loss: 0.00014326
Epoch [65/300], Train Loss: 0.000140
Validation Loss: 0.00013435
Epoch [66/300], Train Loss: 0.000139
Validation Loss: 0.00014184
Epoch [67/300], Train Loss: 0.000134
Validation Loss: 0.00013410
Epoch [68/300], Train Loss: 0.000134
Validation Loss: 0.00013040
Epoch [69/300], Train Loss: 0.000134
Validation Loss: 0.00014885
Epoch [70/300], Train Loss: 0.000145
Validation Loss: 0.00013776
Epoch [71/300], Train Loss: 0.000134
Validation Loss: 0.00013565
Epoch [72/300], Train Loss: 0.000126
Validation Loss: 0.00012386
Epoch [73/300], Train Loss: 0.000174
Validation Loss: 0.00014849
Epoch [74/300], Train Loss: 0.000131
Validation Loss: 0.00013619
Epoch [75/300], Train Loss: 0.000125
Validation Loss: 0.00012795
Epoch [76/300], Train Loss: 0.000123
Validation Loss: 0.00012644
Epoch [77/300], Train Loss: 0.000120
Validation Loss: 0.00012796
Epoch [78/300], Train Loss: 0.000140
Validation Loss: 0.00017164
Epoch [79/300], Train Loss: 0.000133
Validation Loss: 0.00012953
Epoch [80/300], Train Loss: 0.000122
Validation Loss: 0.00012028
Epoch [81/300], Train Loss: 0.000114
Validation Loss: 0.00012056
Epoch [82/300], Train Loss: 0.000116
Validation Loss: 0.00011876
Epoch [83/300], Train Loss: 0.000114
Validation Loss: 0.00011730
Epoch [84/300], Train Loss: 0.000111
Validation Loss: 0.00011742
Epoch [85/300], Train Loss: 0.000110
Validation Loss: 0.00011232
Epoch [86/300], Train Loss: 0.000110
Validation Loss: 0.00011600
Epoch [87/300], Train Loss: 0.000108
Validation Loss: 0.00011175
Epoch [88/300], Train Loss: 0.000107
Validation Loss: 0.00011074
Epoch [89/300], Train Loss: 0.000105
Validation Loss: 0.00011113
Epoch [90/300], Train Loss: 0.000104
Validation Loss: 0.00011666
Epoch [91/300], Train Loss: 0.000103
Validation Loss: 0.00010951
Epoch [92/300], Train Loss: 0.000101
Validation Loss: 0.00012198
Epoch [93/300], Train Loss: 0.000100
Validation Loss: 0.00012181
Epoch [94/300], Train Loss: 0.000099
Validation Loss: 0.00010787
Epoch [95/300], Train Loss: 0.000096
Validation Loss: 0.00010913
Epoch [96/300], Train Loss: 0.000096
Validation Loss: 0.00010970
Epoch [97/300], Train Loss: 0.000094
Validation Loss: 0.00010682
Epoch [98/300], Train Loss: 0.000092
Validation Loss: 0.00010426
Epoch [99/300], Train Loss: 0.000093
Validation Loss: 0.00010508
Epoch [100/300], Train Loss: 0.000096
Validation Loss: 0.00010473
Epoch [101/300], Train Loss: 0.000095
Validation Loss: 0.00011250
Epoch [102/300], Train Loss: 0.000090
Validation Loss: 0.00010300
Epoch [103/300], Train Loss: 0.000089
Validation Loss: 0.00010135
Epoch [104/300], Train Loss: 0.000087
Validation Loss: 0.00010178
Epoch [105/300], Train Loss: 0.000087
Validation Loss: 0.00009985
Epoch [106/300], Train Loss: 0.000084
Validation Loss: 0.00009692
Epoch [107/300], Train Loss: 0.000083
Validation Loss: 0.00009571
Epoch [108/300], Train Loss: 0.000082
Validation Loss: 0.00010739
Epoch [109/300], Train Loss: 0.000083
Validation Loss: 0.00009789
Epoch [110/300], Train Loss: 0.000081
Validation Loss: 0.00010112
Epoch [111/300], Train Loss: 0.000080
Validation Loss: 0.00009950
Epoch [112/300], Train Loss: 0.000079
Validation Loss: 0.00009592
Epoch [113/300], Train Loss: 0.000082
Validation Loss: 0.00009597
Epoch [114/300], Train Loss: 0.000079
Validation Loss: 0.00009483
Epoch [115/300], Train Loss: 0.000077
Validation Loss: 0.00009438
Epoch [116/300], Train Loss: 0.000079
Validation Loss: 0.00009381
Epoch [117/300], Train Loss: 0.000076
Validation Loss: 0.00009330
Epoch [118/300], Train Loss: 0.000075
Validation Loss: 0.00009778
Epoch [119/300], Train Loss: 0.000077
Validation Loss: 0.00009437
Epoch [120/300], Train Loss: 0.000076
Validation Loss: 0.00009083
Epoch [121/300], Train Loss: 0.000072
Validation Loss: 0.00009189
Epoch [122/300], Train Loss: 0.000091
Validation Loss: 0.00009449
Epoch [123/300], Train Loss: 0.000072
Validation Loss: 0.00008968
Epoch [124/300], Train Loss: 0.000070
Validation Loss: 0.00008849
Epoch [125/300], Train Loss: 0.000069
Validation Loss: 0.00009083
Epoch [126/300], Train Loss: 0.000069
Validation Loss: 0.00008845
Epoch [127/300], Train Loss: 0.000069
Validation Loss: 0.00009162
Epoch [128/300], Train Loss: 0.000068
Validation Loss: 0.00009037
Epoch [129/300], Train Loss: 0.000069
Validation Loss: 0.00008792
Epoch [130/300], Train Loss: 0.000066
Validation Loss: 0.00008946
Epoch [131/300], Train Loss: 0.000068
Validation Loss: 0.00008866
Epoch [132/300], Train Loss: 0.000066
Validation Loss: 0.00008866
Epoch [133/300], Train Loss: 0.000066
Validation Loss: 0.00009368
Epoch [134/300], Train Loss: 0.000066
Validation Loss: 0.00008900
Epoch [135/300], Train Loss: 0.000064
Validation Loss: 0.00008766
Epoch [136/300], Train Loss: 0.000064
Validation Loss: 0.00008974
Epoch [137/300], Train Loss: 0.000066
Validation Loss: 0.00008862
Epoch [138/300], Train Loss: 0.000074
Validation Loss: 0.00010822
Epoch [139/300], Train Loss: 0.000066
Validation Loss: 0.00008901
Epoch [140/300], Train Loss: 0.000062
Validation Loss: 0.00008718
Epoch [141/300], Train Loss: 0.000061
Validation Loss: 0.00008512
Epoch [142/300], Train Loss: 0.000061
Validation Loss: 0.00010212
Epoch [143/300], Train Loss: 0.000061
Validation Loss: 0.00009490
Epoch [144/300], Train Loss: 0.000062
Validation Loss: 0.00008387
Epoch [145/300], Train Loss: 0.000061
Validation Loss: 0.00008541
Epoch [146/300], Train Loss: 0.000061
Validation Loss: 0.00008765
Epoch [147/300], Train Loss: 0.000059
Validation Loss: 0.00008482
Epoch [148/300], Train Loss: 0.000060
Validation Loss: 0.00008754
Epoch [149/300], Train Loss: 0.000058
Validation Loss: 0.00008661
Epoch [150/300], Train Loss: 0.000058
Validation Loss: 0.00008435
Epoch [151/300], Train Loss: 0.000059
Validation Loss: 0.00008492
Epoch [152/300], Train Loss: 0.000058
Validation Loss: 0.00008306
Epoch [153/300], Train Loss: 0.000057
Validation Loss: 0.00009057
Epoch [154/300], Train Loss: 0.000058
Validation Loss: 0.00008119
Epoch [155/300], Train Loss: 0.000056
Validation Loss: 0.00008328
Epoch [156/300], Train Loss: 0.000056
Validation Loss: 0.00008275
Epoch [157/300], Train Loss: 0.000056
Validation Loss: 0.00007991
Epoch [158/300], Train Loss: 0.000055
Validation Loss: 0.00008001
Epoch [159/300], Train Loss: 0.000056
Validation Loss: 0.00007918
Epoch [160/300], Train Loss: 0.000055
Validation Loss: 0.00008011
Epoch [161/300], Train Loss: 0.000058
Validation Loss: 0.00009352
Epoch [162/300], Train Loss: 0.000055
Validation Loss: 0.00008017
Epoch [163/300], Train Loss: 0.000054
Validation Loss: 0.00010057
Epoch [164/300], Train Loss: 0.000054
Validation Loss: 0.00008226
Epoch [165/300], Train Loss: 0.000055
Validation Loss: 0.00007988
Epoch [166/300], Train Loss: 0.000052
Validation Loss: 0.00008132
Epoch [167/300], Train Loss: 0.000056
Validation Loss: 0.00009506
Epoch [168/300], Train Loss: 0.000055
Validation Loss: 0.00008217
Epoch [169/300], Train Loss: 0.000053
Validation Loss: 0.00009152
Early stopping triggered

Evaluating model for: Coffee Machine
Run 51/72 completed in 10717.24 seconds with: {'MAE': np.float32(1.8279153), 'MSE': np.float32(361.923), 'RMSE': np.float32(19.024275), 'SAE': np.float32(0.013429025), 'NDE': np.float32(0.30738458)}

Run 52/72: hidden=512, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Coffee Machine
Dataset length: 36156 windows

Epoch [1/300], Train Loss: 0.000989
Validation Loss: 0.00094990
Epoch [2/300], Train Loss: 0.000983
Validation Loss: 0.00094871
Epoch [3/300], Train Loss: 0.000980
Validation Loss: 0.00094296
Epoch [4/300], Train Loss: 0.000949
Validation Loss: 0.00085213
Epoch [5/300], Train Loss: 0.000789
Validation Loss: 0.00073098
Epoch [6/300], Train Loss: 0.000687
Validation Loss: 0.00066107
Epoch [7/300], Train Loss: 0.000621
Validation Loss: 0.00060683
Epoch [8/300], Train Loss: 0.000590
Validation Loss: 0.00053889
Epoch [9/300], Train Loss: 0.000493
Validation Loss: 0.00050157
Epoch [10/300], Train Loss: 0.000446
Validation Loss: 0.00041323
Epoch [11/300], Train Loss: 0.000406
Validation Loss: 0.00036209
Epoch [12/300], Train Loss: 0.000381
Validation Loss: 0.00045244
Epoch [13/300], Train Loss: 0.000368
Validation Loss: 0.00035653
Epoch [14/300], Train Loss: 0.000361
Validation Loss: 0.00034108
Epoch [15/300], Train Loss: 0.000341
Validation Loss: 0.00031598
Epoch [16/300], Train Loss: 0.000324
Validation Loss: 0.00030560
Epoch [17/300], Train Loss: 0.000316
Validation Loss: 0.00029763
Epoch [18/300], Train Loss: 0.000311
Validation Loss: 0.00031667
Epoch [19/300], Train Loss: 0.000304
Validation Loss: 0.00030769
Epoch [20/300], Train Loss: 0.000295
Validation Loss: 0.00028530
Epoch [21/300], Train Loss: 0.000294
Validation Loss: 0.00029959
Epoch [22/300], Train Loss: 0.000295
Validation Loss: 0.00028955
Epoch [23/300], Train Loss: 0.000281
Validation Loss: 0.00027703
Epoch [24/300], Train Loss: 0.000272
Validation Loss: 0.00026410
Epoch [25/300], Train Loss: 0.000255
Validation Loss: 0.00026139
Epoch [26/300], Train Loss: 0.000256
Validation Loss: 0.00024426
Epoch [27/300], Train Loss: 0.000253
Validation Loss: 0.00026116
Epoch [28/300], Train Loss: 0.000244
Validation Loss: 0.00023467
Epoch [29/300], Train Loss: 0.000234
Validation Loss: 0.00024554
Epoch [30/300], Train Loss: 0.000229
Validation Loss: 0.00024451
Epoch [31/300], Train Loss: 0.000230
Validation Loss: 0.00022682
Epoch [32/300], Train Loss: 0.000220
Validation Loss: 0.00023432
Epoch [33/300], Train Loss: 0.000218
Validation Loss: 0.00024065
Epoch [34/300], Train Loss: 0.000220
Validation Loss: 0.00020939
Epoch [35/300], Train Loss: 0.000207
Validation Loss: 0.00021060
Epoch [36/300], Train Loss: 0.000217
Validation Loss: 0.00022197
Epoch [37/300], Train Loss: 0.000203
Validation Loss: 0.00020417
Epoch [38/300], Train Loss: 0.000201
Validation Loss: 0.00021254
Epoch [39/300], Train Loss: 0.000196
Validation Loss: 0.00019991
Epoch [40/300], Train Loss: 0.000190
Validation Loss: 0.00019302
Epoch [41/300], Train Loss: 0.000207
Validation Loss: 0.00022082
Epoch [42/300], Train Loss: 0.000191
Validation Loss: 0.00020034
Epoch [43/300], Train Loss: 0.000191
Validation Loss: 0.00019103
Epoch [44/300], Train Loss: 0.000186
Validation Loss: 0.00019551
Epoch [45/300], Train Loss: 0.000177
Validation Loss: 0.00018233
Epoch [46/300], Train Loss: 0.000180
Validation Loss: 0.00017022
Epoch [47/300], Train Loss: 0.000166
Validation Loss: 0.00017449
Epoch [48/300], Train Loss: 0.000164
Validation Loss: 0.00016555
Epoch [49/300], Train Loss: 0.000160
Validation Loss: 0.00017373
Epoch [50/300], Train Loss: 0.000165
Validation Loss: 0.00016650
Epoch [51/300], Train Loss: 0.000164
Validation Loss: 0.00016336
Epoch [52/300], Train Loss: 0.000156
Validation Loss: 0.00015857
Epoch [53/300], Train Loss: 0.000155
Validation Loss: 0.00016761
Epoch [54/300], Train Loss: 0.000148
Validation Loss: 0.00015650
Epoch [55/300], Train Loss: 0.000146
Validation Loss: 0.00015303
Epoch [56/300], Train Loss: 0.000145
Validation Loss: 0.00015168
Epoch [57/300], Train Loss: 0.000145
Validation Loss: 0.00015212
Epoch [58/300], Train Loss: 0.000142
Validation Loss: 0.00015020
Epoch [59/300], Train Loss: 0.000147
Validation Loss: 0.00014782
Epoch [60/300], Train Loss: 0.000138
Validation Loss: 0.00014875
Epoch [61/300], Train Loss: 0.000132
Validation Loss: 0.00014722
Epoch [62/300], Train Loss: 0.000131
Validation Loss: 0.00015366
Epoch [63/300], Train Loss: 0.000159
Validation Loss: 0.00019263
Epoch [64/300], Train Loss: 0.000151
Validation Loss: 0.00014613
Epoch [65/300], Train Loss: 0.000128
Validation Loss: 0.00013929
Epoch [66/300], Train Loss: 0.000125
Validation Loss: 0.00013794
Epoch [67/300], Train Loss: 0.000125
Validation Loss: 0.00014023
Epoch [68/300], Train Loss: 0.000122
Validation Loss: 0.00013551
Epoch [69/300], Train Loss: 0.000120
Validation Loss: 0.00013486
Epoch [70/300], Train Loss: 0.000117
Validation Loss: 0.00013484
Epoch [71/300], Train Loss: 0.000118
Validation Loss: 0.00013822
Epoch [72/300], Train Loss: 0.000120
Validation Loss: 0.00013806
Epoch [73/300], Train Loss: 0.000115
Validation Loss: 0.00013871
Epoch [74/300], Train Loss: 0.000113
Validation Loss: 0.00013322
Epoch [75/300], Train Loss: 0.000111
Validation Loss: 0.00013842
Epoch [76/300], Train Loss: 0.000113
Validation Loss: 0.00014176
Epoch [77/300], Train Loss: 0.000115
Validation Loss: 0.00013058
Epoch [78/300], Train Loss: 0.000106
Validation Loss: 0.00012637
Epoch [79/300], Train Loss: 0.000104
Validation Loss: 0.00014119
Epoch [80/300], Train Loss: 0.000104
Validation Loss: 0.00012830
Epoch [81/300], Train Loss: 0.000105
Validation Loss: 0.00016418
Epoch [82/300], Train Loss: 0.000107
Validation Loss: 0.00012462
Epoch [83/300], Train Loss: 0.000100
Validation Loss: 0.00012561
Epoch [84/300], Train Loss: 0.000101
Validation Loss: 0.00012452
Epoch [85/300], Train Loss: 0.000098
Validation Loss: 0.00011994
Epoch [86/300], Train Loss: 0.000096
Validation Loss: 0.00012309
Epoch [87/300], Train Loss: 0.000094
Validation Loss: 0.00012105
Epoch [88/300], Train Loss: 0.000094
Validation Loss: 0.00012184
Epoch [89/300], Train Loss: 0.000092
Validation Loss: 0.00012199
Epoch [90/300], Train Loss: 0.000102
Validation Loss: 0.00012108
Epoch [91/300], Train Loss: 0.000089
Validation Loss: 0.00011602
Epoch [92/300], Train Loss: 0.000087
Validation Loss: 0.00011501
Epoch [93/300], Train Loss: 0.000087
Validation Loss: 0.00011668
Epoch [94/300], Train Loss: 0.000087
Validation Loss: 0.00014253
Epoch [95/300], Train Loss: 0.000086
Validation Loss: 0.00011095
Epoch [96/300], Train Loss: 0.000083
Validation Loss: 0.00011130
Epoch [97/300], Train Loss: 0.000094
Validation Loss: 0.00011454
Epoch [98/300], Train Loss: 0.000083
Validation Loss: 0.00011005
Epoch [99/300], Train Loss: 0.000080
Validation Loss: 0.00011462
Epoch [100/300], Train Loss: 0.000107
Validation Loss: 0.00011139
Epoch [101/300], Train Loss: 0.000080
Validation Loss: 0.00011007
Epoch [102/300], Train Loss: 0.000078
Validation Loss: 0.00010748
Epoch [103/300], Train Loss: 0.000078
Validation Loss: 0.00010911
Epoch [104/300], Train Loss: 0.000077
Validation Loss: 0.00010666
Epoch [105/300], Train Loss: 0.000077
Validation Loss: 0.00010710
Epoch [106/300], Train Loss: 0.000074
Validation Loss: 0.00010580
Epoch [107/300], Train Loss: 0.000074
Validation Loss: 0.00010097
Epoch [108/300], Train Loss: 0.000074
Validation Loss: 0.00010591
Epoch [109/300], Train Loss: 0.000073
Validation Loss: 0.00010569
Epoch [110/300], Train Loss: 0.000074
Validation Loss: 0.00010654
Epoch [111/300], Train Loss: 0.000075
Validation Loss: 0.00010276
Epoch [112/300], Train Loss: 0.000078
Validation Loss: 0.00009723
Epoch [113/300], Train Loss: 0.000071
Validation Loss: 0.00010029
Epoch [114/300], Train Loss: 0.000069
Validation Loss: 0.00009900
Epoch [115/300], Train Loss: 0.000069
Validation Loss: 0.00010426
Epoch [116/300], Train Loss: 0.000075
Validation Loss: 0.00009912
Epoch [117/300], Train Loss: 0.000068
Validation Loss: 0.00010968
Epoch [118/300], Train Loss: 0.000069
Validation Loss: 0.00009680
Epoch [119/300], Train Loss: 0.000067
Validation Loss: 0.00009657
Epoch [120/300], Train Loss: 0.000066
Validation Loss: 0.00009831
Epoch [121/300], Train Loss: 0.000065
Validation Loss: 0.00009740
Epoch [122/300], Train Loss: 0.000065
Validation Loss: 0.00010058
Epoch [123/300], Train Loss: 0.000072
Validation Loss: 0.00011891
Epoch [124/300], Train Loss: 0.000078
Validation Loss: 0.00009828
Epoch [125/300], Train Loss: 0.000064
Validation Loss: 0.00009484
Epoch [126/300], Train Loss: 0.000067
Validation Loss: 0.00009412
Epoch [127/300], Train Loss: 0.000086
Validation Loss: 0.00014652
Epoch [128/300], Train Loss: 0.000075
Validation Loss: 0.00009797
Epoch [129/300], Train Loss: 0.000064
Validation Loss: 0.00009516
Epoch [130/300], Train Loss: 0.000062
Validation Loss: 0.00009463
Epoch [131/300], Train Loss: 0.000062
Validation Loss: 0.00009435
Epoch [132/300], Train Loss: 0.000062
Validation Loss: 0.00009570
Epoch [133/300], Train Loss: 0.000063
Validation Loss: 0.00009480
Epoch [134/300], Train Loss: 0.000062
Validation Loss: 0.00009551
Epoch [135/300], Train Loss: 0.000060
Validation Loss: 0.00009531
Epoch [136/300], Train Loss: 0.000071
Validation Loss: 0.00009565
Early stopping triggered

Evaluating model for: Coffee Machine
Run 52/72 completed in 9738.27 seconds with: {'MAE': np.float32(1.9525127), 'MSE': np.float32(506.67282), 'RMSE': np.float32(22.509394), 'SAE': np.float32(0.08453569), 'NDE': np.float32(0.36369523)}

Run 53/72: hidden=512, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Coffee Machine
Dataset length: 18100 windows

Epoch [1/300], Train Loss: 0.001003
Validation Loss: 0.00093646
Epoch [2/300], Train Loss: 0.000966
Validation Loss: 0.00093089
Epoch [3/300], Train Loss: 0.000979
Validation Loss: 0.00092172
Epoch [4/300], Train Loss: 0.000961
Validation Loss: 0.00091182
Epoch [5/300], Train Loss: 0.000939
Validation Loss: 0.00089878
Epoch [6/300], Train Loss: 0.000928
Validation Loss: 0.00087947
Epoch [7/300], Train Loss: 0.000896
Validation Loss: 0.00084797
Epoch [8/300], Train Loss: 0.000857
Validation Loss: 0.00081306
Epoch [9/300], Train Loss: 0.000825
Validation Loss: 0.00078283
Epoch [10/300], Train Loss: 0.000789
Validation Loss: 0.00075348
Epoch [11/300], Train Loss: 0.000752
Validation Loss: 0.00076349
Epoch [12/300], Train Loss: 0.000765
Validation Loss: 0.00073218
Epoch [13/300], Train Loss: 0.000744
Validation Loss: 0.00073082
Epoch [14/300], Train Loss: 0.000716
Validation Loss: 0.00069244
Epoch [15/300], Train Loss: 0.000687
Validation Loss: 0.00065821
Epoch [16/300], Train Loss: 0.000670
Validation Loss: 0.00065332
Epoch [17/300], Train Loss: 0.000652
Validation Loss: 0.00063266
Epoch [18/300], Train Loss: 0.000644
Validation Loss: 0.00063168
Epoch [19/300], Train Loss: 0.000626
Validation Loss: 0.00060552
Epoch [20/300], Train Loss: 0.000618
Validation Loss: 0.00060233
Epoch [21/300], Train Loss: 0.000608
Validation Loss: 0.00058798
Epoch [22/300], Train Loss: 0.000589
Validation Loss: 0.00058593
Epoch [23/300], Train Loss: 0.000612
Validation Loss: 0.00057720
Epoch [24/300], Train Loss: 0.000575
Validation Loss: 0.00056236
Epoch [25/300], Train Loss: 0.000564
Validation Loss: 0.00053503
Epoch [26/300], Train Loss: 0.000556
Validation Loss: 0.00053901
Epoch [27/300], Train Loss: 0.000569
Validation Loss: 0.00055575
Epoch [28/300], Train Loss: 0.000560
Validation Loss: 0.00050812
Epoch [29/300], Train Loss: 0.000532
Validation Loss: 0.00050236
Epoch [30/300], Train Loss: 0.000513
Validation Loss: 0.00051974
Epoch [31/300], Train Loss: 0.000497
Validation Loss: 0.00048569
Epoch [32/300], Train Loss: 0.000479
Validation Loss: 0.00046536
Epoch [33/300], Train Loss: 0.000459
Validation Loss: 0.00040981
Epoch [34/300], Train Loss: 0.000450
Validation Loss: 0.00040702
Epoch [35/300], Train Loss: 0.000438
Validation Loss: 0.00041144
Epoch [36/300], Train Loss: 0.000427
Validation Loss: 0.00037075
Epoch [37/300], Train Loss: 0.000402
Validation Loss: 0.00035929
Epoch [38/300], Train Loss: 0.000403
Validation Loss: 0.00035043
Epoch [39/300], Train Loss: 0.000383
Validation Loss: 0.00033965
Epoch [40/300], Train Loss: 0.000382
Validation Loss: 0.00038225
Epoch [41/300], Train Loss: 0.000374
Validation Loss: 0.00037320
Epoch [42/300], Train Loss: 0.000371
Validation Loss: 0.00037474
Epoch [43/300], Train Loss: 0.000360
Validation Loss: 0.00036452
Epoch [44/300], Train Loss: 0.000352
Validation Loss: 0.00034338
Epoch [45/300], Train Loss: 0.000352
Validation Loss: 0.00034932
Epoch [46/300], Train Loss: 0.000354
Validation Loss: 0.00037423
Epoch [47/300], Train Loss: 0.000366
Validation Loss: 0.00034615
Epoch [48/300], Train Loss: 0.000345
Validation Loss: 0.00031695
Epoch [49/300], Train Loss: 0.000326
Validation Loss: 0.00031191
Epoch [50/300], Train Loss: 0.000325
Validation Loss: 0.00031692
Epoch [51/300], Train Loss: 0.000327
Validation Loss: 0.00029616
Epoch [52/300], Train Loss: 0.000318
Validation Loss: 0.00030148
Epoch [53/300], Train Loss: 0.000320
Validation Loss: 0.00030082
Epoch [54/300], Train Loss: 0.000317
Validation Loss: 0.00029405
Epoch [55/300], Train Loss: 0.000306
Validation Loss: 0.00027254
Epoch [56/300], Train Loss: 0.000291
Validation Loss: 0.00029525
Epoch [57/300], Train Loss: 0.000296
Validation Loss: 0.00028129
Epoch [58/300], Train Loss: 0.000296
Validation Loss: 0.00028789
Epoch [59/300], Train Loss: 0.000285
Validation Loss: 0.00027230
Epoch [60/300], Train Loss: 0.000293
Validation Loss: 0.00027351
Epoch [61/300], Train Loss: 0.000301
Validation Loss: 0.00029758
Epoch [62/300], Train Loss: 0.000282
Validation Loss: 0.00027409
Epoch [63/300], Train Loss: 0.000282
Validation Loss: 0.00027181
Epoch [64/300], Train Loss: 0.000275
Validation Loss: 0.00026379
Epoch [65/300], Train Loss: 0.000268
Validation Loss: 0.00027807
Epoch [66/300], Train Loss: 0.000277
Validation Loss: 0.00028328
Epoch [67/300], Train Loss: 0.000280
Validation Loss: 0.00025720
Epoch [68/300], Train Loss: 0.000267
Validation Loss: 0.00028091
Epoch [69/300], Train Loss: 0.000264
Validation Loss: 0.00025999
Epoch [70/300], Train Loss: 0.000261
Validation Loss: 0.00024848
Epoch [71/300], Train Loss: 0.000258
Validation Loss: 0.00026442
Epoch [72/300], Train Loss: 0.000299
Validation Loss: 0.00026459
Epoch [73/300], Train Loss: 0.000273
Validation Loss: 0.00026227
Epoch [74/300], Train Loss: 0.000253
Validation Loss: 0.00024948
Epoch [75/300], Train Loss: 0.000248
Validation Loss: 0.00024724
Epoch [76/300], Train Loss: 0.000244
Validation Loss: 0.00024063
Epoch [77/300], Train Loss: 0.000249
Validation Loss: 0.00025946
Epoch [78/300], Train Loss: 0.000257
Validation Loss: 0.00025929
Epoch [79/300], Train Loss: 0.000266
Validation Loss: 0.00026524
Epoch [80/300], Train Loss: 0.000264
Validation Loss: 0.00024772
Epoch [81/300], Train Loss: 0.000244
Validation Loss: 0.00023473
Epoch [82/300], Train Loss: 0.000234
Validation Loss: 0.00024083
Epoch [83/300], Train Loss: 0.000238
Validation Loss: 0.00023714
Epoch [84/300], Train Loss: 0.000234
Validation Loss: 0.00023863
Epoch [85/300], Train Loss: 0.000241
Validation Loss: 0.00022995
Epoch [86/300], Train Loss: 0.000241
Validation Loss: 0.00023858
Epoch [87/300], Train Loss: 0.000229
Validation Loss: 0.00024238
Epoch [88/300], Train Loss: 0.000227
Validation Loss: 0.00022912
Epoch [89/300], Train Loss: 0.000227
Validation Loss: 0.00022910
Epoch [90/300], Train Loss: 0.000220
Validation Loss: 0.00023325
Epoch [91/300], Train Loss: 0.000220
Validation Loss: 0.00022398
Epoch [92/300], Train Loss: 0.000228
Validation Loss: 0.00028281
Epoch [93/300], Train Loss: 0.000248
Validation Loss: 0.00023095
Epoch [94/300], Train Loss: 0.000216
Validation Loss: 0.00024178
Epoch [95/300], Train Loss: 0.000215
Validation Loss: 0.00022640
Epoch [96/300], Train Loss: 0.000211
Validation Loss: 0.00023561
Epoch [97/300], Train Loss: 0.000208
Validation Loss: 0.00022223
Epoch [98/300], Train Loss: 0.000209
Validation Loss: 0.00022483
Epoch [99/300], Train Loss: 0.000209
Validation Loss: 0.00022002
Epoch [100/300], Train Loss: 0.000211
Validation Loss: 0.00022022
Epoch [101/300], Train Loss: 0.000217
Validation Loss: 0.00021587
Epoch [102/300], Train Loss: 0.000202
Validation Loss: 0.00022508
Epoch [103/300], Train Loss: 0.000210
Validation Loss: 0.00021495
Epoch [104/300], Train Loss: 0.000201
Validation Loss: 0.00020917
Epoch [105/300], Train Loss: 0.000196
Validation Loss: 0.00020606
Epoch [106/300], Train Loss: 0.000197
Validation Loss: 0.00020590
Epoch [107/300], Train Loss: 0.000194
Validation Loss: 0.00020517
Epoch [108/300], Train Loss: 0.000195
Validation Loss: 0.00021176
Epoch [109/300], Train Loss: 0.000192
Validation Loss: 0.00020807
Epoch [110/300], Train Loss: 0.000199
Validation Loss: 0.00021723
Epoch [111/300], Train Loss: 0.000196
Validation Loss: 0.00021047
Epoch [112/300], Train Loss: 0.000187
Validation Loss: 0.00020638
Epoch [113/300], Train Loss: 0.000189
Validation Loss: 0.00021525
Epoch [114/300], Train Loss: 0.000188
Validation Loss: 0.00020603
Epoch [115/300], Train Loss: 0.000196
Validation Loss: 0.00021073
Epoch [116/300], Train Loss: 0.000187
Validation Loss: 0.00020727
Epoch [117/300], Train Loss: 0.000188
Validation Loss: 0.00021772
Early stopping triggered

Evaluating model for: Coffee Machine
Run 53/72 completed in 3201.85 seconds with: {'MAE': np.float32(3.6920636), 'MSE': np.float32(835.24176), 'RMSE': np.float32(28.900549), 'SAE': np.float32(0.15238442), 'NDE': np.float32(0.46709558)}

Run 54/72: hidden=512, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Coffee Machine
Dataset length: 18100 windows

Epoch [1/300], Train Loss: 0.000977
Validation Loss: 0.00093353
Epoch [2/300], Train Loss: 0.000964
Validation Loss: 0.00093038
Epoch [3/300], Train Loss: 0.000981
Validation Loss: 0.00092774
Epoch [4/300], Train Loss: 0.000968
Validation Loss: 0.00091609
Epoch [5/300], Train Loss: 0.000938
Validation Loss: 0.00088464
Epoch [6/300], Train Loss: 0.000897
Validation Loss: 0.00082624
Epoch [7/300], Train Loss: 0.000827
Validation Loss: 0.00076410
Epoch [8/300], Train Loss: 0.000770
Validation Loss: 0.00077303
Epoch [9/300], Train Loss: 0.000745
Validation Loss: 0.00070571
Epoch [10/300], Train Loss: 0.000706
Validation Loss: 0.00069155
Epoch [11/300], Train Loss: 0.000676
Validation Loss: 0.00066682
Epoch [12/300], Train Loss: 0.000655
Validation Loss: 0.00062573
Epoch [13/300], Train Loss: 0.000649
Validation Loss: 0.00062887
Epoch [14/300], Train Loss: 0.000614
Validation Loss: 0.00062110
Epoch [15/300], Train Loss: 0.000598
Validation Loss: 0.00058158
Epoch [16/300], Train Loss: 0.000607
Validation Loss: 0.00059320
Epoch [17/300], Train Loss: 0.000585
Validation Loss: 0.00058291
Epoch [18/300], Train Loss: 0.000576
Validation Loss: 0.00059276
Epoch [19/300], Train Loss: 0.000561
Validation Loss: 0.00055436
Epoch [20/300], Train Loss: 0.000553
Validation Loss: 0.00054462
Epoch [21/300], Train Loss: 0.000562
Validation Loss: 0.00053504
Epoch [22/300], Train Loss: 0.000543
Validation Loss: 0.00053692
Epoch [23/300], Train Loss: 0.000568
Validation Loss: 0.00053188
Epoch [24/300], Train Loss: 0.000546
Validation Loss: 0.00054801
Epoch [25/300], Train Loss: 0.000521
Validation Loss: 0.00052014
Epoch [26/300], Train Loss: 0.000499
Validation Loss: 0.00048680
Epoch [27/300], Train Loss: 0.000492
Validation Loss: 0.00047346
Epoch [28/300], Train Loss: 0.000495
Validation Loss: 0.00046309
Epoch [29/300], Train Loss: 0.000465
Validation Loss: 0.00044520
Epoch [30/300], Train Loss: 0.000450
Validation Loss: 0.00043336
Epoch [31/300], Train Loss: 0.000431
Validation Loss: 0.00038923
Epoch [32/300], Train Loss: 0.000412
Validation Loss: 0.00037942
Epoch [33/300], Train Loss: 0.000435
Validation Loss: 0.00041448
Epoch [34/300], Train Loss: 0.000408
Validation Loss: 0.00038841
Epoch [35/300], Train Loss: 0.000389
Validation Loss: 0.00037121
Epoch [36/300], Train Loss: 0.000391
Validation Loss: 0.00037088
Epoch [37/300], Train Loss: 0.000356
Validation Loss: 0.00034324
Epoch [38/300], Train Loss: 0.000362
Validation Loss: 0.00037788
Epoch [39/300], Train Loss: 0.000344
Validation Loss: 0.00033318
Epoch [40/300], Train Loss: 0.000335
Validation Loss: 0.00031865
Epoch [41/300], Train Loss: 0.000330
Validation Loss: 0.00035222
Epoch [42/300], Train Loss: 0.000334
Validation Loss: 0.00032749
Epoch [43/300], Train Loss: 0.000315
Validation Loss: 0.00032646
Epoch [44/300], Train Loss: 0.000308
Validation Loss: 0.00030732
Epoch [45/300], Train Loss: 0.000310
Validation Loss: 0.00031556
Epoch [46/300], Train Loss: 0.000298
Validation Loss: 0.00030965
Epoch [47/300], Train Loss: 0.000313
Validation Loss: 0.00030996
Epoch [48/300], Train Loss: 0.000295
Validation Loss: 0.00029747
Epoch [49/300], Train Loss: 0.000297
Validation Loss: 0.00029916
Epoch [50/300], Train Loss: 0.000291
Validation Loss: 0.00028078
Epoch [51/300], Train Loss: 0.000287
Validation Loss: 0.00029624
Epoch [52/300], Train Loss: 0.000289
Validation Loss: 0.00028129
Epoch [53/300], Train Loss: 0.000274
Validation Loss: 0.00028304
Epoch [54/300], Train Loss: 0.000276
Validation Loss: 0.00028429
Epoch [55/300], Train Loss: 0.000264
Validation Loss: 0.00028161
Epoch [56/300], Train Loss: 0.000264
Validation Loss: 0.00027246
Epoch [57/300], Train Loss: 0.000264
Validation Loss: 0.00026046
Epoch [58/300], Train Loss: 0.000263
Validation Loss: 0.00026894
Epoch [59/300], Train Loss: 0.000253
Validation Loss: 0.00026177
Epoch [60/300], Train Loss: 0.000249
Validation Loss: 0.00026439
Epoch [61/300], Train Loss: 0.000246
Validation Loss: 0.00026238
Epoch [62/300], Train Loss: 0.000244
Validation Loss: 0.00026593
Epoch [63/300], Train Loss: 0.000256
Validation Loss: 0.00026575
Epoch [64/300], Train Loss: 0.000241
Validation Loss: 0.00025556
Epoch [65/300], Train Loss: 0.000240
Validation Loss: 0.00026313
Epoch [66/300], Train Loss: 0.000238
Validation Loss: 0.00025329
Epoch [67/300], Train Loss: 0.000234
Validation Loss: 0.00025451
Epoch [68/300], Train Loss: 0.000233
Validation Loss: 0.00027640
Epoch [69/300], Train Loss: 0.000236
Validation Loss: 0.00024812
Epoch [70/300], Train Loss: 0.000228
Validation Loss: 0.00026040
Epoch [71/300], Train Loss: 0.000235
Validation Loss: 0.00027821
Epoch [72/300], Train Loss: 0.000254
Validation Loss: 0.00026086
Epoch [73/300], Train Loss: 0.000262
Validation Loss: 0.00025791
Epoch [74/300], Train Loss: 0.000228
Validation Loss: 0.00024176
Epoch [75/300], Train Loss: 0.000222
Validation Loss: 0.00024408
Epoch [76/300], Train Loss: 0.000216
Validation Loss: 0.00024442
Epoch [77/300], Train Loss: 0.000233
Validation Loss: 0.00026224
Epoch [78/300], Train Loss: 0.000224
Validation Loss: 0.00024780
Epoch [79/300], Train Loss: 0.000210
Validation Loss: 0.00023821
Epoch [80/300], Train Loss: 0.000217
Validation Loss: 0.00024315
Epoch [81/300], Train Loss: 0.000261
Validation Loss: 0.00024396
Epoch [82/300], Train Loss: 0.000214
Validation Loss: 0.00023858
Epoch [83/300], Train Loss: 0.000207
Validation Loss: 0.00023665
Epoch [84/300], Train Loss: 0.000204
Validation Loss: 0.00024303
Epoch [85/300], Train Loss: 0.000203
Validation Loss: 0.00023142
Epoch [86/300], Train Loss: 0.000203
Validation Loss: 0.00024127
Epoch [87/300], Train Loss: 0.000201
Validation Loss: 0.00024150
Epoch [88/300], Train Loss: 0.000196
Validation Loss: 0.00022960
Epoch [89/300], Train Loss: 0.000200
Validation Loss: 0.00022503
Epoch [90/300], Train Loss: 0.000203
Validation Loss: 0.00023323
Epoch [91/300], Train Loss: 0.000202
Validation Loss: 0.00023175
Epoch [92/300], Train Loss: 0.000196
Validation Loss: 0.00022728
Epoch [93/300], Train Loss: 0.000198
Validation Loss: 0.00023265
Epoch [94/300], Train Loss: 0.000214
Validation Loss: 0.00024824
Epoch [95/300], Train Loss: 0.000201
Validation Loss: 0.00022133
Epoch [96/300], Train Loss: 0.000190
Validation Loss: 0.00022091
Epoch [97/300], Train Loss: 0.000183
Validation Loss: 0.00022209
Epoch [98/300], Train Loss: 0.000182
Validation Loss: 0.00022380
Epoch [99/300], Train Loss: 0.000185
Validation Loss: 0.00022234
Epoch [100/300], Train Loss: 0.000187
Validation Loss: 0.00021798
Epoch [101/300], Train Loss: 0.000181
Validation Loss: 0.00021912
Epoch [102/300], Train Loss: 0.000179
Validation Loss: 0.00021500
Epoch [103/300], Train Loss: 0.000180
Validation Loss: 0.00021332
Epoch [104/300], Train Loss: 0.000174
Validation Loss: 0.00021816
Epoch [105/300], Train Loss: 0.000174
Validation Loss: 0.00021601
Epoch [106/300], Train Loss: 0.000176
Validation Loss: 0.00020847
Epoch [107/300], Train Loss: 0.000180
Validation Loss: 0.00021040
Epoch [108/300], Train Loss: 0.000174
Validation Loss: 0.00021394
Epoch [109/300], Train Loss: 0.000172
Validation Loss: 0.00020656
Epoch [110/300], Train Loss: 0.000173
Validation Loss: 0.00020838
Epoch [111/300], Train Loss: 0.000170
Validation Loss: 0.00020842
Epoch [112/300], Train Loss: 0.000167
Validation Loss: 0.00019941
Epoch [113/300], Train Loss: 0.000165
Validation Loss: 0.00020138
Epoch [114/300], Train Loss: 0.000170
Validation Loss: 0.00021141
Epoch [115/300], Train Loss: 0.000167
Validation Loss: 0.00020426
Epoch [116/300], Train Loss: 0.000162
Validation Loss: 0.00020283
Epoch [117/300], Train Loss: 0.000162
Validation Loss: 0.00020095
Epoch [118/300], Train Loss: 0.000164
Validation Loss: 0.00020383
Epoch [119/300], Train Loss: 0.000184
Validation Loss: 0.00021376
Epoch [120/300], Train Loss: 0.000167
Validation Loss: 0.00020232
Epoch [121/300], Train Loss: 0.000159
Validation Loss: 0.00020610
Epoch [122/300], Train Loss: 0.000156
Validation Loss: 0.00019913
Epoch [123/300], Train Loss: 0.000156
Validation Loss: 0.00020935
Epoch [124/300], Train Loss: 0.000155
Validation Loss: 0.00019600
Epoch [125/300], Train Loss: 0.000156
Validation Loss: 0.00019233
Epoch [126/300], Train Loss: 0.000163
Validation Loss: 0.00019982
Epoch [127/300], Train Loss: 0.000153
Validation Loss: 0.00019276
Epoch [128/300], Train Loss: 0.000167
Validation Loss: 0.00019539
Epoch [129/300], Train Loss: 0.000153
Validation Loss: 0.00019927
Epoch [130/300], Train Loss: 0.000150
Validation Loss: 0.00019691
Epoch [131/300], Train Loss: 0.000152
Validation Loss: 0.00019407
Epoch [132/300], Train Loss: 0.000153
Validation Loss: 0.00018921
Epoch [133/300], Train Loss: 0.000151
Validation Loss: 0.00027560
Epoch [134/300], Train Loss: 0.000147
Validation Loss: 0.00019202
Epoch [135/300], Train Loss: 0.000155
Validation Loss: 0.00019635
Epoch [136/300], Train Loss: 0.000145
Validation Loss: 0.00019306
Epoch [137/300], Train Loss: 0.000147
Validation Loss: 0.00019119
Epoch [138/300], Train Loss: 0.000148
Validation Loss: 0.00018998
Epoch [139/300], Train Loss: 0.000147
Validation Loss: 0.00020188
Epoch [140/300], Train Loss: 0.000158
Validation Loss: 0.00020857
Epoch [141/300], Train Loss: 0.000177
Validation Loss: 0.00026242
Epoch [142/300], Train Loss: 0.000172
Validation Loss: 0.00019313
Early stopping triggered

Evaluating model for: Coffee Machine
Run 54/72 completed in 4196.35 seconds with: {'MAE': np.float32(4.0091467), 'MSE': np.float32(689.98883), 'RMSE': np.float32(26.26764), 'SAE': np.float32(0.20751634), 'NDE': np.float32(0.42454237)}

Run 55/72: hidden=512, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Coffee Machine
Dataset length: 18100 windows

Epoch [1/300], Train Loss: 0.000981
Validation Loss: 0.00093765
Epoch [2/300], Train Loss: 0.000967
Validation Loss: 0.00093597
Epoch [3/300], Train Loss: 0.000985
Validation Loss: 0.00093198
Epoch [4/300], Train Loss: 0.000975
Validation Loss: 0.00092921
Epoch [5/300], Train Loss: 0.000958
Validation Loss: 0.00091990
Epoch [6/300], Train Loss: 0.000950
Validation Loss: 0.00089643
Epoch [7/300], Train Loss: 0.000906
Validation Loss: 0.00083508
Epoch [8/300], Train Loss: 0.000828
Validation Loss: 0.00082075
Epoch [9/300], Train Loss: 0.000781
Validation Loss: 0.00074013
Epoch [10/300], Train Loss: 0.000744
Validation Loss: 0.00073033
Epoch [11/300], Train Loss: 0.000703
Validation Loss: 0.00070500
Epoch [12/300], Train Loss: 0.000674
Validation Loss: 0.00068381
Epoch [13/300], Train Loss: 0.000715
Validation Loss: 0.00068323
Epoch [14/300], Train Loss: 0.000637
Validation Loss: 0.00065972
Epoch [15/300], Train Loss: 0.000630
Validation Loss: 0.00063385
Epoch [16/300], Train Loss: 0.000605
Validation Loss: 0.00061890
Epoch [17/300], Train Loss: 0.000587
Validation Loss: 0.00061405
Epoch [18/300], Train Loss: 0.000587
Validation Loss: 0.00061261
Epoch [19/300], Train Loss: 0.000582
Validation Loss: 0.00063542
Epoch [20/300], Train Loss: 0.000580
Validation Loss: 0.00058573
Epoch [21/300], Train Loss: 0.000585
Validation Loss: 0.00059165
Epoch [22/300], Train Loss: 0.000552
Validation Loss: 0.00055364
Epoch [23/300], Train Loss: 0.000549
Validation Loss: 0.00049745
Epoch [24/300], Train Loss: 0.000492
Validation Loss: 0.00051778
Epoch [25/300], Train Loss: 0.000454
Validation Loss: 0.00048278
Epoch [26/300], Train Loss: 0.000432
Validation Loss: 0.00043099
Epoch [27/300], Train Loss: 0.000412
Validation Loss: 0.00041607
Epoch [28/300], Train Loss: 0.000403
Validation Loss: 0.00037136
Epoch [29/300], Train Loss: 0.000371
Validation Loss: 0.00035310
Epoch [30/300], Train Loss: 0.000358
Validation Loss: 0.00038075
Epoch [31/300], Train Loss: 0.000370
Validation Loss: 0.00037825
Epoch [32/300], Train Loss: 0.000341
Validation Loss: 0.00035352
Epoch [33/300], Train Loss: 0.000348
Validation Loss: 0.00031859
Epoch [34/300], Train Loss: 0.000334
Validation Loss: 0.00035663
Epoch [35/300], Train Loss: 0.000331
Validation Loss: 0.00033197
Epoch [36/300], Train Loss: 0.000327
Validation Loss: 0.00035082
Epoch [37/300], Train Loss: 0.000316
Validation Loss: 0.00031006
Epoch [38/300], Train Loss: 0.000315
Validation Loss: 0.00031650
Epoch [39/300], Train Loss: 0.000299
Validation Loss: 0.00030237
Epoch [40/300], Train Loss: 0.000294
Validation Loss: 0.00030558
Epoch [41/300], Train Loss: 0.000295
Validation Loss: 0.00036700
Epoch [42/300], Train Loss: 0.000295
Validation Loss: 0.00030331
Epoch [43/300], Train Loss: 0.000286
Validation Loss: 0.00030635
Epoch [44/300], Train Loss: 0.000284
Validation Loss: 0.00032242
Epoch [45/300], Train Loss: 0.000281
Validation Loss: 0.00041286
Epoch [46/300], Train Loss: 0.000293
Validation Loss: 0.00032614
Epoch [47/300], Train Loss: 0.000271
Validation Loss: 0.00034190
Epoch [48/300], Train Loss: 0.000274
Validation Loss: 0.00030098
Epoch [49/300], Train Loss: 0.000262
Validation Loss: 0.00028865
Epoch [50/300], Train Loss: 0.000268
Validation Loss: 0.00028681
Epoch [51/300], Train Loss: 0.000258
Validation Loss: 0.00029495
Epoch [52/300], Train Loss: 0.000257
Validation Loss: 0.00031324
Epoch [53/300], Train Loss: 0.000260
Validation Loss: 0.00028425
Epoch [54/300], Train Loss: 0.000250
Validation Loss: 0.00027975
Epoch [55/300], Train Loss: 0.000242
Validation Loss: 0.00029213
Epoch [56/300], Train Loss: 0.000244
Validation Loss: 0.00027573
Epoch [57/300], Train Loss: 0.000240
Validation Loss: 0.00026747
Epoch [58/300], Train Loss: 0.000235
Validation Loss: 0.00028840
Epoch [59/300], Train Loss: 0.000238
Validation Loss: 0.00026906
Epoch [60/300], Train Loss: 0.000231
Validation Loss: 0.00026384
Epoch [61/300], Train Loss: 0.000231
Validation Loss: 0.00028041
Epoch [62/300], Train Loss: 0.000224
Validation Loss: 0.00028257
Epoch [63/300], Train Loss: 0.000219
Validation Loss: 0.00028695
Epoch [64/300], Train Loss: 0.000219
Validation Loss: 0.00027004
Epoch [65/300], Train Loss: 0.000214
Validation Loss: 0.00026627
Epoch [66/300], Train Loss: 0.000214
Validation Loss: 0.00026296
Epoch [67/300], Train Loss: 0.000226
Validation Loss: 0.00027160
Epoch [68/300], Train Loss: 0.000214
Validation Loss: 0.00028241
Epoch [69/300], Train Loss: 0.000206
Validation Loss: 0.00026753
Epoch [70/300], Train Loss: 0.000202
Validation Loss: 0.00027790
Epoch [71/300], Train Loss: 0.000206
Validation Loss: 0.00027501
Epoch [72/300], Train Loss: 0.000206
Validation Loss: 0.00026652
Epoch [73/300], Train Loss: 0.000201
Validation Loss: 0.00029660
Epoch [74/300], Train Loss: 0.000201
Validation Loss: 0.00027949
Epoch [75/300], Train Loss: 0.000192
Validation Loss: 0.00026126
Epoch [76/300], Train Loss: 0.000188
Validation Loss: 0.00025465
Epoch [77/300], Train Loss: 0.000192
Validation Loss: 0.00026482
Epoch [78/300], Train Loss: 0.000189
Validation Loss: 0.00026035
Epoch [79/300], Train Loss: 0.000184
Validation Loss: 0.00026462
Epoch [80/300], Train Loss: 0.000185
Validation Loss: 0.00026546
Epoch [81/300], Train Loss: 0.000186
Validation Loss: 0.00024960
Epoch [82/300], Train Loss: 0.000174
Validation Loss: 0.00026066
Epoch [83/300], Train Loss: 0.000175
Validation Loss: 0.00024498
Epoch [84/300], Train Loss: 0.000211
Validation Loss: 0.00027823
Epoch [85/300], Train Loss: 0.000213
Validation Loss: 0.00026031
Epoch [86/300], Train Loss: 0.000182
Validation Loss: 0.00027654
Epoch [87/300], Train Loss: 0.000185
Validation Loss: 0.00025072
Epoch [88/300], Train Loss: 0.000176
Validation Loss: 0.00024808
Epoch [89/300], Train Loss: 0.000183
Validation Loss: 0.00025266
Epoch [90/300], Train Loss: 0.000174
Validation Loss: 0.00023683
Epoch [91/300], Train Loss: 0.000167
Validation Loss: 0.00023690
Epoch [92/300], Train Loss: 0.000166
Validation Loss: 0.00024632
Epoch [93/300], Train Loss: 0.000171
Validation Loss: 0.00024502
Epoch [94/300], Train Loss: 0.000162
Validation Loss: 0.00025846
Epoch [95/300], Train Loss: 0.000165
Validation Loss: 0.00023354
Epoch [96/300], Train Loss: 0.000162
Validation Loss: 0.00022900
Epoch [97/300], Train Loss: 0.000158
Validation Loss: 0.00023637
Epoch [98/300], Train Loss: 0.000160
Validation Loss: 0.00023537
Epoch [99/300], Train Loss: 0.000157
Validation Loss: 0.00023427
Epoch [100/300], Train Loss: 0.000155
Validation Loss: 0.00023503
Epoch [101/300], Train Loss: 0.000156
Validation Loss: 0.00023957
Epoch [102/300], Train Loss: 0.000149
Validation Loss: 0.00023998
Epoch [103/300], Train Loss: 0.000150
Validation Loss: 0.00023209
Epoch [104/300], Train Loss: 0.000149
Validation Loss: 0.00023069
Epoch [105/300], Train Loss: 0.000146
Validation Loss: 0.00023230
Epoch [106/300], Train Loss: 0.000154
Validation Loss: 0.00024809
Early stopping triggered

Evaluating model for: Coffee Machine
Run 55/72 completed in 3379.15 seconds with: {'MAE': np.float32(3.7739637), 'MSE': np.float32(839.1204), 'RMSE': np.float32(28.967575), 'SAE': np.float32(0.06272317), 'NDE': np.float32(0.46817908)}

Run 56/72: hidden=512, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Coffee Machine
Dataset length: 18100 windows

Epoch [1/300], Train Loss: 0.000991
Validation Loss: 0.00093598
Epoch [2/300], Train Loss: 0.000969
Validation Loss: 0.00093559
Epoch [3/300], Train Loss: 0.000987
Validation Loss: 0.00093381
Epoch [4/300], Train Loss: 0.000978
Validation Loss: 0.00093482
Epoch [5/300], Train Loss: 0.000965
Validation Loss: 0.00093182
Epoch [6/300], Train Loss: 0.000969
Validation Loss: 0.00092988
Epoch [7/300], Train Loss: 0.000956
Validation Loss: 0.00091444
Epoch [8/300], Train Loss: 0.000928
Validation Loss: 0.00086846
Epoch [9/300], Train Loss: 0.000846
Validation Loss: 0.00078369
Epoch [10/300], Train Loss: 0.000769
Validation Loss: 0.00073468
Epoch [11/300], Train Loss: 0.000714
Validation Loss: 0.00070569
Epoch [12/300], Train Loss: 0.000692
Validation Loss: 0.00069830
Epoch [13/300], Train Loss: 0.000681
Validation Loss: 0.00070084
Epoch [14/300], Train Loss: 0.000652
Validation Loss: 0.00069282
Epoch [15/300], Train Loss: 0.000667
Validation Loss: 0.00067314
Epoch [16/300], Train Loss: 0.000622
Validation Loss: 0.00062301
Epoch [17/300], Train Loss: 0.000616
Validation Loss: 0.00062791
Epoch [18/300], Train Loss: 0.000596
Validation Loss: 0.00061750
Epoch [19/300], Train Loss: 0.000608
Validation Loss: 0.00064626
Epoch [20/300], Train Loss: 0.000571
Validation Loss: 0.00059007
Epoch [21/300], Train Loss: 0.000534
Validation Loss: 0.00051678
Epoch [22/300], Train Loss: 0.000494
Validation Loss: 0.00046862
Epoch [23/300], Train Loss: 0.000493
Validation Loss: 0.00045306
Epoch [24/300], Train Loss: 0.000435
Validation Loss: 0.00041537
Epoch [25/300], Train Loss: 0.000413
Validation Loss: 0.00040826
Epoch [26/300], Train Loss: 0.000397
Validation Loss: 0.00038512
Epoch [27/300], Train Loss: 0.000396
Validation Loss: 0.00036120
Epoch [28/300], Train Loss: 0.000511
Validation Loss: 0.00041032
Epoch [29/300], Train Loss: 0.000444
Validation Loss: 0.00036966
Epoch [30/300], Train Loss: 0.000393
Validation Loss: 0.00033232
Epoch [31/300], Train Loss: 0.000379
Validation Loss: 0.00033624
Epoch [32/300], Train Loss: 0.000371
Validation Loss: 0.00035238
Epoch [33/300], Train Loss: 0.000374
Validation Loss: 0.00033839
Epoch [34/300], Train Loss: 0.000350
Validation Loss: 0.00033092
Epoch [35/300], Train Loss: 0.000348
Validation Loss: 0.00034679
Epoch [36/300], Train Loss: 0.000354
Validation Loss: 0.00034268
Epoch [37/300], Train Loss: 0.000340
Validation Loss: 0.00030596
Epoch [38/300], Train Loss: 0.000336
Validation Loss: 0.00032965
Epoch [39/300], Train Loss: 0.000320
Validation Loss: 0.00031127
Epoch [40/300], Train Loss: 0.000313
Validation Loss: 0.00031491
Epoch [41/300], Train Loss: 0.000306
Validation Loss: 0.00031187
Epoch [42/300], Train Loss: 0.000300
Validation Loss: 0.00030656
Epoch [43/300], Train Loss: 0.000295
Validation Loss: 0.00030984
Epoch [44/300], Train Loss: 0.000290
Validation Loss: 0.00031077
Epoch [45/300], Train Loss: 0.000288
Validation Loss: 0.00041332
Epoch [46/300], Train Loss: 0.000303
Validation Loss: 0.00030934
Epoch [47/300], Train Loss: 0.000281
Validation Loss: 0.00032117
Early stopping triggered

Evaluating model for: Coffee Machine
Run 56/72 completed in 1701.52 seconds with: {'MAE': np.float32(4.683012), 'MSE': np.float32(1170.9788), 'RMSE': np.float32(34.219566), 'SAE': np.float32(0.33691478), 'NDE': np.float32(0.5530625)}

Run 57/72: hidden=512, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Coffee Machine
Dataset length: 11964 windows

Epoch [1/300], Train Loss: 0.000946
Validation Loss: 0.00102648
Epoch [2/300], Train Loss: 0.000939
Validation Loss: 0.00102700
Epoch [3/300], Train Loss: 0.000937
Validation Loss: 0.00102224
Epoch [4/300], Train Loss: 0.000933
Validation Loss: 0.00102086
Epoch [5/300], Train Loss: 0.000927
Validation Loss: 0.00100831
Epoch [6/300], Train Loss: 0.000915
Validation Loss: 0.00099412
Epoch [7/300], Train Loss: 0.000898
Validation Loss: 0.00096641
Epoch [8/300], Train Loss: 0.000871
Validation Loss: 0.00091887
Epoch [9/300], Train Loss: 0.000831
Validation Loss: 0.00086838
Epoch [10/300], Train Loss: 0.000790
Validation Loss: 0.00082209
Epoch [11/300], Train Loss: 0.000750
Validation Loss: 0.00079973
Epoch [12/300], Train Loss: 0.000717
Validation Loss: 0.00074493
Epoch [13/300], Train Loss: 0.000680
Validation Loss: 0.00072102
Epoch [14/300], Train Loss: 0.000652
Validation Loss: 0.00068718
Epoch [15/300], Train Loss: 0.000646
Validation Loss: 0.00069925
Epoch [16/300], Train Loss: 0.000620
Validation Loss: 0.00068830
Epoch [17/300], Train Loss: 0.000607
Validation Loss: 0.00064421
Epoch [18/300], Train Loss: 0.000595
Validation Loss: 0.00063608
Epoch [19/300], Train Loss: 0.000582
Validation Loss: 0.00062890
Epoch [20/300], Train Loss: 0.000567
Validation Loss: 0.00060609
Epoch [21/300], Train Loss: 0.000554
Validation Loss: 0.00059888
Epoch [22/300], Train Loss: 0.000549
Validation Loss: 0.00059626
Epoch [23/300], Train Loss: 0.000536
Validation Loss: 0.00057196
Epoch [24/300], Train Loss: 0.000519
Validation Loss: 0.00055262
Epoch [25/300], Train Loss: 0.000508
Validation Loss: 0.00053215
Epoch [26/300], Train Loss: 0.000497
Validation Loss: 0.00054016
Epoch [27/300], Train Loss: 0.000495
Validation Loss: 0.00051796
Epoch [28/300], Train Loss: 0.000482
Validation Loss: 0.00052348
Epoch [29/300], Train Loss: 0.000473
Validation Loss: 0.00049466
Epoch [30/300], Train Loss: 0.000459
Validation Loss: 0.00050417
Epoch [31/300], Train Loss: 0.000444
Validation Loss: 0.00054275
Epoch [32/300], Train Loss: 0.000439
Validation Loss: 0.00045560
Epoch [33/300], Train Loss: 0.000421
Validation Loss: 0.00043063
Epoch [34/300], Train Loss: 0.000401
Validation Loss: 0.00040409
Epoch [35/300], Train Loss: 0.000376
Validation Loss: 0.00037502
Epoch [36/300], Train Loss: 0.000388
Validation Loss: 0.00055521
Epoch [37/300], Train Loss: 0.000419
Validation Loss: 0.00038190
Epoch [38/300], Train Loss: 0.000364
Validation Loss: 0.00036692
Epoch [39/300], Train Loss: 0.000349
Validation Loss: 0.00036179
Epoch [40/300], Train Loss: 0.000349
Validation Loss: 0.00033976
Epoch [41/300], Train Loss: 0.000334
Validation Loss: 0.00033446
Epoch [42/300], Train Loss: 0.000325
Validation Loss: 0.00032649
Epoch [43/300], Train Loss: 0.000320
Validation Loss: 0.00032111
Epoch [44/300], Train Loss: 0.000314
Validation Loss: 0.00031736
Epoch [45/300], Train Loss: 0.000310
Validation Loss: 0.00035824
Epoch [46/300], Train Loss: 0.000303
Validation Loss: 0.00031940
Epoch [47/300], Train Loss: 0.000315
Validation Loss: 0.00029370
Epoch [48/300], Train Loss: 0.000286
Validation Loss: 0.00029422
Epoch [49/300], Train Loss: 0.000284
Validation Loss: 0.00028902
Epoch [50/300], Train Loss: 0.000279
Validation Loss: 0.00028908
Epoch [51/300], Train Loss: 0.000272
Validation Loss: 0.00028080
Epoch [52/300], Train Loss: 0.000267
Validation Loss: 0.00029070
Epoch [53/300], Train Loss: 0.000267
Validation Loss: 0.00028166
Epoch [54/300], Train Loss: 0.000261
Validation Loss: 0.00026498
Epoch [55/300], Train Loss: 0.000262
Validation Loss: 0.00028829
Epoch [56/300], Train Loss: 0.000255
Validation Loss: 0.00026342
Epoch [57/300], Train Loss: 0.000251
Validation Loss: 0.00028906
Epoch [58/300], Train Loss: 0.000249
Validation Loss: 0.00026374
Epoch [59/300], Train Loss: 0.000257
Validation Loss: 0.00027242
Epoch [60/300], Train Loss: 0.000245
Validation Loss: 0.00027030
Epoch [61/300], Train Loss: 0.000239
Validation Loss: 0.00026165
Epoch [62/300], Train Loss: 0.000232
Validation Loss: 0.00026716
Epoch [63/300], Train Loss: 0.000248
Validation Loss: 0.00025902
Epoch [64/300], Train Loss: 0.000237
Validation Loss: 0.00024665
Epoch [65/300], Train Loss: 0.000245
Validation Loss: 0.00028903
Epoch [66/300], Train Loss: 0.000241
Validation Loss: 0.00025412
Epoch [67/300], Train Loss: 0.000230
Validation Loss: 0.00024118
Epoch [68/300], Train Loss: 0.000220
Validation Loss: 0.00024124
Epoch [69/300], Train Loss: 0.000221
Validation Loss: 0.00023365
Epoch [70/300], Train Loss: 0.000217
Validation Loss: 0.00023517
Epoch [71/300], Train Loss: 0.000220
Validation Loss: 0.00023303
Epoch [72/300], Train Loss: 0.000215
Validation Loss: 0.00023369
Epoch [73/300], Train Loss: 0.000214
Validation Loss: 0.00023299
Epoch [74/300], Train Loss: 0.000212
Validation Loss: 0.00021836
Epoch [75/300], Train Loss: 0.000210
Validation Loss: 0.00022045
Epoch [76/300], Train Loss: 0.000204
Validation Loss: 0.00021569
Epoch [77/300], Train Loss: 0.000204
Validation Loss: 0.00021402
Epoch [78/300], Train Loss: 0.000203
Validation Loss: 0.00023590
Epoch [79/300], Train Loss: 0.000196
Validation Loss: 0.00021091
Epoch [80/300], Train Loss: 0.000197
Validation Loss: 0.00021931
Epoch [81/300], Train Loss: 0.000191
Validation Loss: 0.00020668
Epoch [82/300], Train Loss: 0.000193
Validation Loss: 0.00020228
Epoch [83/300], Train Loss: 0.000190
Validation Loss: 0.00020099
Epoch [84/300], Train Loss: 0.000193
Validation Loss: 0.00020688
Epoch [85/300], Train Loss: 0.000189
Validation Loss: 0.00021908
Epoch [86/300], Train Loss: 0.000186
Validation Loss: 0.00020020
Epoch [87/300], Train Loss: 0.000184
Validation Loss: 0.00020407
Epoch [88/300], Train Loss: 0.000188
Validation Loss: 0.00019555
Epoch [89/300], Train Loss: 0.000182
Validation Loss: 0.00019901
Epoch [90/300], Train Loss: 0.000181
Validation Loss: 0.00020470
Epoch [91/300], Train Loss: 0.000182
Validation Loss: 0.00020242
Epoch [92/300], Train Loss: 0.000178
Validation Loss: 0.00019213
Epoch [93/300], Train Loss: 0.000176
Validation Loss: 0.00018883
Epoch [94/300], Train Loss: 0.000177
Validation Loss: 0.00019097
Epoch [95/300], Train Loss: 0.000174
Validation Loss: 0.00018675
Epoch [96/300], Train Loss: 0.000174
Validation Loss: 0.00018146
Epoch [97/300], Train Loss: 0.000193
Validation Loss: 0.00019409
Epoch [98/300], Train Loss: 0.000174
Validation Loss: 0.00018318
Epoch [99/300], Train Loss: 0.000165
Validation Loss: 0.00017733
Epoch [100/300], Train Loss: 0.000166
Validation Loss: 0.00017991
Epoch [101/300], Train Loss: 0.000165
Validation Loss: 0.00018735
Epoch [102/300], Train Loss: 0.000167
Validation Loss: 0.00018835
Epoch [103/300], Train Loss: 0.000173
Validation Loss: 0.00020015
Epoch [104/300], Train Loss: 0.000166
Validation Loss: 0.00017380
Epoch [105/300], Train Loss: 0.000158
Validation Loss: 0.00018063
Epoch [106/300], Train Loss: 0.000154
Validation Loss: 0.00017924
Epoch [107/300], Train Loss: 0.000159
Validation Loss: 0.00017785
Epoch [108/300], Train Loss: 0.000155
Validation Loss: 0.00016923
Epoch [109/300], Train Loss: 0.000158
Validation Loss: 0.00018413
Epoch [110/300], Train Loss: 0.000154
Validation Loss: 0.00018080
Epoch [111/300], Train Loss: 0.000158
Validation Loss: 0.00016862
Epoch [112/300], Train Loss: 0.000153
Validation Loss: 0.00017572
Epoch [113/300], Train Loss: 0.000148
Validation Loss: 0.00016524
Epoch [114/300], Train Loss: 0.000147
Validation Loss: 0.00016764
Epoch [115/300], Train Loss: 0.000146
Validation Loss: 0.00017116
Epoch [116/300], Train Loss: 0.000147
Validation Loss: 0.00016950
Epoch [117/300], Train Loss: 0.000144
Validation Loss: 0.00016260
Epoch [118/300], Train Loss: 0.000144
Validation Loss: 0.00016843
Epoch [119/300], Train Loss: 0.000155
Validation Loss: 0.00019642
Epoch [120/300], Train Loss: 0.000158
Validation Loss: 0.00016776
Epoch [121/300], Train Loss: 0.000146
Validation Loss: 0.00017259
Epoch [122/300], Train Loss: 0.000143
Validation Loss: 0.00016197
Epoch [123/300], Train Loss: 0.000140
Validation Loss: 0.00016312
Epoch [124/300], Train Loss: 0.000179
Validation Loss: 0.00019695
Epoch [125/300], Train Loss: 0.000167
Validation Loss: 0.00019742
Epoch [126/300], Train Loss: 0.000154
Validation Loss: 0.00016336
Epoch [127/300], Train Loss: 0.000141
Validation Loss: 0.00015969
Epoch [128/300], Train Loss: 0.000138
Validation Loss: 0.00016188
Epoch [129/300], Train Loss: 0.000136
Validation Loss: 0.00015699
Epoch [130/300], Train Loss: 0.000136
Validation Loss: 0.00015910
Epoch [131/300], Train Loss: 0.000135
Validation Loss: 0.00015738
Epoch [132/300], Train Loss: 0.000135
Validation Loss: 0.00015580
Epoch [133/300], Train Loss: 0.000134
Validation Loss: 0.00015565
Epoch [134/300], Train Loss: 0.000132
Validation Loss: 0.00015972
Epoch [135/300], Train Loss: 0.000132
Validation Loss: 0.00015577
Epoch [136/300], Train Loss: 0.000133
Validation Loss: 0.00015759
Epoch [137/300], Train Loss: 0.000131
Validation Loss: 0.00015625
Epoch [138/300], Train Loss: 0.000131
Validation Loss: 0.00015435
Epoch [139/300], Train Loss: 0.000129
Validation Loss: 0.00015317
Epoch [140/300], Train Loss: 0.000129
Validation Loss: 0.00015365
Epoch [141/300], Train Loss: 0.000128
Validation Loss: 0.00015378
Epoch [142/300], Train Loss: 0.000130
Validation Loss: 0.00015412
Epoch [143/300], Train Loss: 0.000128
Validation Loss: 0.00014997
Epoch [144/300], Train Loss: 0.000127
Validation Loss: 0.00015470
Epoch [145/300], Train Loss: 0.000126
Validation Loss: 0.00015132
Epoch [146/300], Train Loss: 0.000129
Validation Loss: 0.00015032
Epoch [147/300], Train Loss: 0.000128
Validation Loss: 0.00014860
Epoch [148/300], Train Loss: 0.000133
Validation Loss: 0.00015090
Epoch [149/300], Train Loss: 0.000128
Validation Loss: 0.00014609
Epoch [150/300], Train Loss: 0.000126
Validation Loss: 0.00015019
Epoch [151/300], Train Loss: 0.000124
Validation Loss: 0.00015214
Epoch [152/300], Train Loss: 0.000123
Validation Loss: 0.00014791
Epoch [153/300], Train Loss: 0.000122
Validation Loss: 0.00014705
Epoch [154/300], Train Loss: 0.000125
Validation Loss: 0.00014809
Epoch [155/300], Train Loss: 0.000124
Validation Loss: 0.00014823
Epoch [156/300], Train Loss: 0.000121
Validation Loss: 0.00014810
Epoch [157/300], Train Loss: 0.000120
Validation Loss: 0.00014881
Epoch [158/300], Train Loss: 0.000121
Validation Loss: 0.00014572
Epoch [159/300], Train Loss: 0.000120
Validation Loss: 0.00014604
Epoch [160/300], Train Loss: 0.000119
Validation Loss: 0.00014460
Epoch [161/300], Train Loss: 0.000122
Validation Loss: 0.00014907
Epoch [162/300], Train Loss: 0.000131
Validation Loss: 0.00014676
Epoch [163/300], Train Loss: 0.000119
Validation Loss: 0.00014480
Epoch [164/300], Train Loss: 0.000117
Validation Loss: 0.00014356
Epoch [165/300], Train Loss: 0.000117
Validation Loss: 0.00015018
Epoch [166/300], Train Loss: 0.000118
Validation Loss: 0.00014519
Epoch [167/300], Train Loss: 0.000116
Validation Loss: 0.00014133
Epoch [168/300], Train Loss: 0.000115
Validation Loss: 0.00014338
Epoch [169/300], Train Loss: 0.000114
Validation Loss: 0.00015328
Epoch [170/300], Train Loss: 0.000116
Validation Loss: 0.00014121
Epoch [171/300], Train Loss: 0.000115
Validation Loss: 0.00014114
Epoch [172/300], Train Loss: 0.000112
Validation Loss: 0.00014159
Epoch [173/300], Train Loss: 0.000115
Validation Loss: 0.00014432
Epoch [174/300], Train Loss: 0.000114
Validation Loss: 0.00014162
Epoch [175/300], Train Loss: 0.000114
Validation Loss: 0.00014555
Epoch [176/300], Train Loss: 0.000113
Validation Loss: 0.00014000
Epoch [177/300], Train Loss: 0.000112
Validation Loss: 0.00013805
Epoch [178/300], Train Loss: 0.000113
Validation Loss: 0.00014027
Epoch [179/300], Train Loss: 0.000114
Validation Loss: 0.00013811
Epoch [180/300], Train Loss: 0.000110
Validation Loss: 0.00014028
Epoch [181/300], Train Loss: 0.000111
Validation Loss: 0.00014689
Epoch [182/300], Train Loss: 0.000113
Validation Loss: 0.00013941
Epoch [183/300], Train Loss: 0.000111
Validation Loss: 0.00014775
Epoch [184/300], Train Loss: 0.000140
Validation Loss: 0.00015278
Epoch [185/300], Train Loss: 0.000114
Validation Loss: 0.00013948
Epoch [186/300], Train Loss: 0.000110
Validation Loss: 0.00013857
Epoch [187/300], Train Loss: 0.000119
Validation Loss: 0.00014213
Early stopping triggered

Evaluating model for: Coffee Machine
Run 57/72 completed in 4618.61 seconds with: {'MAE': np.float32(3.299005), 'MSE': np.float32(566.5974), 'RMSE': np.float32(23.803307), 'SAE': np.float32(0.057547696), 'NDE': np.float32(0.33082968)}

Run 58/72: hidden=512, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Coffee Machine
Dataset length: 11964 windows

Epoch [1/300], Train Loss: 0.000946
Validation Loss: 0.00102716
Epoch [2/300], Train Loss: 0.000939
Validation Loss: 0.00102612
Epoch [3/300], Train Loss: 0.000936
Validation Loss: 0.00102064
Epoch [4/300], Train Loss: 0.000930
Validation Loss: 0.00101286
Epoch [5/300], Train Loss: 0.000916
Validation Loss: 0.00098831
Epoch [6/300], Train Loss: 0.000890
Validation Loss: 0.00094977
Epoch [7/300], Train Loss: 0.000850
Validation Loss: 0.00089004
Epoch [8/300], Train Loss: 0.000792
Validation Loss: 0.00082901
Epoch [9/300], Train Loss: 0.000747
Validation Loss: 0.00077390
Epoch [10/300], Train Loss: 0.000712
Validation Loss: 0.00073768
Epoch [11/300], Train Loss: 0.000674
Validation Loss: 0.00071750
Epoch [12/300], Train Loss: 0.000655
Validation Loss: 0.00068095
Epoch [13/300], Train Loss: 0.000621
Validation Loss: 0.00067491
Epoch [14/300], Train Loss: 0.000599
Validation Loss: 0.00063140
Epoch [15/300], Train Loss: 0.000598
Validation Loss: 0.00065980
Epoch [16/300], Train Loss: 0.000570
Validation Loss: 0.00061441
Epoch [17/300], Train Loss: 0.000556
Validation Loss: 0.00058612
Epoch [18/300], Train Loss: 0.000544
Validation Loss: 0.00057693
Epoch [19/300], Train Loss: 0.000538
Validation Loss: 0.00055593
Epoch [20/300], Train Loss: 0.000524
Validation Loss: 0.00054597
Epoch [21/300], Train Loss: 0.000507
Validation Loss: 0.00053276
Epoch [22/300], Train Loss: 0.000500
Validation Loss: 0.00054020
Epoch [23/300], Train Loss: 0.000490
Validation Loss: 0.00051875
Epoch [24/300], Train Loss: 0.000505
Validation Loss: 0.00055624
Epoch [25/300], Train Loss: 0.000502
Validation Loss: 0.00052275
Epoch [26/300], Train Loss: 0.000481
Validation Loss: 0.00051220
Epoch [27/300], Train Loss: 0.000469
Validation Loss: 0.00049573
Epoch [28/300], Train Loss: 0.000457
Validation Loss: 0.00049946
Epoch [29/300], Train Loss: 0.000455
Validation Loss: 0.00048787
Epoch [30/300], Train Loss: 0.000437
Validation Loss: 0.00047061
Epoch [31/300], Train Loss: 0.000436
Validation Loss: 0.00046544
Epoch [32/300], Train Loss: 0.000418
Validation Loss: 0.00046501
Epoch [33/300], Train Loss: 0.000411
Validation Loss: 0.00042378
Epoch [34/300], Train Loss: 0.000388
Validation Loss: 0.00039427
Epoch [35/300], Train Loss: 0.000366
Validation Loss: 0.00038672
Epoch [36/300], Train Loss: 0.000353
Validation Loss: 0.00035690
Epoch [37/300], Train Loss: 0.000336
Validation Loss: 0.00035797
Epoch [38/300], Train Loss: 0.000319
Validation Loss: 0.00035159
Epoch [39/300], Train Loss: 0.000307
Validation Loss: 0.00033481
Epoch [40/300], Train Loss: 0.000300
Validation Loss: 0.00031315
Epoch [41/300], Train Loss: 0.000301
Validation Loss: 0.00031660
Epoch [42/300], Train Loss: 0.000297
Validation Loss: 0.00029599
Epoch [43/300], Train Loss: 0.000289
Validation Loss: 0.00030488
Epoch [44/300], Train Loss: 0.000283
Validation Loss: 0.00031228
Epoch [45/300], Train Loss: 0.000297
Validation Loss: 0.00028603
Epoch [46/300], Train Loss: 0.000269
Validation Loss: 0.00028828
Epoch [47/300], Train Loss: 0.000269
Validation Loss: 0.00027764
Epoch [48/300], Train Loss: 0.000258
Validation Loss: 0.00026329
Epoch [49/300], Train Loss: 0.000250
Validation Loss: 0.00026013
Epoch [50/300], Train Loss: 0.000258
Validation Loss: 0.00026897
Epoch [51/300], Train Loss: 0.000251
Validation Loss: 0.00025639
Epoch [52/300], Train Loss: 0.000247
Validation Loss: 0.00025500
Epoch [53/300], Train Loss: 0.000238
Validation Loss: 0.00026320
Epoch [54/300], Train Loss: 0.000235
Validation Loss: 0.00024289
Epoch [55/300], Train Loss: 0.000233
Validation Loss: 0.00026127
Epoch [56/300], Train Loss: 0.000232
Validation Loss: 0.00025587
Epoch [57/300], Train Loss: 0.000230
Validation Loss: 0.00024264
Epoch [58/300], Train Loss: 0.000225
Validation Loss: 0.00023099
Epoch [59/300], Train Loss: 0.000217
Validation Loss: 0.00023588
Epoch [60/300], Train Loss: 0.000224
Validation Loss: 0.00022879
Epoch [61/300], Train Loss: 0.000215
Validation Loss: 0.00022192
Epoch [62/300], Train Loss: 0.000216
Validation Loss: 0.00022338
Epoch [63/300], Train Loss: 0.000215
Validation Loss: 0.00022871
Epoch [64/300], Train Loss: 0.000207
Validation Loss: 0.00021706
Epoch [65/300], Train Loss: 0.000218
Validation Loss: 0.00023225
Epoch [66/300], Train Loss: 0.000212
Validation Loss: 0.00021146
Epoch [67/300], Train Loss: 0.000204
Validation Loss: 0.00021456
Epoch [68/300], Train Loss: 0.000197
Validation Loss: 0.00021014
Epoch [69/300], Train Loss: 0.000196
Validation Loss: 0.00020753
Epoch [70/300], Train Loss: 0.000197
Validation Loss: 0.00021525
Epoch [71/300], Train Loss: 0.000194
Validation Loss: 0.00020661
Epoch [72/300], Train Loss: 0.000195
Validation Loss: 0.00020821
Epoch [73/300], Train Loss: 0.000190
Validation Loss: 0.00020107
Epoch [74/300], Train Loss: 0.000202
Validation Loss: 0.00020607
Epoch [75/300], Train Loss: 0.000192
Validation Loss: 0.00020022
Epoch [76/300], Train Loss: 0.000188
Validation Loss: 0.00019094
Epoch [77/300], Train Loss: 0.000187
Validation Loss: 0.00019657
Epoch [78/300], Train Loss: 0.000183
Validation Loss: 0.00020095
Epoch [79/300], Train Loss: 0.000193
Validation Loss: 0.00025195
Epoch [80/300], Train Loss: 0.000205
Validation Loss: 0.00020189
Epoch [81/300], Train Loss: 0.000184
Validation Loss: 0.00018895
Epoch [82/300], Train Loss: 0.000180
Validation Loss: 0.00018687
Epoch [83/300], Train Loss: 0.000177
Validation Loss: 0.00019018
Epoch [84/300], Train Loss: 0.000177
Validation Loss: 0.00018185
Epoch [85/300], Train Loss: 0.000174
Validation Loss: 0.00018169
Epoch [86/300], Train Loss: 0.000176
Validation Loss: 0.00019720
Epoch [87/300], Train Loss: 0.000172
Validation Loss: 0.00018698
Epoch [88/300], Train Loss: 0.000172
Validation Loss: 0.00019714
Epoch [89/300], Train Loss: 0.000171
Validation Loss: 0.00017720
Epoch [90/300], Train Loss: 0.000166
Validation Loss: 0.00017871
Epoch [91/300], Train Loss: 0.000164
Validation Loss: 0.00017601
Epoch [92/300], Train Loss: 0.000161
Validation Loss: 0.00017427
Epoch [93/300], Train Loss: 0.000167
Validation Loss: 0.00017377
Epoch [94/300], Train Loss: 0.000165
Validation Loss: 0.00017294
Epoch [95/300], Train Loss: 0.000159
Validation Loss: 0.00017127
Epoch [96/300], Train Loss: 0.000157
Validation Loss: 0.00016586
Epoch [97/300], Train Loss: 0.000157
Validation Loss: 0.00016662
Epoch [98/300], Train Loss: 0.000155
Validation Loss: 0.00016520
Epoch [99/300], Train Loss: 0.000153
Validation Loss: 0.00016181
Epoch [100/300], Train Loss: 0.000152
Validation Loss: 0.00016460
Epoch [101/300], Train Loss: 0.000151
Validation Loss: 0.00015973
Epoch [102/300], Train Loss: 0.000151
Validation Loss: 0.00016006
Epoch [103/300], Train Loss: 0.000149
Validation Loss: 0.00016279
Epoch [104/300], Train Loss: 0.000165
Validation Loss: 0.00028779
Epoch [105/300], Train Loss: 0.000221
Validation Loss: 0.00019330
Epoch [106/300], Train Loss: 0.000184
Validation Loss: 0.00017468
Epoch [107/300], Train Loss: 0.000173
Validation Loss: 0.00018452
Epoch [108/300], Train Loss: 0.000165
Validation Loss: 0.00016572
Epoch [109/300], Train Loss: 0.000158
Validation Loss: 0.00016521
Epoch [110/300], Train Loss: 0.000153
Validation Loss: 0.00016056
Epoch [111/300], Train Loss: 0.000149
Validation Loss: 0.00016147
Early stopping triggered

Evaluating model for: Coffee Machine
Run 58/72 completed in 3346.41 seconds with: {'MAE': np.float32(3.2322285), 'MSE': np.float32(714.85626), 'RMSE': np.float32(26.736795), 'SAE': np.float32(0.11193435), 'NDE': np.float32(0.37160036)}

Run 59/72: hidden=512, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Coffee Machine
Dataset length: 11964 windows

Epoch [1/300], Train Loss: 0.000944
Validation Loss: 0.00102752
Epoch [2/300], Train Loss: 0.000940
Validation Loss: 0.00102967
Epoch [3/300], Train Loss: 0.000939
Validation Loss: 0.00102547
Epoch [4/300], Train Loss: 0.000937
Validation Loss: 0.00102593
Epoch [5/300], Train Loss: 0.000935
Validation Loss: 0.00101860
Epoch [6/300], Train Loss: 0.000926
Validation Loss: 0.00100706
Epoch [7/300], Train Loss: 0.000907
Validation Loss: 0.00096752
Epoch [8/300], Train Loss: 0.000863
Validation Loss: 0.00089813
Epoch [9/300], Train Loss: 0.000791
Validation Loss: 0.00080592
Epoch [10/300], Train Loss: 0.000733
Validation Loss: 0.00074544
Epoch [11/300], Train Loss: 0.000690
Validation Loss: 0.00071489
Epoch [12/300], Train Loss: 0.000659
Validation Loss: 0.00067048
Epoch [13/300], Train Loss: 0.000626
Validation Loss: 0.00066741
Epoch [14/300], Train Loss: 0.000601
Validation Loss: 0.00063219
Epoch [15/300], Train Loss: 0.000590
Validation Loss: 0.00065304
Epoch [16/300], Train Loss: 0.000563
Validation Loss: 0.00059611
Epoch [17/300], Train Loss: 0.000544
Validation Loss: 0.00057127
Epoch [18/300], Train Loss: 0.000531
Validation Loss: 0.00056651
Epoch [19/300], Train Loss: 0.000527
Validation Loss: 0.00059131
Epoch [20/300], Train Loss: 0.000529
Validation Loss: 0.00054255
Epoch [21/300], Train Loss: 0.000497
Validation Loss: 0.00051973
Epoch [22/300], Train Loss: 0.000474
Validation Loss: 0.00050040
Epoch [23/300], Train Loss: 0.000455
Validation Loss: 0.00052260
Epoch [24/300], Train Loss: 0.000452
Validation Loss: 0.00049254
Epoch [25/300], Train Loss: 0.000408
Validation Loss: 0.00042462
Epoch [26/300], Train Loss: 0.000388
Validation Loss: 0.00041460
Epoch [27/300], Train Loss: 0.000364
Validation Loss: 0.00038387
Epoch [28/300], Train Loss: 0.000353
Validation Loss: 0.00038918
Epoch [29/300], Train Loss: 0.000343
Validation Loss: 0.00035916
Epoch [30/300], Train Loss: 0.000330
Validation Loss: 0.00034419
Epoch [31/300], Train Loss: 0.000325
Validation Loss: 0.00036128
Epoch [32/300], Train Loss: 0.000318
Validation Loss: 0.00034106
Epoch [33/300], Train Loss: 0.000316
Validation Loss: 0.00033859
Epoch [34/300], Train Loss: 0.000310
Validation Loss: 0.00032677
Epoch [35/300], Train Loss: 0.000306
Validation Loss: 0.00032656
Epoch [36/300], Train Loss: 0.000301
Validation Loss: 0.00032915
Epoch [37/300], Train Loss: 0.000293
Validation Loss: 0.00032324
Epoch [38/300], Train Loss: 0.000288
Validation Loss: 0.00033341
Epoch [39/300], Train Loss: 0.000289
Validation Loss: 0.00032565
Epoch [40/300], Train Loss: 0.000285
Validation Loss: 0.00030282
Epoch [41/300], Train Loss: 0.000285
Validation Loss: 0.00030311
Epoch [42/300], Train Loss: 0.000277
Validation Loss: 0.00030014
Epoch [43/300], Train Loss: 0.000274
Validation Loss: 0.00029720
Epoch [44/300], Train Loss: 0.000267
Validation Loss: 0.00028655
Epoch [45/300], Train Loss: 0.000271
Validation Loss: 0.00033724
Epoch [46/300], Train Loss: 0.000291
Validation Loss: 0.00028173
Epoch [47/300], Train Loss: 0.000269
Validation Loss: 0.00028825
Epoch [48/300], Train Loss: 0.000259
Validation Loss: 0.00027165
Epoch [49/300], Train Loss: 0.000266
Validation Loss: 0.00028059
Epoch [50/300], Train Loss: 0.000258
Validation Loss: 0.00027028
Epoch [51/300], Train Loss: 0.000249
Validation Loss: 0.00025599
Epoch [52/300], Train Loss: 0.000250
Validation Loss: 0.00025903
Epoch [53/300], Train Loss: 0.000255
Validation Loss: 0.00028260
Epoch [54/300], Train Loss: 0.000246
Validation Loss: 0.00025398
Epoch [55/300], Train Loss: 0.000236
Validation Loss: 0.00024453
Epoch [56/300], Train Loss: 0.000228
Validation Loss: 0.00024130
Epoch [57/300], Train Loss: 0.000227
Validation Loss: 0.00023701
Epoch [58/300], Train Loss: 0.000227
Validation Loss: 0.00024713
Epoch [59/300], Train Loss: 0.000225
Validation Loss: 0.00023486
Epoch [60/300], Train Loss: 0.000243
Validation Loss: 0.00025435
Epoch [61/300], Train Loss: 0.000228
Validation Loss: 0.00025178
Epoch [62/300], Train Loss: 0.000216
Validation Loss: 0.00024129
Epoch [63/300], Train Loss: 0.000211
Validation Loss: 0.00022777
Epoch [64/300], Train Loss: 0.000210
Validation Loss: 0.00022225
Epoch [65/300], Train Loss: 0.000206
Validation Loss: 0.00023743
Epoch [66/300], Train Loss: 0.000205
Validation Loss: 0.00022676
Epoch [67/300], Train Loss: 0.000199
Validation Loss: 0.00021868
Epoch [68/300], Train Loss: 0.000201
Validation Loss: 0.00022173
Epoch [69/300], Train Loss: 0.000196
Validation Loss: 0.00021634
Epoch [70/300], Train Loss: 0.000193
Validation Loss: 0.00022086
Epoch [71/300], Train Loss: 0.000190
Validation Loss: 0.00023685
Epoch [72/300], Train Loss: 0.000190
Validation Loss: 0.00020889
Epoch [73/300], Train Loss: 0.000188
Validation Loss: 0.00021395
Epoch [74/300], Train Loss: 0.000185
Validation Loss: 0.00020409
Epoch [75/300], Train Loss: 0.000181
Validation Loss: 0.00019798
Epoch [76/300], Train Loss: 0.000175
Validation Loss: 0.00019444
Epoch [77/300], Train Loss: 0.000173
Validation Loss: 0.00020073
Epoch [78/300], Train Loss: 0.000171
Validation Loss: 0.00019587
Epoch [79/300], Train Loss: 0.000171
Validation Loss: 0.00019414
Epoch [80/300], Train Loss: 0.000166
Validation Loss: 0.00019883
Epoch [81/300], Train Loss: 0.000175
Validation Loss: 0.00019457
Epoch [82/300], Train Loss: 0.000172
Validation Loss: 0.00019067
Epoch [83/300], Train Loss: 0.000162
Validation Loss: 0.00019208
Epoch [84/300], Train Loss: 0.000159
Validation Loss: 0.00018710
Epoch [85/300], Train Loss: 0.000165
Validation Loss: 0.00019442
Epoch [86/300], Train Loss: 0.000162
Validation Loss: 0.00019229
Epoch [87/300], Train Loss: 0.000157
Validation Loss: 0.00018645
Epoch [88/300], Train Loss: 0.000155
Validation Loss: 0.00018398
Epoch [89/300], Train Loss: 0.000153
Validation Loss: 0.00017995
Epoch [90/300], Train Loss: 0.000223
Validation Loss: 0.00022472
Epoch [91/300], Train Loss: 0.000200
Validation Loss: 0.00019910
Epoch [92/300], Train Loss: 0.000171
Validation Loss: 0.00018247
Epoch [93/300], Train Loss: 0.000159
Validation Loss: 0.00018121
Epoch [94/300], Train Loss: 0.000155
Validation Loss: 0.00017547
Epoch [95/300], Train Loss: 0.000151
Validation Loss: 0.00017476
Epoch [96/300], Train Loss: 0.000148
Validation Loss: 0.00017652
Epoch [97/300], Train Loss: 0.000190
Validation Loss: 0.00019456
Epoch [98/300], Train Loss: 0.000156
Validation Loss: 0.00017485
Epoch [99/300], Train Loss: 0.000149
Validation Loss: 0.00017183
Epoch [100/300], Train Loss: 0.000145
Validation Loss: 0.00016894
Epoch [101/300], Train Loss: 0.000154
Validation Loss: 0.00017594
Epoch [102/300], Train Loss: 0.000143
Validation Loss: 0.00017153
Epoch [103/300], Train Loss: 0.000140
Validation Loss: 0.00017423
Epoch [104/300], Train Loss: 0.000146
Validation Loss: 0.00017503
Epoch [105/300], Train Loss: 0.000140
Validation Loss: 0.00016729
Epoch [106/300], Train Loss: 0.000137
Validation Loss: 0.00016820
Epoch [107/300], Train Loss: 0.000138
Validation Loss: 0.00016624
Epoch [108/300], Train Loss: 0.000136
Validation Loss: 0.00016406
Epoch [109/300], Train Loss: 0.000135
Validation Loss: 0.00016560
Epoch [110/300], Train Loss: 0.000136
Validation Loss: 0.00018458
Epoch [111/300], Train Loss: 0.000143
Validation Loss: 0.00016726
Epoch [112/300], Train Loss: 0.000130
Validation Loss: 0.00016447
Epoch [113/300], Train Loss: 0.000130
Validation Loss: 0.00015985
Epoch [114/300], Train Loss: 0.000133
Validation Loss: 0.00016226
Epoch [115/300], Train Loss: 0.000130
Validation Loss: 0.00016144
Epoch [116/300], Train Loss: 0.000127
Validation Loss: 0.00016099
Epoch [117/300], Train Loss: 0.000125
Validation Loss: 0.00015368
Epoch [118/300], Train Loss: 0.000144
Validation Loss: 0.00019673
Epoch [119/300], Train Loss: 0.000139
Validation Loss: 0.00016140
Epoch [120/300], Train Loss: 0.000125
Validation Loss: 0.00015738
Epoch [121/300], Train Loss: 0.000122
Validation Loss: 0.00015678
Epoch [122/300], Train Loss: 0.000123
Validation Loss: 0.00015514
Epoch [123/300], Train Loss: 0.000121
Validation Loss: 0.00015350
Epoch [124/300], Train Loss: 0.000120
Validation Loss: 0.00015170
Epoch [125/300], Train Loss: 0.000119
Validation Loss: 0.00015339
Epoch [126/300], Train Loss: 0.000119
Validation Loss: 0.00015017
Epoch [127/300], Train Loss: 0.000121
Validation Loss: 0.00015177
Epoch [128/300], Train Loss: 0.000125
Validation Loss: 0.00015029
Epoch [129/300], Train Loss: 0.000121
Validation Loss: 0.00015131
Epoch [130/300], Train Loss: 0.000116
Validation Loss: 0.00014688
Epoch [131/300], Train Loss: 0.000115
Validation Loss: 0.00014950
Epoch [132/300], Train Loss: 0.000114
Validation Loss: 0.00014575
Epoch [133/300], Train Loss: 0.000114
Validation Loss: 0.00014621
Epoch [134/300], Train Loss: 0.000113
Validation Loss: 0.00014806
Epoch [135/300], Train Loss: 0.000117
Validation Loss: 0.00014420
Epoch [136/300], Train Loss: 0.000114
Validation Loss: 0.00015098
Epoch [137/300], Train Loss: 0.000113
Validation Loss: 0.00014247
Epoch [138/300], Train Loss: 0.000108
Validation Loss: 0.00014138
Epoch [139/300], Train Loss: 0.000122
Validation Loss: 0.00020990
Epoch [140/300], Train Loss: 0.000143
Validation Loss: 0.00015507
Epoch [141/300], Train Loss: 0.000124
Validation Loss: 0.00014279
Epoch [142/300], Train Loss: 0.000117
Validation Loss: 0.00013820
Epoch [143/300], Train Loss: 0.000116
Validation Loss: 0.00013859
Epoch [144/300], Train Loss: 0.000112
Validation Loss: 0.00013765
Epoch [145/300], Train Loss: 0.000111
Validation Loss: 0.00013589
Epoch [146/300], Train Loss: 0.000111
Validation Loss: 0.00014111
Epoch [147/300], Train Loss: 0.000110
Validation Loss: 0.00013492
Epoch [148/300], Train Loss: 0.000109
Validation Loss: 0.00013273
Epoch [149/300], Train Loss: 0.000110
Validation Loss: 0.00013782
Epoch [150/300], Train Loss: 0.000108
Validation Loss: 0.00013454
Epoch [151/300], Train Loss: 0.000106
Validation Loss: 0.00013513
Epoch [152/300], Train Loss: 0.000103
Validation Loss: 0.00013083
Epoch [153/300], Train Loss: 0.000107
Validation Loss: 0.00013154
Epoch [154/300], Train Loss: 0.000103
Validation Loss: 0.00013015
Epoch [155/300], Train Loss: 0.000101
Validation Loss: 0.00012950
Epoch [156/300], Train Loss: 0.000109
Validation Loss: 0.00014443
Epoch [157/300], Train Loss: 0.000105
Validation Loss: 0.00013088
Epoch [158/300], Train Loss: 0.000100
Validation Loss: 0.00013012
Epoch [159/300], Train Loss: 0.000101
Validation Loss: 0.00013309
Epoch [160/300], Train Loss: 0.000101
Validation Loss: 0.00012911
Epoch [161/300], Train Loss: 0.000102
Validation Loss: 0.00012700
Epoch [162/300], Train Loss: 0.000099
Validation Loss: 0.00012283
Epoch [163/300], Train Loss: 0.000096
Validation Loss: 0.00012506
Epoch [164/300], Train Loss: 0.000099
Validation Loss: 0.00013033
Epoch [165/300], Train Loss: 0.000098
Validation Loss: 0.00012419
Epoch [166/300], Train Loss: 0.000095
Validation Loss: 0.00012457
Epoch [167/300], Train Loss: 0.000093
Validation Loss: 0.00013538
Epoch [168/300], Train Loss: 0.000095
Validation Loss: 0.00012397
Epoch [169/300], Train Loss: 0.000095
Validation Loss: 0.00012458
Epoch [170/300], Train Loss: 0.000092
Validation Loss: 0.00012591
Epoch [171/300], Train Loss: 0.000104
Validation Loss: 0.00013058
Epoch [172/300], Train Loss: 0.000126
Validation Loss: 0.00013175
Early stopping triggered

Evaluating model for: Coffee Machine
Run 59/72 completed in 6049.22 seconds with: {'MAE': np.float32(2.943453), 'MSE': np.float32(576.38605), 'RMSE': np.float32(24.008041), 'SAE': np.float32(0.06896712), 'NDE': np.float32(0.33367443)}

Run 60/72: hidden=512, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Coffee Machine
Dataset length: 11964 windows

Epoch [1/300], Train Loss: 0.000942
Validation Loss: 0.00102817
Epoch [2/300], Train Loss: 0.000939
Validation Loss: 0.00102752
Epoch [3/300], Train Loss: 0.000939
Validation Loss: 0.00102649
Epoch [4/300], Train Loss: 0.000938
Validation Loss: 0.00102945
Epoch [5/300], Train Loss: 0.000940
Validation Loss: 0.00102890
Epoch [6/300], Train Loss: 0.000938
Validation Loss: 0.00102583
Epoch [7/300], Train Loss: 0.000938
Validation Loss: 0.00102602
Epoch [8/300], Train Loss: 0.000933
Validation Loss: 0.00101900
Epoch [9/300], Train Loss: 0.000929
Validation Loss: 0.00100908
Epoch [10/300], Train Loss: 0.000908
Validation Loss: 0.00095578
Epoch [11/300], Train Loss: 0.000820
Validation Loss: 0.00082984
Epoch [12/300], Train Loss: 0.000732
Validation Loss: 0.00074127
Epoch [13/300], Train Loss: 0.000684
Validation Loss: 0.00069809
Epoch [14/300], Train Loss: 0.000641
Validation Loss: 0.00068530
Epoch [15/300], Train Loss: 0.000610
Validation Loss: 0.00071529
Epoch [16/300], Train Loss: 0.000579
Validation Loss: 0.00061602
Epoch [17/300], Train Loss: 0.000554
Validation Loss: 0.00058762
Epoch [18/300], Train Loss: 0.000543
Validation Loss: 0.00056551
Epoch [19/300], Train Loss: 0.000536
Validation Loss: 0.00058480
Epoch [20/300], Train Loss: 0.000510
Validation Loss: 0.00054519
Epoch [21/300], Train Loss: 0.000486
Validation Loss: 0.00052679
Epoch [22/300], Train Loss: 0.000477
Validation Loss: 0.00051769
Epoch [23/300], Train Loss: 0.000465
Validation Loss: 0.00049889
Epoch [24/300], Train Loss: 0.000452
Validation Loss: 0.00048266
Epoch [25/300], Train Loss: 0.000438
Validation Loss: 0.00046759
Epoch [26/300], Train Loss: 0.000432
Validation Loss: 0.00048373
Epoch [27/300], Train Loss: 0.000422
Validation Loss: 0.00048450
Epoch [28/300], Train Loss: 0.000414
Validation Loss: 0.00043948
Epoch [29/300], Train Loss: 0.000400
Validation Loss: 0.00042594
Epoch [30/300], Train Loss: 0.000390
Validation Loss: 0.00042933
Epoch [31/300], Train Loss: 0.000382
Validation Loss: 0.00040070
Epoch [32/300], Train Loss: 0.000367
Validation Loss: 0.00038769
Epoch [33/300], Train Loss: 0.000378
Validation Loss: 0.00039200
Epoch [34/300], Train Loss: 0.000407
Validation Loss: 0.00044427
Epoch [35/300], Train Loss: 0.000383
Validation Loss: 0.00041754
Epoch [36/300], Train Loss: 0.000369
Validation Loss: 0.00041777
Epoch [37/300], Train Loss: 0.000349
Validation Loss: 0.00039136
Epoch [38/300], Train Loss: 0.000339
Validation Loss: 0.00035964
Epoch [39/300], Train Loss: 0.000324
Validation Loss: 0.00036569
Epoch [40/300], Train Loss: 0.000317
Validation Loss: 0.00033487
Epoch [41/300], Train Loss: 0.000305
Validation Loss: 0.00031231
Epoch [42/300], Train Loss: 0.000313
Validation Loss: 0.00030964
Epoch [43/300], Train Loss: 0.000291
Validation Loss: 0.00030646
Epoch [44/300], Train Loss: 0.000280
Validation Loss: 0.00029678
Epoch [45/300], Train Loss: 0.000278
Validation Loss: 0.00028556
Epoch [46/300], Train Loss: 0.000263
Validation Loss: 0.00027881
Epoch [47/300], Train Loss: 0.000260
Validation Loss: 0.00027310
Epoch [48/300], Train Loss: 0.000257
Validation Loss: 0.00028039
Epoch [49/300], Train Loss: 0.000253
Validation Loss: 0.00026377
Epoch [50/300], Train Loss: 0.000252
Validation Loss: 0.00025670
Epoch [51/300], Train Loss: 0.000240
Validation Loss: 0.00025310
Epoch [52/300], Train Loss: 0.000233
Validation Loss: 0.00024991
Epoch [53/300], Train Loss: 0.000234
Validation Loss: 0.00026276
Epoch [54/300], Train Loss: 0.000242
Validation Loss: 0.00025927
Epoch [55/300], Train Loss: 0.000232
Validation Loss: 0.00024513
Epoch [56/300], Train Loss: 0.000222
Validation Loss: 0.00023947
Epoch [57/300], Train Loss: 0.000211
Validation Loss: 0.00023968
Epoch [58/300], Train Loss: 0.000208
Validation Loss: 0.00023401
Epoch [59/300], Train Loss: 0.000205
Validation Loss: 0.00023234
Epoch [60/300], Train Loss: 0.000207
Validation Loss: 0.00022985
Epoch [61/300], Train Loss: 0.000197
Validation Loss: 0.00023054
Epoch [62/300], Train Loss: 0.000227
Validation Loss: 0.00025033
Epoch [63/300], Train Loss: 0.000212
Validation Loss: 0.00022228
Epoch [64/300], Train Loss: 0.000190
Validation Loss: 0.00021564
Epoch [65/300], Train Loss: 0.000188
Validation Loss: 0.00022200
Epoch [66/300], Train Loss: 0.000187
Validation Loss: 0.00022155
Epoch [67/300], Train Loss: 0.000183
Validation Loss: 0.00021561
Epoch [68/300], Train Loss: 0.000179
Validation Loss: 0.00021522
Epoch [69/300], Train Loss: 0.000174
Validation Loss: 0.00021329
Epoch [70/300], Train Loss: 0.000172
Validation Loss: 0.00020945
Epoch [71/300], Train Loss: 0.000169
Validation Loss: 0.00020588
Epoch [72/300], Train Loss: 0.000170
Validation Loss: 0.00020428
Epoch [73/300], Train Loss: 0.000185
Validation Loss: 0.00022802
Epoch [74/300], Train Loss: 0.000191
Validation Loss: 0.00022697
Epoch [75/300], Train Loss: 0.000178
Validation Loss: 0.00020480
Epoch [76/300], Train Loss: 0.000167
Validation Loss: 0.00019781
Epoch [77/300], Train Loss: 0.000158
Validation Loss: 0.00019631
Epoch [78/300], Train Loss: 0.000155
Validation Loss: 0.00019468
Epoch [79/300], Train Loss: 0.000157
Validation Loss: 0.00019312
Epoch [80/300], Train Loss: 0.000159
Validation Loss: 0.00020624
Epoch [81/300], Train Loss: 0.000152
Validation Loss: 0.00019683
Epoch [82/300], Train Loss: 0.000153
Validation Loss: 0.00019860
Epoch [83/300], Train Loss: 0.000147
Validation Loss: 0.00019295
Epoch [84/300], Train Loss: 0.000143
Validation Loss: 0.00018952
Epoch [85/300], Train Loss: 0.000144
Validation Loss: 0.00018454
Epoch [86/300], Train Loss: 0.000142
Validation Loss: 0.00019300
Epoch [87/300], Train Loss: 0.000144
Validation Loss: 0.00019595
Epoch [88/300], Train Loss: 0.000152
Validation Loss: 0.00018951
Epoch [89/300], Train Loss: 0.000144
Validation Loss: 0.00019511
Epoch [90/300], Train Loss: 0.000142
Validation Loss: 0.00018312
Epoch [91/300], Train Loss: 0.000139
Validation Loss: 0.00019788
Epoch [92/300], Train Loss: 0.000136
Validation Loss: 0.00017836
Epoch [93/300], Train Loss: 0.000133
Validation Loss: 0.00018956
Epoch [94/300], Train Loss: 0.000132
Validation Loss: 0.00017596
Epoch [95/300], Train Loss: 0.000128
Validation Loss: 0.00017573
Epoch [96/300], Train Loss: 0.000127
Validation Loss: 0.00017906
Epoch [97/300], Train Loss: 0.000127
Validation Loss: 0.00018015
Epoch [98/300], Train Loss: 0.000127
Validation Loss: 0.00017564
Epoch [99/300], Train Loss: 0.000124
Validation Loss: 0.00018114
Epoch [100/300], Train Loss: 0.000123
Validation Loss: 0.00017601
Epoch [101/300], Train Loss: 0.000122
Validation Loss: 0.00017606
Epoch [102/300], Train Loss: 0.000122
Validation Loss: 0.00021628
Epoch [103/300], Train Loss: 0.000129
Validation Loss: 0.00017845
Epoch [104/300], Train Loss: 0.000126
Validation Loss: 0.00017303
Epoch [105/300], Train Loss: 0.000122
Validation Loss: 0.00016963
Epoch [106/300], Train Loss: 0.000119
Validation Loss: 0.00016755
Epoch [107/300], Train Loss: 0.000117
Validation Loss: 0.00016713
Epoch [108/300], Train Loss: 0.000114
Validation Loss: 0.00016331
Epoch [109/300], Train Loss: 0.000115
Validation Loss: 0.00017765
Epoch [110/300], Train Loss: 0.000114
Validation Loss: 0.00016368
Epoch [111/300], Train Loss: 0.000111
Validation Loss: 0.00016432
Epoch [112/300], Train Loss: 0.000109
Validation Loss: 0.00016652
Epoch [113/300], Train Loss: 0.000110
Validation Loss: 0.00017072
Epoch [114/300], Train Loss: 0.000108
Validation Loss: 0.00016297
Epoch [115/300], Train Loss: 0.000108
Validation Loss: 0.00016342
Epoch [116/300], Train Loss: 0.000106
Validation Loss: 0.00016104
Epoch [117/300], Train Loss: 0.000108
Validation Loss: 0.00016873
Epoch [118/300], Train Loss: 0.000109
Validation Loss: 0.00016967
Epoch [119/300], Train Loss: 0.000105
Validation Loss: 0.00016233
Epoch [120/300], Train Loss: 0.000104
Validation Loss: 0.00016379
Epoch [121/300], Train Loss: 0.000101
Validation Loss: 0.00015795
Epoch [122/300], Train Loss: 0.000103
Validation Loss: 0.00015985
Epoch [123/300], Train Loss: 0.000101
Validation Loss: 0.00015657
Epoch [124/300], Train Loss: 0.000099
Validation Loss: 0.00015430
Epoch [125/300], Train Loss: 0.000098
Validation Loss: 0.00014986
Epoch [126/300], Train Loss: 0.000099
Validation Loss: 0.00015400
Epoch [127/300], Train Loss: 0.000098
Validation Loss: 0.00015343
Epoch [128/300], Train Loss: 0.000096
Validation Loss: 0.00015481
Epoch [129/300], Train Loss: 0.000096
Validation Loss: 0.00015091
Epoch [130/300], Train Loss: 0.000095
Validation Loss: 0.00015369
Epoch [131/300], Train Loss: 0.000100
Validation Loss: 0.00015508
Epoch [132/300], Train Loss: 0.000134
Validation Loss: 0.00016395
Epoch [133/300], Train Loss: 0.000099
Validation Loss: 0.00015758
Epoch [134/300], Train Loss: 0.000095
Validation Loss: 0.00014646
Epoch [135/300], Train Loss: 0.000092
Validation Loss: 0.00014413
Epoch [136/300], Train Loss: 0.000090
Validation Loss: 0.00014282
Epoch [137/300], Train Loss: 0.000090
Validation Loss: 0.00014430
Epoch [138/300], Train Loss: 0.000090
Validation Loss: 0.00014299
Epoch [139/300], Train Loss: 0.000089
Validation Loss: 0.00014445
Epoch [140/300], Train Loss: 0.000088
Validation Loss: 0.00014041
Epoch [141/300], Train Loss: 0.000088
Validation Loss: 0.00014175
Epoch [142/300], Train Loss: 0.000089
Validation Loss: 0.00014516
Epoch [143/300], Train Loss: 0.000087
Validation Loss: 0.00014437
Epoch [144/300], Train Loss: 0.000085
Validation Loss: 0.00014086
Epoch [145/300], Train Loss: 0.000085
Validation Loss: 0.00013864
Epoch [146/300], Train Loss: 0.000084
Validation Loss: 0.00013610
Epoch [147/300], Train Loss: 0.000088
Validation Loss: 0.00014615
Epoch [148/300], Train Loss: 0.000086
Validation Loss: 0.00014483
Epoch [149/300], Train Loss: 0.000083
Validation Loss: 0.00013334
Epoch [150/300], Train Loss: 0.000082
Validation Loss: 0.00013664
Epoch [151/300], Train Loss: 0.000082
Validation Loss: 0.00014414
Epoch [152/300], Train Loss: 0.000083
Validation Loss: 0.00013393
Epoch [153/300], Train Loss: 0.000084
Validation Loss: 0.00014223
Epoch [154/300], Train Loss: 0.000082
Validation Loss: 0.00013917
Epoch [155/300], Train Loss: 0.000081
Validation Loss: 0.00013669
Epoch [156/300], Train Loss: 0.000080
Validation Loss: 0.00013737
Epoch [157/300], Train Loss: 0.000079
Validation Loss: 0.00013207
Epoch [158/300], Train Loss: 0.000078
Validation Loss: 0.00012954
Epoch [159/300], Train Loss: 0.000077
Validation Loss: 0.00013126
Epoch [160/300], Train Loss: 0.000091
Validation Loss: 0.00016086
Epoch [161/300], Train Loss: 0.000095
Validation Loss: 0.00013995
Epoch [162/300], Train Loss: 0.000079
Validation Loss: 0.00013278
Epoch [163/300], Train Loss: 0.000078
Validation Loss: 0.00013133
Epoch [164/300], Train Loss: 0.000077
Validation Loss: 0.00013298
Epoch [165/300], Train Loss: 0.000075
Validation Loss: 0.00013357
Epoch [166/300], Train Loss: 0.000074
Validation Loss: 0.00012995
Epoch [167/300], Train Loss: 0.000074
Validation Loss: 0.00013591
Epoch [168/300], Train Loss: 0.000074
Validation Loss: 0.00012801
Epoch [169/300], Train Loss: 0.000073
Validation Loss: 0.00013122
Epoch [170/300], Train Loss: 0.000074
Validation Loss: 0.00013800
Epoch [171/300], Train Loss: 0.000071
Validation Loss: 0.00012582
Epoch [172/300], Train Loss: 0.000071
Validation Loss: 0.00013393
Epoch [173/300], Train Loss: 0.000072
Validation Loss: 0.00012426
Epoch [174/300], Train Loss: 0.000071
Validation Loss: 0.00012478
Epoch [175/300], Train Loss: 0.000069
Validation Loss: 0.00012736
Epoch [176/300], Train Loss: 0.000071
Validation Loss: 0.00012591
Epoch [177/300], Train Loss: 0.000068
Validation Loss: 0.00012366
Epoch [178/300], Train Loss: 0.000067
Validation Loss: 0.00012375
Epoch [179/300], Train Loss: 0.000068
Validation Loss: 0.00012150
Epoch [180/300], Train Loss: 0.000068
Validation Loss: 0.00012439
Epoch [181/300], Train Loss: 0.000065
Validation Loss: 0.00012056
Epoch [182/300], Train Loss: 0.000065
Validation Loss: 0.00011789
Epoch [183/300], Train Loss: 0.000067
Validation Loss: 0.00012205
Epoch [184/300], Train Loss: 0.000066
Validation Loss: 0.00012635
Epoch [185/300], Train Loss: 0.000064
Validation Loss: 0.00012064
Epoch [186/300], Train Loss: 0.000067
Validation Loss: 0.00012731
Epoch [187/300], Train Loss: 0.000068
Validation Loss: 0.00012555
Epoch [188/300], Train Loss: 0.000067
Validation Loss: 0.00012642
Epoch [189/300], Train Loss: 0.000066
Validation Loss: 0.00012506
Epoch [190/300], Train Loss: 0.000065
Validation Loss: 0.00012626
Epoch [191/300], Train Loss: 0.000070
Validation Loss: 0.00012559
Epoch [192/300], Train Loss: 0.000064
Validation Loss: 0.00012388
Early stopping triggered

Evaluating model for: Coffee Machine
Run 60/72 completed in 8237.32 seconds with: {'MAE': np.float32(2.4194238), 'MSE': np.float32(550.2228), 'RMSE': np.float32(23.456827), 'SAE': np.float32(0.085127085), 'NDE': np.float32(0.32601324)}

Run 61/72: hidden=512, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Coffee Machine
Dataset length: 6004 windows

Epoch [1/300], Train Loss: 0.000981
Validation Loss: 0.00096996
Epoch [2/300], Train Loss: 0.000969
Validation Loss: 0.00096784
Epoch [3/300], Train Loss: 0.000970
Validation Loss: 0.00096604
Epoch [4/300], Train Loss: 0.000966
Validation Loss: 0.00096199
Epoch [5/300], Train Loss: 0.000964
Validation Loss: 0.00095756
Epoch [6/300], Train Loss: 0.000956
Validation Loss: 0.00095118
Epoch [7/300], Train Loss: 0.000942
Validation Loss: 0.00094319
Epoch [8/300], Train Loss: 0.000931
Validation Loss: 0.00093338
Epoch [9/300], Train Loss: 0.000926
Validation Loss: 0.00092789
Epoch [10/300], Train Loss: 0.000901
Validation Loss: 0.00090905
Epoch [11/300], Train Loss: 0.000893
Validation Loss: 0.00089181
Epoch [12/300], Train Loss: 0.000864
Validation Loss: 0.00087361
Epoch [13/300], Train Loss: 0.000835
Validation Loss: 0.00084875
Epoch [14/300], Train Loss: 0.000805
Validation Loss: 0.00082318
Epoch [15/300], Train Loss: 0.000776
Validation Loss: 0.00080175
Epoch [16/300], Train Loss: 0.000745
Validation Loss: 0.00078643
Epoch [17/300], Train Loss: 0.000726
Validation Loss: 0.00075919
Epoch [18/300], Train Loss: 0.000710
Validation Loss: 0.00074801
Epoch [19/300], Train Loss: 0.000697
Validation Loss: 0.00074116
Epoch [20/300], Train Loss: 0.000675
Validation Loss: 0.00072361
Epoch [21/300], Train Loss: 0.000675
Validation Loss: 0.00070599
Epoch [22/300], Train Loss: 0.000645
Validation Loss: 0.00072064
Epoch [23/300], Train Loss: 0.000635
Validation Loss: 0.00070516
Epoch [24/300], Train Loss: 0.000630
Validation Loss: 0.00069221
Epoch [25/300], Train Loss: 0.000614
Validation Loss: 0.00071384
Epoch [26/300], Train Loss: 0.000612
Validation Loss: 0.00068099
Epoch [27/300], Train Loss: 0.000598
Validation Loss: 0.00063652
Epoch [28/300], Train Loss: 0.000583
Validation Loss: 0.00063038
Epoch [29/300], Train Loss: 0.000575
Validation Loss: 0.00064849
Epoch [30/300], Train Loss: 0.000571
Validation Loss: 0.00064896
Epoch [31/300], Train Loss: 0.000556
Validation Loss: 0.00065238
Epoch [32/300], Train Loss: 0.000595
Validation Loss: 0.00066474
Epoch [33/300], Train Loss: 0.000578
Validation Loss: 0.00063905
Epoch [34/300], Train Loss: 0.000561
Validation Loss: 0.00061904
Epoch [35/300], Train Loss: 0.000550
Validation Loss: 0.00061677
Epoch [36/300], Train Loss: 0.000543
Validation Loss: 0.00060498
Epoch [37/300], Train Loss: 0.000539
Validation Loss: 0.00061315
Epoch [38/300], Train Loss: 0.000532
Validation Loss: 0.00059227
Epoch [39/300], Train Loss: 0.000530
Validation Loss: 0.00060813
Epoch [40/300], Train Loss: 0.000538
Validation Loss: 0.00058956
Epoch [41/300], Train Loss: 0.000520
Validation Loss: 0.00059903
Epoch [42/300], Train Loss: 0.000513
Validation Loss: 0.00057576
Epoch [43/300], Train Loss: 0.000515
Validation Loss: 0.00058605
Epoch [44/300], Train Loss: 0.000510
Validation Loss: 0.00056953
Epoch [45/300], Train Loss: 0.000498
Validation Loss: 0.00057090
Epoch [46/300], Train Loss: 0.000501
Validation Loss: 0.00055965
Epoch [47/300], Train Loss: 0.000485
Validation Loss: 0.00058380
Epoch [48/300], Train Loss: 0.000494
Validation Loss: 0.00059434
Epoch [49/300], Train Loss: 0.000488
Validation Loss: 0.00057549
Epoch [50/300], Train Loss: 0.000480
Validation Loss: 0.00059090
Epoch [51/300], Train Loss: 0.000476
Validation Loss: 0.00054644
Epoch [52/300], Train Loss: 0.000467
Validation Loss: 0.00053519
Epoch [53/300], Train Loss: 0.000475
Validation Loss: 0.00054318
Epoch [54/300], Train Loss: 0.000463
Validation Loss: 0.00052767
Epoch [55/300], Train Loss: 0.000458
Validation Loss: 0.00053805
Epoch [56/300], Train Loss: 0.000453
Validation Loss: 0.00054855
Epoch [57/300], Train Loss: 0.000458
Validation Loss: 0.00054871
Epoch [58/300], Train Loss: 0.000452
Validation Loss: 0.00052722
Epoch [59/300], Train Loss: 0.000450
Validation Loss: 0.00051493
Epoch [60/300], Train Loss: 0.000441
Validation Loss: 0.00050749
Epoch [61/300], Train Loss: 0.000432
Validation Loss: 0.00052244
Epoch [62/300], Train Loss: 0.000436
Validation Loss: 0.00050824
Epoch [63/300], Train Loss: 0.000432
Validation Loss: 0.00052444
Epoch [64/300], Train Loss: 0.000426
Validation Loss: 0.00049771
Epoch [65/300], Train Loss: 0.000411
Validation Loss: 0.00052751
Epoch [66/300], Train Loss: 0.000425
Validation Loss: 0.00053087
Epoch [67/300], Train Loss: 0.000420
Validation Loss: 0.00047128
Epoch [68/300], Train Loss: 0.000405
Validation Loss: 0.00054670
Epoch [69/300], Train Loss: 0.000413
Validation Loss: 0.00046668
Epoch [70/300], Train Loss: 0.000408
Validation Loss: 0.00047690
Epoch [71/300], Train Loss: 0.000399
Validation Loss: 0.00047838
Epoch [72/300], Train Loss: 0.000394
Validation Loss: 0.00045672
Epoch [73/300], Train Loss: 0.000393
Validation Loss: 0.00044574
Epoch [74/300], Train Loss: 0.000392
Validation Loss: 0.00046269
Epoch [75/300], Train Loss: 0.000384
Validation Loss: 0.00045481
Epoch [76/300], Train Loss: 0.000386
Validation Loss: 0.00044153
Epoch [77/300], Train Loss: 0.000374
Validation Loss: 0.00045113
Epoch [78/300], Train Loss: 0.000372
Validation Loss: 0.00045274
Epoch [79/300], Train Loss: 0.000373
Validation Loss: 0.00044095
Epoch [80/300], Train Loss: 0.000373
Validation Loss: 0.00044639
Epoch [81/300], Train Loss: 0.000367
Validation Loss: 0.00041951
Epoch [82/300], Train Loss: 0.000365
Validation Loss: 0.00045775
Epoch [83/300], Train Loss: 0.000360
Validation Loss: 0.00043001
Epoch [84/300], Train Loss: 0.000365
Validation Loss: 0.00044564
Epoch [85/300], Train Loss: 0.000355
Validation Loss: 0.00042562
Epoch [86/300], Train Loss: 0.000354
Validation Loss: 0.00042115
Epoch [87/300], Train Loss: 0.000350
Validation Loss: 0.00042944
Epoch [88/300], Train Loss: 0.000347
Validation Loss: 0.00041624
Epoch [89/300], Train Loss: 0.000339
Validation Loss: 0.00041256
Epoch [90/300], Train Loss: 0.000335
Validation Loss: 0.00038479
Epoch [91/300], Train Loss: 0.000335
Validation Loss: 0.00040087
Epoch [92/300], Train Loss: 0.000329
Validation Loss: 0.00037711
Epoch [93/300], Train Loss: 0.000325
Validation Loss: 0.00042265
Epoch [94/300], Train Loss: 0.000349
Validation Loss: 0.00044558
Epoch [95/300], Train Loss: 0.000329
Validation Loss: 0.00041828
Epoch [96/300], Train Loss: 0.000313
Validation Loss: 0.00039189
Epoch [97/300], Train Loss: 0.000319
Validation Loss: 0.00037899
Epoch [98/300], Train Loss: 0.000313
Validation Loss: 0.00035628
Epoch [99/300], Train Loss: 0.000316
Validation Loss: 0.00038502
Epoch [100/300], Train Loss: 0.000305
Validation Loss: 0.00038537
Epoch [101/300], Train Loss: 0.000310
Validation Loss: 0.00035826
Epoch [102/300], Train Loss: 0.000307
Validation Loss: 0.00037039
Epoch [103/300], Train Loss: 0.000299
Validation Loss: 0.00036374
Epoch [104/300], Train Loss: 0.000300
Validation Loss: 0.00034588
Epoch [105/300], Train Loss: 0.000294
Validation Loss: 0.00036782
Epoch [106/300], Train Loss: 0.000306
Validation Loss: 0.00037933
Epoch [107/300], Train Loss: 0.000287
Validation Loss: 0.00034724
Epoch [108/300], Train Loss: 0.000293
Validation Loss: 0.00035069
Epoch [109/300], Train Loss: 0.000288
Validation Loss: 0.00034580
Epoch [110/300], Train Loss: 0.000283
Validation Loss: 0.00037388
Epoch [111/300], Train Loss: 0.000282
Validation Loss: 0.00038514
Epoch [112/300], Train Loss: 0.000291
Validation Loss: 0.00033837
Epoch [113/300], Train Loss: 0.000283
Validation Loss: 0.00036143
Epoch [114/300], Train Loss: 0.000286
Validation Loss: 0.00033479
Epoch [115/300], Train Loss: 0.000274
Validation Loss: 0.00034708
Epoch [116/300], Train Loss: 0.000273
Validation Loss: 0.00033440
Epoch [117/300], Train Loss: 0.000279
Validation Loss: 0.00032943
Epoch [118/300], Train Loss: 0.000266
Validation Loss: 0.00032472
Epoch [119/300], Train Loss: 0.000275
Validation Loss: 0.00032101
Epoch [120/300], Train Loss: 0.000265
Validation Loss: 0.00029801
Epoch [121/300], Train Loss: 0.000260
Validation Loss: 0.00031128
Epoch [122/300], Train Loss: 0.000258
Validation Loss: 0.00031591
Epoch [123/300], Train Loss: 0.000256
Validation Loss: 0.00030567
Epoch [124/300], Train Loss: 0.000257
Validation Loss: 0.00030753
Epoch [125/300], Train Loss: 0.000256
Validation Loss: 0.00031523
Epoch [126/300], Train Loss: 0.000272
Validation Loss: 0.00031082
Epoch [127/300], Train Loss: 0.000272
Validation Loss: 0.00036010
Epoch [128/300], Train Loss: 0.000278
Validation Loss: 0.00030959
Epoch [129/300], Train Loss: 0.000261
Validation Loss: 0.00029473
Epoch [130/300], Train Loss: 0.000256
Validation Loss: 0.00029095
Epoch [131/300], Train Loss: 0.000253
Validation Loss: 0.00026609
Epoch [132/300], Train Loss: 0.000243
Validation Loss: 0.00028763
Epoch [133/300], Train Loss: 0.000237
Validation Loss: 0.00028925
Epoch [134/300], Train Loss: 0.000244
Validation Loss: 0.00029326
Epoch [135/300], Train Loss: 0.000239
Validation Loss: 0.00030562
Epoch [136/300], Train Loss: 0.000248
Validation Loss: 0.00035936
Epoch [137/300], Train Loss: 0.000248
Validation Loss: 0.00030264
Epoch [138/300], Train Loss: 0.000235
Validation Loss: 0.00028585
Epoch [139/300], Train Loss: 0.000244
Validation Loss: 0.00030597
Epoch [140/300], Train Loss: 0.000230
Validation Loss: 0.00027976
Epoch [141/300], Train Loss: 0.000234
Validation Loss: 0.00029205
Early stopping triggered

Evaluating model for: Coffee Machine
Run 61/72 completed in 1740.18 seconds with: {'MAE': np.float32(4.736407), 'MSE': np.float32(1414.1715), 'RMSE': np.float32(37.605473), 'SAE': np.float32(0.0647727), 'NDE': np.float32(0.58465844)}

Run 62/72: hidden=512, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Coffee Machine
Dataset length: 6004 windows

Epoch [1/300], Train Loss: 0.000979
Validation Loss: 0.00097123
Epoch [2/300], Train Loss: 0.000970
Validation Loss: 0.00097094
Epoch [3/300], Train Loss: 0.000973
Validation Loss: 0.00097014
Epoch [4/300], Train Loss: 0.000971
Validation Loss: 0.00096790
Epoch [5/300], Train Loss: 0.000972
Validation Loss: 0.00096564
Epoch [6/300], Train Loss: 0.000965
Validation Loss: 0.00095940
Epoch [7/300], Train Loss: 0.000954
Validation Loss: 0.00095302
Epoch [8/300], Train Loss: 0.000945
Validation Loss: 0.00094919
Epoch [9/300], Train Loss: 0.000943
Validation Loss: 0.00093766
Epoch [10/300], Train Loss: 0.000918
Validation Loss: 0.00092507
Epoch [11/300], Train Loss: 0.000917
Validation Loss: 0.00090841
Epoch [12/300], Train Loss: 0.000889
Validation Loss: 0.00089380
Epoch [13/300], Train Loss: 0.000861
Validation Loss: 0.00086892
Epoch [14/300], Train Loss: 0.000831
Validation Loss: 0.00084239
Epoch [15/300], Train Loss: 0.000797
Validation Loss: 0.00081391
Epoch [16/300], Train Loss: 0.000770
Validation Loss: 0.00079708
Epoch [17/300], Train Loss: 0.000749
Validation Loss: 0.00077250
Epoch [18/300], Train Loss: 0.000732
Validation Loss: 0.00075271
Epoch [19/300], Train Loss: 0.000719
Validation Loss: 0.00073812
Epoch [20/300], Train Loss: 0.000689
Validation Loss: 0.00073141
Epoch [21/300], Train Loss: 0.000694
Validation Loss: 0.00071246
Epoch [22/300], Train Loss: 0.000672
Validation Loss: 0.00068002
Epoch [23/300], Train Loss: 0.000652
Validation Loss: 0.00069085
Epoch [24/300], Train Loss: 0.000647
Validation Loss: 0.00067129
Epoch [25/300], Train Loss: 0.000639
Validation Loss: 0.00068303
Epoch [26/300], Train Loss: 0.000634
Validation Loss: 0.00065212
Epoch [27/300], Train Loss: 0.000617
Validation Loss: 0.00063659
Epoch [28/300], Train Loss: 0.000608
Validation Loss: 0.00062556
Epoch [29/300], Train Loss: 0.000598
Validation Loss: 0.00062722
Epoch [30/300], Train Loss: 0.000593
Validation Loss: 0.00062908
Epoch [31/300], Train Loss: 0.000579
Validation Loss: 0.00061570
Epoch [32/300], Train Loss: 0.000577
Validation Loss: 0.00063902
Epoch [33/300], Train Loss: 0.000563
Validation Loss: 0.00061044
Epoch [34/300], Train Loss: 0.000561
Validation Loss: 0.00060913
Epoch [35/300], Train Loss: 0.000551
Validation Loss: 0.00061598
Epoch [36/300], Train Loss: 0.000547
Validation Loss: 0.00057699
Epoch [37/300], Train Loss: 0.000545
Validation Loss: 0.00057536
Epoch [38/300], Train Loss: 0.000544
Validation Loss: 0.00058984
Epoch [39/300], Train Loss: 0.000560
Validation Loss: 0.00059855
Epoch [40/300], Train Loss: 0.000542
Validation Loss: 0.00056426
Epoch [41/300], Train Loss: 0.000541
Validation Loss: 0.00058033
Epoch [42/300], Train Loss: 0.000524
Validation Loss: 0.00054722
Epoch [43/300], Train Loss: 0.000531
Validation Loss: 0.00054666
Epoch [44/300], Train Loss: 0.000520
Validation Loss: 0.00054838
Epoch [45/300], Train Loss: 0.000511
Validation Loss: 0.00052653
Epoch [46/300], Train Loss: 0.000513
Validation Loss: 0.00055052
Epoch [47/300], Train Loss: 0.000495
Validation Loss: 0.00053905
Epoch [48/300], Train Loss: 0.000506
Validation Loss: 0.00052841
Epoch [49/300], Train Loss: 0.000501
Validation Loss: 0.00051236
Epoch [50/300], Train Loss: 0.000488
Validation Loss: 0.00051741
Epoch [51/300], Train Loss: 0.000485
Validation Loss: 0.00054580
Epoch [52/300], Train Loss: 0.000490
Validation Loss: 0.00052701
Epoch [53/300], Train Loss: 0.000485
Validation Loss: 0.00050813
Epoch [54/300], Train Loss: 0.000472
Validation Loss: 0.00049241
Epoch [55/300], Train Loss: 0.000470
Validation Loss: 0.00049824
Epoch [56/300], Train Loss: 0.000464
Validation Loss: 0.00049317
Epoch [57/300], Train Loss: 0.000469
Validation Loss: 0.00051270
Epoch [58/300], Train Loss: 0.000474
Validation Loss: 0.00046866
Epoch [59/300], Train Loss: 0.000457
Validation Loss: 0.00047380
Epoch [60/300], Train Loss: 0.000451
Validation Loss: 0.00046810
Epoch [61/300], Train Loss: 0.000444
Validation Loss: 0.00046304
Epoch [62/300], Train Loss: 0.000439
Validation Loss: 0.00044640
Epoch [63/300], Train Loss: 0.000441
Validation Loss: 0.00047290
Epoch [64/300], Train Loss: 0.000435
Validation Loss: 0.00042031
Epoch [65/300], Train Loss: 0.000421
Validation Loss: 0.00044045
Epoch [66/300], Train Loss: 0.000422
Validation Loss: 0.00049504
Epoch [67/300], Train Loss: 0.000420
Validation Loss: 0.00045403
Epoch [68/300], Train Loss: 0.000431
Validation Loss: 0.00044183
Epoch [69/300], Train Loss: 0.000419
Validation Loss: 0.00039457
Epoch [70/300], Train Loss: 0.000408
Validation Loss: 0.00038990
Epoch [71/300], Train Loss: 0.000395
Validation Loss: 0.00039435
Epoch [72/300], Train Loss: 0.000388
Validation Loss: 0.00042278
Epoch [73/300], Train Loss: 0.000386
Validation Loss: 0.00037416
Epoch [74/300], Train Loss: 0.000382
Validation Loss: 0.00035870
Epoch [75/300], Train Loss: 0.000370
Validation Loss: 0.00036826
Epoch [76/300], Train Loss: 0.000368
Validation Loss: 0.00033069
Epoch [77/300], Train Loss: 0.000365
Validation Loss: 0.00044104
Epoch [78/300], Train Loss: 0.000368
Validation Loss: 0.00033908
Epoch [79/300], Train Loss: 0.000334
Validation Loss: 0.00031097
Epoch [80/300], Train Loss: 0.000340
Validation Loss: 0.00032834
Epoch [81/300], Train Loss: 0.000323
Validation Loss: 0.00032050
Epoch [82/300], Train Loss: 0.000317
Validation Loss: 0.00029912
Epoch [83/300], Train Loss: 0.000328
Validation Loss: 0.00028493
Epoch [84/300], Train Loss: 0.000320
Validation Loss: 0.00026010
Epoch [85/300], Train Loss: 0.000308
Validation Loss: 0.00027255
Epoch [86/300], Train Loss: 0.000317
Validation Loss: 0.00029738
Epoch [87/300], Train Loss: 0.000318
Validation Loss: 0.00028820
Epoch [88/300], Train Loss: 0.000306
Validation Loss: 0.00026991
Epoch [89/300], Train Loss: 0.000297
Validation Loss: 0.00027074
Epoch [90/300], Train Loss: 0.000293
Validation Loss: 0.00024522
Epoch [91/300], Train Loss: 0.000289
Validation Loss: 0.00023372
Epoch [92/300], Train Loss: 0.000282
Validation Loss: 0.00023628
Epoch [93/300], Train Loss: 0.000282
Validation Loss: 0.00025739
Epoch [94/300], Train Loss: 0.000292
Validation Loss: 0.00023516
Epoch [95/300], Train Loss: 0.000281
Validation Loss: 0.00026620
Epoch [96/300], Train Loss: 0.000287
Validation Loss: 0.00025015
Epoch [97/300], Train Loss: 0.000284
Validation Loss: 0.00023333
Epoch [98/300], Train Loss: 0.000265
Validation Loss: 0.00021926
Epoch [99/300], Train Loss: 0.000266
Validation Loss: 0.00021870
Epoch [100/300], Train Loss: 0.000258
Validation Loss: 0.00020736
Epoch [101/300], Train Loss: 0.000263
Validation Loss: 0.00020754
Epoch [102/300], Train Loss: 0.000260
Validation Loss: 0.00021487
Epoch [103/300], Train Loss: 0.000252
Validation Loss: 0.00021114
Epoch [104/300], Train Loss: 0.000260
Validation Loss: 0.00020118
Epoch [105/300], Train Loss: 0.000248
Validation Loss: 0.00020716
Epoch [106/300], Train Loss: 0.000255
Validation Loss: 0.00019875
Epoch [107/300], Train Loss: 0.000243
Validation Loss: 0.00020166
Epoch [108/300], Train Loss: 0.000260
Validation Loss: 0.00021321
Epoch [109/300], Train Loss: 0.000246
Validation Loss: 0.00020055
Epoch [110/300], Train Loss: 0.000242
Validation Loss: 0.00021701
Epoch [111/300], Train Loss: 0.000244
Validation Loss: 0.00021256
Epoch [112/300], Train Loss: 0.000240
Validation Loss: 0.00019781
Epoch [113/300], Train Loss: 0.000235
Validation Loss: 0.00021793
Epoch [114/300], Train Loss: 0.000241
Validation Loss: 0.00019861
Epoch [115/300], Train Loss: 0.000236
Validation Loss: 0.00018280
Epoch [116/300], Train Loss: 0.000247
Validation Loss: 0.00023090
Epoch [117/300], Train Loss: 0.000236
Validation Loss: 0.00019108
Epoch [118/300], Train Loss: 0.000242
Validation Loss: 0.00020534
Epoch [119/300], Train Loss: 0.000236
Validation Loss: 0.00018740
Epoch [120/300], Train Loss: 0.000224
Validation Loss: 0.00019099
Epoch [121/300], Train Loss: 0.000221
Validation Loss: 0.00020128
Epoch [122/300], Train Loss: 0.000227
Validation Loss: 0.00022678
Epoch [123/300], Train Loss: 0.000228
Validation Loss: 0.00020006
Epoch [124/300], Train Loss: 0.000224
Validation Loss: 0.00018048
Epoch [125/300], Train Loss: 0.000220
Validation Loss: 0.00023171
Epoch [126/300], Train Loss: 0.000232
Validation Loss: 0.00019282
Epoch [127/300], Train Loss: 0.000219
Validation Loss: 0.00018798
Epoch [128/300], Train Loss: 0.000217
Validation Loss: 0.00017868
Epoch [129/300], Train Loss: 0.000219
Validation Loss: 0.00018106
Epoch [130/300], Train Loss: 0.000216
Validation Loss: 0.00017083
Epoch [131/300], Train Loss: 0.000211
Validation Loss: 0.00017192
Epoch [132/300], Train Loss: 0.000214
Validation Loss: 0.00017222
Epoch [133/300], Train Loss: 0.000210
Validation Loss: 0.00019088
Epoch [134/300], Train Loss: 0.000220
Validation Loss: 0.00017537
Epoch [135/300], Train Loss: 0.000208
Validation Loss: 0.00017263
Epoch [136/300], Train Loss: 0.000208
Validation Loss: 0.00018576
Epoch [137/300], Train Loss: 0.000206
Validation Loss: 0.00016886
Epoch [138/300], Train Loss: 0.000209
Validation Loss: 0.00016950
Epoch [139/300], Train Loss: 0.000209
Validation Loss: 0.00017404
Epoch [140/300], Train Loss: 0.000209
Validation Loss: 0.00016629
Epoch [141/300], Train Loss: 0.000210
Validation Loss: 0.00017594
Epoch [142/300], Train Loss: 0.000205
Validation Loss: 0.00016940
Epoch [143/300], Train Loss: 0.000204
Validation Loss: 0.00020352
Epoch [144/300], Train Loss: 0.000204
Validation Loss: 0.00017397
Epoch [145/300], Train Loss: 0.000206
Validation Loss: 0.00016945
Epoch [146/300], Train Loss: 0.000202
Validation Loss: 0.00017837
Epoch [147/300], Train Loss: 0.000204
Validation Loss: 0.00016843
Epoch [148/300], Train Loss: 0.000200
Validation Loss: 0.00018021
Epoch [149/300], Train Loss: 0.000194
Validation Loss: 0.00017391
Epoch [150/300], Train Loss: 0.000197
Validation Loss: 0.00018457
Early stopping triggered

Evaluating model for: Coffee Machine
Run 62/72 completed in 2268.90 seconds with: {'MAE': np.float32(4.054377), 'MSE': np.float32(1247.6749), 'RMSE': np.float32(35.32244), 'SAE': np.float32(0.08337705), 'NDE': np.float32(0.54916394)}

Run 63/72: hidden=512, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Coffee Machine
Dataset length: 6004 windows

Epoch [1/300], Train Loss: 0.001042
Validation Loss: 0.00097428
Epoch [2/300], Train Loss: 0.000976
Validation Loss: 0.00097394
Epoch [3/300], Train Loss: 0.000979
Validation Loss: 0.00097352
Epoch [4/300], Train Loss: 0.000977
Validation Loss: 0.00097332
Epoch [5/300], Train Loss: 0.000979
Validation Loss: 0.00097303
Epoch [6/300], Train Loss: 0.000977
Validation Loss: 0.00097286
Epoch [7/300], Train Loss: 0.000971
Validation Loss: 0.00097225
Epoch [8/300], Train Loss: 0.000968
Validation Loss: 0.00097257
Epoch [9/300], Train Loss: 0.000977
Validation Loss: 0.00097073
Epoch [10/300], Train Loss: 0.000964
Validation Loss: 0.00097206
Epoch [11/300], Train Loss: 0.000977
Validation Loss: 0.00097002
Epoch [12/300], Train Loss: 0.000971
Validation Loss: 0.00096913
Epoch [13/300], Train Loss: 0.000966
Validation Loss: 0.00096647
Epoch [14/300], Train Loss: 0.000962
Validation Loss: 0.00096459
Epoch [15/300], Train Loss: 0.000957
Validation Loss: 0.00095930
Epoch [16/300], Train Loss: 0.000946
Validation Loss: 0.00095256
Epoch [17/300], Train Loss: 0.000939
Validation Loss: 0.00094034
Epoch [18/300], Train Loss: 0.000921
Validation Loss: 0.00092165
Epoch [19/300], Train Loss: 0.000890
Validation Loss: 0.00089379
Epoch [20/300], Train Loss: 0.000842
Validation Loss: 0.00085184
Epoch [21/300], Train Loss: 0.000811
Validation Loss: 0.00081240
Epoch [22/300], Train Loss: 0.000770
Validation Loss: 0.00078846
Epoch [23/300], Train Loss: 0.000738
Validation Loss: 0.00075440
Epoch [24/300], Train Loss: 0.000720
Validation Loss: 0.00073010
Epoch [25/300], Train Loss: 0.000698
Validation Loss: 0.00075218
Epoch [26/300], Train Loss: 0.000688
Validation Loss: 0.00071465
Epoch [27/300], Train Loss: 0.000677
Validation Loss: 0.00072602
Epoch [28/300], Train Loss: 0.000670
Validation Loss: 0.00068767
Epoch [29/300], Train Loss: 0.000650
Validation Loss: 0.00066524
Epoch [30/300], Train Loss: 0.000641
Validation Loss: 0.00064427
Epoch [31/300], Train Loss: 0.000620
Validation Loss: 0.00065257
Epoch [32/300], Train Loss: 0.000614
Validation Loss: 0.00063749
Epoch [33/300], Train Loss: 0.000603
Validation Loss: 0.00061575
Epoch [34/300], Train Loss: 0.000595
Validation Loss: 0.00061048
Epoch [35/300], Train Loss: 0.000578
Validation Loss: 0.00061901
Epoch [36/300], Train Loss: 0.000572
Validation Loss: 0.00056618
Epoch [37/300], Train Loss: 0.000564
Validation Loss: 0.00058633
Epoch [38/300], Train Loss: 0.000552
Validation Loss: 0.00059093
Epoch [39/300], Train Loss: 0.000568
Validation Loss: 0.00060933
Epoch [40/300], Train Loss: 0.000562
Validation Loss: 0.00061053
Epoch [41/300], Train Loss: 0.000553
Validation Loss: 0.00058195
Epoch [42/300], Train Loss: 0.000538
Validation Loss: 0.00062512
Epoch [43/300], Train Loss: 0.000586
Validation Loss: 0.00058725
Epoch [44/300], Train Loss: 0.000541
Validation Loss: 0.00054652
Epoch [45/300], Train Loss: 0.000536
Validation Loss: 0.00053259
Epoch [46/300], Train Loss: 0.000559
Validation Loss: 0.00056060
Epoch [47/300], Train Loss: 0.000533
Validation Loss: 0.00054972
Epoch [48/300], Train Loss: 0.000535
Validation Loss: 0.00053116
Epoch [49/300], Train Loss: 0.000529
Validation Loss: 0.00054418
Epoch [50/300], Train Loss: 0.000514
Validation Loss: 0.00055556
Epoch [51/300], Train Loss: 0.000519
Validation Loss: 0.00052480
Epoch [52/300], Train Loss: 0.000502
Validation Loss: 0.00054327
Epoch [53/300], Train Loss: 0.000505
Validation Loss: 0.00052347
Epoch [54/300], Train Loss: 0.000491
Validation Loss: 0.00051152
Epoch [55/300], Train Loss: 0.000512
Validation Loss: 0.00054448
Epoch [56/300], Train Loss: 0.000505
Validation Loss: 0.00053255
Epoch [57/300], Train Loss: 0.000500
Validation Loss: 0.00052929
Epoch [58/300], Train Loss: 0.000494
Validation Loss: 0.00051114
Epoch [59/300], Train Loss: 0.000484
Validation Loss: 0.00050236
Epoch [60/300], Train Loss: 0.000489
Validation Loss: 0.00051941
Epoch [61/300], Train Loss: 0.000481
Validation Loss: 0.00050364
Epoch [62/300], Train Loss: 0.000478
Validation Loss: 0.00049590
Epoch [63/300], Train Loss: 0.000478
Validation Loss: 0.00049959
Epoch [64/300], Train Loss: 0.000474
Validation Loss: 0.00047444
Epoch [65/300], Train Loss: 0.000451
Validation Loss: 0.00048497
Epoch [66/300], Train Loss: 0.000476
Validation Loss: 0.00046457
Epoch [67/300], Train Loss: 0.000449
Validation Loss: 0.00046373
Epoch [68/300], Train Loss: 0.000444
Validation Loss: 0.00045700
Epoch [69/300], Train Loss: 0.000457
Validation Loss: 0.00048090
Epoch [70/300], Train Loss: 0.000447
Validation Loss: 0.00045793
Epoch [71/300], Train Loss: 0.000428
Validation Loss: 0.00044248
Epoch [72/300], Train Loss: 0.000417
Validation Loss: 0.00042943
Epoch [73/300], Train Loss: 0.000413
Validation Loss: 0.00044058
Epoch [74/300], Train Loss: 0.000411
Validation Loss: 0.00041152
Epoch [75/300], Train Loss: 0.000402
Validation Loss: 0.00043263
Epoch [76/300], Train Loss: 0.000401
Validation Loss: 0.00039510
Epoch [77/300], Train Loss: 0.000396
Validation Loss: 0.00040937
Epoch [78/300], Train Loss: 0.000398
Validation Loss: 0.00040263
Epoch [79/300], Train Loss: 0.000422
Validation Loss: 0.00040161
Epoch [80/300], Train Loss: 0.000403
Validation Loss: 0.00038224
Epoch [81/300], Train Loss: 0.000385
Validation Loss: 0.00038152
Epoch [82/300], Train Loss: 0.000392
Validation Loss: 0.00037340
Epoch [83/300], Train Loss: 0.000375
Validation Loss: 0.00036224
Epoch [84/300], Train Loss: 0.000374
Validation Loss: 0.00034999
Epoch [85/300], Train Loss: 0.000362
Validation Loss: 0.00035511
Epoch [86/300], Train Loss: 0.000358
Validation Loss: 0.00033116
Epoch [87/300], Train Loss: 0.000343
Validation Loss: 0.00033327
Epoch [88/300], Train Loss: 0.000341
Validation Loss: 0.00034007
Epoch [89/300], Train Loss: 0.000353
Validation Loss: 0.00033548
Epoch [90/300], Train Loss: 0.000333
Validation Loss: 0.00031052
Epoch [91/300], Train Loss: 0.000336
Validation Loss: 0.00032934
Epoch [92/300], Train Loss: 0.000323
Validation Loss: 0.00029179
Epoch [93/300], Train Loss: 0.000315
Validation Loss: 0.00030710
Epoch [94/300], Train Loss: 0.000308
Validation Loss: 0.00025925
Epoch [95/300], Train Loss: 0.000299
Validation Loss: 0.00025938
Epoch [96/300], Train Loss: 0.000296
Validation Loss: 0.00026637
Epoch [97/300], Train Loss: 0.000292
Validation Loss: 0.00023187
Epoch [98/300], Train Loss: 0.000296
Validation Loss: 0.00023733
Epoch [99/300], Train Loss: 0.000282
Validation Loss: 0.00022799
Epoch [100/300], Train Loss: 0.000267
Validation Loss: 0.00021770
Epoch [101/300], Train Loss: 0.000270
Validation Loss: 0.00021962
Epoch [102/300], Train Loss: 0.000275
Validation Loss: 0.00029865
Epoch [103/300], Train Loss: 0.000277
Validation Loss: 0.00022220
Epoch [104/300], Train Loss: 0.000258
Validation Loss: 0.00021473
Epoch [105/300], Train Loss: 0.000255
Validation Loss: 0.00021654
Epoch [106/300], Train Loss: 0.000253
Validation Loss: 0.00020551
Epoch [107/300], Train Loss: 0.000244
Validation Loss: 0.00020577
Epoch [108/300], Train Loss: 0.000239
Validation Loss: 0.00021826
Epoch [109/300], Train Loss: 0.000240
Validation Loss: 0.00020385
Epoch [110/300], Train Loss: 0.000234
Validation Loss: 0.00020835
Epoch [111/300], Train Loss: 0.000231
Validation Loss: 0.00020238
Epoch [112/300], Train Loss: 0.000235
Validation Loss: 0.00020195
Epoch [113/300], Train Loss: 0.000225
Validation Loss: 0.00020112
Epoch [114/300], Train Loss: 0.000228
Validation Loss: 0.00018717
Epoch [115/300], Train Loss: 0.000223
Validation Loss: 0.00018561
Epoch [116/300], Train Loss: 0.000232
Validation Loss: 0.00019374
Epoch [117/300], Train Loss: 0.000221
Validation Loss: 0.00018964
Epoch [118/300], Train Loss: 0.000214
Validation Loss: 0.00019126
Epoch [119/300], Train Loss: 0.000230
Validation Loss: 0.00021021
Epoch [120/300], Train Loss: 0.000218
Validation Loss: 0.00019287
Epoch [121/300], Train Loss: 0.000211
Validation Loss: 0.00019210
Epoch [122/300], Train Loss: 0.000207
Validation Loss: 0.00018504
Epoch [123/300], Train Loss: 0.000203
Validation Loss: 0.00019154
Epoch [124/300], Train Loss: 0.000206
Validation Loss: 0.00018719
Epoch [125/300], Train Loss: 0.000202
Validation Loss: 0.00017755
Epoch [126/300], Train Loss: 0.000198
Validation Loss: 0.00018013
Epoch [127/300], Train Loss: 0.000199
Validation Loss: 0.00018238
Epoch [128/300], Train Loss: 0.000197
Validation Loss: 0.00017831
Epoch [129/300], Train Loss: 0.000198
Validation Loss: 0.00017668
Epoch [130/300], Train Loss: 0.000204
Validation Loss: 0.00017736
Epoch [131/300], Train Loss: 0.000193
Validation Loss: 0.00017867
Epoch [132/300], Train Loss: 0.000189
Validation Loss: 0.00017799
Epoch [133/300], Train Loss: 0.000189
Validation Loss: 0.00018049
Epoch [134/300], Train Loss: 0.000192
Validation Loss: 0.00017893
Epoch [135/300], Train Loss: 0.000190
Validation Loss: 0.00018136
Epoch [136/300], Train Loss: 0.000187
Validation Loss: 0.00017553
Epoch [137/300], Train Loss: 0.000181
Validation Loss: 0.00017657
Epoch [138/300], Train Loss: 0.000186
Validation Loss: 0.00018104
Epoch [139/300], Train Loss: 0.000186
Validation Loss: 0.00016934
Epoch [140/300], Train Loss: 0.000185
Validation Loss: 0.00018100
Epoch [141/300], Train Loss: 0.000185
Validation Loss: 0.00017730
Epoch [142/300], Train Loss: 0.000182
Validation Loss: 0.00017261
Epoch [143/300], Train Loss: 0.000180
Validation Loss: 0.00017116
Epoch [144/300], Train Loss: 0.000175
Validation Loss: 0.00017104
Epoch [145/300], Train Loss: 0.000172
Validation Loss: 0.00017285
Epoch [146/300], Train Loss: 0.000175
Validation Loss: 0.00017808
Epoch [147/300], Train Loss: 0.000172
Validation Loss: 0.00016787
Epoch [148/300], Train Loss: 0.000176
Validation Loss: 0.00016855
Epoch [149/300], Train Loss: 0.000169
Validation Loss: 0.00016480
Epoch [150/300], Train Loss: 0.000171
Validation Loss: 0.00016566
Epoch [151/300], Train Loss: 0.000167
Validation Loss: 0.00016616
Epoch [152/300], Train Loss: 0.000165
Validation Loss: 0.00016702
Epoch [153/300], Train Loss: 0.000162
Validation Loss: 0.00017463
Epoch [154/300], Train Loss: 0.000162
Validation Loss: 0.00017339
Epoch [155/300], Train Loss: 0.000164
Validation Loss: 0.00016346
Epoch [156/300], Train Loss: 0.000167
Validation Loss: 0.00016922
Epoch [157/300], Train Loss: 0.000164
Validation Loss: 0.00016881
Epoch [158/300], Train Loss: 0.000165
Validation Loss: 0.00016699
Epoch [159/300], Train Loss: 0.000160
Validation Loss: 0.00016599
Epoch [160/300], Train Loss: 0.000162
Validation Loss: 0.00017213
Epoch [161/300], Train Loss: 0.000159
Validation Loss: 0.00016007
Epoch [162/300], Train Loss: 0.000161
Validation Loss: 0.00017172
Epoch [163/300], Train Loss: 0.000159
Validation Loss: 0.00016045
Epoch [164/300], Train Loss: 0.000157
Validation Loss: 0.00016561
Epoch [165/300], Train Loss: 0.000154
Validation Loss: 0.00016685
Epoch [166/300], Train Loss: 0.000157
Validation Loss: 0.00017109
Epoch [167/300], Train Loss: 0.000155
Validation Loss: 0.00016060
Epoch [168/300], Train Loss: 0.000155
Validation Loss: 0.00015495
Epoch [169/300], Train Loss: 0.000154
Validation Loss: 0.00015879
Epoch [170/300], Train Loss: 0.000152
Validation Loss: 0.00017167
Epoch [171/300], Train Loss: 0.000155
Validation Loss: 0.00016450
Epoch [172/300], Train Loss: 0.000151
Validation Loss: 0.00016494
Epoch [173/300], Train Loss: 0.000153
Validation Loss: 0.00016347
Epoch [174/300], Train Loss: 0.000153
Validation Loss: 0.00015411
Epoch [175/300], Train Loss: 0.000150
Validation Loss: 0.00016595
Epoch [176/300], Train Loss: 0.000148
Validation Loss: 0.00016569
Epoch [177/300], Train Loss: 0.000155
Validation Loss: 0.00016416
Epoch [178/300], Train Loss: 0.000147
Validation Loss: 0.00016805
Epoch [179/300], Train Loss: 0.000146
Validation Loss: 0.00016115
Epoch [180/300], Train Loss: 0.000143
Validation Loss: 0.00016138
Epoch [181/300], Train Loss: 0.000146
Validation Loss: 0.00016171
Epoch [182/300], Train Loss: 0.000147
Validation Loss: 0.00016875
Epoch [183/300], Train Loss: 0.000146
Validation Loss: 0.00015753
Epoch [184/300], Train Loss: 0.000144
Validation Loss: 0.00016602
Early stopping triggered

Evaluating model for: Coffee Machine
Run 63/72 completed in 3265.22 seconds with: {'MAE': np.float32(3.7475915), 'MSE': np.float32(994.4121), 'RMSE': np.float32(31.5343), 'SAE': np.float32(0.11410271), 'NDE': np.float32(0.49026904)}

Run 64/72: hidden=512, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Coffee Machine
Dataset length: 6004 windows

Epoch [1/300], Train Loss: 0.000980
Validation Loss: 0.00097144
Epoch [2/300], Train Loss: 0.000971
Validation Loss: 0.00097195
Epoch [3/300], Train Loss: 0.000975
Validation Loss: 0.00097223
Epoch [4/300], Train Loss: 0.000974
Validation Loss: 0.00097366
Epoch [5/300], Train Loss: 0.000977
Validation Loss: 0.00097189
Epoch [6/300], Train Loss: 0.000974
Validation Loss: 0.00097144
Epoch [7/300], Train Loss: 0.000968
Validation Loss: 0.00097258
Epoch [8/300], Train Loss: 0.000966
Validation Loss: 0.00097281
Epoch [9/300], Train Loss: 0.000976
Validation Loss: 0.00097152
Epoch [10/300], Train Loss: 0.000963
Validation Loss: 0.00097169
Epoch [11/300], Train Loss: 0.000977
Validation Loss: 0.00097138
Epoch [12/300], Train Loss: 0.000972
Validation Loss: 0.00097162
Epoch [13/300], Train Loss: 0.000968
Validation Loss: 0.00097117
Epoch [14/300], Train Loss: 0.000967
Validation Loss: 0.00097120
Epoch [15/300], Train Loss: 0.000966
Validation Loss: 0.00097075
Epoch [16/300], Train Loss: 0.000960
Validation Loss: 0.00096969
Epoch [17/300], Train Loss: 0.000963
Validation Loss: 0.00096748
Epoch [18/300], Train Loss: 0.000963
Validation Loss: 0.00096500
Epoch [19/300], Train Loss: 0.000960
Validation Loss: 0.00096284
Epoch [20/300], Train Loss: 0.000952
Validation Loss: 0.00095841
Epoch [21/300], Train Loss: 0.000956
Validation Loss: 0.00094356
Epoch [22/300], Train Loss: 0.000925
Validation Loss: 0.00092557
Epoch [23/300], Train Loss: 0.000890
Validation Loss: 0.00088553
Epoch [24/300], Train Loss: 0.000838
Validation Loss: 0.00082858
Epoch [25/300], Train Loss: 0.000775
Validation Loss: 0.00078965
Epoch [26/300], Train Loss: 0.000749
Validation Loss: 0.00079234
Epoch [27/300], Train Loss: 0.000721
Validation Loss: 0.00074504
Epoch [28/300], Train Loss: 0.000695
Validation Loss: 0.00072637
Epoch [29/300], Train Loss: 0.000677
Validation Loss: 0.00072983
Epoch [30/300], Train Loss: 0.000666
Validation Loss: 0.00069140
Epoch [31/300], Train Loss: 0.000655
Validation Loss: 0.00067731
Epoch [32/300], Train Loss: 0.000647
Validation Loss: 0.00066239
Epoch [33/300], Train Loss: 0.000619
Validation Loss: 0.00064328
Epoch [34/300], Train Loss: 0.000615
Validation Loss: 0.00062715
Epoch [35/300], Train Loss: 0.000593
Validation Loss: 0.00061302
Epoch [36/300], Train Loss: 0.000588
Validation Loss: 0.00058748
Epoch [37/300], Train Loss: 0.000578
Validation Loss: 0.00060026
Epoch [38/300], Train Loss: 0.000571
Validation Loss: 0.00059739
Epoch [39/300], Train Loss: 0.000572
Validation Loss: 0.00059315
Epoch [40/300], Train Loss: 0.000558
Validation Loss: 0.00057686
Epoch [41/300], Train Loss: 0.000612
Validation Loss: 0.00072312
Epoch [42/300], Train Loss: 0.000627
Validation Loss: 0.00060378
Epoch [43/300], Train Loss: 0.000572
Validation Loss: 0.00056022
Epoch [44/300], Train Loss: 0.000552
Validation Loss: 0.00054801
Epoch [45/300], Train Loss: 0.000529
Validation Loss: 0.00051229
Epoch [46/300], Train Loss: 0.000505
Validation Loss: 0.00051907
Epoch [47/300], Train Loss: 0.000484
Validation Loss: 0.00050279
Epoch [48/300], Train Loss: 0.000479
Validation Loss: 0.00049919
Epoch [49/300], Train Loss: 0.000434
Validation Loss: 0.00044458
Epoch [50/300], Train Loss: 0.000410
Validation Loss: 0.00041802
Epoch [51/300], Train Loss: 0.000388
Validation Loss: 0.00036800
Epoch [52/300], Train Loss: 0.000382
Validation Loss: 0.00035688
Epoch [53/300], Train Loss: 0.000382
Validation Loss: 0.00036041
Epoch [54/300], Train Loss: 0.000357
Validation Loss: 0.00032866
Epoch [55/300], Train Loss: 0.000357
Validation Loss: 0.00033934
Epoch [56/300], Train Loss: 0.000349
Validation Loss: 0.00033626
Epoch [57/300], Train Loss: 0.000349
Validation Loss: 0.00034133
Epoch [58/300], Train Loss: 0.000345
Validation Loss: 0.00031161
Epoch [59/300], Train Loss: 0.000341
Validation Loss: 0.00031482
Epoch [60/300], Train Loss: 0.000332
Validation Loss: 0.00033493
Epoch [61/300], Train Loss: 0.000357
Validation Loss: 0.00030494
Epoch [62/300], Train Loss: 0.000328
Validation Loss: 0.00027945
Epoch [63/300], Train Loss: 0.000326
Validation Loss: 0.00027322
Epoch [64/300], Train Loss: 0.000319
Validation Loss: 0.00028905
Epoch [65/300], Train Loss: 0.000306
Validation Loss: 0.00027486
Epoch [66/300], Train Loss: 0.000308
Validation Loss: 0.00026015
Epoch [67/300], Train Loss: 0.000303
Validation Loss: 0.00026073
Epoch [68/300], Train Loss: 0.000303
Validation Loss: 0.00026505
Epoch [69/300], Train Loss: 0.000300
Validation Loss: 0.00025721
Epoch [70/300], Train Loss: 0.000302
Validation Loss: 0.00024033
Epoch [71/300], Train Loss: 0.000288
Validation Loss: 0.00024831
Epoch [72/300], Train Loss: 0.000287
Validation Loss: 0.00024439
Epoch [73/300], Train Loss: 0.000287
Validation Loss: 0.00022971
Epoch [74/300], Train Loss: 0.000277
Validation Loss: 0.00024892
Epoch [75/300], Train Loss: 0.000270
Validation Loss: 0.00023027
Epoch [76/300], Train Loss: 0.000268
Validation Loss: 0.00022785
Epoch [77/300], Train Loss: 0.000271
Validation Loss: 0.00022211
Epoch [78/300], Train Loss: 0.000285
Validation Loss: 0.00022515
Epoch [79/300], Train Loss: 0.000265
Validation Loss: 0.00022125
Epoch [80/300], Train Loss: 0.000262
Validation Loss: 0.00021934
Epoch [81/300], Train Loss: 0.000256
Validation Loss: 0.00021772
Epoch [82/300], Train Loss: 0.000254
Validation Loss: 0.00020904
Epoch [83/300], Train Loss: 0.000248
Validation Loss: 0.00021204
Epoch [84/300], Train Loss: 0.000254
Validation Loss: 0.00020773
Epoch [85/300], Train Loss: 0.000249
Validation Loss: 0.00022266
Epoch [86/300], Train Loss: 0.000247
Validation Loss: 0.00020463
Epoch [87/300], Train Loss: 0.000241
Validation Loss: 0.00020053
Epoch [88/300], Train Loss: 0.000241
Validation Loss: 0.00019822
Epoch [89/300], Train Loss: 0.000233
Validation Loss: 0.00018852
Epoch [90/300], Train Loss: 0.000231
Validation Loss: 0.00019809
Epoch [91/300], Train Loss: 0.000235
Validation Loss: 0.00019299
Epoch [92/300], Train Loss: 0.000249
Validation Loss: 0.00021163
Epoch [93/300], Train Loss: 0.000233
Validation Loss: 0.00022994
Epoch [94/300], Train Loss: 0.000237
Validation Loss: 0.00022101
Epoch [95/300], Train Loss: 0.000230
Validation Loss: 0.00018710
Epoch [96/300], Train Loss: 0.000221
Validation Loss: 0.00018728
Epoch [97/300], Train Loss: 0.000227
Validation Loss: 0.00020714
Epoch [98/300], Train Loss: 0.000223
Validation Loss: 0.00018389
Epoch [99/300], Train Loss: 0.000224
Validation Loss: 0.00017981
Epoch [100/300], Train Loss: 0.000214
Validation Loss: 0.00017473
Epoch [101/300], Train Loss: 0.000218
Validation Loss: 0.00019491
Epoch [102/300], Train Loss: 0.000240
Validation Loss: 0.00025730
Epoch [103/300], Train Loss: 0.000225
Validation Loss: 0.00017705
Epoch [104/300], Train Loss: 0.000213
Validation Loss: 0.00018348
Epoch [105/300], Train Loss: 0.000211
Validation Loss: 0.00019126
Epoch [106/300], Train Loss: 0.000212
Validation Loss: 0.00019063
Epoch [107/300], Train Loss: 0.000210
Validation Loss: 0.00018734
Epoch [108/300], Train Loss: 0.000206
Validation Loss: 0.00021352
Epoch [109/300], Train Loss: 0.000216
Validation Loss: 0.00019260
Epoch [110/300], Train Loss: 0.000204
Validation Loss: 0.00018413
Early stopping triggered

Evaluating model for: Coffee Machine
Run 64/72 completed in 2383.06 seconds with: {'MAE': np.float32(3.903409), 'MSE': np.float32(1217.6277), 'RMSE': np.float32(34.894524), 'SAE': np.float32(0.09409046), 'NDE': np.float32(0.54251105)}

Run 65/72: hidden=512, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Coffee Machine
Dataset length: 5916 windows

Epoch [1/300], Train Loss: 0.001089
Validation Loss: 0.00101186
Epoch [2/300], Train Loss: 0.000987
Validation Loss: 0.00100691
Epoch [3/300], Train Loss: 0.000985
Validation Loss: 0.00100605
Epoch [4/300], Train Loss: 0.000984
Validation Loss: 0.00100406
Epoch [5/300], Train Loss: 0.000983
Validation Loss: 0.00100249
Epoch [6/300], Train Loss: 0.000981
Validation Loss: 0.00100086
Epoch [7/300], Train Loss: 0.000979
Validation Loss: 0.00099916
Epoch [8/300], Train Loss: 0.000978
Validation Loss: 0.00099683
Epoch [9/300], Train Loss: 0.000975
Validation Loss: 0.00099467
Epoch [10/300], Train Loss: 0.000971
Validation Loss: 0.00098932
Epoch [11/300], Train Loss: 0.000966
Validation Loss: 0.00098319
Epoch [12/300], Train Loss: 0.000961
Validation Loss: 0.00097637
Epoch [13/300], Train Loss: 0.000953
Validation Loss: 0.00096774
Epoch [14/300], Train Loss: 0.000942
Validation Loss: 0.00095291
Epoch [15/300], Train Loss: 0.000926
Validation Loss: 0.00093592
Epoch [16/300], Train Loss: 0.000907
Validation Loss: 0.00091654
Epoch [17/300], Train Loss: 0.000885
Validation Loss: 0.00089401
Epoch [18/300], Train Loss: 0.000861
Validation Loss: 0.00086735
Epoch [19/300], Train Loss: 0.000841
Validation Loss: 0.00084769
Epoch [20/300], Train Loss: 0.000814
Validation Loss: 0.00081666
Epoch [21/300], Train Loss: 0.000785
Validation Loss: 0.00079832
Epoch [22/300], Train Loss: 0.000765
Validation Loss: 0.00076730
Epoch [23/300], Train Loss: 0.000737
Validation Loss: 0.00074644
Epoch [24/300], Train Loss: 0.000717
Validation Loss: 0.00073237
Epoch [25/300], Train Loss: 0.000701
Validation Loss: 0.00070678
Epoch [26/300], Train Loss: 0.000685
Validation Loss: 0.00068294
Epoch [27/300], Train Loss: 0.000666
Validation Loss: 0.00066879
Epoch [28/300], Train Loss: 0.000649
Validation Loss: 0.00064925
Epoch [29/300], Train Loss: 0.000639
Validation Loss: 0.00064253
Epoch [30/300], Train Loss: 0.000628
Validation Loss: 0.00062859
Epoch [31/300], Train Loss: 0.000619
Validation Loss: 0.00062155
Epoch [32/300], Train Loss: 0.000606
Validation Loss: 0.00061020
Epoch [33/300], Train Loss: 0.000597
Validation Loss: 0.00060994
Epoch [34/300], Train Loss: 0.000593
Validation Loss: 0.00059091
Epoch [35/300], Train Loss: 0.000586
Validation Loss: 0.00059198
Epoch [36/300], Train Loss: 0.000578
Validation Loss: 0.00056706
Epoch [37/300], Train Loss: 0.000578
Validation Loss: 0.00056530
Epoch [38/300], Train Loss: 0.000570
Validation Loss: 0.00056791
Epoch [39/300], Train Loss: 0.000560
Validation Loss: 0.00055746
Epoch [40/300], Train Loss: 0.000557
Validation Loss: 0.00056374
Epoch [41/300], Train Loss: 0.000550
Validation Loss: 0.00053704
Epoch [42/300], Train Loss: 0.000546
Validation Loss: 0.00053611
Epoch [43/300], Train Loss: 0.000536
Validation Loss: 0.00053476
Epoch [44/300], Train Loss: 0.000536
Validation Loss: 0.00052262
Epoch [45/300], Train Loss: 0.000519
Validation Loss: 0.00051260
Epoch [46/300], Train Loss: 0.000519
Validation Loss: 0.00050163
Epoch [47/300], Train Loss: 0.000513
Validation Loss: 0.00051423
Epoch [48/300], Train Loss: 0.000507
Validation Loss: 0.00048477
Epoch [49/300], Train Loss: 0.000501
Validation Loss: 0.00048203
Epoch [50/300], Train Loss: 0.000491
Validation Loss: 0.00047157
Epoch [51/300], Train Loss: 0.000479
Validation Loss: 0.00046178
Epoch [52/300], Train Loss: 0.000466
Validation Loss: 0.00045216
Epoch [53/300], Train Loss: 0.000470
Validation Loss: 0.00046202
Epoch [54/300], Train Loss: 0.000459
Validation Loss: 0.00049263
Epoch [55/300], Train Loss: 0.000461
Validation Loss: 0.00044488
Epoch [56/300], Train Loss: 0.000446
Validation Loss: 0.00044430
Epoch [57/300], Train Loss: 0.000437
Validation Loss: 0.00044494
Epoch [58/300], Train Loss: 0.000438
Validation Loss: 0.00042663
Epoch [59/300], Train Loss: 0.000424
Validation Loss: 0.00043267
Epoch [60/300], Train Loss: 0.000420
Validation Loss: 0.00042605
Epoch [61/300], Train Loss: 0.000418
Validation Loss: 0.00044222
Epoch [62/300], Train Loss: 0.000439
Validation Loss: 0.00041589
Epoch [63/300], Train Loss: 0.000404
Validation Loss: 0.00040856
Epoch [64/300], Train Loss: 0.000406
Validation Loss: 0.00039606
Epoch [65/300], Train Loss: 0.000396
Validation Loss: 0.00040247
Epoch [66/300], Train Loss: 0.000401
Validation Loss: 0.00038791
Epoch [67/300], Train Loss: 0.000386
Validation Loss: 0.00039316
Epoch [68/300], Train Loss: 0.000378
Validation Loss: 0.00037867
Epoch [69/300], Train Loss: 0.000370
Validation Loss: 0.00037204
Epoch [70/300], Train Loss: 0.000376
Validation Loss: 0.00037680
Epoch [71/300], Train Loss: 0.000364
Validation Loss: 0.00038205
Epoch [72/300], Train Loss: 0.000367
Validation Loss: 0.00039089
Epoch [73/300], Train Loss: 0.000366
Validation Loss: 0.00036365
Epoch [74/300], Train Loss: 0.000357
Validation Loss: 0.00036898
Epoch [75/300], Train Loss: 0.000352
Validation Loss: 0.00037194
Epoch [76/300], Train Loss: 0.000348
Validation Loss: 0.00037249
Epoch [77/300], Train Loss: 0.000351
Validation Loss: 0.00035028
Epoch [78/300], Train Loss: 0.000341
Validation Loss: 0.00035203
Epoch [79/300], Train Loss: 0.000337
Validation Loss: 0.00034527
Epoch [80/300], Train Loss: 0.000334
Validation Loss: 0.00035599
Epoch [81/300], Train Loss: 0.000330
Validation Loss: 0.00034212
Epoch [82/300], Train Loss: 0.000324
Validation Loss: 0.00035627
Epoch [83/300], Train Loss: 0.000326
Validation Loss: 0.00033450
Epoch [84/300], Train Loss: 0.000320
Validation Loss: 0.00035694
Epoch [85/300], Train Loss: 0.000319
Validation Loss: 0.00033667
Epoch [86/300], Train Loss: 0.000327
Validation Loss: 0.00033854
Epoch [87/300], Train Loss: 0.000311
Validation Loss: 0.00033501
Epoch [88/300], Train Loss: 0.000312
Validation Loss: 0.00033070
Epoch [89/300], Train Loss: 0.000306
Validation Loss: 0.00034285
Epoch [90/300], Train Loss: 0.000302
Validation Loss: 0.00033400
Epoch [91/300], Train Loss: 0.000301
Validation Loss: 0.00031915
Epoch [92/300], Train Loss: 0.000293
Validation Loss: 0.00031869
Epoch [93/300], Train Loss: 0.000293
Validation Loss: 0.00032630
Epoch [94/300], Train Loss: 0.000300
Validation Loss: 0.00032962
Epoch [95/300], Train Loss: 0.000291
Validation Loss: 0.00033884
Epoch [96/300], Train Loss: 0.000287
Validation Loss: 0.00030934
Epoch [97/300], Train Loss: 0.000281
Validation Loss: 0.00031073
Epoch [98/300], Train Loss: 0.000283
Validation Loss: 0.00030335
Epoch [99/300], Train Loss: 0.000273
Validation Loss: 0.00030390
Epoch [100/300], Train Loss: 0.000291
Validation Loss: 0.00032070
Epoch [101/300], Train Loss: 0.000281
Validation Loss: 0.00030423
Epoch [102/300], Train Loss: 0.000272
Validation Loss: 0.00029452
Epoch [103/300], Train Loss: 0.000271
Validation Loss: 0.00029762
Epoch [104/300], Train Loss: 0.000277
Validation Loss: 0.00029451
Epoch [105/300], Train Loss: 0.000266
Validation Loss: 0.00028630
Epoch [106/300], Train Loss: 0.000263
Validation Loss: 0.00030080
Epoch [107/300], Train Loss: 0.000277
Validation Loss: 0.00028837
Epoch [108/300], Train Loss: 0.000262
Validation Loss: 0.00028385
Epoch [109/300], Train Loss: 0.000254
Validation Loss: 0.00027334
Epoch [110/300], Train Loss: 0.000250
Validation Loss: 0.00027886
Epoch [111/300], Train Loss: 0.000244
Validation Loss: 0.00027399
Epoch [112/300], Train Loss: 0.000240
Validation Loss: 0.00026968
Epoch [113/300], Train Loss: 0.000241
Validation Loss: 0.00027365
Epoch [114/300], Train Loss: 0.000239
Validation Loss: 0.00026839
Epoch [115/300], Train Loss: 0.000238
Validation Loss: 0.00027560
Epoch [116/300], Train Loss: 0.000298
Validation Loss: 0.00029859
Epoch [117/300], Train Loss: 0.000253
Validation Loss: 0.00027584
Epoch [118/300], Train Loss: 0.000245
Validation Loss: 0.00026632
Epoch [119/300], Train Loss: 0.000234
Validation Loss: 0.00026326
Epoch [120/300], Train Loss: 0.000233
Validation Loss: 0.00025769
Epoch [121/300], Train Loss: 0.000227
Validation Loss: 0.00025383
Epoch [122/300], Train Loss: 0.000228
Validation Loss: 0.00025957
Epoch [123/300], Train Loss: 0.000228
Validation Loss: 0.00025415
Epoch [124/300], Train Loss: 0.000222
Validation Loss: 0.00025261
Epoch [125/300], Train Loss: 0.000224
Validation Loss: 0.00025069
Epoch [126/300], Train Loss: 0.000224
Validation Loss: 0.00025273
Epoch [127/300], Train Loss: 0.000219
Validation Loss: 0.00024482
Epoch [128/300], Train Loss: 0.000214
Validation Loss: 0.00024547
Epoch [129/300], Train Loss: 0.000218
Validation Loss: 0.00024174
Epoch [130/300], Train Loss: 0.000210
Validation Loss: 0.00024088
Epoch [131/300], Train Loss: 0.000210
Validation Loss: 0.00024189
Epoch [132/300], Train Loss: 0.000214
Validation Loss: 0.00024277
Epoch [133/300], Train Loss: 0.000223
Validation Loss: 0.00024606
Epoch [134/300], Train Loss: 0.000219
Validation Loss: 0.00023927
Epoch [135/300], Train Loss: 0.000208
Validation Loss: 0.00023122
Epoch [136/300], Train Loss: 0.000202
Validation Loss: 0.00023175
Epoch [137/300], Train Loss: 0.000202
Validation Loss: 0.00022784
Epoch [138/300], Train Loss: 0.000200
Validation Loss: 0.00022407
Epoch [139/300], Train Loss: 0.000197
Validation Loss: 0.00022604
Epoch [140/300], Train Loss: 0.000200
Validation Loss: 0.00022070
Epoch [141/300], Train Loss: 0.000200
Validation Loss: 0.00022235
Epoch [142/300], Train Loss: 0.000197
Validation Loss: 0.00023053
Epoch [143/300], Train Loss: 0.000198
Validation Loss: 0.00022094
Epoch [144/300], Train Loss: 0.000192
Validation Loss: 0.00022289
Epoch [145/300], Train Loss: 0.000201
Validation Loss: 0.00022610
Epoch [146/300], Train Loss: 0.000194
Validation Loss: 0.00022386
Epoch [147/300], Train Loss: 0.000192
Validation Loss: 0.00023898
Epoch [148/300], Train Loss: 0.000195
Validation Loss: 0.00021538
Epoch [149/300], Train Loss: 0.000188
Validation Loss: 0.00021009
Epoch [150/300], Train Loss: 0.000184
Validation Loss: 0.00020773
Epoch [151/300], Train Loss: 0.000185
Validation Loss: 0.00021173
Epoch [152/300], Train Loss: 0.000185
Validation Loss: 0.00020465
Epoch [153/300], Train Loss: 0.000181
Validation Loss: 0.00020425
Epoch [154/300], Train Loss: 0.000180
Validation Loss: 0.00020251
Epoch [155/300], Train Loss: 0.000178
Validation Loss: 0.00020333
Epoch [156/300], Train Loss: 0.000180
Validation Loss: 0.00020142
Epoch [157/300], Train Loss: 0.000177
Validation Loss: 0.00020134
Epoch [158/300], Train Loss: 0.000176
Validation Loss: 0.00019703
Epoch [159/300], Train Loss: 0.000177
Validation Loss: 0.00019807
Epoch [160/300], Train Loss: 0.000175
Validation Loss: 0.00019662
Epoch [161/300], Train Loss: 0.000174
Validation Loss: 0.00019394
Epoch [162/300], Train Loss: 0.000173
Validation Loss: 0.00020049
Epoch [163/300], Train Loss: 0.000170
Validation Loss: 0.00019093
Epoch [164/300], Train Loss: 0.000171
Validation Loss: 0.00019131
Epoch [165/300], Train Loss: 0.000171
Validation Loss: 0.00019769
Epoch [166/300], Train Loss: 0.000172
Validation Loss: 0.00018953
Epoch [167/300], Train Loss: 0.000171
Validation Loss: 0.00018831
Epoch [168/300], Train Loss: 0.000168
Validation Loss: 0.00018815
Epoch [169/300], Train Loss: 0.000167
Validation Loss: 0.00018691
Epoch [170/300], Train Loss: 0.000167
Validation Loss: 0.00019192
Epoch [171/300], Train Loss: 0.000168
Validation Loss: 0.00018533
Epoch [172/300], Train Loss: 0.000168
Validation Loss: 0.00018644
Epoch [173/300], Train Loss: 0.000166
Validation Loss: 0.00018031
Epoch [174/300], Train Loss: 0.000162
Validation Loss: 0.00018108
Epoch [175/300], Train Loss: 0.000168
Validation Loss: 0.00018789
Epoch [176/300], Train Loss: 0.000163
Validation Loss: 0.00018100
Epoch [177/300], Train Loss: 0.000162
Validation Loss: 0.00018522
Epoch [178/300], Train Loss: 0.000164
Validation Loss: 0.00017625
Epoch [179/300], Train Loss: 0.000160
Validation Loss: 0.00018001
Epoch [180/300], Train Loss: 0.000160
Validation Loss: 0.00017301
Epoch [181/300], Train Loss: 0.000157
Validation Loss: 0.00017398
Epoch [182/300], Train Loss: 0.000158
Validation Loss: 0.00017579
Epoch [183/300], Train Loss: 0.000154
Validation Loss: 0.00016847
Epoch [184/300], Train Loss: 0.000155
Validation Loss: 0.00017212
Epoch [185/300], Train Loss: 0.000159
Validation Loss: 0.00017425
Epoch [186/300], Train Loss: 0.000158
Validation Loss: 0.00016962
Epoch [187/300], Train Loss: 0.000157
Validation Loss: 0.00018253
Epoch [188/300], Train Loss: 0.000158
Validation Loss: 0.00017488
Epoch [189/300], Train Loss: 0.000155
Validation Loss: 0.00017001
Epoch [190/300], Train Loss: 0.000153
Validation Loss: 0.00016679
Epoch [191/300], Train Loss: 0.000151
Validation Loss: 0.00016770
Epoch [192/300], Train Loss: 0.000151
Validation Loss: 0.00016947
Epoch [193/300], Train Loss: 0.000153
Validation Loss: 0.00016495
Epoch [194/300], Train Loss: 0.000151
Validation Loss: 0.00016505
Epoch [195/300], Train Loss: 0.000148
Validation Loss: 0.00016432
Epoch [196/300], Train Loss: 0.000147
Validation Loss: 0.00016745
Epoch [197/300], Train Loss: 0.000150
Validation Loss: 0.00016374
Epoch [198/300], Train Loss: 0.000146
Validation Loss: 0.00016154
Epoch [199/300], Train Loss: 0.000145
Validation Loss: 0.00015847
Epoch [200/300], Train Loss: 0.000144
Validation Loss: 0.00015880
Epoch [201/300], Train Loss: 0.000148
Validation Loss: 0.00016776
Epoch [202/300], Train Loss: 0.000165
Validation Loss: 0.00016889
Epoch [203/300], Train Loss: 0.000148
Validation Loss: 0.00015905
Epoch [204/300], Train Loss: 0.000143
Validation Loss: 0.00015840
Epoch [205/300], Train Loss: 0.000145
Validation Loss: 0.00015854
Epoch [206/300], Train Loss: 0.000142
Validation Loss: 0.00015578
Epoch [207/300], Train Loss: 0.000140
Validation Loss: 0.00015366
Epoch [208/300], Train Loss: 0.000141
Validation Loss: 0.00015445
Epoch [209/300], Train Loss: 0.000141
Validation Loss: 0.00015271
Epoch [210/300], Train Loss: 0.000140
Validation Loss: 0.00015190
Epoch [211/300], Train Loss: 0.000140
Validation Loss: 0.00015334
Epoch [212/300], Train Loss: 0.000137
Validation Loss: 0.00015190
Epoch [213/300], Train Loss: 0.000142
Validation Loss: 0.00015664
Epoch [214/300], Train Loss: 0.000138
Validation Loss: 0.00014996
Epoch [215/300], Train Loss: 0.000136
Validation Loss: 0.00015041
Epoch [216/300], Train Loss: 0.000135
Validation Loss: 0.00014787
Epoch [217/300], Train Loss: 0.000137
Validation Loss: 0.00015147
Epoch [218/300], Train Loss: 0.000138
Validation Loss: 0.00015787
Epoch [219/300], Train Loss: 0.000142
Validation Loss: 0.00015426
Epoch [220/300], Train Loss: 0.000136
Validation Loss: 0.00014615
Epoch [221/300], Train Loss: 0.000134
Validation Loss: 0.00014592
Epoch [222/300], Train Loss: 0.000134
Validation Loss: 0.00014726
Epoch [223/300], Train Loss: 0.000132
Validation Loss: 0.00014217
Epoch [224/300], Train Loss: 0.000132
Validation Loss: 0.00014430
Epoch [225/300], Train Loss: 0.000131
Validation Loss: 0.00014824
Epoch [226/300], Train Loss: 0.000132
Validation Loss: 0.00014184
Epoch [227/300], Train Loss: 0.000131
Validation Loss: 0.00014522
Epoch [228/300], Train Loss: 0.000132
Validation Loss: 0.00014286
Epoch [229/300], Train Loss: 0.000130
Validation Loss: 0.00014156
Epoch [230/300], Train Loss: 0.000130
Validation Loss: 0.00014308
Epoch [231/300], Train Loss: 0.000128
Validation Loss: 0.00014176
Epoch [232/300], Train Loss: 0.000128
Validation Loss: 0.00014164
Epoch [233/300], Train Loss: 0.000132
Validation Loss: 0.00014214
Epoch [234/300], Train Loss: 0.000129
Validation Loss: 0.00013742
Epoch [235/300], Train Loss: 0.000127
Validation Loss: 0.00013920
Epoch [236/300], Train Loss: 0.000127
Validation Loss: 0.00013641
Epoch [237/300], Train Loss: 0.000127
Validation Loss: 0.00014117
Epoch [238/300], Train Loss: 0.000139
Validation Loss: 0.00016372
Epoch [239/300], Train Loss: 0.000144
Validation Loss: 0.00014630
Epoch [240/300], Train Loss: 0.000133
Validation Loss: 0.00014526
Epoch [241/300], Train Loss: 0.000131
Validation Loss: 0.00014630
Epoch [242/300], Train Loss: 0.000131
Validation Loss: 0.00013832
Epoch [243/300], Train Loss: 0.000125
Validation Loss: 0.00013598
Epoch [244/300], Train Loss: 0.000124
Validation Loss: 0.00013603
Epoch [245/300], Train Loss: 0.000125
Validation Loss: 0.00013415
Epoch [246/300], Train Loss: 0.000124
Validation Loss: 0.00013387
Epoch [247/300], Train Loss: 0.000124
Validation Loss: 0.00013467
Epoch [248/300], Train Loss: 0.000126
Validation Loss: 0.00013595
Epoch [249/300], Train Loss: 0.000124
Validation Loss: 0.00013428
Epoch [250/300], Train Loss: 0.000126
Validation Loss: 0.00014037
Epoch [251/300], Train Loss: 0.000125
Validation Loss: 0.00013530
Epoch [252/300], Train Loss: 0.000123
Validation Loss: 0.00013123
Epoch [253/300], Train Loss: 0.000121
Validation Loss: 0.00013376
Epoch [254/300], Train Loss: 0.000121
Validation Loss: 0.00013299
Epoch [255/300], Train Loss: 0.000125
Validation Loss: 0.00013722
Epoch [256/300], Train Loss: 0.000123
Validation Loss: 0.00013337
Epoch [257/300], Train Loss: 0.000121
Validation Loss: 0.00013198
Epoch [258/300], Train Loss: 0.000120
Validation Loss: 0.00013195
Epoch [259/300], Train Loss: 0.000120
Validation Loss: 0.00012998
Epoch [260/300], Train Loss: 0.000120
Validation Loss: 0.00012952
Epoch [261/300], Train Loss: 0.000119
Validation Loss: 0.00013344
Epoch [262/300], Train Loss: 0.000120
Validation Loss: 0.00013122
Epoch [263/300], Train Loss: 0.000120
Validation Loss: 0.00013419
Epoch [264/300], Train Loss: 0.000121
Validation Loss: 0.00013619
Epoch [265/300], Train Loss: 0.000121
Validation Loss: 0.00012999
Epoch [266/300], Train Loss: 0.000120
Validation Loss: 0.00012866
Epoch [267/300], Train Loss: 0.000118
Validation Loss: 0.00012913
Epoch [268/300], Train Loss: 0.000118
Validation Loss: 0.00013068
Epoch [269/300], Train Loss: 0.000118
Validation Loss: 0.00012934
Epoch [270/300], Train Loss: 0.000118
Validation Loss: 0.00012869
Epoch [271/300], Train Loss: 0.000121
Validation Loss: 0.00012956
Epoch [272/300], Train Loss: 0.000117
Validation Loss: 0.00013308
Epoch [273/300], Train Loss: 0.000117
Validation Loss: 0.00013277
Epoch [274/300], Train Loss: 0.000117
Validation Loss: 0.00012574
Epoch [275/300], Train Loss: 0.000116
Validation Loss: 0.00012700
Epoch [276/300], Train Loss: 0.000116
Validation Loss: 0.00012408
Epoch [277/300], Train Loss: 0.000117
Validation Loss: 0.00012592
Epoch [278/300], Train Loss: 0.000134
Validation Loss: 0.00021787
Epoch [279/300], Train Loss: 0.000157
Validation Loss: 0.00014317
Epoch [280/300], Train Loss: 0.000126
Validation Loss: 0.00012797
Epoch [281/300], Train Loss: 0.000118
Validation Loss: 0.00012533
Epoch [282/300], Train Loss: 0.000116
Validation Loss: 0.00012590
Epoch [283/300], Train Loss: 0.000115
Validation Loss: 0.00012475
Epoch [284/300], Train Loss: 0.000116
Validation Loss: 0.00012352
Epoch [285/300], Train Loss: 0.000116
Validation Loss: 0.00012410
Epoch [286/300], Train Loss: 0.000114
Validation Loss: 0.00012354
Epoch [287/300], Train Loss: 0.000114
Validation Loss: 0.00012449
Epoch [288/300], Train Loss: 0.000114
Validation Loss: 0.00012952
Epoch [289/300], Train Loss: 0.000117
Validation Loss: 0.00012415
Epoch [290/300], Train Loss: 0.000113
Validation Loss: 0.00012387
Epoch [291/300], Train Loss: 0.000112
Validation Loss: 0.00012199
Epoch [292/300], Train Loss: 0.000112
Validation Loss: 0.00012290
Epoch [293/300], Train Loss: 0.000114
Validation Loss: 0.00012288
Epoch [294/300], Train Loss: 0.000118
Validation Loss: 0.00013639
Epoch [295/300], Train Loss: 0.000118
Validation Loss: 0.00013131
Epoch [296/300], Train Loss: 0.000115
Validation Loss: 0.00012880
Epoch [297/300], Train Loss: 0.000112
Validation Loss: 0.00012303
Epoch [298/300], Train Loss: 0.000111
Validation Loss: 0.00012234
Epoch [299/300], Train Loss: 0.000111
Validation Loss: 0.00012196
Epoch [300/300], Train Loss: 0.000112
Validation Loss: 0.00012332

Evaluating model for: Coffee Machine
Run 65/72 completed in 5043.66 seconds with: {'MAE': np.float32(3.1309931), 'MSE': np.float32(574.40173), 'RMSE': np.float32(23.96668), 'SAE': np.float32(0.040347952), 'NDE': np.float32(0.36917797)}

Run 66/72: hidden=512, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Coffee Machine
Dataset length: 5916 windows

Epoch [1/300], Train Loss: 0.000988
Validation Loss: 0.00100559
Epoch [2/300], Train Loss: 0.000984
Validation Loss: 0.00100363
Epoch [3/300], Train Loss: 0.000983
Validation Loss: 0.00100333
Epoch [4/300], Train Loss: 0.000981
Validation Loss: 0.00100056
Epoch [5/300], Train Loss: 0.000978
Validation Loss: 0.00099557
Epoch [6/300], Train Loss: 0.000971
Validation Loss: 0.00098868
Epoch [7/300], Train Loss: 0.000964
Validation Loss: 0.00098019
Epoch [8/300], Train Loss: 0.000953
Validation Loss: 0.00096825
Epoch [9/300], Train Loss: 0.000936
Validation Loss: 0.00094925
Epoch [10/300], Train Loss: 0.000915
Validation Loss: 0.00093095
Epoch [11/300], Train Loss: 0.000889
Validation Loss: 0.00089913
Epoch [12/300], Train Loss: 0.000858
Validation Loss: 0.00086393
Epoch [13/300], Train Loss: 0.000823
Validation Loss: 0.00083357
Epoch [14/300], Train Loss: 0.000789
Validation Loss: 0.00080200
Epoch [15/300], Train Loss: 0.000761
Validation Loss: 0.00078001
Epoch [16/300], Train Loss: 0.000742
Validation Loss: 0.00075447
Epoch [17/300], Train Loss: 0.000727
Validation Loss: 0.00075469
Epoch [18/300], Train Loss: 0.000706
Validation Loss: 0.00071352
Epoch [19/300], Train Loss: 0.000684
Validation Loss: 0.00070495
Epoch [20/300], Train Loss: 0.000670
Validation Loss: 0.00071337
Epoch [21/300], Train Loss: 0.000660
Validation Loss: 0.00067223
Epoch [22/300], Train Loss: 0.000637
Validation Loss: 0.00065093
Epoch [23/300], Train Loss: 0.000621
Validation Loss: 0.00064019
Epoch [24/300], Train Loss: 0.000620
Validation Loss: 0.00063957
Epoch [25/300], Train Loss: 0.000609
Validation Loss: 0.00062477
Epoch [26/300], Train Loss: 0.000595
Validation Loss: 0.00062010
Epoch [27/300], Train Loss: 0.000581
Validation Loss: 0.00059541
Epoch [28/300], Train Loss: 0.000569
Validation Loss: 0.00058528
Epoch [29/300], Train Loss: 0.000559
Validation Loss: 0.00057708
Epoch [30/300], Train Loss: 0.000551
Validation Loss: 0.00056345
Epoch [31/300], Train Loss: 0.000547
Validation Loss: 0.00056886
Epoch [32/300], Train Loss: 0.000529
Validation Loss: 0.00053812
Epoch [33/300], Train Loss: 0.000515
Validation Loss: 0.00053361
Epoch [34/300], Train Loss: 0.000506
Validation Loss: 0.00052598
Epoch [35/300], Train Loss: 0.000495
Validation Loss: 0.00049114
Epoch [36/300], Train Loss: 0.000495
Validation Loss: 0.00051150
Epoch [37/300], Train Loss: 0.000486
Validation Loss: 0.00049233
Epoch [38/300], Train Loss: 0.000481
Validation Loss: 0.00048594
Epoch [39/300], Train Loss: 0.000465
Validation Loss: 0.00047195
Epoch [40/300], Train Loss: 0.000462
Validation Loss: 0.00056901
Epoch [41/300], Train Loss: 0.000460
Validation Loss: 0.00044728
Epoch [42/300], Train Loss: 0.000435
Validation Loss: 0.00046113
Epoch [43/300], Train Loss: 0.000418
Validation Loss: 0.00048359
Epoch [44/300], Train Loss: 0.000431
Validation Loss: 0.00044603
Epoch [45/300], Train Loss: 0.000413
Validation Loss: 0.00040212
Epoch [46/300], Train Loss: 0.000379
Validation Loss: 0.00038016
Epoch [47/300], Train Loss: 0.000372
Validation Loss: 0.00037291
Epoch [48/300], Train Loss: 0.000356
Validation Loss: 0.00038173
Epoch [49/300], Train Loss: 0.000352
Validation Loss: 0.00034924
Epoch [50/300], Train Loss: 0.000343
Validation Loss: 0.00033808
Epoch [51/300], Train Loss: 0.000333
Validation Loss: 0.00032215
Epoch [52/300], Train Loss: 0.000317
Validation Loss: 0.00031829
Epoch [53/300], Train Loss: 0.000309
Validation Loss: 0.00031773
Epoch [54/300], Train Loss: 0.000310
Validation Loss: 0.00030640
Epoch [55/300], Train Loss: 0.000301
Validation Loss: 0.00031648
Epoch [56/300], Train Loss: 0.000298
Validation Loss: 0.00029794
Epoch [57/300], Train Loss: 0.000292
Validation Loss: 0.00029515
Epoch [58/300], Train Loss: 0.000279
Validation Loss: 0.00028598
Epoch [59/300], Train Loss: 0.000277
Validation Loss: 0.00028301
Epoch [60/300], Train Loss: 0.000274
Validation Loss: 0.00028588
Epoch [61/300], Train Loss: 0.000264
Validation Loss: 0.00029657
Epoch [62/300], Train Loss: 0.000274
Validation Loss: 0.00027828
Epoch [63/300], Train Loss: 0.000259
Validation Loss: 0.00030263
Epoch [64/300], Train Loss: 0.000261
Validation Loss: 0.00026218
Epoch [65/300], Train Loss: 0.000252
Validation Loss: 0.00026239
Epoch [66/300], Train Loss: 0.000254
Validation Loss: 0.00028225
Epoch [67/300], Train Loss: 0.000248
Validation Loss: 0.00025634
Epoch [68/300], Train Loss: 0.000240
Validation Loss: 0.00025607
Epoch [69/300], Train Loss: 0.000238
Validation Loss: 0.00024254
Epoch [70/300], Train Loss: 0.000235
Validation Loss: 0.00024861
Epoch [71/300], Train Loss: 0.000237
Validation Loss: 0.00024380
Epoch [72/300], Train Loss: 0.000231
Validation Loss: 0.00024530
Epoch [73/300], Train Loss: 0.000225
Validation Loss: 0.00025219
Epoch [74/300], Train Loss: 0.000228
Validation Loss: 0.00025457
Epoch [75/300], Train Loss: 0.000223
Validation Loss: 0.00023064
Epoch [76/300], Train Loss: 0.000212
Validation Loss: 0.00026277
Epoch [77/300], Train Loss: 0.000219
Validation Loss: 0.00024023
Epoch [78/300], Train Loss: 0.000214
Validation Loss: 0.00022395
Epoch [79/300], Train Loss: 0.000208
Validation Loss: 0.00021529
Epoch [80/300], Train Loss: 0.000207
Validation Loss: 0.00022088
Epoch [81/300], Train Loss: 0.000210
Validation Loss: 0.00023557
Epoch [82/300], Train Loss: 0.000200
Validation Loss: 0.00021363
Epoch [83/300], Train Loss: 0.000200
Validation Loss: 0.00021428
Epoch [84/300], Train Loss: 0.000197
Validation Loss: 0.00021463
Epoch [85/300], Train Loss: 0.000198
Validation Loss: 0.00021140
Epoch [86/300], Train Loss: 0.000191
Validation Loss: 0.00020760
Epoch [87/300], Train Loss: 0.000188
Validation Loss: 0.00020726
Epoch [88/300], Train Loss: 0.000199
Validation Loss: 0.00021452
Epoch [89/300], Train Loss: 0.000193
Validation Loss: 0.00020937
Epoch [90/300], Train Loss: 0.000195
Validation Loss: 0.00021827
Epoch [91/300], Train Loss: 0.000192
Validation Loss: 0.00020446
Epoch [92/300], Train Loss: 0.000187
Validation Loss: 0.00019834
Epoch [93/300], Train Loss: 0.000181
Validation Loss: 0.00019019
Epoch [94/300], Train Loss: 0.000184
Validation Loss: 0.00019136
Epoch [95/300], Train Loss: 0.000181
Validation Loss: 0.00019112
Epoch [96/300], Train Loss: 0.000176
Validation Loss: 0.00018219
Epoch [97/300], Train Loss: 0.000176
Validation Loss: 0.00018458
Epoch [98/300], Train Loss: 0.000174
Validation Loss: 0.00019321
Epoch [99/300], Train Loss: 0.000170
Validation Loss: 0.00020174
Epoch [100/300], Train Loss: 0.000174
Validation Loss: 0.00019743
Epoch [101/300], Train Loss: 0.000180
Validation Loss: 0.00018792
Epoch [102/300], Train Loss: 0.000176
Validation Loss: 0.00018440
Epoch [103/300], Train Loss: 0.000188
Validation Loss: 0.00031637
Epoch [104/300], Train Loss: 0.000235
Validation Loss: 0.00022754
Epoch [105/300], Train Loss: 0.000195
Validation Loss: 0.00021077
Epoch [106/300], Train Loss: 0.000186
Validation Loss: 0.00019252
Early stopping triggered

Evaluating model for: Coffee Machine
Run 66/72 completed in 2373.94 seconds with: {'MAE': np.float32(3.7011087), 'MSE': np.float32(941.7856), 'RMSE': np.float32(30.688526), 'SAE': np.float32(0.09208606), 'NDE': np.float32(0.47271985)}

Run 67/72: hidden=512, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Coffee Machine
Dataset length: 5916 windows

Epoch [1/300], Train Loss: 0.001117
Validation Loss: 0.00101246
Epoch [2/300], Train Loss: 0.000988
Validation Loss: 0.00100802
Epoch [3/300], Train Loss: 0.000987
Validation Loss: 0.00100801
Epoch [4/300], Train Loss: 0.000987
Validation Loss: 0.00100765
Epoch [5/300], Train Loss: 0.000986
Validation Loss: 0.00100748
Epoch [6/300], Train Loss: 0.000986
Validation Loss: 0.00100736
Epoch [7/300], Train Loss: 0.000986
Validation Loss: 0.00100719
Epoch [8/300], Train Loss: 0.000985
Validation Loss: 0.00100709
Epoch [9/300], Train Loss: 0.000984
Validation Loss: 0.00100697
Epoch [10/300], Train Loss: 0.000984
Validation Loss: 0.00100647
Epoch [11/300], Train Loss: 0.000984
Validation Loss: 0.00100620
Epoch [12/300], Train Loss: 0.000983
Validation Loss: 0.00100515
Epoch [13/300], Train Loss: 0.000983
Validation Loss: 0.00100619
Epoch [14/300], Train Loss: 0.000982
Validation Loss: 0.00100322
Epoch [15/300], Train Loss: 0.000980
Validation Loss: 0.00100113
Epoch [16/300], Train Loss: 0.000978
Validation Loss: 0.00099614
Epoch [17/300], Train Loss: 0.000972
Validation Loss: 0.00099166
Epoch [18/300], Train Loss: 0.000967
Validation Loss: 0.00098551
Epoch [19/300], Train Loss: 0.000957
Validation Loss: 0.00096984
Epoch [20/300], Train Loss: 0.000939
Validation Loss: 0.00094831
Epoch [21/300], Train Loss: 0.000906
Validation Loss: 0.00090791
Epoch [22/300], Train Loss: 0.000862
Validation Loss: 0.00086035
Epoch [23/300], Train Loss: 0.000808
Validation Loss: 0.00080837
Epoch [24/300], Train Loss: 0.000772
Validation Loss: 0.00078093
Epoch [25/300], Train Loss: 0.000737
Validation Loss: 0.00076888
Epoch [26/300], Train Loss: 0.000714
Validation Loss: 0.00072744
Epoch [27/300], Train Loss: 0.000685
Validation Loss: 0.00069904
Epoch [28/300], Train Loss: 0.000665
Validation Loss: 0.00067569
Epoch [29/300], Train Loss: 0.000652
Validation Loss: 0.00068285
Epoch [30/300], Train Loss: 0.000676
Validation Loss: 0.00073309
Epoch [31/300], Train Loss: 0.000682
Validation Loss: 0.00070385
Epoch [32/300], Train Loss: 0.000645
Validation Loss: 0.00067153
Epoch [33/300], Train Loss: 0.000698
Validation Loss: 0.00081303
Epoch [34/300], Train Loss: 0.000694
Validation Loss: 0.00067065
Epoch [35/300], Train Loss: 0.000646
Validation Loss: 0.00064408
Epoch [36/300], Train Loss: 0.000615
Validation Loss: 0.00063487
Epoch [37/300], Train Loss: 0.000707
Validation Loss: 0.00086545
Epoch [38/300], Train Loss: 0.000723
Validation Loss: 0.00070775
Epoch [39/300], Train Loss: 0.000601
Validation Loss: 0.00061111
Epoch [40/300], Train Loss: 0.000569
Validation Loss: 0.00058839
Epoch [41/300], Train Loss: 0.000553
Validation Loss: 0.00058867
Epoch [42/300], Train Loss: 0.000557
Validation Loss: 0.00056381
Epoch [43/300], Train Loss: 0.000547
Validation Loss: 0.00054702
Epoch [44/300], Train Loss: 0.000537
Validation Loss: 0.00055092
Epoch [45/300], Train Loss: 0.000534
Validation Loss: 0.00054533
Epoch [46/300], Train Loss: 0.000526
Validation Loss: 0.00053281
Epoch [47/300], Train Loss: 0.000522
Validation Loss: 0.00054967
Epoch [48/300], Train Loss: 0.000527
Validation Loss: 0.00053487
Epoch [49/300], Train Loss: 0.000522
Validation Loss: 0.00052030
Epoch [50/300], Train Loss: 0.000505
Validation Loss: 0.00051095
Epoch [51/300], Train Loss: 0.000503
Validation Loss: 0.00050440
Epoch [52/300], Train Loss: 0.000489
Validation Loss: 0.00051951
Epoch [53/300], Train Loss: 0.000499
Validation Loss: 0.00051622
Epoch [54/300], Train Loss: 0.000486
Validation Loss: 0.00048497
Epoch [55/300], Train Loss: 0.000475
Validation Loss: 0.00048805
Epoch [56/300], Train Loss: 0.000496
Validation Loss: 0.00064107
Epoch [57/300], Train Loss: 0.000585
Validation Loss: 0.00055832
Epoch [58/300], Train Loss: 0.000522
Validation Loss: 0.00052578
Epoch [59/300], Train Loss: 0.000497
Validation Loss: 0.00051150
Epoch [60/300], Train Loss: 0.000487
Validation Loss: 0.00048711
Epoch [61/300], Train Loss: 0.000479
Validation Loss: 0.00047563
Epoch [62/300], Train Loss: 0.000472
Validation Loss: 0.00048754
Epoch [63/300], Train Loss: 0.000469
Validation Loss: 0.00046417
Epoch [64/300], Train Loss: 0.000456
Validation Loss: 0.00045548
Epoch [65/300], Train Loss: 0.000456
Validation Loss: 0.00046850
Epoch [66/300], Train Loss: 0.000452
Validation Loss: 0.00044118
Epoch [67/300], Train Loss: 0.000441
Validation Loss: 0.00043959
Epoch [68/300], Train Loss: 0.000434
Validation Loss: 0.00043042
Epoch [69/300], Train Loss: 0.000431
Validation Loss: 0.00042545
Epoch [70/300], Train Loss: 0.000432
Validation Loss: 0.00041709
Epoch [71/300], Train Loss: 0.000412
Validation Loss: 0.00041180
Epoch [72/300], Train Loss: 0.000410
Validation Loss: 0.00040970
Epoch [73/300], Train Loss: 0.000402
Validation Loss: 0.00041113
Epoch [74/300], Train Loss: 0.000404
Validation Loss: 0.00041306
Epoch [75/300], Train Loss: 0.000394
Validation Loss: 0.00039383
Epoch [76/300], Train Loss: 0.000383
Validation Loss: 0.00039988
Epoch [77/300], Train Loss: 0.000382
Validation Loss: 0.00038744
Epoch [78/300], Train Loss: 0.000375
Validation Loss: 0.00038107
Epoch [79/300], Train Loss: 0.000367
Validation Loss: 0.00037238
Epoch [80/300], Train Loss: 0.000360
Validation Loss: 0.00039063
Epoch [81/300], Train Loss: 0.000371
Validation Loss: 0.00037349
Epoch [82/300], Train Loss: 0.000356
Validation Loss: 0.00037153
Epoch [83/300], Train Loss: 0.000348
Validation Loss: 0.00035974
Epoch [84/300], Train Loss: 0.000343
Validation Loss: 0.00034796
Epoch [85/300], Train Loss: 0.000343
Validation Loss: 0.00035479
Epoch [86/300], Train Loss: 0.000333
Validation Loss: 0.00035372
Epoch [87/300], Train Loss: 0.000329
Validation Loss: 0.00035465
Epoch [88/300], Train Loss: 0.000334
Validation Loss: 0.00034126
Epoch [89/300], Train Loss: 0.000323
Validation Loss: 0.00033014
Epoch [90/300], Train Loss: 0.000314
Validation Loss: 0.00033305
Epoch [91/300], Train Loss: 0.000310
Validation Loss: 0.00032250
Epoch [92/300], Train Loss: 0.000304
Validation Loss: 0.00031306
Epoch [93/300], Train Loss: 0.000300
Validation Loss: 0.00031115
Epoch [94/300], Train Loss: 0.000292
Validation Loss: 0.00030529
Epoch [95/300], Train Loss: 0.000294
Validation Loss: 0.00031753
Epoch [96/300], Train Loss: 0.000299
Validation Loss: 0.00030517
Epoch [97/300], Train Loss: 0.000288
Validation Loss: 0.00029597
Epoch [98/300], Train Loss: 0.000281
Validation Loss: 0.00029059
Epoch [99/300], Train Loss: 0.000276
Validation Loss: 0.00028717
Epoch [100/300], Train Loss: 0.000273
Validation Loss: 0.00029009
Epoch [101/300], Train Loss: 0.000266
Validation Loss: 0.00029037
Epoch [102/300], Train Loss: 0.000267
Validation Loss: 0.00027968
Epoch [103/300], Train Loss: 0.000267
Validation Loss: 0.00032770
Epoch [104/300], Train Loss: 0.000269
Validation Loss: 0.00027642
Epoch [105/300], Train Loss: 0.000255
Validation Loss: 0.00026646
Epoch [106/300], Train Loss: 0.000252
Validation Loss: 0.00027870
Epoch [107/300], Train Loss: 0.000250
Validation Loss: 0.00027716
Epoch [108/300], Train Loss: 0.000254
Validation Loss: 0.00026894
Epoch [109/300], Train Loss: 0.000244
Validation Loss: 0.00025304
Epoch [110/300], Train Loss: 0.000241
Validation Loss: 0.00027465
Epoch [111/300], Train Loss: 0.000244
Validation Loss: 0.00026939
Epoch [112/300], Train Loss: 0.000246
Validation Loss: 0.00026818
Epoch [113/300], Train Loss: 0.000239
Validation Loss: 0.00024586
Epoch [114/300], Train Loss: 0.000238
Validation Loss: 0.00026817
Epoch [115/300], Train Loss: 0.000233
Validation Loss: 0.00025700
Epoch [116/300], Train Loss: 0.000236
Validation Loss: 0.00024726
Epoch [117/300], Train Loss: 0.000223
Validation Loss: 0.00024235
Epoch [118/300], Train Loss: 0.000225
Validation Loss: 0.00024157
Epoch [119/300], Train Loss: 0.000218
Validation Loss: 0.00023490
Epoch [120/300], Train Loss: 0.000216
Validation Loss: 0.00023785
Epoch [121/300], Train Loss: 0.000225
Validation Loss: 0.00024017
Epoch [122/300], Train Loss: 0.000236
Validation Loss: 0.00030772
Epoch [123/300], Train Loss: 0.000264
Validation Loss: 0.00027854
Epoch [124/300], Train Loss: 0.000269
Validation Loss: 0.00042420
Epoch [125/300], Train Loss: 0.000254
Validation Loss: 0.00025611
Epoch [126/300], Train Loss: 0.000228
Validation Loss: 0.00025334
Epoch [127/300], Train Loss: 0.000225
Validation Loss: 0.00023684
Epoch [128/300], Train Loss: 0.000223
Validation Loss: 0.00023521
Epoch [129/300], Train Loss: 0.000214
Validation Loss: 0.00023893
Early stopping triggered

Evaluating model for: Coffee Machine
Run 67/72 completed in 3527.00 seconds with: {'MAE': np.float32(4.20291), 'MSE': np.float32(1069.3022), 'RMSE': np.float32(32.700188), 'SAE': np.float32(0.12269542), 'NDE': np.float32(0.5037079)}

Run 68/72: hidden=512, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Coffee Machine
Dataset length: 5916 windows

Epoch [1/300], Train Loss: 0.001021
Validation Loss: 0.00100820
Epoch [2/300], Train Loss: 0.000987
Validation Loss: 0.00100646
Epoch [3/300], Train Loss: 0.000986
Validation Loss: 0.00100695
Epoch [4/300], Train Loss: 0.000986
Validation Loss: 0.00100638
Epoch [5/300], Train Loss: 0.000985
Validation Loss: 0.00100634
Epoch [6/300], Train Loss: 0.000985
Validation Loss: 0.00100636
Epoch [7/300], Train Loss: 0.000985
Validation Loss: 0.00100634
Epoch [8/300], Train Loss: 0.000985
Validation Loss: 0.00100636
Epoch [9/300], Train Loss: 0.000984
Validation Loss: 0.00100692
Epoch [10/300], Train Loss: 0.000984
Validation Loss: 0.00100615
Epoch [11/300], Train Loss: 0.000984
Validation Loss: 0.00100622
Epoch [12/300], Train Loss: 0.000983
Validation Loss: 0.00100617
Epoch [13/300], Train Loss: 0.000983
Validation Loss: 0.00100798
Epoch [14/300], Train Loss: 0.000983
Validation Loss: 0.00100579
Epoch [15/300], Train Loss: 0.000983
Validation Loss: 0.00100566
Epoch [16/300], Train Loss: 0.000983
Validation Loss: 0.00100560
Epoch [17/300], Train Loss: 0.000982
Validation Loss: 0.00100481
Epoch [18/300], Train Loss: 0.000981
Validation Loss: 0.00100332
Epoch [19/300], Train Loss: 0.000980
Validation Loss: 0.00100062
Epoch [20/300], Train Loss: 0.000977
Validation Loss: 0.00099880
Epoch [21/300], Train Loss: 0.000975
Validation Loss: 0.00099701
Epoch [22/300], Train Loss: 0.000972
Validation Loss: 0.00099137
Epoch [23/300], Train Loss: 0.000964
Validation Loss: 0.00097967
Epoch [24/300], Train Loss: 0.000949
Validation Loss: 0.00096182
Epoch [25/300], Train Loss: 0.000927
Validation Loss: 0.00092830
Epoch [26/300], Train Loss: 0.000881
Validation Loss: 0.00087749
Epoch [27/300], Train Loss: 0.000823
Validation Loss: 0.00082145
Epoch [28/300], Train Loss: 0.000770
Validation Loss: 0.00078129
Epoch [29/300], Train Loss: 0.000739
Validation Loss: 0.00075215
Epoch [30/300], Train Loss: 0.000711
Validation Loss: 0.00073751
Epoch [31/300], Train Loss: 0.000690
Validation Loss: 0.00071144
Epoch [32/300], Train Loss: 0.000695
Validation Loss: 0.00079032
Epoch [33/300], Train Loss: 0.000687
Validation Loss: 0.00068249
Epoch [34/300], Train Loss: 0.000650
Validation Loss: 0.00064435
Epoch [35/300], Train Loss: 0.000638
Validation Loss: 0.00065977
Epoch [36/300], Train Loss: 0.000621
Validation Loss: 0.00063136
Epoch [37/300], Train Loss: 0.000599
Validation Loss: 0.00062002
Epoch [38/300], Train Loss: 0.000591
Validation Loss: 0.00060642
Epoch [39/300], Train Loss: 0.000575
Validation Loss: 0.00061429
Epoch [40/300], Train Loss: 0.000625
Validation Loss: 0.00063541
Epoch [41/300], Train Loss: 0.000580
Validation Loss: 0.00060257
Epoch [42/300], Train Loss: 0.000569
Validation Loss: 0.00055782
Epoch [43/300], Train Loss: 0.000540
Validation Loss: 0.00052398
Epoch [44/300], Train Loss: 0.000522
Validation Loss: 0.00051170
Epoch [45/300], Train Loss: 0.000510
Validation Loss: 0.00048706
Epoch [46/300], Train Loss: 0.000489
Validation Loss: 0.00044871
Epoch [47/300], Train Loss: 0.000457
Validation Loss: 0.00043351
Epoch [48/300], Train Loss: 0.000446
Validation Loss: 0.00043299
Epoch [49/300], Train Loss: 0.000427
Validation Loss: 0.00041050
Epoch [50/300], Train Loss: 0.000412
Validation Loss: 0.00041093
Epoch [51/300], Train Loss: 0.000407
Validation Loss: 0.00038815
Epoch [52/300], Train Loss: 0.000391
Validation Loss: 0.00039110
Epoch [53/300], Train Loss: 0.000384
Validation Loss: 0.00037489
Epoch [54/300], Train Loss: 0.000375
Validation Loss: 0.00035783
Epoch [55/300], Train Loss: 0.000362
Validation Loss: 0.00035100
Epoch [56/300], Train Loss: 0.000356
Validation Loss: 0.00036072
Epoch [57/300], Train Loss: 0.000353
Validation Loss: 0.00034676
Epoch [58/300], Train Loss: 0.000351
Validation Loss: 0.00033947
Epoch [59/300], Train Loss: 0.000342
Validation Loss: 0.00034049
Epoch [60/300], Train Loss: 0.000339
Validation Loss: 0.00034716
Epoch [61/300], Train Loss: 0.000334
Validation Loss: 0.00033596
Epoch [62/300], Train Loss: 0.000326
Validation Loss: 0.00035795
Epoch [63/300], Train Loss: 0.000320
Validation Loss: 0.00032981
Epoch [64/300], Train Loss: 0.000309
Validation Loss: 0.00030934
Epoch [65/300], Train Loss: 0.000315
Validation Loss: 0.00032639
Epoch [66/300], Train Loss: 0.000311
Validation Loss: 0.00031125
Epoch [67/300], Train Loss: 0.000297
Validation Loss: 0.00030581
Epoch [68/300], Train Loss: 0.000297
Validation Loss: 0.00029817
Epoch [69/300], Train Loss: 0.000289
Validation Loss: 0.00029215
Epoch [70/300], Train Loss: 0.000289
Validation Loss: 0.00029193
Epoch [71/300], Train Loss: 0.000280
Validation Loss: 0.00029334
Epoch [72/300], Train Loss: 0.000281
Validation Loss: 0.00028526
Epoch [73/300], Train Loss: 0.000273
Validation Loss: 0.00029225
Epoch [74/300], Train Loss: 0.000280
Validation Loss: 0.00028003
Epoch [75/300], Train Loss: 0.000269
Validation Loss: 0.00027628
Epoch [76/300], Train Loss: 0.000266
Validation Loss: 0.00028381
Epoch [77/300], Train Loss: 0.000262
Validation Loss: 0.00027422
Epoch [78/300], Train Loss: 0.000257
Validation Loss: 0.00026565
Epoch [79/300], Train Loss: 0.000256
Validation Loss: 0.00026959
Epoch [80/300], Train Loss: 0.000249
Validation Loss: 0.00027210
Epoch [81/300], Train Loss: 0.000247
Validation Loss: 0.00026259
Epoch [82/300], Train Loss: 0.000249
Validation Loss: 0.00026482
Epoch [83/300], Train Loss: 0.000249
Validation Loss: 0.00025800
Epoch [84/300], Train Loss: 0.000244
Validation Loss: 0.00026009
Epoch [85/300], Train Loss: 0.000238
Validation Loss: 0.00026040
Epoch [86/300], Train Loss: 0.000236
Validation Loss: 0.00025012
Epoch [87/300], Train Loss: 0.000237
Validation Loss: 0.00025474
Epoch [88/300], Train Loss: 0.000241
Validation Loss: 0.00025299
Epoch [89/300], Train Loss: 0.000238
Validation Loss: 0.00024436
Epoch [90/300], Train Loss: 0.000229
Validation Loss: 0.00024151
Epoch [91/300], Train Loss: 0.000228
Validation Loss: 0.00025063
Epoch [92/300], Train Loss: 0.000231
Validation Loss: 0.00027157
Epoch [93/300], Train Loss: 0.000258
Validation Loss: 0.00030646
Epoch [94/300], Train Loss: 0.000276
Validation Loss: 0.00028054
Epoch [95/300], Train Loss: 0.000253
Validation Loss: 0.00029686
Epoch [96/300], Train Loss: 0.000248
Validation Loss: 0.00026576
Epoch [97/300], Train Loss: 0.000245
Validation Loss: 0.00026137
Epoch [98/300], Train Loss: 0.000235
Validation Loss: 0.00025530
Epoch [99/300], Train Loss: 0.000234
Validation Loss: 0.00024798
Epoch [100/300], Train Loss: 0.000230
Validation Loss: 0.00025334
Early stopping triggered

Evaluating model for: Coffee Machine
Run 68/72 completed in 3577.27 seconds with: {'MAE': np.float32(4.1848493), 'MSE': np.float32(1138.0314), 'RMSE': np.float32(33.734722), 'SAE': np.float32(0.14968283), 'NDE': np.float32(0.5196435)}

Run 69/72: hidden=512, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Coffee Machine
Dataset length: 2980 windows

Epoch [1/300], Train Loss: 0.001130
Validation Loss: 0.00092692
Epoch [2/300], Train Loss: 0.000979
Validation Loss: 0.00091925
Epoch [3/300], Train Loss: 0.000978
Validation Loss: 0.00091680
Epoch [4/300], Train Loss: 0.000978
Validation Loss: 0.00091592
Epoch [5/300], Train Loss: 0.000980
Validation Loss: 0.00091568
Epoch [6/300], Train Loss: 0.000977
Validation Loss: 0.00091440
Epoch [7/300], Train Loss: 0.000976
Validation Loss: 0.00091387
Epoch [8/300], Train Loss: 0.000979
Validation Loss: 0.00091267
Epoch [9/300], Train Loss: 0.000982
Validation Loss: 0.00091157
Epoch [10/300], Train Loss: 0.000982
Validation Loss: 0.00091065
Epoch [11/300], Train Loss: 0.000965
Validation Loss: 0.00090926
Epoch [12/300], Train Loss: 0.000973
Validation Loss: 0.00090840
Epoch [13/300], Train Loss: 0.000974
Validation Loss: 0.00090653
Epoch [14/300], Train Loss: 0.000974
Validation Loss: 0.00090483
Epoch [15/300], Train Loss: 0.000959
Validation Loss: 0.00090329
Epoch [16/300], Train Loss: 0.000965
Validation Loss: 0.00090013
Epoch [17/300], Train Loss: 0.000969
Validation Loss: 0.00089700
Epoch [18/300], Train Loss: 0.000962
Validation Loss: 0.00089521
Epoch [19/300], Train Loss: 0.000962
Validation Loss: 0.00089032
Epoch [20/300], Train Loss: 0.000948
Validation Loss: 0.00088719
Epoch [21/300], Train Loss: 0.000956
Validation Loss: 0.00088384
Epoch [22/300], Train Loss: 0.000940
Validation Loss: 0.00087884
Epoch [23/300], Train Loss: 0.000949
Validation Loss: 0.00087420
Epoch [24/300], Train Loss: 0.000936
Validation Loss: 0.00086668
Epoch [25/300], Train Loss: 0.000932
Validation Loss: 0.00085906
Epoch [26/300], Train Loss: 0.000931
Validation Loss: 0.00085099
Epoch [27/300], Train Loss: 0.000923
Validation Loss: 0.00084349
Epoch [28/300], Train Loss: 0.000907
Validation Loss: 0.00083366
Epoch [29/300], Train Loss: 0.000906
Validation Loss: 0.00082723
Epoch [30/300], Train Loss: 0.000896
Validation Loss: 0.00081253
Epoch [31/300], Train Loss: 0.000884
Validation Loss: 0.00080147
Epoch [32/300], Train Loss: 0.000876
Validation Loss: 0.00079047
Epoch [33/300], Train Loss: 0.000864
Validation Loss: 0.00077367
Epoch [34/300], Train Loss: 0.000851
Validation Loss: 0.00076163
Epoch [35/300], Train Loss: 0.000838
Validation Loss: 0.00074957
Epoch [36/300], Train Loss: 0.000835
Validation Loss: 0.00074100
Epoch [37/300], Train Loss: 0.000827
Validation Loss: 0.00074594
Epoch [38/300], Train Loss: 0.000813
Validation Loss: 0.00071576
Epoch [39/300], Train Loss: 0.000797
Validation Loss: 0.00070638
Epoch [40/300], Train Loss: 0.000781
Validation Loss: 0.00069364
Epoch [41/300], Train Loss: 0.000778
Validation Loss: 0.00068469
Epoch [42/300], Train Loss: 0.000771
Validation Loss: 0.00067853
Epoch [43/300], Train Loss: 0.000757
Validation Loss: 0.00066354
Epoch [44/300], Train Loss: 0.000739
Validation Loss: 0.00065503
Epoch [45/300], Train Loss: 0.000729
Validation Loss: 0.00064635
Epoch [46/300], Train Loss: 0.000727
Validation Loss: 0.00063973
Epoch [47/300], Train Loss: 0.000723
Validation Loss: 0.00063399
Epoch [48/300], Train Loss: 0.000714
Validation Loss: 0.00062401
Epoch [49/300], Train Loss: 0.000701
Validation Loss: 0.00062206
Epoch [50/300], Train Loss: 0.000706
Validation Loss: 0.00063113
Epoch [51/300], Train Loss: 0.000697
Validation Loss: 0.00061027
Epoch [52/300], Train Loss: 0.000682
Validation Loss: 0.00059779
Epoch [53/300], Train Loss: 0.000679
Validation Loss: 0.00059069
Epoch [54/300], Train Loss: 0.000670
Validation Loss: 0.00059373
Epoch [55/300], Train Loss: 0.000674
Validation Loss: 0.00059488
Epoch [56/300], Train Loss: 0.000673
Validation Loss: 0.00057696
Epoch [57/300], Train Loss: 0.000669
Validation Loss: 0.00057724
Epoch [58/300], Train Loss: 0.000650
Validation Loss: 0.00056661
Epoch [59/300], Train Loss: 0.000641
Validation Loss: 0.00056746
Epoch [60/300], Train Loss: 0.000643
Validation Loss: 0.00055628
Epoch [61/300], Train Loss: 0.000636
Validation Loss: 0.00055950
Epoch [62/300], Train Loss: 0.000622
Validation Loss: 0.00054634
Epoch [63/300], Train Loss: 0.000616
Validation Loss: 0.00053294
Epoch [64/300], Train Loss: 0.000614
Validation Loss: 0.00054944
Epoch [65/300], Train Loss: 0.000618
Validation Loss: 0.00053590
Epoch [66/300], Train Loss: 0.000619
Validation Loss: 0.00052325
Epoch [67/300], Train Loss: 0.000605
Validation Loss: 0.00051834
Epoch [68/300], Train Loss: 0.000602
Validation Loss: 0.00051514
Epoch [69/300], Train Loss: 0.000595
Validation Loss: 0.00050929
Epoch [70/300], Train Loss: 0.000595
Validation Loss: 0.00052167
Epoch [71/300], Train Loss: 0.000588
Validation Loss: 0.00050301
Epoch [72/300], Train Loss: 0.000586
Validation Loss: 0.00051613
Epoch [73/300], Train Loss: 0.000584
Validation Loss: 0.00050577
Epoch [74/300], Train Loss: 0.000573
Validation Loss: 0.00050651
Epoch [75/300], Train Loss: 0.000579
Validation Loss: 0.00049593
Epoch [76/300], Train Loss: 0.000573
Validation Loss: 0.00048990
Epoch [77/300], Train Loss: 0.000569
Validation Loss: 0.00048997
Epoch [78/300], Train Loss: 0.000566
Validation Loss: 0.00050701
Epoch [79/300], Train Loss: 0.000579
Validation Loss: 0.00049412
Epoch [80/300], Train Loss: 0.000562
Validation Loss: 0.00049373
Epoch [81/300], Train Loss: 0.000560
Validation Loss: 0.00048253
Epoch [82/300], Train Loss: 0.000549
Validation Loss: 0.00047742
Epoch [83/300], Train Loss: 0.000554
Validation Loss: 0.00048965
Epoch [84/300], Train Loss: 0.000554
Validation Loss: 0.00047429
Epoch [85/300], Train Loss: 0.000553
Validation Loss: 0.00047761
Epoch [86/300], Train Loss: 0.000541
Validation Loss: 0.00046893
Epoch [87/300], Train Loss: 0.000551
Validation Loss: 0.00049030
Epoch [88/300], Train Loss: 0.000555
Validation Loss: 0.00049179
Epoch [89/300], Train Loss: 0.000548
Validation Loss: 0.00047335
Epoch [90/300], Train Loss: 0.000544
Validation Loss: 0.00047058
Epoch [91/300], Train Loss: 0.000536
Validation Loss: 0.00046226
Epoch [92/300], Train Loss: 0.000531
Validation Loss: 0.00046115
Epoch [93/300], Train Loss: 0.000529
Validation Loss: 0.00046609
Epoch [94/300], Train Loss: 0.000534
Validation Loss: 0.00046201
Epoch [95/300], Train Loss: 0.000525
Validation Loss: 0.00047716
Epoch [96/300], Train Loss: 0.000529
Validation Loss: 0.00045893
Epoch [97/300], Train Loss: 0.000517
Validation Loss: 0.00046884
Epoch [98/300], Train Loss: 0.000528
Validation Loss: 0.00045118
Epoch [99/300], Train Loss: 0.000530
Validation Loss: 0.00046111
Epoch [100/300], Train Loss: 0.000515
Validation Loss: 0.00046219
Epoch [101/300], Train Loss: 0.000527
Validation Loss: 0.00046137
Epoch [102/300], Train Loss: 0.000527
Validation Loss: 0.00046428
Epoch [103/300], Train Loss: 0.000522
Validation Loss: 0.00045238
Epoch [104/300], Train Loss: 0.000513
Validation Loss: 0.00044467
Epoch [105/300], Train Loss: 0.000503
Validation Loss: 0.00044137
Epoch [106/300], Train Loss: 0.000503
Validation Loss: 0.00044818
Epoch [107/300], Train Loss: 0.000503
Validation Loss: 0.00043901
Epoch [108/300], Train Loss: 0.000490
Validation Loss: 0.00044440
Epoch [109/300], Train Loss: 0.000498
Validation Loss: 0.00043416
Epoch [110/300], Train Loss: 0.000494
Validation Loss: 0.00044132
Epoch [111/300], Train Loss: 0.000497
Validation Loss: 0.00045416
Epoch [112/300], Train Loss: 0.000501
Validation Loss: 0.00043080
Epoch [113/300], Train Loss: 0.000491
Validation Loss: 0.00043007
Epoch [114/300], Train Loss: 0.000484
Validation Loss: 0.00044058
Epoch [115/300], Train Loss: 0.000519
Validation Loss: 0.00046567
Epoch [116/300], Train Loss: 0.000496
Validation Loss: 0.00042973
Epoch [117/300], Train Loss: 0.000495
Validation Loss: 0.00043482
Epoch [118/300], Train Loss: 0.000491
Validation Loss: 0.00042826
Epoch [119/300], Train Loss: 0.000489
Validation Loss: 0.00042601
Epoch [120/300], Train Loss: 0.000485
Validation Loss: 0.00043032
Epoch [121/300], Train Loss: 0.000480
Validation Loss: 0.00042857
Epoch [122/300], Train Loss: 0.000477
Validation Loss: 0.00041733
Epoch [123/300], Train Loss: 0.000468
Validation Loss: 0.00042683
Epoch [124/300], Train Loss: 0.000475
Validation Loss: 0.00042441
Epoch [125/300], Train Loss: 0.000465
Validation Loss: 0.00041462
Epoch [126/300], Train Loss: 0.000461
Validation Loss: 0.00040982
Epoch [127/300], Train Loss: 0.000459
Validation Loss: 0.00042073
Epoch [128/300], Train Loss: 0.000470
Validation Loss: 0.00043470
Epoch [129/300], Train Loss: 0.000458
Validation Loss: 0.00040966
Epoch [130/300], Train Loss: 0.000449
Validation Loss: 0.00041118
Epoch [131/300], Train Loss: 0.000452
Validation Loss: 0.00041073
Epoch [132/300], Train Loss: 0.000459
Validation Loss: 0.00039977
Epoch [133/300], Train Loss: 0.000441
Validation Loss: 0.00039983
Epoch [134/300], Train Loss: 0.000436
Validation Loss: 0.00039994
Epoch [135/300], Train Loss: 0.000427
Validation Loss: 0.00040123
Epoch [136/300], Train Loss: 0.000445
Validation Loss: 0.00039754
Epoch [137/300], Train Loss: 0.000426
Validation Loss: 0.00037855
Epoch [138/300], Train Loss: 0.000407
Validation Loss: 0.00037533
Epoch [139/300], Train Loss: 0.000416
Validation Loss: 0.00038335
Epoch [140/300], Train Loss: 0.000402
Validation Loss: 0.00035776
Epoch [141/300], Train Loss: 0.000398
Validation Loss: 0.00036648
Epoch [142/300], Train Loss: 0.000393
Validation Loss: 0.00037192
Epoch [143/300], Train Loss: 0.000397
Validation Loss: 0.00035465
Epoch [144/300], Train Loss: 0.000381
Validation Loss: 0.00036941
Epoch [145/300], Train Loss: 0.000388
Validation Loss: 0.00034772
Epoch [146/300], Train Loss: 0.000378
Validation Loss: 0.00033865
Epoch [147/300], Train Loss: 0.000386
Validation Loss: 0.00034759
Epoch [148/300], Train Loss: 0.000377
Validation Loss: 0.00034329
Epoch [149/300], Train Loss: 0.000370
Validation Loss: 0.00034889
Epoch [150/300], Train Loss: 0.000367
Validation Loss: 0.00033864
Epoch [151/300], Train Loss: 0.000363
Validation Loss: 0.00033087
Epoch [152/300], Train Loss: 0.000354
Validation Loss: 0.00032816
Epoch [153/300], Train Loss: 0.000357
Validation Loss: 0.00033258
Epoch [154/300], Train Loss: 0.000361
Validation Loss: 0.00031904
Epoch [155/300], Train Loss: 0.000346
Validation Loss: 0.00031210
Epoch [156/300], Train Loss: 0.000350
Validation Loss: 0.00032072
Epoch [157/300], Train Loss: 0.000343
Validation Loss: 0.00031621
Epoch [158/300], Train Loss: 0.000346
Validation Loss: 0.00031631
Epoch [159/300], Train Loss: 0.000342
Validation Loss: 0.00031435
Epoch [160/300], Train Loss: 0.000349
Validation Loss: 0.00032497
Epoch [161/300], Train Loss: 0.000337
Validation Loss: 0.00031239
Epoch [162/300], Train Loss: 0.000336
Validation Loss: 0.00030345
Epoch [163/300], Train Loss: 0.000329
Validation Loss: 0.00030625
Epoch [164/300], Train Loss: 0.000335
Validation Loss: 0.00030816
Epoch [165/300], Train Loss: 0.000340
Validation Loss: 0.00029565
Epoch [166/300], Train Loss: 0.000331
Validation Loss: 0.00031541
Epoch [167/300], Train Loss: 0.000323
Validation Loss: 0.00029965
Epoch [168/300], Train Loss: 0.000327
Validation Loss: 0.00032908
Epoch [169/300], Train Loss: 0.000332
Validation Loss: 0.00030174
Epoch [170/300], Train Loss: 0.000325
Validation Loss: 0.00030374
Epoch [171/300], Train Loss: 0.000326
Validation Loss: 0.00030113
Epoch [172/300], Train Loss: 0.000320
Validation Loss: 0.00029375
Epoch [173/300], Train Loss: 0.000324
Validation Loss: 0.00031106
Epoch [174/300], Train Loss: 0.000323
Validation Loss: 0.00029545
Epoch [175/300], Train Loss: 0.000319
Validation Loss: 0.00029080
Epoch [176/300], Train Loss: 0.000315
Validation Loss: 0.00029071
Epoch [177/300], Train Loss: 0.000310
Validation Loss: 0.00028423
Epoch [178/300], Train Loss: 0.000308
Validation Loss: 0.00029117
Epoch [179/300], Train Loss: 0.000309
Validation Loss: 0.00028197
Epoch [180/300], Train Loss: 0.000309
Validation Loss: 0.00029109
Epoch [181/300], Train Loss: 0.000305
Validation Loss: 0.00028070
Epoch [182/300], Train Loss: 0.000307
Validation Loss: 0.00027975
Epoch [183/300], Train Loss: 0.000303
Validation Loss: 0.00028115
Epoch [184/300], Train Loss: 0.000306
Validation Loss: 0.00027699
Epoch [185/300], Train Loss: 0.000304
Validation Loss: 0.00027925
Epoch [186/300], Train Loss: 0.000310
Validation Loss: 0.00028239
Epoch [187/300], Train Loss: 0.000298
Validation Loss: 0.00027622
Epoch [188/300], Train Loss: 0.000300
Validation Loss: 0.00027168
Epoch [189/300], Train Loss: 0.000301
Validation Loss: 0.00026970
Epoch [190/300], Train Loss: 0.000308
Validation Loss: 0.00027489
Epoch [191/300], Train Loss: 0.000304
Validation Loss: 0.00029183
Epoch [192/300], Train Loss: 0.000301
Validation Loss: 0.00027383
Epoch [193/300], Train Loss: 0.000306
Validation Loss: 0.00027023
Epoch [194/300], Train Loss: 0.000305
Validation Loss: 0.00027165
Epoch [195/300], Train Loss: 0.000299
Validation Loss: 0.00028800
Epoch [196/300], Train Loss: 0.000299
Validation Loss: 0.00026058
Epoch [197/300], Train Loss: 0.000293
Validation Loss: 0.00026344
Epoch [198/300], Train Loss: 0.000286
Validation Loss: 0.00027115
Epoch [199/300], Train Loss: 0.000291
Validation Loss: 0.00026011
Epoch [200/300], Train Loss: 0.000286
Validation Loss: 0.00025601
Epoch [201/300], Train Loss: 0.000287
Validation Loss: 0.00025702
Epoch [202/300], Train Loss: 0.000289
Validation Loss: 0.00025699
Epoch [203/300], Train Loss: 0.000290
Validation Loss: 0.00025422
Epoch [204/300], Train Loss: 0.000284
Validation Loss: 0.00026287
Epoch [205/300], Train Loss: 0.000283
Validation Loss: 0.00024863
Epoch [206/300], Train Loss: 0.000284
Validation Loss: 0.00025131
Epoch [207/300], Train Loss: 0.000283
Validation Loss: 0.00027430
Epoch [208/300], Train Loss: 0.000283
Validation Loss: 0.00026471
Epoch [209/300], Train Loss: 0.000278
Validation Loss: 0.00025381
Epoch [210/300], Train Loss: 0.000289
Validation Loss: 0.00027587
Epoch [211/300], Train Loss: 0.000291
Validation Loss: 0.00025568
Epoch [212/300], Train Loss: 0.000280
Validation Loss: 0.00024839
Epoch [213/300], Train Loss: 0.000283
Validation Loss: 0.00027065
Epoch [214/300], Train Loss: 0.000285
Validation Loss: 0.00027114
Epoch [215/300], Train Loss: 0.000276
Validation Loss: 0.00024979
Epoch [216/300], Train Loss: 0.000275
Validation Loss: 0.00025323
Epoch [217/300], Train Loss: 0.000272
Validation Loss: 0.00024504
Epoch [218/300], Train Loss: 0.000267
Validation Loss: 0.00024847
Epoch [219/300], Train Loss: 0.000266
Validation Loss: 0.00024040
Epoch [220/300], Train Loss: 0.000274
Validation Loss: 0.00024435
Epoch [221/300], Train Loss: 0.000274
Validation Loss: 0.00025007
Epoch [222/300], Train Loss: 0.000266
Validation Loss: 0.00025384
Epoch [223/300], Train Loss: 0.000270
Validation Loss: 0.00024337
Epoch [224/300], Train Loss: 0.000267
Validation Loss: 0.00024063
Epoch [225/300], Train Loss: 0.000277
Validation Loss: 0.00023339
Epoch [226/300], Train Loss: 0.000269
Validation Loss: 0.00024489
Epoch [227/300], Train Loss: 0.000267
Validation Loss: 0.00024391
Epoch [228/300], Train Loss: 0.000258
Validation Loss: 0.00023319
Epoch [229/300], Train Loss: 0.000260
Validation Loss: 0.00023267
Epoch [230/300], Train Loss: 0.000270
Validation Loss: 0.00024246
Epoch [231/300], Train Loss: 0.000270
Validation Loss: 0.00022910
Epoch [232/300], Train Loss: 0.000266
Validation Loss: 0.00022890
Epoch [233/300], Train Loss: 0.000263
Validation Loss: 0.00024073
Epoch [234/300], Train Loss: 0.000265
Validation Loss: 0.00022965
Epoch [235/300], Train Loss: 0.000264
Validation Loss: 0.00023847
Epoch [236/300], Train Loss: 0.000264
Validation Loss: 0.00024951
Epoch [237/300], Train Loss: 0.000269
Validation Loss: 0.00023571
Epoch [238/300], Train Loss: 0.000262
Validation Loss: 0.00023072
Epoch [239/300], Train Loss: 0.000258
Validation Loss: 0.00023396
Epoch [240/300], Train Loss: 0.000258
Validation Loss: 0.00022544
Epoch [241/300], Train Loss: 0.000260
Validation Loss: 0.00023920
Epoch [242/300], Train Loss: 0.000255
Validation Loss: 0.00022744
Epoch [243/300], Train Loss: 0.000256
Validation Loss: 0.00022381
Epoch [244/300], Train Loss: 0.000254
Validation Loss: 0.00023399
Epoch [245/300], Train Loss: 0.000258
Validation Loss: 0.00023167
Epoch [246/300], Train Loss: 0.000252
Validation Loss: 0.00022513
Epoch [247/300], Train Loss: 0.000256
Validation Loss: 0.00022179
Epoch [248/300], Train Loss: 0.000253
Validation Loss: 0.00022947
Epoch [249/300], Train Loss: 0.000255
Validation Loss: 0.00023308
Epoch [250/300], Train Loss: 0.000251
Validation Loss: 0.00022131
Epoch [251/300], Train Loss: 0.000263
Validation Loss: 0.00023735
Epoch [252/300], Train Loss: 0.000253
Validation Loss: 0.00022372
Epoch [253/300], Train Loss: 0.000259
Validation Loss: 0.00022340
Epoch [254/300], Train Loss: 0.000254
Validation Loss: 0.00022260
Epoch [255/300], Train Loss: 0.000252
Validation Loss: 0.00022424
Epoch [256/300], Train Loss: 0.000255
Validation Loss: 0.00022169
Epoch [257/300], Train Loss: 0.000251
Validation Loss: 0.00021401
Epoch [258/300], Train Loss: 0.000246
Validation Loss: 0.00021862
Epoch [259/300], Train Loss: 0.000246
Validation Loss: 0.00023527
Epoch [260/300], Train Loss: 0.000307
Validation Loss: 0.00026202
Epoch [261/300], Train Loss: 0.000284
Validation Loss: 0.00023562
Epoch [262/300], Train Loss: 0.000263
Validation Loss: 0.00023155
Epoch [263/300], Train Loss: 0.000253
Validation Loss: 0.00023703
Epoch [264/300], Train Loss: 0.000249
Validation Loss: 0.00022178
Epoch [265/300], Train Loss: 0.000247
Validation Loss: 0.00022358
Epoch [266/300], Train Loss: 0.000242
Validation Loss: 0.00021684
Epoch [267/300], Train Loss: 0.000244
Validation Loss: 0.00021864
Early stopping triggered

Evaluating model for: Coffee Machine
Run 69/72 completed in 2442.60 seconds with: {'MAE': np.float32(4.6127462), 'MSE': np.float32(1449.0665), 'RMSE': np.float32(38.066605), 'SAE': np.float32(0.12988493), 'NDE': np.float32(0.57876647)}

Run 70/72: hidden=512, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Coffee Machine
Dataset length: 2980 windows

Epoch [1/300], Train Loss: 0.001040
Validation Loss: 0.00092214
Epoch [2/300], Train Loss: 0.000972
Validation Loss: 0.00091875
Epoch [3/300], Train Loss: 0.000977
Validation Loss: 0.00091713
Epoch [4/300], Train Loss: 0.000978
Validation Loss: 0.00091657
Epoch [5/300], Train Loss: 0.000979
Validation Loss: 0.00091665
Epoch [6/300], Train Loss: 0.000977
Validation Loss: 0.00091608
Epoch [7/300], Train Loss: 0.000977
Validation Loss: 0.00091574
Epoch [8/300], Train Loss: 0.000980
Validation Loss: 0.00091575
Epoch [9/300], Train Loss: 0.000984
Validation Loss: 0.00091501
Epoch [10/300], Train Loss: 0.000984
Validation Loss: 0.00091493
Epoch [11/300], Train Loss: 0.000967
Validation Loss: 0.00091409
Epoch [12/300], Train Loss: 0.000975
Validation Loss: 0.00091464
Epoch [13/300], Train Loss: 0.000978
Validation Loss: 0.00091280
Epoch [14/300], Train Loss: 0.000978
Validation Loss: 0.00091204
Epoch [15/300], Train Loss: 0.000965
Validation Loss: 0.00091250
Epoch [16/300], Train Loss: 0.000972
Validation Loss: 0.00091016
Epoch [17/300], Train Loss: 0.000977
Validation Loss: 0.00090915
Epoch [18/300], Train Loss: 0.000972
Validation Loss: 0.00090829
Epoch [19/300], Train Loss: 0.000972
Validation Loss: 0.00090428
Epoch [20/300], Train Loss: 0.000958
Validation Loss: 0.00090123
Epoch [21/300], Train Loss: 0.000967
Validation Loss: 0.00089799
Epoch [22/300], Train Loss: 0.000950
Validation Loss: 0.00089338
Epoch [23/300], Train Loss: 0.000961
Validation Loss: 0.00088947
Epoch [24/300], Train Loss: 0.000948
Validation Loss: 0.00088280
Epoch [25/300], Train Loss: 0.000945
Validation Loss: 0.00087599
Epoch [26/300], Train Loss: 0.000943
Validation Loss: 0.00086954
Epoch [27/300], Train Loss: 0.000933
Validation Loss: 0.00085686
Epoch [28/300], Train Loss: 0.000916
Validation Loss: 0.00084893
Epoch [29/300], Train Loss: 0.000913
Validation Loss: 0.00083040
Epoch [30/300], Train Loss: 0.000898
Validation Loss: 0.00080998
Epoch [31/300], Train Loss: 0.000879
Validation Loss: 0.00079315
Epoch [32/300], Train Loss: 0.000866
Validation Loss: 0.00077478
Epoch [33/300], Train Loss: 0.000850
Validation Loss: 0.00075843
Epoch [34/300], Train Loss: 0.000830
Validation Loss: 0.00074090
Epoch [35/300], Train Loss: 0.000813
Validation Loss: 0.00073415
Epoch [36/300], Train Loss: 0.000808
Validation Loss: 0.00070898
Epoch [37/300], Train Loss: 0.000795
Validation Loss: 0.00070224
Epoch [38/300], Train Loss: 0.000776
Validation Loss: 0.00068619
Epoch [39/300], Train Loss: 0.000763
Validation Loss: 0.00067537
Epoch [40/300], Train Loss: 0.000747
Validation Loss: 0.00065677
Epoch [41/300], Train Loss: 0.000745
Validation Loss: 0.00065520
Epoch [42/300], Train Loss: 0.000736
Validation Loss: 0.00064316
Epoch [43/300], Train Loss: 0.000721
Validation Loss: 0.00063372
Epoch [44/300], Train Loss: 0.000701
Validation Loss: 0.00062133
Epoch [45/300], Train Loss: 0.000693
Validation Loss: 0.00061628
Epoch [46/300], Train Loss: 0.000690
Validation Loss: 0.00060980
Epoch [47/300], Train Loss: 0.000681
Validation Loss: 0.00059604
Epoch [48/300], Train Loss: 0.000671
Validation Loss: 0.00059601
Epoch [49/300], Train Loss: 0.000664
Validation Loss: 0.00059038
Epoch [50/300], Train Loss: 0.000676
Validation Loss: 0.00062577
Epoch [51/300], Train Loss: 0.000663
Validation Loss: 0.00058042
Epoch [52/300], Train Loss: 0.000643
Validation Loss: 0.00057184
Epoch [53/300], Train Loss: 0.000642
Validation Loss: 0.00057352
Epoch [54/300], Train Loss: 0.000630
Validation Loss: 0.00056361
Epoch [55/300], Train Loss: 0.000628
Validation Loss: 0.00056808
Epoch [56/300], Train Loss: 0.000636
Validation Loss: 0.00055371
Epoch [57/300], Train Loss: 0.000625
Validation Loss: 0.00054888
Epoch [58/300], Train Loss: 0.000609
Validation Loss: 0.00054360
Epoch [59/300], Train Loss: 0.000606
Validation Loss: 0.00054136
Epoch [60/300], Train Loss: 0.000606
Validation Loss: 0.00052980
Epoch [61/300], Train Loss: 0.000591
Validation Loss: 0.00052240
Epoch [62/300], Train Loss: 0.000582
Validation Loss: 0.00053131
Epoch [63/300], Train Loss: 0.000579
Validation Loss: 0.00051564
Epoch [64/300], Train Loss: 0.000577
Validation Loss: 0.00053377
Epoch [65/300], Train Loss: 0.000572
Validation Loss: 0.00052090
Epoch [66/300], Train Loss: 0.000582
Validation Loss: 0.00051999
Epoch [67/300], Train Loss: 0.000569
Validation Loss: 0.00051298
Epoch [68/300], Train Loss: 0.000564
Validation Loss: 0.00051254
Epoch [69/300], Train Loss: 0.000557
Validation Loss: 0.00050417
Epoch [70/300], Train Loss: 0.000558
Validation Loss: 0.00050581
Epoch [71/300], Train Loss: 0.000549
Validation Loss: 0.00049788
Epoch [72/300], Train Loss: 0.000544
Validation Loss: 0.00049594
Epoch [73/300], Train Loss: 0.000540
Validation Loss: 0.00048511
Epoch [74/300], Train Loss: 0.000534
Validation Loss: 0.00050507
Epoch [75/300], Train Loss: 0.000544
Validation Loss: 0.00049302
Epoch [76/300], Train Loss: 0.000536
Validation Loss: 0.00048853
Epoch [77/300], Train Loss: 0.000531
Validation Loss: 0.00049378
Epoch [78/300], Train Loss: 0.000529
Validation Loss: 0.00050863
Epoch [79/300], Train Loss: 0.000542
Validation Loss: 0.00048882
Epoch [80/300], Train Loss: 0.000519
Validation Loss: 0.00048677
Epoch [81/300], Train Loss: 0.000519
Validation Loss: 0.00048303
Epoch [82/300], Train Loss: 0.000515
Validation Loss: 0.00047698
Epoch [83/300], Train Loss: 0.000515
Validation Loss: 0.00048775
Epoch [84/300], Train Loss: 0.000515
Validation Loss: 0.00047935
Epoch [85/300], Train Loss: 0.000523
Validation Loss: 0.00047250
Epoch [86/300], Train Loss: 0.000504
Validation Loss: 0.00046823
Epoch [87/300], Train Loss: 0.000513
Validation Loss: 0.00047271
Epoch [88/300], Train Loss: 0.000511
Validation Loss: 0.00047153
Epoch [89/300], Train Loss: 0.000504
Validation Loss: 0.00046440
Epoch [90/300], Train Loss: 0.000501
Validation Loss: 0.00046241
Epoch [91/300], Train Loss: 0.000493
Validation Loss: 0.00046124
Epoch [92/300], Train Loss: 0.000491
Validation Loss: 0.00046748
Epoch [93/300], Train Loss: 0.000490
Validation Loss: 0.00045421
Epoch [94/300], Train Loss: 0.000490
Validation Loss: 0.00044855
Epoch [95/300], Train Loss: 0.000482
Validation Loss: 0.00045455
Epoch [96/300], Train Loss: 0.000480
Validation Loss: 0.00045046
Epoch [97/300], Train Loss: 0.000469
Validation Loss: 0.00044561
Epoch [98/300], Train Loss: 0.000470
Validation Loss: 0.00043345
Epoch [99/300], Train Loss: 0.000485
Validation Loss: 0.00044675
Epoch [100/300], Train Loss: 0.000464
Validation Loss: 0.00045446
Epoch [101/300], Train Loss: 0.000466
Validation Loss: 0.00043160
Epoch [102/300], Train Loss: 0.000460
Validation Loss: 0.00044231
Epoch [103/300], Train Loss: 0.000462
Validation Loss: 0.00042139
Epoch [104/300], Train Loss: 0.000445
Validation Loss: 0.00040414
Epoch [105/300], Train Loss: 0.000430
Validation Loss: 0.00042125
Epoch [106/300], Train Loss: 0.000430
Validation Loss: 0.00040708
Epoch [107/300], Train Loss: 0.000424
Validation Loss: 0.00040000
Epoch [108/300], Train Loss: 0.000412
Validation Loss: 0.00041138
Epoch [109/300], Train Loss: 0.000419
Validation Loss: 0.00039200
Epoch [110/300], Train Loss: 0.000412
Validation Loss: 0.00038868
Epoch [111/300], Train Loss: 0.000403
Validation Loss: 0.00038919
Epoch [112/300], Train Loss: 0.000412
Validation Loss: 0.00040179
Epoch [113/300], Train Loss: 0.000402
Validation Loss: 0.00039317
Epoch [114/300], Train Loss: 0.000396
Validation Loss: 0.00037585
Epoch [115/300], Train Loss: 0.000410
Validation Loss: 0.00038785
Epoch [116/300], Train Loss: 0.000387
Validation Loss: 0.00036152
Epoch [117/300], Train Loss: 0.000392
Validation Loss: 0.00038169
Epoch [118/300], Train Loss: 0.000396
Validation Loss: 0.00036835
Epoch [119/300], Train Loss: 0.000386
Validation Loss: 0.00038828
Epoch [120/300], Train Loss: 0.000379
Validation Loss: 0.00038805
Epoch [121/300], Train Loss: 0.000375
Validation Loss: 0.00035506
Epoch [122/300], Train Loss: 0.000372
Validation Loss: 0.00035502
Epoch [123/300], Train Loss: 0.000362
Validation Loss: 0.00034246
Epoch [124/300], Train Loss: 0.000366
Validation Loss: 0.00035350
Epoch [125/300], Train Loss: 0.000358
Validation Loss: 0.00034185
Epoch [126/300], Train Loss: 0.000356
Validation Loss: 0.00034145
Epoch [127/300], Train Loss: 0.000356
Validation Loss: 0.00035857
Epoch [128/300], Train Loss: 0.000358
Validation Loss: 0.00033676
Epoch [129/300], Train Loss: 0.000347
Validation Loss: 0.00033062
Epoch [130/300], Train Loss: 0.000341
Validation Loss: 0.00032604
Epoch [131/300], Train Loss: 0.000350
Validation Loss: 0.00034382
Epoch [132/300], Train Loss: 0.000358
Validation Loss: 0.00035234
Epoch [133/300], Train Loss: 0.000344
Validation Loss: 0.00032732
Epoch [134/300], Train Loss: 0.000337
Validation Loss: 0.00033531
Epoch [135/300], Train Loss: 0.000337
Validation Loss: 0.00033865
Epoch [136/300], Train Loss: 0.000341
Validation Loss: 0.00031457
Epoch [137/300], Train Loss: 0.000341
Validation Loss: 0.00031187
Epoch [138/300], Train Loss: 0.000327
Validation Loss: 0.00030447
Epoch [139/300], Train Loss: 0.000325
Validation Loss: 0.00031330
Epoch [140/300], Train Loss: 0.000319
Validation Loss: 0.00030125
Epoch [141/300], Train Loss: 0.000320
Validation Loss: 0.00030491
Epoch [142/300], Train Loss: 0.000317
Validation Loss: 0.00032963
Epoch [143/300], Train Loss: 0.000345
Validation Loss: 0.00032757
Epoch [144/300], Train Loss: 0.000330
Validation Loss: 0.00031532
Epoch [145/300], Train Loss: 0.000323
Validation Loss: 0.00030334
Epoch [146/300], Train Loss: 0.000318
Validation Loss: 0.00029789
Epoch [147/300], Train Loss: 0.000319
Validation Loss: 0.00030399
Epoch [148/300], Train Loss: 0.000317
Validation Loss: 0.00029703
Epoch [149/300], Train Loss: 0.000308
Validation Loss: 0.00029628
Epoch [150/300], Train Loss: 0.000315
Validation Loss: 0.00029995
Epoch [151/300], Train Loss: 0.000311
Validation Loss: 0.00028317
Epoch [152/300], Train Loss: 0.000299
Validation Loss: 0.00028037
Epoch [153/300], Train Loss: 0.000301
Validation Loss: 0.00029651
Epoch [154/300], Train Loss: 0.000296
Validation Loss: 0.00028434
Epoch [155/300], Train Loss: 0.000299
Validation Loss: 0.00027249
Epoch [156/300], Train Loss: 0.000294
Validation Loss: 0.00027674
Epoch [157/300], Train Loss: 0.000289
Validation Loss: 0.00028116
Epoch [158/300], Train Loss: 0.000296
Validation Loss: 0.00027326
Epoch [159/300], Train Loss: 0.000292
Validation Loss: 0.00028113
Epoch [160/300], Train Loss: 0.000293
Validation Loss: 0.00032011
Epoch [161/300], Train Loss: 0.000299
Validation Loss: 0.00032107
Epoch [162/300], Train Loss: 0.000289
Validation Loss: 0.00026660
Epoch [163/300], Train Loss: 0.000286
Validation Loss: 0.00027326
Epoch [164/300], Train Loss: 0.000293
Validation Loss: 0.00028498
Epoch [165/300], Train Loss: 0.000293
Validation Loss: 0.00026428
Epoch [166/300], Train Loss: 0.000282
Validation Loss: 0.00026664
Epoch [167/300], Train Loss: 0.000285
Validation Loss: 0.00026940
Epoch [168/300], Train Loss: 0.000283
Validation Loss: 0.00028106
Epoch [169/300], Train Loss: 0.000280
Validation Loss: 0.00028097
Epoch [170/300], Train Loss: 0.000273
Validation Loss: 0.00025886
Epoch [171/300], Train Loss: 0.000276
Validation Loss: 0.00028588
Epoch [172/300], Train Loss: 0.000274
Validation Loss: 0.00027550
Epoch [173/300], Train Loss: 0.000269
Validation Loss: 0.00027941
Epoch [174/300], Train Loss: 0.000279
Validation Loss: 0.00029003
Epoch [175/300], Train Loss: 0.000274
Validation Loss: 0.00027407
Epoch [176/300], Train Loss: 0.000272
Validation Loss: 0.00025784
Epoch [177/300], Train Loss: 0.000274
Validation Loss: 0.00026147
Epoch [178/300], Train Loss: 0.000266
Validation Loss: 0.00026008
Epoch [179/300], Train Loss: 0.000269
Validation Loss: 0.00025063
Epoch [180/300], Train Loss: 0.000268
Validation Loss: 0.00026004
Epoch [181/300], Train Loss: 0.000264
Validation Loss: 0.00025725
Epoch [182/300], Train Loss: 0.000264
Validation Loss: 0.00025438
Epoch [183/300], Train Loss: 0.000265
Validation Loss: 0.00024883
Epoch [184/300], Train Loss: 0.000263
Validation Loss: 0.00025239
Epoch [185/300], Train Loss: 0.000265
Validation Loss: 0.00026909
Epoch [186/300], Train Loss: 0.000267
Validation Loss: 0.00027387
Epoch [187/300], Train Loss: 0.000257
Validation Loss: 0.00024559
Epoch [188/300], Train Loss: 0.000255
Validation Loss: 0.00024491
Epoch [189/300], Train Loss: 0.000256
Validation Loss: 0.00024096
Epoch [190/300], Train Loss: 0.000255
Validation Loss: 0.00026263
Epoch [191/300], Train Loss: 0.000259
Validation Loss: 0.00025151
Epoch [192/300], Train Loss: 0.000254
Validation Loss: 0.00025399
Epoch [193/300], Train Loss: 0.000254
Validation Loss: 0.00024668
Epoch [194/300], Train Loss: 0.000253
Validation Loss: 0.00023803
Epoch [195/300], Train Loss: 0.000253
Validation Loss: 0.00024849
Epoch [196/300], Train Loss: 0.000248
Validation Loss: 0.00023231
Epoch [197/300], Train Loss: 0.000251
Validation Loss: 0.00023173
Epoch [198/300], Train Loss: 0.000252
Validation Loss: 0.00022646
Epoch [199/300], Train Loss: 0.000250
Validation Loss: 0.00024810
Epoch [200/300], Train Loss: 0.000246
Validation Loss: 0.00023294
Epoch [201/300], Train Loss: 0.000241
Validation Loss: 0.00022673
Epoch [202/300], Train Loss: 0.000245
Validation Loss: 0.00023660
Epoch [203/300], Train Loss: 0.000242
Validation Loss: 0.00023357
Epoch [204/300], Train Loss: 0.000240
Validation Loss: 0.00023498
Epoch [205/300], Train Loss: 0.000238
Validation Loss: 0.00022803
Epoch [206/300], Train Loss: 0.000244
Validation Loss: 0.00024694
Epoch [207/300], Train Loss: 0.000242
Validation Loss: 0.00026013
Epoch [208/300], Train Loss: 0.000241
Validation Loss: 0.00025452
Early stopping triggered

Evaluating model for: Coffee Machine
Run 70/72 completed in 2413.79 seconds with: {'MAE': np.float32(4.8781567), 'MSE': np.float32(1457.6764), 'RMSE': np.float32(38.179527), 'SAE': np.float32(0.052030377), 'NDE': np.float32(0.5804842)}

Run 71/72: hidden=512, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Coffee Machine
Dataset length: 2980 windows

Epoch [1/300], Train Loss: 0.001072
Validation Loss: 0.00093305
Epoch [2/300], Train Loss: 0.000974
Validation Loss: 0.00092103
Epoch [3/300], Train Loss: 0.000978
Validation Loss: 0.00091804
Epoch [4/300], Train Loss: 0.000979
Validation Loss: 0.00091748
Epoch [5/300], Train Loss: 0.000981
Validation Loss: 0.00091787
Epoch [6/300], Train Loss: 0.000978
Validation Loss: 0.00091717
Epoch [7/300], Train Loss: 0.000978
Validation Loss: 0.00091745
Epoch [8/300], Train Loss: 0.000982
Validation Loss: 0.00091733
Epoch [9/300], Train Loss: 0.000986
Validation Loss: 0.00091701
Epoch [10/300], Train Loss: 0.000986
Validation Loss: 0.00091713
Epoch [11/300], Train Loss: 0.000970
Validation Loss: 0.00091682
Epoch [12/300], Train Loss: 0.000979
Validation Loss: 0.00091688
Epoch [13/300], Train Loss: 0.000981
Validation Loss: 0.00091660
Epoch [14/300], Train Loss: 0.000982
Validation Loss: 0.00091649
Epoch [15/300], Train Loss: 0.000970
Validation Loss: 0.00091672
Epoch [16/300], Train Loss: 0.000978
Validation Loss: 0.00091619
Epoch [17/300], Train Loss: 0.000983
Validation Loss: 0.00091614
Epoch [18/300], Train Loss: 0.000979
Validation Loss: 0.00091569
Epoch [19/300], Train Loss: 0.000980
Validation Loss: 0.00091524
Epoch [20/300], Train Loss: 0.000969
Validation Loss: 0.00091489
Epoch [21/300], Train Loss: 0.000980
Validation Loss: 0.00091525
Epoch [22/300], Train Loss: 0.000966
Validation Loss: 0.00091385
Epoch [23/300], Train Loss: 0.000979
Validation Loss: 0.00091355
Epoch [24/300], Train Loss: 0.000971
Validation Loss: 0.00091246
Epoch [25/300], Train Loss: 0.000973
Validation Loss: 0.00091185
Epoch [26/300], Train Loss: 0.000977
Validation Loss: 0.00091443
Epoch [27/300], Train Loss: 0.000974
Validation Loss: 0.00090855
Epoch [28/300], Train Loss: 0.000963
Validation Loss: 0.00090582
Epoch [29/300], Train Loss: 0.000969
Validation Loss: 0.00090359
Epoch [30/300], Train Loss: 0.000966
Validation Loss: 0.00090123
Epoch [31/300], Train Loss: 0.000960
Validation Loss: 0.00089879
Epoch [32/300], Train Loss: 0.000961
Validation Loss: 0.00089551
Epoch [33/300], Train Loss: 0.000958
Validation Loss: 0.00089099
Epoch [34/300], Train Loss: 0.000954
Validation Loss: 0.00088535
Epoch [35/300], Train Loss: 0.000944
Validation Loss: 0.00087943
Epoch [36/300], Train Loss: 0.000948
Validation Loss: 0.00086626
Epoch [37/300], Train Loss: 0.000947
Validation Loss: 0.00086578
Epoch [38/300], Train Loss: 0.000928
Validation Loss: 0.00084530
Epoch [39/300], Train Loss: 0.000915
Validation Loss: 0.00082525
Epoch [40/300], Train Loss: 0.000892
Validation Loss: 0.00080125
Epoch [41/300], Train Loss: 0.000880
Validation Loss: 0.00078800
Epoch [42/300], Train Loss: 0.000863
Validation Loss: 0.00076024
Epoch [43/300], Train Loss: 0.000836
Validation Loss: 0.00073673
Epoch [44/300], Train Loss: 0.000807
Validation Loss: 0.00071392
Epoch [45/300], Train Loss: 0.000782
Validation Loss: 0.00069452
Epoch [46/300], Train Loss: 0.000777
Validation Loss: 0.00067659
Epoch [47/300], Train Loss: 0.000760
Validation Loss: 0.00066194
Epoch [48/300], Train Loss: 0.000745
Validation Loss: 0.00065079
Epoch [49/300], Train Loss: 0.000730
Validation Loss: 0.00063943
Epoch [50/300], Train Loss: 0.000725
Validation Loss: 0.00063615
Epoch [51/300], Train Loss: 0.000718
Validation Loss: 0.00061813
Epoch [52/300], Train Loss: 0.000692
Validation Loss: 0.00060394
Epoch [53/300], Train Loss: 0.000682
Validation Loss: 0.00059584
Epoch [54/300], Train Loss: 0.000669
Validation Loss: 0.00058619
Epoch [55/300], Train Loss: 0.000661
Validation Loss: 0.00058957
Epoch [56/300], Train Loss: 0.000666
Validation Loss: 0.00055824
Epoch [57/300], Train Loss: 0.000653
Validation Loss: 0.00056185
Epoch [58/300], Train Loss: 0.000641
Validation Loss: 0.00056903
Epoch [59/300], Train Loss: 0.000629
Validation Loss: 0.00055097
Epoch [60/300], Train Loss: 0.000620
Validation Loss: 0.00054731
Epoch [61/300], Train Loss: 0.000610
Validation Loss: 0.00053125
Epoch [62/300], Train Loss: 0.000603
Validation Loss: 0.00054717
Epoch [63/300], Train Loss: 0.000592
Validation Loss: 0.00051517
Epoch [64/300], Train Loss: 0.000589
Validation Loss: 0.00051870
Epoch [65/300], Train Loss: 0.000580
Validation Loss: 0.00053193
Epoch [66/300], Train Loss: 0.000605
Validation Loss: 0.00050724
Epoch [67/300], Train Loss: 0.000578
Validation Loss: 0.00048728
Epoch [68/300], Train Loss: 0.000593
Validation Loss: 0.00056057
Epoch [69/300], Train Loss: 0.000643
Validation Loss: 0.00055672
Epoch [70/300], Train Loss: 0.000602
Validation Loss: 0.00053852
Epoch [71/300], Train Loss: 0.000614
Validation Loss: 0.00078343
Epoch [72/300], Train Loss: 0.000883
Validation Loss: 0.00070921
Epoch [73/300], Train Loss: 0.000754
Validation Loss: 0.00060927
Epoch [74/300], Train Loss: 0.000672
Validation Loss: 0.00060352
Epoch [75/300], Train Loss: 0.000649
Validation Loss: 0.00058325
Epoch [76/300], Train Loss: 0.000629
Validation Loss: 0.00056419
Epoch [77/300], Train Loss: 0.000616
Validation Loss: 0.00056087
Early stopping triggered

Evaluating model for: Coffee Machine
Run 71/72 completed in 1102.06 seconds with: {'MAE': np.float32(8.800564), 'MSE': np.float32(3143.0833), 'RMSE': np.float32(56.06321), 'SAE': np.float32(0.50214237), 'NDE': np.float32(0.8523893)}

Run 72/72: hidden=512, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Coffee Machine
Dataset length: 2980 windows

Epoch [1/300], Train Loss: 0.001175
Validation Loss: 0.00093917
Epoch [2/300], Train Loss: 0.000982
Validation Loss: 0.00091953
Epoch [3/300], Train Loss: 0.000979
Validation Loss: 0.00091842
Epoch [4/300], Train Loss: 0.000980
Validation Loss: 0.00091741
Epoch [5/300], Train Loss: 0.000982
Validation Loss: 0.00091770
Epoch [6/300], Train Loss: 0.000979
Validation Loss: 0.00091731
Epoch [7/300], Train Loss: 0.000979
Validation Loss: 0.00091754
Epoch [8/300], Train Loss: 0.000983
Validation Loss: 0.00091724
Epoch [9/300], Train Loss: 0.000987
Validation Loss: 0.00091729
Epoch [10/300], Train Loss: 0.000988
Validation Loss: 0.00091726
Epoch [11/300], Train Loss: 0.000971
Validation Loss: 0.00091716
Epoch [12/300], Train Loss: 0.000980
Validation Loss: 0.00091710
Epoch [13/300], Train Loss: 0.000982
Validation Loss: 0.00091714
Epoch [14/300], Train Loss: 0.000984
Validation Loss: 0.00091705
Epoch [15/300], Train Loss: 0.000971
Validation Loss: 0.00091712
Epoch [16/300], Train Loss: 0.000979
Validation Loss: 0.00091725
Epoch [17/300], Train Loss: 0.000985
Validation Loss: 0.00091762
Epoch [18/300], Train Loss: 0.000981
Validation Loss: 0.00091708
Epoch [19/300], Train Loss: 0.000981
Validation Loss: 0.00091699
Epoch [20/300], Train Loss: 0.000971
Validation Loss: 0.00091687
Epoch [21/300], Train Loss: 0.000982
Validation Loss: 0.00091725
Epoch [22/300], Train Loss: 0.000968
Validation Loss: 0.00091681
Epoch [23/300], Train Loss: 0.000982
Validation Loss: 0.00091685
Epoch [24/300], Train Loss: 0.000974
Validation Loss: 0.00091691
Epoch [25/300], Train Loss: 0.000977
Validation Loss: 0.00091672
Epoch [26/300], Train Loss: 0.000981
Validation Loss: 0.00091669
Epoch [27/300], Train Loss: 0.000978
Validation Loss: 0.00091666
Epoch [28/300], Train Loss: 0.000970
Validation Loss: 0.00091664
Epoch [29/300], Train Loss: 0.000979
Validation Loss: 0.00091668
Epoch [30/300], Train Loss: 0.000976
Validation Loss: 0.00091685
Epoch [31/300], Train Loss: 0.000973
Validation Loss: 0.00091647
Epoch [32/300], Train Loss: 0.000977
Validation Loss: 0.00091643
Epoch [33/300], Train Loss: 0.000977
Validation Loss: 0.00091785
Epoch [34/300], Train Loss: 0.000977
Validation Loss: 0.00091654
Epoch [35/300], Train Loss: 0.000972
Validation Loss: 0.00091624
Epoch [36/300], Train Loss: 0.000984
Validation Loss: 0.00091616
Epoch [37/300], Train Loss: 0.000993
Validation Loss: 0.00091925
Epoch [38/300], Train Loss: 0.000980
Validation Loss: 0.00091592
Epoch [39/300], Train Loss: 0.000983
Validation Loss: 0.00091610
Epoch [40/300], Train Loss: 0.000977
Validation Loss: 0.00091674
Epoch [41/300], Train Loss: 0.000982
Validation Loss: 0.00091619
Epoch [42/300], Train Loss: 0.000986
Validation Loss: 0.00091538
Epoch [43/300], Train Loss: 0.000983
Validation Loss: 0.00091532
Epoch [44/300], Train Loss: 0.000972
Validation Loss: 0.00091462
Epoch [45/300], Train Loss: 0.000968
Validation Loss: 0.00091432
Epoch [46/300], Train Loss: 0.000977
Validation Loss: 0.00091367
Epoch [47/300], Train Loss: 0.000978
Validation Loss: 0.00091444
Epoch [48/300], Train Loss: 0.000974
Validation Loss: 0.00091402
Epoch [49/300], Train Loss: 0.000971
Validation Loss: 0.00091096
Epoch [50/300], Train Loss: 0.000973
Validation Loss: 0.00091053
Epoch [51/300], Train Loss: 0.000976
Validation Loss: 0.00091015
Epoch [52/300], Train Loss: 0.000969
Validation Loss: 0.00090899
Epoch [53/300], Train Loss: 0.000971
Validation Loss: 0.00090909
Epoch [54/300], Train Loss: 0.000977
Validation Loss: 0.00090747
Epoch [55/300], Train Loss: 0.000966
Validation Loss: 0.00090640
Epoch [56/300], Train Loss: 0.000975
Validation Loss: 0.00090736
Epoch [57/300], Train Loss: 0.000981
Validation Loss: 0.00090448
Epoch [58/300], Train Loss: 0.000962
Validation Loss: 0.00090196
Epoch [59/300], Train Loss: 0.000963
Validation Loss: 0.00089886
Epoch [60/300], Train Loss: 0.000974
Validation Loss: 0.00089608
Epoch [61/300], Train Loss: 0.000957
Validation Loss: 0.00088932
Epoch [62/300], Train Loss: 0.000951
Validation Loss: 0.00088216
Epoch [63/300], Train Loss: 0.000948
Validation Loss: 0.00087385
Epoch [64/300], Train Loss: 0.000930
Validation Loss: 0.00086025
Epoch [65/300], Train Loss: 0.000930
Validation Loss: 0.00084216
Epoch [66/300], Train Loss: 0.000912
Validation Loss: 0.00082048
Epoch [67/300], Train Loss: 0.000892
Validation Loss: 0.00079862
Epoch [68/300], Train Loss: 0.000875
Validation Loss: 0.00077588
Epoch [69/300], Train Loss: 0.000851
Validation Loss: 0.00074713
Epoch [70/300], Train Loss: 0.000827
Validation Loss: 0.00072781
Epoch [71/300], Train Loss: 0.000795
Validation Loss: 0.00071092
Epoch [72/300], Train Loss: 0.000780
Validation Loss: 0.00068701
Epoch [73/300], Train Loss: 0.000759
Validation Loss: 0.00065790
Epoch [74/300], Train Loss: 0.000737
Validation Loss: 0.00066007
Epoch [75/300], Train Loss: 0.000729
Validation Loss: 0.00063430
Epoch [76/300], Train Loss: 0.000710
Validation Loss: 0.00061476
Epoch [77/300], Train Loss: 0.000701
Validation Loss: 0.00062165
Epoch [78/300], Train Loss: 0.000695
Validation Loss: 0.00062436
Epoch [79/300], Train Loss: 0.000691
Validation Loss: 0.00061914
Epoch [80/300], Train Loss: 0.000659
Validation Loss: 0.00058769
Epoch [81/300], Train Loss: 0.000652
Validation Loss: 0.00056782
Epoch [82/300], Train Loss: 0.000636
Validation Loss: 0.00055430
Epoch [83/300], Train Loss: 0.000638
Validation Loss: 0.00058214
Epoch [84/300], Train Loss: 0.000630
Validation Loss: 0.00056496
Epoch [85/300], Train Loss: 0.000627
Validation Loss: 0.00055072
Epoch [86/300], Train Loss: 0.000610
Validation Loss: 0.00052925
Epoch [87/300], Train Loss: 0.000603
Validation Loss: 0.00054266
Epoch [88/300], Train Loss: 0.000600
Validation Loss: 0.00052023
Epoch [89/300], Train Loss: 0.000584
Validation Loss: 0.00050483
Epoch [90/300], Train Loss: 0.000585
Validation Loss: 0.00052561
Epoch [91/300], Train Loss: 0.000581
Validation Loss: 0.00051196
Epoch [92/300], Train Loss: 0.000570
Validation Loss: 0.00049761
Epoch [93/300], Train Loss: 0.000560
Validation Loss: 0.00049016
Epoch [94/300], Train Loss: 0.000598
Validation Loss: 0.00053994
Epoch [95/300], Train Loss: 0.000567
Validation Loss: 0.00049906
Epoch [96/300], Train Loss: 0.000552
Validation Loss: 0.00047702
Epoch [97/300], Train Loss: 0.000539
Validation Loss: 0.00050577
Epoch [98/300], Train Loss: 0.000559
Validation Loss: 0.00047903
Epoch [99/300], Train Loss: 0.000548
Validation Loss: 0.00046776
Epoch [100/300], Train Loss: 0.000532
Validation Loss: 0.00048520
Epoch [101/300], Train Loss: 0.000542
Validation Loss: 0.00047166
Epoch [102/300], Train Loss: 0.000529
Validation Loss: 0.00046745
Epoch [103/300], Train Loss: 0.000525
Validation Loss: 0.00046283
Epoch [104/300], Train Loss: 0.000522
Validation Loss: 0.00045232
Epoch [105/300], Train Loss: 0.000506
Validation Loss: 0.00047483
Epoch [106/300], Train Loss: 0.000505
Validation Loss: 0.00046472
Epoch [107/300], Train Loss: 0.000499
Validation Loss: 0.00044614
Epoch [108/300], Train Loss: 0.000497
Validation Loss: 0.00048085
Epoch [109/300], Train Loss: 0.000505
Validation Loss: 0.00045824
Epoch [110/300], Train Loss: 0.000485
Validation Loss: 0.00044683
Epoch [111/300], Train Loss: 0.000477
Validation Loss: 0.00043369
Epoch [112/300], Train Loss: 0.000479
Validation Loss: 0.00044340
Epoch [113/300], Train Loss: 0.000477
Validation Loss: 0.00044984
Epoch [114/300], Train Loss: 0.000458
Validation Loss: 0.00042904
Epoch [115/300], Train Loss: 0.000464
Validation Loss: 0.00040588
Epoch [116/300], Train Loss: 0.000450
Validation Loss: 0.00039905
Epoch [117/300], Train Loss: 0.000428
Validation Loss: 0.00038664
Epoch [118/300], Train Loss: 0.000422
Validation Loss: 0.00038871
Epoch [119/300], Train Loss: 0.000420
Validation Loss: 0.00034203
Epoch [120/300], Train Loss: 0.000456
Validation Loss: 0.00042008
Epoch [121/300], Train Loss: 0.000427
Validation Loss: 0.00037641
Epoch [122/300], Train Loss: 0.000405
Validation Loss: 0.00036157
Epoch [123/300], Train Loss: 0.000388
Validation Loss: 0.00034939
Epoch [124/300], Train Loss: 0.000386
Validation Loss: 0.00035754
Epoch [125/300], Train Loss: 0.000371
Validation Loss: 0.00033293
Epoch [126/300], Train Loss: 0.000360
Validation Loss: 0.00031372
Epoch [127/300], Train Loss: 0.000361
Validation Loss: 0.00031762
Epoch [128/300], Train Loss: 0.000353
Validation Loss: 0.00029967
Epoch [129/300], Train Loss: 0.000345
Validation Loss: 0.00030458
Epoch [130/300], Train Loss: 0.000342
Validation Loss: 0.00029592
Epoch [131/300], Train Loss: 0.000344
Validation Loss: 0.00028769
Epoch [132/300], Train Loss: 0.000346
Validation Loss: 0.00029561
Epoch [133/300], Train Loss: 0.000333
Validation Loss: 0.00028079
Epoch [134/300], Train Loss: 0.000329
Validation Loss: 0.00029502
Epoch [135/300], Train Loss: 0.000331
Validation Loss: 0.00029036
Epoch [136/300], Train Loss: 0.000321
Validation Loss: 0.00027063
Epoch [137/300], Train Loss: 0.000324
Validation Loss: 0.00027781
Epoch [138/300], Train Loss: 0.000318
Validation Loss: 0.00028011
Epoch [139/300], Train Loss: 0.000313
Validation Loss: 0.00027197
Epoch [140/300], Train Loss: 0.000307
Validation Loss: 0.00026737
Epoch [141/300], Train Loss: 0.000303
Validation Loss: 0.00026042
Epoch [142/300], Train Loss: 0.000301
Validation Loss: 0.00030353
Epoch [143/300], Train Loss: 0.000310
Validation Loss: 0.00028673
Epoch [144/300], Train Loss: 0.000303
Validation Loss: 0.00026836
Epoch [145/300], Train Loss: 0.000297
Validation Loss: 0.00025878
Epoch [146/300], Train Loss: 0.000292
Validation Loss: 0.00025557
Epoch [147/300], Train Loss: 0.000296
Validation Loss: 0.00026498
Epoch [148/300], Train Loss: 0.000284
Validation Loss: 0.00025516
Epoch [149/300], Train Loss: 0.000285
Validation Loss: 0.00024446
Epoch [150/300], Train Loss: 0.000283
Validation Loss: 0.00024831
Epoch [151/300], Train Loss: 0.000284
Validation Loss: 0.00024618
Epoch [152/300], Train Loss: 0.000277
Validation Loss: 0.00024556
Epoch [153/300], Train Loss: 0.000283
Validation Loss: 0.00024970
Epoch [154/300], Train Loss: 0.000282
Validation Loss: 0.00024848
Epoch [155/300], Train Loss: 0.000275
Validation Loss: 0.00024789
Epoch [156/300], Train Loss: 0.000273
Validation Loss: 0.00024761
Epoch [157/300], Train Loss: 0.000272
Validation Loss: 0.00024127
Epoch [158/300], Train Loss: 0.000271
Validation Loss: 0.00023709
Epoch [159/300], Train Loss: 0.000274
Validation Loss: 0.00025131
Epoch [160/300], Train Loss: 0.000263
Validation Loss: 0.00025542
Epoch [161/300], Train Loss: 0.000271
Validation Loss: 0.00023290
Epoch [162/300], Train Loss: 0.000262
Validation Loss: 0.00022959
Epoch [163/300], Train Loss: 0.000256
Validation Loss: 0.00024405
Epoch [164/300], Train Loss: 0.000257
Validation Loss: 0.00022123
Epoch [165/300], Train Loss: 0.000260
Validation Loss: 0.00023181
Epoch [166/300], Train Loss: 0.000251
Validation Loss: 0.00021854
Epoch [167/300], Train Loss: 0.000248
Validation Loss: 0.00023559
Epoch [168/300], Train Loss: 0.000249
Validation Loss: 0.00022443
Epoch [169/300], Train Loss: 0.000258
Validation Loss: 0.00024341
Epoch [170/300], Train Loss: 0.000244
Validation Loss: 0.00021625
Epoch [171/300], Train Loss: 0.000246
Validation Loss: 0.00022883
Epoch [172/300], Train Loss: 0.000241
Validation Loss: 0.00023082
Epoch [173/300], Train Loss: 0.000238
Validation Loss: 0.00024086
Epoch [174/300], Train Loss: 0.000241
Validation Loss: 0.00021639
Epoch [175/300], Train Loss: 0.000243
Validation Loss: 0.00022862
Epoch [176/300], Train Loss: 0.000238
Validation Loss: 0.00022145
Epoch [177/300], Train Loss: 0.000241
Validation Loss: 0.00022430
Epoch [178/300], Train Loss: 0.000229
Validation Loss: 0.00023173
Epoch [179/300], Train Loss: 0.000230
Validation Loss: 0.00021323
Epoch [180/300], Train Loss: 0.000232
Validation Loss: 0.00021235
Epoch [181/300], Train Loss: 0.000223
Validation Loss: 0.00020577
Epoch [182/300], Train Loss: 0.000222
Validation Loss: 0.00020460
Epoch [183/300], Train Loss: 0.000224
Validation Loss: 0.00022588
Epoch [184/300], Train Loss: 0.000225
Validation Loss: 0.00020087
Epoch [185/300], Train Loss: 0.000221
Validation Loss: 0.00022075
Epoch [186/300], Train Loss: 0.000221
Validation Loss: 0.00020668
Epoch [187/300], Train Loss: 0.000215
Validation Loss: 0.00020088
Epoch [188/300], Train Loss: 0.000212
Validation Loss: 0.00019296
Epoch [189/300], Train Loss: 0.000219
Validation Loss: 0.00022580
Epoch [190/300], Train Loss: 0.000217
Validation Loss: 0.00019806
Epoch [191/300], Train Loss: 0.000212
Validation Loss: 0.00020313
Epoch [192/300], Train Loss: 0.000213
Validation Loss: 0.00021730
Epoch [193/300], Train Loss: 0.000212
Validation Loss: 0.00020586
Epoch [194/300], Train Loss: 0.000210
Validation Loss: 0.00019879
Epoch [195/300], Train Loss: 0.000209
Validation Loss: 0.00021207
Epoch [196/300], Train Loss: 0.000203
Validation Loss: 0.00019834
Epoch [197/300], Train Loss: 0.000206
Validation Loss: 0.00020778
Epoch [198/300], Train Loss: 0.000205
Validation Loss: 0.00019705
Early stopping triggered

Evaluating model for: Coffee Machine
Run 72/72 completed in 3678.48 seconds with: {'MAE': np.float32(4.044619), 'MSE': np.float32(1322.7708), 'RMSE': np.float32(36.369915), 'SAE': np.float32(0.16971189), 'NDE': np.float32(0.5529696)}
    hidden_size  seq_length  stride  num_layers  eval_result
50          512         120    0.25           4     1.827915
51          512         120    0.25           5     1.952513
25          256         120    0.25           3     2.148332
27          256         120    0.25           5     2.274553
59          512         360    0.25           5     2.419424
..          ...         ...     ...         ...          ...
23          128         720    0.50           5     6.341186
14          128         360    0.50           4     6.471159
12          128         360    0.50           2     6.678108
20          128         720    0.50           2     7.013828
70          512         720    0.50           4     8.800564

[72 rows x 5 columns]
