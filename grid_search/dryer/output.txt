Using device: cuda

Run 1/72: hidden=128, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Dryer
Dataset length: 9150 windows

Epoch [1/300], Train Loss: 0.010649
Validation Loss: 0.01192293
Epoch [2/300], Train Loss: 0.010288
Validation Loss: 0.01154062
Epoch [3/300], Train Loss: 0.008728
Validation Loss: 0.00527401
Epoch [4/300], Train Loss: 0.004244
Validation Loss: 0.00329948
Epoch [5/300], Train Loss: 0.003405
Validation Loss: 0.00297946
Epoch [6/300], Train Loss: 0.003014
Validation Loss: 0.00263303
Epoch [7/300], Train Loss: 0.002641
Validation Loss: 0.00253611
Epoch [8/300], Train Loss: 0.002384
Validation Loss: 0.00201416
Epoch [9/300], Train Loss: 0.002188
Validation Loss: 0.00217837
Epoch [10/300], Train Loss: 0.002110
Validation Loss: 0.00292024
Epoch [11/300], Train Loss: 0.002132
Validation Loss: 0.00213098
Epoch [12/300], Train Loss: 0.001867
Validation Loss: 0.00198667
Epoch [13/300], Train Loss: 0.001826
Validation Loss: 0.00196081
Epoch [14/300], Train Loss: 0.001708
Validation Loss: 0.00174480
Epoch [15/300], Train Loss: 0.001585
Validation Loss: 0.00170267
Epoch [16/300], Train Loss: 0.001539
Validation Loss: 0.00159043
Epoch [17/300], Train Loss: 0.001457
Validation Loss: 0.00168022
Epoch [18/300], Train Loss: 0.001498
Validation Loss: 0.00173427
Epoch [19/300], Train Loss: 0.001405
Validation Loss: 0.00158017
Epoch [20/300], Train Loss: 0.001379
Validation Loss: 0.00128795
Epoch [21/300], Train Loss: 0.001392
Validation Loss: 0.00126348
Epoch [22/300], Train Loss: 0.001364
Validation Loss: 0.00133979
Epoch [23/300], Train Loss: 0.001319
Validation Loss: 0.00130526
Epoch [24/300], Train Loss: 0.001289
Validation Loss: 0.00124185
Epoch [25/300], Train Loss: 0.001254
Validation Loss: 0.00118136
Epoch [26/300], Train Loss: 0.001227
Validation Loss: 0.00139861
Epoch [27/300], Train Loss: 0.001224
Validation Loss: 0.00117937
Epoch [28/300], Train Loss: 0.001191
Validation Loss: 0.00119191
Epoch [29/300], Train Loss: 0.001200
Validation Loss: 0.00114001
Epoch [30/300], Train Loss: 0.001178
Validation Loss: 0.00116777
Epoch [31/300], Train Loss: 0.001168
Validation Loss: 0.00124446
Epoch [32/300], Train Loss: 0.001139
Validation Loss: 0.00139568
Epoch [33/300], Train Loss: 0.001094
Validation Loss: 0.00110095
Epoch [34/300], Train Loss: 0.001108
Validation Loss: 0.00110139
Epoch [35/300], Train Loss: 0.001079
Validation Loss: 0.00110432
Epoch [36/300], Train Loss: 0.001156
Validation Loss: 0.00161563
Epoch [37/300], Train Loss: 0.001262
Validation Loss: 0.00126944
Epoch [38/300], Train Loss: 0.001086
Validation Loss: 0.00106642
Epoch [39/300], Train Loss: 0.001178
Validation Loss: 0.00139701
Epoch [40/300], Train Loss: 0.001178
Validation Loss: 0.00131631
Epoch [41/300], Train Loss: 0.001070
Validation Loss: 0.00115017
Epoch [42/300], Train Loss: 0.001036
Validation Loss: 0.00118282
Epoch [43/300], Train Loss: 0.001026
Validation Loss: 0.00114306
Epoch [44/300], Train Loss: 0.000970
Validation Loss: 0.00116124
Epoch [45/300], Train Loss: 0.000954
Validation Loss: 0.00112662
Epoch [46/300], Train Loss: 0.001018
Validation Loss: 0.00111922
Epoch [47/300], Train Loss: 0.000968
Validation Loss: 0.00117008
Epoch [48/300], Train Loss: 0.001000
Validation Loss: 0.00123598
Early stopping triggered

Evaluating model for: Dryer
Run 1/72 completed in 369.37 seconds with: {'MAE': np.float32(4.6834106), 'MSE': np.float32(1400.1187), 'RMSE': np.float32(37.41816), 'SAE': np.float32(0.032515526), 'NDE': np.float32(0.36370417)}

Run 2/72: hidden=128, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Dryer
Dataset length: 9150 windows

Epoch [1/300], Train Loss: 0.010975
Validation Loss: 0.01205375
Epoch [2/300], Train Loss: 0.010447
Validation Loss: 0.01182810
Epoch [3/300], Train Loss: 0.009201
Validation Loss: 0.00443094
Epoch [4/300], Train Loss: 0.004089
Validation Loss: 0.00329413
Epoch [5/300], Train Loss: 0.003424
Validation Loss: 0.00310501
Epoch [6/300], Train Loss: 0.003054
Validation Loss: 0.00270696
Epoch [7/300], Train Loss: 0.002732
Validation Loss: 0.00252178
Epoch [8/300], Train Loss: 0.002374
Validation Loss: 0.00220146
Epoch [9/300], Train Loss: 0.002116
Validation Loss: 0.00207062
Epoch [10/300], Train Loss: 0.002174
Validation Loss: 0.00247019
Epoch [11/300], Train Loss: 0.002041
Validation Loss: 0.00183547
Epoch [12/300], Train Loss: 0.001756
Validation Loss: 0.00172214
Epoch [13/300], Train Loss: 0.001678
Validation Loss: 0.00173101
Epoch [14/300], Train Loss: 0.001699
Validation Loss: 0.00167019
Epoch [15/300], Train Loss: 0.001566
Validation Loss: 0.00175474
Epoch [16/300], Train Loss: 0.001545
Validation Loss: 0.00145186
Epoch [17/300], Train Loss: 0.001483
Validation Loss: 0.00141602
Epoch [18/300], Train Loss: 0.001385
Validation Loss: 0.00137095
Epoch [19/300], Train Loss: 0.001285
Validation Loss: 0.00133600
Epoch [20/300], Train Loss: 0.001260
Validation Loss: 0.00129650
Epoch [21/300], Train Loss: 0.001300
Validation Loss: 0.00126133
Epoch [22/300], Train Loss: 0.001254
Validation Loss: 0.00128579
Epoch [23/300], Train Loss: 0.001205
Validation Loss: 0.00129423
Epoch [24/300], Train Loss: 0.001149
Validation Loss: 0.00119207
Epoch [25/300], Train Loss: 0.001122
Validation Loss: 0.00115930
Epoch [26/300], Train Loss: 0.001094
Validation Loss: 0.00117267
Epoch [27/300], Train Loss: 0.001056
Validation Loss: 0.00115753
Epoch [28/300], Train Loss: 0.001007
Validation Loss: 0.00114228
Epoch [29/300], Train Loss: 0.001339
Validation Loss: 0.00117923
Epoch [30/300], Train Loss: 0.001134
Validation Loss: 0.00116423
Epoch [31/300], Train Loss: 0.001037
Validation Loss: 0.00113000
Epoch [32/300], Train Loss: 0.001004
Validation Loss: 0.00112370
Epoch [33/300], Train Loss: 0.000959
Validation Loss: 0.00108603
Epoch [34/300], Train Loss: 0.000940
Validation Loss: 0.00110245
Epoch [35/300], Train Loss: 0.000934
Validation Loss: 0.00107413
Epoch [36/300], Train Loss: 0.000933
Validation Loss: 0.00110985
Epoch [37/300], Train Loss: 0.000949
Validation Loss: 0.00104051
Epoch [38/300], Train Loss: 0.000918
Validation Loss: 0.00101868
Epoch [39/300], Train Loss: 0.000902
Validation Loss: 0.00102225
Epoch [40/300], Train Loss: 0.000889
Validation Loss: 0.00102977
Epoch [41/300], Train Loss: 0.000878
Validation Loss: 0.00101579
Epoch [42/300], Train Loss: 0.000876
Validation Loss: 0.00105976
Epoch [43/300], Train Loss: 0.000873
Validation Loss: 0.00103278
Epoch [44/300], Train Loss: 0.000859
Validation Loss: 0.00100704
Epoch [45/300], Train Loss: 0.000852
Validation Loss: 0.00100114
Epoch [46/300], Train Loss: 0.000894
Validation Loss: 0.00103868
Epoch [47/300], Train Loss: 0.000841
Validation Loss: 0.00102302
Epoch [48/300], Train Loss: 0.000834
Validation Loss: 0.00097929
Epoch [49/300], Train Loss: 0.000832
Validation Loss: 0.00101160
Epoch [50/300], Train Loss: 0.000812
Validation Loss: 0.00094888
Epoch [51/300], Train Loss: 0.000815
Validation Loss: 0.00098430
Epoch [52/300], Train Loss: 0.000800
Validation Loss: 0.00096925
Epoch [53/300], Train Loss: 0.000786
Validation Loss: 0.00095341
Epoch [54/300], Train Loss: 0.000794
Validation Loss: 0.00094204
Epoch [55/300], Train Loss: 0.000779
Validation Loss: 0.00094251
Epoch [56/300], Train Loss: 0.000792
Validation Loss: 0.00094329
Epoch [57/300], Train Loss: 0.000775
Validation Loss: 0.00096668
Epoch [58/300], Train Loss: 0.000755
Validation Loss: 0.00098516
Epoch [59/300], Train Loss: 0.000767
Validation Loss: 0.00091251
Epoch [60/300], Train Loss: 0.000733
Validation Loss: 0.00092229
Epoch [61/300], Train Loss: 0.000720
Validation Loss: 0.00095316
Epoch [62/300], Train Loss: 0.000737
Validation Loss: 0.00094704
Epoch [63/300], Train Loss: 0.000730
Validation Loss: 0.00090130
Epoch [64/300], Train Loss: 0.000701
Validation Loss: 0.00097973
Epoch [65/300], Train Loss: 0.000704
Validation Loss: 0.00089276
Epoch [66/300], Train Loss: 0.000720
Validation Loss: 0.00090249
Epoch [67/300], Train Loss: 0.000681
Validation Loss: 0.00090530
Epoch [68/300], Train Loss: 0.000710
Validation Loss: 0.00088841
Epoch [69/300], Train Loss: 0.000687
Validation Loss: 0.00089491
Epoch [70/300], Train Loss: 0.000677
Validation Loss: 0.00089045
Epoch [71/300], Train Loss: 0.000724
Validation Loss: 0.00089695
Epoch [72/300], Train Loss: 0.000694
Validation Loss: 0.00093048
Epoch [73/300], Train Loss: 0.000656
Validation Loss: 0.00089395
Epoch [74/300], Train Loss: 0.000655
Validation Loss: 0.00085200
Epoch [75/300], Train Loss: 0.000647
Validation Loss: 0.00089809
Epoch [76/300], Train Loss: 0.000633
Validation Loss: 0.00089957
Epoch [77/300], Train Loss: 0.000667
Validation Loss: 0.00085522
Epoch [78/300], Train Loss: 0.000657
Validation Loss: 0.00083410
Epoch [79/300], Train Loss: 0.000630
Validation Loss: 0.00085184
Epoch [80/300], Train Loss: 0.000616
Validation Loss: 0.00086172
Epoch [81/300], Train Loss: 0.000609
Validation Loss: 0.00085155
Epoch [82/300], Train Loss: 0.000602
Validation Loss: 0.00084415
Epoch [83/300], Train Loss: 0.000592
Validation Loss: 0.00084470
Epoch [84/300], Train Loss: 0.000587
Validation Loss: 0.00086289
Epoch [85/300], Train Loss: 0.000607
Validation Loss: 0.00084567
Epoch [86/300], Train Loss: 0.000598
Validation Loss: 0.00088186
Epoch [87/300], Train Loss: 0.000623
Validation Loss: 0.00083982
Epoch [88/300], Train Loss: 0.000585
Validation Loss: 0.00081808
Epoch [89/300], Train Loss: 0.000580
Validation Loss: 0.00082594
Epoch [90/300], Train Loss: 0.000583
Validation Loss: 0.00083922
Epoch [91/300], Train Loss: 0.000561
Validation Loss: 0.00082566
Epoch [92/300], Train Loss: 0.000547
Validation Loss: 0.00079849
Epoch [93/300], Train Loss: 0.000618
Validation Loss: 0.00081616
Epoch [94/300], Train Loss: 0.000557
Validation Loss: 0.00082594
Epoch [95/300], Train Loss: 0.000545
Validation Loss: 0.00081648
Epoch [96/300], Train Loss: 0.000527
Validation Loss: 0.00081406
Epoch [97/300], Train Loss: 0.000535
Validation Loss: 0.00083229
Epoch [98/300], Train Loss: 0.000531
Validation Loss: 0.00080615
Epoch [99/300], Train Loss: 0.000550
Validation Loss: 0.00081383
Epoch [100/300], Train Loss: 0.000532
Validation Loss: 0.00078272
Epoch [101/300], Train Loss: 0.000520
Validation Loss: 0.00081538
Epoch [102/300], Train Loss: 0.000508
Validation Loss: 0.00081758
Epoch [103/300], Train Loss: 0.000518
Validation Loss: 0.00079980
Epoch [104/300], Train Loss: 0.000495
Validation Loss: 0.00079461
Epoch [105/300], Train Loss: 0.000502
Validation Loss: 0.00080681
Epoch [106/300], Train Loss: 0.000503
Validation Loss: 0.00078827
Epoch [107/300], Train Loss: 0.000507
Validation Loss: 0.00078145
Epoch [108/300], Train Loss: 0.000517
Validation Loss: 0.00080243
Epoch [109/300], Train Loss: 0.000495
Validation Loss: 0.00078711
Epoch [110/300], Train Loss: 0.000491
Validation Loss: 0.00080074
Epoch [111/300], Train Loss: 0.000480
Validation Loss: 0.00078061
Epoch [112/300], Train Loss: 0.000484
Validation Loss: 0.00078729
Epoch [113/300], Train Loss: 0.000486
Validation Loss: 0.00075442
Epoch [114/300], Train Loss: 0.000497
Validation Loss: 0.00074390
Epoch [115/300], Train Loss: 0.000473
Validation Loss: 0.00076774
Epoch [116/300], Train Loss: 0.000474
Validation Loss: 0.00078968
Epoch [117/300], Train Loss: 0.000467
Validation Loss: 0.00077251
Epoch [118/300], Train Loss: 0.000472
Validation Loss: 0.00075833
Epoch [119/300], Train Loss: 0.000461
Validation Loss: 0.00076614
Epoch [120/300], Train Loss: 0.000471
Validation Loss: 0.00075442
Epoch [121/300], Train Loss: 0.000461
Validation Loss: 0.00075331
Epoch [122/300], Train Loss: 0.000456
Validation Loss: 0.00076568
Epoch [123/300], Train Loss: 0.000498
Validation Loss: 0.00077248
Epoch [124/300], Train Loss: 0.000450
Validation Loss: 0.00076178
Early stopping triggered

Evaluating model for: Dryer
Run 2/72 completed in 965.65 seconds with: {'MAE': np.float32(2.6453388), 'MSE': np.float32(653.91156), 'RMSE': np.float32(25.571695), 'SAE': np.float32(0.038490128), 'NDE': np.float32(0.24855652)}

Run 3/72: hidden=128, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Dryer
Dataset length: 9150 windows

Epoch [1/300], Train Loss: 0.010480
Validation Loss: 0.01204161
Epoch [2/300], Train Loss: 0.010407
Validation Loss: 0.01153175
Epoch [3/300], Train Loss: 0.006541
Validation Loss: 0.00342740
Epoch [4/300], Train Loss: 0.003546
Validation Loss: 0.00286614
Epoch [5/300], Train Loss: 0.003072
Validation Loss: 0.00270263
Epoch [6/300], Train Loss: 0.002769
Validation Loss: 0.00242150
Epoch [7/300], Train Loss: 0.002494
Validation Loss: 0.00203635
Epoch [8/300], Train Loss: 0.002378
Validation Loss: 0.00211759
Epoch [9/300], Train Loss: 0.002312
Validation Loss: 0.00202005
Epoch [10/300], Train Loss: 0.002200
Validation Loss: 0.00193697
Epoch [11/300], Train Loss: 0.002017
Validation Loss: 0.00180835
Epoch [12/300], Train Loss: 0.001923
Validation Loss: 0.00177014
Epoch [13/300], Train Loss: 0.001784
Validation Loss: 0.00152975
Epoch [14/300], Train Loss: 0.001827
Validation Loss: 0.00139516
Epoch [15/300], Train Loss: 0.001571
Validation Loss: 0.00142700
Epoch [16/300], Train Loss: 0.001511
Validation Loss: 0.00126981
Epoch [17/300], Train Loss: 0.001462
Validation Loss: 0.00129031
Epoch [18/300], Train Loss: 0.001382
Validation Loss: 0.00123686
Epoch [19/300], Train Loss: 0.001343
Validation Loss: 0.00119897
Epoch [20/300], Train Loss: 0.001239
Validation Loss: 0.00129240
Epoch [21/300], Train Loss: 0.001230
Validation Loss: 0.00118244
Epoch [22/300], Train Loss: 0.001215
Validation Loss: 0.00110617
Epoch [23/300], Train Loss: 0.001182
Validation Loss: 0.00117620
Epoch [24/300], Train Loss: 0.001094
Validation Loss: 0.00105780
Epoch [25/300], Train Loss: 0.001102
Validation Loss: 0.00117553
Epoch [26/300], Train Loss: 0.001021
Validation Loss: 0.00111958
Epoch [27/300], Train Loss: 0.000986
Validation Loss: 0.00111058
Epoch [28/300], Train Loss: 0.000955
Validation Loss: 0.00110037
Epoch [29/300], Train Loss: 0.001012
Validation Loss: 0.00109291
Epoch [30/300], Train Loss: 0.000977
Validation Loss: 0.00109432
Epoch [31/300], Train Loss: 0.000910
Validation Loss: 0.00105438
Epoch [32/300], Train Loss: 0.000902
Validation Loss: 0.00105438
Epoch [33/300], Train Loss: 0.000886
Validation Loss: 0.00102861
Epoch [34/300], Train Loss: 0.000875
Validation Loss: 0.00103493
Epoch [35/300], Train Loss: 0.000854
Validation Loss: 0.00104004
Epoch [36/300], Train Loss: 0.000852
Validation Loss: 0.00111958
Epoch [37/300], Train Loss: 0.000916
Validation Loss: 0.00102555
Epoch [38/300], Train Loss: 0.000826
Validation Loss: 0.00097633
Epoch [39/300], Train Loss: 0.000840
Validation Loss: 0.00095951
Epoch [40/300], Train Loss: 0.000834
Validation Loss: 0.00096255
Epoch [41/300], Train Loss: 0.000782
Validation Loss: 0.00098037
Epoch [42/300], Train Loss: 0.000771
Validation Loss: 0.00103812
Epoch [43/300], Train Loss: 0.000777
Validation Loss: 0.00100668
Epoch [44/300], Train Loss: 0.000772
Validation Loss: 0.00096229
Epoch [45/300], Train Loss: 0.000748
Validation Loss: 0.00097153
Epoch [46/300], Train Loss: 0.000807
Validation Loss: 0.00106073
Epoch [47/300], Train Loss: 0.000765
Validation Loss: 0.00096477
Epoch [48/300], Train Loss: 0.000786
Validation Loss: 0.00093596
Epoch [49/300], Train Loss: 0.000743
Validation Loss: 0.00098521
Epoch [50/300], Train Loss: 0.000698
Validation Loss: 0.00095683
Epoch [51/300], Train Loss: 0.000786
Validation Loss: 0.00093128
Epoch [52/300], Train Loss: 0.000725
Validation Loss: 0.00092366
Epoch [53/300], Train Loss: 0.000690
Validation Loss: 0.00093525
Epoch [54/300], Train Loss: 0.000679
Validation Loss: 0.00090883
Epoch [55/300], Train Loss: 0.000675
Validation Loss: 0.00090444
Epoch [56/300], Train Loss: 0.000694
Validation Loss: 0.00089304
Epoch [57/300], Train Loss: 0.000666
Validation Loss: 0.00090587
Epoch [58/300], Train Loss: 0.000658
Validation Loss: 0.00091113
Epoch [59/300], Train Loss: 0.000677
Validation Loss: 0.00087325
Epoch [60/300], Train Loss: 0.000649
Validation Loss: 0.00087712
Epoch [61/300], Train Loss: 0.000679
Validation Loss: 0.00089375
Epoch [62/300], Train Loss: 0.000684
Validation Loss: 0.00089430
Epoch [63/300], Train Loss: 0.000697
Validation Loss: 0.00084958
Epoch [64/300], Train Loss: 0.000629
Validation Loss: 0.00087764
Epoch [65/300], Train Loss: 0.000633
Validation Loss: 0.00083000
Epoch [66/300], Train Loss: 0.000637
Validation Loss: 0.00083345
Epoch [67/300], Train Loss: 0.000609
Validation Loss: 0.00085092
Epoch [68/300], Train Loss: 0.000684
Validation Loss: 0.00082175
Epoch [69/300], Train Loss: 0.000642
Validation Loss: 0.00082321
Epoch [70/300], Train Loss: 0.000613
Validation Loss: 0.00080950
Epoch [71/300], Train Loss: 0.000664
Validation Loss: 0.00081616
Epoch [72/300], Train Loss: 0.000634
Validation Loss: 0.00080819
Epoch [73/300], Train Loss: 0.000603
Validation Loss: 0.00081702
Epoch [74/300], Train Loss: 0.000575
Validation Loss: 0.00079611
Epoch [75/300], Train Loss: 0.000575
Validation Loss: 0.00079041
Epoch [76/300], Train Loss: 0.000571
Validation Loss: 0.00078830
Epoch [77/300], Train Loss: 0.000564
Validation Loss: 0.00083400
Epoch [78/300], Train Loss: 0.000570
Validation Loss: 0.00078096
Epoch [79/300], Train Loss: 0.000571
Validation Loss: 0.00078436
Epoch [80/300], Train Loss: 0.000560
Validation Loss: 0.00077177
Epoch [81/300], Train Loss: 0.000551
Validation Loss: 0.00076096
Epoch [82/300], Train Loss: 0.000543
Validation Loss: 0.00075506
Epoch [83/300], Train Loss: 0.000545
Validation Loss: 0.00074903
Epoch [84/300], Train Loss: 0.000547
Validation Loss: 0.00076708
Epoch [85/300], Train Loss: 0.000569
Validation Loss: 0.00074604
Epoch [86/300], Train Loss: 0.000585
Validation Loss: 0.00074914
Epoch [87/300], Train Loss: 0.000534
Validation Loss: 0.00078084
Epoch [88/300], Train Loss: 0.000532
Validation Loss: 0.00072708
Epoch [89/300], Train Loss: 0.000525
Validation Loss: 0.00072814
Epoch [90/300], Train Loss: 0.000526
Validation Loss: 0.00072958
Epoch [91/300], Train Loss: 0.000543
Validation Loss: 0.00072797
Epoch [92/300], Train Loss: 0.000539
Validation Loss: 0.00071078
Epoch [93/300], Train Loss: 0.000572
Validation Loss: 0.00072592
Epoch [94/300], Train Loss: 0.000699
Validation Loss: 0.00081388
Epoch [95/300], Train Loss: 0.000562
Validation Loss: 0.00071958
Epoch [96/300], Train Loss: 0.000519
Validation Loss: 0.00071884
Epoch [97/300], Train Loss: 0.000534
Validation Loss: 0.00069779
Epoch [98/300], Train Loss: 0.000500
Validation Loss: 0.00070170
Epoch [99/300], Train Loss: 0.000555
Validation Loss: 0.00082030
Epoch [100/300], Train Loss: 0.000541
Validation Loss: 0.00067476
Epoch [101/300], Train Loss: 0.000523
Validation Loss: 0.00074825
Epoch [102/300], Train Loss: 0.000483
Validation Loss: 0.00072666
Epoch [103/300], Train Loss: 0.000499
Validation Loss: 0.00072174
Epoch [104/300], Train Loss: 0.000475
Validation Loss: 0.00068316
Epoch [105/300], Train Loss: 0.000473
Validation Loss: 0.00072614
Epoch [106/300], Train Loss: 0.000463
Validation Loss: 0.00069292
Epoch [107/300], Train Loss: 0.000473
Validation Loss: 0.00069963
Epoch [108/300], Train Loss: 0.000481
Validation Loss: 0.00074204
Epoch [109/300], Train Loss: 0.000482
Validation Loss: 0.00068339
Epoch [110/300], Train Loss: 0.000466
Validation Loss: 0.00069733
Early stopping triggered

Evaluating model for: Dryer
Run 3/72 completed in 874.84 seconds with: {'MAE': np.float32(2.6819413), 'MSE': np.float32(671.40234), 'RMSE': np.float32(25.911432), 'SAE': np.float32(0.055451956), 'NDE': np.float32(0.25185886)}

Run 4/72: hidden=128, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Dryer
Dataset length: 9150 windows

Epoch [1/300], Train Loss: 0.010868
Validation Loss: 0.01209405
Epoch [2/300], Train Loss: 0.010530
Validation Loss: 0.01202631
Epoch [3/300], Train Loss: 0.008472
Validation Loss: 0.00345767
Epoch [4/300], Train Loss: 0.003405
Validation Loss: 0.00302264
Epoch [5/300], Train Loss: 0.003150
Validation Loss: 0.00288512
Epoch [6/300], Train Loss: 0.002908
Validation Loss: 0.00275959
Epoch [7/300], Train Loss: 0.002752
Validation Loss: 0.00253768
Epoch [8/300], Train Loss: 0.002520
Validation Loss: 0.00223910
Epoch [9/300], Train Loss: 0.001947
Validation Loss: 0.00174462
Epoch [10/300], Train Loss: 0.001665
Validation Loss: 0.00178220
Epoch [11/300], Train Loss: 0.001471
Validation Loss: 0.00140083
Epoch [12/300], Train Loss: 0.001361
Validation Loss: 0.00133183
Epoch [13/300], Train Loss: 0.001299
Validation Loss: 0.00130319
Epoch [14/300], Train Loss: 0.001435
Validation Loss: 0.00127272
Epoch [15/300], Train Loss: 0.001238
Validation Loss: 0.00154150
Epoch [16/300], Train Loss: 0.001192
Validation Loss: 0.00123672
Epoch [17/300], Train Loss: 0.001153
Validation Loss: 0.00123144
Epoch [18/300], Train Loss: 0.001130
Validation Loss: 0.00127935
Epoch [19/300], Train Loss: 0.001082
Validation Loss: 0.00121623
Epoch [20/300], Train Loss: 0.001072
Validation Loss: 0.00121383
Epoch [21/300], Train Loss: 0.001064
Validation Loss: 0.00115083
Epoch [22/300], Train Loss: 0.001011
Validation Loss: 0.00115085
Epoch [23/300], Train Loss: 0.000975
Validation Loss: 0.00111318
Epoch [24/300], Train Loss: 0.000963
Validation Loss: 0.00109034
Epoch [25/300], Train Loss: 0.000924
Validation Loss: 0.00108997
Epoch [26/300], Train Loss: 0.000916
Validation Loss: 0.00105515
Epoch [27/300], Train Loss: 0.000895
Validation Loss: 0.00105073
Epoch [28/300], Train Loss: 0.000883
Validation Loss: 0.00105337
Epoch [29/300], Train Loss: 0.000866
Validation Loss: 0.00107034
Epoch [30/300], Train Loss: 0.000863
Validation Loss: 0.00102408
Epoch [31/300], Train Loss: 0.000842
Validation Loss: 0.00098696
Epoch [32/300], Train Loss: 0.000812
Validation Loss: 0.00099092
Epoch [33/300], Train Loss: 0.000808
Validation Loss: 0.00094609
Epoch [34/300], Train Loss: 0.000773
Validation Loss: 0.00097064
Epoch [35/300], Train Loss: 0.000790
Validation Loss: 0.00096811
Epoch [36/300], Train Loss: 0.000764
Validation Loss: 0.00098384
Epoch [37/300], Train Loss: 0.000792
Validation Loss: 0.00091108
Epoch [38/300], Train Loss: 0.000740
Validation Loss: 0.00086959
Epoch [39/300], Train Loss: 0.000771
Validation Loss: 0.00092443
Epoch [40/300], Train Loss: 0.000739
Validation Loss: 0.00085954
Epoch [41/300], Train Loss: 0.000734
Validation Loss: 0.00089186
Epoch [42/300], Train Loss: 0.000712
Validation Loss: 0.00092757
Epoch [43/300], Train Loss: 0.000688
Validation Loss: 0.00088624
Epoch [44/300], Train Loss: 0.000681
Validation Loss: 0.00084452
Epoch [45/300], Train Loss: 0.000666
Validation Loss: 0.00081252
Epoch [46/300], Train Loss: 0.000723
Validation Loss: 0.00087297
Epoch [47/300], Train Loss: 0.000675
Validation Loss: 0.00096897
Epoch [48/300], Train Loss: 0.000664
Validation Loss: 0.00076149
Epoch [49/300], Train Loss: 0.000643
Validation Loss: 0.00077302
Epoch [50/300], Train Loss: 0.000619
Validation Loss: 0.00073502
Epoch [51/300], Train Loss: 0.000653
Validation Loss: 0.00082241
Epoch [52/300], Train Loss: 0.000631
Validation Loss: 0.00077531
Epoch [53/300], Train Loss: 0.000616
Validation Loss: 0.00074173
Epoch [54/300], Train Loss: 0.000617
Validation Loss: 0.00073617
Epoch [55/300], Train Loss: 0.000662
Validation Loss: 0.00076595
Epoch [56/300], Train Loss: 0.000620
Validation Loss: 0.00070900
Epoch [57/300], Train Loss: 0.000593
Validation Loss: 0.00073736
Epoch [58/300], Train Loss: 0.000608
Validation Loss: 0.00077847
Epoch [59/300], Train Loss: 0.000594
Validation Loss: 0.00070983
Epoch [60/300], Train Loss: 0.000558
Validation Loss: 0.00067162
Epoch [61/300], Train Loss: 0.000579
Validation Loss: 0.00072207
Epoch [62/300], Train Loss: 0.000556
Validation Loss: 0.00068239
Epoch [63/300], Train Loss: 0.000559
Validation Loss: 0.00066381
Epoch [64/300], Train Loss: 0.000589
Validation Loss: 0.00069447
Epoch [65/300], Train Loss: 0.000673
Validation Loss: 0.00062679
Epoch [66/300], Train Loss: 0.000552
Validation Loss: 0.00062413
Epoch [67/300], Train Loss: 0.000528
Validation Loss: 0.00063368
Epoch [68/300], Train Loss: 0.000515
Validation Loss: 0.00061855
Epoch [69/300], Train Loss: 0.000516
Validation Loss: 0.00062014
Epoch [70/300], Train Loss: 0.000529
Validation Loss: 0.00059128
Epoch [71/300], Train Loss: 0.000562
Validation Loss: 0.00064170
Epoch [72/300], Train Loss: 0.000534
Validation Loss: 0.00057910
Epoch [73/300], Train Loss: 0.000492
Validation Loss: 0.00056414
Epoch [74/300], Train Loss: 0.000482
Validation Loss: 0.00058923
Epoch [75/300], Train Loss: 0.000503
Validation Loss: 0.00058103
Epoch [76/300], Train Loss: 0.000489
Validation Loss: 0.00055606
Epoch [77/300], Train Loss: 0.000473
Validation Loss: 0.00063179
Epoch [78/300], Train Loss: 0.000479
Validation Loss: 0.00053991
Epoch [79/300], Train Loss: 0.000481
Validation Loss: 0.00054144
Epoch [80/300], Train Loss: 0.000461
Validation Loss: 0.00054080
Epoch [81/300], Train Loss: 0.000453
Validation Loss: 0.00052295
Epoch [82/300], Train Loss: 0.000450
Validation Loss: 0.00050509
Epoch [83/300], Train Loss: 0.000449
Validation Loss: 0.00049282
Epoch [84/300], Train Loss: 0.000450
Validation Loss: 0.00050202
Epoch [85/300], Train Loss: 0.000459
Validation Loss: 0.00052647
Epoch [86/300], Train Loss: 0.000478
Validation Loss: 0.00051911
Epoch [87/300], Train Loss: 0.000505
Validation Loss: 0.00073429
Epoch [88/300], Train Loss: 0.000631
Validation Loss: 0.00048293
Epoch [89/300], Train Loss: 0.000442
Validation Loss: 0.00048002
Epoch [90/300], Train Loss: 0.000427
Validation Loss: 0.00048193
Epoch [91/300], Train Loss: 0.000419
Validation Loss: 0.00048460
Epoch [92/300], Train Loss: 0.000424
Validation Loss: 0.00046406
Epoch [93/300], Train Loss: 0.000423
Validation Loss: 0.00048064
Epoch [94/300], Train Loss: 0.000417
Validation Loss: 0.00048276
Epoch [95/300], Train Loss: 0.000408
Validation Loss: 0.00048366
Epoch [96/300], Train Loss: 0.000395
Validation Loss: 0.00048146
Epoch [97/300], Train Loss: 0.000399
Validation Loss: 0.00048689
Epoch [98/300], Train Loss: 0.000396
Validation Loss: 0.00047637
Epoch [99/300], Train Loss: 0.000408
Validation Loss: 0.00048347
Epoch [100/300], Train Loss: 0.000386
Validation Loss: 0.00046045
Epoch [101/300], Train Loss: 0.000393
Validation Loss: 0.00056125
Epoch [102/300], Train Loss: 0.000393
Validation Loss: 0.00050121
Epoch [103/300], Train Loss: 0.000387
Validation Loss: 0.00046624
Epoch [104/300], Train Loss: 0.000370
Validation Loss: 0.00046795
Epoch [105/300], Train Loss: 0.000373
Validation Loss: 0.00048726
Epoch [106/300], Train Loss: 0.000396
Validation Loss: 0.00045847
Epoch [107/300], Train Loss: 0.000379
Validation Loss: 0.00046788
Epoch [108/300], Train Loss: 0.000362
Validation Loss: 0.00046093
Epoch [109/300], Train Loss: 0.000368
Validation Loss: 0.00044217
Epoch [110/300], Train Loss: 0.000363
Validation Loss: 0.00046353
Epoch [111/300], Train Loss: 0.000358
Validation Loss: 0.00044777
Epoch [112/300], Train Loss: 0.000362
Validation Loss: 0.00044695
Epoch [113/300], Train Loss: 0.000374
Validation Loss: 0.00049105
Epoch [114/300], Train Loss: 0.000357
Validation Loss: 0.00046228
Epoch [115/300], Train Loss: 0.000352
Validation Loss: 0.00044613
Epoch [116/300], Train Loss: 0.000349
Validation Loss: 0.00048072
Epoch [117/300], Train Loss: 0.000344
Validation Loss: 0.00044995
Epoch [118/300], Train Loss: 0.000349
Validation Loss: 0.00044465
Epoch [119/300], Train Loss: 0.000341
Validation Loss: 0.00047695
Early stopping triggered

Evaluating model for: Dryer
Run 4/72 completed in 957.13 seconds with: {'MAE': np.float32(2.6163595), 'MSE': np.float32(380.70245), 'RMSE': np.float32(19.511599), 'SAE': np.float32(0.01864536), 'NDE': np.float32(0.1896529)}

Run 5/72: hidden=128, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Dryer
Dataset length: 4586 windows

Epoch [1/300], Train Loss: 0.010889
Validation Loss: 0.01250592
Epoch [2/300], Train Loss: 0.010726
Validation Loss: 0.01237543
Epoch [3/300], Train Loss: 0.010582
Validation Loss: 0.01203408
Epoch [4/300], Train Loss: 0.010079
Validation Loss: 0.01066382
Epoch [5/300], Train Loss: 0.006647
Validation Loss: 0.00408370
Epoch [6/300], Train Loss: 0.003796
Validation Loss: 0.00303551
Epoch [7/300], Train Loss: 0.003399
Validation Loss: 0.00278866
Epoch [8/300], Train Loss: 0.003234
Validation Loss: 0.00276393
Epoch [9/300], Train Loss: 0.003116
Validation Loss: 0.00279576
Epoch [10/300], Train Loss: 0.002957
Validation Loss: 0.00251506
Epoch [11/300], Train Loss: 0.002801
Validation Loss: 0.00230827
Epoch [12/300], Train Loss: 0.002694
Validation Loss: 0.00227435
Epoch [13/300], Train Loss: 0.002523
Validation Loss: 0.00210938
Epoch [14/300], Train Loss: 0.002339
Validation Loss: 0.00209511
Epoch [15/300], Train Loss: 0.002298
Validation Loss: 0.00183904
Epoch [16/300], Train Loss: 0.002172
Validation Loss: 0.00177500
Epoch [17/300], Train Loss: 0.002014
Validation Loss: 0.00176818
Epoch [18/300], Train Loss: 0.001979
Validation Loss: 0.00174419
Epoch [19/300], Train Loss: 0.002021
Validation Loss: 0.00165329
Epoch [20/300], Train Loss: 0.001928
Validation Loss: 0.00165712
Epoch [21/300], Train Loss: 0.001810
Validation Loss: 0.00155331
Epoch [22/300], Train Loss: 0.001744
Validation Loss: 0.00146272
Epoch [23/300], Train Loss: 0.001775
Validation Loss: 0.00148713
Epoch [24/300], Train Loss: 0.001669
Validation Loss: 0.00142792
Epoch [25/300], Train Loss: 0.001628
Validation Loss: 0.00197778
Epoch [26/300], Train Loss: 0.001865
Validation Loss: 0.00153885
Epoch [27/300], Train Loss: 0.001690
Validation Loss: 0.00146757
Epoch [28/300], Train Loss: 0.001586
Validation Loss: 0.00138438
Epoch [29/300], Train Loss: 0.001520
Validation Loss: 0.00134173
Epoch [30/300], Train Loss: 0.001503
Validation Loss: 0.00133192
Epoch [31/300], Train Loss: 0.001502
Validation Loss: 0.00131765
Epoch [32/300], Train Loss: 0.001493
Validation Loss: 0.00140074
Epoch [33/300], Train Loss: 0.001545
Validation Loss: 0.00132843
Epoch [34/300], Train Loss: 0.001489
Validation Loss: 0.00125317
Epoch [35/300], Train Loss: 0.001429
Validation Loss: 0.00123744
Epoch [36/300], Train Loss: 0.001421
Validation Loss: 0.00124099
Epoch [37/300], Train Loss: 0.001423
Validation Loss: 0.00125166
Epoch [38/300], Train Loss: 0.001419
Validation Loss: 0.00122350
Epoch [39/300], Train Loss: 0.001370
Validation Loss: 0.00119880
Epoch [40/300], Train Loss: 0.001376
Validation Loss: 0.00119293
Epoch [41/300], Train Loss: 0.001381
Validation Loss: 0.00116580
Epoch [42/300], Train Loss: 0.001338
Validation Loss: 0.00118257
Epoch [43/300], Train Loss: 0.001348
Validation Loss: 0.00116518
Epoch [44/300], Train Loss: 0.001366
Validation Loss: 0.00115132
Epoch [45/300], Train Loss: 0.001310
Validation Loss: 0.00114680
Epoch [46/300], Train Loss: 0.001336
Validation Loss: 0.00111457
Epoch [47/300], Train Loss: 0.001372
Validation Loss: 0.00110506
Epoch [48/300], Train Loss: 0.001317
Validation Loss: 0.00114446
Epoch [49/300], Train Loss: 0.001323
Validation Loss: 0.00109479
Epoch [50/300], Train Loss: 0.001311
Validation Loss: 0.00111733
Epoch [51/300], Train Loss: 0.001485
Validation Loss: 0.00169963
Epoch [52/300], Train Loss: 0.001679
Validation Loss: 0.00127072
Epoch [53/300], Train Loss: 0.001439
Validation Loss: 0.00118828
Epoch [54/300], Train Loss: 0.001341
Validation Loss: 0.00119527
Epoch [55/300], Train Loss: 0.001283
Validation Loss: 0.00119986
Epoch [56/300], Train Loss: 0.001285
Validation Loss: 0.00117435
Epoch [57/300], Train Loss: 0.001260
Validation Loss: 0.00117827
Epoch [58/300], Train Loss: 0.001251
Validation Loss: 0.00115926
Epoch [59/300], Train Loss: 0.001242
Validation Loss: 0.00115978
Early stopping triggered

Evaluating model for: Dryer
Run 5/72 completed in 221.78 seconds with: {'MAE': np.float32(6.1899176), 'MSE': np.float32(1798.4581), 'RMSE': np.float32(42.408234), 'SAE': np.float32(0.10056931), 'NDE': np.float32(0.4522151)}

Run 6/72: hidden=128, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Dryer
Dataset length: 4586 windows

Epoch [1/300], Train Loss: 0.012766
Validation Loss: 0.01289594
Epoch [2/300], Train Loss: 0.010904
Validation Loss: 0.01257369
Epoch [3/300], Train Loss: 0.010866
Validation Loss: 0.01250888
Epoch [4/300], Train Loss: 0.010894
Validation Loss: 0.01230468
Epoch [5/300], Train Loss: 0.010321
Validation Loss: 0.01119317
Epoch [6/300], Train Loss: 0.006245
Validation Loss: 0.00449492
Epoch [7/300], Train Loss: 0.004009
Validation Loss: 0.00347972
Epoch [8/300], Train Loss: 0.003522
Validation Loss: 0.00318919
Epoch [9/300], Train Loss: 0.003406
Validation Loss: 0.00287131
Epoch [10/300], Train Loss: 0.003228
Validation Loss: 0.00283358
Epoch [11/300], Train Loss: 0.003094
Validation Loss: 0.00259554
Epoch [12/300], Train Loss: 0.003040
Validation Loss: 0.00254216
Epoch [13/300], Train Loss: 0.002885
Validation Loss: 0.00236527
Epoch [14/300], Train Loss: 0.002601
Validation Loss: 0.00244819
Epoch [15/300], Train Loss: 0.002413
Validation Loss: 0.00346951
Epoch [16/300], Train Loss: 0.002546
Validation Loss: 0.00204564
Epoch [17/300], Train Loss: 0.002248
Validation Loss: 0.00191910
Epoch [18/300], Train Loss: 0.002125
Validation Loss: 0.00175448
Epoch [19/300], Train Loss: 0.002029
Validation Loss: 0.00162680
Epoch [20/300], Train Loss: 0.001952
Validation Loss: 0.00163254
Epoch [21/300], Train Loss: 0.001864
Validation Loss: 0.00153426
Epoch [22/300], Train Loss: 0.001858
Validation Loss: 0.00147256
Epoch [23/300], Train Loss: 0.001921
Validation Loss: 0.00145189
Epoch [24/300], Train Loss: 0.001750
Validation Loss: 0.00140779
Epoch [25/300], Train Loss: 0.001702
Validation Loss: 0.00137349
Epoch [26/300], Train Loss: 0.001708
Validation Loss: 0.00133199
Epoch [27/300], Train Loss: 0.001632
Validation Loss: 0.00129937
Epoch [28/300], Train Loss: 0.001638
Validation Loss: 0.00131812
Epoch [29/300], Train Loss: 0.001562
Validation Loss: 0.00136110
Epoch [30/300], Train Loss: 0.001566
Validation Loss: 0.00131129
Epoch [31/300], Train Loss: 0.001635
Validation Loss: 0.00130155
Epoch [32/300], Train Loss: 0.001560
Validation Loss: 0.00134476
Epoch [33/300], Train Loss: 0.001574
Validation Loss: 0.00128514
Epoch [34/300], Train Loss: 0.001493
Validation Loss: 0.00130088
Epoch [35/300], Train Loss: 0.001461
Validation Loss: 0.00121926
Epoch [36/300], Train Loss: 0.001454
Validation Loss: 0.00122814
Epoch [37/300], Train Loss: 0.001440
Validation Loss: 0.00117925
Epoch [38/300], Train Loss: 0.001402
Validation Loss: 0.00116889
Epoch [39/300], Train Loss: 0.001371
Validation Loss: 0.00114759
Epoch [40/300], Train Loss: 0.001356
Validation Loss: 0.00113768
Epoch [41/300], Train Loss: 0.001406
Validation Loss: 0.00113691
Epoch [42/300], Train Loss: 0.001364
Validation Loss: 0.00118220
Epoch [43/300], Train Loss: 0.001368
Validation Loss: 0.00110222
Epoch [44/300], Train Loss: 0.001350
Validation Loss: 0.00111337
Epoch [45/300], Train Loss: 0.001345
Validation Loss: 0.00109688
Epoch [46/300], Train Loss: 0.001358
Validation Loss: 0.00109576
Epoch [47/300], Train Loss: 0.001331
Validation Loss: 0.00107632
Epoch [48/300], Train Loss: 0.001294
Validation Loss: 0.00106384
Epoch [49/300], Train Loss: 0.001278
Validation Loss: 0.00105499
Epoch [50/300], Train Loss: 0.001287
Validation Loss: 0.00104441
Epoch [51/300], Train Loss: 0.001243
Validation Loss: 0.00103415
Epoch [52/300], Train Loss: 0.001217
Validation Loss: 0.00105638
Epoch [53/300], Train Loss: 0.001227
Validation Loss: 0.00104093
Epoch [54/300], Train Loss: 0.001202
Validation Loss: 0.00103151
Epoch [55/300], Train Loss: 0.001177
Validation Loss: 0.00100903
Epoch [56/300], Train Loss: 0.001163
Validation Loss: 0.00099094
Epoch [57/300], Train Loss: 0.001132
Validation Loss: 0.00104276
Epoch [58/300], Train Loss: 0.001129
Validation Loss: 0.00104042
Epoch [59/300], Train Loss: 0.001128
Validation Loss: 0.00103893
Epoch [60/300], Train Loss: 0.001030
Validation Loss: 0.00097849
Epoch [61/300], Train Loss: 0.001056
Validation Loss: 0.00098011
Epoch [62/300], Train Loss: 0.001065
Validation Loss: 0.00100473
Epoch [63/300], Train Loss: 0.001108
Validation Loss: 0.00099693
Epoch [64/300], Train Loss: 0.001033
Validation Loss: 0.00102847
Epoch [65/300], Train Loss: 0.001063
Validation Loss: 0.00100640
Epoch [66/300], Train Loss: 0.001089
Validation Loss: 0.00097670
Epoch [67/300], Train Loss: 0.001067
Validation Loss: 0.00097840
Epoch [68/300], Train Loss: 0.001035
Validation Loss: 0.00103953
Epoch [69/300], Train Loss: 0.000996
Validation Loss: 0.00104699
Epoch [70/300], Train Loss: 0.001060
Validation Loss: 0.00100119
Epoch [71/300], Train Loss: 0.001046
Validation Loss: 0.00097075
Epoch [72/300], Train Loss: 0.001014
Validation Loss: 0.00099642
Epoch [73/300], Train Loss: 0.000968
Validation Loss: 0.00100562
Epoch [74/300], Train Loss: 0.000963
Validation Loss: 0.00098743
Epoch [75/300], Train Loss: 0.000959
Validation Loss: 0.00098380
Epoch [76/300], Train Loss: 0.000944
Validation Loss: 0.00100061
Epoch [77/300], Train Loss: 0.000963
Validation Loss: 0.00099825
Epoch [78/300], Train Loss: 0.000953
Validation Loss: 0.00098826
Epoch [79/300], Train Loss: 0.000956
Validation Loss: 0.00098978
Epoch [80/300], Train Loss: 0.000940
Validation Loss: 0.00096583
Epoch [81/300], Train Loss: 0.000936
Validation Loss: 0.00098556
Epoch [82/300], Train Loss: 0.000948
Validation Loss: 0.00095590
Epoch [83/300], Train Loss: 0.000916
Validation Loss: 0.00094209
Epoch [84/300], Train Loss: 0.000898
Validation Loss: 0.00093666
Epoch [85/300], Train Loss: 0.000920
Validation Loss: 0.00092953
Epoch [86/300], Train Loss: 0.000899
Validation Loss: 0.00093505
Epoch [87/300], Train Loss: 0.000891
Validation Loss: 0.00091619
Epoch [88/300], Train Loss: 0.000887
Validation Loss: 0.00107596
Epoch [89/300], Train Loss: 0.001005
Validation Loss: 0.00085425
Epoch [90/300], Train Loss: 0.000917
Validation Loss: 0.00086251
Epoch [91/300], Train Loss: 0.000886
Validation Loss: 0.00092080
Epoch [92/300], Train Loss: 0.000881
Validation Loss: 0.00091550
Epoch [93/300], Train Loss: 0.000888
Validation Loss: 0.00099016
Epoch [94/300], Train Loss: 0.000939
Validation Loss: 0.00094527
Epoch [95/300], Train Loss: 0.000898
Validation Loss: 0.00092576
Epoch [96/300], Train Loss: 0.000900
Validation Loss: 0.00089187
Epoch [97/300], Train Loss: 0.000864
Validation Loss: 0.00087800
Epoch [98/300], Train Loss: 0.000843
Validation Loss: 0.00086007
Epoch [99/300], Train Loss: 0.000848
Validation Loss: 0.00087837
Early stopping triggered

Evaluating model for: Dryer
Run 6/72 completed in 384.23 seconds with: {'MAE': np.float32(4.514743), 'MSE': np.float32(1416.6053), 'RMSE': np.float32(37.637817), 'SAE': np.float32(0.003949473), 'NDE': np.float32(0.4013457)}

Run 7/72: hidden=128, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Dryer
Dataset length: 4586 windows

Epoch [1/300], Train Loss: 0.010931
Validation Loss: 0.01255744
Epoch [2/300], Train Loss: 0.010814
Validation Loss: 0.01254160
Epoch [3/300], Train Loss: 0.010807
Validation Loss: 0.01244092
Epoch [4/300], Train Loss: 0.010578
Validation Loss: 0.01125866
Epoch [5/300], Train Loss: 0.006657
Validation Loss: 0.00411805
Epoch [6/300], Train Loss: 0.003827
Validation Loss: 0.00296829
Epoch [7/300], Train Loss: 0.003566
Validation Loss: 0.00277597
Epoch [8/300], Train Loss: 0.003318
Validation Loss: 0.00280983
Epoch [9/300], Train Loss: 0.003190
Validation Loss: 0.00244214
Epoch [10/300], Train Loss: 0.002988
Validation Loss: 0.00244462
Epoch [11/300], Train Loss: 0.002793
Validation Loss: 0.00262710
Epoch [12/300], Train Loss: 0.002586
Validation Loss: 0.00234637
Epoch [13/300], Train Loss: 0.002367
Validation Loss: 0.00229681
Epoch [14/300], Train Loss: 0.002306
Validation Loss: 0.00254204
Epoch [15/300], Train Loss: 0.002488
Validation Loss: 0.00247458
Epoch [16/300], Train Loss: 0.002262
Validation Loss: 0.00219894
Epoch [17/300], Train Loss: 0.002172
Validation Loss: 0.00209750
Epoch [18/300], Train Loss: 0.002194
Validation Loss: 0.00212181
Epoch [19/300], Train Loss: 0.002127
Validation Loss: 0.00202532
Epoch [20/300], Train Loss: 0.002037
Validation Loss: 0.00201215
Epoch [21/300], Train Loss: 0.002113
Validation Loss: 0.00180937
Epoch [22/300], Train Loss: 0.002078
Validation Loss: 0.00192880
Epoch [23/300], Train Loss: 0.002117
Validation Loss: 0.00180552
Epoch [24/300], Train Loss: 0.002066
Validation Loss: 0.00182298
Epoch [25/300], Train Loss: 0.001977
Validation Loss: 0.00205914
Epoch [26/300], Train Loss: 0.001886
Validation Loss: 0.00202603
Epoch [27/300], Train Loss: 0.001808
Validation Loss: 0.00198525
Epoch [28/300], Train Loss: 0.001749
Validation Loss: 0.00186936
Epoch [29/300], Train Loss: 0.001645
Validation Loss: 0.00179564
Epoch [30/300], Train Loss: 0.001613
Validation Loss: 0.00185045
Epoch [31/300], Train Loss: 0.001579
Validation Loss: 0.00196330
Epoch [32/300], Train Loss: 0.001495
Validation Loss: 0.00187093
Epoch [33/300], Train Loss: 0.001505
Validation Loss: 0.00180795
Epoch [34/300], Train Loss: 0.001453
Validation Loss: 0.00171641
Epoch [35/300], Train Loss: 0.001399
Validation Loss: 0.00169904
Epoch [36/300], Train Loss: 0.001359
Validation Loss: 0.00174934
Epoch [37/300], Train Loss: 0.001351
Validation Loss: 0.00170196
Epoch [38/300], Train Loss: 0.001373
Validation Loss: 0.00171053
Epoch [39/300], Train Loss: 0.001297
Validation Loss: 0.00170979
Epoch [40/300], Train Loss: 0.001299
Validation Loss: 0.00170820
Epoch [41/300], Train Loss: 0.001321
Validation Loss: 0.00165571
Epoch [42/300], Train Loss: 0.001277
Validation Loss: 0.00152777
Epoch [43/300], Train Loss: 0.001296
Validation Loss: 0.00147985
Epoch [44/300], Train Loss: 0.001277
Validation Loss: 0.00150801
Epoch [45/300], Train Loss: 0.001226
Validation Loss: 0.00168718
Epoch [46/300], Train Loss: 0.001279
Validation Loss: 0.00162220
Epoch [47/300], Train Loss: 0.001347
Validation Loss: 0.00170691
Epoch [48/300], Train Loss: 0.001295
Validation Loss: 0.00164115
Epoch [49/300], Train Loss: 0.001232
Validation Loss: 0.00163041
Epoch [50/300], Train Loss: 0.001212
Validation Loss: 0.00143327
Epoch [51/300], Train Loss: 0.001221
Validation Loss: 0.00160776
Epoch [52/300], Train Loss: 0.001195
Validation Loss: 0.00161666
Epoch [53/300], Train Loss: 0.001174
Validation Loss: 0.00157131
Epoch [54/300], Train Loss: 0.001163
Validation Loss: 0.00158279
Epoch [55/300], Train Loss: 0.001125
Validation Loss: 0.00154892
Epoch [56/300], Train Loss: 0.001166
Validation Loss: 0.00152439
Epoch [57/300], Train Loss: 0.001105
Validation Loss: 0.00161234
Epoch [58/300], Train Loss: 0.001131
Validation Loss: 0.00155481
Epoch [59/300], Train Loss: 0.001122
Validation Loss: 0.00152863
Epoch [60/300], Train Loss: 0.001106
Validation Loss: 0.00149956
Early stopping triggered

Evaluating model for: Dryer
Run 7/72 completed in 229.26 seconds with: {'MAE': np.float32(6.4679675), 'MSE': np.float32(1825.195), 'RMSE': np.float32(42.7223), 'SAE': np.float32(0.20535482), 'NDE': np.float32(0.45556447)}

Run 8/72: hidden=128, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Dryer
Dataset length: 4586 windows

Epoch [1/300], Train Loss: 0.011014
Validation Loss: 0.01257648
Epoch [2/300], Train Loss: 0.010844
Validation Loss: 0.01258212
Epoch [3/300], Train Loss: 0.010868
Validation Loss: 0.01256235
Epoch [4/300], Train Loss: 0.010958
Validation Loss: 0.01243556
Epoch [5/300], Train Loss: 0.009737
Validation Loss: 0.00645943
Epoch [6/300], Train Loss: 0.004442
Validation Loss: 0.00326515
Epoch [7/300], Train Loss: 0.003411
Validation Loss: 0.00285460
Epoch [8/300], Train Loss: 0.003159
Validation Loss: 0.00291285
Epoch [9/300], Train Loss: 0.003099
Validation Loss: 0.00258062
Epoch [10/300], Train Loss: 0.002925
Validation Loss: 0.00255796
Epoch [11/300], Train Loss: 0.002767
Validation Loss: 0.00246667
Epoch [12/300], Train Loss: 0.002714
Validation Loss: 0.00250055
Epoch [13/300], Train Loss: 0.002520
Validation Loss: 0.00249120
Epoch [14/300], Train Loss: 0.002387
Validation Loss: 0.00280851
Epoch [15/300], Train Loss: 0.002430
Validation Loss: 0.00257315
Epoch [16/300], Train Loss: 0.002268
Validation Loss: 0.00248844
Epoch [17/300], Train Loss: 0.002157
Validation Loss: 0.00241119
Epoch [18/300], Train Loss: 0.002096
Validation Loss: 0.00207384
Epoch [19/300], Train Loss: 0.001970
Validation Loss: 0.00191749
Epoch [20/300], Train Loss: 0.002093
Validation Loss: 0.00201510
Epoch [21/300], Train Loss: 0.001850
Validation Loss: 0.00185531
Epoch [22/300], Train Loss: 0.001803
Validation Loss: 0.00184885
Epoch [23/300], Train Loss: 0.001803
Validation Loss: 0.00177903
Epoch [24/300], Train Loss: 0.001756
Validation Loss: 0.00177278
Epoch [25/300], Train Loss: 0.001702
Validation Loss: 0.00173686
Epoch [26/300], Train Loss: 0.001609
Validation Loss: 0.00170194
Epoch [27/300], Train Loss: 0.001557
Validation Loss: 0.00173272
Epoch [28/300], Train Loss: 0.001531
Validation Loss: 0.00163481
Epoch [29/300], Train Loss: 0.001517
Validation Loss: 0.00164550
Epoch [30/300], Train Loss: 0.001500
Validation Loss: 0.00159328
Epoch [31/300], Train Loss: 0.001426
Validation Loss: 0.00158322
Epoch [32/300], Train Loss: 0.001405
Validation Loss: 0.00160380
Epoch [33/300], Train Loss: 0.001397
Validation Loss: 0.00155118
Epoch [34/300], Train Loss: 0.001350
Validation Loss: 0.00151175
Epoch [35/300], Train Loss: 0.001313
Validation Loss: 0.00155201
Epoch [36/300], Train Loss: 0.001308
Validation Loss: 0.00147852
Epoch [37/300], Train Loss: 0.001281
Validation Loss: 0.00147566
Epoch [38/300], Train Loss: 0.001339
Validation Loss: 0.00147573
Epoch [39/300], Train Loss: 0.001251
Validation Loss: 0.00145452
Epoch [40/300], Train Loss: 0.001245
Validation Loss: 0.00144291
Epoch [41/300], Train Loss: 0.001278
Validation Loss: 0.00145855
Epoch [42/300], Train Loss: 0.001254
Validation Loss: 0.00146074
Epoch [43/300], Train Loss: 0.001261
Validation Loss: 0.00141598
Epoch [44/300], Train Loss: 0.001245
Validation Loss: 0.00141351
Epoch [45/300], Train Loss: 0.001211
Validation Loss: 0.00142703
Epoch [46/300], Train Loss: 0.001262
Validation Loss: 0.00140556
Epoch [47/300], Train Loss: 0.001270
Validation Loss: 0.00142903
Epoch [48/300], Train Loss: 0.001211
Validation Loss: 0.00140160
Epoch [49/300], Train Loss: 0.001189
Validation Loss: 0.00138250
Epoch [50/300], Train Loss: 0.001204
Validation Loss: 0.00137941
Epoch [51/300], Train Loss: 0.001219
Validation Loss: 0.00137633
Epoch [52/300], Train Loss: 0.001176
Validation Loss: 0.00138465
Epoch [53/300], Train Loss: 0.001204
Validation Loss: 0.00137348
Epoch [54/300], Train Loss: 0.001173
Validation Loss: 0.00135245
Epoch [55/300], Train Loss: 0.001132
Validation Loss: 0.00134991
Epoch [56/300], Train Loss: 0.001173
Validation Loss: 0.00134687
Epoch [57/300], Train Loss: 0.001125
Validation Loss: 0.00138475
Epoch [58/300], Train Loss: 0.001152
Validation Loss: 0.00135514
Epoch [59/300], Train Loss: 0.001130
Validation Loss: 0.00133244
Epoch [60/300], Train Loss: 0.001124
Validation Loss: 0.00133497
Epoch [61/300], Train Loss: 0.001155
Validation Loss: 0.00134078
Epoch [62/300], Train Loss: 0.001142
Validation Loss: 0.00132400
Epoch [63/300], Train Loss: 0.001096
Validation Loss: 0.00131758
Epoch [64/300], Train Loss: 0.001090
Validation Loss: 0.00132758
Epoch [65/300], Train Loss: 0.001099
Validation Loss: 0.00130461
Epoch [66/300], Train Loss: 0.001097
Validation Loss: 0.00132457
Epoch [67/300], Train Loss: 0.001134
Validation Loss: 0.00129800
Epoch [68/300], Train Loss: 0.001098
Validation Loss: 0.00131744
Epoch [69/300], Train Loss: 0.001095
Validation Loss: 0.00129145
Epoch [70/300], Train Loss: 0.001095
Validation Loss: 0.00128817
Epoch [71/300], Train Loss: 0.001093
Validation Loss: 0.00127904
Epoch [72/300], Train Loss: 0.001092
Validation Loss: 0.00128051
Epoch [73/300], Train Loss: 0.001065
Validation Loss: 0.00128986
Epoch [74/300], Train Loss: 0.001061
Validation Loss: 0.00127677
Epoch [75/300], Train Loss: 0.001047
Validation Loss: 0.00127578
Epoch [76/300], Train Loss: 0.001056
Validation Loss: 0.00127067
Epoch [77/300], Train Loss: 0.001073
Validation Loss: 0.00129578
Epoch [78/300], Train Loss: 0.001088
Validation Loss: 0.00129668
Epoch [79/300], Train Loss: 0.001093
Validation Loss: 0.00125831
Epoch [80/300], Train Loss: 0.001028
Validation Loss: 0.00126564
Epoch [81/300], Train Loss: 0.001042
Validation Loss: 0.00125810
Epoch [82/300], Train Loss: 0.001031
Validation Loss: 0.00125047
Epoch [83/300], Train Loss: 0.001067
Validation Loss: 0.00124617
Epoch [84/300], Train Loss: 0.001030
Validation Loss: 0.00124280
Epoch [85/300], Train Loss: 0.001035
Validation Loss: 0.00123834
Epoch [86/300], Train Loss: 0.001017
Validation Loss: 0.00124421
Epoch [87/300], Train Loss: 0.001029
Validation Loss: 0.00124295
Epoch [88/300], Train Loss: 0.001007
Validation Loss: 0.00123524
Epoch [89/300], Train Loss: 0.001013
Validation Loss: 0.00123030
Epoch [90/300], Train Loss: 0.001018
Validation Loss: 0.00123336
Epoch [91/300], Train Loss: 0.000998
Validation Loss: 0.00122477
Epoch [92/300], Train Loss: 0.001026
Validation Loss: 0.00122184
Epoch [93/300], Train Loss: 0.001014
Validation Loss: 0.00122796
Epoch [94/300], Train Loss: 0.000989
Validation Loss: 0.00123588
Epoch [95/300], Train Loss: 0.001009
Validation Loss: 0.00122426
Epoch [96/300], Train Loss: 0.001004
Validation Loss: 0.00121077
Epoch [97/300], Train Loss: 0.000999
Validation Loss: 0.00120888
Epoch [98/300], Train Loss: 0.001018
Validation Loss: 0.00121191
Epoch [99/300], Train Loss: 0.000976
Validation Loss: 0.00120623
Epoch [100/300], Train Loss: 0.000955
Validation Loss: 0.00120696
Epoch [101/300], Train Loss: 0.000958
Validation Loss: 0.00120230
Epoch [102/300], Train Loss: 0.000989
Validation Loss: 0.00123974
Epoch [103/300], Train Loss: 0.000968
Validation Loss: 0.00121230
Epoch [104/300], Train Loss: 0.000951
Validation Loss: 0.00119354
Epoch [105/300], Train Loss: 0.000959
Validation Loss: 0.00119170
Epoch [106/300], Train Loss: 0.000959
Validation Loss: 0.00119085
Epoch [107/300], Train Loss: 0.000930
Validation Loss: 0.00118959
Epoch [108/300], Train Loss: 0.000924
Validation Loss: 0.00119907
Epoch [109/300], Train Loss: 0.000971
Validation Loss: 0.00119544
Epoch [110/300], Train Loss: 0.000956
Validation Loss: 0.00119151
Epoch [111/300], Train Loss: 0.000922
Validation Loss: 0.00118784
Epoch [112/300], Train Loss: 0.000920
Validation Loss: 0.00118087
Epoch [113/300], Train Loss: 0.000933
Validation Loss: 0.00118046
Epoch [114/300], Train Loss: 0.000919
Validation Loss: 0.00117704
Epoch [115/300], Train Loss: 0.000947
Validation Loss: 0.00118061
Epoch [116/300], Train Loss: 0.000900
Validation Loss: 0.00117502
Epoch [117/300], Train Loss: 0.000895
Validation Loss: 0.00117118
Epoch [118/300], Train Loss: 0.000890
Validation Loss: 0.00117690
Epoch [119/300], Train Loss: 0.000902
Validation Loss: 0.00116723
Epoch [120/300], Train Loss: 0.000884
Validation Loss: 0.00116875
Epoch [121/300], Train Loss: 0.000891
Validation Loss: 0.00116604
Epoch [122/300], Train Loss: 0.000893
Validation Loss: 0.00116999
Epoch [123/300], Train Loss: 0.000887
Validation Loss: 0.00116211
Epoch [124/300], Train Loss: 0.000906
Validation Loss: 0.00117902
Epoch [125/300], Train Loss: 0.000940
Validation Loss: 0.00116040
Epoch [126/300], Train Loss: 0.000922
Validation Loss: 0.00116045
Epoch [127/300], Train Loss: 0.000904
Validation Loss: 0.00115703
Epoch [128/300], Train Loss: 0.000915
Validation Loss: 0.00116009
Epoch [129/300], Train Loss: 0.000890
Validation Loss: 0.00116145
Epoch [130/300], Train Loss: 0.000932
Validation Loss: 0.00115117
Epoch [131/300], Train Loss: 0.000898
Validation Loss: 0.00115326
Epoch [132/300], Train Loss: 0.000867
Validation Loss: 0.00115936
Epoch [133/300], Train Loss: 0.000908
Validation Loss: 0.00115696
Epoch [134/300], Train Loss: 0.000882
Validation Loss: 0.00114916
Epoch [135/300], Train Loss: 0.000884
Validation Loss: 0.00114794
Epoch [136/300], Train Loss: 0.000850
Validation Loss: 0.00114335
Epoch [137/300], Train Loss: 0.000850
Validation Loss: 0.00114203
Epoch [138/300], Train Loss: 0.000851
Validation Loss: 0.00113916
Epoch [139/300], Train Loss: 0.000853
Validation Loss: 0.00113895
Epoch [140/300], Train Loss: 0.000888
Validation Loss: 0.00114069
Epoch [141/300], Train Loss: 0.000852
Validation Loss: 0.00113589
Epoch [142/300], Train Loss: 0.000850
Validation Loss: 0.00113500
Epoch [143/300], Train Loss: 0.000845
Validation Loss: 0.00113699
Epoch [144/300], Train Loss: 0.000860
Validation Loss: 0.00113345
Epoch [145/300], Train Loss: 0.000875
Validation Loss: 0.00113602
Epoch [146/300], Train Loss: 0.000853
Validation Loss: 0.00113037
Epoch [147/300], Train Loss: 0.000860
Validation Loss: 0.00113574
Epoch [148/300], Train Loss: 0.000849
Validation Loss: 0.00114365
Epoch [149/300], Train Loss: 0.000843
Validation Loss: 0.00113527
Epoch [150/300], Train Loss: 0.000834
Validation Loss: 0.00113071
Epoch [151/300], Train Loss: 0.000843
Validation Loss: 0.00112729
Epoch [152/300], Train Loss: 0.000828
Validation Loss: 0.00112647
Epoch [153/300], Train Loss: 0.000840
Validation Loss: 0.00112595
Epoch [154/300], Train Loss: 0.000843
Validation Loss: 0.00113984
Epoch [155/300], Train Loss: 0.000828
Validation Loss: 0.00112005
Epoch [156/300], Train Loss: 0.000834
Validation Loss: 0.00112376
Epoch [157/300], Train Loss: 0.000841
Validation Loss: 0.00112277
Epoch [158/300], Train Loss: 0.000848
Validation Loss: 0.00112025
Epoch [159/300], Train Loss: 0.000833
Validation Loss: 0.00112368
Epoch [160/300], Train Loss: 0.000821
Validation Loss: 0.00111531
Epoch [161/300], Train Loss: 0.000838
Validation Loss: 0.00111586
Epoch [162/300], Train Loss: 0.000824
Validation Loss: 0.00111648
Epoch [163/300], Train Loss: 0.000814
Validation Loss: 0.00111535
Epoch [164/300], Train Loss: 0.000818
Validation Loss: 0.00111223
Epoch [165/300], Train Loss: 0.000819
Validation Loss: 0.00111198
Epoch [166/300], Train Loss: 0.000809
Validation Loss: 0.00111094
Epoch [167/300], Train Loss: 0.000850
Validation Loss: 0.00111042
Epoch [168/300], Train Loss: 0.000809
Validation Loss: 0.00110990
Epoch [169/300], Train Loss: 0.000853
Validation Loss: 0.00111046
Epoch [170/300], Train Loss: 0.000817
Validation Loss: 0.00111623
Epoch [171/300], Train Loss: 0.000814
Validation Loss: 0.00110637
Epoch [172/300], Train Loss: 0.000815
Validation Loss: 0.00111483
Epoch [173/300], Train Loss: 0.000822
Validation Loss: 0.00110581
Epoch [174/300], Train Loss: 0.000805
Validation Loss: 0.00110436
Epoch [175/300], Train Loss: 0.000828
Validation Loss: 0.00110379
Epoch [176/300], Train Loss: 0.000802
Validation Loss: 0.00110410
Epoch [177/300], Train Loss: 0.000798
Validation Loss: 0.00110823
Epoch [178/300], Train Loss: 0.000804
Validation Loss: 0.00112047
Epoch [179/300], Train Loss: 0.000804
Validation Loss: 0.00110616
Epoch [180/300], Train Loss: 0.000801
Validation Loss: 0.00110202
Epoch [181/300], Train Loss: 0.000826
Validation Loss: 0.00110095
Epoch [182/300], Train Loss: 0.000791
Validation Loss: 0.00110304
Epoch [183/300], Train Loss: 0.000803
Validation Loss: 0.00109841
Epoch [184/300], Train Loss: 0.000794
Validation Loss: 0.00109758
Epoch [185/300], Train Loss: 0.000799
Validation Loss: 0.00109746
Epoch [186/300], Train Loss: 0.000796
Validation Loss: 0.00109618
Epoch [187/300], Train Loss: 0.000793
Validation Loss: 0.00110034
Epoch [188/300], Train Loss: 0.000793
Validation Loss: 0.00109689
Epoch [189/300], Train Loss: 0.000796
Validation Loss: 0.00109297
Epoch [190/300], Train Loss: 0.000802
Validation Loss: 0.00109367
Epoch [191/300], Train Loss: 0.000795
Validation Loss: 0.00109299
Epoch [192/300], Train Loss: 0.000799
Validation Loss: 0.00109183
Epoch [193/300], Train Loss: 0.000796
Validation Loss: 0.00109160
Epoch [194/300], Train Loss: 0.000792
Validation Loss: 0.00108903
Epoch [195/300], Train Loss: 0.000781
Validation Loss: 0.00109101
Epoch [196/300], Train Loss: 0.000779
Validation Loss: 0.00108931
Epoch [197/300], Train Loss: 0.000788
Validation Loss: 0.00109042
Epoch [198/300], Train Loss: 0.000778
Validation Loss: 0.00108738
Epoch [199/300], Train Loss: 0.000787
Validation Loss: 0.00108828
Epoch [200/300], Train Loss: 0.000781
Validation Loss: 0.00108602
Epoch [201/300], Train Loss: 0.000791
Validation Loss: 0.00108837
Epoch [202/300], Train Loss: 0.000784
Validation Loss: 0.00109225
Epoch [203/300], Train Loss: 0.000784
Validation Loss: 0.00108550
Epoch [204/300], Train Loss: 0.000784
Validation Loss: 0.00108442
Epoch [205/300], Train Loss: 0.000784
Validation Loss: 0.00108878
Epoch [206/300], Train Loss: 0.000782
Validation Loss: 0.00108443
Epoch [207/300], Train Loss: 0.000769
Validation Loss: 0.00108260
Epoch [208/300], Train Loss: 0.000806
Validation Loss: 0.00108229
Epoch [209/300], Train Loss: 0.000808
Validation Loss: 0.00108473
Epoch [210/300], Train Loss: 0.000772
Validation Loss: 0.00108157
Epoch [211/300], Train Loss: 0.000790
Validation Loss: 0.00108597
Epoch [212/300], Train Loss: 0.000774
Validation Loss: 0.00108287
Epoch [213/300], Train Loss: 0.000775
Validation Loss: 0.00108084
Epoch [214/300], Train Loss: 0.000775
Validation Loss: 0.00107917
Epoch [215/300], Train Loss: 0.000770
Validation Loss: 0.00108089
Epoch [216/300], Train Loss: 0.000778
Validation Loss: 0.00108014
Epoch [217/300], Train Loss: 0.000778
Validation Loss: 0.00108307
Epoch [218/300], Train Loss: 0.000770
Validation Loss: 0.00107754
Epoch [219/300], Train Loss: 0.000763
Validation Loss: 0.00107860
Epoch [220/300], Train Loss: 0.000767
Validation Loss: 0.00107709
Epoch [221/300], Train Loss: 0.000802
Validation Loss: 0.00107483
Epoch [222/300], Train Loss: 0.000760
Validation Loss: 0.00107467
Epoch [223/300], Train Loss: 0.000763
Validation Loss: 0.00107528
Epoch [224/300], Train Loss: 0.000782
Validation Loss: 0.00107867
Epoch [225/300], Train Loss: 0.000784
Validation Loss: 0.00107569
Epoch [226/300], Train Loss: 0.000780
Validation Loss: 0.00107323
Epoch [227/300], Train Loss: 0.000757
Validation Loss: 0.00107382
Epoch [228/300], Train Loss: 0.000761
Validation Loss: 0.00107328
Epoch [229/300], Train Loss: 0.000771
Validation Loss: 0.00107227
Epoch [230/300], Train Loss: 0.000757
Validation Loss: 0.00107164
Epoch [231/300], Train Loss: 0.000772
Validation Loss: 0.00107362
Epoch [232/300], Train Loss: 0.000756
Validation Loss: 0.00107145
Epoch [233/300], Train Loss: 0.000757
Validation Loss: 0.00107146
Epoch [234/300], Train Loss: 0.000755
Validation Loss: 0.00107048
Epoch [235/300], Train Loss: 0.000760
Validation Loss: 0.00106971
Epoch [236/300], Train Loss: 0.000773
Validation Loss: 0.00106872
Epoch [237/300], Train Loss: 0.000749
Validation Loss: 0.00106917
Epoch [238/300], Train Loss: 0.000775
Validation Loss: 0.00106860
Epoch [239/300], Train Loss: 0.000765
Validation Loss: 0.00106850
Epoch [240/300], Train Loss: 0.000761
Validation Loss: 0.00106855
Epoch [241/300], Train Loss: 0.000751
Validation Loss: 0.00106654
Epoch [242/300], Train Loss: 0.000743
Validation Loss: 0.00106631
Epoch [243/300], Train Loss: 0.000772
Validation Loss: 0.00106558
Epoch [244/300], Train Loss: 0.000755
Validation Loss: 0.00106593
Epoch [245/300], Train Loss: 0.000749
Validation Loss: 0.00106608
Epoch [246/300], Train Loss: 0.000744
Validation Loss: 0.00106452
Epoch [247/300], Train Loss: 0.000747
Validation Loss: 0.00106454
Epoch [248/300], Train Loss: 0.000747
Validation Loss: 0.00106452
Epoch [249/300], Train Loss: 0.000745
Validation Loss: 0.00106270
Epoch [250/300], Train Loss: 0.000742
Validation Loss: 0.00106372
Epoch [251/300], Train Loss: 0.000748
Validation Loss: 0.00106273
Epoch [252/300], Train Loss: 0.000749
Validation Loss: 0.00106231
Epoch [253/300], Train Loss: 0.000750
Validation Loss: 0.00106198
Epoch [254/300], Train Loss: 0.000771
Validation Loss: 0.00106330
Epoch [255/300], Train Loss: 0.000738
Validation Loss: 0.00106257
Epoch [256/300], Train Loss: 0.000741
Validation Loss: 0.00106036
Epoch [257/300], Train Loss: 0.000751
Validation Loss: 0.00106495
Epoch [258/300], Train Loss: 0.000751
Validation Loss: 0.00106128
Epoch [259/300], Train Loss: 0.000759
Validation Loss: 0.00106150
Epoch [260/300], Train Loss: 0.000744
Validation Loss: 0.00106025
Epoch [261/300], Train Loss: 0.000739
Validation Loss: 0.00106026
Epoch [262/300], Train Loss: 0.000739
Validation Loss: 0.00105909
Epoch [263/300], Train Loss: 0.000745
Validation Loss: 0.00105832
Epoch [264/300], Train Loss: 0.000741
Validation Loss: 0.00105792
Epoch [265/300], Train Loss: 0.000729
Validation Loss: 0.00105795
Epoch [266/300], Train Loss: 0.000762
Validation Loss: 0.00105839
Epoch [267/300], Train Loss: 0.000743
Validation Loss: 0.00105657
Epoch [268/300], Train Loss: 0.000760
Validation Loss: 0.00105692
Epoch [269/300], Train Loss: 0.000742
Validation Loss: 0.00105864
Epoch [270/300], Train Loss: 0.000735
Validation Loss: 0.00105503
Epoch [271/300], Train Loss: 0.000732
Validation Loss: 0.00105534
Epoch [272/300], Train Loss: 0.000740
Validation Loss: 0.00105650
Epoch [273/300], Train Loss: 0.000736
Validation Loss: 0.00105547
Epoch [274/300], Train Loss: 0.000733
Validation Loss: 0.00105560
Epoch [275/300], Train Loss: 0.000731
Validation Loss: 0.00105441
Epoch [276/300], Train Loss: 0.000734
Validation Loss: 0.00105385
Epoch [277/300], Train Loss: 0.000772
Validation Loss: 0.00105524
Epoch [278/300], Train Loss: 0.000736
Validation Loss: 0.00105390
Epoch [279/300], Train Loss: 0.000726
Validation Loss: 0.00105330
Epoch [280/300], Train Loss: 0.000724
Validation Loss: 0.00105312
Epoch [281/300], Train Loss: 0.000739
Validation Loss: 0.00105298
Epoch [282/300], Train Loss: 0.000752
Validation Loss: 0.00105305
Epoch [283/300], Train Loss: 0.000725
Validation Loss: 0.00105367
Epoch [284/300], Train Loss: 0.000735
Validation Loss: 0.00105225
Epoch [285/300], Train Loss: 0.000731
Validation Loss: 0.00105239
Epoch [286/300], Train Loss: 0.000735
Validation Loss: 0.00105336
Epoch [287/300], Train Loss: 0.000723
Validation Loss: 0.00105154
Epoch [288/300], Train Loss: 0.000730
Validation Loss: 0.00105116
Epoch [289/300], Train Loss: 0.000733
Validation Loss: 0.00105103
Epoch [290/300], Train Loss: 0.000733
Validation Loss: 0.00105029
Epoch [291/300], Train Loss: 0.000733
Validation Loss: 0.00105028
Epoch [292/300], Train Loss: 0.000723
Validation Loss: 0.00104989
Epoch [293/300], Train Loss: 0.000737
Validation Loss: 0.00104919
Epoch [294/300], Train Loss: 0.000722
Validation Loss: 0.00104944
Epoch [295/300], Train Loss: 0.000758
Validation Loss: 0.00104923
Epoch [296/300], Train Loss: 0.000721
Validation Loss: 0.00104889
Epoch [297/300], Train Loss: 0.000719
Validation Loss: 0.00104862
Epoch [298/300], Train Loss: 0.000737
Validation Loss: 0.00104892
Epoch [299/300], Train Loss: 0.000720
Validation Loss: 0.00104946
Epoch [300/300], Train Loss: 0.000721
Validation Loss: 0.00104924

Evaluating model for: Dryer
Run 8/72 completed in 1207.55 seconds with: {'MAE': np.float32(4.2875786), 'MSE': np.float32(1401.4058), 'RMSE': np.float32(37.435356), 'SAE': np.float32(0.048077382), 'NDE': np.float32(0.39918947)}

Run 9/72: hidden=128, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Dryer
Dataset length: 3006 windows

Epoch [1/300], Train Loss: 0.010600
Validation Loss: 0.00789742
Epoch [2/300], Train Loss: 0.010569
Validation Loss: 0.00783341
Epoch [3/300], Train Loss: 0.010349
Validation Loss: 0.00776004
Epoch [4/300], Train Loss: 0.010298
Validation Loss: 0.00766653
Epoch [5/300], Train Loss: 0.010044
Validation Loss: 0.00748235
Epoch [6/300], Train Loss: 0.009642
Validation Loss: 0.00706648
Epoch [7/300], Train Loss: 0.008670
Validation Loss: 0.00587832
Epoch [8/300], Train Loss: 0.006289
Validation Loss: 0.00540627
Epoch [9/300], Train Loss: 0.003909
Validation Loss: 0.00474006
Epoch [10/300], Train Loss: 0.003168
Validation Loss: 0.00409437
Epoch [11/300], Train Loss: 0.002842
Validation Loss: 0.00411340
Epoch [12/300], Train Loss: 0.002658
Validation Loss: 0.00385528
Epoch [13/300], Train Loss: 0.002627
Validation Loss: 0.00371963
Epoch [14/300], Train Loss: 0.002483
Validation Loss: 0.00393991
Epoch [15/300], Train Loss: 0.002437
Validation Loss: 0.00405296
Epoch [16/300], Train Loss: 0.002394
Validation Loss: 0.00349063
Epoch [17/300], Train Loss: 0.002329
Validation Loss: 0.00340518
Epoch [18/300], Train Loss: 0.002190
Validation Loss: 0.00334873
Epoch [19/300], Train Loss: 0.002139
Validation Loss: 0.00333524
Epoch [20/300], Train Loss: 0.002039
Validation Loss: 0.00303748
Epoch [21/300], Train Loss: 0.001967
Validation Loss: 0.00277410
Epoch [22/300], Train Loss: 0.001892
Validation Loss: 0.00248669
Epoch [23/300], Train Loss: 0.001764
Validation Loss: 0.00222827
Epoch [24/300], Train Loss: 0.001794
Validation Loss: 0.00265006
Epoch [25/300], Train Loss: 0.001866
Validation Loss: 0.00303212
Epoch [26/300], Train Loss: 0.001646
Validation Loss: 0.00209512
Epoch [27/300], Train Loss: 0.001497
Validation Loss: 0.00187827
Epoch [28/300], Train Loss: 0.001377
Validation Loss: 0.00133198
Epoch [29/300], Train Loss: 0.001272
Validation Loss: 0.00125508
Epoch [30/300], Train Loss: 0.001228
Validation Loss: 0.00112998
Epoch [31/300], Train Loss: 0.001147
Validation Loss: 0.00112258
Epoch [32/300], Train Loss: 0.002426
Validation Loss: 0.00403964
Epoch [33/300], Train Loss: 0.002365
Validation Loss: 0.00363988
Epoch [34/300], Train Loss: 0.001938
Validation Loss: 0.00308097
Epoch [35/300], Train Loss: 0.001860
Validation Loss: 0.00323546
Epoch [36/300], Train Loss: 0.001815
Validation Loss: 0.00299524
Epoch [37/300], Train Loss: 0.001788
Validation Loss: 0.00301050
Epoch [38/300], Train Loss: 0.001738
Validation Loss: 0.00286761
Epoch [39/300], Train Loss: 0.001697
Validation Loss: 0.00284326
Epoch [40/300], Train Loss: 0.001641
Validation Loss: 0.00264215
Epoch [41/300], Train Loss: 0.001599
Validation Loss: 0.00266881
Early stopping triggered

Evaluating model for: Dryer
Run 9/72 completed in 109.59 seconds with: {'MAE': np.float32(8.627031), 'MSE': np.float32(2865.0122), 'RMSE': np.float32(53.52581), 'SAE': np.float32(0.043314695), 'NDE': np.float32(0.38725582)}

Run 10/72: hidden=128, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Dryer
Dataset length: 3006 windows

Epoch [1/300], Train Loss: 0.010814
Validation Loss: 0.00795138
Epoch [2/300], Train Loss: 0.010660
Validation Loss: 0.00791995
Epoch [3/300], Train Loss: 0.010455
Validation Loss: 0.00786184
Epoch [4/300], Train Loss: 0.010455
Validation Loss: 0.00782016
Epoch [5/300], Train Loss: 0.010247
Validation Loss: 0.00763758
Epoch [6/300], Train Loss: 0.009712
Validation Loss: 0.00684644
Epoch [7/300], Train Loss: 0.006279
Validation Loss: 0.00662095
Epoch [8/300], Train Loss: 0.003233
Validation Loss: 0.00398171
Epoch [9/300], Train Loss: 0.002641
Validation Loss: 0.00376211
Epoch [10/300], Train Loss: 0.002531
Validation Loss: 0.00351368
Epoch [11/300], Train Loss: 0.002384
Validation Loss: 0.00351971
Epoch [12/300], Train Loss: 0.002266
Validation Loss: 0.00316973
Epoch [13/300], Train Loss: 0.002195
Validation Loss: 0.00304435
Epoch [14/300], Train Loss: 0.002093
Validation Loss: 0.00289031
Epoch [15/300], Train Loss: 0.002132
Validation Loss: 0.00294147
Epoch [16/300], Train Loss: 0.001951
Validation Loss: 0.00253212
Epoch [17/300], Train Loss: 0.001917
Validation Loss: 0.00239288
Epoch [18/300], Train Loss: 0.001779
Validation Loss: 0.00220110
Epoch [19/300], Train Loss: 0.001749
Validation Loss: 0.00212542
Epoch [20/300], Train Loss: 0.001685
Validation Loss: 0.00199080
Epoch [21/300], Train Loss: 0.001670
Validation Loss: 0.00175721
Epoch [22/300], Train Loss: 0.001598
Validation Loss: 0.00188110
Epoch [23/300], Train Loss: 0.001559
Validation Loss: 0.00154323
Epoch [24/300], Train Loss: 0.001428
Validation Loss: 0.00197546
Epoch [25/300], Train Loss: 0.001496
Validation Loss: 0.00142603
Epoch [26/300], Train Loss: 0.001335
Validation Loss: 0.00161108
Epoch [27/300], Train Loss: 0.001513
Validation Loss: 0.00183627
Epoch [28/300], Train Loss: 0.001346
Validation Loss: 0.00138846
Epoch [29/300], Train Loss: 0.001412
Validation Loss: 0.00112668
Epoch [30/300], Train Loss: 0.001598
Validation Loss: 0.00331619
Epoch [31/300], Train Loss: 0.001565
Validation Loss: 0.00194245
Epoch [32/300], Train Loss: 0.001303
Validation Loss: 0.00125919
Epoch [33/300], Train Loss: 0.001173
Validation Loss: 0.00119516
Epoch [34/300], Train Loss: 0.001111
Validation Loss: 0.00103174
Epoch [35/300], Train Loss: 0.001145
Validation Loss: 0.00119350
Epoch [36/300], Train Loss: 0.001108
Validation Loss: 0.00093580
Epoch [37/300], Train Loss: 0.001041
Validation Loss: 0.00096741
Epoch [38/300], Train Loss: 0.001006
Validation Loss: 0.00093567
Epoch [39/300], Train Loss: 0.000999
Validation Loss: 0.00110707
Epoch [40/300], Train Loss: 0.001055
Validation Loss: 0.00090201
Epoch [41/300], Train Loss: 0.000973
Validation Loss: 0.00094158
Epoch [42/300], Train Loss: 0.000983
Validation Loss: 0.00092179
Epoch [43/300], Train Loss: 0.000963
Validation Loss: 0.00094724
Epoch [44/300], Train Loss: 0.000951
Validation Loss: 0.00080872
Epoch [45/300], Train Loss: 0.000961
Validation Loss: 0.00094554
Epoch [46/300], Train Loss: 0.000936
Validation Loss: 0.00066324
Epoch [47/300], Train Loss: 0.000934
Validation Loss: 0.00092450
Epoch [48/300], Train Loss: 0.000955
Validation Loss: 0.00092317
Epoch [49/300], Train Loss: 0.000914
Validation Loss: 0.00088881
Epoch [50/300], Train Loss: 0.000903
Validation Loss: 0.00084569
Epoch [51/300], Train Loss: 0.000952
Validation Loss: 0.00094087
Epoch [52/300], Train Loss: 0.000909
Validation Loss: 0.00085547
Epoch [53/300], Train Loss: 0.000929
Validation Loss: 0.00087801
Epoch [54/300], Train Loss: 0.000894
Validation Loss: 0.00080005
Epoch [55/300], Train Loss: 0.000894
Validation Loss: 0.00089733
Epoch [56/300], Train Loss: 0.000880
Validation Loss: 0.00090380
Early stopping triggered

Evaluating model for: Dryer
Run 10/72 completed in 157.40 seconds with: {'MAE': np.float32(6.9310637), 'MSE': np.float32(2846.5952), 'RMSE': np.float32(53.353493), 'SAE': np.float32(0.079312995), 'NDE': np.float32(0.38600916)}

Run 11/72: hidden=128, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Dryer
Dataset length: 3006 windows

Epoch [1/300], Train Loss: 0.010689
Validation Loss: 0.00796894
Epoch [2/300], Train Loss: 0.010659
Validation Loss: 0.00793649
Epoch [3/300], Train Loss: 0.010491
Validation Loss: 0.00791311
Epoch [4/300], Train Loss: 0.010536
Validation Loss: 0.00791968
Epoch [5/300], Train Loss: 0.010448
Validation Loss: 0.00788793
Epoch [6/300], Train Loss: 0.010351
Validation Loss: 0.00781195
Epoch [7/300], Train Loss: 0.009962
Validation Loss: 0.00703983
Epoch [8/300], Train Loss: 0.006791
Validation Loss: 0.00579918
Epoch [9/300], Train Loss: 0.003657
Validation Loss: 0.00436731
Epoch [10/300], Train Loss: 0.002900
Validation Loss: 0.00371641
Epoch [11/300], Train Loss: 0.002674
Validation Loss: 0.00354676
Epoch [12/300], Train Loss: 0.002467
Validation Loss: 0.00355564
Epoch [13/300], Train Loss: 0.002365
Validation Loss: 0.00338091
Epoch [14/300], Train Loss: 0.002229
Validation Loss: 0.00359001
Epoch [15/300], Train Loss: 0.002161
Validation Loss: 0.00341713
Epoch [16/300], Train Loss: 0.002136
Validation Loss: 0.00313340
Epoch [17/300], Train Loss: 0.002065
Validation Loss: 0.00311045
Epoch [18/300], Train Loss: 0.001964
Validation Loss: 0.00325265
Epoch [19/300], Train Loss: 0.001915
Validation Loss: 0.00279655
Epoch [20/300], Train Loss: 0.001810
Validation Loss: 0.00295361
Epoch [21/300], Train Loss: 0.001639
Validation Loss: 0.00224209
Epoch [22/300], Train Loss: 0.001760
Validation Loss: 0.00213719
Epoch [23/300], Train Loss: 0.001899
Validation Loss: 0.00315081
Epoch [24/300], Train Loss: 0.001670
Validation Loss: 0.00257528
Epoch [25/300], Train Loss: 0.001545
Validation Loss: 0.00169295
Epoch [26/300], Train Loss: 0.001472
Validation Loss: 0.00161654
Epoch [27/300], Train Loss: 0.001503
Validation Loss: 0.00342173
Epoch [28/300], Train Loss: 0.001685
Validation Loss: 0.00235457
Epoch [29/300], Train Loss: 0.001250
Validation Loss: 0.00132578
Epoch [30/300], Train Loss: 0.001171
Validation Loss: 0.00107911
Epoch [31/300], Train Loss: 0.001097
Validation Loss: 0.00097887
Epoch [32/300], Train Loss: 0.001133
Validation Loss: 0.00121887
Epoch [33/300], Train Loss: 0.001076
Validation Loss: 0.00089743
Epoch [34/300], Train Loss: 0.001056
Validation Loss: 0.00119829
Epoch [35/300], Train Loss: 0.001058
Validation Loss: 0.00102763
Epoch [36/300], Train Loss: 0.001018
Validation Loss: 0.00075831
Epoch [37/300], Train Loss: 0.001019
Validation Loss: 0.00101984
Epoch [38/300], Train Loss: 0.000968
Validation Loss: 0.00092214
Epoch [39/300], Train Loss: 0.000975
Validation Loss: 0.00089536
Epoch [40/300], Train Loss: 0.000960
Validation Loss: 0.00091896
Epoch [41/300], Train Loss: 0.000944
Validation Loss: 0.00091227
Epoch [42/300], Train Loss: 0.000955
Validation Loss: 0.00103079
Epoch [43/300], Train Loss: 0.000957
Validation Loss: 0.00109180
Epoch [44/300], Train Loss: 0.000923
Validation Loss: 0.00093817
Epoch [45/300], Train Loss: 0.000937
Validation Loss: 0.00081635
Epoch [46/300], Train Loss: 0.000904
Validation Loss: 0.00086210
Early stopping triggered

Evaluating model for: Dryer
Run 11/72 completed in 136.18 seconds with: {'MAE': np.float32(5.1806083), 'MSE': np.float32(1446.0178), 'RMSE': np.float32(38.026543), 'SAE': np.float32(0.0049735126), 'NDE': np.float32(0.2751198)}

Run 12/72: hidden=128, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Dryer
Dataset length: 3006 windows

Epoch [1/300], Train Loss: 0.012946
Validation Loss: 0.00835219
Epoch [2/300], Train Loss: 0.010833
Validation Loss: 0.00807315
Epoch [3/300], Train Loss: 0.010575
Validation Loss: 0.00793694
Epoch [4/300], Train Loss: 0.010600
Validation Loss: 0.00794345
Epoch [5/300], Train Loss: 0.010525
Validation Loss: 0.00794560
Epoch [6/300], Train Loss: 0.010484
Validation Loss: 0.00794224
Epoch [7/300], Train Loss: 0.010401
Validation Loss: 0.00792929
Epoch [8/300], Train Loss: 0.010401
Validation Loss: 0.00787483
Epoch [9/300], Train Loss: 0.010150
Validation Loss: 0.00732337
Epoch [10/300], Train Loss: 0.006141
Validation Loss: 0.00439175
Epoch [11/300], Train Loss: 0.002935
Validation Loss: 0.00381291
Epoch [12/300], Train Loss: 0.002565
Validation Loss: 0.00358115
Epoch [13/300], Train Loss: 0.002535
Validation Loss: 0.00349644
Epoch [14/300], Train Loss: 0.002366
Validation Loss: 0.00394124
Epoch [15/300], Train Loss: 0.002354
Validation Loss: 0.00400706
Epoch [16/300], Train Loss: 0.002346
Validation Loss: 0.00341922
Epoch [17/300], Train Loss: 0.002333
Validation Loss: 0.00341176
Epoch [18/300], Train Loss: 0.002218
Validation Loss: 0.00343390
Epoch [19/300], Train Loss: 0.002191
Validation Loss: 0.00376924
Epoch [20/300], Train Loss: 0.002164
Validation Loss: 0.00346128
Epoch [21/300], Train Loss: 0.002131
Validation Loss: 0.00334900
Epoch [22/300], Train Loss: 0.002054
Validation Loss: 0.00308173
Epoch [23/300], Train Loss: 0.001933
Validation Loss: 0.00249943
Epoch [24/300], Train Loss: 0.001832
Validation Loss: 0.00329153
Epoch [25/300], Train Loss: 0.002070
Validation Loss: 0.00276386
Epoch [26/300], Train Loss: 0.002015
Validation Loss: 0.00333821
Epoch [27/300], Train Loss: 0.001991
Validation Loss: 0.00330028
Epoch [28/300], Train Loss: 0.001970
Validation Loss: 0.00323722
Epoch [29/300], Train Loss: 0.001923
Validation Loss: 0.00287827
Epoch [30/300], Train Loss: 0.001662
Validation Loss: 0.00251799
Epoch [31/300], Train Loss: 0.001512
Validation Loss: 0.00199749
Epoch [32/300], Train Loss: 0.001401
Validation Loss: 0.00147091
Epoch [33/300], Train Loss: 0.001471
Validation Loss: 0.00125265
Epoch [34/300], Train Loss: 0.001194
Validation Loss: 0.00125249
Epoch [35/300], Train Loss: 0.001178
Validation Loss: 0.00109762
Epoch [36/300], Train Loss: 0.001164
Validation Loss: 0.00110030
Epoch [37/300], Train Loss: 0.001005
Validation Loss: 0.00108310
Epoch [38/300], Train Loss: 0.001031
Validation Loss: 0.00106875
Epoch [39/300], Train Loss: 0.000953
Validation Loss: 0.00099664
Epoch [40/300], Train Loss: 0.001007
Validation Loss: 0.00108357
Epoch [41/300], Train Loss: 0.000990
Validation Loss: 0.00101564
Epoch [42/300], Train Loss: 0.001011
Validation Loss: 0.00098513
Epoch [43/300], Train Loss: 0.000993
Validation Loss: 0.00107354
Epoch [44/300], Train Loss: 0.000977
Validation Loss: 0.00086082
Epoch [45/300], Train Loss: 0.000982
Validation Loss: 0.00103736
Epoch [46/300], Train Loss: 0.000932
Validation Loss: 0.00094777
Epoch [47/300], Train Loss: 0.000948
Validation Loss: 0.00102570
Epoch [48/300], Train Loss: 0.000909
Validation Loss: 0.00104597
Epoch [49/300], Train Loss: 0.000939
Validation Loss: 0.00063003
Epoch [50/300], Train Loss: 0.000915
Validation Loss: 0.00099122
Epoch [51/300], Train Loss: 0.000916
Validation Loss: 0.00100667
Epoch [52/300], Train Loss: 0.000849
Validation Loss: 0.00109531
Epoch [53/300], Train Loss: 0.001282
Validation Loss: 0.00153015
Epoch [54/300], Train Loss: 0.000960
Validation Loss: 0.00093489
Epoch [55/300], Train Loss: 0.000877
Validation Loss: 0.00096215
Epoch [56/300], Train Loss: 0.000859
Validation Loss: 0.00091939
Epoch [57/300], Train Loss: 0.000829
Validation Loss: 0.00089757
Epoch [58/300], Train Loss: 0.000824
Validation Loss: 0.00087699
Epoch [59/300], Train Loss: 0.000834
Validation Loss: 0.00060429
Epoch [60/300], Train Loss: 0.000833
Validation Loss: 0.00102157
Epoch [61/300], Train Loss: 0.000794
Validation Loss: 0.00095424
Epoch [62/300], Train Loss: 0.000895
Validation Loss: 0.00334872
Epoch [63/300], Train Loss: 0.002751
Validation Loss: 0.00380310
Epoch [64/300], Train Loss: 0.001810
Validation Loss: 0.00273525
Epoch [65/300], Train Loss: 0.001598
Validation Loss: 0.00238914
Epoch [66/300], Train Loss: 0.001260
Validation Loss: 0.00146676
Epoch [67/300], Train Loss: 0.001014
Validation Loss: 0.00090977
Epoch [68/300], Train Loss: 0.001097
Validation Loss: 0.00413523
Epoch [69/300], Train Loss: 0.002067
Validation Loss: 0.00154206
Early stopping triggered

Evaluating model for: Dryer
Run 12/72 completed in 214.44 seconds with: {'MAE': np.float32(7.902244), 'MSE': np.float32(2109.8252), 'RMSE': np.float32(45.932835), 'SAE': np.float32(0.0607474), 'NDE': np.float32(0.33232138)}

Run 13/72: hidden=128, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Dryer
Dataset length: 1514 windows

Epoch [1/300], Train Loss: 0.010266
Validation Loss: 0.00831740
Epoch [2/300], Train Loss: 0.010095
Validation Loss: 0.00828675
Epoch [3/300], Train Loss: 0.009681
Validation Loss: 0.00827489
Epoch [4/300], Train Loss: 0.009976
Validation Loss: 0.00825897
Epoch [5/300], Train Loss: 0.010518
Validation Loss: 0.00823989
Epoch [6/300], Train Loss: 0.010342
Validation Loss: 0.00821114
Epoch [7/300], Train Loss: 0.010345
Validation Loss: 0.00818006
Epoch [8/300], Train Loss: 0.009884
Validation Loss: 0.00810928
Epoch [9/300], Train Loss: 0.009418
Validation Loss: 0.00802825
Epoch [10/300], Train Loss: 0.010565
Validation Loss: 0.00789506
Epoch [11/300], Train Loss: 0.009534
Validation Loss: 0.00774641
Epoch [12/300], Train Loss: 0.009435
Validation Loss: 0.00738404
Epoch [13/300], Train Loss: 0.008661
Validation Loss: 0.00676329
Epoch [14/300], Train Loss: 0.007495
Validation Loss: 0.00549138
Epoch [15/300], Train Loss: 0.005541
Validation Loss: 0.00280206
Epoch [16/300], Train Loss: 0.003939
Validation Loss: 0.00252518
Epoch [17/300], Train Loss: 0.003488
Validation Loss: 0.00241156
Epoch [18/300], Train Loss: 0.003222
Validation Loss: 0.00220700
Epoch [19/300], Train Loss: 0.003099
Validation Loss: 0.00211187
Epoch [20/300], Train Loss: 0.003157
Validation Loss: 0.00203502
Epoch [21/300], Train Loss: 0.003028
Validation Loss: 0.00200028
Epoch [22/300], Train Loss: 0.002991
Validation Loss: 0.00190259
Epoch [23/300], Train Loss: 0.002869
Validation Loss: 0.00184128
Epoch [24/300], Train Loss: 0.003011
Validation Loss: 0.00181634
Epoch [25/300], Train Loss: 0.003012
Validation Loss: 0.00181691
Epoch [26/300], Train Loss: 0.002878
Validation Loss: 0.00175783
Epoch [27/300], Train Loss: 0.002720
Validation Loss: 0.00174860
Epoch [28/300], Train Loss: 0.002897
Validation Loss: 0.00168284
Epoch [29/300], Train Loss: 0.002574
Validation Loss: 0.00166729
Epoch [30/300], Train Loss: 0.002538
Validation Loss: 0.00163760
Epoch [31/300], Train Loss: 0.002569
Validation Loss: 0.00165467
Epoch [32/300], Train Loss: 0.002649
Validation Loss: 0.00158069
Epoch [33/300], Train Loss: 0.002543
Validation Loss: 0.00157635
Epoch [34/300], Train Loss: 0.002409
Validation Loss: 0.00155203
Epoch [35/300], Train Loss: 0.002472
Validation Loss: 0.00152323
Epoch [36/300], Train Loss: 0.002481
Validation Loss: 0.00151184
Epoch [37/300], Train Loss: 0.002422
Validation Loss: 0.00148848
Epoch [38/300], Train Loss: 0.002367
Validation Loss: 0.00148218
Epoch [39/300], Train Loss: 0.002461
Validation Loss: 0.00144173
Epoch [40/300], Train Loss: 0.002344
Validation Loss: 0.00143226
Epoch [41/300], Train Loss: 0.002401
Validation Loss: 0.00139852
Epoch [42/300], Train Loss: 0.002388
Validation Loss: 0.00140318
Epoch [43/300], Train Loss: 0.002243
Validation Loss: 0.00137889
Epoch [44/300], Train Loss: 0.002153
Validation Loss: 0.00135243
Epoch [45/300], Train Loss: 0.002209
Validation Loss: 0.00132139
Epoch [46/300], Train Loss: 0.002226
Validation Loss: 0.00129227
Epoch [47/300], Train Loss: 0.002038
Validation Loss: 0.00126598
Epoch [48/300], Train Loss: 0.002201
Validation Loss: 0.00122610
Epoch [49/300], Train Loss: 0.001988
Validation Loss: 0.00120471
Epoch [50/300], Train Loss: 0.001825
Validation Loss: 0.00117078
Epoch [51/300], Train Loss: 0.002149
Validation Loss: 0.00115771
Epoch [52/300], Train Loss: 0.002056
Validation Loss: 0.00113636
Epoch [53/300], Train Loss: 0.001992
Validation Loss: 0.00111551
Epoch [54/300], Train Loss: 0.001678
Validation Loss: 0.00110741
Epoch [55/300], Train Loss: 0.001712
Validation Loss: 0.00112880
Epoch [56/300], Train Loss: 0.002004
Validation Loss: 0.00100020
Epoch [57/300], Train Loss: 0.003482
Validation Loss: 0.00410830
Epoch [58/300], Train Loss: 0.005841
Validation Loss: 0.00392209
Epoch [59/300], Train Loss: 0.005033
Validation Loss: 0.00245017
Epoch [60/300], Train Loss: 0.003086
Validation Loss: 0.00129942
Epoch [61/300], Train Loss: 0.002449
Validation Loss: 0.00129367
Epoch [62/300], Train Loss: 0.002472
Validation Loss: 0.00125518
Epoch [63/300], Train Loss: 0.002396
Validation Loss: 0.00124133
Epoch [64/300], Train Loss: 0.002364
Validation Loss: 0.00124266
Epoch [65/300], Train Loss: 0.002274
Validation Loss: 0.00124158
Epoch [66/300], Train Loss: 0.002279
Validation Loss: 0.00123946
Early stopping triggered

Evaluating model for: Dryer
Run 13/72 completed in 89.24 seconds with: {'MAE': np.float32(14.344554), 'MSE': np.float32(3649.9937), 'RMSE': np.float32(60.415176), 'SAE': np.float32(0.110067084), 'NDE': np.float32(0.4102672)}

Run 14/72: hidden=128, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Dryer
Dataset length: 1514 windows

Epoch [1/300], Train Loss: 0.010218
Validation Loss: 0.00830381
Epoch [2/300], Train Loss: 0.010116
Validation Loss: 0.00828831
Epoch [3/300], Train Loss: 0.009683
Validation Loss: 0.00827011
Epoch [4/300], Train Loss: 0.009977
Validation Loss: 0.00824161
Epoch [5/300], Train Loss: 0.010518
Validation Loss: 0.00820974
Epoch [6/300], Train Loss: 0.010312
Validation Loss: 0.00815477
Epoch [7/300], Train Loss: 0.010259
Validation Loss: 0.00804773
Epoch [8/300], Train Loss: 0.009675
Validation Loss: 0.00781119
Epoch [9/300], Train Loss: 0.008953
Validation Loss: 0.00734281
Epoch [10/300], Train Loss: 0.009139
Validation Loss: 0.00638543
Epoch [11/300], Train Loss: 0.006976
Validation Loss: 0.00438238
Epoch [12/300], Train Loss: 0.004522
Validation Loss: 0.00313051
Epoch [13/300], Train Loss: 0.003915
Validation Loss: 0.00276115
Epoch [14/300], Train Loss: 0.003685
Validation Loss: 0.00237129
Epoch [15/300], Train Loss: 0.003284
Validation Loss: 0.00220238
Epoch [16/300], Train Loss: 0.003153
Validation Loss: 0.00209687
Epoch [17/300], Train Loss: 0.003048
Validation Loss: 0.00202747
Epoch [18/300], Train Loss: 0.002837
Validation Loss: 0.00191880
Epoch [19/300], Train Loss: 0.002762
Validation Loss: 0.00182482
Epoch [20/300], Train Loss: 0.002827
Validation Loss: 0.00174102
Epoch [21/300], Train Loss: 0.002743
Validation Loss: 0.00170676
Epoch [22/300], Train Loss: 0.002693
Validation Loss: 0.00164363
Epoch [23/300], Train Loss: 0.002552
Validation Loss: 0.00160330
Epoch [24/300], Train Loss: 0.002684
Validation Loss: 0.00152797
Epoch [25/300], Train Loss: 0.002551
Validation Loss: 0.00151283
Epoch [26/300], Train Loss: 0.002398
Validation Loss: 0.00144668
Epoch [27/300], Train Loss: 0.002275
Validation Loss: 0.00137639
Epoch [28/300], Train Loss: 0.002509
Validation Loss: 0.00151556
Epoch [29/300], Train Loss: 0.002065
Validation Loss: 0.00130303
Epoch [30/300], Train Loss: 0.001939
Validation Loss: 0.00131061
Epoch [31/300], Train Loss: 0.002016
Validation Loss: 0.00125446
Epoch [32/300], Train Loss: 0.001966
Validation Loss: 0.00123354
Epoch [33/300], Train Loss: 0.001873
Validation Loss: 0.00124990
Epoch [34/300], Train Loss: 0.001782
Validation Loss: 0.00116344
Epoch [35/300], Train Loss: 0.001690
Validation Loss: 0.00115501
Epoch [36/300], Train Loss: 0.002006
Validation Loss: 0.00114281
Epoch [37/300], Train Loss: 0.001924
Validation Loss: 0.00115993
Epoch [38/300], Train Loss: 0.001623
Validation Loss: 0.00114250
Epoch [39/300], Train Loss: 0.001600
Validation Loss: 0.00112159
Epoch [40/300], Train Loss: 0.001702
Validation Loss: 0.00109933
Epoch [41/300], Train Loss: 0.001622
Validation Loss: 0.00107641
Epoch [42/300], Train Loss: 0.001555
Validation Loss: 0.00109253
Epoch [43/300], Train Loss: 0.001503
Validation Loss: 0.00109539
Epoch [44/300], Train Loss: 0.001664
Validation Loss: 0.00100687
Epoch [45/300], Train Loss: 0.001617
Validation Loss: 0.00109846
Epoch [46/300], Train Loss: 0.001518
Validation Loss: 0.00107644
Epoch [47/300], Train Loss: 0.001459
Validation Loss: 0.00107799
Epoch [48/300], Train Loss: 0.001494
Validation Loss: 0.00107277
Epoch [49/300], Train Loss: 0.001643
Validation Loss: 0.00106455
Epoch [50/300], Train Loss: 0.001434
Validation Loss: 0.00106123
Epoch [51/300], Train Loss: 0.001681
Validation Loss: 0.00112501
Epoch [52/300], Train Loss: 0.001422
Validation Loss: 0.00106598
Epoch [53/300], Train Loss: 0.001475
Validation Loss: 0.00104675
Epoch [54/300], Train Loss: 0.001388
Validation Loss: 0.00102212
Early stopping triggered

Evaluating model for: Dryer
Run 14/72 completed in 76.81 seconds with: {'MAE': np.float32(8.83121), 'MSE': np.float32(2848.9111), 'RMSE': np.float32(53.37519), 'SAE': np.float32(0.07127813), 'NDE': np.float32(0.36245984)}

Run 15/72: hidden=128, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Dryer
Dataset length: 1514 windows

Epoch [1/300], Train Loss: 0.012798
Validation Loss: 0.00966658
Epoch [2/300], Train Loss: 0.011114
Validation Loss: 0.00859777
Epoch [3/300], Train Loss: 0.009907
Validation Loss: 0.00832730
Epoch [4/300], Train Loss: 0.010077
Validation Loss: 0.00839162
Epoch [5/300], Train Loss: 0.010640
Validation Loss: 0.00833152
Epoch [6/300], Train Loss: 0.010481
Validation Loss: 0.00830748
Epoch [7/300], Train Loss: 0.010503
Validation Loss: 0.00830405
Epoch [8/300], Train Loss: 0.010077
Validation Loss: 0.00829705
Epoch [9/300], Train Loss: 0.009665
Validation Loss: 0.00827814
Epoch [10/300], Train Loss: 0.010941
Validation Loss: 0.00823699
Epoch [11/300], Train Loss: 0.009990
Validation Loss: 0.00822044
Epoch [12/300], Train Loss: 0.010101
Validation Loss: 0.00810916
Epoch [13/300], Train Loss: 0.009617
Validation Loss: 0.00787702
Epoch [14/300], Train Loss: 0.008763
Validation Loss: 0.00709292
Epoch [15/300], Train Loss: 0.006655
Validation Loss: 0.00523341
Epoch [16/300], Train Loss: 0.004903
Validation Loss: 0.00417594
Epoch [17/300], Train Loss: 0.004407
Validation Loss: 0.00394789
Epoch [18/300], Train Loss: 0.003884
Validation Loss: 0.00339080
Epoch [19/300], Train Loss: 0.003760
Validation Loss: 0.00307894
Epoch [20/300], Train Loss: 0.003763
Validation Loss: 0.00326308
Epoch [21/300], Train Loss: 0.003653
Validation Loss: 0.00267115
Epoch [22/300], Train Loss: 0.003453
Validation Loss: 0.00259480
Epoch [23/300], Train Loss: 0.003303
Validation Loss: 0.00251115
Epoch [24/300], Train Loss: 0.003374
Validation Loss: 0.00233704
Epoch [25/300], Train Loss: 0.003380
Validation Loss: 0.00234102
Epoch [26/300], Train Loss: 0.003233
Validation Loss: 0.00214864
Epoch [27/300], Train Loss: 0.002950
Validation Loss: 0.00225324
Epoch [28/300], Train Loss: 0.003147
Validation Loss: 0.00201320
Epoch [29/300], Train Loss: 0.002820
Validation Loss: 0.00210521
Epoch [30/300], Train Loss: 0.002726
Validation Loss: 0.00193419
Epoch [31/300], Train Loss: 0.002798
Validation Loss: 0.00201303
Epoch [32/300], Train Loss: 0.002838
Validation Loss: 0.00182487
Epoch [33/300], Train Loss: 0.002748
Validation Loss: 0.00182901
Epoch [34/300], Train Loss: 0.002553
Validation Loss: 0.00176982
Epoch [35/300], Train Loss: 0.002610
Validation Loss: 0.00176179
Epoch [36/300], Train Loss: 0.002641
Validation Loss: 0.00169265
Epoch [37/300], Train Loss: 0.002538
Validation Loss: 0.00166621
Epoch [38/300], Train Loss: 0.002466
Validation Loss: 0.00161593
Epoch [39/300], Train Loss: 0.002540
Validation Loss: 0.00156697
Epoch [40/300], Train Loss: 0.002477
Validation Loss: 0.00151401
Epoch [41/300], Train Loss: 0.002491
Validation Loss: 0.00148998
Epoch [42/300], Train Loss: 0.002442
Validation Loss: 0.00145654
Epoch [43/300], Train Loss: 0.002336
Validation Loss: 0.00141130
Epoch [44/300], Train Loss: 0.002189
Validation Loss: 0.00136540
Epoch [45/300], Train Loss: 0.002235
Validation Loss: 0.00130875
Epoch [46/300], Train Loss: 0.002175
Validation Loss: 0.00125940
Epoch [47/300], Train Loss: 0.001944
Validation Loss: 0.00123059
Epoch [48/300], Train Loss: 0.002040
Validation Loss: 0.00118272
Epoch [49/300], Train Loss: 0.001900
Validation Loss: 0.00112228
Epoch [50/300], Train Loss: 0.001814
Validation Loss: 0.00111823
Epoch [51/300], Train Loss: 0.001725
Validation Loss: 0.00108766
Epoch [52/300], Train Loss: 0.001698
Validation Loss: 0.00105214
Epoch [53/300], Train Loss: 0.001619
Validation Loss: 0.00102869
Epoch [54/300], Train Loss: 0.001508
Validation Loss: 0.00101434
Epoch [55/300], Train Loss: 0.001559
Validation Loss: 0.00112604
Epoch [56/300], Train Loss: 0.001693
Validation Loss: 0.00135515
Epoch [57/300], Train Loss: 0.001978
Validation Loss: 0.00110363
Epoch [58/300], Train Loss: 0.001695
Validation Loss: 0.00117718
Epoch [59/300], Train Loss: 0.001669
Validation Loss: 0.00099989
Epoch [60/300], Train Loss: 0.001675
Validation Loss: 0.00096714
Epoch [61/300], Train Loss: 0.001752
Validation Loss: 0.00104162
Epoch [62/300], Train Loss: 0.001558
Validation Loss: 0.00096721
Epoch [63/300], Train Loss: 0.001511
Validation Loss: 0.00099516
Epoch [64/300], Train Loss: 0.001407
Validation Loss: 0.00100515
Epoch [65/300], Train Loss: 0.001385
Validation Loss: 0.00093166
Epoch [66/300], Train Loss: 0.001370
Validation Loss: 0.00095150
Epoch [67/300], Train Loss: 0.001379
Validation Loss: 0.00093146
Epoch [68/300], Train Loss: 0.001421
Validation Loss: 0.00092550
Epoch [69/300], Train Loss: 0.001330
Validation Loss: 0.00091360
Epoch [70/300], Train Loss: 0.001364
Validation Loss: 0.00091379
Epoch [71/300], Train Loss: 0.001527
Validation Loss: 0.00092386
Epoch [72/300], Train Loss: 0.001469
Validation Loss: 0.00096490
Epoch [73/300], Train Loss: 0.001282
Validation Loss: 0.00092326
Epoch [74/300], Train Loss: 0.001354
Validation Loss: 0.00093383
Epoch [75/300], Train Loss: 0.001278
Validation Loss: 0.00090691
Epoch [76/300], Train Loss: 0.001408
Validation Loss: 0.00091450
Epoch [77/300], Train Loss: 0.001225
Validation Loss: 0.00089758
Epoch [78/300], Train Loss: 0.001240
Validation Loss: 0.00088570
Epoch [79/300], Train Loss: 0.001239
Validation Loss: 0.00089317
Epoch [80/300], Train Loss: 0.001262
Validation Loss: 0.00088386
Epoch [81/300], Train Loss: 0.001220
Validation Loss: 0.00089160
Epoch [82/300], Train Loss: 0.001280
Validation Loss: 0.00087426
Epoch [83/300], Train Loss: 0.001187
Validation Loss: 0.00088722
Epoch [84/300], Train Loss: 0.001217
Validation Loss: 0.00087775
Epoch [85/300], Train Loss: 0.001235
Validation Loss: 0.00086822
Epoch [86/300], Train Loss: 0.001222
Validation Loss: 0.00088759
Epoch [87/300], Train Loss: 0.001199
Validation Loss: 0.00084418
Epoch [88/300], Train Loss: 0.001172
Validation Loss: 0.00087971
Epoch [89/300], Train Loss: 0.001180
Validation Loss: 0.00084411
Epoch [90/300], Train Loss: 0.001189
Validation Loss: 0.00084458
Epoch [91/300], Train Loss: 0.001239
Validation Loss: 0.00083468
Epoch [92/300], Train Loss: 0.001131
Validation Loss: 0.00082718
Epoch [93/300], Train Loss: 0.001133
Validation Loss: 0.00082493
Epoch [94/300], Train Loss: 0.001127
Validation Loss: 0.00082051
Epoch [95/300], Train Loss: 0.001127
Validation Loss: 0.00079102
Epoch [96/300], Train Loss: 0.001141
Validation Loss: 0.00080972
Epoch [97/300], Train Loss: 0.001103
Validation Loss: 0.00078288
Epoch [98/300], Train Loss: 0.001173
Validation Loss: 0.00077749
Epoch [99/300], Train Loss: 0.001063
Validation Loss: 0.00081827
Epoch [100/300], Train Loss: 0.001138
Validation Loss: 0.00076274
Epoch [101/300], Train Loss: 0.001109
Validation Loss: 0.00082959
Epoch [102/300], Train Loss: 0.001052
Validation Loss: 0.00075760
Epoch [103/300], Train Loss: 0.001131
Validation Loss: 0.00075895
Epoch [104/300], Train Loss: 0.001021
Validation Loss: 0.00076857
Epoch [105/300], Train Loss: 0.000993
Validation Loss: 0.00074547
Epoch [106/300], Train Loss: 0.000976
Validation Loss: 0.00077126
Epoch [107/300], Train Loss: 0.001053
Validation Loss: 0.00075247
Epoch [108/300], Train Loss: 0.000961
Validation Loss: 0.00072886
Epoch [109/300], Train Loss: 0.000939
Validation Loss: 0.00073998
Epoch [110/300], Train Loss: 0.000982
Validation Loss: 0.00073563
Epoch [111/300], Train Loss: 0.000989
Validation Loss: 0.00073757
Epoch [112/300], Train Loss: 0.000969
Validation Loss: 0.00072351
Epoch [113/300], Train Loss: 0.000973
Validation Loss: 0.00072513
Epoch [114/300], Train Loss: 0.000992
Validation Loss: 0.00071007
Epoch [115/300], Train Loss: 0.001055
Validation Loss: 0.00071664
Epoch [116/300], Train Loss: 0.001055
Validation Loss: 0.00071657
Epoch [117/300], Train Loss: 0.000968
Validation Loss: 0.00070771
Epoch [118/300], Train Loss: 0.000983
Validation Loss: 0.00075408
Epoch [119/300], Train Loss: 0.000926
Validation Loss: 0.00069443
Epoch [120/300], Train Loss: 0.000942
Validation Loss: 0.00071596
Epoch [121/300], Train Loss: 0.000951
Validation Loss: 0.00071278
Epoch [122/300], Train Loss: 0.000957
Validation Loss: 0.00070160
Epoch [123/300], Train Loss: 0.001000
Validation Loss: 0.00067191
Epoch [124/300], Train Loss: 0.001005
Validation Loss: 0.00068431
Epoch [125/300], Train Loss: 0.000966
Validation Loss: 0.00070833
Epoch [126/300], Train Loss: 0.000928
Validation Loss: 0.00068580
Epoch [127/300], Train Loss: 0.000913
Validation Loss: 0.00069024
Epoch [128/300], Train Loss: 0.000983
Validation Loss: 0.00069050
Epoch [129/300], Train Loss: 0.001037
Validation Loss: 0.00068673
Epoch [130/300], Train Loss: 0.000924
Validation Loss: 0.00067220
Epoch [131/300], Train Loss: 0.000957
Validation Loss: 0.00068281
Epoch [132/300], Train Loss: 0.000912
Validation Loss: 0.00067502
Epoch [133/300], Train Loss: 0.000891
Validation Loss: 0.00067689
Early stopping triggered

Evaluating model for: Dryer
Run 15/72 completed in 199.71 seconds with: {'MAE': np.float32(6.013744), 'MSE': np.float32(1642.3705), 'RMSE': np.float32(40.52617), 'SAE': np.float32(0.041867062), 'NDE': np.float32(0.27520487)}

Run 16/72: hidden=128, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Dryer
Dataset length: 1514 windows

Epoch [1/300], Train Loss: 0.010278
Validation Loss: 0.00831207
Epoch [2/300], Train Loss: 0.010149
Validation Loss: 0.00834680
Epoch [3/300], Train Loss: 0.009720
Validation Loss: 0.00832493
Epoch [4/300], Train Loss: 0.010036
Validation Loss: 0.00830965
Epoch [5/300], Train Loss: 0.010619
Validation Loss: 0.00830939
Epoch [6/300], Train Loss: 0.010469
Validation Loss: 0.00831330
Epoch [7/300], Train Loss: 0.010513
Validation Loss: 0.00832417
Epoch [8/300], Train Loss: 0.010101
Validation Loss: 0.00831218
Epoch [9/300], Train Loss: 0.009700
Validation Loss: 0.00830477
Epoch [10/300], Train Loss: 0.011015
Validation Loss: 0.00828715
Epoch [11/300], Train Loss: 0.010095
Validation Loss: 0.00828372
Epoch [12/300], Train Loss: 0.010292
Validation Loss: 0.00821820
Epoch [13/300], Train Loss: 0.009907
Validation Loss: 0.00798877
Epoch [14/300], Train Loss: 0.009045
Validation Loss: 0.00702770
Epoch [15/300], Train Loss: 0.007087
Validation Loss: 0.00389008
Epoch [16/300], Train Loss: 0.003913
Validation Loss: 0.00200443
Epoch [17/300], Train Loss: 0.002855
Validation Loss: 0.00168241
Epoch [18/300], Train Loss: 0.002649
Validation Loss: 0.00166443
Epoch [19/300], Train Loss: 0.002526
Validation Loss: 0.00152860
Epoch [20/300], Train Loss: 0.002664
Validation Loss: 0.00151026
Epoch [21/300], Train Loss: 0.002577
Validation Loss: 0.00146325
Epoch [22/300], Train Loss: 0.002469
Validation Loss: 0.00144092
Epoch [23/300], Train Loss: 0.002384
Validation Loss: 0.00143020
Epoch [24/300], Train Loss: 0.002474
Validation Loss: 0.00137959
Epoch [25/300], Train Loss: 0.002508
Validation Loss: 0.00137590
Epoch [26/300], Train Loss: 0.002458
Validation Loss: 0.00141521
Epoch [27/300], Train Loss: 0.002317
Validation Loss: 0.00142966
Epoch [28/300], Train Loss: 0.002507
Validation Loss: 0.00134953
Epoch [29/300], Train Loss: 0.002171
Validation Loss: 0.00132499
Epoch [30/300], Train Loss: 0.002117
Validation Loss: 0.00130824
Epoch [31/300], Train Loss: 0.002189
Validation Loss: 0.00130341
Epoch [32/300], Train Loss: 0.002241
Validation Loss: 0.00128479
Epoch [33/300], Train Loss: 0.002134
Validation Loss: 0.00124836
Epoch [34/300], Train Loss: 0.002065
Validation Loss: 0.00118928
Epoch [35/300], Train Loss: 0.002156
Validation Loss: 0.00124683
Epoch [36/300], Train Loss: 0.002137
Validation Loss: 0.00122235
Epoch [37/300], Train Loss: 0.002091
Validation Loss: 0.00120957
Epoch [38/300], Train Loss: 0.002024
Validation Loss: 0.00119302
Epoch [39/300], Train Loss: 0.002182
Validation Loss: 0.00118622
Epoch [40/300], Train Loss: 0.002041
Validation Loss: 0.00123034
Epoch [41/300], Train Loss: 0.002145
Validation Loss: 0.00122576
Epoch [42/300], Train Loss: 0.002118
Validation Loss: 0.00122426
Epoch [43/300], Train Loss: 0.002018
Validation Loss: 0.00121108
Epoch [44/300], Train Loss: 0.001942
Validation Loss: 0.00116614
Epoch [45/300], Train Loss: 0.001995
Validation Loss: 0.00114330
Epoch [46/300], Train Loss: 0.002074
Validation Loss: 0.00113834
Epoch [47/300], Train Loss: 0.001905
Validation Loss: 0.00115962
Epoch [48/300], Train Loss: 0.002186
Validation Loss: 0.00115222
Epoch [49/300], Train Loss: 0.001947
Validation Loss: 0.00111518
Epoch [50/300], Train Loss: 0.001859
Validation Loss: 0.00109658
Epoch [51/300], Train Loss: 0.001945
Validation Loss: 0.00108780
Epoch [52/300], Train Loss: 0.001905
Validation Loss: 0.00107544
Epoch [53/300], Train Loss: 0.001868
Validation Loss: 0.00106225
Epoch [54/300], Train Loss: 0.001860
Validation Loss: 0.00108387
Epoch [55/300], Train Loss: 0.001925
Validation Loss: 0.00106220
Epoch [56/300], Train Loss: 0.001805
Validation Loss: 0.00102675
Epoch [57/300], Train Loss: 0.001650
Validation Loss: 0.00099015
Epoch [58/300], Train Loss: 0.001539
Validation Loss: 0.00134350
Epoch [59/300], Train Loss: 0.001681
Validation Loss: 0.00095273
Epoch [60/300], Train Loss: 0.001537
Validation Loss: 0.00093485
Epoch [61/300], Train Loss: 0.001580
Validation Loss: 0.00088888
Epoch [62/300], Train Loss: 0.001444
Validation Loss: 0.00092581
Epoch [63/300], Train Loss: 0.001366
Validation Loss: 0.00085569
Epoch [64/300], Train Loss: 0.001361
Validation Loss: 0.00080580
Epoch [65/300], Train Loss: 0.001415
Validation Loss: 0.00080723
Epoch [66/300], Train Loss: 0.001274
Validation Loss: 0.00079729
Epoch [67/300], Train Loss: 0.001257
Validation Loss: 0.00079445
Epoch [68/300], Train Loss: 0.001172
Validation Loss: 0.00074840
Epoch [69/300], Train Loss: 0.001071
Validation Loss: 0.00075994
Epoch [70/300], Train Loss: 0.001078
Validation Loss: 0.00070157
Epoch [71/300], Train Loss: 0.001187
Validation Loss: 0.00070159
Epoch [72/300], Train Loss: 0.001193
Validation Loss: 0.00072307
Epoch [73/300], Train Loss: 0.001031
Validation Loss: 0.00070786
Epoch [74/300], Train Loss: 0.000956
Validation Loss: 0.00071136
Epoch [75/300], Train Loss: 0.000951
Validation Loss: 0.00068992
Epoch [76/300], Train Loss: 0.000987
Validation Loss: 0.00067999
Epoch [77/300], Train Loss: 0.000897
Validation Loss: 0.00069187
Epoch [78/300], Train Loss: 0.000931
Validation Loss: 0.00068027
Epoch [79/300], Train Loss: 0.000916
Validation Loss: 0.00066010
Epoch [80/300], Train Loss: 0.001239
Validation Loss: 0.00066846
Epoch [81/300], Train Loss: 0.001173
Validation Loss: 0.00073403
Epoch [82/300], Train Loss: 0.000995
Validation Loss: 0.00064891
Epoch [83/300], Train Loss: 0.000926
Validation Loss: 0.00064045
Epoch [84/300], Train Loss: 0.000914
Validation Loss: 0.00063971
Epoch [85/300], Train Loss: 0.000950
Validation Loss: 0.00064767
Epoch [86/300], Train Loss: 0.000941
Validation Loss: 0.00063955
Epoch [87/300], Train Loss: 0.000920
Validation Loss: 0.00061329
Epoch [88/300], Train Loss: 0.000896
Validation Loss: 0.00062379
Epoch [89/300], Train Loss: 0.000899
Validation Loss: 0.00062913
Epoch [90/300], Train Loss: 0.000884
Validation Loss: 0.00060627
Epoch [91/300], Train Loss: 0.001007
Validation Loss: 0.00060965
Epoch [92/300], Train Loss: 0.001230
Validation Loss: 0.00067212
Epoch [93/300], Train Loss: 0.001334
Validation Loss: 0.00062598
Epoch [94/300], Train Loss: 0.001255
Validation Loss: 0.00064605
Epoch [95/300], Train Loss: 0.001184
Validation Loss: 0.00059098
Epoch [96/300], Train Loss: 0.000939
Validation Loss: 0.00057161
Epoch [97/300], Train Loss: 0.000879
Validation Loss: 0.00058578
Epoch [98/300], Train Loss: 0.001041
Validation Loss: 0.00058154
Epoch [99/300], Train Loss: 0.000887
Validation Loss: 0.00057356
Epoch [100/300], Train Loss: 0.000955
Validation Loss: 0.00057845
Epoch [101/300], Train Loss: 0.000877
Validation Loss: 0.00059841
Epoch [102/300], Train Loss: 0.000886
Validation Loss: 0.00058897
Epoch [103/300], Train Loss: 0.000913
Validation Loss: 0.00056486
Epoch [104/300], Train Loss: 0.000962
Validation Loss: 0.00055766
Epoch [105/300], Train Loss: 0.000830
Validation Loss: 0.00057578
Epoch [106/300], Train Loss: 0.000818
Validation Loss: 0.00056823
Epoch [107/300], Train Loss: 0.000883
Validation Loss: 0.00055046
Epoch [108/300], Train Loss: 0.000844
Validation Loss: 0.00053267
Epoch [109/300], Train Loss: 0.000818
Validation Loss: 0.00054452
Epoch [110/300], Train Loss: 0.000843
Validation Loss: 0.00055840
Epoch [111/300], Train Loss: 0.000900
Validation Loss: 0.00056440
Epoch [112/300], Train Loss: 0.000839
Validation Loss: 0.00055610
Epoch [113/300], Train Loss: 0.000846
Validation Loss: 0.00054990
Epoch [114/300], Train Loss: 0.000830
Validation Loss: 0.00054691
Epoch [115/300], Train Loss: 0.000886
Validation Loss: 0.00054674
Epoch [116/300], Train Loss: 0.000836
Validation Loss: 0.00055434
Epoch [117/300], Train Loss: 0.000850
Validation Loss: 0.00054728
Epoch [118/300], Train Loss: 0.000895
Validation Loss: 0.00052617
Epoch [119/300], Train Loss: 0.000787
Validation Loss: 0.00052789
Epoch [120/300], Train Loss: 0.000798
Validation Loss: 0.00056535
Epoch [121/300], Train Loss: 0.000969
Validation Loss: 0.00054207
Epoch [122/300], Train Loss: 0.000867
Validation Loss: 0.00052201
Epoch [123/300], Train Loss: 0.000846
Validation Loss: 0.00051827
Epoch [124/300], Train Loss: 0.000801
Validation Loss: 0.00053624
Epoch [125/300], Train Loss: 0.000817
Validation Loss: 0.00053012
Epoch [126/300], Train Loss: 0.000783
Validation Loss: 0.00053788
Epoch [127/300], Train Loss: 0.000779
Validation Loss: 0.00052535
Epoch [128/300], Train Loss: 0.000889
Validation Loss: 0.00051085
Epoch [129/300], Train Loss: 0.001020
Validation Loss: 0.00055933
Epoch [130/300], Train Loss: 0.001149
Validation Loss: 0.00059233
Epoch [131/300], Train Loss: 0.001048
Validation Loss: 0.00053587
Epoch [132/300], Train Loss: 0.000919
Validation Loss: 0.00052493
Epoch [133/300], Train Loss: 0.000854
Validation Loss: 0.00053340
Epoch [134/300], Train Loss: 0.000857
Validation Loss: 0.00051504
Epoch [135/300], Train Loss: 0.000820
Validation Loss: 0.00051112
Epoch [136/300], Train Loss: 0.000845
Validation Loss: 0.00052457
Epoch [137/300], Train Loss: 0.000789
Validation Loss: 0.00051527
Epoch [138/300], Train Loss: 0.000845
Validation Loss: 0.00051423
Early stopping triggered

Evaluating model for: Dryer
Run 16/72 completed in 219.36 seconds with: {'MAE': np.float32(5.9868946), 'MSE': np.float32(1703.6743), 'RMSE': np.float32(41.27559), 'SAE': np.float32(0.02078687), 'NDE': np.float32(0.28029418)}

Run 17/72: hidden=128, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Dryer
Dataset length: 1470 windows

Epoch [1/300], Train Loss: 0.012522
Validation Loss: 0.00895462
Epoch [2/300], Train Loss: 0.010370
Validation Loss: 0.00827217
Epoch [3/300], Train Loss: 0.009861
Validation Loss: 0.00810661
Epoch [4/300], Train Loss: 0.009935
Validation Loss: 0.00814041
Epoch [5/300], Train Loss: 0.010094
Validation Loss: 0.00810986
Epoch [6/300], Train Loss: 0.010335
Validation Loss: 0.00808005
Epoch [7/300], Train Loss: 0.010613
Validation Loss: 0.00805526
Epoch [8/300], Train Loss: 0.010547
Validation Loss: 0.00803735
Epoch [9/300], Train Loss: 0.009706
Validation Loss: 0.00801811
Epoch [10/300], Train Loss: 0.010923
Validation Loss: 0.00798806
Epoch [11/300], Train Loss: 0.013492
Validation Loss: 0.00796635
Epoch [12/300], Train Loss: 0.011040
Validation Loss: 0.00796260
Epoch [13/300], Train Loss: 0.010819
Validation Loss: 0.00787453
Epoch [14/300], Train Loss: 0.011217
Validation Loss: 0.00777275
Epoch [15/300], Train Loss: 0.011634
Validation Loss: 0.00767696
Epoch [16/300], Train Loss: 0.009272
Validation Loss: 0.00757624
Epoch [17/300], Train Loss: 0.008925
Validation Loss: 0.00733053
Epoch [18/300], Train Loss: 0.008842
Validation Loss: 0.00698401
Epoch [19/300], Train Loss: 0.008134
Validation Loss: 0.00620590
Epoch [20/300], Train Loss: 0.007552
Validation Loss: 0.00385757
Epoch [21/300], Train Loss: 0.004041
Validation Loss: 0.00251510
Epoch [22/300], Train Loss: 0.003134
Validation Loss: 0.00193295
Epoch [23/300], Train Loss: 0.002896
Validation Loss: 0.00179704
Epoch [24/300], Train Loss: 0.002987
Validation Loss: 0.00171001
Epoch [25/300], Train Loss: 0.002747
Validation Loss: 0.00167155
Epoch [26/300], Train Loss: 0.002530
Validation Loss: 0.00157050
Epoch [27/300], Train Loss: 0.002324
Validation Loss: 0.00156063
Epoch [28/300], Train Loss: 0.002479
Validation Loss: 0.00152883
Epoch [29/300], Train Loss: 0.002620
Validation Loss: 0.00151321
Epoch [30/300], Train Loss: 0.002206
Validation Loss: 0.00155121
Epoch [31/300], Train Loss: 0.002623
Validation Loss: 0.00147590
Epoch [32/300], Train Loss: 0.002264
Validation Loss: 0.00145246
Epoch [33/300], Train Loss: 0.002625
Validation Loss: 0.00151946
Epoch [34/300], Train Loss: 0.002360
Validation Loss: 0.00145554
Epoch [35/300], Train Loss: 0.002181
Validation Loss: 0.00143395
Epoch [36/300], Train Loss: 0.002426
Validation Loss: 0.00138645
Epoch [37/300], Train Loss: 0.002166
Validation Loss: 0.00145960
Epoch [38/300], Train Loss: 0.002001
Validation Loss: 0.00140507
Epoch [39/300], Train Loss: 0.002054
Validation Loss: 0.00144396
Epoch [40/300], Train Loss: 0.001930
Validation Loss: 0.00138113
Epoch [41/300], Train Loss: 0.002022
Validation Loss: 0.00127175
Epoch [42/300], Train Loss: 0.001765
Validation Loss: 0.00125996
Epoch [43/300], Train Loss: 0.001774
Validation Loss: 0.00133800
Epoch [44/300], Train Loss: 0.001854
Validation Loss: 0.00120657
Epoch [45/300], Train Loss: 0.001688
Validation Loss: 0.00126576
Epoch [46/300], Train Loss: 0.001629
Validation Loss: 0.00112293
Epoch [47/300], Train Loss: 0.001853
Validation Loss: 0.00109134
Epoch [48/300], Train Loss: 0.001572
Validation Loss: 0.00114417
Epoch [49/300], Train Loss: 0.001658
Validation Loss: 0.00115032
Epoch [50/300], Train Loss: 0.001740
Validation Loss: 0.00100321
Epoch [51/300], Train Loss: 0.001515
Validation Loss: 0.00095740
Epoch [52/300], Train Loss: 0.001443
Validation Loss: 0.00097455
Epoch [53/300], Train Loss: 0.001309
Validation Loss: 0.00096795
Epoch [54/300], Train Loss: 0.001377
Validation Loss: 0.00096310
Epoch [55/300], Train Loss: 0.001269
Validation Loss: 0.00094954
Epoch [56/300], Train Loss: 0.001668
Validation Loss: 0.00094003
Epoch [57/300], Train Loss: 0.001576
Validation Loss: 0.00089925
Epoch [58/300], Train Loss: 0.001719
Validation Loss: 0.00087366
Epoch [59/300], Train Loss: 0.001393
Validation Loss: 0.00089458
Epoch [60/300], Train Loss: 0.001265
Validation Loss: 0.00084242
Epoch [61/300], Train Loss: 0.001204
Validation Loss: 0.00079539
Epoch [62/300], Train Loss: 0.001091
Validation Loss: 0.00070176
Epoch [63/300], Train Loss: 0.000977
Validation Loss: 0.00069709
Epoch [64/300], Train Loss: 0.001057
Validation Loss: 0.00069669
Epoch [65/300], Train Loss: 0.001000
Validation Loss: 0.00068681
Epoch [66/300], Train Loss: 0.000956
Validation Loss: 0.00068212
Epoch [67/300], Train Loss: 0.001214
Validation Loss: 0.00079336
Epoch [68/300], Train Loss: 0.001147
Validation Loss: 0.00074288
Epoch [69/300], Train Loss: 0.003070
Validation Loss: 0.00773084
Epoch [70/300], Train Loss: 0.007604
Validation Loss: 0.00393334
Epoch [71/300], Train Loss: 0.004298
Validation Loss: 0.00222785
Epoch [72/300], Train Loss: 0.002932
Validation Loss: 0.00174631
Epoch [73/300], Train Loss: 0.002318
Validation Loss: 0.00150448
Epoch [74/300], Train Loss: 0.002225
Validation Loss: 0.00148403
Epoch [75/300], Train Loss: 0.002330
Validation Loss: 0.00145956
Epoch [76/300], Train Loss: 0.002414
Validation Loss: 0.00141454
Early stopping triggered

Evaluating model for: Dryer
Run 17/72 completed in 108.89 seconds with: {'MAE': np.float32(8.55314), 'MSE': np.float32(3430.3623), 'RMSE': np.float32(58.569294), 'SAE': np.float32(0.04751488), 'NDE': np.float32(0.49927276)}

Run 18/72: hidden=128, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Dryer
Dataset length: 1470 windows

Epoch [1/300], Train Loss: 0.010690
Validation Loss: 0.00816377
Epoch [2/300], Train Loss: 0.009778
Validation Loss: 0.00813125
Epoch [3/300], Train Loss: 0.009742
Validation Loss: 0.00808666
Epoch [4/300], Train Loss: 0.009891
Validation Loss: 0.00806171
Epoch [5/300], Train Loss: 0.010021
Validation Loss: 0.00802270
Epoch [6/300], Train Loss: 0.010239
Validation Loss: 0.00796019
Epoch [7/300], Train Loss: 0.010405
Validation Loss: 0.00782994
Epoch [8/300], Train Loss: 0.010133
Validation Loss: 0.00761396
Epoch [9/300], Train Loss: 0.008985
Validation Loss: 0.00709590
Epoch [10/300], Train Loss: 0.009165
Validation Loss: 0.00611834
Epoch [11/300], Train Loss: 0.008076
Validation Loss: 0.00349581
Epoch [12/300], Train Loss: 0.003889
Validation Loss: 0.00244435
Epoch [13/300], Train Loss: 0.003483
Validation Loss: 0.00201337
Epoch [14/300], Train Loss: 0.003065
Validation Loss: 0.00183210
Epoch [15/300], Train Loss: 0.003021
Validation Loss: 0.00168528
Epoch [16/300], Train Loss: 0.002597
Validation Loss: 0.00159882
Epoch [17/300], Train Loss: 0.002484
Validation Loss: 0.00161758
Epoch [18/300], Train Loss: 0.002467
Validation Loss: 0.00152527
Epoch [19/300], Train Loss: 0.002421
Validation Loss: 0.00141684
Epoch [20/300], Train Loss: 0.002561
Validation Loss: 0.00139268
Epoch [21/300], Train Loss: 0.002286
Validation Loss: 0.00140386
Epoch [22/300], Train Loss: 0.002242
Validation Loss: 0.00132513
Epoch [23/300], Train Loss: 0.002076
Validation Loss: 0.00128872
Epoch [24/300], Train Loss: 0.002010
Validation Loss: 0.00134957
Epoch [25/300], Train Loss: 0.001983
Validation Loss: 0.00130596
Epoch [26/300], Train Loss: 0.001870
Validation Loss: 0.00125897
Epoch [27/300], Train Loss: 0.001801
Validation Loss: 0.00122360
Epoch [28/300], Train Loss: 0.002257
Validation Loss: 0.00159970
Epoch [29/300], Train Loss: 0.002580
Validation Loss: 0.00139107
Epoch [30/300], Train Loss: 0.002075
Validation Loss: 0.00142025
Epoch [31/300], Train Loss: 0.002412
Validation Loss: 0.00131829
Epoch [32/300], Train Loss: 0.002008
Validation Loss: 0.00128480
Epoch [33/300], Train Loss: 0.002293
Validation Loss: 0.00129924
Epoch [34/300], Train Loss: 0.002063
Validation Loss: 0.00130442
Epoch [35/300], Train Loss: 0.001862
Validation Loss: 0.00125195
Epoch [36/300], Train Loss: 0.002059
Validation Loss: 0.00122546
Epoch [37/300], Train Loss: 0.001822
Validation Loss: 0.00126800
Early stopping triggered

Evaluating model for: Dryer
Run 18/72 completed in 59.47 seconds with: {'MAE': np.float32(9.490904), 'MSE': np.float32(2420.9316), 'RMSE': np.float32(49.202965), 'SAE': np.float32(0.072325386), 'NDE': np.float32(0.41943005)}

Run 19/72: hidden=128, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Dryer
Dataset length: 1470 windows

Epoch [1/300], Train Loss: 0.010711
Validation Loss: 0.00815170
Epoch [2/300], Train Loss: 0.009797
Validation Loss: 0.00816364
Epoch [3/300], Train Loss: 0.009792
Validation Loss: 0.00815006
Epoch [4/300], Train Loss: 0.009967
Validation Loss: 0.00814385
Epoch [5/300], Train Loss: 0.010141
Validation Loss: 0.00813956
Epoch [6/300], Train Loss: 0.010413
Validation Loss: 0.00814837
Epoch [7/300], Train Loss: 0.010699
Validation Loss: 0.00812301
Epoch [8/300], Train Loss: 0.010639
Validation Loss: 0.00810840
Epoch [9/300], Train Loss: 0.009787
Validation Loss: 0.00807125
Epoch [10/300], Train Loss: 0.010981
Validation Loss: 0.00798631
Epoch [11/300], Train Loss: 0.013377
Validation Loss: 0.00780664
Epoch [12/300], Train Loss: 0.010626
Validation Loss: 0.00729756
Epoch [13/300], Train Loss: 0.009432
Validation Loss: 0.00611848
Epoch [14/300], Train Loss: 0.007470
Validation Loss: 0.00405361
Epoch [15/300], Train Loss: 0.004875
Validation Loss: 0.00223397
Epoch [16/300], Train Loss: 0.003537
Validation Loss: 0.00213673
Epoch [17/300], Train Loss: 0.003336
Validation Loss: 0.00178112
Epoch [18/300], Train Loss: 0.003082
Validation Loss: 0.00172160
Epoch [19/300], Train Loss: 0.003105
Validation Loss: 0.00166448
Epoch [20/300], Train Loss: 0.003333
Validation Loss: 0.00161886
Epoch [21/300], Train Loss: 0.003073
Validation Loss: 0.00152322
Epoch [22/300], Train Loss: 0.002993
Validation Loss: 0.00155181
Epoch [23/300], Train Loss: 0.003037
Validation Loss: 0.00148127
Epoch [24/300], Train Loss: 0.002888
Validation Loss: 0.00148245
Epoch [25/300], Train Loss: 0.003105
Validation Loss: 0.00145876
Epoch [26/300], Train Loss: 0.002756
Validation Loss: 0.00142993
Epoch [27/300], Train Loss: 0.002444
Validation Loss: 0.00152331
Epoch [28/300], Train Loss: 0.002471
Validation Loss: 0.00145042
Epoch [29/300], Train Loss: 0.002556
Validation Loss: 0.00156261
Epoch [30/300], Train Loss: 0.002305
Validation Loss: 0.00164491
Epoch [31/300], Train Loss: 0.002521
Validation Loss: 0.00156408
Epoch [32/300], Train Loss: 0.002322
Validation Loss: 0.00155990
Epoch [33/300], Train Loss: 0.002545
Validation Loss: 0.00147677
Epoch [34/300], Train Loss: 0.002236
Validation Loss: 0.00163792
Epoch [35/300], Train Loss: 0.002271
Validation Loss: 0.00158707
Epoch [36/300], Train Loss: 0.002410
Validation Loss: 0.00145955
Early stopping triggered

Evaluating model for: Dryer
Run 19/72 completed in 60.46 seconds with: {'MAE': np.float32(8.835562), 'MSE': np.float32(3265.3022), 'RMSE': np.float32(57.142822), 'SAE': np.float32(0.06328936), 'NDE': np.float32(0.4871132)}

Run 20/72: hidden=128, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Dryer
Dataset length: 1470 windows

Epoch [1/300], Train Loss: 0.010702
Validation Loss: 0.00816115
Epoch [2/300], Train Loss: 0.009801
Validation Loss: 0.00816958
Epoch [3/300], Train Loss: 0.009795
Validation Loss: 0.00814958
Epoch [4/300], Train Loss: 0.009971
Validation Loss: 0.00814542
Epoch [5/300], Train Loss: 0.010146
Validation Loss: 0.00814364
Epoch [6/300], Train Loss: 0.010419
Validation Loss: 0.00815215
Epoch [7/300], Train Loss: 0.010708
Validation Loss: 0.00812923
Epoch [8/300], Train Loss: 0.010645
Validation Loss: 0.00809973
Epoch [9/300], Train Loss: 0.009759
Validation Loss: 0.00801591
Epoch [10/300], Train Loss: 0.010814
Validation Loss: 0.00772890
Epoch [11/300], Train Loss: 0.012156
Validation Loss: 0.00638484
Epoch [12/300], Train Loss: 0.006451
Validation Loss: 0.00276272
Epoch [13/300], Train Loss: 0.003943
Validation Loss: 0.00199978
Epoch [14/300], Train Loss: 0.002916
Validation Loss: 0.00183185
Epoch [15/300], Train Loss: 0.002671
Validation Loss: 0.00143012
Epoch [16/300], Train Loss: 0.002330
Validation Loss: 0.00149273
Epoch [17/300], Train Loss: 0.002232
Validation Loss: 0.00143648
Epoch [18/300], Train Loss: 0.002225
Validation Loss: 0.00144212
Epoch [19/300], Train Loss: 0.002271
Validation Loss: 0.00139821
Epoch [20/300], Train Loss: 0.002513
Validation Loss: 0.00142473
Epoch [21/300], Train Loss: 0.002334
Validation Loss: 0.00142888
Epoch [22/300], Train Loss: 0.002379
Validation Loss: 0.00141001
Epoch [23/300], Train Loss: 0.002311
Validation Loss: 0.00139697
Epoch [24/300], Train Loss: 0.002404
Validation Loss: 0.00143263
Epoch [25/300], Train Loss: 0.002311
Validation Loss: 0.00139235
Epoch [26/300], Train Loss: 0.002159
Validation Loss: 0.00139852
Epoch [27/300], Train Loss: 0.001971
Validation Loss: 0.00139289
Epoch [28/300], Train Loss: 0.002033
Validation Loss: 0.00135800
Epoch [29/300], Train Loss: 0.002140
Validation Loss: 0.00130639
Epoch [30/300], Train Loss: 0.001876
Validation Loss: 0.00132886
Epoch [31/300], Train Loss: 0.002002
Validation Loss: 0.00131526
Epoch [32/300], Train Loss: 0.001943
Validation Loss: 0.00126763
Epoch [33/300], Train Loss: 0.001926
Validation Loss: 0.00125122
Epoch [34/300], Train Loss: 0.002015
Validation Loss: 0.00130828
Epoch [35/300], Train Loss: 0.001787
Validation Loss: 0.00113366
Epoch [36/300], Train Loss: 0.001560
Validation Loss: 0.00121368
Epoch [37/300], Train Loss: 0.001456
Validation Loss: 0.00122896
Epoch [38/300], Train Loss: 0.001363
Validation Loss: 0.00100928
Epoch [39/300], Train Loss: 0.001410
Validation Loss: 0.00083447
Epoch [40/300], Train Loss: 0.001057
Validation Loss: 0.00084741
Epoch [41/300], Train Loss: 0.001466
Validation Loss: 0.00080836
Epoch [42/300], Train Loss: 0.001096
Validation Loss: 0.00080767
Epoch [43/300], Train Loss: 0.001015
Validation Loss: 0.00077536
Epoch [44/300], Train Loss: 0.001000
Validation Loss: 0.00073777
Epoch [45/300], Train Loss: 0.001279
Validation Loss: 0.00097436
Epoch [46/300], Train Loss: 0.001428
Validation Loss: 0.00076005
Epoch [47/300], Train Loss: 0.001110
Validation Loss: 0.00068395
Epoch [48/300], Train Loss: 0.000947
Validation Loss: 0.00115119
Epoch [49/300], Train Loss: 0.001023
Validation Loss: 0.00069701
Epoch [50/300], Train Loss: 0.000950
Validation Loss: 0.00065153
Epoch [51/300], Train Loss: 0.000858
Validation Loss: 0.00064847
Epoch [52/300], Train Loss: 0.000918
Validation Loss: 0.00065880
Epoch [53/300], Train Loss: 0.000841
Validation Loss: 0.00067677
Epoch [54/300], Train Loss: 0.000917
Validation Loss: 0.00067266
Epoch [55/300], Train Loss: 0.000817
Validation Loss: 0.00066978
Epoch [56/300], Train Loss: 0.003838
Validation Loss: 0.00398090
Epoch [57/300], Train Loss: 0.001774
Validation Loss: 0.00084441
Epoch [58/300], Train Loss: 0.001303
Validation Loss: 0.00084392
Epoch [59/300], Train Loss: 0.001391
Validation Loss: 0.00235411
Epoch [60/300], Train Loss: 0.001209
Validation Loss: 0.00099043
Epoch [61/300], Train Loss: 0.001209
Validation Loss: 0.00088792
Early stopping triggered

Evaluating model for: Dryer
Run 20/72 completed in 108.00 seconds with: {'MAE': np.float32(5.7510686), 'MSE': np.float32(1692.7535), 'RMSE': np.float32(41.143085), 'SAE': np.float32(0.13025707), 'NDE': np.float32(0.35072386)}

Run 21/72: hidden=128, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Dryer
Dataset length: 746 windows

Epoch [1/300], Train Loss: 0.012825
Validation Loss: 0.00941410
Epoch [2/300], Train Loss: 0.011669
Validation Loss: 0.00912185
Epoch [3/300], Train Loss: 0.012415
Validation Loss: 0.00896113
Epoch [4/300], Train Loss: 0.011714
Validation Loss: 0.00889957
Epoch [5/300], Train Loss: 0.011918
Validation Loss: 0.00887843
Epoch [6/300], Train Loss: 0.012013
Validation Loss: 0.00886290
Epoch [7/300], Train Loss: 0.011283
Validation Loss: 0.00885929
Epoch [8/300], Train Loss: 0.012502
Validation Loss: 0.00885073
Epoch [9/300], Train Loss: 0.011733
Validation Loss: 0.00884669
Epoch [10/300], Train Loss: 0.011775
Validation Loss: 0.00883569
Epoch [11/300], Train Loss: 0.011886
Validation Loss: 0.00880419
Epoch [12/300], Train Loss: 0.011776
Validation Loss: 0.00876933
Epoch [13/300], Train Loss: 0.011654
Validation Loss: 0.00872908
Epoch [14/300], Train Loss: 0.011755
Validation Loss: 0.00869493
Epoch [15/300], Train Loss: 0.011207
Validation Loss: 0.00865867
Epoch [16/300], Train Loss: 0.011160
Validation Loss: 0.00860803
Epoch [17/300], Train Loss: 0.011855
Validation Loss: 0.00854523
Epoch [18/300], Train Loss: 0.011489
Validation Loss: 0.00847909
Epoch [19/300], Train Loss: 0.010815
Validation Loss: 0.00839897
Epoch [20/300], Train Loss: 0.011283
Validation Loss: 0.00827403
Epoch [21/300], Train Loss: 0.010592
Validation Loss: 0.00811602
Epoch [22/300], Train Loss: 0.010663
Validation Loss: 0.00791657
Epoch [23/300], Train Loss: 0.010459
Validation Loss: 0.00766681
Epoch [24/300], Train Loss: 0.010065
Validation Loss: 0.00733530
Epoch [25/300], Train Loss: 0.009050
Validation Loss: 0.00688562
Epoch [26/300], Train Loss: 0.008732
Validation Loss: 0.00633180
Epoch [27/300], Train Loss: 0.007838
Validation Loss: 0.00565202
Epoch [28/300], Train Loss: 0.006230
Validation Loss: 0.00492473
Epoch [29/300], Train Loss: 0.004902
Validation Loss: 0.00423953
Epoch [30/300], Train Loss: 0.003841
Validation Loss: 0.00363415
Epoch [31/300], Train Loss: 0.003256
Validation Loss: 0.00314863
Epoch [32/300], Train Loss: 0.003083
Validation Loss: 0.00296119
Epoch [33/300], Train Loss: 0.002985
Validation Loss: 0.00282641
Epoch [34/300], Train Loss: 0.002985
Validation Loss: 0.00270625
Epoch [35/300], Train Loss: 0.002866
Validation Loss: 0.00254952
Epoch [36/300], Train Loss: 0.002887
Validation Loss: 0.00245963
Epoch [37/300], Train Loss: 0.002719
Validation Loss: 0.00239398
Epoch [38/300], Train Loss: 0.002596
Validation Loss: 0.00236020
Epoch [39/300], Train Loss: 0.002688
Validation Loss: 0.00230791
Epoch [40/300], Train Loss: 0.002616
Validation Loss: 0.00226537
Epoch [41/300], Train Loss: 0.002740
Validation Loss: 0.00224046
Epoch [42/300], Train Loss: 0.002674
Validation Loss: 0.00221318
Epoch [43/300], Train Loss: 0.002574
Validation Loss: 0.00219833
Epoch [44/300], Train Loss: 0.002448
Validation Loss: 0.00220223
Epoch [45/300], Train Loss: 0.002453
Validation Loss: 0.00217378
Epoch [46/300], Train Loss: 0.002509
Validation Loss: 0.00215487
Epoch [47/300], Train Loss: 0.002411
Validation Loss: 0.00214564
Epoch [48/300], Train Loss: 0.002411
Validation Loss: 0.00214615
Epoch [49/300], Train Loss: 0.002414
Validation Loss: 0.00212648
Epoch [50/300], Train Loss: 0.002472
Validation Loss: 0.00212273
Epoch [51/300], Train Loss: 0.002492
Validation Loss: 0.00210361
Epoch [52/300], Train Loss: 0.002449
Validation Loss: 0.00209883
Epoch [53/300], Train Loss: 0.002459
Validation Loss: 0.00209011
Epoch [54/300], Train Loss: 0.002341
Validation Loss: 0.00206328
Epoch [55/300], Train Loss: 0.002328
Validation Loss: 0.00205514
Epoch [56/300], Train Loss: 0.002399
Validation Loss: 0.00205895
Epoch [57/300], Train Loss: 0.002380
Validation Loss: 0.00202902
Epoch [58/300], Train Loss: 0.002267
Validation Loss: 0.00200575
Epoch [59/300], Train Loss: 0.002192
Validation Loss: 0.00203341
Epoch [60/300], Train Loss: 0.002356
Validation Loss: 0.00203564
Epoch [61/300], Train Loss: 0.002354
Validation Loss: 0.00196717
Epoch [62/300], Train Loss: 0.002133
Validation Loss: 0.00193186
Epoch [63/300], Train Loss: 0.002122
Validation Loss: 0.00194296
Epoch [64/300], Train Loss: 0.002222
Validation Loss: 0.00197042
Epoch [65/300], Train Loss: 0.002261
Validation Loss: 0.00194140
Epoch [66/300], Train Loss: 0.002024
Validation Loss: 0.00189531
Epoch [67/300], Train Loss: 0.002145
Validation Loss: 0.00189549
Epoch [68/300], Train Loss: 0.002025
Validation Loss: 0.00186635
Epoch [69/300], Train Loss: 0.002124
Validation Loss: 0.00185418
Epoch [70/300], Train Loss: 0.002069
Validation Loss: 0.00187052
Epoch [71/300], Train Loss: 0.002014
Validation Loss: 0.00181653
Epoch [72/300], Train Loss: 0.001997
Validation Loss: 0.00181794
Epoch [73/300], Train Loss: 0.001954
Validation Loss: 0.00182657
Epoch [74/300], Train Loss: 0.001973
Validation Loss: 0.00177033
Epoch [75/300], Train Loss: 0.001873
Validation Loss: 0.00173770
Epoch [76/300], Train Loss: 0.001879
Validation Loss: 0.00176783
Epoch [77/300], Train Loss: 0.001796
Validation Loss: 0.00170774
Epoch [78/300], Train Loss: 0.001811
Validation Loss: 0.00170289
Epoch [79/300], Train Loss: 0.001858
Validation Loss: 0.00167006
Epoch [80/300], Train Loss: 0.001838
Validation Loss: 0.00162121
Epoch [81/300], Train Loss: 0.001761
Validation Loss: 0.00162234
Epoch [82/300], Train Loss: 0.001706
Validation Loss: 0.00153488
Epoch [83/300], Train Loss: 0.001701
Validation Loss: 0.00146107
Epoch [84/300], Train Loss: 0.001646
Validation Loss: 0.00147186
Epoch [85/300], Train Loss: 0.001659
Validation Loss: 0.00145909
Epoch [86/300], Train Loss: 0.001613
Validation Loss: 0.00140004
Epoch [87/300], Train Loss: 0.001779
Validation Loss: 0.00157628
Epoch [88/300], Train Loss: 0.001874
Validation Loss: 0.00220234
Epoch [89/300], Train Loss: 0.001955
Validation Loss: 0.00175953
Epoch [90/300], Train Loss: 0.001820
Validation Loss: 0.00176447
Epoch [91/300], Train Loss: 0.001715
Validation Loss: 0.00163490
Epoch [92/300], Train Loss: 0.001603
Validation Loss: 0.00155977
Epoch [93/300], Train Loss: 0.001610
Validation Loss: 0.00156264
Epoch [94/300], Train Loss: 0.001616
Validation Loss: 0.00159163
Epoch [95/300], Train Loss: 0.001586
Validation Loss: 0.00147026
Epoch [96/300], Train Loss: 0.001501
Validation Loss: 0.00142425
Early stopping triggered

Evaluating model for: Dryer
Run 21/72 completed in 70.62 seconds with: {'MAE': np.float32(5.283154), 'MSE': np.float32(827.2517), 'RMSE': np.float32(28.761984), 'SAE': np.float32(0.6444113), 'NDE': np.float32(0.4497931)}

Run 22/72: hidden=128, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Dryer
Dataset length: 746 windows

Epoch [1/300], Train Loss: 0.014793
Validation Loss: 0.01041404
Epoch [2/300], Train Loss: 0.012978
Validation Loss: 0.00977050
Epoch [3/300], Train Loss: 0.013326
Validation Loss: 0.00932312
Epoch [4/300], Train Loss: 0.012177
Validation Loss: 0.00904033
Epoch [5/300], Train Loss: 0.012122
Validation Loss: 0.00892220
Epoch [6/300], Train Loss: 0.012078
Validation Loss: 0.00893035
Epoch [7/300], Train Loss: 0.011373
Validation Loss: 0.00900159
Epoch [8/300], Train Loss: 0.012612
Validation Loss: 0.00899753
Epoch [9/300], Train Loss: 0.011867
Validation Loss: 0.00897190
Epoch [10/300], Train Loss: 0.011912
Validation Loss: 0.00893196
Epoch [11/300], Train Loss: 0.012044
Validation Loss: 0.00890122
Epoch [12/300], Train Loss: 0.011960
Validation Loss: 0.00888644
Epoch [13/300], Train Loss: 0.011871
Validation Loss: 0.00887563
Epoch [14/300], Train Loss: 0.012014
Validation Loss: 0.00887027
Epoch [15/300], Train Loss: 0.011490
Validation Loss: 0.00886928
Epoch [16/300], Train Loss: 0.011501
Validation Loss: 0.00886102
Epoch [17/300], Train Loss: 0.012286
Validation Loss: 0.00884718
Epoch [18/300], Train Loss: 0.011979
Validation Loss: 0.00883516
Epoch [19/300], Train Loss: 0.011368
Validation Loss: 0.00882442
Epoch [20/300], Train Loss: 0.011995
Validation Loss: 0.00880036
Epoch [21/300], Train Loss: 0.011422
Validation Loss: 0.00877117
Epoch [22/300], Train Loss: 0.011716
Validation Loss: 0.00872268
Epoch [23/300], Train Loss: 0.011797
Validation Loss: 0.00867650
Epoch [24/300], Train Loss: 0.011752
Validation Loss: 0.00862722
Epoch [25/300], Train Loss: 0.011055
Validation Loss: 0.00856004
Epoch [26/300], Train Loss: 0.011514
Validation Loss: 0.00841865
Epoch [27/300], Train Loss: 0.011697
Validation Loss: 0.00820236
Epoch [28/300], Train Loss: 0.010464
Validation Loss: 0.00792044
Epoch [29/300], Train Loss: 0.010202
Validation Loss: 0.00717836
Epoch [30/300], Train Loss: 0.008183
Validation Loss: 0.00579206
Epoch [31/300], Train Loss: 0.005473
Validation Loss: 0.00338112
Epoch [32/300], Train Loss: 0.003789
Validation Loss: 0.00300171
Epoch [33/300], Train Loss: 0.003757
Validation Loss: 0.00299555
Epoch [34/300], Train Loss: 0.003474
Validation Loss: 0.00288653
Epoch [35/300], Train Loss: 0.002953
Validation Loss: 0.00246557
Epoch [36/300], Train Loss: 0.002985
Validation Loss: 0.00246342
Epoch [37/300], Train Loss: 0.002850
Validation Loss: 0.00239885
Epoch [38/300], Train Loss: 0.002631
Validation Loss: 0.00223168
Epoch [39/300], Train Loss: 0.002709
Validation Loss: 0.00216619
Epoch [40/300], Train Loss: 0.002618
Validation Loss: 0.00220337
Epoch [41/300], Train Loss: 0.002769
Validation Loss: 0.00210183
Epoch [42/300], Train Loss: 0.002650
Validation Loss: 0.00208046
Epoch [43/300], Train Loss: 0.002537
Validation Loss: 0.00207596
Epoch [44/300], Train Loss: 0.002430
Validation Loss: 0.00203772
Epoch [45/300], Train Loss: 0.002443
Validation Loss: 0.00206006
Epoch [46/300], Train Loss: 0.002486
Validation Loss: 0.00200116
Epoch [47/300], Train Loss: 0.002380
Validation Loss: 0.00199388
Epoch [48/300], Train Loss: 0.002379
Validation Loss: 0.00197568
Epoch [49/300], Train Loss: 0.002335
Validation Loss: 0.00196167
Epoch [50/300], Train Loss: 0.002414
Validation Loss: 0.00193258
Epoch [51/300], Train Loss: 0.002434
Validation Loss: 0.00196649
Epoch [52/300], Train Loss: 0.002363
Validation Loss: 0.00190640
Epoch [53/300], Train Loss: 0.002305
Validation Loss: 0.00185072
Epoch [54/300], Train Loss: 0.002192
Validation Loss: 0.00184379
Epoch [55/300], Train Loss: 0.002169
Validation Loss: 0.00180201
Epoch [56/300], Train Loss: 0.002139
Validation Loss: 0.00174553
Epoch [57/300], Train Loss: 0.002126
Validation Loss: 0.00176749
Epoch [58/300], Train Loss: 0.002050
Validation Loss: 0.00171012
Epoch [59/300], Train Loss: 0.001966
Validation Loss: 0.00161608
Epoch [60/300], Train Loss: 0.001985
Validation Loss: 0.00158107
Epoch [61/300], Train Loss: 0.001962
Validation Loss: 0.00149012
Epoch [62/300], Train Loss: 0.001837
Validation Loss: 0.00153906
Epoch [63/300], Train Loss: 0.001804
Validation Loss: 0.00151612
Epoch [64/300], Train Loss: 0.001842
Validation Loss: 0.00147471
Epoch [65/300], Train Loss: 0.001932
Validation Loss: 0.00140054
Epoch [66/300], Train Loss: 0.001950
Validation Loss: 0.00246475
Epoch [67/300], Train Loss: 0.003429
Validation Loss: 0.00256029
Epoch [68/300], Train Loss: 0.002385
Validation Loss: 0.00212765
Epoch [69/300], Train Loss: 0.002611
Validation Loss: 0.00227502
Epoch [70/300], Train Loss: 0.002108
Validation Loss: 0.00165599
Epoch [71/300], Train Loss: 0.001896
Validation Loss: 0.00163112
Epoch [72/300], Train Loss: 0.001919
Validation Loss: 0.00158320
Epoch [73/300], Train Loss: 0.001793
Validation Loss: 0.00150142
Epoch [74/300], Train Loss: 0.001766
Validation Loss: 0.00152096
Epoch [75/300], Train Loss: 0.001715
Validation Loss: 0.00152333
Early stopping triggered

Evaluating model for: Dryer
Run 22/72 completed in 59.85 seconds with: {'MAE': np.float32(6.627277), 'MSE': np.float32(995.62646), 'RMSE': np.float32(31.553549), 'SAE': np.float32(0.4790208), 'NDE': np.float32(0.4934489)}

Run 23/72: hidden=128, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Dryer
Dataset length: 746 windows

Epoch [1/300], Train Loss: 0.013807
Validation Loss: 0.00966944
Epoch [2/300], Train Loss: 0.012235
Validation Loss: 0.00923491
Epoch [3/300], Train Loss: 0.012750
Validation Loss: 0.00898332
Epoch [4/300], Train Loss: 0.011819
Validation Loss: 0.00889003
Epoch [5/300], Train Loss: 0.011937
Validation Loss: 0.00892605
Epoch [6/300], Train Loss: 0.012033
Validation Loss: 0.00898679
Epoch [7/300], Train Loss: 0.011369
Validation Loss: 0.00899728
Epoch [8/300], Train Loss: 0.012593
Validation Loss: 0.00893495
Epoch [9/300], Train Loss: 0.011819
Validation Loss: 0.00890663
Epoch [10/300], Train Loss: 0.011877
Validation Loss: 0.00888763
Epoch [11/300], Train Loss: 0.012016
Validation Loss: 0.00887397
Epoch [12/300], Train Loss: 0.011929
Validation Loss: 0.00886840
Epoch [13/300], Train Loss: 0.011830
Validation Loss: 0.00886046
Epoch [14/300], Train Loss: 0.011962
Validation Loss: 0.00885627
Epoch [15/300], Train Loss: 0.011439
Validation Loss: 0.00884492
Epoch [16/300], Train Loss: 0.011428
Validation Loss: 0.00881183
Epoch [17/300], Train Loss: 0.012167
Validation Loss: 0.00876965
Epoch [18/300], Train Loss: 0.011822
Validation Loss: 0.00872638
Epoch [19/300], Train Loss: 0.011158
Validation Loss: 0.00867060
Epoch [20/300], Train Loss: 0.011642
Validation Loss: 0.00855472
Epoch [21/300], Train Loss: 0.010901
Validation Loss: 0.00835456
Epoch [22/300], Train Loss: 0.010780
Validation Loss: 0.00797726
Epoch [23/300], Train Loss: 0.009974
Validation Loss: 0.00728003
Epoch [24/300], Train Loss: 0.007965
Validation Loss: 0.00575118
Epoch [25/300], Train Loss: 0.005046
Validation Loss: 0.00355887
Epoch [26/300], Train Loss: 0.003724
Validation Loss: 0.00356146
Epoch [27/300], Train Loss: 0.003992
Validation Loss: 0.00353823
Epoch [28/300], Train Loss: 0.003854
Validation Loss: 0.00333758
Epoch [29/300], Train Loss: 0.003332
Validation Loss: 0.00321791
Epoch [30/300], Train Loss: 0.003150
Validation Loss: 0.00302283
Epoch [31/300], Train Loss: 0.003040
Validation Loss: 0.00298977
Epoch [32/300], Train Loss: 0.003114
Validation Loss: 0.00313032
Epoch [33/300], Train Loss: 0.002984
Validation Loss: 0.00288224
Epoch [34/300], Train Loss: 0.003043
Validation Loss: 0.00282901
Epoch [35/300], Train Loss: 0.002953
Validation Loss: 0.00288641
Epoch [36/300], Train Loss: 0.002988
Validation Loss: 0.00280717
Epoch [37/300], Train Loss: 0.002876
Validation Loss: 0.00279670
Epoch [38/300], Train Loss: 0.002747
Validation Loss: 0.00277486
Epoch [39/300], Train Loss: 0.002875
Validation Loss: 0.00282772
Epoch [40/300], Train Loss: 0.002784
Validation Loss: 0.00278248
Epoch [41/300], Train Loss: 0.002919
Validation Loss: 0.00276928
Epoch [42/300], Train Loss: 0.002855
Validation Loss: 0.00277517
Epoch [43/300], Train Loss: 0.002747
Validation Loss: 0.00279348
Epoch [44/300], Train Loss: 0.002622
Validation Loss: 0.00279542
Epoch [45/300], Train Loss: 0.002665
Validation Loss: 0.00273664
Epoch [46/300], Train Loss: 0.002720
Validation Loss: 0.00276054
Epoch [47/300], Train Loss: 0.002632
Validation Loss: 0.00275015
Epoch [48/300], Train Loss: 0.002639
Validation Loss: 0.00273969
Epoch [49/300], Train Loss: 0.002620
Validation Loss: 0.00272516
Epoch [50/300], Train Loss: 0.002707
Validation Loss: 0.00275570
Epoch [51/300], Train Loss: 0.002732
Validation Loss: 0.00270506
Epoch [52/300], Train Loss: 0.002704
Validation Loss: 0.00269776
Epoch [53/300], Train Loss: 0.002700
Validation Loss: 0.00270055
Epoch [54/300], Train Loss: 0.002577
Validation Loss: 0.00266913
Epoch [55/300], Train Loss: 0.002570
Validation Loss: 0.00266046
Epoch [56/300], Train Loss: 0.002649
Validation Loss: 0.00266358
Epoch [57/300], Train Loss: 0.002643
Validation Loss: 0.00264434
Epoch [58/300], Train Loss: 0.002538
Validation Loss: 0.00262451
Epoch [59/300], Train Loss: 0.002472
Validation Loss: 0.00262223
Epoch [60/300], Train Loss: 0.002660
Validation Loss: 0.00264645
Epoch [61/300], Train Loss: 0.002677
Validation Loss: 0.00259573
Epoch [62/300], Train Loss: 0.002394
Validation Loss: 0.00257809
Epoch [63/300], Train Loss: 0.002456
Validation Loss: 0.00255608
Epoch [64/300], Train Loss: 0.002553
Validation Loss: 0.00257017
Epoch [65/300], Train Loss: 0.002581
Validation Loss: 0.00256812
Epoch [66/300], Train Loss: 0.002337
Validation Loss: 0.00253129
Epoch [67/300], Train Loss: 0.002468
Validation Loss: 0.00250862
Epoch [68/300], Train Loss: 0.002347
Validation Loss: 0.00248845
Epoch [69/300], Train Loss: 0.002483
Validation Loss: 0.00248587
Epoch [70/300], Train Loss: 0.002395
Validation Loss: 0.00245356
Epoch [71/300], Train Loss: 0.002314
Validation Loss: 0.00240240
Epoch [72/300], Train Loss: 0.002275
Validation Loss: 0.00241046
Epoch [73/300], Train Loss: 0.002209
Validation Loss: 0.00235460
Epoch [74/300], Train Loss: 0.002216
Validation Loss: 0.00232793
Epoch [75/300], Train Loss: 0.002066
Validation Loss: 0.00225609
Epoch [76/300], Train Loss: 0.002066
Validation Loss: 0.00224422
Epoch [77/300], Train Loss: 0.001930
Validation Loss: 0.00213074
Epoch [78/300], Train Loss: 0.001907
Validation Loss: 0.00213915
Epoch [79/300], Train Loss: 0.001982
Validation Loss: 0.00207462
Epoch [80/300], Train Loss: 0.001839
Validation Loss: 0.00185666
Epoch [81/300], Train Loss: 0.001741
Validation Loss: 0.00202174
Epoch [82/300], Train Loss: 0.001735
Validation Loss: 0.00178325
Epoch [83/300], Train Loss: 0.001696
Validation Loss: 0.00176861
Epoch [84/300], Train Loss: 0.001590
Validation Loss: 0.00171732
Epoch [85/300], Train Loss: 0.001506
Validation Loss: 0.00161926
Epoch [86/300], Train Loss: 0.001515
Validation Loss: 0.00165005
Epoch [87/300], Train Loss: 0.001351
Validation Loss: 0.00140643
Epoch [88/300], Train Loss: 0.001327
Validation Loss: 0.00144420
Epoch [89/300], Train Loss: 0.001232
Validation Loss: 0.00133824
Epoch [90/300], Train Loss: 0.001224
Validation Loss: 0.00124798
Epoch [91/300], Train Loss: 0.001133
Validation Loss: 0.00130005
Epoch [92/300], Train Loss: 0.001116
Validation Loss: 0.00128864
Epoch [93/300], Train Loss: 0.001280
Validation Loss: 0.00136047
Epoch [94/300], Train Loss: 0.001204
Validation Loss: 0.00122040
Epoch [95/300], Train Loss: 0.001239
Validation Loss: 0.00121930
Epoch [96/300], Train Loss: 0.001206
Validation Loss: 0.00124639
Epoch [97/300], Train Loss: 0.001179
Validation Loss: 0.00126652
Epoch [98/300], Train Loss: 0.001179
Validation Loss: 0.00125066
Epoch [99/300], Train Loss: 0.001203
Validation Loss: 0.00123522
Epoch [100/300], Train Loss: 0.001219
Validation Loss: 0.00122498
Epoch [101/300], Train Loss: 0.001178
Validation Loss: 0.00122744
Epoch [102/300], Train Loss: 0.001178
Validation Loss: 0.00164951
Epoch [103/300], Train Loss: 0.001526
Validation Loss: 0.00148761
Epoch [104/300], Train Loss: 0.001298
Validation Loss: 0.00116808
Epoch [105/300], Train Loss: 0.001669
Validation Loss: 0.00125608
Epoch [106/300], Train Loss: 0.001300
Validation Loss: 0.00136219
Epoch [107/300], Train Loss: 0.001311
Validation Loss: 0.00146055
Epoch [108/300], Train Loss: 0.001246
Validation Loss: 0.00122668
Epoch [109/300], Train Loss: 0.001464
Validation Loss: 0.00121979
Epoch [110/300], Train Loss: 0.001130
Validation Loss: 0.00148155
Epoch [111/300], Train Loss: 0.001286
Validation Loss: 0.00139742
Epoch [112/300], Train Loss: 0.001174
Validation Loss: 0.00115288
Epoch [113/300], Train Loss: 0.001353
Validation Loss: 0.00115422
Epoch [114/300], Train Loss: 0.001196
Validation Loss: 0.00131038
Epoch [115/300], Train Loss: 0.001111
Validation Loss: 0.00120837
Epoch [116/300], Train Loss: 0.001114
Validation Loss: 0.00109841
Epoch [117/300], Train Loss: 0.001227
Validation Loss: 0.00119043
Epoch [118/300], Train Loss: 0.001178
Validation Loss: 0.00128453
Epoch [119/300], Train Loss: 0.001263
Validation Loss: 0.00142126
Epoch [120/300], Train Loss: 0.001170
Validation Loss: 0.00114425
Epoch [121/300], Train Loss: 0.001117
Validation Loss: 0.00105282
Epoch [122/300], Train Loss: 0.001117
Validation Loss: 0.00105984
Epoch [123/300], Train Loss: 0.001174
Validation Loss: 0.00111132
Epoch [124/300], Train Loss: 0.001091
Validation Loss: 0.00115046
Epoch [125/300], Train Loss: 0.001032
Validation Loss: 0.00111044
Epoch [126/300], Train Loss: 0.001013
Validation Loss: 0.00108015
Epoch [127/300], Train Loss: 0.001035
Validation Loss: 0.00107516
Epoch [128/300], Train Loss: 0.001021
Validation Loss: 0.00108371
Epoch [129/300], Train Loss: 0.001017
Validation Loss: 0.00113219
Epoch [130/300], Train Loss: 0.001064
Validation Loss: 0.00113466
Epoch [131/300], Train Loss: 0.001045
Validation Loss: 0.00105402
Early stopping triggered

Evaluating model for: Dryer
Run 23/72 completed in 108.92 seconds with: {'MAE': np.float32(4.5081396), 'MSE': np.float32(655.74115), 'RMSE': np.float32(25.607443), 'SAE': np.float32(0.129934), 'NDE': np.float32(0.400461)}

Run 24/72: hidden=128, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Dryer
Dataset length: 746 windows

Epoch [1/300], Train Loss: 0.013095
Validation Loss: 0.00960850
Epoch [2/300], Train Loss: 0.011777
Validation Loss: 0.00918799
Epoch [3/300], Train Loss: 0.012440
Validation Loss: 0.00896970
Epoch [4/300], Train Loss: 0.011729
Validation Loss: 0.00890825
Epoch [5/300], Train Loss: 0.011961
Validation Loss: 0.00890404
Epoch [6/300], Train Loss: 0.012087
Validation Loss: 0.00890338
Epoch [7/300], Train Loss: 0.011366
Validation Loss: 0.00891051
Epoch [8/300], Train Loss: 0.012616
Validation Loss: 0.00891895
Epoch [9/300], Train Loss: 0.011861
Validation Loss: 0.00893797
Epoch [10/300], Train Loss: 0.011933
Validation Loss: 0.00894707
Epoch [11/300], Train Loss: 0.012081
Validation Loss: 0.00893973
Epoch [12/300], Train Loss: 0.012003
Validation Loss: 0.00893109
Epoch [13/300], Train Loss: 0.011922
Validation Loss: 0.00891984
Epoch [14/300], Train Loss: 0.012080
Validation Loss: 0.00891649
Epoch [15/300], Train Loss: 0.011565
Validation Loss: 0.00891745
Epoch [16/300], Train Loss: 0.011594
Validation Loss: 0.00891567
Early stopping triggered

Evaluating model for: Dryer
Run 24/72 completed in 14.47 seconds with: {'MAE': np.float32(27.807644), 'MSE': np.float32(4359.1763), 'RMSE': np.float32(66.024055), 'SAE': np.float32(3.1561785), 'NDE': np.float32(1.0325147)}

Run 25/72: hidden=256, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Dryer
Dataset length: 9150 windows

Epoch [1/300], Train Loss: 0.010826
Validation Loss: 0.01187409
Epoch [2/300], Train Loss: 0.009850
Validation Loss: 0.00857161
Epoch [3/300], Train Loss: 0.004551
Validation Loss: 0.00311375
Epoch [4/300], Train Loss: 0.003063
Validation Loss: 0.00219394
Epoch [5/300], Train Loss: 0.002481
Validation Loss: 0.00202247
Epoch [6/300], Train Loss: 0.002076
Validation Loss: 0.00202919
Epoch [7/300], Train Loss: 0.001955
Validation Loss: 0.00189542
Epoch [8/300], Train Loss: 0.001941
Validation Loss: 0.00175165
Epoch [9/300], Train Loss: 0.002098
Validation Loss: 0.00207059
Epoch [10/300], Train Loss: 0.001856
Validation Loss: 0.00198665
Epoch [11/300], Train Loss: 0.001649
Validation Loss: 0.00180543
Epoch [12/300], Train Loss: 0.001557
Validation Loss: 0.00167883
Epoch [13/300], Train Loss: 0.001562
Validation Loss: 0.00168144
Epoch [14/300], Train Loss: 0.001618
Validation Loss: 0.00165995
Epoch [15/300], Train Loss: 0.001503
Validation Loss: 0.00178636
Epoch [16/300], Train Loss: 0.001422
Validation Loss: 0.00155906
Epoch [17/300], Train Loss: 0.001332
Validation Loss: 0.00151645
Epoch [18/300], Train Loss: 0.001302
Validation Loss: 0.00149022
Epoch [19/300], Train Loss: 0.001246
Validation Loss: 0.00151999
Epoch [20/300], Train Loss: 0.001236
Validation Loss: 0.00139564
Epoch [21/300], Train Loss: 0.001276
Validation Loss: 0.00133707
Epoch [22/300], Train Loss: 0.001260
Validation Loss: 0.00132230
Epoch [23/300], Train Loss: 0.001147
Validation Loss: 0.00127123
Epoch [24/300], Train Loss: 0.001134
Validation Loss: 0.00131072
Epoch [25/300], Train Loss: 0.001052
Validation Loss: 0.00122763
Epoch [26/300], Train Loss: 0.001248
Validation Loss: 0.00150618
Epoch [27/300], Train Loss: 0.001179
Validation Loss: 0.00116649
Epoch [28/300], Train Loss: 0.001181
Validation Loss: 0.00136879
Epoch [29/300], Train Loss: 0.001040
Validation Loss: 0.00113749
Epoch [30/300], Train Loss: 0.000998
Validation Loss: 0.00113557
Epoch [31/300], Train Loss: 0.000985
Validation Loss: 0.00110411
Epoch [32/300], Train Loss: 0.000949
Validation Loss: 0.00110726
Epoch [33/300], Train Loss: 0.000938
Validation Loss: 0.00108480
Epoch [34/300], Train Loss: 0.000907
Validation Loss: 0.00109471
Epoch [35/300], Train Loss: 0.000906
Validation Loss: 0.00110683
Epoch [36/300], Train Loss: 0.000893
Validation Loss: 0.00115936
Epoch [37/300], Train Loss: 0.000956
Validation Loss: 0.00109407
Epoch [38/300], Train Loss: 0.000922
Validation Loss: 0.00100652
Epoch [39/300], Train Loss: 0.000886
Validation Loss: 0.00107508
Epoch [40/300], Train Loss: 0.000855
Validation Loss: 0.00102722
Epoch [41/300], Train Loss: 0.000834
Validation Loss: 0.00102636
Epoch [42/300], Train Loss: 0.000813
Validation Loss: 0.00104703
Epoch [43/300], Train Loss: 0.000808
Validation Loss: 0.00103615
Epoch [44/300], Train Loss: 0.000824
Validation Loss: 0.00100493
Epoch [45/300], Train Loss: 0.000790
Validation Loss: 0.00106782
Epoch [46/300], Train Loss: 0.000832
Validation Loss: 0.00108565
Epoch [47/300], Train Loss: 0.000785
Validation Loss: 0.00101929
Epoch [48/300], Train Loss: 0.000779
Validation Loss: 0.00096229
Epoch [49/300], Train Loss: 0.000790
Validation Loss: 0.00100282
Epoch [50/300], Train Loss: 0.000731
Validation Loss: 0.00097411
Epoch [51/300], Train Loss: 0.000754
Validation Loss: 0.00106590
Epoch [52/300], Train Loss: 0.000751
Validation Loss: 0.00098527
Epoch [53/300], Train Loss: 0.000715
Validation Loss: 0.00098326
Epoch [54/300], Train Loss: 0.000744
Validation Loss: 0.00121079
Epoch [55/300], Train Loss: 0.000727
Validation Loss: 0.00094796
Epoch [56/300], Train Loss: 0.000707
Validation Loss: 0.00099031
Epoch [57/300], Train Loss: 0.000685
Validation Loss: 0.00094803
Epoch [58/300], Train Loss: 0.000681
Validation Loss: 0.00094773
Epoch [59/300], Train Loss: 0.000692
Validation Loss: 0.00094929
Epoch [60/300], Train Loss: 0.000666
Validation Loss: 0.00091573
Epoch [61/300], Train Loss: 0.000654
Validation Loss: 0.00093325
Epoch [62/300], Train Loss: 0.000684
Validation Loss: 0.00096339
Epoch [63/300], Train Loss: 0.000670
Validation Loss: 0.00095631
Epoch [64/300], Train Loss: 0.000638
Validation Loss: 0.00095925
Epoch [65/300], Train Loss: 0.000642
Validation Loss: 0.00088375
Epoch [66/300], Train Loss: 0.000661
Validation Loss: 0.00092857
Epoch [67/300], Train Loss: 0.000624
Validation Loss: 0.00090726
Epoch [68/300], Train Loss: 0.000608
Validation Loss: 0.00086692
Epoch [69/300], Train Loss: 0.000616
Validation Loss: 0.00089737
Epoch [70/300], Train Loss: 0.000617
Validation Loss: 0.00087091
Epoch [71/300], Train Loss: 0.000665
Validation Loss: 0.00088545
Epoch [72/300], Train Loss: 0.000622
Validation Loss: 0.00102999
Epoch [73/300], Train Loss: 0.000599
Validation Loss: 0.00090695
Epoch [74/300], Train Loss: 0.000619
Validation Loss: 0.00094782
Epoch [75/300], Train Loss: 0.000608
Validation Loss: 0.00086993
Epoch [76/300], Train Loss: 0.000586
Validation Loss: 0.00086930
Epoch [77/300], Train Loss: 0.000577
Validation Loss: 0.00086450
Epoch [78/300], Train Loss: 0.000589
Validation Loss: 0.00083648
Epoch [79/300], Train Loss: 0.000580
Validation Loss: 0.00084806
Epoch [80/300], Train Loss: 0.000556
Validation Loss: 0.00087525
Epoch [81/300], Train Loss: 0.000553
Validation Loss: 0.00084737
Epoch [82/300], Train Loss: 0.000563
Validation Loss: 0.00084230
Epoch [83/300], Train Loss: 0.000545
Validation Loss: 0.00084097
Epoch [84/300], Train Loss: 0.000553
Validation Loss: 0.00087088
Epoch [85/300], Train Loss: 0.000559
Validation Loss: 0.00083482
Epoch [86/300], Train Loss: 0.000593
Validation Loss: 0.00095623
Epoch [87/300], Train Loss: 0.000572
Validation Loss: 0.00081156
Epoch [88/300], Train Loss: 0.000537
Validation Loss: 0.00080311
Epoch [89/300], Train Loss: 0.000530
Validation Loss: 0.00081390
Epoch [90/300], Train Loss: 0.000540
Validation Loss: 0.00081245
Epoch [91/300], Train Loss: 0.000508
Validation Loss: 0.00083435
Epoch [92/300], Train Loss: 0.000502
Validation Loss: 0.00080644
Epoch [93/300], Train Loss: 0.000549
Validation Loss: 0.00078389
Epoch [94/300], Train Loss: 0.000509
Validation Loss: 0.00080592
Epoch [95/300], Train Loss: 0.000563
Validation Loss: 0.00078848
Epoch [96/300], Train Loss: 0.000505
Validation Loss: 0.00077876
Epoch [97/300], Train Loss: 0.000486
Validation Loss: 0.00082564
Epoch [98/300], Train Loss: 0.000489
Validation Loss: 0.00077794
Epoch [99/300], Train Loss: 0.000520
Validation Loss: 0.00078303
Epoch [100/300], Train Loss: 0.000474
Validation Loss: 0.00074738
Epoch [101/300], Train Loss: 0.000464
Validation Loss: 0.00081387
Epoch [102/300], Train Loss: 0.000462
Validation Loss: 0.00078608
Epoch [103/300], Train Loss: 0.000471
Validation Loss: 0.00077080
Epoch [104/300], Train Loss: 0.000447
Validation Loss: 0.00072864
Epoch [105/300], Train Loss: 0.000446
Validation Loss: 0.00080104
Epoch [106/300], Train Loss: 0.000449
Validation Loss: 0.00079749
Epoch [107/300], Train Loss: 0.000454
Validation Loss: 0.00072046
Epoch [108/300], Train Loss: 0.000562
Validation Loss: 0.00099349
Epoch [109/300], Train Loss: 0.000519
Validation Loss: 0.00074302
Epoch [110/300], Train Loss: 0.000446
Validation Loss: 0.00077470
Epoch [111/300], Train Loss: 0.000434
Validation Loss: 0.00070262
Epoch [112/300], Train Loss: 0.000432
Validation Loss: 0.00073600
Epoch [113/300], Train Loss: 0.000426
Validation Loss: 0.00070208
Epoch [114/300], Train Loss: 0.000429
Validation Loss: 0.00069762
Epoch [115/300], Train Loss: 0.000423
Validation Loss: 0.00076517
Epoch [116/300], Train Loss: 0.000412
Validation Loss: 0.00074932
Epoch [117/300], Train Loss: 0.000425
Validation Loss: 0.00070519
Epoch [118/300], Train Loss: 0.000417
Validation Loss: 0.00071147
Epoch [119/300], Train Loss: 0.000409
Validation Loss: 0.00079546
Epoch [120/300], Train Loss: 0.000413
Validation Loss: 0.00071887
Epoch [121/300], Train Loss: 0.000397
Validation Loss: 0.00079284
Epoch [122/300], Train Loss: 0.000414
Validation Loss: 0.00075789
Epoch [123/300], Train Loss: 0.000429
Validation Loss: 0.00077010
Epoch [124/300], Train Loss: 0.000387
Validation Loss: 0.00071422
Early stopping triggered

Evaluating model for: Dryer
Run 25/72 completed in 1094.10 seconds with: {'MAE': np.float32(2.7414231), 'MSE': np.float32(637.6375), 'RMSE': np.float32(25.251486), 'SAE': np.float32(0.034935657), 'NDE': np.float32(0.24544433)}

Run 26/72: hidden=256, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Dryer
Dataset length: 9150 windows

Epoch [1/300], Train Loss: 0.010454
Validation Loss: 0.01179527
Epoch [2/300], Train Loss: 0.007456
Validation Loss: 0.00294456
Epoch [3/300], Train Loss: 0.002854
Validation Loss: 0.00237988
Epoch [4/300], Train Loss: 0.002541
Validation Loss: 0.00206909
Epoch [5/300], Train Loss: 0.002253
Validation Loss: 0.00190731
Epoch [6/300], Train Loss: 0.001838
Validation Loss: 0.00159503
Epoch [7/300], Train Loss: 0.001673
Validation Loss: 0.00135068
Epoch [8/300], Train Loss: 0.001452
Validation Loss: 0.00126792
Epoch [9/300], Train Loss: 0.001346
Validation Loss: 0.00118698
Epoch [10/300], Train Loss: 0.001363
Validation Loss: 0.00116281
Epoch [11/300], Train Loss: 0.001189
Validation Loss: 0.00115931
Epoch [12/300], Train Loss: 0.001093
Validation Loss: 0.00099782
Epoch [13/300], Train Loss: 0.001030
Validation Loss: 0.00110425
Epoch [14/300], Train Loss: 0.001096
Validation Loss: 0.00093436
Epoch [15/300], Train Loss: 0.000955
Validation Loss: 0.00112222
Epoch [16/300], Train Loss: 0.000879
Validation Loss: 0.00085713
Epoch [17/300], Train Loss: 0.000838
Validation Loss: 0.00088776
Epoch [18/300], Train Loss: 0.000840
Validation Loss: 0.00082769
Epoch [19/300], Train Loss: 0.000794
Validation Loss: 0.00086140
Epoch [20/300], Train Loss: 0.000782
Validation Loss: 0.00079027
Epoch [21/300], Train Loss: 0.000767
Validation Loss: 0.00077492
Epoch [22/300], Train Loss: 0.000759
Validation Loss: 0.00075870
Epoch [23/300], Train Loss: 0.000728
Validation Loss: 0.00072251
Epoch [24/300], Train Loss: 0.000704
Validation Loss: 0.00070893
Epoch [25/300], Train Loss: 0.000680
Validation Loss: 0.00068954
Epoch [26/300], Train Loss: 0.000675
Validation Loss: 0.00070341
Epoch [27/300], Train Loss: 0.000661
Validation Loss: 0.00080248
Epoch [28/300], Train Loss: 0.000653
Validation Loss: 0.00067808
Epoch [29/300], Train Loss: 0.000633
Validation Loss: 0.00070286
Epoch [30/300], Train Loss: 0.000625
Validation Loss: 0.00065739
Epoch [31/300], Train Loss: 0.000588
Validation Loss: 0.00064591
Epoch [32/300], Train Loss: 0.000584
Validation Loss: 0.00065216
Epoch [33/300], Train Loss: 0.000573
Validation Loss: 0.00065264
Epoch [34/300], Train Loss: 0.000564
Validation Loss: 0.00063133
Epoch [35/300], Train Loss: 0.000558
Validation Loss: 0.00061421
Epoch [36/300], Train Loss: 0.000545
Validation Loss: 0.00066364
Epoch [37/300], Train Loss: 0.000581
Validation Loss: 0.00056813
Epoch [38/300], Train Loss: 0.000538
Validation Loss: 0.00056671
Epoch [39/300], Train Loss: 0.000528
Validation Loss: 0.00058728
Epoch [40/300], Train Loss: 0.000525
Validation Loss: 0.00059731
Epoch [41/300], Train Loss: 0.000550
Validation Loss: 0.00058909
Epoch [42/300], Train Loss: 0.000503
Validation Loss: 0.00060124
Epoch [43/300], Train Loss: 0.000493
Validation Loss: 0.00056434
Epoch [44/300], Train Loss: 0.000504
Validation Loss: 0.00054367
Epoch [45/300], Train Loss: 0.000485
Validation Loss: 0.00053983
Epoch [46/300], Train Loss: 0.000536
Validation Loss: 0.00054266
Epoch [47/300], Train Loss: 0.000478
Validation Loss: 0.00054816
Epoch [48/300], Train Loss: 0.000480
Validation Loss: 0.00051397
Epoch [49/300], Train Loss: 0.000474
Validation Loss: 0.00049823
Epoch [50/300], Train Loss: 0.000450
Validation Loss: 0.00049684
Epoch [51/300], Train Loss: 0.000480
Validation Loss: 0.00053790
Epoch [52/300], Train Loss: 0.000525
Validation Loss: 0.00051106
Epoch [53/300], Train Loss: 0.000458
Validation Loss: 0.00049469
Epoch [54/300], Train Loss: 0.000446
Validation Loss: 0.00046044
Epoch [55/300], Train Loss: 0.000465
Validation Loss: 0.00048489
Epoch [56/300], Train Loss: 0.000464
Validation Loss: 0.00046001
Epoch [57/300], Train Loss: 0.000437
Validation Loss: 0.00047698
Epoch [58/300], Train Loss: 0.000426
Validation Loss: 0.00045805
Epoch [59/300], Train Loss: 0.000436
Validation Loss: 0.00045811
Epoch [60/300], Train Loss: 0.000441
Validation Loss: 0.00046136
Epoch [61/300], Train Loss: 0.000429
Validation Loss: 0.00046501
Epoch [62/300], Train Loss: 0.000413
Validation Loss: 0.00047943
Epoch [63/300], Train Loss: 0.000419
Validation Loss: 0.00048542
Epoch [64/300], Train Loss: 0.000412
Validation Loss: 0.00047627
Epoch [65/300], Train Loss: 0.000402
Validation Loss: 0.00044059
Epoch [66/300], Train Loss: 0.000401
Validation Loss: 0.00046840
Epoch [67/300], Train Loss: 0.000387
Validation Loss: 0.00045388
Epoch [68/300], Train Loss: 0.000394
Validation Loss: 0.00046060
Epoch [69/300], Train Loss: 0.000460
Validation Loss: 0.00053146
Epoch [70/300], Train Loss: 0.000466
Validation Loss: 0.00046094
Epoch [71/300], Train Loss: 0.000437
Validation Loss: 0.00045000
Epoch [72/300], Train Loss: 0.000478
Validation Loss: 0.00043538
Epoch [73/300], Train Loss: 0.000389
Validation Loss: 0.00045709
Epoch [74/300], Train Loss: 0.000367
Validation Loss: 0.00042677
Epoch [75/300], Train Loss: 0.000367
Validation Loss: 0.00044040
Epoch [76/300], Train Loss: 0.000363
Validation Loss: 0.00043116
Epoch [77/300], Train Loss: 0.000365
Validation Loss: 0.00045394
Epoch [78/300], Train Loss: 0.000361
Validation Loss: 0.00040834
Epoch [79/300], Train Loss: 0.000361
Validation Loss: 0.00045034
Epoch [80/300], Train Loss: 0.000358
Validation Loss: 0.00041283
Epoch [81/300], Train Loss: 0.000342
Validation Loss: 0.00041244
Epoch [82/300], Train Loss: 0.000340
Validation Loss: 0.00040446
Epoch [83/300], Train Loss: 0.000340
Validation Loss: 0.00046675
Epoch [84/300], Train Loss: 0.000352
Validation Loss: 0.00043966
Epoch [85/300], Train Loss: 0.000344
Validation Loss: 0.00045120
Epoch [86/300], Train Loss: 0.000334
Validation Loss: 0.00040702
Epoch [87/300], Train Loss: 0.000325
Validation Loss: 0.00047140
Epoch [88/300], Train Loss: 0.000320
Validation Loss: 0.00044832
Epoch [89/300], Train Loss: 0.000316
Validation Loss: 0.00049381
Epoch [90/300], Train Loss: 0.000310
Validation Loss: 0.00046351
Epoch [91/300], Train Loss: 0.000306
Validation Loss: 0.00042459
Epoch [92/300], Train Loss: 0.000311
Validation Loss: 0.00049727
Early stopping triggered

Evaluating model for: Dryer
Run 26/72 completed in 898.01 seconds with: {'MAE': np.float32(2.1969392), 'MSE': np.float32(305.4549), 'RMSE': np.float32(17.477268), 'SAE': np.float32(0.017821973), 'NDE': np.float32(0.16987908)}

Run 27/72: hidden=256, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Dryer
Dataset length: 9150 windows

Epoch [1/300], Train Loss: 0.010416
Validation Loss: 0.01135268
Epoch [2/300], Train Loss: 0.006086
Validation Loss: 0.00394820
Epoch [3/300], Train Loss: 0.003750
Validation Loss: 0.00304610
Epoch [4/300], Train Loss: 0.003241
Validation Loss: 0.00239739
Epoch [5/300], Train Loss: 0.002779
Validation Loss: 0.00220509
Epoch [6/300], Train Loss: 0.002322
Validation Loss: 0.00197803
Epoch [7/300], Train Loss: 0.002010
Validation Loss: 0.00190558
Epoch [8/300], Train Loss: 0.001758
Validation Loss: 0.00175596
Epoch [9/300], Train Loss: 0.001465
Validation Loss: 0.00170145
Epoch [10/300], Train Loss: 0.001526
Validation Loss: 0.00154180
Epoch [11/300], Train Loss: 0.001291
Validation Loss: 0.00153883
Epoch [12/300], Train Loss: 0.001241
Validation Loss: 0.00150851
Epoch [13/300], Train Loss: 0.001205
Validation Loss: 0.00143292
Epoch [14/300], Train Loss: 0.001151
Validation Loss: 0.00149435
Epoch [15/300], Train Loss: 0.001106
Validation Loss: 0.00125200
Epoch [16/300], Train Loss: 0.001119
Validation Loss: 0.00135404
Epoch [17/300], Train Loss: 0.001096
Validation Loss: 0.00138997
Epoch [18/300], Train Loss: 0.001013
Validation Loss: 0.00144702
Epoch [19/300], Train Loss: 0.000992
Validation Loss: 0.00141719
Epoch [20/300], Train Loss: 0.000974
Validation Loss: 0.00135855
Epoch [21/300], Train Loss: 0.000976
Validation Loss: 0.00136623
Epoch [22/300], Train Loss: 0.000930
Validation Loss: 0.00127851
Epoch [23/300], Train Loss: 0.000919
Validation Loss: 0.00118826
Epoch [24/300], Train Loss: 0.000915
Validation Loss: 0.00123134
Epoch [25/300], Train Loss: 0.000880
Validation Loss: 0.00126028
Epoch [26/300], Train Loss: 0.000848
Validation Loss: 0.00121721
Epoch [27/300], Train Loss: 0.000886
Validation Loss: 0.00117829
Epoch [28/300], Train Loss: 0.000851
Validation Loss: 0.00129577
Epoch [29/300], Train Loss: 0.000868
Validation Loss: 0.00117688
Epoch [30/300], Train Loss: 0.000808
Validation Loss: 0.00117862
Epoch [31/300], Train Loss: 0.000784
Validation Loss: 0.00120699
Epoch [32/300], Train Loss: 0.000774
Validation Loss: 0.00100597
Epoch [33/300], Train Loss: 0.000804
Validation Loss: 0.00095115
Epoch [34/300], Train Loss: 0.000777
Validation Loss: 0.00098814
Epoch [35/300], Train Loss: 0.000760
Validation Loss: 0.00090813
Epoch [36/300], Train Loss: 0.000754
Validation Loss: 0.00096499
Epoch [37/300], Train Loss: 0.000779
Validation Loss: 0.00081014
Epoch [38/300], Train Loss: 0.000683
Validation Loss: 0.00080666
Epoch [39/300], Train Loss: 0.000673
Validation Loss: 0.00092580
Epoch [40/300], Train Loss: 0.000697
Validation Loss: 0.00080012
Epoch [41/300], Train Loss: 0.000648
Validation Loss: 0.00078920
Epoch [42/300], Train Loss: 0.000667
Validation Loss: 0.00074852
Epoch [43/300], Train Loss: 0.000628
Validation Loss: 0.00083794
Epoch [44/300], Train Loss: 0.000654
Validation Loss: 0.00081946
Epoch [45/300], Train Loss: 0.000650
Validation Loss: 0.00077464
Epoch [46/300], Train Loss: 0.000673
Validation Loss: 0.00087567
Epoch [47/300], Train Loss: 0.000757
Validation Loss: 0.00095912
Epoch [48/300], Train Loss: 0.000692
Validation Loss: 0.00073525
Epoch [49/300], Train Loss: 0.000594
Validation Loss: 0.00079866
Epoch [50/300], Train Loss: 0.000553
Validation Loss: 0.00067540
Epoch [51/300], Train Loss: 0.000584
Validation Loss: 0.00073817
Epoch [52/300], Train Loss: 0.000588
Validation Loss: 0.00068054
Epoch [53/300], Train Loss: 0.000653
Validation Loss: 0.00071639
Epoch [54/300], Train Loss: 0.000532
Validation Loss: 0.00069388
Epoch [55/300], Train Loss: 0.000515
Validation Loss: 0.00066514
Epoch [56/300], Train Loss: 0.000551
Validation Loss: 0.00065513
Epoch [57/300], Train Loss: 0.000513
Validation Loss: 0.00081597
Epoch [58/300], Train Loss: 0.000550
Validation Loss: 0.00068461
Epoch [59/300], Train Loss: 0.000535
Validation Loss: 0.00063101
Epoch [60/300], Train Loss: 0.000497
Validation Loss: 0.00060480
Epoch [61/300], Train Loss: 0.000512
Validation Loss: 0.00065338
Epoch [62/300], Train Loss: 0.000495
Validation Loss: 0.00070362
Epoch [63/300], Train Loss: 0.000533
Validation Loss: 0.00063081
Epoch [64/300], Train Loss: 0.000491
Validation Loss: 0.00069960
Epoch [65/300], Train Loss: 0.000482
Validation Loss: 0.00055332
Epoch [66/300], Train Loss: 0.000514
Validation Loss: 0.00066005
Epoch [67/300], Train Loss: 0.000480
Validation Loss: 0.00060016
Epoch [68/300], Train Loss: 0.000467
Validation Loss: 0.00063321
Epoch [69/300], Train Loss: 0.000454
Validation Loss: 0.00064714
Epoch [70/300], Train Loss: 0.000487
Validation Loss: 0.00065147
Epoch [71/300], Train Loss: 0.000529
Validation Loss: 0.00068480
Epoch [72/300], Train Loss: 0.000505
Validation Loss: 0.00052739
Epoch [73/300], Train Loss: 0.000460
Validation Loss: 0.00060557
Epoch [74/300], Train Loss: 0.000434
Validation Loss: 0.00057738
Epoch [75/300], Train Loss: 0.000473
Validation Loss: 0.00063738
Epoch [76/300], Train Loss: 0.000593
Validation Loss: 0.00060613
Epoch [77/300], Train Loss: 0.000516
Validation Loss: 0.00063460
Epoch [78/300], Train Loss: 0.000468
Validation Loss: 0.00054427
Epoch [79/300], Train Loss: 0.000455
Validation Loss: 0.00056670
Epoch [80/300], Train Loss: 0.000437
Validation Loss: 0.00061959
Epoch [81/300], Train Loss: 0.000437
Validation Loss: 0.00062420
Epoch [82/300], Train Loss: 0.000452
Validation Loss: 0.00054941
Early stopping triggered

Evaluating model for: Dryer
Run 27/72 completed in 861.65 seconds with: {'MAE': np.float32(3.119751), 'MSE': np.float32(788.32605), 'RMSE': np.float32(28.077145), 'SAE': np.float32(0.029135596), 'NDE': np.float32(0.2729094)}

Run 28/72: hidden=256, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Dryer
Dataset length: 9150 windows

Epoch [1/300], Train Loss: 0.010622
Validation Loss: 0.01205929
Epoch [2/300], Train Loss: 0.010042
Validation Loss: 0.00501175
Epoch [3/300], Train Loss: 0.003794
Validation Loss: 0.00300303
Epoch [4/300], Train Loss: 0.003223
Validation Loss: 0.00252049
Epoch [5/300], Train Loss: 0.002877
Validation Loss: 0.00258014
Epoch [6/300], Train Loss: 0.002931
Validation Loss: 0.00243289
Epoch [7/300], Train Loss: 0.002387
Validation Loss: 0.00187851
Epoch [8/300], Train Loss: 0.002047
Validation Loss: 0.00171079
Epoch [9/300], Train Loss: 0.001834
Validation Loss: 0.00153844
Epoch [10/300], Train Loss: 0.001710
Validation Loss: 0.00166063
Epoch [11/300], Train Loss: 0.001581
Validation Loss: 0.00152235
Epoch [12/300], Train Loss: 0.001555
Validation Loss: 0.00136466
Epoch [13/300], Train Loss: 0.001450
Validation Loss: 0.00131420
Epoch [14/300], Train Loss: 0.001445
Validation Loss: 0.00124993
Epoch [15/300], Train Loss: 0.001312
Validation Loss: 0.00128335
Epoch [16/300], Train Loss: 0.001288
Validation Loss: 0.00126994
Epoch [17/300], Train Loss: 0.001228
Validation Loss: 0.00115226
Epoch [18/300], Train Loss: 0.001197
Validation Loss: 0.00113082
Epoch [19/300], Train Loss: 0.001141
Validation Loss: 0.00105468
Epoch [20/300], Train Loss: 0.001110
Validation Loss: 0.00112263
Epoch [21/300], Train Loss: 0.001073
Validation Loss: 0.00105931
Epoch [22/300], Train Loss: 0.001022
Validation Loss: 0.00101544
Epoch [23/300], Train Loss: 0.001047
Validation Loss: 0.00109576
Epoch [24/300], Train Loss: 0.000992
Validation Loss: 0.00099439
Epoch [25/300], Train Loss: 0.000936
Validation Loss: 0.00102411
Epoch [26/300], Train Loss: 0.000936
Validation Loss: 0.00099890
Epoch [27/300], Train Loss: 0.000926
Validation Loss: 0.00100542
Epoch [28/300], Train Loss: 0.000896
Validation Loss: 0.00091224
Epoch [29/300], Train Loss: 0.000927
Validation Loss: 0.00102976
Epoch [30/300], Train Loss: 0.000892
Validation Loss: 0.00101186
Epoch [31/300], Train Loss: 0.000872
Validation Loss: 0.00102464
Epoch [32/300], Train Loss: 0.000834
Validation Loss: 0.00102307
Epoch [33/300], Train Loss: 0.000911
Validation Loss: 0.00099071
Epoch [34/300], Train Loss: 0.000820
Validation Loss: 0.00098417
Epoch [35/300], Train Loss: 0.000799
Validation Loss: 0.00097192
Epoch [36/300], Train Loss: 0.000787
Validation Loss: 0.00106484
Epoch [37/300], Train Loss: 0.000858
Validation Loss: 0.00093853
Epoch [38/300], Train Loss: 0.000779
Validation Loss: 0.00091043
Epoch [39/300], Train Loss: 0.000776
Validation Loss: 0.00093560
Epoch [40/300], Train Loss: 0.000782
Validation Loss: 0.00097742
Epoch [41/300], Train Loss: 0.000743
Validation Loss: 0.00091213
Epoch [42/300], Train Loss: 0.000729
Validation Loss: 0.00092505
Epoch [43/300], Train Loss: 0.000721
Validation Loss: 0.00092371
Epoch [44/300], Train Loss: 0.000764
Validation Loss: 0.00090022
Epoch [45/300], Train Loss: 0.000709
Validation Loss: 0.00092128
Epoch [46/300], Train Loss: 0.000773
Validation Loss: 0.00094368
Epoch [47/300], Train Loss: 0.000685
Validation Loss: 0.00090351
Epoch [48/300], Train Loss: 0.000699
Validation Loss: 0.00087794
Epoch [49/300], Train Loss: 0.000668
Validation Loss: 0.00089444
Epoch [50/300], Train Loss: 0.000672
Validation Loss: 0.00087308
Epoch [51/300], Train Loss: 0.000654
Validation Loss: 0.00087939
Epoch [52/300], Train Loss: 0.000673
Validation Loss: 0.00086404
Epoch [53/300], Train Loss: 0.000618
Validation Loss: 0.00085074
Epoch [54/300], Train Loss: 0.000657
Validation Loss: 0.00092585
Epoch [55/300], Train Loss: 0.000633
Validation Loss: 0.00083748
Epoch [56/300], Train Loss: 0.000623
Validation Loss: 0.00085736
Epoch [57/300], Train Loss: 0.000607
Validation Loss: 0.00082618
Epoch [58/300], Train Loss: 0.000605
Validation Loss: 0.00080368
Epoch [59/300], Train Loss: 0.000602
Validation Loss: 0.00086734
Epoch [60/300], Train Loss: 0.000580
Validation Loss: 0.00080397
Epoch [61/300], Train Loss: 0.000597
Validation Loss: 0.00081603
Epoch [62/300], Train Loss: 0.000585
Validation Loss: 0.00083940
Epoch [63/300], Train Loss: 0.000606
Validation Loss: 0.00079786
Epoch [64/300], Train Loss: 0.000611
Validation Loss: 0.00087685
Epoch [65/300], Train Loss: 0.000582
Validation Loss: 0.00082492
Epoch [66/300], Train Loss: 0.000567
Validation Loss: 0.00077756
Epoch [67/300], Train Loss: 0.000532
Validation Loss: 0.00079575
Epoch [68/300], Train Loss: 0.000564
Validation Loss: 0.00078821
Epoch [69/300], Train Loss: 0.000535
Validation Loss: 0.00077799
Epoch [70/300], Train Loss: 0.000549
Validation Loss: 0.00077373
Epoch [71/300], Train Loss: 0.000597
Validation Loss: 0.00085723
Epoch [72/300], Train Loss: 0.000636
Validation Loss: 0.00098818
Epoch [73/300], Train Loss: 0.000554
Validation Loss: 0.00075851
Epoch [74/300], Train Loss: 0.000511
Validation Loss: 0.00075718
Epoch [75/300], Train Loss: 0.000514
Validation Loss: 0.00078570
Epoch [76/300], Train Loss: 0.000508
Validation Loss: 0.00075442
Epoch [77/300], Train Loss: 0.000513
Validation Loss: 0.00075291
Epoch [78/300], Train Loss: 0.000490
Validation Loss: 0.00073934
Epoch [79/300], Train Loss: 0.000509
Validation Loss: 0.00080797
Epoch [80/300], Train Loss: 0.000559
Validation Loss: 0.00076880
Epoch [81/300], Train Loss: 0.000498
Validation Loss: 0.00071887
Epoch [82/300], Train Loss: 0.000481
Validation Loss: 0.00072786
Epoch [83/300], Train Loss: 0.000484
Validation Loss: 0.00075289
Epoch [84/300], Train Loss: 0.000484
Validation Loss: 0.00072247
Epoch [85/300], Train Loss: 0.000501
Validation Loss: 0.00072482
Epoch [86/300], Train Loss: 0.000590
Validation Loss: 0.00076386
Epoch [87/300], Train Loss: 0.000474
Validation Loss: 0.00072989
Epoch [88/300], Train Loss: 0.000464
Validation Loss: 0.00078848
Epoch [89/300], Train Loss: 0.000458
Validation Loss: 0.00071776
Epoch [90/300], Train Loss: 0.000457
Validation Loss: 0.00072291
Epoch [91/300], Train Loss: 0.000453
Validation Loss: 0.00072716
Epoch [92/300], Train Loss: 0.000430
Validation Loss: 0.00069703
Epoch [93/300], Train Loss: 0.000439
Validation Loss: 0.00069971
Epoch [94/300], Train Loss: 0.000447
Validation Loss: 0.00073041
Epoch [95/300], Train Loss: 0.000417
Validation Loss: 0.00074127
Epoch [96/300], Train Loss: 0.000414
Validation Loss: 0.00073622
Epoch [97/300], Train Loss: 0.000415
Validation Loss: 0.00070934
Epoch [98/300], Train Loss: 0.000432
Validation Loss: 0.00072010
Epoch [99/300], Train Loss: 0.000418
Validation Loss: 0.00071328
Epoch [100/300], Train Loss: 0.000406
Validation Loss: 0.00068012
Epoch [101/300], Train Loss: 0.000564
Validation Loss: 0.00071457
Epoch [102/300], Train Loss: 0.000732
Validation Loss: 0.00091552
Epoch [103/300], Train Loss: 0.000546
Validation Loss: 0.00097487
Epoch [104/300], Train Loss: 0.000471
Validation Loss: 0.00094023
Epoch [105/300], Train Loss: 0.000466
Validation Loss: 0.00090441
Epoch [106/300], Train Loss: 0.000457
Validation Loss: 0.00089352
Epoch [107/300], Train Loss: 0.000447
Validation Loss: 0.00089281
Epoch [108/300], Train Loss: 0.000441
Validation Loss: 0.00086828
Epoch [109/300], Train Loss: 0.000511
Validation Loss: 0.00086756
Epoch [110/300], Train Loss: 0.000428
Validation Loss: 0.00089830
Early stopping triggered

Evaluating model for: Dryer
Run 28/72 completed in 1353.98 seconds with: {'MAE': np.float32(2.9111085), 'MSE': np.float32(766.30756), 'RMSE': np.float32(27.68226), 'SAE': np.float32(0.11551188), 'NDE': np.float32(0.26907158)}

Run 29/72: hidden=256, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Dryer
Dataset length: 4586 windows

Epoch [1/300], Train Loss: 0.010772
Validation Loss: 0.01228133
Epoch [2/300], Train Loss: 0.010351
Validation Loss: 0.01159886
Epoch [3/300], Train Loss: 0.008221
Validation Loss: 0.00389094
Epoch [4/300], Train Loss: 0.004270
Validation Loss: 0.00287095
Epoch [5/300], Train Loss: 0.003385
Validation Loss: 0.00255568
Epoch [6/300], Train Loss: 0.002903
Validation Loss: 0.00230076
Epoch [7/300], Train Loss: 0.002828
Validation Loss: 0.00226500
Epoch [8/300], Train Loss: 0.002553
Validation Loss: 0.00236837
Epoch [9/300], Train Loss: 0.002548
Validation Loss: 0.00218343
Epoch [10/300], Train Loss: 0.002358
Validation Loss: 0.00245799
Epoch [11/300], Train Loss: 0.002192
Validation Loss: 0.00207580
Epoch [12/300], Train Loss: 0.002163
Validation Loss: 0.00204571
Epoch [13/300], Train Loss: 0.002106
Validation Loss: 0.00189367
Epoch [14/300], Train Loss: 0.001892
Validation Loss: 0.00225333
Epoch [15/300], Train Loss: 0.002131
Validation Loss: 0.00229029
Epoch [16/300], Train Loss: 0.002028
Validation Loss: 0.00190795
Epoch [17/300], Train Loss: 0.001804
Validation Loss: 0.00193761
Epoch [18/300], Train Loss: 0.001745
Validation Loss: 0.00174754
Epoch [19/300], Train Loss: 0.001649
Validation Loss: 0.00160529
Epoch [20/300], Train Loss: 0.001643
Validation Loss: 0.00166572
Epoch [21/300], Train Loss: 0.001590
Validation Loss: 0.00146857
Epoch [22/300], Train Loss: 0.001655
Validation Loss: 0.00154479
Epoch [23/300], Train Loss: 0.001565
Validation Loss: 0.00150942
Epoch [24/300], Train Loss: 0.001519
Validation Loss: 0.00164203
Epoch [25/300], Train Loss: 0.001452
Validation Loss: 0.00172425
Epoch [26/300], Train Loss: 0.001443
Validation Loss: 0.00171430
Epoch [27/300], Train Loss: 0.001418
Validation Loss: 0.00189661
Epoch [28/300], Train Loss: 0.001415
Validation Loss: 0.00174098
Epoch [29/300], Train Loss: 0.001314
Validation Loss: 0.00171036
Epoch [30/300], Train Loss: 0.001338
Validation Loss: 0.00168708
Epoch [31/300], Train Loss: 0.001295
Validation Loss: 0.00179887
Early stopping triggered

Evaluating model for: Dryer
Run 29/72 completed in 143.36 seconds with: {'MAE': np.float32(5.1860905), 'MSE': np.float32(1551.4603), 'RMSE': np.float32(39.38858), 'SAE': np.float32(0.09910959), 'NDE': np.float32(0.42001548)}

Run 30/72: hidden=256, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Dryer
Dataset length: 4586 windows

Epoch [1/300], Train Loss: 0.011407
Validation Loss: 0.01258542
Epoch [2/300], Train Loss: 0.010785
Validation Loss: 0.01241759
Epoch [3/300], Train Loss: 0.010516
Validation Loss: 0.01139075
Epoch [4/300], Train Loss: 0.006177
Validation Loss: 0.00350950
Epoch [5/300], Train Loss: 0.003942
Validation Loss: 0.00292000
Epoch [6/300], Train Loss: 0.003468
Validation Loss: 0.00275274
Epoch [7/300], Train Loss: 0.003223
Validation Loss: 0.00247898
Epoch [8/300], Train Loss: 0.003000
Validation Loss: 0.00252901
Epoch [9/300], Train Loss: 0.002939
Validation Loss: 0.00224721
Epoch [10/300], Train Loss: 0.002765
Validation Loss: 0.00218573
Epoch [11/300], Train Loss: 0.002582
Validation Loss: 0.00201757
Epoch [12/300], Train Loss: 0.002551
Validation Loss: 0.00193530
Epoch [13/300], Train Loss: 0.002396
Validation Loss: 0.00173946
Epoch [14/300], Train Loss: 0.002274
Validation Loss: 0.00217254
Epoch [15/300], Train Loss: 0.002141
Validation Loss: 0.00159615
Epoch [16/300], Train Loss: 0.001902
Validation Loss: 0.00152825
Epoch [17/300], Train Loss: 0.001934
Validation Loss: 0.00146373
Epoch [18/300], Train Loss: 0.002732
Validation Loss: 0.00193819
Epoch [19/300], Train Loss: 0.002053
Validation Loss: 0.00145013
Epoch [20/300], Train Loss: 0.001814
Validation Loss: 0.00147648
Epoch [21/300], Train Loss: 0.001652
Validation Loss: 0.00138408
Epoch [22/300], Train Loss: 0.002251
Validation Loss: 0.00181212
Epoch [23/300], Train Loss: 0.002444
Validation Loss: 0.00164310
Epoch [24/300], Train Loss: 0.001747
Validation Loss: 0.00150248
Epoch [25/300], Train Loss: 0.001561
Validation Loss: 0.00144896
Epoch [26/300], Train Loss: 0.001479
Validation Loss: 0.00144518
Epoch [27/300], Train Loss: 0.001366
Validation Loss: 0.00139702
Epoch [28/300], Train Loss: 0.001379
Validation Loss: 0.00138189
Epoch [29/300], Train Loss: 0.001293
Validation Loss: 0.00135307
Epoch [30/300], Train Loss: 0.001289
Validation Loss: 0.00136066
Epoch [31/300], Train Loss: 0.001263
Validation Loss: 0.00142787
Epoch [32/300], Train Loss: 0.001271
Validation Loss: 0.00146302
Epoch [33/300], Train Loss: 0.001328
Validation Loss: 0.00141078
Epoch [34/300], Train Loss: 0.001317
Validation Loss: 0.00130261
Epoch [35/300], Train Loss: 0.001161
Validation Loss: 0.00130356
Epoch [36/300], Train Loss: 0.001173
Validation Loss: 0.00131415
Epoch [37/300], Train Loss: 0.001134
Validation Loss: 0.00126154
Epoch [38/300], Train Loss: 0.001146
Validation Loss: 0.00128669
Epoch [39/300], Train Loss: 0.001095
Validation Loss: 0.00122548
Epoch [40/300], Train Loss: 0.001112
Validation Loss: 0.00122676
Epoch [41/300], Train Loss: 0.001116
Validation Loss: 0.00116737
Epoch [42/300], Train Loss: 0.001071
Validation Loss: 0.00121375
Epoch [43/300], Train Loss: 0.001091
Validation Loss: 0.00117608
Epoch [44/300], Train Loss: 0.001072
Validation Loss: 0.00115273
Epoch [45/300], Train Loss: 0.001025
Validation Loss: 0.00113035
Epoch [46/300], Train Loss: 0.001059
Validation Loss: 0.00108957
Epoch [47/300], Train Loss: 0.001089
Validation Loss: 0.00111657
Epoch [48/300], Train Loss: 0.001015
Validation Loss: 0.00105949
Epoch [49/300], Train Loss: 0.001004
Validation Loss: 0.00105612
Epoch [50/300], Train Loss: 0.001008
Validation Loss: 0.00103664
Epoch [51/300], Train Loss: 0.001018
Validation Loss: 0.00101527
Epoch [52/300], Train Loss: 0.000981
Validation Loss: 0.00102121
Epoch [53/300], Train Loss: 0.001000
Validation Loss: 0.00098066
Epoch [54/300], Train Loss: 0.000990
Validation Loss: 0.00104896
Epoch [55/300], Train Loss: 0.000931
Validation Loss: 0.00097416
Epoch [56/300], Train Loss: 0.000951
Validation Loss: 0.00096058
Epoch [57/300], Train Loss: 0.000901
Validation Loss: 0.00099376
Epoch [58/300], Train Loss: 0.000936
Validation Loss: 0.00093223
Epoch [59/300], Train Loss: 0.000901
Validation Loss: 0.00092254
Epoch [60/300], Train Loss: 0.000896
Validation Loss: 0.00092430
Epoch [61/300], Train Loss: 0.000886
Validation Loss: 0.00094519
Epoch [62/300], Train Loss: 0.000912
Validation Loss: 0.00090341
Epoch [63/300], Train Loss: 0.000868
Validation Loss: 0.00085325
Epoch [64/300], Train Loss: 0.000870
Validation Loss: 0.00088403
Epoch [65/300], Train Loss: 0.000868
Validation Loss: 0.00086536
Epoch [66/300], Train Loss: 0.000858
Validation Loss: 0.00096746
Epoch [67/300], Train Loss: 0.000935
Validation Loss: 0.00091755
Epoch [68/300], Train Loss: 0.000865
Validation Loss: 0.00090054
Epoch [69/300], Train Loss: 0.000846
Validation Loss: 0.00082282
Epoch [70/300], Train Loss: 0.000830
Validation Loss: 0.00081567
Epoch [71/300], Train Loss: 0.000867
Validation Loss: 0.00084856
Epoch [72/300], Train Loss: 0.000851
Validation Loss: 0.00082128
Epoch [73/300], Train Loss: 0.000821
Validation Loss: 0.00085022
Epoch [74/300], Train Loss: 0.000809
Validation Loss: 0.00080272
Epoch [75/300], Train Loss: 0.000801
Validation Loss: 0.00080141
Epoch [76/300], Train Loss: 0.000801
Validation Loss: 0.00079290
Epoch [77/300], Train Loss: 0.000812
Validation Loss: 0.00078383
Epoch [78/300], Train Loss: 0.000831
Validation Loss: 0.00083696
Epoch [79/300], Train Loss: 0.000826
Validation Loss: 0.00077749
Epoch [80/300], Train Loss: 0.000803
Validation Loss: 0.00078572
Epoch [81/300], Train Loss: 0.000786
Validation Loss: 0.00076016
Epoch [82/300], Train Loss: 0.000766
Validation Loss: 0.00074700
Epoch [83/300], Train Loss: 0.000780
Validation Loss: 0.00075882
Epoch [84/300], Train Loss: 0.000762
Validation Loss: 0.00074049
Epoch [85/300], Train Loss: 0.000784
Validation Loss: 0.00072181
Epoch [86/300], Train Loss: 0.000761
Validation Loss: 0.00073654
Epoch [87/300], Train Loss: 0.000758
Validation Loss: 0.00071173
Epoch [88/300], Train Loss: 0.000777
Validation Loss: 0.00074903
Epoch [89/300], Train Loss: 0.000778
Validation Loss: 0.00072456
Epoch [90/300], Train Loss: 0.000763
Validation Loss: 0.00072286
Epoch [91/300], Train Loss: 0.000728
Validation Loss: 0.00069628
Epoch [92/300], Train Loss: 0.000735
Validation Loss: 0.00069404
Epoch [93/300], Train Loss: 0.000737
Validation Loss: 0.00073540
Epoch [94/300], Train Loss: 0.000739
Validation Loss: 0.00071325
Epoch [95/300], Train Loss: 0.000737
Validation Loss: 0.00071018
Epoch [96/300], Train Loss: 0.000779
Validation Loss: 0.00069771
Epoch [97/300], Train Loss: 0.000730
Validation Loss: 0.00068431
Epoch [98/300], Train Loss: 0.000710
Validation Loss: 0.00068651
Epoch [99/300], Train Loss: 0.000713
Validation Loss: 0.00067436
Epoch [100/300], Train Loss: 0.000700
Validation Loss: 0.00067897
Epoch [101/300], Train Loss: 0.000712
Validation Loss: 0.00066615
Epoch [102/300], Train Loss: 0.000716
Validation Loss: 0.00066718
Epoch [103/300], Train Loss: 0.000710
Validation Loss: 0.00068282
Epoch [104/300], Train Loss: 0.000834
Validation Loss: 0.00066664
Epoch [105/300], Train Loss: 0.000728
Validation Loss: 0.00067931
Epoch [106/300], Train Loss: 0.000718
Validation Loss: 0.00066673
Epoch [107/300], Train Loss: 0.000699
Validation Loss: 0.00066106
Epoch [108/300], Train Loss: 0.000684
Validation Loss: 0.00066197
Epoch [109/300], Train Loss: 0.000699
Validation Loss: 0.00064345
Epoch [110/300], Train Loss: 0.000689
Validation Loss: 0.00066041
Epoch [111/300], Train Loss: 0.000696
Validation Loss: 0.00064899
Epoch [112/300], Train Loss: 0.000708
Validation Loss: 0.00063848
Epoch [113/300], Train Loss: 0.000683
Validation Loss: 0.00063992
Epoch [114/300], Train Loss: 0.000697
Validation Loss: 0.00063101
Epoch [115/300], Train Loss: 0.000691
Validation Loss: 0.00062902
Epoch [116/300], Train Loss: 0.000676
Validation Loss: 0.00062763
Epoch [117/300], Train Loss: 0.000679
Validation Loss: 0.00061986
Epoch [118/300], Train Loss: 0.000666
Validation Loss: 0.00061885
Epoch [119/300], Train Loss: 0.000656
Validation Loss: 0.00062039
Epoch [120/300], Train Loss: 0.000671
Validation Loss: 0.00062149
Epoch [121/300], Train Loss: 0.000662
Validation Loss: 0.00061925
Epoch [122/300], Train Loss: 0.000656
Validation Loss: 0.00062709
Epoch [123/300], Train Loss: 0.000657
Validation Loss: 0.00060571
Epoch [124/300], Train Loss: 0.000656
Validation Loss: 0.00060761
Epoch [125/300], Train Loss: 0.000648
Validation Loss: 0.00060786
Epoch [126/300], Train Loss: 0.000649
Validation Loss: 0.00060420
Epoch [127/300], Train Loss: 0.000650
Validation Loss: 0.00061683
Epoch [128/300], Train Loss: 0.000656
Validation Loss: 0.00061033
Epoch [129/300], Train Loss: 0.000646
Validation Loss: 0.00061133
Epoch [130/300], Train Loss: 0.000660
Validation Loss: 0.00059503
Epoch [131/300], Train Loss: 0.000637
Validation Loss: 0.00059304
Epoch [132/300], Train Loss: 0.000637
Validation Loss: 0.00061488
Epoch [133/300], Train Loss: 0.000654
Validation Loss: 0.00060820
Epoch [134/300], Train Loss: 0.000642
Validation Loss: 0.00058514
Epoch [135/300], Train Loss: 0.000637
Validation Loss: 0.00058751
Epoch [136/300], Train Loss: 0.000628
Validation Loss: 0.00058386
Epoch [137/300], Train Loss: 0.000630
Validation Loss: 0.00057995
Epoch [138/300], Train Loss: 0.000620
Validation Loss: 0.00058009
Epoch [139/300], Train Loss: 0.000624
Validation Loss: 0.00057584
Epoch [140/300], Train Loss: 0.000643
Validation Loss: 0.00057720
Epoch [141/300], Train Loss: 0.000634
Validation Loss: 0.00057433
Epoch [142/300], Train Loss: 0.000628
Validation Loss: 0.00058182
Epoch [143/300], Train Loss: 0.000627
Validation Loss: 0.00056853
Epoch [144/300], Train Loss: 0.000617
Validation Loss: 0.00056782
Epoch [145/300], Train Loss: 0.000618
Validation Loss: 0.00056646
Epoch [146/300], Train Loss: 0.000624
Validation Loss: 0.00056694
Epoch [147/300], Train Loss: 0.000613
Validation Loss: 0.00060108
Epoch [148/300], Train Loss: 0.000635
Validation Loss: 0.00060300
Epoch [149/300], Train Loss: 0.000610
Validation Loss: 0.00059611
Epoch [150/300], Train Loss: 0.000616
Validation Loss: 0.00055501
Epoch [151/300], Train Loss: 0.000603
Validation Loss: 0.00056221
Epoch [152/300], Train Loss: 0.000594
Validation Loss: 0.00057895
Epoch [153/300], Train Loss: 0.000601
Validation Loss: 0.00055556
Epoch [154/300], Train Loss: 0.000600
Validation Loss: 0.00058662
Epoch [155/300], Train Loss: 0.000591
Validation Loss: 0.00054812
Epoch [156/300], Train Loss: 0.000600
Validation Loss: 0.00055771
Epoch [157/300], Train Loss: 0.000589
Validation Loss: 0.00055925
Epoch [158/300], Train Loss: 0.000600
Validation Loss: 0.00055701
Epoch [159/300], Train Loss: 0.000605
Validation Loss: 0.00058166
Epoch [160/300], Train Loss: 0.000594
Validation Loss: 0.00054939
Epoch [161/300], Train Loss: 0.000605
Validation Loss: 0.00054269
Epoch [162/300], Train Loss: 0.000589
Validation Loss: 0.00054129
Epoch [163/300], Train Loss: 0.000582
Validation Loss: 0.00054243
Epoch [164/300], Train Loss: 0.000577
Validation Loss: 0.00053550
Epoch [165/300], Train Loss: 0.000585
Validation Loss: 0.00053788
Epoch [166/300], Train Loss: 0.000579
Validation Loss: 0.00053810
Epoch [167/300], Train Loss: 0.000621
Validation Loss: 0.00053395
Epoch [168/300], Train Loss: 0.000573
Validation Loss: 0.00052976
Epoch [169/300], Train Loss: 0.000595
Validation Loss: 0.00052775
Epoch [170/300], Train Loss: 0.000570
Validation Loss: 0.00054341
Epoch [171/300], Train Loss: 0.000573
Validation Loss: 0.00052737
Epoch [172/300], Train Loss: 0.000574
Validation Loss: 0.00055810
Epoch [173/300], Train Loss: 0.000580
Validation Loss: 0.00054111
Epoch [174/300], Train Loss: 0.000563
Validation Loss: 0.00052383
Epoch [175/300], Train Loss: 0.000564
Validation Loss: 0.00052338
Epoch [176/300], Train Loss: 0.000561
Validation Loss: 0.00052718
Epoch [177/300], Train Loss: 0.000553
Validation Loss: 0.00052484
Epoch [178/300], Train Loss: 0.000549
Validation Loss: 0.00056004
Epoch [179/300], Train Loss: 0.000566
Validation Loss: 0.00051675
Epoch [180/300], Train Loss: 0.000557
Validation Loss: 0.00052074
Epoch [181/300], Train Loss: 0.000561
Validation Loss: 0.00051774
Epoch [182/300], Train Loss: 0.000542
Validation Loss: 0.00055429
Epoch [183/300], Train Loss: 0.000581
Validation Loss: 0.00053010
Epoch [184/300], Train Loss: 0.000557
Validation Loss: 0.00051939
Epoch [185/300], Train Loss: 0.000548
Validation Loss: 0.00051127
Epoch [186/300], Train Loss: 0.000549
Validation Loss: 0.00051673
Epoch [187/300], Train Loss: 0.000551
Validation Loss: 0.00054703
Epoch [188/300], Train Loss: 0.000553
Validation Loss: 0.00050569
Epoch [189/300], Train Loss: 0.000553
Validation Loss: 0.00050920
Epoch [190/300], Train Loss: 0.000545
Validation Loss: 0.00050307
Epoch [191/300], Train Loss: 0.000553
Validation Loss: 0.00050122
Epoch [192/300], Train Loss: 0.000556
Validation Loss: 0.00050073
Epoch [193/300], Train Loss: 0.000539
Validation Loss: 0.00050374
Epoch [194/300], Train Loss: 0.000539
Validation Loss: 0.00050655
Epoch [195/300], Train Loss: 0.000526
Validation Loss: 0.00050299
Epoch [196/300], Train Loss: 0.000537
Validation Loss: 0.00050655
Epoch [197/300], Train Loss: 0.000547
Validation Loss: 0.00049661
Epoch [198/300], Train Loss: 0.000535
Validation Loss: 0.00050018
Epoch [199/300], Train Loss: 0.000536
Validation Loss: 0.00050100
Epoch [200/300], Train Loss: 0.000524
Validation Loss: 0.00049773
Epoch [201/300], Train Loss: 0.000531
Validation Loss: 0.00049966
Epoch [202/300], Train Loss: 0.000536
Validation Loss: 0.00053231
Epoch [203/300], Train Loss: 0.000552
Validation Loss: 0.00048861
Epoch [204/300], Train Loss: 0.000529
Validation Loss: 0.00049079
Epoch [205/300], Train Loss: 0.000531
Validation Loss: 0.00049057
Epoch [206/300], Train Loss: 0.000530
Validation Loss: 0.00050106
Epoch [207/300], Train Loss: 0.000520
Validation Loss: 0.00049929
Epoch [208/300], Train Loss: 0.000531
Validation Loss: 0.00049130
Epoch [209/300], Train Loss: 0.000538
Validation Loss: 0.00050408
Epoch [210/300], Train Loss: 0.000516
Validation Loss: 0.00048581
Epoch [211/300], Train Loss: 0.000527
Validation Loss: 0.00048518
Epoch [212/300], Train Loss: 0.000519
Validation Loss: 0.00049530
Epoch [213/300], Train Loss: 0.000518
Validation Loss: 0.00049947
Epoch [214/300], Train Loss: 0.000519
Validation Loss: 0.00049400
Epoch [215/300], Train Loss: 0.000513
Validation Loss: 0.00048319
Epoch [216/300], Train Loss: 0.000517
Validation Loss: 0.00048700
Epoch [217/300], Train Loss: 0.000517
Validation Loss: 0.00048326
Epoch [218/300], Train Loss: 0.000505
Validation Loss: 0.00049115
Epoch [219/300], Train Loss: 0.000506
Validation Loss: 0.00048036
Epoch [220/300], Train Loss: 0.000500
Validation Loss: 0.00048519
Epoch [221/300], Train Loss: 0.000514
Validation Loss: 0.00047756
Epoch [222/300], Train Loss: 0.000505
Validation Loss: 0.00048880
Epoch [223/300], Train Loss: 0.000505
Validation Loss: 0.00048349
Epoch [224/300], Train Loss: 0.000524
Validation Loss: 0.00049174
Epoch [225/300], Train Loss: 0.000530
Validation Loss: 0.00050605
Epoch [226/300], Train Loss: 0.000520
Validation Loss: 0.00049593
Epoch [227/300], Train Loss: 0.000507
Validation Loss: 0.00047762
Epoch [228/300], Train Loss: 0.000502
Validation Loss: 0.00047930
Epoch [229/300], Train Loss: 0.000504
Validation Loss: 0.00047701
Epoch [230/300], Train Loss: 0.000494
Validation Loss: 0.00048543
Epoch [231/300], Train Loss: 0.000493
Validation Loss: 0.00047542
Epoch [232/300], Train Loss: 0.000493
Validation Loss: 0.00047861
Epoch [233/300], Train Loss: 0.000497
Validation Loss: 0.00047843
Epoch [234/300], Train Loss: 0.000491
Validation Loss: 0.00047527
Epoch [235/300], Train Loss: 0.000493
Validation Loss: 0.00047717
Epoch [236/300], Train Loss: 0.000500
Validation Loss: 0.00046656
Epoch [237/300], Train Loss: 0.000499
Validation Loss: 0.00047904
Epoch [238/300], Train Loss: 0.000494
Validation Loss: 0.00048787
Epoch [239/300], Train Loss: 0.000496
Validation Loss: 0.00047119
Epoch [240/300], Train Loss: 0.000498
Validation Loss: 0.00046601
Epoch [241/300], Train Loss: 0.000484
Validation Loss: 0.00047645
Epoch [242/300], Train Loss: 0.000485
Validation Loss: 0.00047594
Epoch [243/300], Train Loss: 0.000485
Validation Loss: 0.00046654
Epoch [244/300], Train Loss: 0.000484
Validation Loss: 0.00046301
Epoch [245/300], Train Loss: 0.000483
Validation Loss: 0.00046607
Epoch [246/300], Train Loss: 0.000484
Validation Loss: 0.00046501
Epoch [247/300], Train Loss: 0.000480
Validation Loss: 0.00046334
Epoch [248/300], Train Loss: 0.000483
Validation Loss: 0.00046186
Epoch [249/300], Train Loss: 0.000473
Validation Loss: 0.00046503
Epoch [250/300], Train Loss: 0.000477
Validation Loss: 0.00046760
Epoch [251/300], Train Loss: 0.000485
Validation Loss: 0.00046770
Epoch [252/300], Train Loss: 0.000478
Validation Loss: 0.00045858
Epoch [253/300], Train Loss: 0.000481
Validation Loss: 0.00045880
Epoch [254/300], Train Loss: 0.000501
Validation Loss: 0.00047279
Epoch [255/300], Train Loss: 0.000478
Validation Loss: 0.00046376
Epoch [256/300], Train Loss: 0.000474
Validation Loss: 0.00047091
Epoch [257/300], Train Loss: 0.000473
Validation Loss: 0.00046242
Epoch [258/300], Train Loss: 0.000482
Validation Loss: 0.00047329
Epoch [259/300], Train Loss: 0.000470
Validation Loss: 0.00046136
Epoch [260/300], Train Loss: 0.000470
Validation Loss: 0.00046948
Epoch [261/300], Train Loss: 0.000470
Validation Loss: 0.00045737
Epoch [262/300], Train Loss: 0.000476
Validation Loss: 0.00047770
Epoch [263/300], Train Loss: 0.000476
Validation Loss: 0.00046500
Epoch [264/300], Train Loss: 0.000469
Validation Loss: 0.00047668
Epoch [265/300], Train Loss: 0.000464
Validation Loss: 0.00045935
Epoch [266/300], Train Loss: 0.000475
Validation Loss: 0.00045594
Epoch [267/300], Train Loss: 0.000470
Validation Loss: 0.00046121
Epoch [268/300], Train Loss: 0.000470
Validation Loss: 0.00046071
Epoch [269/300], Train Loss: 0.000459
Validation Loss: 0.00047298
Epoch [270/300], Train Loss: 0.000465
Validation Loss: 0.00046188
Epoch [271/300], Train Loss: 0.000464
Validation Loss: 0.00046001
Epoch [272/300], Train Loss: 0.000469
Validation Loss: 0.00045218
Epoch [273/300], Train Loss: 0.000471
Validation Loss: 0.00045940
Epoch [274/300], Train Loss: 0.000463
Validation Loss: 0.00045637
Epoch [275/300], Train Loss: 0.000454
Validation Loss: 0.00045164
Epoch [276/300], Train Loss: 0.000453
Validation Loss: 0.00046533
Epoch [277/300], Train Loss: 0.000467
Validation Loss: 0.00045730
Epoch [278/300], Train Loss: 0.000453
Validation Loss: 0.00046199
Epoch [279/300], Train Loss: 0.000454
Validation Loss: 0.00046380
Epoch [280/300], Train Loss: 0.000457
Validation Loss: 0.00045440
Epoch [281/300], Train Loss: 0.000446
Validation Loss: 0.00045497
Epoch [282/300], Train Loss: 0.000463
Validation Loss: 0.00045083
Epoch [283/300], Train Loss: 0.000446
Validation Loss: 0.00044740
Epoch [284/300], Train Loss: 0.000458
Validation Loss: 0.00045983
Epoch [285/300], Train Loss: 0.000463
Validation Loss: 0.00045187
Epoch [286/300], Train Loss: 0.000484
Validation Loss: 0.00047397
Epoch [287/300], Train Loss: 0.000452
Validation Loss: 0.00045094
Epoch [288/300], Train Loss: 0.000449
Validation Loss: 0.00045740
Epoch [289/300], Train Loss: 0.000450
Validation Loss: 0.00045232
Epoch [290/300], Train Loss: 0.000453
Validation Loss: 0.00045032
Epoch [291/300], Train Loss: 0.000446
Validation Loss: 0.00045327
Epoch [292/300], Train Loss: 0.000441
Validation Loss: 0.00045569
Epoch [293/300], Train Loss: 0.000456
Validation Loss: 0.00045429
Early stopping triggered

Evaluating model for: Dryer
Run 30/72 completed in 1413.34 seconds with: {'MAE': np.float32(4.1172214), 'MSE': np.float32(1896.4905), 'RMSE': np.float32(43.548714), 'SAE': np.float32(0.10336166), 'NDE': np.float32(0.464376)}

Run 31/72: hidden=256, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Dryer
Dataset length: 4586 windows

Epoch [1/300], Train Loss: 0.010931
Validation Loss: 0.01257648
Epoch [2/300], Train Loss: 0.010803
Validation Loss: 0.01252513
Epoch [3/300], Train Loss: 0.010715
Validation Loss: 0.01200864
Epoch [4/300], Train Loss: 0.006287
Validation Loss: 0.00399676
Epoch [5/300], Train Loss: 0.003542
Validation Loss: 0.00329926
Epoch [6/300], Train Loss: 0.003071
Validation Loss: 0.00250783
Epoch [7/300], Train Loss: 0.002969
Validation Loss: 0.00245162
Epoch [8/300], Train Loss: 0.002575
Validation Loss: 0.00263956
Epoch [9/300], Train Loss: 0.002416
Validation Loss: 0.00237387
Epoch [10/300], Train Loss: 0.002400
Validation Loss: 0.00250930
Epoch [11/300], Train Loss: 0.002321
Validation Loss: 0.00207937
Epoch [12/300], Train Loss: 0.002406
Validation Loss: 0.00242187
Epoch [13/300], Train Loss: 0.002091
Validation Loss: 0.00198541
Epoch [14/300], Train Loss: 0.001962
Validation Loss: 0.00205821
Epoch [15/300], Train Loss: 0.002359
Validation Loss: 0.00204826
Epoch [16/300], Train Loss: 0.001948
Validation Loss: 0.00183400
Epoch [17/300], Train Loss: 0.001893
Validation Loss: 0.00177169
Epoch [18/300], Train Loss: 0.001735
Validation Loss: 0.00172025
Epoch [19/300], Train Loss: 0.001667
Validation Loss: 0.00161686
Epoch [20/300], Train Loss: 0.001542
Validation Loss: 0.00157744
Epoch [21/300], Train Loss: 0.001515
Validation Loss: 0.00157855
Epoch [22/300], Train Loss: 0.001523
Validation Loss: 0.00174816
Epoch [23/300], Train Loss: 0.001554
Validation Loss: 0.00175012
Epoch [24/300], Train Loss: 0.001322
Validation Loss: 0.00157326
Epoch [25/300], Train Loss: 0.001264
Validation Loss: 0.00148508
Epoch [26/300], Train Loss: 0.001331
Validation Loss: 0.00146403
Epoch [27/300], Train Loss: 0.001244
Validation Loss: 0.00149187
Epoch [28/300], Train Loss: 0.001255
Validation Loss: 0.00146010
Epoch [29/300], Train Loss: 0.001214
Validation Loss: 0.00143013
Epoch [30/300], Train Loss: 0.001357
Validation Loss: 0.00150623
Epoch [31/300], Train Loss: 0.001301
Validation Loss: 0.00195964
Epoch [32/300], Train Loss: 0.001527
Validation Loss: 0.00159343
Epoch [33/300], Train Loss: 0.001342
Validation Loss: 0.00140382
Epoch [34/300], Train Loss: 0.001325
Validation Loss: 0.00139000
Epoch [35/300], Train Loss: 0.001172
Validation Loss: 0.00138705
Epoch [36/300], Train Loss: 0.001151
Validation Loss: 0.00136555
Epoch [37/300], Train Loss: 0.001145
Validation Loss: 0.00137533
Epoch [38/300], Train Loss: 0.001209
Validation Loss: 0.00135742
Epoch [39/300], Train Loss: 0.001122
Validation Loss: 0.00135619
Epoch [40/300], Train Loss: 0.001118
Validation Loss: 0.00132585
Epoch [41/300], Train Loss: 0.001152
Validation Loss: 0.00139180
Epoch [42/300], Train Loss: 0.001143
Validation Loss: 0.00141219
Epoch [43/300], Train Loss: 0.001162
Validation Loss: 0.00131487
Epoch [44/300], Train Loss: 0.001166
Validation Loss: 0.00134652
Epoch [45/300], Train Loss: 0.001104
Validation Loss: 0.00132284
Epoch [46/300], Train Loss: 0.001143
Validation Loss: 0.00134711
Epoch [47/300], Train Loss: 0.001167
Validation Loss: 0.00132218
Epoch [48/300], Train Loss: 0.001071
Validation Loss: 0.00131893
Epoch [49/300], Train Loss: 0.001086
Validation Loss: 0.00128605
Epoch [50/300], Train Loss: 0.001092
Validation Loss: 0.00128643
Epoch [51/300], Train Loss: 0.001092
Validation Loss: 0.00128939
Epoch [52/300], Train Loss: 0.001056
Validation Loss: 0.00127831
Epoch [53/300], Train Loss: 0.001044
Validation Loss: 0.00126960
Epoch [54/300], Train Loss: 0.001043
Validation Loss: 0.00125557
Epoch [55/300], Train Loss: 0.001010
Validation Loss: 0.00125205
Epoch [56/300], Train Loss: 0.001048
Validation Loss: 0.00126047
Epoch [57/300], Train Loss: 0.000993
Validation Loss: 0.00127671
Epoch [58/300], Train Loss: 0.001010
Validation Loss: 0.00125933
Epoch [59/300], Train Loss: 0.001023
Validation Loss: 0.00124797
Epoch [60/300], Train Loss: 0.000990
Validation Loss: 0.00123320
Epoch [61/300], Train Loss: 0.001024
Validation Loss: 0.00123761
Epoch [62/300], Train Loss: 0.001010
Validation Loss: 0.00123226
Epoch [63/300], Train Loss: 0.000971
Validation Loss: 0.00122510
Epoch [64/300], Train Loss: 0.000964
Validation Loss: 0.00125029
Epoch [65/300], Train Loss: 0.000988
Validation Loss: 0.00122715
Epoch [66/300], Train Loss: 0.000949
Validation Loss: 0.00123501
Epoch [67/300], Train Loss: 0.001005
Validation Loss: 0.00121295
Epoch [68/300], Train Loss: 0.000974
Validation Loss: 0.00121988
Epoch [69/300], Train Loss: 0.000961
Validation Loss: 0.00120516
Epoch [70/300], Train Loss: 0.000979
Validation Loss: 0.00120310
Epoch [71/300], Train Loss: 0.000983
Validation Loss: 0.00119610
Epoch [72/300], Train Loss: 0.000967
Validation Loss: 0.00119407
Epoch [73/300], Train Loss: 0.000939
Validation Loss: 0.00122192
Epoch [74/300], Train Loss: 0.000931
Validation Loss: 0.00119075
Epoch [75/300], Train Loss: 0.000937
Validation Loss: 0.00118768
Epoch [76/300], Train Loss: 0.000931
Validation Loss: 0.00119407
Epoch [77/300], Train Loss: 0.000944
Validation Loss: 0.00119586
Epoch [78/300], Train Loss: 0.000938
Validation Loss: 0.00125106
Epoch [79/300], Train Loss: 0.000980
Validation Loss: 0.00117863
Epoch [80/300], Train Loss: 0.000924
Validation Loss: 0.00117611
Epoch [81/300], Train Loss: 0.000919
Validation Loss: 0.00117622
Epoch [82/300], Train Loss: 0.000919
Validation Loss: 0.00117576
Epoch [83/300], Train Loss: 0.000947
Validation Loss: 0.00117104
Epoch [84/300], Train Loss: 0.000898
Validation Loss: 0.00117034
Epoch [85/300], Train Loss: 0.000920
Validation Loss: 0.00116801
Epoch [86/300], Train Loss: 0.000908
Validation Loss: 0.00117802
Epoch [87/300], Train Loss: 0.000913
Validation Loss: 0.00117724
Epoch [88/300], Train Loss: 0.000884
Validation Loss: 0.00117005
Epoch [89/300], Train Loss: 0.000885
Validation Loss: 0.00117357
Epoch [90/300], Train Loss: 0.000961
Validation Loss: 0.00118512
Epoch [91/300], Train Loss: 0.000902
Validation Loss: 0.00115028
Epoch [92/300], Train Loss: 0.000915
Validation Loss: 0.00115282
Epoch [93/300], Train Loss: 0.000890
Validation Loss: 0.00115962
Epoch [94/300], Train Loss: 0.000873
Validation Loss: 0.00115923
Epoch [95/300], Train Loss: 0.000896
Validation Loss: 0.00116081
Epoch [96/300], Train Loss: 0.000926
Validation Loss: 0.00114628
Epoch [97/300], Train Loss: 0.000886
Validation Loss: 0.00114241
Epoch [98/300], Train Loss: 0.000899
Validation Loss: 0.00115203
Epoch [99/300], Train Loss: 0.000861
Validation Loss: 0.00113584
Epoch [100/300], Train Loss: 0.000851
Validation Loss: 0.00114008
Epoch [101/300], Train Loss: 0.000842
Validation Loss: 0.00113466
Epoch [102/300], Train Loss: 0.000858
Validation Loss: 0.00115492
Epoch [103/300], Train Loss: 0.000856
Validation Loss: 0.00114769
Epoch [104/300], Train Loss: 0.000841
Validation Loss: 0.00113342
Epoch [105/300], Train Loss: 0.000838
Validation Loss: 0.00112932
Epoch [106/300], Train Loss: 0.000855
Validation Loss: 0.00112853
Epoch [107/300], Train Loss: 0.000829
Validation Loss: 0.00112656
Epoch [108/300], Train Loss: 0.000812
Validation Loss: 0.00113401
Epoch [109/300], Train Loss: 0.000843
Validation Loss: 0.00113192
Epoch [110/300], Train Loss: 0.000833
Validation Loss: 0.00112675
Epoch [111/300], Train Loss: 0.000814
Validation Loss: 0.00115241
Epoch [112/300], Train Loss: 0.000817
Validation Loss: 0.00111842
Epoch [113/300], Train Loss: 0.000841
Validation Loss: 0.00112263
Epoch [114/300], Train Loss: 0.000878
Validation Loss: 0.00113583
Epoch [115/300], Train Loss: 0.000913
Validation Loss: 0.00114166
Epoch [116/300], Train Loss: 0.000837
Validation Loss: 0.00112119
Epoch [117/300], Train Loss: 0.000822
Validation Loss: 0.00112064
Epoch [118/300], Train Loss: 0.000798
Validation Loss: 0.00111748
Epoch [119/300], Train Loss: 0.000795
Validation Loss: 0.00111645
Epoch [120/300], Train Loss: 0.000805
Validation Loss: 0.00111223
Epoch [121/300], Train Loss: 0.000806
Validation Loss: 0.00111909
Epoch [122/300], Train Loss: 0.000790
Validation Loss: 0.00111732
Epoch [123/300], Train Loss: 0.000792
Validation Loss: 0.00111127
Epoch [124/300], Train Loss: 0.000790
Validation Loss: 0.00111041
Epoch [125/300], Train Loss: 0.000812
Validation Loss: 0.00110412
Epoch [126/300], Train Loss: 0.000815
Validation Loss: 0.00110839
Epoch [127/300], Train Loss: 0.000808
Validation Loss: 0.00110561
Epoch [128/300], Train Loss: 0.000895
Validation Loss: 0.00110649
Epoch [129/300], Train Loss: 0.000830
Validation Loss: 0.00113278
Epoch [130/300], Train Loss: 0.000833
Validation Loss: 0.00110144
Epoch [131/300], Train Loss: 0.000826
Validation Loss: 0.00110564
Epoch [132/300], Train Loss: 0.000793
Validation Loss: 0.00110795
Epoch [133/300], Train Loss: 0.000816
Validation Loss: 0.00110724
Epoch [134/300], Train Loss: 0.000785
Validation Loss: 0.00110009
Epoch [135/300], Train Loss: 0.000798
Validation Loss: 0.00109693
Epoch [136/300], Train Loss: 0.000777
Validation Loss: 0.00109607
Epoch [137/300], Train Loss: 0.000772
Validation Loss: 0.00109619
Epoch [138/300], Train Loss: 0.000768
Validation Loss: 0.00109315
Epoch [139/300], Train Loss: 0.000765
Validation Loss: 0.00109348
Epoch [140/300], Train Loss: 0.000802
Validation Loss: 0.00109694
Epoch [141/300], Train Loss: 0.000770
Validation Loss: 0.00109153
Epoch [142/300], Train Loss: 0.000766
Validation Loss: 0.00108884
Epoch [143/300], Train Loss: 0.000755
Validation Loss: 0.00109058
Epoch [144/300], Train Loss: 0.000767
Validation Loss: 0.00109029
Epoch [145/300], Train Loss: 0.000788
Validation Loss: 0.00108836
Epoch [146/300], Train Loss: 0.000759
Validation Loss: 0.00108742
Epoch [147/300], Train Loss: 0.000749
Validation Loss: 0.00109086
Epoch [148/300], Train Loss: 0.000760
Validation Loss: 0.00108969
Epoch [149/300], Train Loss: 0.000836
Validation Loss: 0.00113036
Epoch [150/300], Train Loss: 0.000826
Validation Loss: 0.00109534
Epoch [151/300], Train Loss: 0.000796
Validation Loss: 0.00109008
Epoch [152/300], Train Loss: 0.000770
Validation Loss: 0.00108453
Epoch [153/300], Train Loss: 0.000774
Validation Loss: 0.00108563
Epoch [154/300], Train Loss: 0.000764
Validation Loss: 0.00110751
Epoch [155/300], Train Loss: 0.000751
Validation Loss: 0.00108101
Epoch [156/300], Train Loss: 0.000762
Validation Loss: 0.00108239
Epoch [157/300], Train Loss: 0.000748
Validation Loss: 0.00108373
Epoch [158/300], Train Loss: 0.000766
Validation Loss: 0.00108276
Epoch [159/300], Train Loss: 0.000752
Validation Loss: 0.00108620
Epoch [160/300], Train Loss: 0.000746
Validation Loss: 0.00107853
Epoch [161/300], Train Loss: 0.000759
Validation Loss: 0.00107671
Epoch [162/300], Train Loss: 0.000752
Validation Loss: 0.00107530
Epoch [163/300], Train Loss: 0.000741
Validation Loss: 0.00107878
Epoch [164/300], Train Loss: 0.000737
Validation Loss: 0.00107520
Epoch [165/300], Train Loss: 0.000744
Validation Loss: 0.00107645
Epoch [166/300], Train Loss: 0.000734
Validation Loss: 0.00107501
Epoch [167/300], Train Loss: 0.000770
Validation Loss: 0.00107271
Epoch [168/300], Train Loss: 0.000738
Validation Loss: 0.00107148
Epoch [169/300], Train Loss: 0.000764
Validation Loss: 0.00107433
Epoch [170/300], Train Loss: 0.000730
Validation Loss: 0.00107677
Epoch [171/300], Train Loss: 0.000734
Validation Loss: 0.00107180
Epoch [172/300], Train Loss: 0.000737
Validation Loss: 0.00108071
Epoch [173/300], Train Loss: 0.000734
Validation Loss: 0.00107151
Epoch [174/300], Train Loss: 0.000727
Validation Loss: 0.00106965
Epoch [175/300], Train Loss: 0.000751
Validation Loss: 0.00107006
Epoch [176/300], Train Loss: 0.000730
Validation Loss: 0.00106819
Epoch [177/300], Train Loss: 0.000721
Validation Loss: 0.00107151
Epoch [178/300], Train Loss: 0.000718
Validation Loss: 0.00108962
Epoch [179/300], Train Loss: 0.000729
Validation Loss: 0.00107062
Epoch [180/300], Train Loss: 0.000729
Validation Loss: 0.00106815
Epoch [181/300], Train Loss: 0.000755
Validation Loss: 0.00106668
Epoch [182/300], Train Loss: 0.000720
Validation Loss: 0.00107463
Epoch [183/300], Train Loss: 0.000730
Validation Loss: 0.00106816
Epoch [184/300], Train Loss: 0.000719
Validation Loss: 0.00106346
Epoch [185/300], Train Loss: 0.000726
Validation Loss: 0.00106233
Epoch [186/300], Train Loss: 0.000725
Validation Loss: 0.00106346
Epoch [187/300], Train Loss: 0.000723
Validation Loss: 0.00107514
Epoch [188/300], Train Loss: 0.000728
Validation Loss: 0.00106349
Epoch [189/300], Train Loss: 0.000718
Validation Loss: 0.00106055
Epoch [190/300], Train Loss: 0.000722
Validation Loss: 0.00106025
Epoch [191/300], Train Loss: 0.000727
Validation Loss: 0.00105893
Epoch [192/300], Train Loss: 0.000727
Validation Loss: 0.00105887
Epoch [193/300], Train Loss: 0.000718
Validation Loss: 0.00105792
Epoch [194/300], Train Loss: 0.000719
Validation Loss: 0.00105805
Epoch [195/300], Train Loss: 0.000712
Validation Loss: 0.00106159
Epoch [196/300], Train Loss: 0.000709
Validation Loss: 0.00105767
Epoch [197/300], Train Loss: 0.000718
Validation Loss: 0.00105783
Epoch [198/300], Train Loss: 0.000707
Validation Loss: 0.00105665
Epoch [199/300], Train Loss: 0.000716
Validation Loss: 0.00105559
Epoch [200/300], Train Loss: 0.000704
Validation Loss: 0.00105470
Epoch [201/300], Train Loss: 0.000720
Validation Loss: 0.00105842
Epoch [202/300], Train Loss: 0.000708
Validation Loss: 0.00106228
Epoch [203/300], Train Loss: 0.000708
Validation Loss: 0.00105447
Epoch [204/300], Train Loss: 0.000712
Validation Loss: 0.00105303
Epoch [205/300], Train Loss: 0.000703
Validation Loss: 0.00105990
Epoch [206/300], Train Loss: 0.000702
Validation Loss: 0.00105197
Epoch [207/300], Train Loss: 0.000695
Validation Loss: 0.00105351
Epoch [208/300], Train Loss: 0.000744
Validation Loss: 0.00105086
Epoch [209/300], Train Loss: 0.000731
Validation Loss: 0.00105811
Epoch [210/300], Train Loss: 0.000700
Validation Loss: 0.00105326
Epoch [211/300], Train Loss: 0.000708
Validation Loss: 0.00105442
Epoch [212/300], Train Loss: 0.000698
Validation Loss: 0.00105374
Epoch [213/300], Train Loss: 0.000698
Validation Loss: 0.00105432
Epoch [214/300], Train Loss: 0.000700
Validation Loss: 0.00105055
Epoch [215/300], Train Loss: 0.000700
Validation Loss: 0.00105121
Epoch [216/300], Train Loss: 0.000699
Validation Loss: 0.00104783
Epoch [217/300], Train Loss: 0.000711
Validation Loss: 0.00105372
Epoch [218/300], Train Loss: 0.000671
Validation Loss: 0.00104485
Epoch [219/300], Train Loss: 0.000684
Validation Loss: 0.00104785
Epoch [220/300], Train Loss: 0.000709
Validation Loss: 0.00104464
Epoch [221/300], Train Loss: 0.000737
Validation Loss: 0.00104695
Epoch [222/300], Train Loss: 0.000683
Validation Loss: 0.00104506
Epoch [223/300], Train Loss: 0.000676
Validation Loss: 0.00104645
Epoch [224/300], Train Loss: 0.000751
Validation Loss: 0.00105376
Epoch [225/300], Train Loss: 0.000750
Validation Loss: 0.00105336
Epoch [226/300], Train Loss: 0.000725
Validation Loss: 0.00104514
Epoch [227/300], Train Loss: 0.000708
Validation Loss: 0.00104163
Epoch [228/300], Train Loss: 0.000696
Validation Loss: 0.00104231
Epoch [229/300], Train Loss: 0.000697
Validation Loss: 0.00104112
Epoch [230/300], Train Loss: 0.000686
Validation Loss: 0.00104437
Epoch [231/300], Train Loss: 0.000689
Validation Loss: 0.00104232
Epoch [232/300], Train Loss: 0.000674
Validation Loss: 0.00103948
Epoch [233/300], Train Loss: 0.000676
Validation Loss: 0.00104375
Epoch [234/300], Train Loss: 0.000655
Validation Loss: 0.00104183
Epoch [235/300], Train Loss: 0.000656
Validation Loss: 0.00104254
Epoch [236/300], Train Loss: 0.000656
Validation Loss: 0.00104000
Epoch [237/300], Train Loss: 0.000665
Validation Loss: 0.00103942
Epoch [238/300], Train Loss: 0.000694
Validation Loss: 0.00104215
Epoch [239/300], Train Loss: 0.000660
Validation Loss: 0.00104048
Epoch [240/300], Train Loss: 0.000664
Validation Loss: 0.00103839
Epoch [241/300], Train Loss: 0.000648
Validation Loss: 0.00103779
Epoch [242/300], Train Loss: 0.000650
Validation Loss: 0.00103860
Epoch [243/300], Train Loss: 0.000676
Validation Loss: 0.00103821
Epoch [244/300], Train Loss: 0.000654
Validation Loss: 0.00103592
Epoch [245/300], Train Loss: 0.000652
Validation Loss: 0.00103915
Epoch [246/300], Train Loss: 0.000650
Validation Loss: 0.00103866
Epoch [247/300], Train Loss: 0.000652
Validation Loss: 0.00103938
Epoch [248/300], Train Loss: 0.000647
Validation Loss: 0.00103769
Epoch [249/300], Train Loss: 0.000643
Validation Loss: 0.00103568
Epoch [250/300], Train Loss: 0.000646
Validation Loss: 0.00103458
Epoch [251/300], Train Loss: 0.000644
Validation Loss: 0.00103572
Epoch [252/300], Train Loss: 0.000644
Validation Loss: 0.00103601
Epoch [253/300], Train Loss: 0.000643
Validation Loss: 0.00103758
Epoch [254/300], Train Loss: 0.000658
Validation Loss: 0.00103427
Epoch [255/300], Train Loss: 0.000641
Validation Loss: 0.00103482
Epoch [256/300], Train Loss: 0.000644
Validation Loss: 0.00103561
Epoch [257/300], Train Loss: 0.000652
Validation Loss: 0.00104053
Epoch [258/300], Train Loss: 0.000650
Validation Loss: 0.00103375
Epoch [259/300], Train Loss: 0.000662
Validation Loss: 0.00103297
Epoch [260/300], Train Loss: 0.000641
Validation Loss: 0.00103368
Epoch [261/300], Train Loss: 0.000645
Validation Loss: 0.00103384
Epoch [262/300], Train Loss: 0.000637
Validation Loss: 0.00103318
Epoch [263/300], Train Loss: 0.000646
Validation Loss: 0.00103272
Epoch [264/300], Train Loss: 0.000641
Validation Loss: 0.00103113
Epoch [265/300], Train Loss: 0.000639
Validation Loss: 0.00103012
Epoch [266/300], Train Loss: 0.000664
Validation Loss: 0.00103283
Epoch [267/300], Train Loss: 0.000638
Validation Loss: 0.00102970
Epoch [268/300], Train Loss: 0.000663
Validation Loss: 0.00103151
Epoch [269/300], Train Loss: 0.000635
Validation Loss: 0.00103054
Epoch [270/300], Train Loss: 0.000635
Validation Loss: 0.00102924
Epoch [271/300], Train Loss: 0.000641
Validation Loss: 0.00102976
Epoch [272/300], Train Loss: 0.000642
Validation Loss: 0.00103230
Epoch [273/300], Train Loss: 0.000637
Validation Loss: 0.00102910
Epoch [274/300], Train Loss: 0.000634
Validation Loss: 0.00102857
Epoch [275/300], Train Loss: 0.000633
Validation Loss: 0.00102925
Epoch [276/300], Train Loss: 0.000635
Validation Loss: 0.00102990
Epoch [277/300], Train Loss: 0.000658
Validation Loss: 0.00102654
Epoch [278/300], Train Loss: 0.000631
Validation Loss: 0.00102726
Epoch [279/300], Train Loss: 0.000631
Validation Loss: 0.00102917
Epoch [280/300], Train Loss: 0.000631
Validation Loss: 0.00102980
Epoch [281/300], Train Loss: 0.000646
Validation Loss: 0.00102706
Epoch [282/300], Train Loss: 0.000654
Validation Loss: 0.00102559
Epoch [283/300], Train Loss: 0.000631
Validation Loss: 0.00102745
Epoch [284/300], Train Loss: 0.000634
Validation Loss: 0.00102458
Epoch [285/300], Train Loss: 0.000644
Validation Loss: 0.00102569
Epoch [286/300], Train Loss: 0.000656
Validation Loss: 0.00103297
Epoch [287/300], Train Loss: 0.000635
Validation Loss: 0.00102730
Epoch [288/300], Train Loss: 0.000640
Validation Loss: 0.00102494
Epoch [289/300], Train Loss: 0.000628
Validation Loss: 0.00102649
Epoch [290/300], Train Loss: 0.000634
Validation Loss: 0.00102370
Epoch [291/300], Train Loss: 0.000625
Validation Loss: 0.00102489
Epoch [292/300], Train Loss: 0.000627
Validation Loss: 0.00102646
Epoch [293/300], Train Loss: 0.000642
Validation Loss: 0.00102320
Epoch [294/300], Train Loss: 0.000634
Validation Loss: 0.00102205
Epoch [295/300], Train Loss: 0.000661
Validation Loss: 0.00102351
Epoch [296/300], Train Loss: 0.000623
Validation Loss: 0.00102116
Epoch [297/300], Train Loss: 0.000624
Validation Loss: 0.00102215
Epoch [298/300], Train Loss: 0.000624
Validation Loss: 0.00102167
Epoch [299/300], Train Loss: 0.000629
Validation Loss: 0.00102178
Epoch [300/300], Train Loss: 0.000672
Validation Loss: 0.00102256

Evaluating model for: Dryer
Run 31/72 completed in 1538.71 seconds with: {'MAE': np.float32(5.859699), 'MSE': np.float32(2842.325), 'RMSE': np.float32(53.313457), 'SAE': np.float32(0.18196365), 'NDE': np.float32(0.5685016)}

Run 32/72: hidden=256, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Dryer
Dataset length: 4586 windows

Epoch [1/300], Train Loss: 0.011561
Validation Loss: 0.01263873
Epoch [2/300], Train Loss: 0.010874
Validation Loss: 0.01260041
Epoch [3/300], Train Loss: 0.010886
Validation Loss: 0.01258907
Epoch [4/300], Train Loss: 0.010922
Validation Loss: 0.01221088
Epoch [5/300], Train Loss: 0.007696
Validation Loss: 0.00528305
Epoch [6/300], Train Loss: 0.004467
Validation Loss: 0.00353543
Epoch [7/300], Train Loss: 0.003609
Validation Loss: 0.00288834
Epoch [8/300], Train Loss: 0.003286
Validation Loss: 0.00307670
Epoch [9/300], Train Loss: 0.003241
Validation Loss: 0.00264301
Epoch [10/300], Train Loss: 0.003000
Validation Loss: 0.00268754
Epoch [11/300], Train Loss: 0.002907
Validation Loss: 0.00250972
Epoch [12/300], Train Loss: 0.002839
Validation Loss: 0.00282229
Epoch [13/300], Train Loss: 0.002674
Validation Loss: 0.00263082
Epoch [14/300], Train Loss: 0.002482
Validation Loss: 0.00282653
Epoch [15/300], Train Loss: 0.002738
Validation Loss: 0.00431226
Epoch [16/300], Train Loss: 0.002705
Validation Loss: 0.00222830
Epoch [17/300], Train Loss: 0.002139
Validation Loss: 0.00191728
Epoch [18/300], Train Loss: 0.002022
Validation Loss: 0.00184926
Epoch [19/300], Train Loss: 0.001998
Validation Loss: 0.00176280
Epoch [20/300], Train Loss: 0.001947
Validation Loss: 0.00167434
Epoch [21/300], Train Loss: 0.001812
Validation Loss: 0.00186393
Epoch [22/300], Train Loss: 0.002053
Validation Loss: 0.00155018
Epoch [23/300], Train Loss: 0.001871
Validation Loss: 0.00172517
Epoch [24/300], Train Loss: 0.001620
Validation Loss: 0.00175254
Epoch [25/300], Train Loss: 0.001584
Validation Loss: 0.00163090
Epoch [26/300], Train Loss: 0.001535
Validation Loss: 0.00161535
Epoch [27/300], Train Loss: 0.001471
Validation Loss: 0.00165056
Epoch [28/300], Train Loss: 0.001476
Validation Loss: 0.00159744
Epoch [29/300], Train Loss: 0.001418
Validation Loss: 0.00157541
Epoch [30/300], Train Loss: 0.001448
Validation Loss: 0.00156507
Epoch [31/300], Train Loss: 0.001431
Validation Loss: 0.00161424
Epoch [32/300], Train Loss: 0.001405
Validation Loss: 0.00166752
Early stopping triggered

Evaluating model for: Dryer
Run 32/72 completed in 191.37 seconds with: {'MAE': np.float32(6.429838), 'MSE': np.float32(1680.4108), 'RMSE': np.float32(40.992813), 'SAE': np.float32(0.0025885282), 'NDE': np.float32(0.4371211)}

Run 33/72: hidden=256, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Dryer
Dataset length: 3006 windows

Epoch [1/300], Train Loss: 0.010950
Validation Loss: 0.00806531
Epoch [2/300], Train Loss: 0.010580
Validation Loss: 0.00776767
Epoch [3/300], Train Loss: 0.010255
Validation Loss: 0.00764437
Epoch [4/300], Train Loss: 0.010042
Validation Loss: 0.00733349
Epoch [5/300], Train Loss: 0.009167
Validation Loss: 0.00626996
Epoch [6/300], Train Loss: 0.006160
Validation Loss: 0.00549256
Epoch [7/300], Train Loss: 0.004331
Validation Loss: 0.00504924
Epoch [8/300], Train Loss: 0.002836
Validation Loss: 0.00398575
Epoch [9/300], Train Loss: 0.002509
Validation Loss: 0.00364031
Epoch [10/300], Train Loss: 0.002348
Validation Loss: 0.00343235
Epoch [11/300], Train Loss: 0.002239
Validation Loss: 0.00332365
Epoch [12/300], Train Loss: 0.002112
Validation Loss: 0.00313544
Epoch [13/300], Train Loss: 0.002078
Validation Loss: 0.00292785
Epoch [14/300], Train Loss: 0.001897
Validation Loss: 0.00299390
Epoch [15/300], Train Loss: 0.001860
Validation Loss: 0.00270947
Epoch [16/300], Train Loss: 0.001764
Validation Loss: 0.00221332
Epoch [17/300], Train Loss: 0.001705
Validation Loss: 0.00200627
Epoch [18/300], Train Loss: 0.001576
Validation Loss: 0.00186539
Epoch [19/300], Train Loss: 0.001530
Validation Loss: 0.00175354
Epoch [20/300], Train Loss: 0.001479
Validation Loss: 0.00182256
Epoch [21/300], Train Loss: 0.001423
Validation Loss: 0.00150362
Epoch [22/300], Train Loss: 0.001410
Validation Loss: 0.00185733
Epoch [23/300], Train Loss: 0.001426
Validation Loss: 0.00245338
Epoch [24/300], Train Loss: 0.001494
Validation Loss: 0.00217117
Epoch [25/300], Train Loss: 0.001558
Validation Loss: 0.00198350
Epoch [26/300], Train Loss: 0.001332
Validation Loss: 0.00168702
Epoch [27/300], Train Loss: 0.001174
Validation Loss: 0.00137015
Epoch [28/300], Train Loss: 0.001116
Validation Loss: 0.00108020
Epoch [29/300], Train Loss: 0.001126
Validation Loss: 0.00107160
Epoch [30/300], Train Loss: 0.001033
Validation Loss: 0.00107288
Epoch [31/300], Train Loss: 0.001030
Validation Loss: 0.00102421
Epoch [32/300], Train Loss: 0.001062
Validation Loss: 0.00113088
Epoch [33/300], Train Loss: 0.001006
Validation Loss: 0.00092023
Epoch [34/300], Train Loss: 0.000962
Validation Loss: 0.00088273
Epoch [35/300], Train Loss: 0.000948
Validation Loss: 0.00092291
Epoch [36/300], Train Loss: 0.000951
Validation Loss: 0.00077938
Epoch [37/300], Train Loss: 0.000958
Validation Loss: 0.00096594
Epoch [38/300], Train Loss: 0.000904
Validation Loss: 0.00086455
Epoch [39/300], Train Loss: 0.000891
Validation Loss: 0.00080660
Epoch [40/300], Train Loss: 0.000896
Validation Loss: 0.00088448
Epoch [41/300], Train Loss: 0.000876
Validation Loss: 0.00094419
Epoch [42/300], Train Loss: 0.000913
Validation Loss: 0.00091123
Epoch [43/300], Train Loss: 0.000940
Validation Loss: 0.00106599
Epoch [44/300], Train Loss: 0.000919
Validation Loss: 0.00082127
Epoch [45/300], Train Loss: 0.000884
Validation Loss: 0.00079365
Epoch [46/300], Train Loss: 0.000849
Validation Loss: 0.00088444
Early stopping triggered

Evaluating model for: Dryer
Run 33/72 completed in 184.95 seconds with: {'MAE': np.float32(5.4293694), 'MSE': np.float32(1295.4087), 'RMSE': np.float32(35.991787), 'SAE': np.float32(0.008946845), 'NDE': np.float32(0.2603984)}

Run 34/72: hidden=256, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Dryer
Dataset length: 3006 windows

Epoch [1/300], Train Loss: 0.010721
Validation Loss: 0.00802862
Epoch [2/300], Train Loss: 0.010620
Validation Loss: 0.00786604
Epoch [3/300], Train Loss: 0.010417
Validation Loss: 0.00780546
Epoch [4/300], Train Loss: 0.010300
Validation Loss: 0.00756093
Epoch [5/300], Train Loss: 0.009235
Validation Loss: 0.00568556
Epoch [6/300], Train Loss: 0.005226
Validation Loss: 0.00425627
Epoch [7/300], Train Loss: 0.003521
Validation Loss: 0.00430137
Epoch [8/300], Train Loss: 0.003069
Validation Loss: 0.00401555
Epoch [9/300], Train Loss: 0.002926
Validation Loss: 0.00450000
Epoch [10/300], Train Loss: 0.002769
Validation Loss: 0.00363940
Epoch [11/300], Train Loss: 0.002598
Validation Loss: 0.00382531
Epoch [12/300], Train Loss: 0.002430
Validation Loss: 0.00356630
Epoch [13/300], Train Loss: 0.002392
Validation Loss: 0.00329191
Epoch [14/300], Train Loss: 0.002204
Validation Loss: 0.00329662
Epoch [15/300], Train Loss: 0.002101
Validation Loss: 0.00326161
Epoch [16/300], Train Loss: 0.001981
Validation Loss: 0.00259202
Epoch [17/300], Train Loss: 0.001926
Validation Loss: 0.00247324
Epoch [18/300], Train Loss: 0.001775
Validation Loss: 0.00236692
Epoch [19/300], Train Loss: 0.001669
Validation Loss: 0.00230203
Epoch [20/300], Train Loss: 0.001571
Validation Loss: 0.00206279
Epoch [21/300], Train Loss: 0.001492
Validation Loss: 0.00190052
Epoch [22/300], Train Loss: 0.001405
Validation Loss: 0.00151634
Epoch [23/300], Train Loss: 0.001308
Validation Loss: 0.00120032
Epoch [24/300], Train Loss: 0.001536
Validation Loss: 0.00167241
Epoch [25/300], Train Loss: 0.001243
Validation Loss: 0.00151907
Epoch [26/300], Train Loss: 0.001108
Validation Loss: 0.00123653
Epoch [27/300], Train Loss: 0.001088
Validation Loss: 0.00113497
Epoch [28/300], Train Loss: 0.001056
Validation Loss: 0.00117637
Epoch [29/300], Train Loss: 0.001197
Validation Loss: 0.00123794
Epoch [30/300], Train Loss: 0.001023
Validation Loss: 0.00109887
Epoch [31/300], Train Loss: 0.000962
Validation Loss: 0.00097885
Epoch [32/300], Train Loss: 0.000964
Validation Loss: 0.00085131
Epoch [33/300], Train Loss: 0.000915
Validation Loss: 0.00080118
Epoch [34/300], Train Loss: 0.000887
Validation Loss: 0.00079493
Epoch [35/300], Train Loss: 0.000894
Validation Loss: 0.00081840
Epoch [36/300], Train Loss: 0.001062
Validation Loss: 0.00085196
Epoch [37/300], Train Loss: 0.000970
Validation Loss: 0.00096888
Epoch [38/300], Train Loss: 0.000832
Validation Loss: 0.00085077
Epoch [39/300], Train Loss: 0.000814
Validation Loss: 0.00085541
Epoch [40/300], Train Loss: 0.000794
Validation Loss: 0.00070443
Epoch [41/300], Train Loss: 0.000781
Validation Loss: 0.00073644
Epoch [42/300], Train Loss: 0.000774
Validation Loss: 0.00076987
Epoch [43/300], Train Loss: 0.000808
Validation Loss: 0.00073083
Epoch [44/300], Train Loss: 0.000809
Validation Loss: 0.00078195
Epoch [45/300], Train Loss: 0.000759
Validation Loss: 0.00092246
Epoch [46/300], Train Loss: 0.000836
Validation Loss: 0.00091715
Epoch [47/300], Train Loss: 0.000763
Validation Loss: 0.00084430
Epoch [48/300], Train Loss: 0.000774
Validation Loss: 0.00080970
Epoch [49/300], Train Loss: 0.000726
Validation Loss: 0.00066293
Epoch [50/300], Train Loss: 0.000699
Validation Loss: 0.00065031
Epoch [51/300], Train Loss: 0.000696
Validation Loss: 0.00064299
Epoch [52/300], Train Loss: 0.000688
Validation Loss: 0.00062764
Epoch [53/300], Train Loss: 0.000701
Validation Loss: 0.00070584
Epoch [54/300], Train Loss: 0.000668
Validation Loss: 0.00060535
Epoch [55/300], Train Loss: 0.000670
Validation Loss: 0.00071900
Epoch [56/300], Train Loss: 0.000662
Validation Loss: 0.00056090
Epoch [57/300], Train Loss: 0.000629
Validation Loss: 0.00059252
Epoch [58/300], Train Loss: 0.000625
Validation Loss: 0.00055793
Epoch [59/300], Train Loss: 0.000625
Validation Loss: 0.00056256
Epoch [60/300], Train Loss: 0.000611
Validation Loss: 0.00054045
Epoch [61/300], Train Loss: 0.000594
Validation Loss: 0.00054958
Epoch [62/300], Train Loss: 0.000714
Validation Loss: 0.00267397
Epoch [63/300], Train Loss: 0.001091
Validation Loss: 0.00118116
Epoch [64/300], Train Loss: 0.000737
Validation Loss: 0.00085241
Epoch [65/300], Train Loss: 0.000704
Validation Loss: 0.00063151
Epoch [66/300], Train Loss: 0.000629
Validation Loss: 0.00058965
Epoch [67/300], Train Loss: 0.000606
Validation Loss: 0.00054678
Epoch [68/300], Train Loss: 0.000591
Validation Loss: 0.00054407
Epoch [69/300], Train Loss: 0.000586
Validation Loss: 0.00052292
Epoch [70/300], Train Loss: 0.000584
Validation Loss: 0.00051978
Epoch [71/300], Train Loss: 0.000562
Validation Loss: 0.00050538
Epoch [72/300], Train Loss: 0.000709
Validation Loss: 0.00058384
Epoch [73/300], Train Loss: 0.000611
Validation Loss: 0.00051877
Epoch [74/300], Train Loss: 0.000558
Validation Loss: 0.00052714
Epoch [75/300], Train Loss: 0.000546
Validation Loss: 0.00051607
Epoch [76/300], Train Loss: 0.000547
Validation Loss: 0.00049774
Epoch [77/300], Train Loss: 0.000631
Validation Loss: 0.00049151
Epoch [78/300], Train Loss: 0.000576
Validation Loss: 0.00053305
Epoch [79/300], Train Loss: 0.000543
Validation Loss: 0.00049078
Epoch [80/300], Train Loss: 0.000531
Validation Loss: 0.00047398
Epoch [81/300], Train Loss: 0.000515
Validation Loss: 0.00047137
Epoch [82/300], Train Loss: 0.000603
Validation Loss: 0.00050930
Epoch [83/300], Train Loss: 0.000522
Validation Loss: 0.00045437
Epoch [84/300], Train Loss: 0.002032
Validation Loss: 0.00294742
Epoch [85/300], Train Loss: 0.001246
Validation Loss: 0.00131691
Epoch [86/300], Train Loss: 0.000809
Validation Loss: 0.00108172
Epoch [87/300], Train Loss: 0.000721
Validation Loss: 0.00093127
Epoch [88/300], Train Loss: 0.000687
Validation Loss: 0.00088948
Epoch [89/300], Train Loss: 0.000663
Validation Loss: 0.00084630
Epoch [90/300], Train Loss: 0.000645
Validation Loss: 0.00081733
Epoch [91/300], Train Loss: 0.000623
Validation Loss: 0.00071313
Epoch [92/300], Train Loss: 0.000612
Validation Loss: 0.00077455
Epoch [93/300], Train Loss: 0.000588
Validation Loss: 0.00061241
Early stopping triggered

Evaluating model for: Dryer
Run 34/72 completed in 433.22 seconds with: {'MAE': np.float32(4.2714615), 'MSE': np.float32(883.7791), 'RMSE': np.float32(29.728422), 'SAE': np.float32(0.0030917076), 'NDE': np.float32(0.21508326)}

Run 35/72: hidden=256, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Dryer
Dataset length: 3006 windows

Epoch [1/300], Train Loss: 0.010895
Validation Loss: 0.00814875
Epoch [2/300], Train Loss: 0.010684
Validation Loss: 0.00791348
Epoch [3/300], Train Loss: 0.010504
Validation Loss: 0.00791793
Epoch [4/300], Train Loss: 0.010523
Validation Loss: 0.00788641
Epoch [5/300], Train Loss: 0.010337
Validation Loss: 0.00767725
Epoch [6/300], Train Loss: 0.008149
Validation Loss: 0.00562851
Epoch [7/300], Train Loss: 0.004077
Validation Loss: 0.00458840
Epoch [8/300], Train Loss: 0.003140
Validation Loss: 0.00386787
Epoch [9/300], Train Loss: 0.002827
Validation Loss: 0.00371750
Epoch [10/300], Train Loss: 0.002678
Validation Loss: 0.00348296
Epoch [11/300], Train Loss: 0.002472
Validation Loss: 0.00353066
Epoch [12/300], Train Loss: 0.002289
Validation Loss: 0.00321710
Epoch [13/300], Train Loss: 0.002239
Validation Loss: 0.00322258
Epoch [14/300], Train Loss: 0.002095
Validation Loss: 0.00344642
Epoch [15/300], Train Loss: 0.002128
Validation Loss: 0.00327548
Epoch [16/300], Train Loss: 0.001983
Validation Loss: 0.00279718
Epoch [17/300], Train Loss: 0.001901
Validation Loss: 0.00236704
Epoch [18/300], Train Loss: 0.001853
Validation Loss: 0.00244181
Epoch [19/300], Train Loss: 0.001659
Validation Loss: 0.00220975
Epoch [20/300], Train Loss: 0.001599
Validation Loss: 0.00234100
Epoch [21/300], Train Loss: 0.001486
Validation Loss: 0.00271571
Epoch [22/300], Train Loss: 0.001792
Validation Loss: 0.00173192
Epoch [23/300], Train Loss: 0.001544
Validation Loss: 0.00180428
Epoch [24/300], Train Loss: 0.001304
Validation Loss: 0.00234555
Epoch [25/300], Train Loss: 0.001325
Validation Loss: 0.00124735
Epoch [26/300], Train Loss: 0.001088
Validation Loss: 0.00104719
Epoch [27/300], Train Loss: 0.001056
Validation Loss: 0.00113593
Epoch [28/300], Train Loss: 0.001007
Validation Loss: 0.00107557
Epoch [29/300], Train Loss: 0.001003
Validation Loss: 0.00098146
Epoch [30/300], Train Loss: 0.000972
Validation Loss: 0.00170201
Epoch [31/300], Train Loss: 0.001329
Validation Loss: 0.00100432
Epoch [32/300], Train Loss: 0.005649
Validation Loss: 0.00730834
Epoch [33/300], Train Loss: 0.004371
Validation Loss: 0.00369430
Epoch [34/300], Train Loss: 0.002211
Validation Loss: 0.00341504
Epoch [35/300], Train Loss: 0.001957
Validation Loss: 0.00315796
Epoch [36/300], Train Loss: 0.001772
Validation Loss: 0.00267789
Epoch [37/300], Train Loss: 0.001652
Validation Loss: 0.00228659
Epoch [38/300], Train Loss: 0.001498
Validation Loss: 0.00184444
Epoch [39/300], Train Loss: 0.001729
Validation Loss: 0.00333272
Early stopping triggered

Evaluating model for: Dryer
Run 35/72 completed in 205.34 seconds with: {'MAE': np.float32(7.7440815), 'MSE': np.float32(3397.5652), 'RMSE': np.float32(58.288635), 'SAE': np.float32(0.11782079), 'NDE': np.float32(0.42171448)}

Run 36/72: hidden=256, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Dryer
Dataset length: 3006 windows

Epoch [1/300], Train Loss: 0.010793
Validation Loss: 0.00791956
Epoch [2/300], Train Loss: 0.010652
Validation Loss: 0.00795908
Epoch [3/300], Train Loss: 0.010493
Validation Loss: 0.00791379
Epoch [4/300], Train Loss: 0.010528
Validation Loss: 0.00789927
Epoch [5/300], Train Loss: 0.010042
Validation Loss: 0.00646404
Epoch [6/300], Train Loss: 0.004668
Validation Loss: 0.00445621
Epoch [7/300], Train Loss: 0.003062
Validation Loss: 0.00381263
Epoch [8/300], Train Loss: 0.002470
Validation Loss: 0.00355914
Epoch [9/300], Train Loss: 0.002378
Validation Loss: 0.00333492
Epoch [10/300], Train Loss: 0.002386
Validation Loss: 0.00334236
Epoch [11/300], Train Loss: 0.002273
Validation Loss: 0.00333377
Epoch [12/300], Train Loss: 0.002157
Validation Loss: 0.00334507
Epoch [13/300], Train Loss: 0.002099
Validation Loss: 0.00327000
Epoch [14/300], Train Loss: 0.002433
Validation Loss: 0.00285765
Epoch [15/300], Train Loss: 0.002602
Validation Loss: 0.00262234
Epoch [16/300], Train Loss: 0.002736
Validation Loss: 0.00254906
Epoch [17/300], Train Loss: 0.002643
Validation Loss: 0.00266687
Epoch [18/300], Train Loss: 0.002583
Validation Loss: 0.00258447
Epoch [19/300], Train Loss: 0.002488
Validation Loss: 0.00286797
Epoch [20/300], Train Loss: 0.002340
Validation Loss: 0.00223880
Epoch [21/300], Train Loss: 0.002087
Validation Loss: 0.00248268
Epoch [22/300], Train Loss: 0.002118
Validation Loss: 0.00249754
Epoch [23/300], Train Loss: 0.002138
Validation Loss: 0.00199549
Epoch [24/300], Train Loss: 0.001727
Validation Loss: 0.00228725
Epoch [25/300], Train Loss: 0.002664
Validation Loss: 0.00236569
Epoch [26/300], Train Loss: 0.002631
Validation Loss: 0.00243058
Epoch [27/300], Train Loss: 0.002602
Validation Loss: 0.00236489
Epoch [28/300], Train Loss: 0.002565
Validation Loss: 0.00219550
Epoch [29/300], Train Loss: 0.002583
Validation Loss: 0.00216081
Epoch [30/300], Train Loss: 0.002519
Validation Loss: 0.00205709
Epoch [31/300], Train Loss: 0.002476
Validation Loss: 0.00201907
Epoch [32/300], Train Loss: 0.002519
Validation Loss: 0.00193442
Epoch [33/300], Train Loss: 0.002480
Validation Loss: 0.00186558
Epoch [34/300], Train Loss: 0.002439
Validation Loss: 0.00184773
Epoch [35/300], Train Loss: 0.002431
Validation Loss: 0.00188580
Epoch [36/300], Train Loss: 0.002418
Validation Loss: 0.00179506
Epoch [37/300], Train Loss: 0.002441
Validation Loss: 0.00174046
Epoch [38/300], Train Loss: 0.002418
Validation Loss: 0.00181057
Epoch [39/300], Train Loss: 0.002400
Validation Loss: 0.00176713
Epoch [40/300], Train Loss: 0.002399
Validation Loss: 0.00175742
Epoch [41/300], Train Loss: 0.002428
Validation Loss: 0.00166258
Epoch [42/300], Train Loss: 0.002394
Validation Loss: 0.00172094
Epoch [43/300], Train Loss: 0.002370
Validation Loss: 0.00157138
Epoch [44/300], Train Loss: 0.002398
Validation Loss: 0.00180596
Epoch [45/300], Train Loss: 0.002461
Validation Loss: 0.00201149
Epoch [46/300], Train Loss: 0.002440
Validation Loss: 0.00187026
Epoch [47/300], Train Loss: 0.002421
Validation Loss: 0.00183847
Epoch [48/300], Train Loss: 0.002404
Validation Loss: 0.00185083
Epoch [49/300], Train Loss: 0.002386
Validation Loss: 0.00184140
Epoch [50/300], Train Loss: 0.002371
Validation Loss: 0.00174218
Epoch [51/300], Train Loss: 0.002405
Validation Loss: 0.00164115
Epoch [52/300], Train Loss: 0.002370
Validation Loss: 0.00174756
Epoch [53/300], Train Loss: 0.002369
Validation Loss: 0.00175223
Early stopping triggered

Evaluating model for: Dryer
Run 36/72 completed in 355.10 seconds with: {'MAE': np.float32(13.659948), 'MSE': np.float32(3969.2258), 'RMSE': np.float32(63.001793), 'SAE': np.float32(0.04786821), 'NDE': np.float32(0.4558142)}

Run 37/72: hidden=256, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Dryer
Dataset length: 1514 windows

Epoch [1/300], Train Loss: 0.010446
Validation Loss: 0.00830981
Epoch [2/300], Train Loss: 0.010156
Validation Loss: 0.00835192
Epoch [3/300], Train Loss: 0.009641
Validation Loss: 0.00824683
Epoch [4/300], Train Loss: 0.009940
Validation Loss: 0.00821294
Epoch [5/300], Train Loss: 0.010441
Validation Loss: 0.00817916
Epoch [6/300], Train Loss: 0.010212
Validation Loss: 0.00810613
Epoch [7/300], Train Loss: 0.010139
Validation Loss: 0.00797566
Epoch [8/300], Train Loss: 0.009517
Validation Loss: 0.00774177
Epoch [9/300], Train Loss: 0.008744
Validation Loss: 0.00717336
Epoch [10/300], Train Loss: 0.008354
Validation Loss: 0.00595896
Epoch [11/300], Train Loss: 0.007012
Validation Loss: 0.00451764
Epoch [12/300], Train Loss: 0.005424
Validation Loss: 0.00421937
Epoch [13/300], Train Loss: 0.004624
Validation Loss: 0.00302722
Epoch [14/300], Train Loss: 0.004147
Validation Loss: 0.00266466
Epoch [15/300], Train Loss: 0.003663
Validation Loss: 0.00249562
Epoch [16/300], Train Loss: 0.003440
Validation Loss: 0.00218296
Epoch [17/300], Train Loss: 0.003278
Validation Loss: 0.00213722
Epoch [18/300], Train Loss: 0.003042
Validation Loss: 0.00198704
Epoch [19/300], Train Loss: 0.002935
Validation Loss: 0.00185553
Epoch [20/300], Train Loss: 0.003015
Validation Loss: 0.00191986
Epoch [21/300], Train Loss: 0.002931
Validation Loss: 0.00174848
Epoch [22/300], Train Loss: 0.002862
Validation Loss: 0.00177671
Epoch [23/300], Train Loss: 0.002682
Validation Loss: 0.00153418
Epoch [24/300], Train Loss: 0.002741
Validation Loss: 0.00147502
Epoch [25/300], Train Loss: 0.002567
Validation Loss: 0.00144276
Epoch [26/300], Train Loss: 0.002367
Validation Loss: 0.00133070
Epoch [27/300], Train Loss: 0.002425
Validation Loss: 0.00221762
Epoch [28/300], Train Loss: 0.003006
Validation Loss: 0.00153681
Epoch [29/300], Train Loss: 0.002488
Validation Loss: 0.00194843
Epoch [30/300], Train Loss: 0.002743
Validation Loss: 0.00142981
Epoch [31/300], Train Loss: 0.002411
Validation Loss: 0.00137469
Epoch [32/300], Train Loss: 0.004942
Validation Loss: 0.00402897
Epoch [33/300], Train Loss: 0.003592
Validation Loss: 0.00189048
Epoch [34/300], Train Loss: 0.003205
Validation Loss: 0.00159381
Epoch [35/300], Train Loss: 0.002711
Validation Loss: 0.00157573
Epoch [36/300], Train Loss: 0.002715
Validation Loss: 0.00143768
Early stopping triggered

Evaluating model for: Dryer
Run 37/72 completed in 71.26 seconds with: {'MAE': np.float32(13.12703), 'MSE': np.float32(3987.578), 'RMSE': np.float32(63.14727), 'SAE': np.float32(0.047910694), 'NDE': np.float32(0.4288202)}

Run 38/72: hidden=256, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Dryer
Dataset length: 1514 windows

Epoch [1/300], Train Loss: 0.011561
Validation Loss: 0.00852064
Epoch [2/300], Train Loss: 0.010256
Validation Loss: 0.00842582
Epoch [3/300], Train Loss: 0.009758
Validation Loss: 0.00833233
Epoch [4/300], Train Loss: 0.009995
Validation Loss: 0.00827243
Epoch [5/300], Train Loss: 0.010551
Validation Loss: 0.00824320
Epoch [6/300], Train Loss: 0.010331
Validation Loss: 0.00821737
Epoch [7/300], Train Loss: 0.010303
Validation Loss: 0.00811330
Epoch [8/300], Train Loss: 0.009714
Validation Loss: 0.00787662
Epoch [9/300], Train Loss: 0.008898
Validation Loss: 0.00711157
Epoch [10/300], Train Loss: 0.006451
Validation Loss: 0.00383974
Epoch [11/300], Train Loss: 0.004852
Validation Loss: 0.00316120
Epoch [12/300], Train Loss: 0.003790
Validation Loss: 0.00254011
Epoch [13/300], Train Loss: 0.003318
Validation Loss: 0.00226829
Epoch [14/300], Train Loss: 0.003226
Validation Loss: 0.00200260
Epoch [15/300], Train Loss: 0.002911
Validation Loss: 0.00190677
Epoch [16/300], Train Loss: 0.002804
Validation Loss: 0.00179561
Epoch [17/300], Train Loss: 0.002673
Validation Loss: 0.00172979
Epoch [18/300], Train Loss: 0.002401
Validation Loss: 0.00168422
Epoch [19/300], Train Loss: 0.002235
Validation Loss: 0.00166577
Epoch [20/300], Train Loss: 0.002388
Validation Loss: 0.00231677
Epoch [21/300], Train Loss: 0.002779
Validation Loss: 0.00152641
Epoch [22/300], Train Loss: 0.002488
Validation Loss: 0.00160010
Epoch [23/300], Train Loss: 0.002220
Validation Loss: 0.00139604
Epoch [24/300], Train Loss: 0.002183
Validation Loss: 0.00137669
Epoch [25/300], Train Loss: 0.002174
Validation Loss: 0.00148709
Epoch [26/300], Train Loss: 0.002073
Validation Loss: 0.00128469
Epoch [27/300], Train Loss: 0.001873
Validation Loss: 0.00141368
Epoch [28/300], Train Loss: 0.002039
Validation Loss: 0.00132708
Epoch [29/300], Train Loss: 0.001735
Validation Loss: 0.00122163
Epoch [30/300], Train Loss: 0.001713
Validation Loss: 0.00122705
Epoch [31/300], Train Loss: 0.001815
Validation Loss: 0.00141697
Epoch [32/300], Train Loss: 0.003028
Validation Loss: 0.00137807
Epoch [33/300], Train Loss: 0.002443
Validation Loss: 0.00141481
Epoch [34/300], Train Loss: 0.002093
Validation Loss: 0.00121994
Epoch [35/300], Train Loss: 0.002003
Validation Loss: 0.00116419
Epoch [36/300], Train Loss: 0.001783
Validation Loss: 0.00112101
Epoch [37/300], Train Loss: 0.001730
Validation Loss: 0.00111622
Epoch [38/300], Train Loss: 0.001593
Validation Loss: 0.00108212
Epoch [39/300], Train Loss: 0.001750
Validation Loss: 0.00126930
Epoch [40/300], Train Loss: 0.001863
Validation Loss: 0.00107941
Epoch [41/300], Train Loss: 0.001532
Validation Loss: 0.00113656
Epoch [42/300], Train Loss: 0.001515
Validation Loss: 0.00102577
Epoch [43/300], Train Loss: 0.001557
Validation Loss: 0.00101294
Epoch [44/300], Train Loss: 0.001356
Validation Loss: 0.00102338
Epoch [45/300], Train Loss: 0.001388
Validation Loss: 0.00102281
Epoch [46/300], Train Loss: 0.001438
Validation Loss: 0.00100146
Epoch [47/300], Train Loss: 0.001448
Validation Loss: 0.00099797
Epoch [48/300], Train Loss: 0.001458
Validation Loss: 0.00096798
Epoch [49/300], Train Loss: 0.001536
Validation Loss: 0.00096789
Epoch [50/300], Train Loss: 0.001291
Validation Loss: 0.00098251
Epoch [51/300], Train Loss: 0.001518
Validation Loss: 0.00098294
Epoch [52/300], Train Loss: 0.001329
Validation Loss: 0.00093246
Epoch [53/300], Train Loss: 0.001371
Validation Loss: 0.00093379
Epoch [54/300], Train Loss: 0.001278
Validation Loss: 0.00092396
Epoch [55/300], Train Loss: 0.001330
Validation Loss: 0.00091900
Epoch [56/300], Train Loss: 0.001315
Validation Loss: 0.00088810
Epoch [57/300], Train Loss: 0.001223
Validation Loss: 0.00087598
Epoch [58/300], Train Loss: 0.001228
Validation Loss: 0.00087043
Epoch [59/300], Train Loss: 0.001365
Validation Loss: 0.00086063
Epoch [60/300], Train Loss: 0.001266
Validation Loss: 0.00080445
Epoch [61/300], Train Loss: 0.001389
Validation Loss: 0.00085078
Epoch [62/300], Train Loss: 0.001200
Validation Loss: 0.00078511
Epoch [63/300], Train Loss: 0.001183
Validation Loss: 0.00076390
Epoch [64/300], Train Loss: 0.001118
Validation Loss: 0.00075183
Epoch [65/300], Train Loss: 0.001105
Validation Loss: 0.00071565
Epoch [66/300], Train Loss: 0.001075
Validation Loss: 0.00070290
Epoch [67/300], Train Loss: 0.001073
Validation Loss: 0.00066751
Epoch [68/300], Train Loss: 0.001081
Validation Loss: 0.00064203
Epoch [69/300], Train Loss: 0.001033
Validation Loss: 0.00063256
Epoch [70/300], Train Loss: 0.001015
Validation Loss: 0.00063490
Epoch [71/300], Train Loss: 0.001094
Validation Loss: 0.00064608
Epoch [72/300], Train Loss: 0.001051
Validation Loss: 0.00062826
Epoch [73/300], Train Loss: 0.000983
Validation Loss: 0.00061510
Epoch [74/300], Train Loss: 0.000948
Validation Loss: 0.00064165
Epoch [75/300], Train Loss: 0.000973
Validation Loss: 0.00060825
Epoch [76/300], Train Loss: 0.001002
Validation Loss: 0.00060513
Epoch [77/300], Train Loss: 0.000943
Validation Loss: 0.00060202
Epoch [78/300], Train Loss: 0.000955
Validation Loss: 0.00061152
Epoch [79/300], Train Loss: 0.000915
Validation Loss: 0.00060566
Epoch [80/300], Train Loss: 0.000933
Validation Loss: 0.00060236
Epoch [81/300], Train Loss: 0.000893
Validation Loss: 0.00059486
Epoch [82/300], Train Loss: 0.000955
Validation Loss: 0.00059650
Epoch [83/300], Train Loss: 0.000887
Validation Loss: 0.00058432
Epoch [84/300], Train Loss: 0.000895
Validation Loss: 0.00058884
Epoch [85/300], Train Loss: 0.000929
Validation Loss: 0.00057682
Epoch [86/300], Train Loss: 0.000895
Validation Loss: 0.00058009
Epoch [87/300], Train Loss: 0.000893
Validation Loss: 0.00056889
Epoch [88/300], Train Loss: 0.000859
Validation Loss: 0.00057987
Epoch [89/300], Train Loss: 0.000911
Validation Loss: 0.00057960
Epoch [90/300], Train Loss: 0.000893
Validation Loss: 0.00057115
Epoch [91/300], Train Loss: 0.001000
Validation Loss: 0.00056207
Epoch [92/300], Train Loss: 0.000867
Validation Loss: 0.00058202
Epoch [93/300], Train Loss: 0.000864
Validation Loss: 0.00054878
Epoch [94/300], Train Loss: 0.000920
Validation Loss: 0.00054575
Epoch [95/300], Train Loss: 0.000846
Validation Loss: 0.00056665
Epoch [96/300], Train Loss: 0.000869
Validation Loss: 0.00054817
Epoch [97/300], Train Loss: 0.000826
Validation Loss: 0.00054509
Epoch [98/300], Train Loss: 0.000881
Validation Loss: 0.00054280
Epoch [99/300], Train Loss: 0.000815
Validation Loss: 0.00053953
Epoch [100/300], Train Loss: 0.000873
Validation Loss: 0.00055275
Epoch [101/300], Train Loss: 0.000833
Validation Loss: 0.00054203
Epoch [102/300], Train Loss: 0.000837
Validation Loss: 0.00053636
Epoch [103/300], Train Loss: 0.000844
Validation Loss: 0.00053116
Epoch [104/300], Train Loss: 0.000849
Validation Loss: 0.00053204
Epoch [105/300], Train Loss: 0.000778
Validation Loss: 0.00053199
Epoch [106/300], Train Loss: 0.000776
Validation Loss: 0.00053327
Epoch [107/300], Train Loss: 0.000852
Validation Loss: 0.00052667
Epoch [108/300], Train Loss: 0.000764
Validation Loss: 0.00052113
Epoch [109/300], Train Loss: 0.000762
Validation Loss: 0.00053562
Epoch [110/300], Train Loss: 0.000779
Validation Loss: 0.00052068
Epoch [111/300], Train Loss: 0.000814
Validation Loss: 0.00052785
Epoch [112/300], Train Loss: 0.000799
Validation Loss: 0.00051797
Epoch [113/300], Train Loss: 0.000779
Validation Loss: 0.00051171
Epoch [114/300], Train Loss: 0.000777
Validation Loss: 0.00051367
Epoch [115/300], Train Loss: 0.000820
Validation Loss: 0.00050588
Epoch [116/300], Train Loss: 0.000814
Validation Loss: 0.00050752
Epoch [117/300], Train Loss: 0.000766
Validation Loss: 0.00050528
Epoch [118/300], Train Loss: 0.000770
Validation Loss: 0.00050664
Epoch [119/300], Train Loss: 0.000728
Validation Loss: 0.00050856
Epoch [120/300], Train Loss: 0.000758
Validation Loss: 0.00050763
Epoch [121/300], Train Loss: 0.000767
Validation Loss: 0.00051063
Epoch [122/300], Train Loss: 0.000745
Validation Loss: 0.00050496
Epoch [123/300], Train Loss: 0.000750
Validation Loss: 0.00049637
Epoch [124/300], Train Loss: 0.000725
Validation Loss: 0.00049495
Epoch [125/300], Train Loss: 0.000743
Validation Loss: 0.00049586
Epoch [126/300], Train Loss: 0.000731
Validation Loss: 0.00049698
Epoch [127/300], Train Loss: 0.000700
Validation Loss: 0.00049676
Epoch [128/300], Train Loss: 0.000759
Validation Loss: 0.00049598
Epoch [129/300], Train Loss: 0.000768
Validation Loss: 0.00049021
Epoch [130/300], Train Loss: 0.000737
Validation Loss: 0.00049057
Epoch [131/300], Train Loss: 0.000762
Validation Loss: 0.00050682
Epoch [132/300], Train Loss: 0.000715
Validation Loss: 0.00048516
Epoch [133/300], Train Loss: 0.000716
Validation Loss: 0.00048387
Epoch [134/300], Train Loss: 0.000753
Validation Loss: 0.00048630
Epoch [135/300], Train Loss: 0.000710
Validation Loss: 0.00048711
Epoch [136/300], Train Loss: 0.000724
Validation Loss: 0.00048085
Epoch [137/300], Train Loss: 0.000706
Validation Loss: 0.00048648
Epoch [138/300], Train Loss: 0.000732
Validation Loss: 0.00047545
Epoch [139/300], Train Loss: 0.000694
Validation Loss: 0.00049021
Epoch [140/300], Train Loss: 0.000700
Validation Loss: 0.00048510
Epoch [141/300], Train Loss: 0.000743
Validation Loss: 0.00048764
Epoch [142/300], Train Loss: 0.000753
Validation Loss: 0.00047440
Epoch [143/300], Train Loss: 0.000694
Validation Loss: 0.00048303
Epoch [144/300], Train Loss: 0.000680
Validation Loss: 0.00047960
Epoch [145/300], Train Loss: 0.000699
Validation Loss: 0.00047209
Epoch [146/300], Train Loss: 0.000676
Validation Loss: 0.00046696
Epoch [147/300], Train Loss: 0.000659
Validation Loss: 0.00046812
Epoch [148/300], Train Loss: 0.000683
Validation Loss: 0.00046774
Epoch [149/300], Train Loss: 0.000681
Validation Loss: 0.00046841
Epoch [150/300], Train Loss: 0.000677
Validation Loss: 0.00046950
Epoch [151/300], Train Loss: 0.000664
Validation Loss: 0.00046413
Epoch [152/300], Train Loss: 0.000697
Validation Loss: 0.00046905
Epoch [153/300], Train Loss: 0.000649
Validation Loss: 0.00046119
Epoch [154/300], Train Loss: 0.000711
Validation Loss: 0.00046730
Epoch [155/300], Train Loss: 0.000660
Validation Loss: 0.00047756
Epoch [156/300], Train Loss: 0.000712
Validation Loss: 0.00045067
Epoch [157/300], Train Loss: 0.000678
Validation Loss: 0.00045491
Epoch [158/300], Train Loss: 0.000664
Validation Loss: 0.00045437
Epoch [159/300], Train Loss: 0.000678
Validation Loss: 0.00045103
Epoch [160/300], Train Loss: 0.000715
Validation Loss: 0.00045636
Epoch [161/300], Train Loss: 0.000698
Validation Loss: 0.00046479
Epoch [162/300], Train Loss: 0.000694
Validation Loss: 0.00045740
Epoch [163/300], Train Loss: 0.000653
Validation Loss: 0.00045897
Epoch [164/300], Train Loss: 0.000647
Validation Loss: 0.00045033
Epoch [165/300], Train Loss: 0.000664
Validation Loss: 0.00045260
Epoch [166/300], Train Loss: 0.000640
Validation Loss: 0.00045573
Epoch [167/300], Train Loss: 0.000649
Validation Loss: 0.00044816
Epoch [168/300], Train Loss: 0.000664
Validation Loss: 0.00044559
Epoch [169/300], Train Loss: 0.000624
Validation Loss: 0.00044524
Epoch [170/300], Train Loss: 0.000600
Validation Loss: 0.00046083
Epoch [171/300], Train Loss: 0.000653
Validation Loss: 0.00045587
Epoch [172/300], Train Loss: 0.000629
Validation Loss: 0.00044804
Epoch [173/300], Train Loss: 0.000603
Validation Loss: 0.00045527
Epoch [174/300], Train Loss: 0.000639
Validation Loss: 0.00045063
Epoch [175/300], Train Loss: 0.000653
Validation Loss: 0.00043605
Epoch [176/300], Train Loss: 0.000624
Validation Loss: 0.00043789
Epoch [177/300], Train Loss: 0.000833
Validation Loss: 0.00066448
Epoch [178/300], Train Loss: 0.001313
Validation Loss: 0.00061193
Epoch [179/300], Train Loss: 0.001092
Validation Loss: 0.00057471
Epoch [180/300], Train Loss: 0.001048
Validation Loss: 0.00054813
Epoch [181/300], Train Loss: 0.000964
Validation Loss: 0.00051615
Epoch [182/300], Train Loss: 0.000903
Validation Loss: 0.00048623
Epoch [183/300], Train Loss: 0.000906
Validation Loss: 0.00047391
Epoch [184/300], Train Loss: 0.000898
Validation Loss: 0.00045870
Epoch [185/300], Train Loss: 0.000852
Validation Loss: 0.00045464
Early stopping triggered

Evaluating model for: Dryer
Run 38/72 completed in 436.16 seconds with: {'MAE': np.float32(4.9957867), 'MSE': np.float32(1438.3861), 'RMSE': np.float32(37.92606), 'SAE': np.float32(0.047052164), 'NDE': np.float32(0.25754812)}

Run 39/72: hidden=256, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Dryer
Dataset length: 1514 windows

Epoch [1/300], Train Loss: 0.010330
Validation Loss: 0.00830477
Epoch [2/300], Train Loss: 0.010137
Validation Loss: 0.00830186
Epoch [3/300], Train Loss: 0.009726
Validation Loss: 0.00831763
Epoch [4/300], Train Loss: 0.010026
Validation Loss: 0.00829597
Epoch [5/300], Train Loss: 0.010601
Validation Loss: 0.00828885
Epoch [6/300], Train Loss: 0.010442
Validation Loss: 0.00827700
Epoch [7/300], Train Loss: 0.010459
Validation Loss: 0.00823345
Epoch [8/300], Train Loss: 0.009980
Validation Loss: 0.00810436
Epoch [9/300], Train Loss: 0.009345
Validation Loss: 0.00764508
Epoch [10/300], Train Loss: 0.009262
Validation Loss: 0.00657459
Epoch [11/300], Train Loss: 0.006642
Validation Loss: 0.00357311
Epoch [12/300], Train Loss: 0.004015
Validation Loss: 0.00260744
Epoch [13/300], Train Loss: 0.003834
Validation Loss: 0.00238838
Epoch [14/300], Train Loss: 0.003346
Validation Loss: 0.00215636
Epoch [15/300], Train Loss: 0.003068
Validation Loss: 0.00197888
Epoch [16/300], Train Loss: 0.002968
Validation Loss: 0.00185103
Epoch [17/300], Train Loss: 0.002832
Validation Loss: 0.00182325
Epoch [18/300], Train Loss: 0.002684
Validation Loss: 0.00168862
Epoch [19/300], Train Loss: 0.002536
Validation Loss: 0.00162998
Epoch [20/300], Train Loss: 0.002683
Validation Loss: 0.00164792
Epoch [21/300], Train Loss: 0.002672
Validation Loss: 0.00154327
Epoch [22/300], Train Loss: 0.002541
Validation Loss: 0.00148239
Epoch [23/300], Train Loss: 0.002703
Validation Loss: 0.00284440
Epoch [24/300], Train Loss: 0.002859
Validation Loss: 0.00317829
Epoch [25/300], Train Loss: 0.002719
Validation Loss: 0.00289168
Epoch [26/300], Train Loss: 0.002676
Validation Loss: 0.00284510
Epoch [27/300], Train Loss: 0.002632
Validation Loss: 0.00269265
Epoch [28/300], Train Loss: 0.002844
Validation Loss: 0.00267950
Epoch [29/300], Train Loss: 0.002526
Validation Loss: 0.00268762
Epoch [30/300], Train Loss: 0.002262
Validation Loss: 0.00265604
Epoch [31/300], Train Loss: 0.002435
Validation Loss: 0.00264600
Epoch [32/300], Train Loss: 0.002412
Validation Loss: 0.00263914
Early stopping triggered

Evaluating model for: Dryer
Run 39/72 completed in 85.85 seconds with: {'MAE': np.float32(9.73739), 'MSE': np.float32(4189.1753), 'RMSE': np.float32(64.72384), 'SAE': np.float32(0.23033643), 'NDE': np.float32(0.43952537)}

Run 40/72: hidden=256, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Dryer
Dataset length: 1514 windows

Epoch [1/300], Train Loss: 0.010521
Validation Loss: 0.00832170
Epoch [2/300], Train Loss: 0.010204
Validation Loss: 0.00839030
Epoch [3/300], Train Loss: 0.009706
Validation Loss: 0.00831150
Epoch [4/300], Train Loss: 0.010047
Validation Loss: 0.00830972
Epoch [5/300], Train Loss: 0.010614
Validation Loss: 0.00831539
Epoch [6/300], Train Loss: 0.010464
Validation Loss: 0.00831788
Epoch [7/300], Train Loss: 0.010504
Validation Loss: 0.00831251
Epoch [8/300], Train Loss: 0.010083
Validation Loss: 0.00828172
Epoch [9/300], Train Loss: 0.009649
Validation Loss: 0.00821359
Epoch [10/300], Train Loss: 0.010698
Validation Loss: 0.00774845
Epoch [11/300], Train Loss: 0.007779
Validation Loss: 0.00400983
Epoch [12/300], Train Loss: 0.004168
Validation Loss: 0.00236071
Epoch [13/300], Train Loss: 0.003711
Validation Loss: 0.00225625
Epoch [14/300], Train Loss: 0.003045
Validation Loss: 0.00194870
Epoch [15/300], Train Loss: 0.002856
Validation Loss: 0.00189663
Epoch [16/300], Train Loss: 0.002850
Validation Loss: 0.00170732
Epoch [17/300], Train Loss: 0.002693
Validation Loss: 0.00177493
Epoch [18/300], Train Loss: 0.002582
Validation Loss: 0.00159386
Epoch [19/300], Train Loss: 0.002442
Validation Loss: 0.00152691
Epoch [20/300], Train Loss: 0.002470
Validation Loss: 0.00143212
Epoch [21/300], Train Loss: 0.002520
Validation Loss: 0.00143803
Epoch [22/300], Train Loss: 0.002495
Validation Loss: 0.00149377
Epoch [23/300], Train Loss: 0.002376
Validation Loss: 0.00142043
Epoch [24/300], Train Loss: 0.002529
Validation Loss: 0.00138966
Epoch [25/300], Train Loss: 0.002446
Validation Loss: 0.00133564
Epoch [26/300], Train Loss: 0.002414
Validation Loss: 0.00132752
Epoch [27/300], Train Loss: 0.002169
Validation Loss: 0.00132951
Epoch [28/300], Train Loss: 0.002335
Validation Loss: 0.00125184
Epoch [29/300], Train Loss: 0.002129
Validation Loss: 0.00120613
Epoch [30/300], Train Loss: 0.001985
Validation Loss: 0.00122348
Epoch [31/300], Train Loss: 0.001983
Validation Loss: 0.00128290
Epoch [32/300], Train Loss: 0.001903
Validation Loss: 0.00111084
Epoch [33/300], Train Loss: 0.002028
Validation Loss: 0.00122869
Epoch [34/300], Train Loss: 0.001981
Validation Loss: 0.00108143
Epoch [35/300], Train Loss: 0.001693
Validation Loss: 0.00112473
Epoch [36/300], Train Loss: 0.001696
Validation Loss: 0.00103304
Epoch [37/300], Train Loss: 0.001642
Validation Loss: 0.00101108
Epoch [38/300], Train Loss: 0.001451
Validation Loss: 0.00101864
Epoch [39/300], Train Loss: 0.001539
Validation Loss: 0.00094902
Epoch [40/300], Train Loss: 0.001369
Validation Loss: 0.00102311
Epoch [41/300], Train Loss: 0.001439
Validation Loss: 0.00084697
Epoch [42/300], Train Loss: 0.001381
Validation Loss: 0.00095925
Epoch [43/300], Train Loss: 0.001285
Validation Loss: 0.00085729
Epoch [44/300], Train Loss: 0.001142
Validation Loss: 0.00084870
Epoch [45/300], Train Loss: 0.001191
Validation Loss: 0.00075606
Epoch [46/300], Train Loss: 0.001132
Validation Loss: 0.00072547
Epoch [47/300], Train Loss: 0.001073
Validation Loss: 0.00069937
Epoch [48/300], Train Loss: 0.001177
Validation Loss: 0.00070024
Epoch [49/300], Train Loss: 0.001115
Validation Loss: 0.00069254
Epoch [50/300], Train Loss: 0.000993
Validation Loss: 0.00064497
Epoch [51/300], Train Loss: 0.001033
Validation Loss: 0.00065535
Epoch [52/300], Train Loss: 0.000951
Validation Loss: 0.00058309
Epoch [53/300], Train Loss: 0.001039
Validation Loss: 0.00059000
Epoch [54/300], Train Loss: 0.000899
Validation Loss: 0.00055656
Epoch [55/300], Train Loss: 0.000970
Validation Loss: 0.00063189
Epoch [56/300], Train Loss: 0.000949
Validation Loss: 0.00053587
Epoch [57/300], Train Loss: 0.000878
Validation Loss: 0.00053958
Epoch [58/300], Train Loss: 0.000857
Validation Loss: 0.00057991
Epoch [59/300], Train Loss: 0.000894
Validation Loss: 0.00054583
Epoch [60/300], Train Loss: 0.000889
Validation Loss: 0.00051724
Epoch [61/300], Train Loss: 0.000900
Validation Loss: 0.00057356
Epoch [62/300], Train Loss: 0.000889
Validation Loss: 0.00052867
Epoch [63/300], Train Loss: 0.000860
Validation Loss: 0.00051620
Epoch [64/300], Train Loss: 0.000800
Validation Loss: 0.00055941
Epoch [65/300], Train Loss: 0.000830
Validation Loss: 0.00051319
Epoch [66/300], Train Loss: 0.000813
Validation Loss: 0.00052679
Epoch [67/300], Train Loss: 0.000856
Validation Loss: 0.00051882
Epoch [68/300], Train Loss: 0.000842
Validation Loss: 0.00050359
Epoch [69/300], Train Loss: 0.000791
Validation Loss: 0.00048987
Epoch [70/300], Train Loss: 0.000800
Validation Loss: 0.00051269
Epoch [71/300], Train Loss: 0.000910
Validation Loss: 0.00051251
Epoch [72/300], Train Loss: 0.000874
Validation Loss: 0.00053695
Epoch [73/300], Train Loss: 0.000818
Validation Loss: 0.00051765
Epoch [74/300], Train Loss: 0.000789
Validation Loss: 0.00049552
Epoch [75/300], Train Loss: 0.000781
Validation Loss: 0.00049148
Epoch [76/300], Train Loss: 0.000793
Validation Loss: 0.00047667
Epoch [77/300], Train Loss: 0.000733
Validation Loss: 0.00048841
Epoch [78/300], Train Loss: 0.000765
Validation Loss: 0.00048242
Epoch [79/300], Train Loss: 0.000740
Validation Loss: 0.00047527
Epoch [80/300], Train Loss: 0.000763
Validation Loss: 0.00046851
Epoch [81/300], Train Loss: 0.000732
Validation Loss: 0.00048037
Epoch [82/300], Train Loss: 0.000774
Validation Loss: 0.00048017
Epoch [83/300], Train Loss: 0.000716
Validation Loss: 0.00044941
Epoch [84/300], Train Loss: 0.000718
Validation Loss: 0.00045805
Epoch [85/300], Train Loss: 0.000739
Validation Loss: 0.00044624
Epoch [86/300], Train Loss: 0.000712
Validation Loss: 0.00047555
Epoch [87/300], Train Loss: 0.000704
Validation Loss: 0.00044719
Epoch [88/300], Train Loss: 0.000667
Validation Loss: 0.00047585
Epoch [89/300], Train Loss: 0.000690
Validation Loss: 0.00043943
Epoch [90/300], Train Loss: 0.000672
Validation Loss: 0.00047489
Epoch [91/300], Train Loss: 0.000796
Validation Loss: 0.00045584
Epoch [92/300], Train Loss: 0.000677
Validation Loss: 0.00044402
Epoch [93/300], Train Loss: 0.000654
Validation Loss: 0.00045598
Epoch [94/300], Train Loss: 0.000751
Validation Loss: 0.00041894
Epoch [95/300], Train Loss: 0.000709
Validation Loss: 0.00047355
Epoch [96/300], Train Loss: 0.000658
Validation Loss: 0.00043548
Epoch [97/300], Train Loss: 0.000624
Validation Loss: 0.00043747
Epoch [98/300], Train Loss: 0.000663
Validation Loss: 0.00043327
Epoch [99/300], Train Loss: 0.000620
Validation Loss: 0.00044271
Epoch [100/300], Train Loss: 0.000681
Validation Loss: 0.00041737
Epoch [101/300], Train Loss: 0.000624
Validation Loss: 0.00042321
Epoch [102/300], Train Loss: 0.000632
Validation Loss: 0.00043341
Epoch [103/300], Train Loss: 0.000657
Validation Loss: 0.00042070
Epoch [104/300], Train Loss: 0.000685
Validation Loss: 0.00043963
Epoch [105/300], Train Loss: 0.000629
Validation Loss: 0.00041678
Epoch [106/300], Train Loss: 0.000609
Validation Loss: 0.00040242
Epoch [107/300], Train Loss: 0.000661
Validation Loss: 0.00041899
Epoch [108/300], Train Loss: 0.000628
Validation Loss: 0.00041612
Epoch [109/300], Train Loss: 0.000610
Validation Loss: 0.00041930
Epoch [110/300], Train Loss: 0.000607
Validation Loss: 0.00044929
Epoch [111/300], Train Loss: 0.000671
Validation Loss: 0.00042619
Epoch [112/300], Train Loss: 0.000596
Validation Loss: 0.00042094
Epoch [113/300], Train Loss: 0.000581
Validation Loss: 0.00040548
Epoch [114/300], Train Loss: 0.000592
Validation Loss: 0.00042947
Epoch [115/300], Train Loss: 0.000630
Validation Loss: 0.00039832
Epoch [116/300], Train Loss: 0.000616
Validation Loss: 0.00041124
Epoch [117/300], Train Loss: 0.000579
Validation Loss: 0.00040742
Epoch [118/300], Train Loss: 0.000631
Validation Loss: 0.00041329
Epoch [119/300], Train Loss: 0.000543
Validation Loss: 0.00040943
Epoch [120/300], Train Loss: 0.000602
Validation Loss: 0.00039320
Epoch [121/300], Train Loss: 0.000602
Validation Loss: 0.00041702
Epoch [122/300], Train Loss: 0.000634
Validation Loss: 0.00040315
Epoch [123/300], Train Loss: 0.000582
Validation Loss: 0.00043027
Epoch [124/300], Train Loss: 0.000575
Validation Loss: 0.00040783
Epoch [125/300], Train Loss: 0.000577
Validation Loss: 0.00041028
Epoch [126/300], Train Loss: 0.000544
Validation Loss: 0.00039846
Epoch [127/300], Train Loss: 0.000559
Validation Loss: 0.00038786
Epoch [128/300], Train Loss: 0.000579
Validation Loss: 0.00040594
Epoch [129/300], Train Loss: 0.000689
Validation Loss: 0.00039125
Epoch [130/300], Train Loss: 0.001565
Validation Loss: 0.00087686
Epoch [131/300], Train Loss: 0.001531
Validation Loss: 0.00080235
Epoch [132/300], Train Loss: 0.001446
Validation Loss: 0.00061150
Epoch [133/300], Train Loss: 0.001222
Validation Loss: 0.00056717
Epoch [134/300], Train Loss: 0.001072
Validation Loss: 0.00047028
Epoch [135/300], Train Loss: 0.000853
Validation Loss: 0.00044172
Epoch [136/300], Train Loss: 0.000816
Validation Loss: 0.00043110
Epoch [137/300], Train Loss: 0.000740
Validation Loss: 0.00042335
Early stopping triggered

Evaluating model for: Dryer
Run 40/72 completed in 468.59 seconds with: {'MAE': np.float32(5.3610864), 'MSE': np.float32(1286.7843), 'RMSE': np.float32(35.871777), 'SAE': np.float32(0.021488875), 'NDE': np.float32(0.243598)}

Run 41/72: hidden=256, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Dryer
Dataset length: 1470 windows

Epoch [1/300], Train Loss: 0.010693
Validation Loss: 0.00819365
Epoch [2/300], Train Loss: 0.009727
Validation Loss: 0.00805826
Epoch [3/300], Train Loss: 0.009693
Validation Loss: 0.00801226
Epoch [4/300], Train Loss: 0.009774
Validation Loss: 0.00794624
Epoch [5/300], Train Loss: 0.009846
Validation Loss: 0.00783791
Epoch [6/300], Train Loss: 0.009968
Validation Loss: 0.00765000
Epoch [7/300], Train Loss: 0.009906
Validation Loss: 0.00732625
Epoch [8/300], Train Loss: 0.009143
Validation Loss: 0.00652395
Epoch [9/300], Train Loss: 0.007210
Validation Loss: 0.00495930
Epoch [10/300], Train Loss: 0.005791
Validation Loss: 0.00374273
Epoch [11/300], Train Loss: 0.005846
Validation Loss: 0.00321516
Epoch [12/300], Train Loss: 0.004438
Validation Loss: 0.00250867
Epoch [13/300], Train Loss: 0.003846
Validation Loss: 0.00236390
Epoch [14/300], Train Loss: 0.003618
Validation Loss: 0.00220874
Epoch [15/300], Train Loss: 0.003465
Validation Loss: 0.00191972
Epoch [16/300], Train Loss: 0.002817
Validation Loss: 0.00176727
Epoch [17/300], Train Loss: 0.002620
Validation Loss: 0.00180870
Epoch [18/300], Train Loss: 0.002530
Validation Loss: 0.00161218
Epoch [19/300], Train Loss: 0.002363
Validation Loss: 0.00159081
Epoch [20/300], Train Loss: 0.002464
Validation Loss: 0.00159468
Epoch [21/300], Train Loss: 0.002164
Validation Loss: 0.00165065
Epoch [22/300], Train Loss: 0.002248
Validation Loss: 0.00183251
Epoch [23/300], Train Loss: 0.002055
Validation Loss: 0.00148247
Epoch [24/300], Train Loss: 0.001810
Validation Loss: 0.00157649
Epoch [25/300], Train Loss: 0.001962
Validation Loss: 0.00148781
Epoch [26/300], Train Loss: 0.001921
Validation Loss: 0.00300086
Epoch [27/300], Train Loss: 0.003013
Validation Loss: 0.00144614
Epoch [28/300], Train Loss: 0.002499
Validation Loss: 0.00150950
Epoch [29/300], Train Loss: 0.002489
Validation Loss: 0.00131725
Epoch [30/300], Train Loss: 0.002115
Validation Loss: 0.00141304
Epoch [31/300], Train Loss: 0.002297
Validation Loss: 0.00127989
Epoch [32/300], Train Loss: 0.001892
Validation Loss: 0.00126334
Epoch [33/300], Train Loss: 0.001905
Validation Loss: 0.00123805
Epoch [34/300], Train Loss: 0.001709
Validation Loss: 0.00120527
Epoch [35/300], Train Loss: 0.001511
Validation Loss: 0.00110300
Epoch [36/300], Train Loss: 0.001487
Validation Loss: 0.00118074
Epoch [37/300], Train Loss: 0.001418
Validation Loss: 0.00103785
Epoch [38/300], Train Loss: 0.001491
Validation Loss: 0.00105083
Epoch [39/300], Train Loss: 0.001286
Validation Loss: 0.00103809
Epoch [40/300], Train Loss: 0.001211
Validation Loss: 0.00106590
Epoch [41/300], Train Loss: 0.001320
Validation Loss: 0.00102528
Epoch [42/300], Train Loss: 0.001442
Validation Loss: 0.00100196
Epoch [43/300], Train Loss: 0.001193
Validation Loss: 0.00082464
Epoch [44/300], Train Loss: 0.001435
Validation Loss: 0.00147398
Epoch [45/300], Train Loss: 0.001152
Validation Loss: 0.00082861
Epoch [46/300], Train Loss: 0.001070
Validation Loss: 0.00332647
Epoch [47/300], Train Loss: 0.001819
Validation Loss: 0.00107007
Epoch [48/300], Train Loss: 0.001270
Validation Loss: 0.00077420
Epoch [49/300], Train Loss: 0.001283
Validation Loss: 0.00073280
Epoch [50/300], Train Loss: 0.001415
Validation Loss: 0.00074167
Epoch [51/300], Train Loss: 0.000969
Validation Loss: 0.00072654
Epoch [52/300], Train Loss: 0.001211
Validation Loss: 0.00087938
Epoch [53/300], Train Loss: 0.002102
Validation Loss: 0.00151894
Epoch [54/300], Train Loss: 0.002539
Validation Loss: 0.00171217
Epoch [55/300], Train Loss: 0.002155
Validation Loss: 0.00137447
Epoch [56/300], Train Loss: 0.002408
Validation Loss: 0.00141512
Epoch [57/300], Train Loss: 0.001975
Validation Loss: 0.00136878
Epoch [58/300], Train Loss: 0.002094
Validation Loss: 0.00131716
Epoch [59/300], Train Loss: 0.001872
Validation Loss: 0.00133005
Epoch [60/300], Train Loss: 0.001793
Validation Loss: 0.00126550
Epoch [61/300], Train Loss: 0.001883
Validation Loss: 0.00125278
Early stopping triggered

Evaluating model for: Dryer
Run 41/72 completed in 159.84 seconds with: {'MAE': np.float32(7.9964256), 'MSE': np.float32(2772.4658), 'RMSE': np.float32(52.65421), 'SAE': np.float32(0.0023767094), 'NDE': np.float32(0.44885004)}

Run 42/72: hidden=256, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Dryer
Dataset length: 1470 windows

Epoch [1/300], Train Loss: 0.012153
Validation Loss: 0.00828459
Epoch [2/300], Train Loss: 0.009889
Validation Loss: 0.00832379
Epoch [3/300], Train Loss: 0.009831
Validation Loss: 0.00814808
Epoch [4/300], Train Loss: 0.009932
Validation Loss: 0.00811167
Epoch [5/300], Train Loss: 0.010112
Validation Loss: 0.00809823
Epoch [6/300], Train Loss: 0.010374
Validation Loss: 0.00810592
Epoch [7/300], Train Loss: 0.010621
Validation Loss: 0.00805552
Epoch [8/300], Train Loss: 0.010532
Validation Loss: 0.00802157
Epoch [9/300], Train Loss: 0.009672
Validation Loss: 0.00794313
Epoch [10/300], Train Loss: 0.010773
Validation Loss: 0.00780760
Epoch [11/300], Train Loss: 0.012979
Validation Loss: 0.00747892
Epoch [12/300], Train Loss: 0.009972
Validation Loss: 0.00634734
Epoch [13/300], Train Loss: 0.007869
Validation Loss: 0.00480252
Epoch [14/300], Train Loss: 0.005940
Validation Loss: 0.00464825
Epoch [15/300], Train Loss: 0.004687
Validation Loss: 0.00289589
Epoch [16/300], Train Loss: 0.003403
Validation Loss: 0.00312514
Epoch [17/300], Train Loss: 0.003248
Validation Loss: 0.00209246
Epoch [18/300], Train Loss: 0.002807
Validation Loss: 0.00211684
Epoch [19/300], Train Loss: 0.002700
Validation Loss: 0.00178079
Epoch [20/300], Train Loss: 0.002978
Validation Loss: 0.00173075
Epoch [21/300], Train Loss: 0.002637
Validation Loss: 0.00185400
Epoch [22/300], Train Loss: 0.002653
Validation Loss: 0.00166296
Epoch [23/300], Train Loss: 0.002615
Validation Loss: 0.00178237
Epoch [24/300], Train Loss: 0.002205
Validation Loss: 0.00157089
Epoch [25/300], Train Loss: 0.002205
Validation Loss: 0.00162551
Epoch [26/300], Train Loss: 0.002050
Validation Loss: 0.00146662
Epoch [27/300], Train Loss: 0.001803
Validation Loss: 0.00148756
Epoch [28/300], Train Loss: 0.001760
Validation Loss: 0.00139995
Epoch [29/300], Train Loss: 0.001813
Validation Loss: 0.00134124
Epoch [30/300], Train Loss: 0.001666
Validation Loss: 0.00141528
Epoch [31/300], Train Loss: 0.001834
Validation Loss: 0.00114078
Epoch [32/300], Train Loss: 0.001470
Validation Loss: 0.00110836
Epoch [33/300], Train Loss: 0.001535
Validation Loss: 0.00091964
Epoch [34/300], Train Loss: 0.001915
Validation Loss: 0.00137083
Epoch [35/300], Train Loss: 0.002056
Validation Loss: 0.00115147
Epoch [36/300], Train Loss: 0.001931
Validation Loss: 0.00119372
Epoch [37/300], Train Loss: 0.001645
Validation Loss: 0.00108851
Epoch [38/300], Train Loss: 0.001314
Validation Loss: 0.00100463
Epoch [39/300], Train Loss: 0.001247
Validation Loss: 0.00098165
Epoch [40/300], Train Loss: 0.001150
Validation Loss: 0.00083820
Epoch [41/300], Train Loss: 0.001291
Validation Loss: 0.00083086
Epoch [42/300], Train Loss: 0.001087
Validation Loss: 0.00089553
Epoch [43/300], Train Loss: 0.001095
Validation Loss: 0.00078842
Epoch [44/300], Train Loss: 0.001057
Validation Loss: 0.00073418
Epoch [45/300], Train Loss: 0.001013
Validation Loss: 0.00075422
Epoch [46/300], Train Loss: 0.000974
Validation Loss: 0.00074900
Epoch [47/300], Train Loss: 0.001072
Validation Loss: 0.00074776
Epoch [48/300], Train Loss: 0.001000
Validation Loss: 0.00071351
Epoch [49/300], Train Loss: 0.001014
Validation Loss: 0.00071270
Epoch [50/300], Train Loss: 0.000998
Validation Loss: 0.00070389
Epoch [51/300], Train Loss: 0.000903
Validation Loss: 0.00069295
Epoch [52/300], Train Loss: 0.000951
Validation Loss: 0.00071202
Epoch [53/300], Train Loss: 0.000897
Validation Loss: 0.00069623
Epoch [54/300], Train Loss: 0.000895
Validation Loss: 0.00073907
Epoch [55/300], Train Loss: 0.000902
Validation Loss: 0.00070565
Epoch [56/300], Train Loss: 0.001056
Validation Loss: 0.00070595
Epoch [57/300], Train Loss: 0.000909
Validation Loss: 0.00071071
Epoch [58/300], Train Loss: 0.001069
Validation Loss: 0.00066760
Epoch [59/300], Train Loss: 0.001042
Validation Loss: 0.00071083
Epoch [60/300], Train Loss: 0.000931
Validation Loss: 0.00066449
Epoch [61/300], Train Loss: 0.000909
Validation Loss: 0.00071671
Epoch [62/300], Train Loss: 0.000898
Validation Loss: 0.00074810
Epoch [63/300], Train Loss: 0.000854
Validation Loss: 0.00066759
Epoch [64/300], Train Loss: 0.000892
Validation Loss: 0.00068132
Epoch [65/300], Train Loss: 0.000909
Validation Loss: 0.00069297
Epoch [66/300], Train Loss: 0.000844
Validation Loss: 0.00068571
Epoch [67/300], Train Loss: 0.000970
Validation Loss: 0.00067956
Epoch [68/300], Train Loss: 0.000833
Validation Loss: 0.00066631
Epoch [69/300], Train Loss: 0.000784
Validation Loss: 0.00071810
Epoch [70/300], Train Loss: 0.000797
Validation Loss: 0.00066742
Early stopping triggered

Evaluating model for: Dryer
Run 42/72 completed in 238.45 seconds with: {'MAE': np.float32(4.244625), 'MSE': np.float32(1244.661), 'RMSE': np.float32(35.279755), 'SAE': np.float32(0.0075539164), 'NDE': np.float32(0.30074173)}

Run 43/72: hidden=256, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Dryer
Dataset length: 1470 windows

Epoch [1/300], Train Loss: 0.010789
Validation Loss: 0.00826694
Epoch [2/300], Train Loss: 0.009830
Validation Loss: 0.00815587
Epoch [3/300], Train Loss: 0.009790
Validation Loss: 0.00812997
Epoch [4/300], Train Loss: 0.009959
Validation Loss: 0.00812752
Epoch [5/300], Train Loss: 0.010101
Validation Loss: 0.00810276
Epoch [6/300], Train Loss: 0.010332
Validation Loss: 0.00803071
Epoch [7/300], Train Loss: 0.010445
Validation Loss: 0.00774680
Epoch [8/300], Train Loss: 0.009287
Validation Loss: 0.00555155
Epoch [9/300], Train Loss: 0.005004
Validation Loss: 0.00266093
Epoch [10/300], Train Loss: 0.003823
Validation Loss: 0.00263348
Epoch [11/300], Train Loss: 0.003817
Validation Loss: 0.00189976
Epoch [12/300], Train Loss: 0.002835
Validation Loss: 0.00165506
Epoch [13/300], Train Loss: 0.002430
Validation Loss: 0.00163154
Epoch [14/300], Train Loss: 0.002444
Validation Loss: 0.00156034
Epoch [15/300], Train Loss: 0.002461
Validation Loss: 0.00150196
Epoch [16/300], Train Loss: 0.002108
Validation Loss: 0.00147356
Epoch [17/300], Train Loss: 0.001977
Validation Loss: 0.00155510
Epoch [18/300], Train Loss: 0.001955
Validation Loss: 0.00148960
Epoch [19/300], Train Loss: 0.001877
Validation Loss: 0.00160425
Epoch [20/300], Train Loss: 0.002060
Validation Loss: 0.00160431
Epoch [21/300], Train Loss: 0.001828
Validation Loss: 0.00169429
Epoch [22/300], Train Loss: 0.001927
Validation Loss: 0.00157912
Epoch [23/300], Train Loss: 0.001796
Validation Loss: 0.00144032
Epoch [24/300], Train Loss: 0.001816
Validation Loss: 0.00129686
Epoch [25/300], Train Loss: 0.001815
Validation Loss: 0.00136493
Epoch [26/300], Train Loss: 0.001616
Validation Loss: 0.00137200
Epoch [27/300], Train Loss: 0.001502
Validation Loss: 0.00133714
Epoch [28/300], Train Loss: 0.001446
Validation Loss: 0.00121240
Epoch [29/300], Train Loss: 0.001691
Validation Loss: 0.00122399
Epoch [30/300], Train Loss: 0.001687
Validation Loss: 0.00165624
Epoch [31/300], Train Loss: 0.002134
Validation Loss: 0.00121087
Epoch [32/300], Train Loss: 0.001638
Validation Loss: 0.00131988
Epoch [33/300], Train Loss: 0.001574
Validation Loss: 0.00110843
Epoch [34/300], Train Loss: 0.001612
Validation Loss: 0.00115616
Epoch [35/300], Train Loss: 0.001419
Validation Loss: 0.00116822
Epoch [36/300], Train Loss: 0.001318
Validation Loss: 0.00118436
Epoch [37/300], Train Loss: 0.001292
Validation Loss: 0.00121559
Epoch [38/300], Train Loss: 0.001237
Validation Loss: 0.00111100
Epoch [39/300], Train Loss: 0.001198
Validation Loss: 0.00113542
Epoch [40/300], Train Loss: 0.001140
Validation Loss: 0.00111825
Epoch [41/300], Train Loss: 0.001311
Validation Loss: 0.00106795
Epoch [42/300], Train Loss: 0.001101
Validation Loss: 0.00100357
Epoch [43/300], Train Loss: 0.001129
Validation Loss: 0.00102254
Epoch [44/300], Train Loss: 0.001096
Validation Loss: 0.00103649
Epoch [45/300], Train Loss: 0.001066
Validation Loss: 0.00093356
Epoch [46/300], Train Loss: 0.000987
Validation Loss: 0.00100591
Epoch [47/300], Train Loss: 0.001141
Validation Loss: 0.00109293
Epoch [48/300], Train Loss: 0.001042
Validation Loss: 0.00089565
Epoch [49/300], Train Loss: 0.001000
Validation Loss: 0.00074770
Epoch [50/300], Train Loss: 0.000915
Validation Loss: 0.00076040
Epoch [51/300], Train Loss: 0.000820
Validation Loss: 0.00077070
Epoch [52/300], Train Loss: 0.000862
Validation Loss: 0.00074686
Epoch [53/300], Train Loss: 0.000783
Validation Loss: 0.00076400
Epoch [54/300], Train Loss: 0.000779
Validation Loss: 0.00074970
Epoch [55/300], Train Loss: 0.000758
Validation Loss: 0.00074002
Epoch [56/300], Train Loss: 0.000897
Validation Loss: 0.00074614
Epoch [57/300], Train Loss: 0.000815
Validation Loss: 0.00074459
Epoch [58/300], Train Loss: 0.000925
Validation Loss: 0.00069107
Epoch [59/300], Train Loss: 0.000888
Validation Loss: 0.00072895
Epoch [60/300], Train Loss: 0.000957
Validation Loss: 0.00081958
Epoch [61/300], Train Loss: 0.001072
Validation Loss: 0.00074784
Epoch [62/300], Train Loss: 0.000893
Validation Loss: 0.00073708
Epoch [63/300], Train Loss: 0.000728
Validation Loss: 0.00071362
Epoch [64/300], Train Loss: 0.000795
Validation Loss: 0.00068203
Epoch [65/300], Train Loss: 0.000761
Validation Loss: 0.00067975
Epoch [66/300], Train Loss: 0.000703
Validation Loss: 0.00066350
Epoch [67/300], Train Loss: 0.000790
Validation Loss: 0.00065678
Epoch [68/300], Train Loss: 0.000707
Validation Loss: 0.00065619
Epoch [69/300], Train Loss: 0.000668
Validation Loss: 0.00065382
Epoch [70/300], Train Loss: 0.000676
Validation Loss: 0.00064257
Epoch [71/300], Train Loss: 0.000664
Validation Loss: 0.00064125
Epoch [72/300], Train Loss: 0.000735
Validation Loss: 0.00063891
Epoch [73/300], Train Loss: 0.000702
Validation Loss: 0.00062157
Epoch [74/300], Train Loss: 0.000706
Validation Loss: 0.00064042
Epoch [75/300], Train Loss: 0.000712
Validation Loss: 0.00062522
Epoch [76/300], Train Loss: 0.000688
Validation Loss: 0.00062010
Epoch [77/300], Train Loss: 0.000650
Validation Loss: 0.00062833
Epoch [78/300], Train Loss: 0.000701
Validation Loss: 0.00061670
Epoch [79/300], Train Loss: 0.000661
Validation Loss: 0.00062308
Epoch [80/300], Train Loss: 0.000668
Validation Loss: 0.00061290
Epoch [81/300], Train Loss: 0.000784
Validation Loss: 0.00061286
Epoch [82/300], Train Loss: 0.000758
Validation Loss: 0.00060505
Epoch [83/300], Train Loss: 0.000651
Validation Loss: 0.00059369
Epoch [84/300], Train Loss: 0.000610
Validation Loss: 0.00059524
Epoch [85/300], Train Loss: 0.000742
Validation Loss: 0.00059788
Epoch [86/300], Train Loss: 0.000768
Validation Loss: 0.00061720
Epoch [87/300], Train Loss: 0.000638
Validation Loss: 0.00058167
Epoch [88/300], Train Loss: 0.000703
Validation Loss: 0.00059121
Epoch [89/300], Train Loss: 0.000671
Validation Loss: 0.00058880
Epoch [90/300], Train Loss: 0.000627
Validation Loss: 0.00061057
Epoch [91/300], Train Loss: 0.000638
Validation Loss: 0.00059138
Epoch [92/300], Train Loss: 0.000599
Validation Loss: 0.00058132
Epoch [93/300], Train Loss: 0.000587
Validation Loss: 0.00059650
Epoch [94/300], Train Loss: 0.000616
Validation Loss: 0.00058997
Epoch [95/300], Train Loss: 0.000643
Validation Loss: 0.00057778
Epoch [96/300], Train Loss: 0.000719
Validation Loss: 0.00057602
Epoch [97/300], Train Loss: 0.000598
Validation Loss: 0.00059206
Epoch [98/300], Train Loss: 0.000644
Validation Loss: 0.00059152
Epoch [99/300], Train Loss: 0.000572
Validation Loss: 0.00058981
Epoch [100/300], Train Loss: 0.000609
Validation Loss: 0.00058986
Epoch [101/300], Train Loss: 0.000629
Validation Loss: 0.00057575
Epoch [102/300], Train Loss: 0.000572
Validation Loss: 0.00059332
Epoch [103/300], Train Loss: 0.000597
Validation Loss: 0.00057082
Epoch [104/300], Train Loss: 0.000568
Validation Loss: 0.00056354
Epoch [105/300], Train Loss: 0.000560
Validation Loss: 0.00056586
Epoch [106/300], Train Loss: 0.000586
Validation Loss: 0.00057187
Epoch [107/300], Train Loss: 0.000583
Validation Loss: 0.00056937
Epoch [108/300], Train Loss: 0.000595
Validation Loss: 0.00056682
Epoch [109/300], Train Loss: 0.000551
Validation Loss: 0.00055492
Epoch [110/300], Train Loss: 0.000588
Validation Loss: 0.00056260
Epoch [111/300], Train Loss: 0.000544
Validation Loss: 0.00055771
Epoch [112/300], Train Loss: 0.000572
Validation Loss: 0.00056815
Epoch [113/300], Train Loss: 0.000642
Validation Loss: 0.00056325
Epoch [114/300], Train Loss: 0.000598
Validation Loss: 0.00055599
Epoch [115/300], Train Loss: 0.000554
Validation Loss: 0.00054882
Epoch [116/300], Train Loss: 0.000649
Validation Loss: 0.00054989
Epoch [117/300], Train Loss: 0.000542
Validation Loss: 0.00056050
Epoch [118/300], Train Loss: 0.000568
Validation Loss: 0.00055775
Epoch [119/300], Train Loss: 0.000536
Validation Loss: 0.00054894
Epoch [120/300], Train Loss: 0.000552
Validation Loss: 0.00054983
Epoch [121/300], Train Loss: 0.000549
Validation Loss: 0.00055266
Epoch [122/300], Train Loss: 0.000526
Validation Loss: 0.00055547
Epoch [123/300], Train Loss: 0.000545
Validation Loss: 0.00055157
Epoch [124/300], Train Loss: 0.000528
Validation Loss: 0.00056533
Epoch [125/300], Train Loss: 0.000632
Validation Loss: 0.00055232
Early stopping triggered

Evaluating model for: Dryer
Run 43/72 completed in 513.86 seconds with: {'MAE': np.float32(3.9656847), 'MSE': np.float32(866.9139), 'RMSE': np.float32(29.443401), 'SAE': np.float32(0.0065472135), 'NDE': np.float32(0.25098997)}

Run 44/72: hidden=256, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Dryer
Dataset length: 1470 windows

Epoch [1/300], Train Loss: 0.011229
Validation Loss: 0.00822362
Epoch [2/300], Train Loss: 0.009794
Validation Loss: 0.00816183
Epoch [3/300], Train Loss: 0.009832
Validation Loss: 0.00815789
Epoch [4/300], Train Loss: 0.009978
Validation Loss: 0.00817179
Epoch [5/300], Train Loss: 0.010148
Validation Loss: 0.00814947
Epoch [6/300], Train Loss: 0.010422
Validation Loss: 0.00815528
Epoch [7/300], Train Loss: 0.010718
Validation Loss: 0.00814416
Epoch [8/300], Train Loss: 0.010665
Validation Loss: 0.00813269
Epoch [9/300], Train Loss: 0.009810
Validation Loss: 0.00807556
Epoch [10/300], Train Loss: 0.010931
Validation Loss: 0.00779272
Epoch [11/300], Train Loss: 0.011906
Validation Loss: 0.00646627
Epoch [12/300], Train Loss: 0.006029
Validation Loss: 0.00213507
Epoch [13/300], Train Loss: 0.003095
Validation Loss: 0.00163257
Epoch [14/300], Train Loss: 0.002720
Validation Loss: 0.00168666
Epoch [15/300], Train Loss: 0.002586
Validation Loss: 0.00145788
Epoch [16/300], Train Loss: 0.002214
Validation Loss: 0.00154621
Epoch [17/300], Train Loss: 0.002087
Validation Loss: 0.00150380
Epoch [18/300], Train Loss: 0.002062
Validation Loss: 0.00152992
Epoch [19/300], Train Loss: 0.002103
Validation Loss: 0.00150149
Epoch [20/300], Train Loss: 0.002294
Validation Loss: 0.00160446
Epoch [21/300], Train Loss: 0.002059
Validation Loss: 0.00158570
Epoch [22/300], Train Loss: 0.002128
Validation Loss: 0.00144253
Epoch [23/300], Train Loss: 0.002081
Validation Loss: 0.00144878
Epoch [24/300], Train Loss: 0.002173
Validation Loss: 0.00164200
Epoch [25/300], Train Loss: 0.002156
Validation Loss: 0.00138659
Epoch [26/300], Train Loss: 0.001951
Validation Loss: 0.00142389
Epoch [27/300], Train Loss: 0.001765
Validation Loss: 0.00141117
Epoch [28/300], Train Loss: 0.001844
Validation Loss: 0.00152118
Epoch [29/300], Train Loss: 0.001998
Validation Loss: 0.00138391
Epoch [30/300], Train Loss: 0.001762
Validation Loss: 0.00144429
Epoch [31/300], Train Loss: 0.002018
Validation Loss: 0.00130348
Epoch [32/300], Train Loss: 0.001758
Validation Loss: 0.00137499
Epoch [33/300], Train Loss: 0.001968
Validation Loss: 0.00124858
Epoch [34/300], Train Loss: 0.001713
Validation Loss: 0.00122253
Epoch [35/300], Train Loss: 0.001589
Validation Loss: 0.00124966
Epoch [36/300], Train Loss: 0.001855
Validation Loss: 0.00119425
Epoch [37/300], Train Loss: 0.001542
Validation Loss: 0.00122336
Epoch [38/300], Train Loss: 0.001414
Validation Loss: 0.00116699
Epoch [39/300], Train Loss: 0.001264
Validation Loss: 0.00125499
Epoch [40/300], Train Loss: 0.001150
Validation Loss: 0.00111152
Epoch [41/300], Train Loss: 0.001259
Validation Loss: 0.00097120
Epoch [42/300], Train Loss: 0.000965
Validation Loss: 0.00083326
Epoch [43/300], Train Loss: 0.001098
Validation Loss: 0.00103771
Epoch [44/300], Train Loss: 0.001052
Validation Loss: 0.00079617
Epoch [45/300], Train Loss: 0.000849
Validation Loss: 0.00075783
Epoch [46/300], Train Loss: 0.000758
Validation Loss: 0.00068209
Epoch [47/300], Train Loss: 0.000793
Validation Loss: 0.00068308
Epoch [48/300], Train Loss: 0.000800
Validation Loss: 0.00067174
Epoch [49/300], Train Loss: 0.000765
Validation Loss: 0.00061685
Epoch [50/300], Train Loss: 0.000723
Validation Loss: 0.00060667
Epoch [51/300], Train Loss: 0.000658
Validation Loss: 0.00062385
Epoch [52/300], Train Loss: 0.000687
Validation Loss: 0.00061912
Epoch [53/300], Train Loss: 0.000662
Validation Loss: 0.00061066
Epoch [54/300], Train Loss: 0.000636
Validation Loss: 0.00061387
Epoch [55/300], Train Loss: 0.000640
Validation Loss: 0.00061066
Epoch [56/300], Train Loss: 0.000743
Validation Loss: 0.00060928
Epoch [57/300], Train Loss: 0.000677
Validation Loss: 0.00059798
Epoch [58/300], Train Loss: 0.000822
Validation Loss: 0.00060274
Epoch [59/300], Train Loss: 0.000804
Validation Loss: 0.00064767
Epoch [60/300], Train Loss: 0.000772
Validation Loss: 0.00069711
Epoch [61/300], Train Loss: 0.000781
Validation Loss: 0.00061233
Epoch [62/300], Train Loss: 0.000708
Validation Loss: 0.00068823
Epoch [63/300], Train Loss: 0.000689
Validation Loss: 0.00062278
Epoch [64/300], Train Loss: 0.000717
Validation Loss: 0.00058051
Epoch [65/300], Train Loss: 0.000654
Validation Loss: 0.00058877
Epoch [66/300], Train Loss: 0.000615
Validation Loss: 0.00059606
Epoch [67/300], Train Loss: 0.000699
Validation Loss: 0.00056948
Epoch [68/300], Train Loss: 0.000626
Validation Loss: 0.00058041
Epoch [69/300], Train Loss: 0.000593
Validation Loss: 0.00058009
Epoch [70/300], Train Loss: 0.000586
Validation Loss: 0.00057124
Epoch [71/300], Train Loss: 0.000580
Validation Loss: 0.00057982
Epoch [72/300], Train Loss: 0.000669
Validation Loss: 0.00057046
Epoch [73/300], Train Loss: 0.000648
Validation Loss: 0.00058173
Epoch [74/300], Train Loss: 0.000653
Validation Loss: 0.00059810
Epoch [75/300], Train Loss: 0.000648
Validation Loss: 0.00056775
Epoch [76/300], Train Loss: 0.000627
Validation Loss: 0.00057925
Epoch [77/300], Train Loss: 0.000572
Validation Loss: 0.00056606
Epoch [78/300], Train Loss: 0.000625
Validation Loss: 0.00055371
Epoch [79/300], Train Loss: 0.000586
Validation Loss: 0.00056381
Epoch [80/300], Train Loss: 0.000622
Validation Loss: 0.00056311
Epoch [81/300], Train Loss: 0.000706
Validation Loss: 0.00055601
Epoch [82/300], Train Loss: 0.000675
Validation Loss: 0.00054896
Epoch [83/300], Train Loss: 0.000601
Validation Loss: 0.00054354
Epoch [84/300], Train Loss: 0.000553
Validation Loss: 0.00055676
Epoch [85/300], Train Loss: 0.000655
Validation Loss: 0.00054843
Epoch [86/300], Train Loss: 0.000718
Validation Loss: 0.00063169
Epoch [87/300], Train Loss: 0.000675
Validation Loss: 0.00062909
Epoch [88/300], Train Loss: 0.000776
Validation Loss: 0.00063528
Epoch [89/300], Train Loss: 0.000782
Validation Loss: 0.00061293
Epoch [90/300], Train Loss: 0.000595
Validation Loss: 0.00059171
Epoch [91/300], Train Loss: 0.000613
Validation Loss: 0.00057770
Epoch [92/300], Train Loss: 0.000587
Validation Loss: 0.00054909
Epoch [93/300], Train Loss: 0.000554
Validation Loss: 0.00055170
Early stopping triggered

Evaluating model for: Dryer
Run 44/72 completed in 532.77 seconds with: {'MAE': np.float32(3.7119448), 'MSE': np.float32(895.64874), 'RMSE': np.float32(29.927391), 'SAE': np.float32(0.042754102), 'NDE': np.float32(0.2551157)}

Run 45/72: hidden=256, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Dryer
Dataset length: 746 windows

Epoch [1/300], Train Loss: 0.013762
Validation Loss: 0.00945825
Epoch [2/300], Train Loss: 0.011915
Validation Loss: 0.00898512
Epoch [3/300], Train Loss: 0.012398
Validation Loss: 0.00894845
Epoch [4/300], Train Loss: 0.011716
Validation Loss: 0.00908770
Epoch [5/300], Train Loss: 0.011987
Validation Loss: 0.00906521
Epoch [6/300], Train Loss: 0.012042
Validation Loss: 0.00895072
Epoch [7/300], Train Loss: 0.011283
Validation Loss: 0.00889570
Epoch [8/300], Train Loss: 0.012546
Validation Loss: 0.00886855
Epoch [9/300], Train Loss: 0.011776
Validation Loss: 0.00886263
Epoch [10/300], Train Loss: 0.011823
Validation Loss: 0.00886649
Epoch [11/300], Train Loss: 0.011940
Validation Loss: 0.00886471
Epoch [12/300], Train Loss: 0.011842
Validation Loss: 0.00885045
Epoch [13/300], Train Loss: 0.011734
Validation Loss: 0.00881299
Epoch [14/300], Train Loss: 0.011854
Validation Loss: 0.00878471
Epoch [15/300], Train Loss: 0.011314
Validation Loss: 0.00875666
Epoch [16/300], Train Loss: 0.011284
Validation Loss: 0.00871207
Epoch [17/300], Train Loss: 0.012000
Validation Loss: 0.00865884
Epoch [18/300], Train Loss: 0.011638
Validation Loss: 0.00860495
Epoch [19/300], Train Loss: 0.010966
Validation Loss: 0.00852424
Epoch [20/300], Train Loss: 0.011415
Validation Loss: 0.00834857
Epoch [21/300], Train Loss: 0.010669
Validation Loss: 0.00812046
Epoch [22/300], Train Loss: 0.010554
Validation Loss: 0.00774191
Epoch [23/300], Train Loss: 0.009863
Validation Loss: 0.00698026
Epoch [24/300], Train Loss: 0.007616
Validation Loss: 0.00531840
Epoch [25/300], Train Loss: 0.006685
Validation Loss: 0.00453527
Epoch [26/300], Train Loss: 0.004188
Validation Loss: 0.00363981
Epoch [27/300], Train Loss: 0.003877
Validation Loss: 0.00347962
Epoch [28/300], Train Loss: 0.003501
Validation Loss: 0.00318090
Epoch [29/300], Train Loss: 0.003236
Validation Loss: 0.00316127
Epoch [30/300], Train Loss: 0.003097
Validation Loss: 0.00294559
Epoch [31/300], Train Loss: 0.002964
Validation Loss: 0.00281434
Epoch [32/300], Train Loss: 0.002926
Validation Loss: 0.00271411
Epoch [33/300], Train Loss: 0.002846
Validation Loss: 0.00264354
Epoch [34/300], Train Loss: 0.002862
Validation Loss: 0.00255331
Epoch [35/300], Train Loss: 0.002794
Validation Loss: 0.00250134
Epoch [36/300], Train Loss: 0.002838
Validation Loss: 0.00242923
Epoch [37/300], Train Loss: 0.002694
Validation Loss: 0.00238819
Epoch [38/300], Train Loss: 0.002601
Validation Loss: 0.00234090
Epoch [39/300], Train Loss: 0.002728
Validation Loss: 0.00230745
Epoch [40/300], Train Loss: 0.002598
Validation Loss: 0.00233322
Epoch [41/300], Train Loss: 0.002791
Validation Loss: 0.00228880
Epoch [42/300], Train Loss: 0.002702
Validation Loss: 0.00226671
Epoch [43/300], Train Loss: 0.002547
Validation Loss: 0.00220852
Epoch [44/300], Train Loss: 0.002480
Validation Loss: 0.00218866
Epoch [45/300], Train Loss: 0.002513
Validation Loss: 0.00223218
Epoch [46/300], Train Loss: 0.002555
Validation Loss: 0.00218310
Epoch [47/300], Train Loss: 0.002438
Validation Loss: 0.00218965
Epoch [48/300], Train Loss: 0.002425
Validation Loss: 0.00213856
Epoch [49/300], Train Loss: 0.002421
Validation Loss: 0.00212891
Epoch [50/300], Train Loss: 0.002476
Validation Loss: 0.00210026
Epoch [51/300], Train Loss: 0.002541
Validation Loss: 0.00213965
Epoch [52/300], Train Loss: 0.002444
Validation Loss: 0.00208156
Epoch [53/300], Train Loss: 0.002424
Validation Loss: 0.00206514
Epoch [54/300], Train Loss: 0.002288
Validation Loss: 0.00202879
Epoch [55/300], Train Loss: 0.002273
Validation Loss: 0.00198132
Epoch [56/300], Train Loss: 0.002248
Validation Loss: 0.00195288
Epoch [57/300], Train Loss: 0.002217
Validation Loss: 0.00191958
Epoch [58/300], Train Loss: 0.002043
Validation Loss: 0.00186673
Epoch [59/300], Train Loss: 0.001967
Validation Loss: 0.00187548
Epoch [60/300], Train Loss: 0.002021
Validation Loss: 0.00175896
Epoch [61/300], Train Loss: 0.002022
Validation Loss: 0.00179622
Epoch [62/300], Train Loss: 0.001795
Validation Loss: 0.00167576
Epoch [63/300], Train Loss: 0.001747
Validation Loss: 0.00157923
Epoch [64/300], Train Loss: 0.001785
Validation Loss: 0.00158187
Epoch [65/300], Train Loss: 0.001796
Validation Loss: 0.00152245
Epoch [66/300], Train Loss: 0.001578
Validation Loss: 0.00152346
Epoch [67/300], Train Loss: 0.001639
Validation Loss: 0.00146582
Epoch [68/300], Train Loss: 0.001527
Validation Loss: 0.00131215
Epoch [69/300], Train Loss: 0.001562
Validation Loss: 0.00127565
Epoch [70/300], Train Loss: 0.001482
Validation Loss: 0.00122502
Epoch [71/300], Train Loss: 0.001537
Validation Loss: 0.00116546
Epoch [72/300], Train Loss: 0.001426
Validation Loss: 0.00120994
Epoch [73/300], Train Loss: 0.001281
Validation Loss: 0.00113556
Epoch [74/300], Train Loss: 0.001309
Validation Loss: 0.00108980
Epoch [75/300], Train Loss: 0.001220
Validation Loss: 0.00103970
Epoch [76/300], Train Loss: 0.001230
Validation Loss: 0.00106229
Epoch [77/300], Train Loss: 0.001171
Validation Loss: 0.00101218
Epoch [78/300], Train Loss: 0.001150
Validation Loss: 0.00106877
Epoch [79/300], Train Loss: 0.001185
Validation Loss: 0.00098065
Epoch [80/300], Train Loss: 0.001244
Validation Loss: 0.00106324
Epoch [81/300], Train Loss: 0.001164
Validation Loss: 0.00100209
Epoch [82/300], Train Loss: 0.001249
Validation Loss: 0.00098643
Epoch [83/300], Train Loss: 0.001266
Validation Loss: 0.00099408
Epoch [84/300], Train Loss: 0.001220
Validation Loss: 0.00099200
Epoch [85/300], Train Loss: 0.001190
Validation Loss: 0.00101284
Epoch [86/300], Train Loss: 0.001190
Validation Loss: 0.00100069
Epoch [87/300], Train Loss: 0.001164
Validation Loss: 0.00099816
Epoch [88/300], Train Loss: 0.001156
Validation Loss: 0.00102402
Epoch [89/300], Train Loss: 0.001115
Validation Loss: 0.00099139
Early stopping triggered

Evaluating model for: Dryer
Run 45/72 completed in 114.47 seconds with: {'MAE': np.float32(4.534592), 'MSE': np.float32(717.25446), 'RMSE': np.float32(26.781607), 'SAE': np.float32(0.22933023), 'NDE': np.float32(0.41882303)}

Run 46/72: hidden=256, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Dryer
Dataset length: 746 windows

Epoch [1/300], Train Loss: 0.013474
Validation Loss: 0.00922181
Epoch [2/300], Train Loss: 0.011707
Validation Loss: 0.00889580
Epoch [3/300], Train Loss: 0.012333
Validation Loss: 0.00899954
Epoch [4/300], Train Loss: 0.011756
Validation Loss: 0.00907309
Epoch [5/300], Train Loss: 0.011971
Validation Loss: 0.00897864
Epoch [6/300], Train Loss: 0.012022
Validation Loss: 0.00888746
Epoch [7/300], Train Loss: 0.011287
Validation Loss: 0.00885908
Epoch [8/300], Train Loss: 0.012551
Validation Loss: 0.00884177
Epoch [9/300], Train Loss: 0.011774
Validation Loss: 0.00883668
Epoch [10/300], Train Loss: 0.011815
Validation Loss: 0.00883941
Epoch [11/300], Train Loss: 0.011923
Validation Loss: 0.00881477
Epoch [12/300], Train Loss: 0.011798
Validation Loss: 0.00876390
Epoch [13/300], Train Loss: 0.011647
Validation Loss: 0.00868033
Epoch [14/300], Train Loss: 0.011680
Validation Loss: 0.00857592
Epoch [15/300], Train Loss: 0.011011
Validation Loss: 0.00839444
Epoch [16/300], Train Loss: 0.010711
Validation Loss: 0.00803686
Epoch [17/300], Train Loss: 0.010742
Validation Loss: 0.00735385
Epoch [18/300], Train Loss: 0.009031
Validation Loss: 0.00613509
Epoch [19/300], Train Loss: 0.005948
Validation Loss: 0.00718976
Epoch [20/300], Train Loss: 0.005536
Validation Loss: 0.00552260
Epoch [21/300], Train Loss: 0.004703
Validation Loss: 0.00542086
Epoch [22/300], Train Loss: 0.004405
Validation Loss: 0.00415460
Epoch [23/300], Train Loss: 0.004139
Validation Loss: 0.00409119
Epoch [24/300], Train Loss: 0.003735
Validation Loss: 0.00447727
Epoch [25/300], Train Loss: 0.003671
Validation Loss: 0.00391089
Epoch [26/300], Train Loss: 0.003635
Validation Loss: 0.00358703
Epoch [27/300], Train Loss: 0.003446
Validation Loss: 0.00383099
Epoch [28/300], Train Loss: 0.003386
Validation Loss: 0.00350640
Epoch [29/300], Train Loss: 0.003212
Validation Loss: 0.00318720
Epoch [30/300], Train Loss: 0.003076
Validation Loss: 0.00342981
Epoch [31/300], Train Loss: 0.002991
Validation Loss: 0.00299198
Epoch [32/300], Train Loss: 0.003055
Validation Loss: 0.00284186
Epoch [33/300], Train Loss: 0.002835
Validation Loss: 0.00293303
Epoch [34/300], Train Loss: 0.002912
Validation Loss: 0.00279934
Epoch [35/300], Train Loss: 0.002852
Validation Loss: 0.00258800
Epoch [36/300], Train Loss: 0.002850
Validation Loss: 0.00264422
Epoch [37/300], Train Loss: 0.002826
Validation Loss: 0.00266107
Epoch [38/300], Train Loss: 0.002619
Validation Loss: 0.00249980
Epoch [39/300], Train Loss: 0.002707
Validation Loss: 0.00258894
Epoch [40/300], Train Loss: 0.002464
Validation Loss: 0.00246967
Epoch [41/300], Train Loss: 0.002862
Validation Loss: 0.00256215
Epoch [42/300], Train Loss: 0.002445
Validation Loss: 0.00218529
Epoch [43/300], Train Loss: 0.002373
Validation Loss: 0.00235853
Epoch [44/300], Train Loss: 0.002514
Validation Loss: 0.00230440
Epoch [45/300], Train Loss: 0.002390
Validation Loss: 0.00236625
Epoch [46/300], Train Loss: 0.002537
Validation Loss: 0.00240424
Epoch [47/300], Train Loss: 0.002308
Validation Loss: 0.00220423
Epoch [48/300], Train Loss: 0.002312
Validation Loss: 0.00245697
Epoch [49/300], Train Loss: 0.002331
Validation Loss: 0.00230515
Epoch [50/300], Train Loss: 0.002345
Validation Loss: 0.00200564
Epoch [51/300], Train Loss: 0.002185
Validation Loss: 0.00214859
Epoch [52/300], Train Loss: 0.002094
Validation Loss: 0.00195574
Epoch [53/300], Train Loss: 0.001988
Validation Loss: 0.00192173
Epoch [54/300], Train Loss: 0.002010
Validation Loss: 0.00172695
Epoch [55/300], Train Loss: 0.002056
Validation Loss: 0.00199219
Epoch [56/300], Train Loss: 0.002739
Validation Loss: 0.00235606
Epoch [57/300], Train Loss: 0.002429
Validation Loss: 0.00232397
Epoch [58/300], Train Loss: 0.002135
Validation Loss: 0.00212183
Epoch [59/300], Train Loss: 0.002063
Validation Loss: 0.00186740
Epoch [60/300], Train Loss: 0.001873
Validation Loss: 0.00177083
Epoch [61/300], Train Loss: 0.001934
Validation Loss: 0.00148498
Epoch [62/300], Train Loss: 0.001632
Validation Loss: 0.00123455
Epoch [63/300], Train Loss: 0.001953
Validation Loss: 0.00107680
Epoch [64/300], Train Loss: 0.001988
Validation Loss: 0.00125412
Epoch [65/300], Train Loss: 0.001731
Validation Loss: 0.00131164
Epoch [66/300], Train Loss: 0.001565
Validation Loss: 0.00125446
Epoch [67/300], Train Loss: 0.001558
Validation Loss: 0.00125906
Epoch [68/300], Train Loss: 0.001535
Validation Loss: 0.00119916
Epoch [69/300], Train Loss: 0.001651
Validation Loss: 0.00153848
Epoch [70/300], Train Loss: 0.001801
Validation Loss: 0.00170220
Epoch [71/300], Train Loss: 0.001749
Validation Loss: 0.00157281
Epoch [72/300], Train Loss: 0.001545
Validation Loss: 0.00123030
Epoch [73/300], Train Loss: 0.001519
Validation Loss: 0.00104327
Epoch [74/300], Train Loss: 0.001542
Validation Loss: 0.00114933
Epoch [75/300], Train Loss: 0.001476
Validation Loss: 0.00107051
Epoch [76/300], Train Loss: 0.001484
Validation Loss: 0.00100808
Epoch [77/300], Train Loss: 0.001427
Validation Loss: 0.00094956
Epoch [78/300], Train Loss: 0.001413
Validation Loss: 0.00102851
Epoch [79/300], Train Loss: 0.001432
Validation Loss: 0.00100670
Epoch [80/300], Train Loss: 0.001432
Validation Loss: 0.00092639
Epoch [81/300], Train Loss: 0.001387
Validation Loss: 0.00101089
Epoch [82/300], Train Loss: 0.001376
Validation Loss: 0.00095414
Epoch [83/300], Train Loss: 0.001394
Validation Loss: 0.00090426
Epoch [84/300], Train Loss: 0.001353
Validation Loss: 0.00087453
Epoch [85/300], Train Loss: 0.001358
Validation Loss: 0.00088562
Epoch [86/300], Train Loss: 0.001359
Validation Loss: 0.00105887
Epoch [87/300], Train Loss: 0.001328
Validation Loss: 0.00089271
Epoch [88/300], Train Loss: 0.001278
Validation Loss: 0.00088222
Epoch [89/300], Train Loss: 0.001236
Validation Loss: 0.00088764
Epoch [90/300], Train Loss: 0.001313
Validation Loss: 0.00100252
Epoch [91/300], Train Loss: 0.001203
Validation Loss: 0.00086106
Epoch [92/300], Train Loss: 0.001182
Validation Loss: 0.00084118
Epoch [93/300], Train Loss: 0.001268
Validation Loss: 0.00085370
Epoch [94/300], Train Loss: 0.001196
Validation Loss: 0.00098150
Epoch [95/300], Train Loss: 0.001170
Validation Loss: 0.00095169
Epoch [96/300], Train Loss: 0.001071
Validation Loss: 0.00096675
Epoch [97/300], Train Loss: 0.001049
Validation Loss: 0.00084413
Epoch [98/300], Train Loss: 0.001052
Validation Loss: 0.00081032
Epoch [99/300], Train Loss: 0.001158
Validation Loss: 0.00094618
Epoch [100/300], Train Loss: 0.001039
Validation Loss: 0.00052077
Epoch [101/300], Train Loss: 0.001207
Validation Loss: 0.00061919
Epoch [102/300], Train Loss: 0.000957
Validation Loss: 0.00074946
Epoch [103/300], Train Loss: 0.001053
Validation Loss: 0.00055480
Epoch [104/300], Train Loss: 0.001782
Validation Loss: 0.00410981
Epoch [105/300], Train Loss: 0.007087
Validation Loss: 0.00608986
Epoch [106/300], Train Loss: 0.007367
Validation Loss: 0.00573121
Epoch [107/300], Train Loss: 0.006609
Validation Loss: 0.00431664
Epoch [108/300], Train Loss: 0.004207
Validation Loss: 0.00269071
Epoch [109/300], Train Loss: 0.002904
Validation Loss: 0.00291309
Epoch [110/300], Train Loss: 0.002635
Validation Loss: 0.00319705
Early stopping triggered

Evaluating model for: Dryer
Run 46/72 completed in 182.25 seconds with: {'MAE': np.float32(11.01547), 'MSE': np.float32(2965.2742), 'RMSE': np.float32(54.45433), 'SAE': np.float32(1.6696128), 'NDE': np.float32(0.85158193)}

Run 47/72: hidden=256, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Dryer
Dataset length: 746 windows

Epoch [1/300], Train Loss: 0.014030
Validation Loss: 0.00956754
Epoch [2/300], Train Loss: 0.012007
Validation Loss: 0.00897342
Epoch [3/300], Train Loss: 0.012406
Validation Loss: 0.00893900
Epoch [4/300], Train Loss: 0.011744
Validation Loss: 0.00910610
Epoch [5/300], Train Loss: 0.012019
Validation Loss: 0.00905155
Epoch [6/300], Train Loss: 0.012072
Validation Loss: 0.00893583
Epoch [7/300], Train Loss: 0.011322
Validation Loss: 0.00889945
Epoch [8/300], Train Loss: 0.012611
Validation Loss: 0.00888748
Epoch [9/300], Train Loss: 0.011840
Validation Loss: 0.00888989
Epoch [10/300], Train Loss: 0.011900
Validation Loss: 0.00890385
Epoch [11/300], Train Loss: 0.012032
Validation Loss: 0.00890761
Epoch [12/300], Train Loss: 0.011948
Validation Loss: 0.00889815
Epoch [13/300], Train Loss: 0.011850
Validation Loss: 0.00886808
Epoch [14/300], Train Loss: 0.011976
Validation Loss: 0.00884363
Epoch [15/300], Train Loss: 0.011434
Validation Loss: 0.00881071
Epoch [16/300], Train Loss: 0.011392
Validation Loss: 0.00874250
Epoch [17/300], Train Loss: 0.012036
Validation Loss: 0.00860958
Epoch [18/300], Train Loss: 0.011491
Validation Loss: 0.00835228
Epoch [19/300], Train Loss: 0.010357
Validation Loss: 0.00747043
Epoch [20/300], Train Loss: 0.008457
Validation Loss: 0.00455566
Epoch [21/300], Train Loss: 0.005129
Validation Loss: 0.00387815
Epoch [22/300], Train Loss: 0.004826
Validation Loss: 0.00364620
Epoch [23/300], Train Loss: 0.003899
Validation Loss: 0.00343619
Epoch [24/300], Train Loss: 0.003556
Validation Loss: 0.00322571
Epoch [25/300], Train Loss: 0.003464
Validation Loss: 0.00316417
Epoch [26/300], Train Loss: 0.003289
Validation Loss: 0.00280398
Epoch [27/300], Train Loss: 0.003225
Validation Loss: 0.00277208
Epoch [28/300], Train Loss: 0.003291
Validation Loss: 0.00274652
Epoch [29/300], Train Loss: 0.003080
Validation Loss: 0.00254342
Epoch [30/300], Train Loss: 0.003068
Validation Loss: 0.00281019
Epoch [31/300], Train Loss: 0.002956
Validation Loss: 0.00250595
Epoch [32/300], Train Loss: 0.002970
Validation Loss: 0.00242694
Epoch [33/300], Train Loss: 0.002889
Validation Loss: 0.00247927
Epoch [34/300], Train Loss: 0.002995
Validation Loss: 0.00248107
Epoch [35/300], Train Loss: 0.002895
Validation Loss: 0.00231224
Epoch [36/300], Train Loss: 0.002926
Validation Loss: 0.00240494
Epoch [37/300], Train Loss: 0.002800
Validation Loss: 0.00228216
Epoch [38/300], Train Loss: 0.002628
Validation Loss: 0.00227280
Epoch [39/300], Train Loss: 0.002688
Validation Loss: 0.00220713
Epoch [40/300], Train Loss: 0.002572
Validation Loss: 0.00221231
Epoch [41/300], Train Loss: 0.002589
Validation Loss: 0.00208384
Epoch [42/300], Train Loss: 0.002546
Validation Loss: 0.00200984
Epoch [43/300], Train Loss: 0.002360
Validation Loss: 0.00203725
Epoch [44/300], Train Loss: 0.002193
Validation Loss: 0.00183415
Epoch [45/300], Train Loss: 0.002164
Validation Loss: 0.00194729
Epoch [46/300], Train Loss: 0.002131
Validation Loss: 0.00177764
Epoch [47/300], Train Loss: 0.002154
Validation Loss: 0.00187775
Epoch [48/300], Train Loss: 0.002147
Validation Loss: 0.00187028
Epoch [49/300], Train Loss: 0.001967
Validation Loss: 0.00175706
Epoch [50/300], Train Loss: 0.002019
Validation Loss: 0.00149581
Epoch [51/300], Train Loss: 0.001952
Validation Loss: 0.00185178
Epoch [52/300], Train Loss: 0.001871
Validation Loss: 0.00151661
Epoch [53/300], Train Loss: 0.001854
Validation Loss: 0.00135165
Epoch [54/300], Train Loss: 0.001745
Validation Loss: 0.00172072
Epoch [55/300], Train Loss: 0.001693
Validation Loss: 0.00158467
Epoch [56/300], Train Loss: 0.001702
Validation Loss: 0.00120580
Epoch [57/300], Train Loss: 0.001622
Validation Loss: 0.00113736
Epoch [58/300], Train Loss: 0.001586
Validation Loss: 0.00136584
Epoch [59/300], Train Loss: 0.001542
Validation Loss: 0.00134773
Epoch [60/300], Train Loss: 0.001516
Validation Loss: 0.00130252
Epoch [61/300], Train Loss: 0.001518
Validation Loss: 0.00108145
Epoch [62/300], Train Loss: 0.001325
Validation Loss: 0.00125271
Epoch [63/300], Train Loss: 0.001467
Validation Loss: 0.00084672
Epoch [64/300], Train Loss: 0.001425
Validation Loss: 0.00110158
Epoch [65/300], Train Loss: 0.001312
Validation Loss: 0.00111646
Epoch [66/300], Train Loss: 0.001137
Validation Loss: 0.00073842
Epoch [67/300], Train Loss: 0.001225
Validation Loss: 0.00099878
Epoch [68/300], Train Loss: 0.001541
Validation Loss: 0.00154085
Epoch [69/300], Train Loss: 0.001458
Validation Loss: 0.00074982
Epoch [70/300], Train Loss: 0.001418
Validation Loss: 0.00111717
Epoch [71/300], Train Loss: 0.001275
Validation Loss: 0.00145909
Epoch [72/300], Train Loss: 0.001375
Validation Loss: 0.00115209
Epoch [73/300], Train Loss: 0.001573
Validation Loss: 0.00224801
Epoch [74/300], Train Loss: 0.004966
Validation Loss: 0.00513443
Epoch [75/300], Train Loss: 0.006470
Validation Loss: 0.00432689
Epoch [76/300], Train Loss: 0.004464
Validation Loss: 0.00271230
Early stopping triggered

Evaluating model for: Dryer
Run 47/72 completed in 152.16 seconds with: {'MAE': np.float32(13.112146), 'MSE': np.float32(2860.396), 'RMSE': np.float32(53.48267), 'SAE': np.float32(1.8026216), 'NDE': np.float32(0.8363867)}

Run 48/72: hidden=256, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Dryer
Dataset length: 746 windows

Epoch [1/300], Train Loss: 0.012371
Validation Loss: 0.00893248
Epoch [2/300], Train Loss: 0.011485
Validation Loss: 0.00905805
Epoch [3/300], Train Loss: 0.012380
Validation Loss: 0.00894586
Epoch [4/300], Train Loss: 0.011706
Validation Loss: 0.00890454
Epoch [5/300], Train Loss: 0.011930
Validation Loss: 0.00889814
Epoch [6/300], Train Loss: 0.012036
Validation Loss: 0.00890223
Epoch [7/300], Train Loss: 0.011335
Validation Loss: 0.00892644
Epoch [8/300], Train Loss: 0.012584
Validation Loss: 0.00890555
Epoch [9/300], Train Loss: 0.011820
Validation Loss: 0.00890708
Epoch [10/300], Train Loss: 0.011881
Validation Loss: 0.00889054
Epoch [11/300], Train Loss: 0.011998
Validation Loss: 0.00884901
Epoch [12/300], Train Loss: 0.011864
Validation Loss: 0.00877977
Epoch [13/300], Train Loss: 0.011612
Validation Loss: 0.00856753
Epoch [14/300], Train Loss: 0.011259
Validation Loss: 0.00785846
Epoch [15/300], Train Loss: 0.009209
Validation Loss: 0.00530912
Epoch [16/300], Train Loss: 0.004570
Validation Loss: 0.00773271
Epoch [17/300], Train Loss: 0.005475
Validation Loss: 0.00348381
Epoch [18/300], Train Loss: 0.004325
Validation Loss: 0.00308563
Epoch [19/300], Train Loss: 0.003517
Validation Loss: 0.00292494
Epoch [20/300], Train Loss: 0.002902
Validation Loss: 0.00228025
Epoch [21/300], Train Loss: 0.002860
Validation Loss: 0.00238717
Epoch [22/300], Train Loss: 0.003022
Validation Loss: 0.00214874
Epoch [23/300], Train Loss: 0.002759
Validation Loss: 0.00200245
Epoch [24/300], Train Loss: 0.002667
Validation Loss: 0.00211943
Epoch [25/300], Train Loss: 0.002731
Validation Loss: 0.00221721
Epoch [26/300], Train Loss: 0.002626
Validation Loss: 0.00187718
Epoch [27/300], Train Loss: 0.002619
Validation Loss: 0.00186045
Epoch [28/300], Train Loss: 0.002640
Validation Loss: 0.00209036
Epoch [29/300], Train Loss: 0.002511
Validation Loss: 0.00183407
Epoch [30/300], Train Loss: 0.002418
Validation Loss: 0.00176482
Epoch [31/300], Train Loss: 0.002323
Validation Loss: 0.00174970
Epoch [32/300], Train Loss: 0.002452
Validation Loss: 0.00175825
Epoch [33/300], Train Loss: 0.002308
Validation Loss: 0.00167128
Epoch [34/300], Train Loss: 0.002315
Validation Loss: 0.00164242
Epoch [35/300], Train Loss: 0.002223
Validation Loss: 0.00158628
Epoch [36/300], Train Loss: 0.002172
Validation Loss: 0.00151743
Epoch [37/300], Train Loss: 0.002082
Validation Loss: 0.00144890
Epoch [38/300], Train Loss: 0.001887
Validation Loss: 0.00138514
Epoch [39/300], Train Loss: 0.001858
Validation Loss: 0.00138694
Epoch [40/300], Train Loss: 0.001842
Validation Loss: 0.00129982
Epoch [41/300], Train Loss: 0.001882
Validation Loss: 0.00122314
Epoch [42/300], Train Loss: 0.001718
Validation Loss: 0.00141483
Epoch [43/300], Train Loss: 0.001761
Validation Loss: 0.00118391
Epoch [44/300], Train Loss: 0.001630
Validation Loss: 0.00111637
Epoch [45/300], Train Loss: 0.001594
Validation Loss: 0.00114004
Epoch [46/300], Train Loss: 0.001504
Validation Loss: 0.00120116
Epoch [47/300], Train Loss: 0.001508
Validation Loss: 0.00094930
Epoch [48/300], Train Loss: 0.001449
Validation Loss: 0.00095909
Epoch [49/300], Train Loss: 0.001314
Validation Loss: 0.00100965
Epoch [50/300], Train Loss: 0.001269
Validation Loss: 0.00082584
Epoch [51/300], Train Loss: 0.001216
Validation Loss: 0.00085266
Epoch [52/300], Train Loss: 0.001175
Validation Loss: 0.00083761
Epoch [53/300], Train Loss: 0.001107
Validation Loss: 0.00076525
Epoch [54/300], Train Loss: 0.001051
Validation Loss: 0.00077712
Epoch [55/300], Train Loss: 0.001036
Validation Loss: 0.00077612
Epoch [56/300], Train Loss: 0.001053
Validation Loss: 0.00081457
Epoch [57/300], Train Loss: 0.001267
Validation Loss: 0.00080679
Epoch [58/300], Train Loss: 0.001181
Validation Loss: 0.00096825
Epoch [59/300], Train Loss: 0.001150
Validation Loss: 0.00078691
Epoch [60/300], Train Loss: 0.001237
Validation Loss: 0.00079595
Epoch [61/300], Train Loss: 0.001187
Validation Loss: 0.00085432
Epoch [62/300], Train Loss: 0.001054
Validation Loss: 0.00098049
Epoch [63/300], Train Loss: 0.001100
Validation Loss: 0.00086082
Early stopping triggered

Evaluating model for: Dryer
Run 48/72 completed in 173.82 seconds with: {'MAE': np.float32(3.3651161), 'MSE': np.float32(659.615), 'RMSE': np.float32(25.68297), 'SAE': np.float32(0.35141242), 'NDE': np.float32(0.40164208)}

Run 49/72: hidden=512, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Dryer
Dataset length: 9150 windows

Epoch [1/300], Train Loss: 0.009822
Validation Loss: 0.00584362
Epoch [2/300], Train Loss: 0.005339
Validation Loss: 0.00346439
Epoch [3/300], Train Loss: 0.003561
Validation Loss: 0.00276402
Epoch [4/300], Train Loss: 0.003043
Validation Loss: 0.00229966
Epoch [5/300], Train Loss: 0.002605
Validation Loss: 0.00204707
Epoch [6/300], Train Loss: 0.002157
Validation Loss: 0.00268956
Epoch [7/300], Train Loss: 0.001956
Validation Loss: 0.00180941
Epoch [8/300], Train Loss: 0.001732
Validation Loss: 0.00152605
Epoch [9/300], Train Loss: 0.001580
Validation Loss: 0.00154062
Epoch [10/300], Train Loss: 0.001526
Validation Loss: 0.00153967
Epoch [11/300], Train Loss: 0.001383
Validation Loss: 0.00178458
Epoch [12/300], Train Loss: 0.001325
Validation Loss: 0.00152994
Epoch [13/300], Train Loss: 0.001220
Validation Loss: 0.00148492
Epoch [14/300], Train Loss: 0.001746
Validation Loss: 0.00170258
Epoch [15/300], Train Loss: 0.001229
Validation Loss: 0.00143769
Epoch [16/300], Train Loss: 0.001091
Validation Loss: 0.00124136
Epoch [17/300], Train Loss: 0.001097
Validation Loss: 0.00132282
Epoch [18/300], Train Loss: 0.001026
Validation Loss: 0.00138000
Epoch [19/300], Train Loss: 0.000990
Validation Loss: 0.00163542
Epoch [20/300], Train Loss: 0.000997
Validation Loss: 0.00145947
Epoch [21/300], Train Loss: 0.002863
Validation Loss: 0.00207522
Epoch [22/300], Train Loss: 0.002015
Validation Loss: 0.00182218
Epoch [23/300], Train Loss: 0.001709
Validation Loss: 0.00165131
Epoch [24/300], Train Loss: 0.001329
Validation Loss: 0.00132576
Epoch [25/300], Train Loss: 0.001188
Validation Loss: 0.00134200
Epoch [26/300], Train Loss: 0.001135
Validation Loss: 0.00130246
Early stopping triggered

Evaluating model for: Dryer
Run 49/72 completed in 262.39 seconds with: {'MAE': np.float32(5.254199), 'MSE': np.float32(1310.9115), 'RMSE': np.float32(36.206512), 'SAE': np.float32(0.03245271), 'NDE': np.float32(0.35192704)}

Run 50/72: hidden=512, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Dryer
Dataset length: 9150 windows

Epoch [1/300], Train Loss: 0.010199
Validation Loss: 0.00904949
Epoch [2/300], Train Loss: 0.005002
Validation Loss: 0.00344035
Epoch [3/300], Train Loss: 0.003060
Validation Loss: 0.00236647
Epoch [4/300], Train Loss: 0.002735
Validation Loss: 0.00231069
Epoch [5/300], Train Loss: 0.002486
Validation Loss: 0.00203563
Epoch [6/300], Train Loss: 0.002145
Validation Loss: 0.00236889
Epoch [7/300], Train Loss: 0.002401
Validation Loss: 0.00253015
Epoch [8/300], Train Loss: 0.002405
Validation Loss: 0.00241322
Epoch [9/300], Train Loss: 0.001928
Validation Loss: 0.00216370
Epoch [10/300], Train Loss: 0.001767
Validation Loss: 0.00210089
Epoch [11/300], Train Loss: 0.001671
Validation Loss: 0.00187499
Epoch [12/300], Train Loss: 0.001623
Validation Loss: 0.00130256
Epoch [13/300], Train Loss: 0.001472
Validation Loss: 0.00131329
Epoch [14/300], Train Loss: 0.001747
Validation Loss: 0.00115204
Epoch [15/300], Train Loss: 0.001458
Validation Loss: 0.00120834
Epoch [16/300], Train Loss: 0.001367
Validation Loss: 0.00108074
Epoch [17/300], Train Loss: 0.001308
Validation Loss: 0.00108957
Epoch [18/300], Train Loss: 0.001270
Validation Loss: 0.00110923
Epoch [19/300], Train Loss: 0.001191
Validation Loss: 0.00119154
Epoch [20/300], Train Loss: 0.001194
Validation Loss: 0.00125122
Epoch [21/300], Train Loss: 0.001155
Validation Loss: 0.00109308
Epoch [22/300], Train Loss: 0.001100
Validation Loss: 0.00106313
Epoch [23/300], Train Loss: 0.001092
Validation Loss: 0.00115249
Epoch [24/300], Train Loss: 0.000950
Validation Loss: 0.00115621
Epoch [25/300], Train Loss: 0.001001
Validation Loss: 0.00101454
Epoch [26/300], Train Loss: 0.000994
Validation Loss: 0.00105194
Epoch [27/300], Train Loss: 0.000913
Validation Loss: 0.00097727
Epoch [28/300], Train Loss: 0.000850
Validation Loss: 0.00118711
Epoch [29/300], Train Loss: 0.001085
Validation Loss: 0.00098635
Epoch [30/300], Train Loss: 0.001048
Validation Loss: 0.00095518
Epoch [31/300], Train Loss: 0.000868
Validation Loss: 0.00101735
Epoch [32/300], Train Loss: 0.000873
Validation Loss: 0.00108748
Epoch [33/300], Train Loss: 0.000845
Validation Loss: 0.00101005
Epoch [34/300], Train Loss: 0.000792
Validation Loss: 0.00110147
Epoch [35/300], Train Loss: 0.000864
Validation Loss: 0.00093680
Epoch [36/300], Train Loss: 0.000819
Validation Loss: 0.00096171
Epoch [37/300], Train Loss: 0.000791
Validation Loss: 0.00089484
Epoch [38/300], Train Loss: 0.000752
Validation Loss: 0.00087049
Epoch [39/300], Train Loss: 0.000731
Validation Loss: 0.00089102
Epoch [40/300], Train Loss: 0.000729
Validation Loss: 0.00088481
Epoch [41/300], Train Loss: 0.000717
Validation Loss: 0.00085714
Epoch [42/300], Train Loss: 0.000703
Validation Loss: 0.00087004
Epoch [43/300], Train Loss: 0.000688
Validation Loss: 0.00087872
Epoch [44/300], Train Loss: 0.000681
Validation Loss: 0.00085904
Epoch [45/300], Train Loss: 0.000673
Validation Loss: 0.00083717
Epoch [46/300], Train Loss: 0.000776
Validation Loss: 0.00088209
Epoch [47/300], Train Loss: 0.000667
Validation Loss: 0.00089237
Epoch [48/300], Train Loss: 0.000663
Validation Loss: 0.00081439
Epoch [49/300], Train Loss: 0.000653
Validation Loss: 0.00079443
Epoch [50/300], Train Loss: 0.000680
Validation Loss: 0.00082109
Epoch [51/300], Train Loss: 0.000652
Validation Loss: 0.00106936
Epoch [52/300], Train Loss: 0.000656
Validation Loss: 0.00082601
Epoch [53/300], Train Loss: 0.000604
Validation Loss: 0.00106963
Epoch [54/300], Train Loss: 0.000619
Validation Loss: 0.00108104
Epoch [55/300], Train Loss: 0.000608
Validation Loss: 0.00082778
Epoch [56/300], Train Loss: 0.000714
Validation Loss: 0.00079721
Epoch [57/300], Train Loss: 0.000626
Validation Loss: 0.00112690
Epoch [58/300], Train Loss: 0.000616
Validation Loss: 0.00094439
Epoch [59/300], Train Loss: 0.000644
Validation Loss: 0.00077262
Epoch [60/300], Train Loss: 0.000651
Validation Loss: 0.00094945
Epoch [61/300], Train Loss: 0.000621
Validation Loss: 0.00103155
Epoch [62/300], Train Loss: 0.000594
Validation Loss: 0.00078977
Epoch [63/300], Train Loss: 0.000568
Validation Loss: 0.00078182
Epoch [64/300], Train Loss: 0.000595
Validation Loss: 0.00099166
Epoch [65/300], Train Loss: 0.000574
Validation Loss: 0.00074766
Epoch [66/300], Train Loss: 0.000600
Validation Loss: 0.00074355
Epoch [67/300], Train Loss: 0.000549
Validation Loss: 0.00079006
Epoch [68/300], Train Loss: 0.000544
Validation Loss: 0.00075024
Epoch [69/300], Train Loss: 0.000527
Validation Loss: 0.00088124
Epoch [70/300], Train Loss: 0.000530
Validation Loss: 0.00075437
Epoch [71/300], Train Loss: 0.000555
Validation Loss: 0.00102077
Epoch [72/300], Train Loss: 0.000546
Validation Loss: 0.00100334
Epoch [73/300], Train Loss: 0.000543
Validation Loss: 0.00092613
Epoch [74/300], Train Loss: 0.000497
Validation Loss: 0.00087329
Epoch [75/300], Train Loss: 0.000502
Validation Loss: 0.00091922
Epoch [76/300], Train Loss: 0.000506
Validation Loss: 0.00089157
Early stopping triggered

Evaluating model for: Dryer
Run 50/72 completed in 848.90 seconds with: {'MAE': np.float32(3.0721338), 'MSE': np.float32(752.1029), 'RMSE': np.float32(27.424494), 'SAE': np.float32(0.08858649), 'NDE': np.float32(0.26656595)}

Run 51/72: hidden=512, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Dryer
Dataset length: 9150 windows

Epoch [1/300], Train Loss: 0.010386
Validation Loss: 0.01016508
Epoch [2/300], Train Loss: 0.004590
Validation Loss: 0.00324525
Epoch [3/300], Train Loss: 0.003030
Validation Loss: 0.00247202
Epoch [4/300], Train Loss: 0.002726
Validation Loss: 0.00229289
Epoch [5/300], Train Loss: 0.002544
Validation Loss: 0.00237572
Epoch [6/300], Train Loss: 0.002100
Validation Loss: 0.00195647
Epoch [7/300], Train Loss: 0.001891
Validation Loss: 0.00170354
Epoch [8/300], Train Loss: 0.001907
Validation Loss: 0.00150545
Epoch [9/300], Train Loss: 0.001873
Validation Loss: 0.00154875
Epoch [10/300], Train Loss: 0.001628
Validation Loss: 0.00155021
Epoch [11/300], Train Loss: 0.001451
Validation Loss: 0.00135799
Epoch [12/300], Train Loss: 0.001457
Validation Loss: 0.00112476
Epoch [13/300], Train Loss: 0.001394
Validation Loss: 0.00113574
Epoch [14/300], Train Loss: 0.001686
Validation Loss: 0.00115027
Epoch [15/300], Train Loss: 0.001372
Validation Loss: 0.00121383
Epoch [16/300], Train Loss: 0.001332
Validation Loss: 0.00096807
Epoch [17/300], Train Loss: 0.001209
Validation Loss: 0.00103210
Epoch [18/300], Train Loss: 0.001210
Validation Loss: 0.00095204
Epoch [19/300], Train Loss: 0.001208
Validation Loss: 0.00112964
Epoch [20/300], Train Loss: 0.001418
Validation Loss: 0.00089907
Epoch [21/300], Train Loss: 0.001260
Validation Loss: 0.00083867
Epoch [22/300], Train Loss: 0.001141
Validation Loss: 0.00080182
Epoch [23/300], Train Loss: 0.001117
Validation Loss: 0.00081475
Epoch [24/300], Train Loss: 0.001099
Validation Loss: 0.00084440
Epoch [25/300], Train Loss: 0.001078
Validation Loss: 0.00084636
Epoch [26/300], Train Loss: 0.001072
Validation Loss: 0.00082377
Epoch [27/300], Train Loss: 0.001065
Validation Loss: 0.00074303
Epoch [28/300], Train Loss: 0.001065
Validation Loss: 0.00079109
Epoch [29/300], Train Loss: 0.001063
Validation Loss: 0.00088073
Epoch [30/300], Train Loss: 0.001178
Validation Loss: 0.00075574
Epoch [31/300], Train Loss: 0.001017
Validation Loss: 0.00075276
Epoch [32/300], Train Loss: 0.001024
Validation Loss: 0.00079390
Epoch [33/300], Train Loss: 0.001171
Validation Loss: 0.00095651
Epoch [34/300], Train Loss: 0.001056
Validation Loss: 0.00074445
Epoch [35/300], Train Loss: 0.000990
Validation Loss: 0.00066941
Epoch [36/300], Train Loss: 0.000979
Validation Loss: 0.00069652
Epoch [37/300], Train Loss: 0.000995
Validation Loss: 0.00065196
Epoch [38/300], Train Loss: 0.000966
Validation Loss: 0.00060964
Epoch [39/300], Train Loss: 0.000956
Validation Loss: 0.00066093
Epoch [40/300], Train Loss: 0.000973
Validation Loss: 0.00061865
Epoch [41/300], Train Loss: 0.000950
Validation Loss: 0.00061690
Epoch [42/300], Train Loss: 0.000964
Validation Loss: 0.00065534
Epoch [43/300], Train Loss: 0.000941
Validation Loss: 0.00066218
Epoch [44/300], Train Loss: 0.000933
Validation Loss: 0.00064487
Epoch [45/300], Train Loss: 0.000930
Validation Loss: 0.00059140
Epoch [46/300], Train Loss: 0.001002
Validation Loss: 0.00075448
Epoch [47/300], Train Loss: 0.000950
Validation Loss: 0.00061515
Epoch [48/300], Train Loss: 0.001005
Validation Loss: 0.00055374
Epoch [49/300], Train Loss: 0.000893
Validation Loss: 0.00058735
Epoch [50/300], Train Loss: 0.000868
Validation Loss: 0.00057432
Epoch [51/300], Train Loss: 0.000899
Validation Loss: 0.00135568
Epoch [52/300], Train Loss: 0.000948
Validation Loss: 0.00060094
Epoch [53/300], Train Loss: 0.000874
Validation Loss: 0.00051972
Epoch [54/300], Train Loss: 0.000856
Validation Loss: 0.00053638
Epoch [55/300], Train Loss: 0.000832
Validation Loss: 0.00061809
Epoch [56/300], Train Loss: 0.000924
Validation Loss: 0.00064114
Epoch [57/300], Train Loss: 0.000882
Validation Loss: 0.00055776
Epoch [58/300], Train Loss: 0.000807
Validation Loss: 0.00049983
Epoch [59/300], Train Loss: 0.000790
Validation Loss: 0.00047786
Epoch [60/300], Train Loss: 0.000833
Validation Loss: 0.00054775
Epoch [61/300], Train Loss: 0.000843
Validation Loss: 0.00052905
Epoch [62/300], Train Loss: 0.000880
Validation Loss: 0.00052505
Epoch [63/300], Train Loss: 0.000819
Validation Loss: 0.00044348
Epoch [64/300], Train Loss: 0.000802
Validation Loss: 0.00052470
Epoch [65/300], Train Loss: 0.000800
Validation Loss: 0.00047006
Epoch [66/300], Train Loss: 0.000787
Validation Loss: 0.00050234
Epoch [67/300], Train Loss: 0.000787
Validation Loss: 0.00042888
Epoch [68/300], Train Loss: 0.000767
Validation Loss: 0.00044894
Epoch [69/300], Train Loss: 0.000771
Validation Loss: 0.00045486
Epoch [70/300], Train Loss: 0.000775
Validation Loss: 0.00037746
Epoch [71/300], Train Loss: 0.000814
Validation Loss: 0.00054917
Epoch [72/300], Train Loss: 0.000987
Validation Loss: 0.00068558
Epoch [73/300], Train Loss: 0.000820
Validation Loss: 0.00041159
Epoch [74/300], Train Loss: 0.000783
Validation Loss: 0.00040213
Epoch [75/300], Train Loss: 0.000764
Validation Loss: 0.00042249
Epoch [76/300], Train Loss: 0.000741
Validation Loss: 0.00043467
Epoch [77/300], Train Loss: 0.000745
Validation Loss: 0.00048339
Epoch [78/300], Train Loss: 0.000749
Validation Loss: 0.00038697
Epoch [79/300], Train Loss: 0.000771
Validation Loss: 0.00048624
Epoch [80/300], Train Loss: 0.000775
Validation Loss: 0.00034712
Epoch [81/300], Train Loss: 0.000801
Validation Loss: 0.00037870
Epoch [82/300], Train Loss: 0.000717
Validation Loss: 0.00035226
Epoch [83/300], Train Loss: 0.000737
Validation Loss: 0.00048115
Epoch [84/300], Train Loss: 0.000484
Validation Loss: 0.00034486
Epoch [85/300], Train Loss: 0.000437
Validation Loss: 0.00033423
Epoch [86/300], Train Loss: 0.000459
Validation Loss: 0.00042047
Epoch [87/300], Train Loss: 0.000358
Validation Loss: 0.00035584
Epoch [88/300], Train Loss: 0.000350
Validation Loss: 0.00034842
Epoch [89/300], Train Loss: 0.000353
Validation Loss: 0.00034203
Epoch [90/300], Train Loss: 0.000330
Validation Loss: 0.00034528
Epoch [91/300], Train Loss: 0.000339
Validation Loss: 0.00035257
Epoch [92/300], Train Loss: 0.000366
Validation Loss: 0.00033639
Epoch [93/300], Train Loss: 0.000323
Validation Loss: 0.00034147
Epoch [94/300], Train Loss: 0.000314
Validation Loss: 0.00034558
Epoch [95/300], Train Loss: 0.000300
Validation Loss: 0.00046934
Early stopping triggered

Evaluating model for: Dryer
Run 51/72 completed in 1171.77 seconds with: {'MAE': np.float32(2.0615625), 'MSE': np.float32(317.77872), 'RMSE': np.float32(17.82635), 'SAE': np.float32(0.04344798), 'NDE': np.float32(0.17327197)}

Run 52/72: hidden=512, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Dryer
Dataset length: 9150 windows

Epoch [1/300], Train Loss: 0.010125
Validation Loss: 0.00507556
Epoch [2/300], Train Loss: 0.003416
Validation Loss: 0.00302038
Epoch [3/300], Train Loss: 0.002591
Validation Loss: 0.00238637
Epoch [4/300], Train Loss: 0.002266
Validation Loss: 0.00196854
Epoch [5/300], Train Loss: 0.002042
Validation Loss: 0.00159790
Epoch [6/300], Train Loss: 0.001489
Validation Loss: 0.00169675
Epoch [7/300], Train Loss: 0.001392
Validation Loss: 0.00156708
Epoch [8/300], Train Loss: 0.001241
Validation Loss: 0.00149250
Epoch [9/300], Train Loss: 0.001125
Validation Loss: 0.00119128
Epoch [10/300], Train Loss: 0.001040
Validation Loss: 0.00120501
Epoch [11/300], Train Loss: 0.000947
Validation Loss: 0.00118772
Epoch [12/300], Train Loss: 0.001062
Validation Loss: 0.00107840
Epoch [13/300], Train Loss: 0.000897
Validation Loss: 0.00104402
Epoch [14/300], Train Loss: 0.000968
Validation Loss: 0.00102555
Epoch [15/300], Train Loss: 0.000979
Validation Loss: 0.00102917
Epoch [16/300], Train Loss: 0.000824
Validation Loss: 0.00090026
Epoch [17/300], Train Loss: 0.000803
Validation Loss: 0.00103673
Epoch [18/300], Train Loss: 0.001451
Validation Loss: 0.00092608
Epoch [19/300], Train Loss: 0.000857
Validation Loss: 0.00089357
Epoch [20/300], Train Loss: 0.000897
Validation Loss: 0.00087282
Epoch [21/300], Train Loss: 0.000824
Validation Loss: 0.00085970
Epoch [22/300], Train Loss: 0.000770
Validation Loss: 0.00087944
Epoch [23/300], Train Loss: 0.000805
Validation Loss: 0.00083162
Epoch [24/300], Train Loss: 0.000735
Validation Loss: 0.00078467
Epoch [25/300], Train Loss: 0.000680
Validation Loss: 0.00076072
Epoch [26/300], Train Loss: 0.000613
Validation Loss: 0.00079337
Epoch [27/300], Train Loss: 0.000611
Validation Loss: 0.00077337
Epoch [28/300], Train Loss: 0.000584
Validation Loss: 0.00075613
Epoch [29/300], Train Loss: 0.000558
Validation Loss: 0.00073191
Epoch [30/300], Train Loss: 0.000546
Validation Loss: 0.00069027
Epoch [31/300], Train Loss: 0.000522
Validation Loss: 0.00067779
Epoch [32/300], Train Loss: 0.000500
Validation Loss: 0.00066236
Epoch [33/300], Train Loss: 0.000487
Validation Loss: 0.00066535
Epoch [34/300], Train Loss: 0.000476
Validation Loss: 0.00064791
Epoch [35/300], Train Loss: 0.000481
Validation Loss: 0.00066587
Epoch [36/300], Train Loss: 0.000490
Validation Loss: 0.00074290
Epoch [37/300], Train Loss: 0.000494
Validation Loss: 0.00063164
Epoch [38/300], Train Loss: 0.000506
Validation Loss: 0.00060145
Epoch [39/300], Train Loss: 0.000460
Validation Loss: 0.00062089
Epoch [40/300], Train Loss: 0.000431
Validation Loss: 0.00062942
Epoch [41/300], Train Loss: 0.000421
Validation Loss: 0.00061769
Epoch [42/300], Train Loss: 0.000418
Validation Loss: 0.00065924
Epoch [43/300], Train Loss: 0.000415
Validation Loss: 0.00061710
Epoch [44/300], Train Loss: 0.000423
Validation Loss: 0.00063234
Epoch [45/300], Train Loss: 0.000411
Validation Loss: 0.00061768
Epoch [46/300], Train Loss: 0.000469
Validation Loss: 0.00061557
Epoch [47/300], Train Loss: 0.000387
Validation Loss: 0.00062427
Epoch [48/300], Train Loss: 0.000395
Validation Loss: 0.00058569
Epoch [49/300], Train Loss: 0.000378
Validation Loss: 0.00060391
Epoch [50/300], Train Loss: 0.000369
Validation Loss: 0.00058001
Epoch [51/300], Train Loss: 0.000405
Validation Loss: 0.00063746
Epoch [52/300], Train Loss: 0.000423
Validation Loss: 0.00064665
Epoch [53/300], Train Loss: 0.000413
Validation Loss: 0.00054128
Epoch [54/300], Train Loss: 0.000370
Validation Loss: 0.00056973
Epoch [55/300], Train Loss: 0.000373
Validation Loss: 0.00057405
Epoch [56/300], Train Loss: 0.000377
Validation Loss: 0.00057587
Epoch [57/300], Train Loss: 0.000375
Validation Loss: 0.00055997
Epoch [58/300], Train Loss: 0.000344
Validation Loss: 0.00057248
Epoch [59/300], Train Loss: 0.000352
Validation Loss: 0.00056293
Epoch [60/300], Train Loss: 0.000338
Validation Loss: 0.00054961
Epoch [61/300], Train Loss: 0.000338
Validation Loss: 0.00063408
Epoch [62/300], Train Loss: 0.000341
Validation Loss: 0.00060779
Epoch [63/300], Train Loss: 0.000310
Validation Loss: 0.00058884
Early stopping triggered

Evaluating model for: Dryer
Run 52/72 completed in 911.94 seconds with: {'MAE': np.float32(3.788457), 'MSE': np.float32(597.38824), 'RMSE': np.float32(24.441526), 'SAE': np.float32(0.0008951323), 'NDE': np.float32(0.23757188)}

Run 53/72: hidden=512, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Dryer
Dataset length: 4586 windows

Epoch [1/300], Train Loss: 0.010835
Validation Loss: 0.01227027
Epoch [2/300], Train Loss: 0.010044
Validation Loss: 0.01002294
Epoch [3/300], Train Loss: 0.006247
Validation Loss: 0.00504874
Epoch [4/300], Train Loss: 0.004090
Validation Loss: 0.00315201
Epoch [5/300], Train Loss: 0.003639
Validation Loss: 0.00293126
Epoch [6/300], Train Loss: 0.003101
Validation Loss: 0.00227378
Epoch [7/300], Train Loss: 0.003083
Validation Loss: 0.00208477
Epoch [8/300], Train Loss: 0.002599
Validation Loss: 0.00213201
Epoch [9/300], Train Loss: 0.002465
Validation Loss: 0.00236897
Epoch [10/300], Train Loss: 0.002300
Validation Loss: 0.00211248
Epoch [11/300], Train Loss: 0.002069
Validation Loss: 0.00180355
Epoch [12/300], Train Loss: 0.002190
Validation Loss: 0.00191469
Epoch [13/300], Train Loss: 0.002330
Validation Loss: 0.00160480
Epoch [14/300], Train Loss: 0.001882
Validation Loss: 0.00235108
Epoch [15/300], Train Loss: 0.002118
Validation Loss: 0.00214470
Epoch [16/300], Train Loss: 0.001883
Validation Loss: 0.00168580
Epoch [17/300], Train Loss: 0.001720
Validation Loss: 0.00165749
Epoch [18/300], Train Loss: 0.001628
Validation Loss: 0.00142361
Epoch [19/300], Train Loss: 0.001544
Validation Loss: 0.00150193
Epoch [20/300], Train Loss: 0.001478
Validation Loss: 0.00145304
Epoch [21/300], Train Loss: 0.001483
Validation Loss: 0.00133842
Epoch [22/300], Train Loss: 0.001497
Validation Loss: 0.00142742
Epoch [23/300], Train Loss: 0.001410
Validation Loss: 0.00135104
Epoch [24/300], Train Loss: 0.001347
Validation Loss: 0.00141383
Epoch [25/300], Train Loss: 0.001283
Validation Loss: 0.00138378
Epoch [26/300], Train Loss: 0.001304
Validation Loss: 0.00138121
Epoch [27/300], Train Loss: 0.001230
Validation Loss: 0.00141623
Epoch [28/300], Train Loss: 0.001325
Validation Loss: 0.00122484
Epoch [29/300], Train Loss: 0.001145
Validation Loss: 0.00119806
Epoch [30/300], Train Loss: 0.001163
Validation Loss: 0.00110908
Epoch [31/300], Train Loss: 0.001132
Validation Loss: 0.00113276
Epoch [32/300], Train Loss: 0.001089
Validation Loss: 0.00105985
Epoch [33/300], Train Loss: 0.001090
Validation Loss: 0.00101984
Epoch [34/300], Train Loss: 0.001067
Validation Loss: 0.00100391
Epoch [35/300], Train Loss: 0.001039
Validation Loss: 0.00096603
Epoch [36/300], Train Loss: 0.001003
Validation Loss: 0.00096075
Epoch [37/300], Train Loss: 0.000966
Validation Loss: 0.00093231
Epoch [38/300], Train Loss: 0.000992
Validation Loss: 0.00093948
Epoch [39/300], Train Loss: 0.000951
Validation Loss: 0.00092192
Epoch [40/300], Train Loss: 0.000941
Validation Loss: 0.00090392
Epoch [41/300], Train Loss: 0.000962
Validation Loss: 0.00088603
Epoch [42/300], Train Loss: 0.000925
Validation Loss: 0.00089706
Epoch [43/300], Train Loss: 0.000978
Validation Loss: 0.00093661
Epoch [44/300], Train Loss: 0.000983
Validation Loss: 0.00088429
Epoch [45/300], Train Loss: 0.000907
Validation Loss: 0.00082784
Epoch [46/300], Train Loss: 0.000943
Validation Loss: 0.00077913
Epoch [47/300], Train Loss: 0.000979
Validation Loss: 0.00080318
Epoch [48/300], Train Loss: 0.000882
Validation Loss: 0.00080107
Epoch [49/300], Train Loss: 0.000892
Validation Loss: 0.00072432
Epoch [50/300], Train Loss: 0.000893
Validation Loss: 0.00073516
Epoch [51/300], Train Loss: 0.000954
Validation Loss: 0.00080516
Epoch [52/300], Train Loss: 0.001019
Validation Loss: 0.00085117
Epoch [53/300], Train Loss: 0.000997
Validation Loss: 0.00072800
Epoch [54/300], Train Loss: 0.000960
Validation Loss: 0.00077733
Epoch [55/300], Train Loss: 0.000852
Validation Loss: 0.00071198
Epoch [56/300], Train Loss: 0.000857
Validation Loss: 0.00072471
Epoch [57/300], Train Loss: 0.000839
Validation Loss: 0.00074186
Epoch [58/300], Train Loss: 0.000825
Validation Loss: 0.00073390
Epoch [59/300], Train Loss: 0.000836
Validation Loss: 0.00067940
Epoch [60/300], Train Loss: 0.000801
Validation Loss: 0.00069040
Epoch [61/300], Train Loss: 0.000801
Validation Loss: 0.00066550
Epoch [62/300], Train Loss: 0.000800
Validation Loss: 0.00067396
Epoch [63/300], Train Loss: 0.000944
Validation Loss: 0.00068765
Epoch [64/300], Train Loss: 0.000853
Validation Loss: 0.00071562
Epoch [65/300], Train Loss: 0.000814
Validation Loss: 0.00064103
Epoch [66/300], Train Loss: 0.000794
Validation Loss: 0.00064624
Epoch [67/300], Train Loss: 0.000835
Validation Loss: 0.00070012
Epoch [68/300], Train Loss: 0.000747
Validation Loss: 0.00065152
Epoch [69/300], Train Loss: 0.000797
Validation Loss: 0.00063547
Epoch [70/300], Train Loss: 0.000750
Validation Loss: 0.00062125
Epoch [71/300], Train Loss: 0.000742
Validation Loss: 0.00062855
Epoch [72/300], Train Loss: 0.000735
Validation Loss: 0.00063246
Epoch [73/300], Train Loss: 0.000716
Validation Loss: 0.00064192
Epoch [74/300], Train Loss: 0.000704
Validation Loss: 0.00060681
Epoch [75/300], Train Loss: 0.000817
Validation Loss: 0.00063580
Epoch [76/300], Train Loss: 0.000782
Validation Loss: 0.00063828
Epoch [77/300], Train Loss: 0.000724
Validation Loss: 0.00061614
Epoch [78/300], Train Loss: 0.000814
Validation Loss: 0.00102966
Epoch [79/300], Train Loss: 0.000842
Validation Loss: 0.00064538
Epoch [80/300], Train Loss: 0.000751
Validation Loss: 0.00059376
Epoch [81/300], Train Loss: 0.000748
Validation Loss: 0.00058948
Epoch [82/300], Train Loss: 0.000691
Validation Loss: 0.00058305
Epoch [83/300], Train Loss: 0.000690
Validation Loss: 0.00058542
Epoch [84/300], Train Loss: 0.000678
Validation Loss: 0.00058180
Epoch [85/300], Train Loss: 0.000686
Validation Loss: 0.00057951
Epoch [86/300], Train Loss: 0.000673
Validation Loss: 0.00059544
Epoch [87/300], Train Loss: 0.000685
Validation Loss: 0.00058225
Epoch [88/300], Train Loss: 0.000672
Validation Loss: 0.00061402
Epoch [89/300], Train Loss: 0.000676
Validation Loss: 0.00058260
Epoch [90/300], Train Loss: 0.000668
Validation Loss: 0.00057284
Epoch [91/300], Train Loss: 0.000661
Validation Loss: 0.00058527
Epoch [92/300], Train Loss: 0.000646
Validation Loss: 0.00057007
Epoch [93/300], Train Loss: 0.000648
Validation Loss: 0.00062050
Epoch [94/300], Train Loss: 0.000648
Validation Loss: 0.00056111
Epoch [95/300], Train Loss: 0.000804
Validation Loss: 0.00063559
Epoch [96/300], Train Loss: 0.000794
Validation Loss: 0.00057020
Epoch [97/300], Train Loss: 0.000692
Validation Loss: 0.00053723
Epoch [98/300], Train Loss: 0.000635
Validation Loss: 0.00055361
Epoch [99/300], Train Loss: 0.000667
Validation Loss: 0.00054180
Epoch [100/300], Train Loss: 0.000609
Validation Loss: 0.00054385
Epoch [101/300], Train Loss: 0.000617
Validation Loss: 0.00055860
Epoch [102/300], Train Loss: 0.000623
Validation Loss: 0.00053743
Epoch [103/300], Train Loss: 0.000598
Validation Loss: 0.00057101
Epoch [104/300], Train Loss: 0.000631
Validation Loss: 0.00055558
Epoch [105/300], Train Loss: 0.000626
Validation Loss: 0.00053254
Epoch [106/300], Train Loss: 0.001173
Validation Loss: 0.00160322
Epoch [107/300], Train Loss: 0.001389
Validation Loss: 0.00082971
Epoch [108/300], Train Loss: 0.000969
Validation Loss: 0.00078194
Epoch [109/300], Train Loss: 0.000872
Validation Loss: 0.00064539
Epoch [110/300], Train Loss: 0.000823
Validation Loss: 0.00063515
Epoch [111/300], Train Loss: 0.000793
Validation Loss: 0.00061055
Epoch [112/300], Train Loss: 0.000770
Validation Loss: 0.00061759
Epoch [113/300], Train Loss: 0.000764
Validation Loss: 0.00057466
Epoch [114/300], Train Loss: 0.000764
Validation Loss: 0.00055475
Epoch [115/300], Train Loss: 0.000743
Validation Loss: 0.00054362
Early stopping triggered

Evaluating model for: Dryer
Run 53/72 completed in 576.70 seconds with: {'MAE': np.float32(4.2129283), 'MSE': np.float32(1071.5231), 'RMSE': np.float32(32.734127), 'SAE': np.float32(0.00858712), 'NDE': np.float32(0.3490564)}

Run 54/72: hidden=512, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Dryer
Dataset length: 4586 windows

Epoch [1/300], Train Loss: 0.010860
Validation Loss: 0.01245669
Epoch [2/300], Train Loss: 0.010350
Validation Loss: 0.01033734
Epoch [3/300], Train Loss: 0.005503
Validation Loss: 0.00342226
Epoch [4/300], Train Loss: 0.003231
Validation Loss: 0.00268283
Epoch [5/300], Train Loss: 0.002903
Validation Loss: 0.00247788
Epoch [6/300], Train Loss: 0.002649
Validation Loss: 0.00248292
Epoch [7/300], Train Loss: 0.002886
Validation Loss: 0.00222617
Epoch [8/300], Train Loss: 0.002304
Validation Loss: 0.00215327
Epoch [9/300], Train Loss: 0.002204
Validation Loss: 0.00214090
Epoch [10/300], Train Loss: 0.002065
Validation Loss: 0.00196660
Epoch [11/300], Train Loss: 0.001880
Validation Loss: 0.00187206
Epoch [12/300], Train Loss: 0.001996
Validation Loss: 0.00174786
Epoch [13/300], Train Loss: 0.001790
Validation Loss: 0.00156544
Epoch [14/300], Train Loss: 0.001591
Validation Loss: 0.00172780
Epoch [15/300], Train Loss: 0.001524
Validation Loss: 0.00160917
Epoch [16/300], Train Loss: 0.001574
Validation Loss: 0.00153176
Epoch [17/300], Train Loss: 0.001442
Validation Loss: 0.00140436
Epoch [18/300], Train Loss: 0.001411
Validation Loss: 0.00134089
Epoch [19/300], Train Loss: 0.001417
Validation Loss: 0.00139770
Epoch [20/300], Train Loss: 0.001368
Validation Loss: 0.00127160
Epoch [21/300], Train Loss: 0.001409
Validation Loss: 0.00138563
Epoch [22/300], Train Loss: 0.001389
Validation Loss: 0.00124906
Epoch [23/300], Train Loss: 0.001328
Validation Loss: 0.00120702
Epoch [24/300], Train Loss: 0.001254
Validation Loss: 0.00130101
Epoch [25/300], Train Loss: 0.001245
Validation Loss: 0.00123711
Epoch [26/300], Train Loss: 0.001273
Validation Loss: 0.00119456
Epoch [27/300], Train Loss: 0.001238
Validation Loss: 0.00103447
Epoch [28/300], Train Loss: 0.001179
Validation Loss: 0.00107987
Epoch [29/300], Train Loss: 0.001138
Validation Loss: 0.00095651
Epoch [30/300], Train Loss: 0.001204
Validation Loss: 0.00098947
Epoch [31/300], Train Loss: 0.001109
Validation Loss: 0.00107639
Epoch [32/300], Train Loss: 0.001102
Validation Loss: 0.00106084
Epoch [33/300], Train Loss: 0.001202
Validation Loss: 0.00106016
Epoch [34/300], Train Loss: 0.001112
Validation Loss: 0.00099422
Epoch [35/300], Train Loss: 0.001076
Validation Loss: 0.00109319
Epoch [36/300], Train Loss: 0.001082
Validation Loss: 0.00101798
Epoch [37/300], Train Loss: 0.001016
Validation Loss: 0.00096091
Epoch [38/300], Train Loss: 0.001025
Validation Loss: 0.00099040
Epoch [39/300], Train Loss: 0.001006
Validation Loss: 0.00114035
Early stopping triggered

Evaluating model for: Dryer
Run 54/72 completed in 217.22 seconds with: {'MAE': np.float32(6.052048), 'MSE': np.float32(1325.8718), 'RMSE': np.float32(36.41252), 'SAE': np.float32(0.30807105), 'NDE': np.float32(0.3882807)}

Run 55/72: hidden=512, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Dryer
Dataset length: 4586 windows

Epoch [1/300], Train Loss: 0.010910
Validation Loss: 0.01251996
Epoch [2/300], Train Loss: 0.010567
Validation Loss: 0.01095703
Epoch [3/300], Train Loss: 0.004930
Validation Loss: 0.00302726
Epoch [4/300], Train Loss: 0.003049
Validation Loss: 0.00269281
Epoch [5/300], Train Loss: 0.002920
Validation Loss: 0.00272884
Epoch [6/300], Train Loss: 0.002576
Validation Loss: 0.00241297
Epoch [7/300], Train Loss: 0.002844
Validation Loss: 0.00256784
Epoch [8/300], Train Loss: 0.002126
Validation Loss: 0.00205493
Epoch [9/300], Train Loss: 0.002329
Validation Loss: 0.00197697
Epoch [10/300], Train Loss: 0.002045
Validation Loss: 0.00208575
Epoch [11/300], Train Loss: 0.001982
Validation Loss: 0.00201698
Epoch [12/300], Train Loss: 0.001903
Validation Loss: 0.00168666
Epoch [13/300], Train Loss: 0.001775
Validation Loss: 0.00150982
Epoch [14/300], Train Loss: 0.001531
Validation Loss: 0.00194590
Epoch [15/300], Train Loss: 0.001603
Validation Loss: 0.00190030
Epoch [16/300], Train Loss: 0.001524
Validation Loss: 0.00169157
Epoch [17/300], Train Loss: 0.001773
Validation Loss: 0.00152604
Epoch [18/300], Train Loss: 0.001627
Validation Loss: 0.00131155
Epoch [19/300], Train Loss: 0.001406
Validation Loss: 0.00123386
Epoch [20/300], Train Loss: 0.001314
Validation Loss: 0.00116401
Epoch [21/300], Train Loss: 0.001404
Validation Loss: 0.00117689
Epoch [22/300], Train Loss: 0.001297
Validation Loss: 0.00110319
Epoch [23/300], Train Loss: 0.001271
Validation Loss: 0.00123102
Epoch [24/300], Train Loss: 0.001232
Validation Loss: 0.00114521
Epoch [25/300], Train Loss: 0.001108
Validation Loss: 0.00113217
Epoch [26/300], Train Loss: 0.001106
Validation Loss: 0.00113931
Epoch [27/300], Train Loss: 0.001054
Validation Loss: 0.00106962
Epoch [28/300], Train Loss: 0.001118
Validation Loss: 0.00111496
Epoch [29/300], Train Loss: 0.000977
Validation Loss: 0.00098284
Epoch [30/300], Train Loss: 0.001068
Validation Loss: 0.00102682
Epoch [31/300], Train Loss: 0.000979
Validation Loss: 0.00096078
Epoch [32/300], Train Loss: 0.000975
Validation Loss: 0.00098663
Epoch [33/300], Train Loss: 0.000982
Validation Loss: 0.00090360
Epoch [34/300], Train Loss: 0.000952
Validation Loss: 0.00080475
Epoch [35/300], Train Loss: 0.000924
Validation Loss: 0.00078661
Epoch [36/300], Train Loss: 0.000949
Validation Loss: 0.00096010
Epoch [37/300], Train Loss: 0.001074
Validation Loss: 0.00106926
Epoch [38/300], Train Loss: 0.001169
Validation Loss: 0.00087140
Epoch [39/300], Train Loss: 0.000951
Validation Loss: 0.00070855
Epoch [40/300], Train Loss: 0.000890
Validation Loss: 0.00071742
Epoch [41/300], Train Loss: 0.001138
Validation Loss: 0.00091235
Epoch [42/300], Train Loss: 0.001048
Validation Loss: 0.00099482
Epoch [43/300], Train Loss: 0.001018
Validation Loss: 0.00080372
Epoch [44/300], Train Loss: 0.000986
Validation Loss: 0.00074001
Epoch [45/300], Train Loss: 0.000899
Validation Loss: 0.00063423
Epoch [46/300], Train Loss: 0.000924
Validation Loss: 0.00061290
Epoch [47/300], Train Loss: 0.000952
Validation Loss: 0.00064005
Epoch [48/300], Train Loss: 0.000850
Validation Loss: 0.00063325
Epoch [49/300], Train Loss: 0.000950
Validation Loss: 0.00063991
Epoch [50/300], Train Loss: 0.000872
Validation Loss: 0.00060128
Epoch [51/300], Train Loss: 0.000893
Validation Loss: 0.00061310
Epoch [52/300], Train Loss: 0.000849
Validation Loss: 0.00058040
Epoch [53/300], Train Loss: 0.000823
Validation Loss: 0.00058020
Epoch [54/300], Train Loss: 0.000819
Validation Loss: 0.00057218
Epoch [55/300], Train Loss: 0.000790
Validation Loss: 0.00055254
Epoch [56/300], Train Loss: 0.000819
Validation Loss: 0.00056872
Epoch [57/300], Train Loss: 0.000785
Validation Loss: 0.00063126
Epoch [58/300], Train Loss: 0.000790
Validation Loss: 0.00057654
Epoch [59/300], Train Loss: 0.000830
Validation Loss: 0.00060412
Epoch [60/300], Train Loss: 0.000813
Validation Loss: 0.00058887
Epoch [61/300], Train Loss: 0.000777
Validation Loss: 0.00053761
Epoch [62/300], Train Loss: 0.000790
Validation Loss: 0.00054423
Epoch [63/300], Train Loss: 0.000778
Validation Loss: 0.00053081
Epoch [64/300], Train Loss: 0.000755
Validation Loss: 0.00057851
Epoch [65/300], Train Loss: 0.000755
Validation Loss: 0.00053112
Epoch [66/300], Train Loss: 0.000730
Validation Loss: 0.00054555
Epoch [67/300], Train Loss: 0.000825
Validation Loss: 0.00058740
Epoch [68/300], Train Loss: 0.000762
Validation Loss: 0.00056833
Epoch [69/300], Train Loss: 0.000741
Validation Loss: 0.00050410
Epoch [70/300], Train Loss: 0.000749
Validation Loss: 0.00050217
Epoch [71/300], Train Loss: 0.000760
Validation Loss: 0.00050145
Epoch [72/300], Train Loss: 0.000746
Validation Loss: 0.00049657
Epoch [73/300], Train Loss: 0.000714
Validation Loss: 0.00052312
Epoch [74/300], Train Loss: 0.000711
Validation Loss: 0.00049583
Epoch [75/300], Train Loss: 0.000715
Validation Loss: 0.00048366
Epoch [76/300], Train Loss: 0.000709
Validation Loss: 0.00048878
Epoch [77/300], Train Loss: 0.000715
Validation Loss: 0.00048669
Epoch [78/300], Train Loss: 0.000797
Validation Loss: 0.00066716
Epoch [79/300], Train Loss: 0.000731
Validation Loss: 0.00049923
Epoch [80/300], Train Loss: 0.000682
Validation Loss: 0.00048620
Epoch [81/300], Train Loss: 0.000682
Validation Loss: 0.00048251
Epoch [82/300], Train Loss: 0.000621
Validation Loss: 0.00046174
Epoch [83/300], Train Loss: 0.000621
Validation Loss: 0.00047941
Epoch [84/300], Train Loss: 0.000603
Validation Loss: 0.00045861
Epoch [85/300], Train Loss: 0.000620
Validation Loss: 0.00045382
Epoch [86/300], Train Loss: 0.000814
Validation Loss: 0.00051743
Epoch [87/300], Train Loss: 0.000752
Validation Loss: 0.00048323
Epoch [88/300], Train Loss: 0.000627
Validation Loss: 0.00051926
Epoch [89/300], Train Loss: 0.000626
Validation Loss: 0.00047571
Epoch [90/300], Train Loss: 0.000610
Validation Loss: 0.00049889
Epoch [91/300], Train Loss: 0.000585
Validation Loss: 0.00044281
Epoch [92/300], Train Loss: 0.000594
Validation Loss: 0.00043983
Epoch [93/300], Train Loss: 0.000598
Validation Loss: 0.00046295
Epoch [94/300], Train Loss: 0.000575
Validation Loss: 0.00044789
Epoch [95/300], Train Loss: 0.000575
Validation Loss: 0.00046837
Epoch [96/300], Train Loss: 0.000632
Validation Loss: 0.00042705
Epoch [97/300], Train Loss: 0.000583
Validation Loss: 0.00042960
Epoch [98/300], Train Loss: 0.000566
Validation Loss: 0.00046935
Epoch [99/300], Train Loss: 0.000560
Validation Loss: 0.00042648
Epoch [100/300], Train Loss: 0.000554
Validation Loss: 0.00042530
Epoch [101/300], Train Loss: 0.000573
Validation Loss: 0.00044052
Epoch [102/300], Train Loss: 0.000590
Validation Loss: 0.00042657
Epoch [103/300], Train Loss: 0.000550
Validation Loss: 0.00048054
Epoch [104/300], Train Loss: 0.000574
Validation Loss: 0.00043894
Epoch [105/300], Train Loss: 0.000563
Validation Loss: 0.00041411
Epoch [106/300], Train Loss: 0.000574
Validation Loss: 0.00041458
Epoch [107/300], Train Loss: 0.000536
Validation Loss: 0.00041248
Epoch [108/300], Train Loss: 0.000531
Validation Loss: 0.00042523
Epoch [109/300], Train Loss: 0.000541
Validation Loss: 0.00040752
Epoch [110/300], Train Loss: 0.000535
Validation Loss: 0.00041869
Epoch [111/300], Train Loss: 0.000522
Validation Loss: 0.00044710
Epoch [112/300], Train Loss: 0.000542
Validation Loss: 0.00041246
Epoch [113/300], Train Loss: 0.000533
Validation Loss: 0.00041350
Epoch [114/300], Train Loss: 0.000562
Validation Loss: 0.00039935
Epoch [115/300], Train Loss: 0.000543
Validation Loss: 0.00040291
Epoch [116/300], Train Loss: 0.000523
Validation Loss: 0.00040260
Epoch [117/300], Train Loss: 0.000529
Validation Loss: 0.00039887
Epoch [118/300], Train Loss: 0.000521
Validation Loss: 0.00039424
Epoch [119/300], Train Loss: 0.000515
Validation Loss: 0.00039797
Epoch [120/300], Train Loss: 0.000519
Validation Loss: 0.00039195
Epoch [121/300], Train Loss: 0.000516
Validation Loss: 0.00039692
Epoch [122/300], Train Loss: 0.000505
Validation Loss: 0.00040848
Epoch [123/300], Train Loss: 0.000501
Validation Loss: 0.00039148
Epoch [124/300], Train Loss: 0.000500
Validation Loss: 0.00039334
Epoch [125/300], Train Loss: 0.000517
Validation Loss: 0.00040374
Epoch [126/300], Train Loss: 0.000499
Validation Loss: 0.00039633
Epoch [127/300], Train Loss: 0.000503
Validation Loss: 0.00041495
Epoch [128/300], Train Loss: 0.000506
Validation Loss: 0.00039256
Epoch [129/300], Train Loss: 0.000522
Validation Loss: 0.00039075
Epoch [130/300], Train Loss: 0.000508
Validation Loss: 0.00038078
Epoch [131/300], Train Loss: 0.000495
Validation Loss: 0.00038983
Epoch [132/300], Train Loss: 0.000494
Validation Loss: 0.00041949
Epoch [133/300], Train Loss: 0.000517
Validation Loss: 0.00039070
Epoch [134/300], Train Loss: 0.000490
Validation Loss: 0.00037520
Epoch [135/300], Train Loss: 0.000499
Validation Loss: 0.00039190
Epoch [136/300], Train Loss: 0.000482
Validation Loss: 0.00037829
Epoch [137/300], Train Loss: 0.000481
Validation Loss: 0.00038736
Epoch [138/300], Train Loss: 0.000477
Validation Loss: 0.00038371
Epoch [139/300], Train Loss: 0.000473
Validation Loss: 0.00039064
Epoch [140/300], Train Loss: 0.000491
Validation Loss: 0.00039157
Epoch [141/300], Train Loss: 0.000478
Validation Loss: 0.00038409
Epoch [142/300], Train Loss: 0.000487
Validation Loss: 0.00042233
Epoch [143/300], Train Loss: 0.000636
Validation Loss: 0.00074983
Epoch [144/300], Train Loss: 0.000794
Validation Loss: 0.00057400
Early stopping triggered

Evaluating model for: Dryer
Run 55/72 completed in 905.89 seconds with: {'MAE': np.float32(3.5683053), 'MSE': np.float32(1189.621), 'RMSE': np.float32(34.490883), 'SAE': np.float32(0.077384055), 'NDE': np.float32(0.3677891)}

Run 56/72: hidden=512, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Dryer
Dataset length: 4586 windows

Epoch [1/300], Train Loss: 0.011009
Validation Loss: 0.01257469
Epoch [2/300], Train Loss: 0.010838
Validation Loss: 0.01253172
Epoch [3/300], Train Loss: 0.008605
Validation Loss: 0.00576005
Epoch [4/300], Train Loss: 0.003816
Validation Loss: 0.00316972
Epoch [5/300], Train Loss: 0.003215
Validation Loss: 0.00331353
Epoch [6/300], Train Loss: 0.002702
Validation Loss: 0.00261916
Epoch [7/300], Train Loss: 0.002613
Validation Loss: 0.00268563
Epoch [8/300], Train Loss: 0.002386
Validation Loss: 0.00250871
Epoch [9/300], Train Loss: 0.002255
Validation Loss: 0.00208526
Epoch [10/300], Train Loss: 0.002349
Validation Loss: 0.00265226
Epoch [11/300], Train Loss: 0.002252
Validation Loss: 0.00189707
Epoch [12/300], Train Loss: 0.001950
Validation Loss: 0.00176114
Epoch [13/300], Train Loss: 0.001738
Validation Loss: 0.00169769
Epoch [14/300], Train Loss: 0.001740
Validation Loss: 0.00191381
Epoch [15/300], Train Loss: 0.001551
Validation Loss: 0.00192096
Epoch [16/300], Train Loss: 0.001555
Validation Loss: 0.00158603
Epoch [17/300], Train Loss: 0.001396
Validation Loss: 0.00149237
Epoch [18/300], Train Loss: 0.001354
Validation Loss: 0.00144770
Epoch [19/300], Train Loss: 0.001379
Validation Loss: 0.00143601
Epoch [20/300], Train Loss: 0.001308
Validation Loss: 0.00140669
Epoch [21/300], Train Loss: 0.001306
Validation Loss: 0.00145463
Epoch [22/300], Train Loss: 0.001387
Validation Loss: 0.00135096
Epoch [23/300], Train Loss: 0.001524
Validation Loss: 0.00124464
Epoch [24/300], Train Loss: 0.001289
Validation Loss: 0.00124096
Epoch [25/300], Train Loss: 0.001101
Validation Loss: 0.00117514
Epoch [26/300], Train Loss: 0.001115
Validation Loss: 0.00119373
Epoch [27/300], Train Loss: 0.001111
Validation Loss: 0.00129942
Epoch [28/300], Train Loss: 0.001150
Validation Loss: 0.00128448
Epoch [29/300], Train Loss: 0.001017
Validation Loss: 0.00098134
Epoch [30/300], Train Loss: 0.001033
Validation Loss: 0.00098314
Epoch [31/300], Train Loss: 0.000994
Validation Loss: 0.00116026
Epoch [32/300], Train Loss: 0.001011
Validation Loss: 0.00099381
Epoch [33/300], Train Loss: 0.000955
Validation Loss: 0.00089189
Epoch [34/300], Train Loss: 0.000965
Validation Loss: 0.00081094
Epoch [35/300], Train Loss: 0.000921
Validation Loss: 0.00083789
Epoch [36/300], Train Loss: 0.000842
Validation Loss: 0.00072152
Epoch [37/300], Train Loss: 0.000889
Validation Loss: 0.00082738
Epoch [38/300], Train Loss: 0.000896
Validation Loss: 0.00074932
Epoch [39/300], Train Loss: 0.000835
Validation Loss: 0.00071664
Epoch [40/300], Train Loss: 0.000843
Validation Loss: 0.00077673
Epoch [41/300], Train Loss: 0.000847
Validation Loss: 0.00070287
Epoch [42/300], Train Loss: 0.000807
Validation Loss: 0.00069761
Epoch [43/300], Train Loss: 0.000829
Validation Loss: 0.00068087
Epoch [44/300], Train Loss: 0.000824
Validation Loss: 0.00070466
Epoch [45/300], Train Loss: 0.000758
Validation Loss: 0.00062095
Epoch [46/300], Train Loss: 0.000763
Validation Loss: 0.00058823
Epoch [47/300], Train Loss: 0.000792
Validation Loss: 0.00056451
Epoch [48/300], Train Loss: 0.000713
Validation Loss: 0.00078265
Epoch [49/300], Train Loss: 0.000778
Validation Loss: 0.00054641
Epoch [50/300], Train Loss: 0.000661
Validation Loss: 0.00053271
Epoch [51/300], Train Loss: 0.000677
Validation Loss: 0.00055812
Epoch [52/300], Train Loss: 0.000659
Validation Loss: 0.00051821
Epoch [53/300], Train Loss: 0.000676
Validation Loss: 0.00051967
Epoch [54/300], Train Loss: 0.000655
Validation Loss: 0.00051972
Epoch [55/300], Train Loss: 0.000613
Validation Loss: 0.00049826
Epoch [56/300], Train Loss: 0.000626
Validation Loss: 0.00050930
Epoch [57/300], Train Loss: 0.000610
Validation Loss: 0.00063491
Epoch [58/300], Train Loss: 0.000630
Validation Loss: 0.00052168
Epoch [59/300], Train Loss: 0.000639
Validation Loss: 0.00048959
Epoch [60/300], Train Loss: 0.000640
Validation Loss: 0.00051119
Epoch [61/300], Train Loss: 0.000855
Validation Loss: 0.00125459
Epoch [62/300], Train Loss: 0.001469
Validation Loss: 0.00102079
Epoch [63/300], Train Loss: 0.001159
Validation Loss: 0.00087065
Epoch [64/300], Train Loss: 0.000853
Validation Loss: 0.00072668
Epoch [65/300], Train Loss: 0.000800
Validation Loss: 0.00065607
Epoch [66/300], Train Loss: 0.000728
Validation Loss: 0.00060398
Epoch [67/300], Train Loss: 0.000739
Validation Loss: 0.00058147
Epoch [68/300], Train Loss: 0.000696
Validation Loss: 0.00057539
Epoch [69/300], Train Loss: 0.000696
Validation Loss: 0.00046511
Epoch [70/300], Train Loss: 0.000671
Validation Loss: 0.00046285
Epoch [71/300], Train Loss: 0.000632
Validation Loss: 0.00052319
Epoch [72/300], Train Loss: 0.000619
Validation Loss: 0.00045979
Epoch [73/300], Train Loss: 0.000581
Validation Loss: 0.00048461
Epoch [74/300], Train Loss: 0.000572
Validation Loss: 0.00044835
Epoch [75/300], Train Loss: 0.000590
Validation Loss: 0.00045992
Epoch [76/300], Train Loss: 0.000568
Validation Loss: 0.00050596
Epoch [77/300], Train Loss: 0.000585
Validation Loss: 0.00045914
Epoch [78/300], Train Loss: 0.000548
Validation Loss: 0.00051663
Epoch [79/300], Train Loss: 0.000574
Validation Loss: 0.00045958
Epoch [80/300], Train Loss: 0.000561
Validation Loss: 0.00044982
Epoch [81/300], Train Loss: 0.000571
Validation Loss: 0.00042688
Epoch [82/300], Train Loss: 0.000558
Validation Loss: 0.00042524
Epoch [83/300], Train Loss: 0.000556
Validation Loss: 0.00044163
Epoch [84/300], Train Loss: 0.000539
Validation Loss: 0.00042395
Epoch [85/300], Train Loss: 0.000548
Validation Loss: 0.00042006
Epoch [86/300], Train Loss: 0.000545
Validation Loss: 0.00047676
Epoch [87/300], Train Loss: 0.000556
Validation Loss: 0.00042068
Epoch [88/300], Train Loss: 0.000532
Validation Loss: 0.00045866
Epoch [89/300], Train Loss: 0.000545
Validation Loss: 0.00044025
Epoch [90/300], Train Loss: 0.000549
Validation Loss: 0.00044401
Epoch [91/300], Train Loss: 0.000515
Validation Loss: 0.00041281
Epoch [92/300], Train Loss: 0.000543
Validation Loss: 0.00042861
Epoch [93/300], Train Loss: 0.000533
Validation Loss: 0.00045605
Epoch [94/300], Train Loss: 0.000521
Validation Loss: 0.00042104
Epoch [95/300], Train Loss: 0.000537
Validation Loss: 0.00047869
Epoch [96/300], Train Loss: 0.000589
Validation Loss: 0.00041255
Epoch [97/300], Train Loss: 0.000519
Validation Loss: 0.00039840
Epoch [98/300], Train Loss: 0.000509
Validation Loss: 0.00043440
Epoch [99/300], Train Loss: 0.000505
Validation Loss: 0.00039455
Epoch [100/300], Train Loss: 0.000489
Validation Loss: 0.00040765
Epoch [101/300], Train Loss: 0.000496
Validation Loss: 0.00044084
Epoch [102/300], Train Loss: 0.000508
Validation Loss: 0.00038682
Epoch [103/300], Train Loss: 0.000485
Validation Loss: 0.00041448
Epoch [104/300], Train Loss: 0.000519
Validation Loss: 0.00039257
Epoch [105/300], Train Loss: 0.000516
Validation Loss: 0.00039379
Epoch [106/300], Train Loss: 0.000513
Validation Loss: 0.00038350
Epoch [107/300], Train Loss: 0.000482
Validation Loss: 0.00038545
Epoch [108/300], Train Loss: 0.000479
Validation Loss: 0.00039620
Epoch [109/300], Train Loss: 0.000489
Validation Loss: 0.00037627
Epoch [110/300], Train Loss: 0.000471
Validation Loss: 0.00038322
Epoch [111/300], Train Loss: 0.000461
Validation Loss: 0.00050593
Epoch [112/300], Train Loss: 0.000504
Validation Loss: 0.00038785
Epoch [113/300], Train Loss: 0.000479
Validation Loss: 0.00036780
Epoch [114/300], Train Loss: 0.000494
Validation Loss: 0.00036949
Epoch [115/300], Train Loss: 0.000480
Validation Loss: 0.00035901
Epoch [116/300], Train Loss: 0.000484
Validation Loss: 0.00038043
Epoch [117/300], Train Loss: 0.000479
Validation Loss: 0.00041179
Epoch [118/300], Train Loss: 0.000486
Validation Loss: 0.00035405
Epoch [119/300], Train Loss: 0.000457
Validation Loss: 0.00036104
Epoch [120/300], Train Loss: 0.000456
Validation Loss: 0.00035495
Epoch [121/300], Train Loss: 0.000451
Validation Loss: 0.00035249
Epoch [122/300], Train Loss: 0.000441
Validation Loss: 0.00036783
Epoch [123/300], Train Loss: 0.000440
Validation Loss: 0.00035140
Epoch [124/300], Train Loss: 0.000447
Validation Loss: 0.00034414
Epoch [125/300], Train Loss: 0.000435
Validation Loss: 0.00034468
Epoch [126/300], Train Loss: 0.000437
Validation Loss: 0.00034872
Epoch [127/300], Train Loss: 0.000438
Validation Loss: 0.00039043
Epoch [128/300], Train Loss: 0.000446
Validation Loss: 0.00035027
Epoch [129/300], Train Loss: 0.000452
Validation Loss: 0.00036608
Epoch [130/300], Train Loss: 0.000449
Validation Loss: 0.00033510
Epoch [131/300], Train Loss: 0.000435
Validation Loss: 0.00033253
Epoch [132/300], Train Loss: 0.000427
Validation Loss: 0.00035164
Epoch [133/300], Train Loss: 0.000544
Validation Loss: 0.00035641
Epoch [134/300], Train Loss: 0.000480
Validation Loss: 0.00035535
Epoch [135/300], Train Loss: 0.000452
Validation Loss: 0.00032697
Epoch [136/300], Train Loss: 0.000420
Validation Loss: 0.00032673
Epoch [137/300], Train Loss: 0.000416
Validation Loss: 0.00032682
Epoch [138/300], Train Loss: 0.000412
Validation Loss: 0.00032340
Epoch [139/300], Train Loss: 0.000422
Validation Loss: 0.00032110
Epoch [140/300], Train Loss: 0.000454
Validation Loss: 0.00032858
Epoch [141/300], Train Loss: 0.000431
Validation Loss: 0.00031657
Epoch [142/300], Train Loss: 0.000423
Validation Loss: 0.00036025
Epoch [143/300], Train Loss: 0.000415
Validation Loss: 0.00032576
Epoch [144/300], Train Loss: 0.000405
Validation Loss: 0.00031769
Epoch [145/300], Train Loss: 0.000404
Validation Loss: 0.00032118
Epoch [146/300], Train Loss: 0.000413
Validation Loss: 0.00031122
Epoch [147/300], Train Loss: 0.000407
Validation Loss: 0.00034687
Epoch [148/300], Train Loss: 0.000445
Validation Loss: 0.00033558
Epoch [149/300], Train Loss: 0.000411
Validation Loss: 0.00037727
Epoch [150/300], Train Loss: 0.000411
Validation Loss: 0.00029425
Epoch [151/300], Train Loss: 0.000407
Validation Loss: 0.00030346
Epoch [152/300], Train Loss: 0.000385
Validation Loss: 0.00030847
Epoch [153/300], Train Loss: 0.000380
Validation Loss: 0.00033022
Epoch [154/300], Train Loss: 0.000389
Validation Loss: 0.00033091
Epoch [155/300], Train Loss: 0.000376
Validation Loss: 0.00029579
Epoch [156/300], Train Loss: 0.000391
Validation Loss: 0.00030914
Epoch [157/300], Train Loss: 0.000382
Validation Loss: 0.00031097
Epoch [158/300], Train Loss: 0.000386
Validation Loss: 0.00028449
Epoch [159/300], Train Loss: 0.000401
Validation Loss: 0.00033232
Epoch [160/300], Train Loss: 0.000381
Validation Loss: 0.00027389
Epoch [161/300], Train Loss: 0.000415
Validation Loss: 0.00029678
Epoch [162/300], Train Loss: 0.000442
Validation Loss: 0.00029877
Epoch [163/300], Train Loss: 0.000370
Validation Loss: 0.00028540
Epoch [164/300], Train Loss: 0.000371
Validation Loss: 0.00027361
Epoch [165/300], Train Loss: 0.000380
Validation Loss: 0.00028938
Epoch [166/300], Train Loss: 0.000363
Validation Loss: 0.00027404
Epoch [167/300], Train Loss: 0.000420
Validation Loss: 0.00031299
Epoch [168/300], Train Loss: 0.000377
Validation Loss: 0.00025515
Epoch [169/300], Train Loss: 0.000366
Validation Loss: 0.00033435
Epoch [170/300], Train Loss: 0.000365
Validation Loss: 0.00032051
Epoch [171/300], Train Loss: 0.000361
Validation Loss: 0.00030893
Epoch [172/300], Train Loss: 0.000368
Validation Loss: 0.00031023
Epoch [173/300], Train Loss: 0.000374
Validation Loss: 0.00034157
Epoch [174/300], Train Loss: 0.000360
Validation Loss: 0.00033120
Epoch [175/300], Train Loss: 0.000347
Validation Loss: 0.00028751
Epoch [176/300], Train Loss: 0.000358
Validation Loss: 0.00025314
Epoch [177/300], Train Loss: 0.000349
Validation Loss: 0.00024059
Epoch [178/300], Train Loss: 0.000345
Validation Loss: 0.00027760
Epoch [179/300], Train Loss: 0.000347
Validation Loss: 0.00036169
Epoch [180/300], Train Loss: 0.000415
Validation Loss: 0.00021727
Epoch [181/300], Train Loss: 0.000346
Validation Loss: 0.00033297
Epoch [182/300], Train Loss: 0.000339
Validation Loss: 0.00034204
Epoch [183/300], Train Loss: 0.000390
Validation Loss: 0.00026086
Epoch [184/300], Train Loss: 0.000354
Validation Loss: 0.00021215
Epoch [185/300], Train Loss: 0.000343
Validation Loss: 0.00021426
Epoch [186/300], Train Loss: 0.000342
Validation Loss: 0.00020669
Epoch [187/300], Train Loss: 0.000352
Validation Loss: 0.00020556
Epoch [188/300], Train Loss: 0.000351
Validation Loss: 0.00026681
Epoch [189/300], Train Loss: 0.000337
Validation Loss: 0.00019850
Epoch [190/300], Train Loss: 0.000347
Validation Loss: 0.00018043
Epoch [191/300], Train Loss: 0.000372
Validation Loss: 0.00033530
Epoch [192/300], Train Loss: 0.000336
Validation Loss: 0.00034603
Epoch [193/300], Train Loss: 0.000334
Validation Loss: 0.00032092
Epoch [194/300], Train Loss: 0.000341
Validation Loss: 0.00032142
Epoch [195/300], Train Loss: 0.000319
Validation Loss: 0.00032227
Epoch [196/300], Train Loss: 0.000323
Validation Loss: 0.00017656
Epoch [197/300], Train Loss: 0.000332
Validation Loss: 0.00033481
Epoch [198/300], Train Loss: 0.000331
Validation Loss: 0.00016966
Epoch [199/300], Train Loss: 0.000322
Validation Loss: 0.00018616
Epoch [200/300], Train Loss: 0.000305
Validation Loss: 0.00030446
Epoch [201/300], Train Loss: 0.000315
Validation Loss: 0.00024891
Epoch [202/300], Train Loss: 0.000317
Validation Loss: 0.00020529
Epoch [203/300], Train Loss: 0.000313
Validation Loss: 0.00032419
Epoch [204/300], Train Loss: 0.000314
Validation Loss: 0.00017069
Epoch [205/300], Train Loss: 0.000321
Validation Loss: 0.00034286
Epoch [206/300], Train Loss: 0.000320
Validation Loss: 0.00017416
Epoch [207/300], Train Loss: 0.000297
Validation Loss: 0.00026852
Epoch [208/300], Train Loss: 0.000313
Validation Loss: 0.00030929
Early stopping triggered

Evaluating model for: Dryer
Run 56/72 completed in 1510.21 seconds with: {'MAE': np.float32(3.028476), 'MSE': np.float32(1165.7354), 'RMSE': np.float32(34.142868), 'SAE': np.float32(0.08646368), 'NDE': np.float32(0.3640782)}

Run 57/72: hidden=512, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Dryer
Dataset length: 3006 windows

Epoch [1/300], Train Loss: 0.010562
Validation Loss: 0.00790814
Epoch [2/300], Train Loss: 0.010476
Validation Loss: 0.00769625
Epoch [3/300], Train Loss: 0.009953
Validation Loss: 0.00728578
Epoch [4/300], Train Loss: 0.007251
Validation Loss: 0.00604655
Epoch [5/300], Train Loss: 0.003428
Validation Loss: 0.00451599
Epoch [6/300], Train Loss: 0.002588
Validation Loss: 0.00367769
Epoch [7/300], Train Loss: 0.002433
Validation Loss: 0.00346734
Epoch [8/300], Train Loss: 0.002173
Validation Loss: 0.00339531
Epoch [9/300], Train Loss: 0.002159
Validation Loss: 0.00325207
Epoch [10/300], Train Loss: 0.002141
Validation Loss: 0.00313023
Epoch [11/300], Train Loss: 0.002066
Validation Loss: 0.00308920
Epoch [12/300], Train Loss: 0.001965
Validation Loss: 0.00281970
Epoch [13/300], Train Loss: 0.001973
Validation Loss: 0.00294717
Epoch [14/300], Train Loss: 0.001804
Validation Loss: 0.00284146
Epoch [15/300], Train Loss: 0.001911
Validation Loss: 0.00246894
Epoch [16/300], Train Loss: 0.001804
Validation Loss: 0.00320098
Epoch [17/300], Train Loss: 0.001773
Validation Loss: 0.00271117
Epoch [18/300], Train Loss: 0.001575
Validation Loss: 0.00232166
Epoch [19/300], Train Loss: 0.001383
Validation Loss: 0.00195538
Epoch [20/300], Train Loss: 0.001218
Validation Loss: 0.00118889
Epoch [21/300], Train Loss: 0.001122
Validation Loss: 0.00108544
Epoch [22/300], Train Loss: 0.001393
Validation Loss: 0.00269933
Epoch [23/300], Train Loss: 0.001355
Validation Loss: 0.00114011
Epoch [24/300], Train Loss: 0.001198
Validation Loss: 0.00126266
Epoch [25/300], Train Loss: 0.001067
Validation Loss: 0.00109134
Epoch [26/300], Train Loss: 0.000965
Validation Loss: 0.00100329
Epoch [27/300], Train Loss: 0.001035
Validation Loss: 0.00103987
Epoch [28/300], Train Loss: 0.000974
Validation Loss: 0.00178426
Epoch [29/300], Train Loss: 0.001639
Validation Loss: 0.00234503
Epoch [30/300], Train Loss: 0.001372
Validation Loss: 0.00236314
Epoch [31/300], Train Loss: 0.001204
Validation Loss: 0.00183866
Epoch [32/300], Train Loss: 0.001226
Validation Loss: 0.00250762
Epoch [33/300], Train Loss: 0.001235
Validation Loss: 0.00157084
Epoch [34/300], Train Loss: 0.001103
Validation Loss: 0.00119683
Epoch [35/300], Train Loss: 0.000918
Validation Loss: 0.00108699
Epoch [36/300], Train Loss: 0.000880
Validation Loss: 0.00111312
Early stopping triggered

Evaluating model for: Dryer
Run 57/72 completed in 178.46 seconds with: {'MAE': np.float32(5.72368), 'MSE': np.float32(1248.1696), 'RMSE': np.float32(35.329445), 'SAE': np.float32(0.02917147), 'NDE': np.float32(0.25560638)}

Run 58/72: hidden=512, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Dryer
Dataset length: 3006 windows

Epoch [1/300], Train Loss: 0.010651
Validation Loss: 0.00788984
Epoch [2/300], Train Loss: 0.010472
Validation Loss: 0.00762231
Epoch [3/300], Train Loss: 0.008480
Validation Loss: 0.00613631
Epoch [4/300], Train Loss: 0.004751
Validation Loss: 0.00413128
Epoch [5/300], Train Loss: 0.003105
Validation Loss: 0.00396783
Epoch [6/300], Train Loss: 0.002639
Validation Loss: 0.00347352
Epoch [7/300], Train Loss: 0.002776
Validation Loss: 0.00294277
Epoch [8/300], Train Loss: 0.002768
Validation Loss: 0.00277457
Epoch [9/300], Train Loss: 0.002612
Validation Loss: 0.00268633
Epoch [10/300], Train Loss: 0.002672
Validation Loss: 0.00262383
Epoch [11/300], Train Loss: 0.002531
Validation Loss: 0.00383312
Epoch [12/300], Train Loss: 0.002528
Validation Loss: 0.00282927
Epoch [13/300], Train Loss: 0.003991
Validation Loss: 0.00354496
Epoch [14/300], Train Loss: 0.003912
Validation Loss: 0.00368649
Epoch [15/300], Train Loss: 0.002934
Validation Loss: 0.00365688
Epoch [16/300], Train Loss: 0.002779
Validation Loss: 0.00256331
Epoch [17/300], Train Loss: 0.002690
Validation Loss: 0.00341315
Epoch [18/300], Train Loss: 0.002657
Validation Loss: 0.00261760
Epoch [19/300], Train Loss: 0.002630
Validation Loss: 0.00266602
Epoch [20/300], Train Loss: 0.002648
Validation Loss: 0.00277297
Epoch [21/300], Train Loss: 0.002618
Validation Loss: 0.00255213
Epoch [22/300], Train Loss: 0.002633
Validation Loss: 0.00258816
Epoch [23/300], Train Loss: 0.002621
Validation Loss: 0.00328653
Epoch [24/300], Train Loss: 0.002581
Validation Loss: 0.00335148
Epoch [25/300], Train Loss: 0.002594
Validation Loss: 0.00259614
Epoch [26/300], Train Loss: 0.002595
Validation Loss: 0.00262655
Epoch [27/300], Train Loss: 0.002589
Validation Loss: 0.00342511
Epoch [28/300], Train Loss: 0.002568
Validation Loss: 0.00237534
Epoch [29/300], Train Loss: 0.002622
Validation Loss: 0.00252016
Epoch [30/300], Train Loss: 0.002562
Validation Loss: 0.00244701
Epoch [31/300], Train Loss: 0.002520
Validation Loss: 0.00235803
Epoch [32/300], Train Loss: 0.002590
Validation Loss: 0.00248402
Epoch [33/300], Train Loss: 0.002538
Validation Loss: 0.00234322
Epoch [34/300], Train Loss: 0.002486
Validation Loss: 0.00231282
Epoch [35/300], Train Loss: 0.002484
Validation Loss: 0.00231684
Epoch [36/300], Train Loss: 0.002462
Validation Loss: 0.00222501
Epoch [37/300], Train Loss: 0.002491
Validation Loss: 0.00209510
Epoch [38/300], Train Loss: 0.002468
Validation Loss: 0.00208471
Epoch [39/300], Train Loss: 0.002468
Validation Loss: 0.00218997
Epoch [40/300], Train Loss: 0.002439
Validation Loss: 0.00215177
Epoch [41/300], Train Loss: 0.002469
Validation Loss: 0.00207493
Epoch [42/300], Train Loss: 0.002423
Validation Loss: 0.00196340
Epoch [43/300], Train Loss: 0.002391
Validation Loss: 0.00280109
Epoch [44/300], Train Loss: 0.002413
Validation Loss: 0.00190716
Epoch [45/300], Train Loss: 0.002420
Validation Loss: 0.00185270
Epoch [46/300], Train Loss: 0.002424
Validation Loss: 0.00180578
Epoch [47/300], Train Loss: 0.002320
Validation Loss: 0.00188721
Epoch [48/300], Train Loss: 0.002277
Validation Loss: 0.00187513
Epoch [49/300], Train Loss: 0.002256
Validation Loss: 0.00178542
Epoch [50/300], Train Loss: 0.002226
Validation Loss: 0.00173437
Epoch [51/300], Train Loss: 0.002272
Validation Loss: 0.00167529
Epoch [52/300], Train Loss: 0.002241
Validation Loss: 0.00165725
Epoch [53/300], Train Loss: 0.002231
Validation Loss: 0.00178027
Epoch [54/300], Train Loss: 0.002207
Validation Loss: 0.00167945
Epoch [55/300], Train Loss: 0.002259
Validation Loss: 0.00172174
Epoch [56/300], Train Loss: 0.002259
Validation Loss: 0.00165517
Epoch [57/300], Train Loss: 0.002190
Validation Loss: 0.00166233
Epoch [58/300], Train Loss: 0.002195
Validation Loss: 0.00159481
Epoch [59/300], Train Loss: 0.002232
Validation Loss: 0.00158629
Epoch [60/300], Train Loss: 0.002239
Validation Loss: 0.00157957
Epoch [61/300], Train Loss: 0.002179
Validation Loss: 0.00162060
Epoch [62/300], Train Loss: 0.002178
Validation Loss: 0.00158243
Epoch [63/300], Train Loss: 0.002182
Validation Loss: 0.00158372
Epoch [64/300], Train Loss: 0.002204
Validation Loss: 0.00153715
Epoch [65/300], Train Loss: 0.002168
Validation Loss: 0.00155699
Epoch [66/300], Train Loss: 0.002164
Validation Loss: 0.00162016
Epoch [67/300], Train Loss: 0.002217
Validation Loss: 0.00152857
Epoch [68/300], Train Loss: 0.002179
Validation Loss: 0.00151225
Epoch [69/300], Train Loss: 0.002160
Validation Loss: 0.00147934
Epoch [70/300], Train Loss: 0.002170
Validation Loss: 0.00150424
Epoch [71/300], Train Loss: 0.002163
Validation Loss: 0.00156528
Epoch [72/300], Train Loss: 0.002149
Validation Loss: 0.00149583
Epoch [73/300], Train Loss: 0.002169
Validation Loss: 0.00153255
Epoch [74/300], Train Loss: 0.002151
Validation Loss: 0.00147011
Epoch [75/300], Train Loss: 0.002138
Validation Loss: 0.00148172
Epoch [76/300], Train Loss: 0.002141
Validation Loss: 0.00151867
Epoch [77/300], Train Loss: 0.002139
Validation Loss: 0.00148358
Epoch [78/300], Train Loss: 0.002150
Validation Loss: 0.00147570
Epoch [79/300], Train Loss: 0.002128
Validation Loss: 0.00147036
Epoch [80/300], Train Loss: 0.002169
Validation Loss: 0.00149164
Epoch [81/300], Train Loss: 0.002144
Validation Loss: 0.00146699
Epoch [82/300], Train Loss: 0.002133
Validation Loss: 0.00145904
Epoch [83/300], Train Loss: 0.002159
Validation Loss: 0.00172658
Epoch [84/300], Train Loss: 0.002174
Validation Loss: 0.00155174
Epoch [85/300], Train Loss: 0.002180
Validation Loss: 0.00152842
Epoch [86/300], Train Loss: 0.002131
Validation Loss: 0.00148335
Epoch [87/300], Train Loss: 0.002170
Validation Loss: 0.00144108
Epoch [88/300], Train Loss: 0.002129
Validation Loss: 0.00145070
Epoch [89/300], Train Loss: 0.002136
Validation Loss: 0.00142327
Epoch [90/300], Train Loss: 0.002122
Validation Loss: 0.00142085
Epoch [91/300], Train Loss: 0.002138
Validation Loss: 0.00142554
Epoch [92/300], Train Loss: 0.002184
Validation Loss: 0.00146571
Epoch [93/300], Train Loss: 0.002138
Validation Loss: 0.00145818
Epoch [94/300], Train Loss: 0.002179
Validation Loss: 0.00143559
Epoch [95/300], Train Loss: 0.002136
Validation Loss: 0.00141778
Epoch [96/300], Train Loss: 0.002159
Validation Loss: 0.00143733
Epoch [97/300], Train Loss: 0.002157
Validation Loss: 0.00141490
Epoch [98/300], Train Loss: 0.002140
Validation Loss: 0.00139833
Epoch [99/300], Train Loss: 0.002125
Validation Loss: 0.00137910
Epoch [100/300], Train Loss: 0.002174
Validation Loss: 0.00139260
Epoch [101/300], Train Loss: 0.002164
Validation Loss: 0.00137738
Epoch [102/300], Train Loss: 0.002101
Validation Loss: 0.00142333
Epoch [103/300], Train Loss: 0.002099
Validation Loss: 0.00141359
Epoch [104/300], Train Loss: 0.002152
Validation Loss: 0.00135695
Epoch [105/300], Train Loss: 0.002136
Validation Loss: 0.00136711
Epoch [106/300], Train Loss: 0.002101
Validation Loss: 0.00136622
Epoch [107/300], Train Loss: 0.002088
Validation Loss: 0.00138201
Epoch [108/300], Train Loss: 0.002158
Validation Loss: 0.00137287
Epoch [109/300], Train Loss: 0.002085
Validation Loss: 0.00136776
Epoch [110/300], Train Loss: 0.002106
Validation Loss: 0.00143197
Epoch [111/300], Train Loss: 0.002141
Validation Loss: 0.00135824
Epoch [112/300], Train Loss: 0.002145
Validation Loss: 0.00134394
Epoch [113/300], Train Loss: 0.002083
Validation Loss: 0.00135325
Epoch [114/300], Train Loss: 0.002147
Validation Loss: 0.00135941
Epoch [115/300], Train Loss: 0.002082
Validation Loss: 0.00133965
Epoch [116/300], Train Loss: 0.002085
Validation Loss: 0.00133508
Epoch [117/300], Train Loss: 0.002100
Validation Loss: 0.00137840
Epoch [118/300], Train Loss: 0.002093
Validation Loss: 0.00133777
Epoch [119/300], Train Loss: 0.002097
Validation Loss: 0.00131354
Epoch [120/300], Train Loss: 0.002079
Validation Loss: 0.00133349
Epoch [121/300], Train Loss: 0.002080
Validation Loss: 0.00135051
Epoch [122/300], Train Loss: 0.002107
Validation Loss: 0.00132131
Epoch [123/300], Train Loss: 0.002108
Validation Loss: 0.00133660
Epoch [124/300], Train Loss: 0.002069
Validation Loss: 0.00130194
Epoch [125/300], Train Loss: 0.002111
Validation Loss: 0.00132007
Epoch [126/300], Train Loss: 0.002096
Validation Loss: 0.00135340
Epoch [127/300], Train Loss: 0.002073
Validation Loss: 0.00134691
Epoch [128/300], Train Loss: 0.002097
Validation Loss: 0.00133566
Epoch [129/300], Train Loss: 0.002106
Validation Loss: 0.00132675
Epoch [130/300], Train Loss: 0.002083
Validation Loss: 0.00134280
Epoch [131/300], Train Loss: 0.002105
Validation Loss: 0.00130850
Epoch [132/300], Train Loss: 0.002072
Validation Loss: 0.00133543
Epoch [133/300], Train Loss: 0.002072
Validation Loss: 0.00133135
Epoch [134/300], Train Loss: 0.002080
Validation Loss: 0.00133042
Early stopping triggered

Evaluating model for: Dryer
Run 58/72 completed in 843.74 seconds with: {'MAE': np.float32(10.464115), 'MSE': np.float32(3695.5906), 'RMSE': np.float32(60.79137), 'SAE': np.float32(0.05553999), 'NDE': np.float32(0.43982023)}

Run 59/72: hidden=512, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Dryer
Dataset length: 3006 windows

Epoch [1/300], Train Loss: 0.010665
Validation Loss: 0.00792494
Epoch [2/300], Train Loss: 0.010620
Validation Loss: 0.00785648
Epoch [3/300], Train Loss: 0.010173
Validation Loss: 0.00690111
Epoch [4/300], Train Loss: 0.005566
Validation Loss: 0.00472730
Epoch [5/300], Train Loss: 0.002966
Validation Loss: 0.00380382
Epoch [6/300], Train Loss: 0.002615
Validation Loss: 0.00350379
Epoch [7/300], Train Loss: 0.002373
Validation Loss: 0.00261099
Epoch [8/300], Train Loss: 0.002514
Validation Loss: 0.00343331
Epoch [9/300], Train Loss: 0.002801
Validation Loss: 0.00355134
Epoch [10/300], Train Loss: 0.002387
Validation Loss: 0.00308186
Epoch [11/300], Train Loss: 0.002175
Validation Loss: 0.00298877
Epoch [12/300], Train Loss: 0.002009
Validation Loss: 0.00246592
Epoch [13/300], Train Loss: 0.001914
Validation Loss: 0.00305571
Epoch [14/300], Train Loss: 0.001731
Validation Loss: 0.00266672
Epoch [15/300], Train Loss: 0.001774
Validation Loss: 0.00216450
Epoch [16/300], Train Loss: 0.002055
Validation Loss: 0.00245463
Epoch [17/300], Train Loss: 0.001638
Validation Loss: 0.00209158
Epoch [18/300], Train Loss: 0.001471
Validation Loss: 0.00183149
Epoch [19/300], Train Loss: 0.001388
Validation Loss: 0.00238438
Epoch [20/300], Train Loss: 0.001454
Validation Loss: 0.00236536
Epoch [21/300], Train Loss: 0.001258
Validation Loss: 0.00134285
Epoch [22/300], Train Loss: 0.001173
Validation Loss: 0.00171210
Epoch [23/300], Train Loss: 0.000973
Validation Loss: 0.00110641
Epoch [24/300], Train Loss: 0.000895
Validation Loss: 0.00192028
Epoch [25/300], Train Loss: 0.000989
Validation Loss: 0.00100371
Epoch [26/300], Train Loss: 0.000815
Validation Loss: 0.00075475
Epoch [27/300], Train Loss: 0.000787
Validation Loss: 0.00111550
Epoch [28/300], Train Loss: 0.000749
Validation Loss: 0.00078174
Epoch [29/300], Train Loss: 0.000681
Validation Loss: 0.00072715
Epoch [30/300], Train Loss: 0.000691
Validation Loss: 0.00067420
Epoch [31/300], Train Loss: 0.000637
Validation Loss: 0.00056650
Epoch [32/300], Train Loss: 0.000644
Validation Loss: 0.00102335
Epoch [33/300], Train Loss: 0.000619
Validation Loss: 0.00069468
Epoch [34/300], Train Loss: 0.000598
Validation Loss: 0.00065715
Epoch [35/300], Train Loss: 0.000614
Validation Loss: 0.00105936
Epoch [36/300], Train Loss: 0.000644
Validation Loss: 0.00067236
Epoch [37/300], Train Loss: 0.000580
Validation Loss: 0.00064104
Epoch [38/300], Train Loss: 0.000558
Validation Loss: 0.00067947
Epoch [39/300], Train Loss: 0.000559
Validation Loss: 0.00065264
Epoch [40/300], Train Loss: 0.000548
Validation Loss: 0.00063521
Epoch [41/300], Train Loss: 0.000538
Validation Loss: 0.00064703
Early stopping triggered

Evaluating model for: Dryer
Run 59/72 completed in 308.78 seconds with: {'MAE': np.float32(3.3400452), 'MSE': np.float32(692.6646), 'RMSE': np.float32(26.318521), 'SAE': np.float32(0.030641183), 'NDE': np.float32(0.19041266)}

Run 60/72: hidden=512, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Dryer
Dataset length: 3006 windows

Epoch [1/300], Train Loss: 0.010653
Validation Loss: 0.00796511
Epoch [2/300], Train Loss: 0.010664
Validation Loss: 0.00790866
Epoch [3/300], Train Loss: 0.010483
Validation Loss: 0.00784853
Epoch [4/300], Train Loss: 0.007978
Validation Loss: 0.00427725
Epoch [5/300], Train Loss: 0.002908
Validation Loss: 0.00438011
Epoch [6/300], Train Loss: 0.003005
Validation Loss: 0.00353579
Epoch [7/300], Train Loss: 0.002417
Validation Loss: 0.00312400
Epoch [8/300], Train Loss: 0.002634
Validation Loss: 0.00271730
Epoch [9/300], Train Loss: 0.002786
Validation Loss: 0.00575929
Epoch [10/300], Train Loss: 0.007659
Validation Loss: 0.00497640
Epoch [11/300], Train Loss: 0.003360
Validation Loss: 0.00369423
Epoch [12/300], Train Loss: 0.004318
Validation Loss: 0.00276604
Epoch [13/300], Train Loss: 0.002912
Validation Loss: 0.00265298
Epoch [14/300], Train Loss: 0.003460
Validation Loss: 0.00284302
Epoch [15/300], Train Loss: 0.002749
Validation Loss: 0.00294542
Epoch [16/300], Train Loss: 0.002726
Validation Loss: 0.00245028
Epoch [17/300], Train Loss: 0.002731
Validation Loss: 0.00250460
Epoch [18/300], Train Loss: 0.002986
Validation Loss: 0.00527678
Epoch [19/300], Train Loss: 0.004256
Validation Loss: 0.00287955
Epoch [20/300], Train Loss: 0.002933
Validation Loss: 0.00274068
Epoch [21/300], Train Loss: 0.002684
Validation Loss: 0.00249581
Epoch [22/300], Train Loss: 0.002656
Validation Loss: 0.00260987
Epoch [23/300], Train Loss: 0.002636
Validation Loss: 0.00243935
Epoch [24/300], Train Loss: 0.002606
Validation Loss: 0.00247745
Epoch [25/300], Train Loss: 0.002617
Validation Loss: 0.00253930
Epoch [26/300], Train Loss: 0.002601
Validation Loss: 0.00268953
Epoch [27/300], Train Loss: 0.002589
Validation Loss: 0.00264490
Epoch [28/300], Train Loss: 0.002561
Validation Loss: 0.00244471
Epoch [29/300], Train Loss: 0.002594
Validation Loss: 0.00246617
Epoch [30/300], Train Loss: 0.002553
Validation Loss: 0.00324173
Epoch [31/300], Train Loss: 0.002508
Validation Loss: 0.00315986
Epoch [32/300], Train Loss: 0.002552
Validation Loss: 0.00321258
Epoch [33/300], Train Loss: 0.002519
Validation Loss: 0.00310277
Early stopping triggered

Evaluating model for: Dryer
Run 60/72 completed in 318.36 seconds with: {'MAE': np.float32(12.733362), 'MSE': np.float32(3926.4043), 'RMSE': np.float32(62.661026), 'SAE': np.float32(0.023363663), 'NDE': np.float32(0.4533508)}

Run 61/72: hidden=512, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Dryer
Dataset length: 1514 windows

Epoch [1/300], Train Loss: 0.010207
Validation Loss: 0.00833667
Epoch [2/300], Train Loss: 0.010018
Validation Loss: 0.00817908
Epoch [3/300], Train Loss: 0.009563
Validation Loss: 0.00807958
Epoch [4/300], Train Loss: 0.009659
Validation Loss: 0.00783478
Epoch [5/300], Train Loss: 0.009708
Validation Loss: 0.00712975
Epoch [6/300], Train Loss: 0.007282
Validation Loss: 0.00359870
Epoch [7/300], Train Loss: 0.005053
Validation Loss: 0.00384592
Epoch [8/300], Train Loss: 0.004534
Validation Loss: 0.00259000
Epoch [9/300], Train Loss: 0.003206
Validation Loss: 0.00164869
Epoch [10/300], Train Loss: 0.003077
Validation Loss: 0.00152102
Epoch [11/300], Train Loss: 0.002967
Validation Loss: 0.00145868
Epoch [12/300], Train Loss: 0.002769
Validation Loss: 0.00126511
Epoch [13/300], Train Loss: 0.002513
Validation Loss: 0.00136182
Epoch [14/300], Train Loss: 0.002439
Validation Loss: 0.00123498
Epoch [15/300], Train Loss: 0.002274
Validation Loss: 0.00121122
Epoch [16/300], Train Loss: 0.002323
Validation Loss: 0.00121691
Epoch [17/300], Train Loss: 0.002209
Validation Loss: 0.00120085
Epoch [18/300], Train Loss: 0.002067
Validation Loss: 0.00120129
Epoch [19/300], Train Loss: 0.002019
Validation Loss: 0.00116602
Epoch [20/300], Train Loss: 0.002075
Validation Loss: 0.00111622
Epoch [21/300], Train Loss: 0.002132
Validation Loss: 0.00112471
Epoch [22/300], Train Loss: 0.002009
Validation Loss: 0.00106348
Epoch [23/300], Train Loss: 0.001921
Validation Loss: 0.00104753
Epoch [24/300], Train Loss: 0.001813
Validation Loss: 0.00100419
Epoch [25/300], Train Loss: 0.001794
Validation Loss: 0.00135771
Epoch [26/300], Train Loss: 0.002008
Validation Loss: 0.00112696
Epoch [27/300], Train Loss: 0.002202
Validation Loss: 0.00111029
Epoch [28/300], Train Loss: 0.002153
Validation Loss: 0.00109617
Epoch [29/300], Train Loss: 0.001636
Validation Loss: 0.00093828
Epoch [30/300], Train Loss: 0.001519
Validation Loss: 0.00100648
Epoch [31/300], Train Loss: 0.001570
Validation Loss: 0.00095435
Epoch [32/300], Train Loss: 0.001534
Validation Loss: 0.00097976
Epoch [33/300], Train Loss: 0.001570
Validation Loss: 0.00088567
Epoch [34/300], Train Loss: 0.001517
Validation Loss: 0.00100364
Epoch [35/300], Train Loss: 0.001457
Validation Loss: 0.00090848
Epoch [36/300], Train Loss: 0.001424
Validation Loss: 0.00099614
Epoch [37/300], Train Loss: 0.001457
Validation Loss: 0.00087294
Epoch [38/300], Train Loss: 0.001373
Validation Loss: 0.00093713
Epoch [39/300], Train Loss: 0.001453
Validation Loss: 0.00081833
Epoch [40/300], Train Loss: 0.001826
Validation Loss: 0.00111185
Epoch [41/300], Train Loss: 0.002373
Validation Loss: 0.00254987
Epoch [42/300], Train Loss: 0.003210
Validation Loss: 0.00162608
Epoch [43/300], Train Loss: 0.002397
Validation Loss: 0.00125939
Epoch [44/300], Train Loss: 0.002146
Validation Loss: 0.00115729
Epoch [45/300], Train Loss: 0.002127
Validation Loss: 0.00113221
Epoch [46/300], Train Loss: 0.002181
Validation Loss: 0.00110705
Epoch [47/300], Train Loss: 0.002033
Validation Loss: 0.00111173
Epoch [48/300], Train Loss: 0.002328
Validation Loss: 0.00109044
Epoch [49/300], Train Loss: 0.002088
Validation Loss: 0.00111358
Early stopping triggered

Evaluating model for: Dryer
Run 61/72 completed in 122.36 seconds with: {'MAE': np.float32(10.7513), 'MSE': np.float32(2851.1396), 'RMSE': np.float32(53.396065), 'SAE': np.float32(0.067731015), 'NDE': np.float32(0.36260185)}

Run 62/72: hidden=512, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Dryer
Dataset length: 1514 windows

Epoch [1/300], Train Loss: 0.010193
Validation Loss: 0.00830496
Epoch [2/300], Train Loss: 0.010090
Validation Loss: 0.00826984
Epoch [3/300], Train Loss: 0.009690
Validation Loss: 0.00824610
Epoch [4/300], Train Loss: 0.009922
Validation Loss: 0.00814502
Epoch [5/300], Train Loss: 0.010254
Validation Loss: 0.00779530
Epoch [6/300], Train Loss: 0.008752
Validation Loss: 0.00592769
Epoch [7/300], Train Loss: 0.006132
Validation Loss: 0.00403505
Epoch [8/300], Train Loss: 0.005130
Validation Loss: 0.00316112
Epoch [9/300], Train Loss: 0.003949
Validation Loss: 0.00339437
Epoch [10/300], Train Loss: 0.003815
Validation Loss: 0.00244383
Epoch [11/300], Train Loss: 0.003515
Validation Loss: 0.00230770
Epoch [12/300], Train Loss: 0.002930
Validation Loss: 0.00182459
Epoch [13/300], Train Loss: 0.002674
Validation Loss: 0.00208962
Epoch [14/300], Train Loss: 0.002655
Validation Loss: 0.00359125
Epoch [15/300], Train Loss: 0.002565
Validation Loss: 0.00293941
Epoch [16/300], Train Loss: 0.002589
Validation Loss: 0.00192924
Epoch [17/300], Train Loss: 0.002432
Validation Loss: 0.00290854
Epoch [18/300], Train Loss: 0.002452
Validation Loss: 0.00295865
Epoch [19/300], Train Loss: 0.002360
Validation Loss: 0.00413042
Epoch [20/300], Train Loss: 0.002391
Validation Loss: 0.00290828
Epoch [21/300], Train Loss: 0.002206
Validation Loss: 0.00279790
Epoch [22/300], Train Loss: 0.002277
Validation Loss: 0.00271746
Early stopping triggered

Evaluating model for: Dryer
Run 62/72 completed in 71.68 seconds with: {'MAE': np.float32(12.536589), 'MSE': np.float32(6560.2656), 'RMSE': np.float32(80.99547), 'SAE': np.float32(0.26231998), 'NDE': np.float32(0.5500247)}

Run 63/72: hidden=512, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Dryer
Dataset length: 1514 windows

Epoch [1/300], Train Loss: 0.010643
Validation Loss: 0.00856771
Epoch [2/300], Train Loss: 0.010192
Validation Loss: 0.00831124
Epoch [3/300], Train Loss: 0.009744
Validation Loss: 0.00829559
Epoch [4/300], Train Loss: 0.010008
Validation Loss: 0.00829817
Epoch [5/300], Train Loss: 0.010527
Validation Loss: 0.00822306
Epoch [6/300], Train Loss: 0.010141
Validation Loss: 0.00792361
Epoch [7/300], Train Loss: 0.007824
Validation Loss: 0.00307252
Epoch [8/300], Train Loss: 0.004758
Validation Loss: 0.00243308
Epoch [9/300], Train Loss: 0.002985
Validation Loss: 0.00203375
Epoch [10/300], Train Loss: 0.003205
Validation Loss: 0.00175468
Epoch [11/300], Train Loss: 0.003021
Validation Loss: 0.00182003
Epoch [12/300], Train Loss: 0.002765
Validation Loss: 0.00163612
Epoch [13/300], Train Loss: 0.002688
Validation Loss: 0.00166262
Epoch [14/300], Train Loss: 0.002633
Validation Loss: 0.00155042
Epoch [15/300], Train Loss: 0.002491
Validation Loss: 0.00160471
Epoch [16/300], Train Loss: 0.002565
Validation Loss: 0.00145858
Epoch [17/300], Train Loss: 0.002449
Validation Loss: 0.00145295
Epoch [18/300], Train Loss: 0.002237
Validation Loss: 0.00129255
Epoch [19/300], Train Loss: 0.002115
Validation Loss: 0.00127702
Epoch [20/300], Train Loss: 0.002049
Validation Loss: 0.00129943
Epoch [21/300], Train Loss: 0.002111
Validation Loss: 0.00122086
Epoch [22/300], Train Loss: 0.002178
Validation Loss: 0.00117081
Epoch [23/300], Train Loss: 0.001872
Validation Loss: 0.00113064
Epoch [24/300], Train Loss: 0.001846
Validation Loss: 0.00115088
Epoch [25/300], Train Loss: 0.001736
Validation Loss: 0.00125668
Epoch [26/300], Train Loss: 0.001867
Validation Loss: 0.00114999
Epoch [27/300], Train Loss: 0.001610
Validation Loss: 0.00100905
Epoch [28/300], Train Loss: 0.001695
Validation Loss: 0.00097044
Epoch [29/300], Train Loss: 0.001407
Validation Loss: 0.00093425
Epoch [30/300], Train Loss: 0.001328
Validation Loss: 0.00098298
Epoch [31/300], Train Loss: 0.001381
Validation Loss: 0.00099311
Epoch [32/300], Train Loss: 0.001264
Validation Loss: 0.00091277
Epoch [33/300], Train Loss: 0.001239
Validation Loss: 0.00088691
Epoch [34/300], Train Loss: 0.001230
Validation Loss: 0.00078991
Epoch [35/300], Train Loss: 0.001651
Validation Loss: 0.00110570
Epoch [36/300], Train Loss: 0.001412
Validation Loss: 0.00074864
Epoch [37/300], Train Loss: 0.001334
Validation Loss: 0.00094453
Epoch [38/300], Train Loss: 0.001139
Validation Loss: 0.00069098
Epoch [39/300], Train Loss: 0.001105
Validation Loss: 0.00072157
Epoch [40/300], Train Loss: 0.001074
Validation Loss: 0.00065316
Epoch [41/300], Train Loss: 0.001013
Validation Loss: 0.00071743
Epoch [42/300], Train Loss: 0.000923
Validation Loss: 0.00062034
Epoch [43/300], Train Loss: 0.000909
Validation Loss: 0.00063366
Epoch [44/300], Train Loss: 0.000829
Validation Loss: 0.00058432
Epoch [45/300], Train Loss: 0.000808
Validation Loss: 0.00067175
Epoch [46/300], Train Loss: 0.000856
Validation Loss: 0.00055945
Epoch [47/300], Train Loss: 0.000814
Validation Loss: 0.00061164
Epoch [48/300], Train Loss: 0.000868
Validation Loss: 0.00054803
Epoch [49/300], Train Loss: 0.000891
Validation Loss: 0.00054204
Epoch [50/300], Train Loss: 0.001046
Validation Loss: 0.00056994
Epoch [51/300], Train Loss: 0.000971
Validation Loss: 0.00057538
Epoch [52/300], Train Loss: 0.000776
Validation Loss: 0.00054457
Epoch [53/300], Train Loss: 0.000835
Validation Loss: 0.00052457
Epoch [54/300], Train Loss: 0.000844
Validation Loss: 0.00050178
Epoch [55/300], Train Loss: 0.000845
Validation Loss: 0.00063240
Epoch [56/300], Train Loss: 0.000817
Validation Loss: 0.00053587
Epoch [57/300], Train Loss: 0.000720
Validation Loss: 0.00051032
Epoch [58/300], Train Loss: 0.000693
Validation Loss: 0.00051239
Epoch [59/300], Train Loss: 0.000687
Validation Loss: 0.00051191
Epoch [60/300], Train Loss: 0.000684
Validation Loss: 0.00051835
Epoch [61/300], Train Loss: 0.000783
Validation Loss: 0.00053303
Epoch [62/300], Train Loss: 0.000784
Validation Loss: 0.00047062
Epoch [63/300], Train Loss: 0.000738
Validation Loss: 0.00048717
Epoch [64/300], Train Loss: 0.000633
Validation Loss: 0.00049178
Epoch [65/300], Train Loss: 0.000642
Validation Loss: 0.00046659
Epoch [66/300], Train Loss: 0.000630
Validation Loss: 0.00046585
Epoch [67/300], Train Loss: 0.000706
Validation Loss: 0.00046879
Epoch [68/300], Train Loss: 0.000660
Validation Loss: 0.00047114
Epoch [69/300], Train Loss: 0.000639
Validation Loss: 0.00046648
Epoch [70/300], Train Loss: 0.000635
Validation Loss: 0.00045901
Epoch [71/300], Train Loss: 0.000683
Validation Loss: 0.00049135
Epoch [72/300], Train Loss: 0.000664
Validation Loss: 0.00048261
Epoch [73/300], Train Loss: 0.000640
Validation Loss: 0.00054190
Epoch [74/300], Train Loss: 0.000626
Validation Loss: 0.00048127
Epoch [75/300], Train Loss: 0.000648
Validation Loss: 0.00052591
Epoch [76/300], Train Loss: 0.000698
Validation Loss: 0.00045321
Epoch [77/300], Train Loss: 0.000588
Validation Loss: 0.00045377
Epoch [78/300], Train Loss: 0.000600
Validation Loss: 0.00045924
Epoch [79/300], Train Loss: 0.000579
Validation Loss: 0.00045453
Epoch [80/300], Train Loss: 0.000583
Validation Loss: 0.00046725
Epoch [81/300], Train Loss: 0.000576
Validation Loss: 0.00045182
Epoch [82/300], Train Loss: 0.000592
Validation Loss: 0.00049395
Epoch [83/300], Train Loss: 0.000628
Validation Loss: 0.00046166
Epoch [84/300], Train Loss: 0.000585
Validation Loss: 0.00046557
Epoch [85/300], Train Loss: 0.002127
Validation Loss: 0.00159542
Epoch [86/300], Train Loss: 0.002971
Validation Loss: 0.00125632
Epoch [87/300], Train Loss: 0.002245
Validation Loss: 0.00117702
Epoch [88/300], Train Loss: 0.001825
Validation Loss: 0.00090872
Epoch [89/300], Train Loss: 0.001266
Validation Loss: 0.00072882
Epoch [90/300], Train Loss: 0.001119
Validation Loss: 0.00069535
Epoch [91/300], Train Loss: 0.001095
Validation Loss: 0.00063371
Early stopping triggered

Evaluating model for: Dryer
Run 63/72 completed in 349.20 seconds with: {'MAE': np.float32(6.8445725), 'MSE': np.float32(1515.0537), 'RMSE': np.float32(38.92369), 'SAE': np.float32(0.06543415), 'NDE': np.float32(0.2643229)}

Run 64/72: hidden=512, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Dryer
Dataset length: 1514 windows

Epoch [1/300], Train Loss: 0.010241
Validation Loss: 0.00835436
Epoch [2/300], Train Loss: 0.010112
Validation Loss: 0.00831469
Epoch [3/300], Train Loss: 0.009746
Validation Loss: 0.00832851
Epoch [4/300], Train Loss: 0.010029
Validation Loss: 0.00830401
Epoch [5/300], Train Loss: 0.010599
Validation Loss: 0.00829987
Epoch [6/300], Train Loss: 0.010419
Validation Loss: 0.00821904
Epoch [7/300], Train Loss: 0.009897
Validation Loss: 0.00645850
Epoch [8/300], Train Loss: 0.004576
Validation Loss: 0.00203274
Epoch [9/300], Train Loss: 0.002996
Validation Loss: 0.00221678
Epoch [10/300], Train Loss: 0.003248
Validation Loss: 0.00166202
Epoch [11/300], Train Loss: 0.003020
Validation Loss: 0.00156532
Epoch [12/300], Train Loss: 0.002694
Validation Loss: 0.00161346
Epoch [13/300], Train Loss: 0.002586
Validation Loss: 0.00152113
Epoch [14/300], Train Loss: 0.002539
Validation Loss: 0.00151781
Epoch [15/300], Train Loss: 0.002357
Validation Loss: 0.00164473
Epoch [16/300], Train Loss: 0.002534
Validation Loss: 0.00138831
Epoch [17/300], Train Loss: 0.002369
Validation Loss: 0.00145610
Epoch [18/300], Train Loss: 0.002326
Validation Loss: 0.00129215
Epoch [19/300], Train Loss: 0.002208
Validation Loss: 0.00128402
Epoch [20/300], Train Loss: 0.002252
Validation Loss: 0.00127614
Epoch [21/300], Train Loss: 0.002243
Validation Loss: 0.00131136
Epoch [22/300], Train Loss: 0.002408
Validation Loss: 0.00121011
Epoch [23/300], Train Loss: 0.002079
Validation Loss: 0.00117778
Epoch [24/300], Train Loss: 0.002219
Validation Loss: 0.00123380
Epoch [25/300], Train Loss: 0.002070
Validation Loss: 0.00115472
Epoch [26/300], Train Loss: 0.002099
Validation Loss: 0.00115252
Epoch [27/300], Train Loss: 0.001669
Validation Loss: 0.00108660
Epoch [28/300], Train Loss: 0.001731
Validation Loss: 0.00107443
Epoch [29/300], Train Loss: 0.001451
Validation Loss: 0.00109978
Epoch [30/300], Train Loss: 0.001377
Validation Loss: 0.00098923
Epoch [31/300], Train Loss: 0.001432
Validation Loss: 0.00109142
Epoch [32/300], Train Loss: 0.001434
Validation Loss: 0.00096132
Epoch [33/300], Train Loss: 0.001586
Validation Loss: 0.00093361
Epoch [34/300], Train Loss: 0.001609
Validation Loss: 0.00079297
Epoch [35/300], Train Loss: 0.001228
Validation Loss: 0.00088566
Epoch [36/300], Train Loss: 0.001285
Validation Loss: 0.00085643
Epoch [37/300], Train Loss: 0.001217
Validation Loss: 0.00078660
Epoch [38/300], Train Loss: 0.001053
Validation Loss: 0.00072871
Epoch [39/300], Train Loss: 0.001083
Validation Loss: 0.00070697
Epoch [40/300], Train Loss: 0.001005
Validation Loss: 0.00058915
Epoch [41/300], Train Loss: 0.000997
Validation Loss: 0.00056668
Epoch [42/300], Train Loss: 0.000871
Validation Loss: 0.00056546
Epoch [43/300], Train Loss: 0.000824
Validation Loss: 0.00051201
Epoch [44/300], Train Loss: 0.000776
Validation Loss: 0.00052932
Epoch [45/300], Train Loss: 0.000822
Validation Loss: 0.00051367
Epoch [46/300], Train Loss: 0.000790
Validation Loss: 0.00051825
Epoch [47/300], Train Loss: 0.000792
Validation Loss: 0.00056883
Epoch [48/300], Train Loss: 0.000876
Validation Loss: 0.00055285
Epoch [49/300], Train Loss: 0.000868
Validation Loss: 0.00052215
Epoch [50/300], Train Loss: 0.000749
Validation Loss: 0.00048201
Epoch [51/300], Train Loss: 0.000777
Validation Loss: 0.00047748
Epoch [52/300], Train Loss: 0.000746
Validation Loss: 0.00048305
Epoch [53/300], Train Loss: 0.000819
Validation Loss: 0.00046490
Epoch [54/300], Train Loss: 0.000721
Validation Loss: 0.00046788
Epoch [55/300], Train Loss: 0.000749
Validation Loss: 0.00048500
Epoch [56/300], Train Loss: 0.000737
Validation Loss: 0.00045264
Epoch [57/300], Train Loss: 0.000673
Validation Loss: 0.00044881
Epoch [58/300], Train Loss: 0.000649
Validation Loss: 0.00043736
Epoch [59/300], Train Loss: 0.000669
Validation Loss: 0.00044861
Epoch [60/300], Train Loss: 0.000683
Validation Loss: 0.00042779
Epoch [61/300], Train Loss: 0.000690
Validation Loss: 0.00043937
Epoch [62/300], Train Loss: 0.000656
Validation Loss: 0.00042140
Epoch [63/300], Train Loss: 0.000657
Validation Loss: 0.00042319
Epoch [64/300], Train Loss: 0.000595
Validation Loss: 0.00044536
Epoch [65/300], Train Loss: 0.000603
Validation Loss: 0.00043828
Epoch [66/300], Train Loss: 0.000596
Validation Loss: 0.00041137
Epoch [67/300], Train Loss: 0.000630
Validation Loss: 0.00041485
Epoch [68/300], Train Loss: 0.000650
Validation Loss: 0.00041187
Epoch [69/300], Train Loss: 0.000662
Validation Loss: 0.00040347
Epoch [70/300], Train Loss: 0.000612
Validation Loss: 0.00041356
Epoch [71/300], Train Loss: 0.000651
Validation Loss: 0.00042207
Epoch [72/300], Train Loss: 0.000610
Validation Loss: 0.00043045
Epoch [73/300], Train Loss: 0.000728
Validation Loss: 0.00040718
Epoch [74/300], Train Loss: 0.000653
Validation Loss: 0.00039633
Epoch [75/300], Train Loss: 0.000631
Validation Loss: 0.00040287
Epoch [76/300], Train Loss: 0.000744
Validation Loss: 0.00039750
Epoch [77/300], Train Loss: 0.000570
Validation Loss: 0.00040728
Epoch [78/300], Train Loss: 0.000570
Validation Loss: 0.00040394
Epoch [79/300], Train Loss: 0.000534
Validation Loss: 0.00039297
Epoch [80/300], Train Loss: 0.000543
Validation Loss: 0.00040563
Epoch [81/300], Train Loss: 0.000665
Validation Loss: 0.00042320
Epoch [82/300], Train Loss: 0.000739
Validation Loss: 0.00043967
Epoch [83/300], Train Loss: 0.000566
Validation Loss: 0.00040233
Epoch [84/300], Train Loss: 0.000558
Validation Loss: 0.00039632
Epoch [85/300], Train Loss: 0.000630
Validation Loss: 0.00038599
Epoch [86/300], Train Loss: 0.000602
Validation Loss: 0.00037909
Epoch [87/300], Train Loss: 0.000613
Validation Loss: 0.00037324
Epoch [88/300], Train Loss: 0.000547
Validation Loss: 0.00049526
Epoch [89/300], Train Loss: 0.000589
Validation Loss: 0.00036556
Epoch [90/300], Train Loss: 0.000556
Validation Loss: 0.00038352
Epoch [91/300], Train Loss: 0.000629
Validation Loss: 0.00036152
Epoch [92/300], Train Loss: 0.000517
Validation Loss: 0.00036994
Epoch [93/300], Train Loss: 0.000520
Validation Loss: 0.00036288
Epoch [94/300], Train Loss: 0.000603
Validation Loss: 0.00035915
Epoch [95/300], Train Loss: 0.000592
Validation Loss: 0.00037399
Epoch [96/300], Train Loss: 0.000514
Validation Loss: 0.00035972
Epoch [97/300], Train Loss: 0.000499
Validation Loss: 0.00035653
Epoch [98/300], Train Loss: 0.000522
Validation Loss: 0.00036066
Epoch [99/300], Train Loss: 0.000499
Validation Loss: 0.00035344
Epoch [100/300], Train Loss: 0.000551
Validation Loss: 0.00035797
Epoch [101/300], Train Loss: 0.000487
Validation Loss: 0.00035414
Epoch [102/300], Train Loss: 0.000493
Validation Loss: 0.00035563
Epoch [103/300], Train Loss: 0.000522
Validation Loss: 0.00035397
Epoch [104/300], Train Loss: 0.000560
Validation Loss: 0.00035035
Epoch [105/300], Train Loss: 0.000479
Validation Loss: 0.00037472
Epoch [106/300], Train Loss: 0.000608
Validation Loss: 0.00036432
Epoch [107/300], Train Loss: 0.000516
Validation Loss: 0.00034997
Epoch [108/300], Train Loss: 0.000490
Validation Loss: 0.00035801
Epoch [109/300], Train Loss: 0.000464
Validation Loss: 0.00034673
Epoch [110/300], Train Loss: 0.000545
Validation Loss: 0.00048480
Epoch [111/300], Train Loss: 0.000639
Validation Loss: 0.00036614
Epoch [112/300], Train Loss: 0.000551
Validation Loss: 0.00035262
Epoch [113/300], Train Loss: 0.000518
Validation Loss: 0.00034836
Epoch [114/300], Train Loss: 0.000505
Validation Loss: 0.00035762
Epoch [115/300], Train Loss: 0.000553
Validation Loss: 0.00033629
Epoch [116/300], Train Loss: 0.000540
Validation Loss: 0.00033515
Epoch [117/300], Train Loss: 0.000509
Validation Loss: 0.00033467
Epoch [118/300], Train Loss: 0.000538
Validation Loss: 0.00033629
Epoch [119/300], Train Loss: 0.000470
Validation Loss: 0.00033472
Epoch [120/300], Train Loss: 0.000487
Validation Loss: 0.00033338
Epoch [121/300], Train Loss: 0.000489
Validation Loss: 0.00034509
Epoch [122/300], Train Loss: 0.000532
Validation Loss: 0.00032884
Epoch [123/300], Train Loss: 0.000494
Validation Loss: 0.00032898
Epoch [124/300], Train Loss: 0.000464
Validation Loss: 0.00032997
Epoch [125/300], Train Loss: 0.000477
Validation Loss: 0.00032732
Epoch [126/300], Train Loss: 0.000454
Validation Loss: 0.00032620
Epoch [127/300], Train Loss: 0.000454
Validation Loss: 0.00032843
Epoch [128/300], Train Loss: 0.000483
Validation Loss: 0.00032831
Epoch [129/300], Train Loss: 0.000480
Validation Loss: 0.00032512
Epoch [130/300], Train Loss: 0.000520
Validation Loss: 0.00032337
Epoch [131/300], Train Loss: 0.000503
Validation Loss: 0.00034792
Epoch [132/300], Train Loss: 0.000469
Validation Loss: 0.00032382
Epoch [133/300], Train Loss: 0.000463
Validation Loss: 0.00032128
Epoch [134/300], Train Loss: 0.000485
Validation Loss: 0.00032827
Epoch [135/300], Train Loss: 0.000450
Validation Loss: 0.00031989
Epoch [136/300], Train Loss: 0.000482
Validation Loss: 0.00032214
Epoch [137/300], Train Loss: 0.000443
Validation Loss: 0.00032334
Epoch [138/300], Train Loss: 0.000476
Validation Loss: 0.00031607
Epoch [139/300], Train Loss: 0.000445
Validation Loss: 0.00033201
Epoch [140/300], Train Loss: 0.000459
Validation Loss: 0.00031567
Epoch [141/300], Train Loss: 0.000483
Validation Loss: 0.00033514
Epoch [142/300], Train Loss: 0.000471
Validation Loss: 0.00031290
Epoch [143/300], Train Loss: 0.000518
Validation Loss: 0.00031230
Epoch [144/300], Train Loss: 0.000433
Validation Loss: 0.00031650
Epoch [145/300], Train Loss: 0.000458
Validation Loss: 0.00031235
Epoch [146/300], Train Loss: 0.000443
Validation Loss: 0.00031063
Epoch [147/300], Train Loss: 0.000453
Validation Loss: 0.00031935
Epoch [148/300], Train Loss: 0.000462
Validation Loss: 0.00031139
Epoch [149/300], Train Loss: 0.000467
Validation Loss: 0.00030760
Epoch [150/300], Train Loss: 0.000459
Validation Loss: 0.00032044
Epoch [151/300], Train Loss: 0.000437
Validation Loss: 0.00030525
Epoch [152/300], Train Loss: 0.000462
Validation Loss: 0.00031624
Epoch [153/300], Train Loss: 0.000425
Validation Loss: 0.00030673
Epoch [154/300], Train Loss: 0.000446
Validation Loss: 0.00031403
Epoch [155/300], Train Loss: 0.000444
Validation Loss: 0.00030817
Epoch [156/300], Train Loss: 0.000425
Validation Loss: 0.00031004
Epoch [157/300], Train Loss: 0.000439
Validation Loss: 0.00030013
Epoch [158/300], Train Loss: 0.000433
Validation Loss: 0.00030414
Epoch [159/300], Train Loss: 0.000450
Validation Loss: 0.00030233
Epoch [160/300], Train Loss: 0.000436
Validation Loss: 0.00029832
Epoch [161/300], Train Loss: 0.000472
Validation Loss: 0.00031618
Epoch [162/300], Train Loss: 0.000436
Validation Loss: 0.00029707
Epoch [163/300], Train Loss: 0.000406
Validation Loss: 0.00030146
Epoch [164/300], Train Loss: 0.000406
Validation Loss: 0.00029954
Epoch [165/300], Train Loss: 0.000419
Validation Loss: 0.00029766
Epoch [166/300], Train Loss: 0.000401
Validation Loss: 0.00029753
Epoch [167/300], Train Loss: 0.000412
Validation Loss: 0.00029075
Epoch [168/300], Train Loss: 0.000420
Validation Loss: 0.00029288
Epoch [169/300], Train Loss: 0.000409
Validation Loss: 0.00029006
Epoch [170/300], Train Loss: 0.000388
Validation Loss: 0.00029628
Epoch [171/300], Train Loss: 0.000400
Validation Loss: 0.00028903
Epoch [172/300], Train Loss: 0.000425
Validation Loss: 0.00029140
Epoch [173/300], Train Loss: 0.000385
Validation Loss: 0.00028946
Epoch [174/300], Train Loss: 0.000413
Validation Loss: 0.00028824
Epoch [175/300], Train Loss: 0.000408
Validation Loss: 0.00029506
Epoch [176/300], Train Loss: 0.000406
Validation Loss: 0.00028805
Epoch [177/300], Train Loss: 0.000408
Validation Loss: 0.00028561
Epoch [178/300], Train Loss: 0.000397
Validation Loss: 0.00029114
Epoch [179/300], Train Loss: 0.000393
Validation Loss: 0.00028334
Epoch [180/300], Train Loss: 0.000417
Validation Loss: 0.00028727
Epoch [181/300], Train Loss: 0.000409
Validation Loss: 0.00028003
Epoch [182/300], Train Loss: 0.000402
Validation Loss: 0.00029510
Epoch [183/300], Train Loss: 0.000407
Validation Loss: 0.00028279
Epoch [184/300], Train Loss: 0.000406
Validation Loss: 0.00028092
Epoch [185/300], Train Loss: 0.000383
Validation Loss: 0.00029341
Epoch [186/300], Train Loss: 0.000375
Validation Loss: 0.00027587
Epoch [187/300], Train Loss: 0.000414
Validation Loss: 0.00028110
Epoch [188/300], Train Loss: 0.000397
Validation Loss: 0.00028894
Epoch [189/300], Train Loss: 0.000379
Validation Loss: 0.00027667
Epoch [190/300], Train Loss: 0.000416
Validation Loss: 0.00028918
Epoch [191/300], Train Loss: 0.000376
Validation Loss: 0.00027645
Epoch [192/300], Train Loss: 0.000381
Validation Loss: 0.00027973
Epoch [193/300], Train Loss: 0.000367
Validation Loss: 0.00027810
Epoch [194/300], Train Loss: 0.000378
Validation Loss: 0.00027330
Epoch [195/300], Train Loss: 0.000371
Validation Loss: 0.00028030
Epoch [196/300], Train Loss: 0.000375
Validation Loss: 0.00027158
Epoch [197/300], Train Loss: 0.000390
Validation Loss: 0.00027018
Epoch [198/300], Train Loss: 0.000359
Validation Loss: 0.00028048
Epoch [199/300], Train Loss: 0.000387
Validation Loss: 0.00027073
Epoch [200/300], Train Loss: 0.000361
Validation Loss: 0.00027678
Epoch [201/300], Train Loss: 0.000361
Validation Loss: 0.00027427
Epoch [202/300], Train Loss: 0.000361
Validation Loss: 0.00026707
Epoch [203/300], Train Loss: 0.000356
Validation Loss: 0.00028302
Epoch [204/300], Train Loss: 0.000400
Validation Loss: 0.00026596
Epoch [205/300], Train Loss: 0.000391
Validation Loss: 0.00026989
Epoch [206/300], Train Loss: 0.000355
Validation Loss: 0.00027854
Epoch [207/300], Train Loss: 0.000364
Validation Loss: 0.00026777
Epoch [208/300], Train Loss: 0.000348
Validation Loss: 0.00027287
Epoch [209/300], Train Loss: 0.000348
Validation Loss: 0.00027544
Epoch [210/300], Train Loss: 0.000390
Validation Loss: 0.00026385
Epoch [211/300], Train Loss: 0.000363
Validation Loss: 0.00027871
Epoch [212/300], Train Loss: 0.000386
Validation Loss: 0.00026463
Epoch [213/300], Train Loss: 0.000352
Validation Loss: 0.00027173
Epoch [214/300], Train Loss: 0.000352
Validation Loss: 0.00026689
Epoch [215/300], Train Loss: 0.000359
Validation Loss: 0.00026443
Epoch [216/300], Train Loss: 0.000357
Validation Loss: 0.00026526
Epoch [217/300], Train Loss: 0.000330
Validation Loss: 0.00026840
Epoch [218/300], Train Loss: 0.000327
Validation Loss: 0.00026126
Epoch [219/300], Train Loss: 0.000328
Validation Loss: 0.00026711
Epoch [220/300], Train Loss: 0.000324
Validation Loss: 0.00025852
Epoch [221/300], Train Loss: 0.000330
Validation Loss: 0.00027405
Epoch [222/300], Train Loss: 0.000348
Validation Loss: 0.00025634
Epoch [223/300], Train Loss: 0.000383
Validation Loss: 0.00026976
Epoch [224/300], Train Loss: 0.000339
Validation Loss: 0.00025872
Epoch [225/300], Train Loss: 0.000341
Validation Loss: 0.00028078
Epoch [226/300], Train Loss: 0.000369
Validation Loss: 0.00026023
Epoch [227/300], Train Loss: 0.000352
Validation Loss: 0.00026674
Epoch [228/300], Train Loss: 0.000346
Validation Loss: 0.00025707
Epoch [229/300], Train Loss: 0.000316
Validation Loss: 0.00026439
Epoch [230/300], Train Loss: 0.000340
Validation Loss: 0.00025706
Epoch [231/300], Train Loss: 0.000335
Validation Loss: 0.00026652
Epoch [232/300], Train Loss: 0.000315
Validation Loss: 0.00025417
Epoch [233/300], Train Loss: 0.000377
Validation Loss: 0.00026958
Epoch [234/300], Train Loss: 0.000570
Validation Loss: 0.00028638
Epoch [235/300], Train Loss: 0.000449
Validation Loss: 0.00026519
Epoch [236/300], Train Loss: 0.000410
Validation Loss: 0.00025821
Epoch [237/300], Train Loss: 0.000417
Validation Loss: 0.00025573
Epoch [238/300], Train Loss: 0.000393
Validation Loss: 0.00025372
Epoch [239/300], Train Loss: 0.000391
Validation Loss: 0.00025285
Epoch [240/300], Train Loss: 0.000402
Validation Loss: 0.00025467
Epoch [241/300], Train Loss: 0.000358
Validation Loss: 0.00025213
Epoch [242/300], Train Loss: 0.000384
Validation Loss: 0.00025393
Epoch [243/300], Train Loss: 0.000364
Validation Loss: 0.00025362
Epoch [244/300], Train Loss: 0.000370
Validation Loss: 0.00025149
Epoch [245/300], Train Loss: 0.000357
Validation Loss: 0.00025173
Epoch [246/300], Train Loss: 0.000362
Validation Loss: 0.00025110
Epoch [247/300], Train Loss: 0.000350
Validation Loss: 0.00025091
Epoch [248/300], Train Loss: 0.000347
Validation Loss: 0.00025151
Epoch [249/300], Train Loss: 0.000362
Validation Loss: 0.00025177
Epoch [250/300], Train Loss: 0.000378
Validation Loss: 0.00025103
Epoch [251/300], Train Loss: 0.000430
Validation Loss: 0.00024921
Epoch [252/300], Train Loss: 0.000362
Validation Loss: 0.00026012
Epoch [253/300], Train Loss: 0.000375
Validation Loss: 0.00024873
Epoch [254/300], Train Loss: 0.000350
Validation Loss: 0.00025053
Epoch [255/300], Train Loss: 0.000347
Validation Loss: 0.00024711
Epoch [256/300], Train Loss: 0.000333
Validation Loss: 0.00024815
Epoch [257/300], Train Loss: 0.000342
Validation Loss: 0.00024569
Epoch [258/300], Train Loss: 0.000364
Validation Loss: 0.00026592
Epoch [259/300], Train Loss: 0.000376
Validation Loss: 0.00025452
Epoch [260/300], Train Loss: 0.000414
Validation Loss: 0.00025728
Epoch [261/300], Train Loss: 0.000339
Validation Loss: 0.00024933
Epoch [262/300], Train Loss: 0.000362
Validation Loss: 0.00025326
Epoch [263/300], Train Loss: 0.000352
Validation Loss: 0.00024831
Epoch [264/300], Train Loss: 0.000342
Validation Loss: 0.00024636
Epoch [265/300], Train Loss: 0.000326
Validation Loss: 0.00025368
Epoch [266/300], Train Loss: 0.000314
Validation Loss: 0.00024590
Epoch [267/300], Train Loss: 0.000362
Validation Loss: 0.00024928
Early stopping triggered

Evaluating model for: Dryer
Run 64/72 completed in 1313.02 seconds with: {'MAE': np.float32(3.224705), 'MSE': np.float32(441.48538), 'RMSE': np.float32(21.011553), 'SAE': np.float32(0.016546635), 'NDE': np.float32(0.14268519)}

Run 65/72: hidden=512, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Dryer
Dataset length: 1470 windows

Epoch [1/300], Train Loss: 0.011420
Validation Loss: 0.00816353
Epoch [2/300], Train Loss: 0.009818
Validation Loss: 0.00805536
Epoch [3/300], Train Loss: 0.009609
Validation Loss: 0.00792369
Epoch [4/300], Train Loss: 0.009648
Validation Loss: 0.00777784
Epoch [5/300], Train Loss: 0.009521
Validation Loss: 0.00744208
Epoch [6/300], Train Loss: 0.009167
Validation Loss: 0.00641875
Epoch [7/300], Train Loss: 0.007819
Validation Loss: 0.00569326
Epoch [8/300], Train Loss: 0.006090
Validation Loss: 0.00424927
Epoch [9/300], Train Loss: 0.004283
Validation Loss: 0.00217874
Epoch [10/300], Train Loss: 0.003142
Validation Loss: 0.00204620
Epoch [11/300], Train Loss: 0.003240
Validation Loss: 0.00184941
Epoch [12/300], Train Loss: 0.002742
Validation Loss: 0.00171162
Epoch [13/300], Train Loss: 0.002408
Validation Loss: 0.00146731
Epoch [14/300], Train Loss: 0.002289
Validation Loss: 0.00139749
Epoch [15/300], Train Loss: 0.002285
Validation Loss: 0.00128090
Epoch [16/300], Train Loss: 0.001918
Validation Loss: 0.00126033
Epoch [17/300], Train Loss: 0.001785
Validation Loss: 0.00128816
Epoch [18/300], Train Loss: 0.001734
Validation Loss: 0.00120114
Epoch [19/300], Train Loss: 0.001661
Validation Loss: 0.00116139
Epoch [20/300], Train Loss: 0.001586
Validation Loss: 0.00139382
Epoch [21/300], Train Loss: 0.001918
Validation Loss: 0.00108798
Epoch [22/300], Train Loss: 0.001708
Validation Loss: 0.00101226
Epoch [23/300], Train Loss: 0.001556
Validation Loss: 0.00100074
Epoch [24/300], Train Loss: 0.001382
Validation Loss: 0.00101107
Epoch [25/300], Train Loss: 0.001445
Validation Loss: 0.00108412
Epoch [26/300], Train Loss: 0.001461
Validation Loss: 0.00094402
Epoch [27/300], Train Loss: 0.001166
Validation Loss: 0.00107977
Epoch [28/300], Train Loss: 0.001249
Validation Loss: 0.00090018
Epoch [29/300], Train Loss: 0.001262
Validation Loss: 0.00099958
Epoch [30/300], Train Loss: 0.001786
Validation Loss: 0.00153639
Epoch [31/300], Train Loss: 0.002354
Validation Loss: 0.00132856
Epoch [32/300], Train Loss: 0.001960
Validation Loss: 0.00132909
Epoch [33/300], Train Loss: 0.002028
Validation Loss: 0.00154941
Epoch [34/300], Train Loss: 0.001932
Validation Loss: 0.00109241
Epoch [35/300], Train Loss: 0.001682
Validation Loss: 0.00110891
Epoch [36/300], Train Loss: 0.001596
Validation Loss: 0.00107562
Epoch [37/300], Train Loss: 0.001377
Validation Loss: 0.00092321
Epoch [38/300], Train Loss: 0.001243
Validation Loss: 0.00087144
Epoch [39/300], Train Loss: 0.001113
Validation Loss: 0.00079868
Epoch [40/300], Train Loss: 0.001146
Validation Loss: 0.00076012
Epoch [41/300], Train Loss: 0.001072
Validation Loss: 0.00077331
Epoch [42/300], Train Loss: 0.000874
Validation Loss: 0.00071352
Epoch [43/300], Train Loss: 0.000874
Validation Loss: 0.00066950
Epoch [44/300], Train Loss: 0.000822
Validation Loss: 0.00063726
Epoch [45/300], Train Loss: 0.000766
Validation Loss: 0.00063381
Epoch [46/300], Train Loss: 0.000786
Validation Loss: 0.00062675
Epoch [47/300], Train Loss: 0.000835
Validation Loss: 0.00064127
Epoch [48/300], Train Loss: 0.000751
Validation Loss: 0.00061085
Epoch [49/300], Train Loss: 0.000812
Validation Loss: 0.00059035
Epoch [50/300], Train Loss: 0.001126
Validation Loss: 0.00081075
Epoch [51/300], Train Loss: 0.000882
Validation Loss: 0.00064252
Epoch [52/300], Train Loss: 0.000821
Validation Loss: 0.00062820
Epoch [53/300], Train Loss: 0.000739
Validation Loss: 0.00060831
Epoch [54/300], Train Loss: 0.000715
Validation Loss: 0.00058609
Epoch [55/300], Train Loss: 0.000703
Validation Loss: 0.00058245
Epoch [56/300], Train Loss: 0.000784
Validation Loss: 0.00056941
Epoch [57/300], Train Loss: 0.000710
Validation Loss: 0.00056541
Epoch [58/300], Train Loss: 0.000901
Validation Loss: 0.00058977
Epoch [59/300], Train Loss: 0.000865
Validation Loss: 0.00063245
Epoch [60/300], Train Loss: 0.000746
Validation Loss: 0.00061939
Epoch [61/300], Train Loss: 0.000800
Validation Loss: 0.00056502
Epoch [62/300], Train Loss: 0.000677
Validation Loss: 0.00057123
Epoch [63/300], Train Loss: 0.000632
Validation Loss: 0.00056836
Epoch [64/300], Train Loss: 0.000699
Validation Loss: 0.00054809
Epoch [65/300], Train Loss: 0.000673
Validation Loss: 0.00054951
Epoch [66/300], Train Loss: 0.000641
Validation Loss: 0.00056282
Epoch [67/300], Train Loss: 0.000710
Validation Loss: 0.00053357
Epoch [68/300], Train Loss: 0.000635
Validation Loss: 0.00053480
Epoch [69/300], Train Loss: 0.000604
Validation Loss: 0.00054227
Epoch [70/300], Train Loss: 0.000602
Validation Loss: 0.00053078
Epoch [71/300], Train Loss: 0.000597
Validation Loss: 0.00052980
Epoch [72/300], Train Loss: 0.000666
Validation Loss: 0.00052833
Epoch [73/300], Train Loss: 0.000633
Validation Loss: 0.00052509
Epoch [74/300], Train Loss: 0.000636
Validation Loss: 0.00052074
Epoch [75/300], Train Loss: 0.000631
Validation Loss: 0.00051587
Epoch [76/300], Train Loss: 0.000631
Validation Loss: 0.00051216
Epoch [77/300], Train Loss: 0.000586
Validation Loss: 0.00051671
Epoch [78/300], Train Loss: 0.000634
Validation Loss: 0.00050879
Epoch [79/300], Train Loss: 0.000605
Validation Loss: 0.00050704
Epoch [80/300], Train Loss: 0.000607
Validation Loss: 0.00051133
Epoch [81/300], Train Loss: 0.000700
Validation Loss: 0.00050456
Epoch [82/300], Train Loss: 0.000678
Validation Loss: 0.00050092
Epoch [83/300], Train Loss: 0.000596
Validation Loss: 0.00049555
Epoch [84/300], Train Loss: 0.000562
Validation Loss: 0.00049592
Epoch [85/300], Train Loss: 0.000656
Validation Loss: 0.00050644
Epoch [86/300], Train Loss: 0.000693
Validation Loss: 0.00050399
Epoch [87/300], Train Loss: 0.000853
Validation Loss: 0.00284937
Epoch [88/300], Train Loss: 0.004296
Validation Loss: 0.00183685
Epoch [89/300], Train Loss: 0.002864
Validation Loss: 0.00180157
Epoch [90/300], Train Loss: 0.002041
Validation Loss: 0.00125657
Epoch [91/300], Train Loss: 0.001868
Validation Loss: 0.00114257
Epoch [92/300], Train Loss: 0.001548
Validation Loss: 0.00114060
Epoch [93/300], Train Loss: 0.001463
Validation Loss: 0.00108056
Early stopping triggered

Evaluating model for: Dryer
Run 65/72 completed in 331.49 seconds with: {'MAE': np.float32(6.974755), 'MSE': np.float32(2698.3948), 'RMSE': np.float32(51.946075), 'SAE': np.float32(0.07236695), 'NDE': np.float32(0.44281316)}

Run 66/72: hidden=512, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Dryer
Dataset length: 1470 windows

Epoch [1/300], Train Loss: 0.010716
Validation Loss: 0.00818269
Epoch [2/300], Train Loss: 0.009712
Validation Loss: 0.00803296
Epoch [3/300], Train Loss: 0.009640
Validation Loss: 0.00789289
Epoch [4/300], Train Loss: 0.009384
Validation Loss: 0.00716375
Epoch [5/300], Train Loss: 0.007525
Validation Loss: 0.00364004
Epoch [6/300], Train Loss: 0.005198
Validation Loss: 0.00445745
Epoch [7/300], Train Loss: 0.005570
Validation Loss: 0.00288021
Epoch [8/300], Train Loss: 0.003780
Validation Loss: 0.00230104
Epoch [9/300], Train Loss: 0.003786
Validation Loss: 0.00212239
Epoch [10/300], Train Loss: 0.003203
Validation Loss: 0.00175784
Epoch [11/300], Train Loss: 0.003413
Validation Loss: 0.00156478
Epoch [12/300], Train Loss: 0.002753
Validation Loss: 0.00157746
Epoch [13/300], Train Loss: 0.002383
Validation Loss: 0.00144168
Epoch [14/300], Train Loss: 0.002507
Validation Loss: 0.00137001
Epoch [15/300], Train Loss: 0.002455
Validation Loss: 0.00134952
Epoch [16/300], Train Loss: 0.002027
Validation Loss: 0.00137480
Epoch [17/300], Train Loss: 0.001877
Validation Loss: 0.00142964
Epoch [18/300], Train Loss: 0.001812
Validation Loss: 0.00128561
Epoch [19/300], Train Loss: 0.001732
Validation Loss: 0.00139978
Epoch [20/300], Train Loss: 0.001834
Validation Loss: 0.00123078
Epoch [21/300], Train Loss: 0.001648
Validation Loss: 0.00128447
Epoch [22/300], Train Loss: 0.001737
Validation Loss: 0.00145649
Epoch [23/300], Train Loss: 0.001722
Validation Loss: 0.00129652
Epoch [24/300], Train Loss: 0.001708
Validation Loss: 0.00110745
Epoch [25/300], Train Loss: 0.001724
Validation Loss: 0.00125863
Epoch [26/300], Train Loss: 0.001446
Validation Loss: 0.00503185
Epoch [27/300], Train Loss: 0.003969
Validation Loss: 0.00362010
Epoch [28/300], Train Loss: 0.003234
Validation Loss: 0.00378706
Epoch [29/300], Train Loss: 0.002306
Validation Loss: 0.00101674
Epoch [30/300], Train Loss: 0.001538
Validation Loss: 0.00122315
Epoch [31/300], Train Loss: 0.001763
Validation Loss: 0.00147141
Epoch [32/300], Train Loss: 0.004188
Validation Loss: 0.00142883
Epoch [33/300], Train Loss: 0.002981
Validation Loss: 0.00219851
Epoch [34/300], Train Loss: 0.003243
Validation Loss: 0.00137806
Epoch [35/300], Train Loss: 0.002324
Validation Loss: 0.00125886
Epoch [36/300], Train Loss: 0.002332
Validation Loss: 0.00119866
Epoch [37/300], Train Loss: 0.001884
Validation Loss: 0.00120370
Epoch [38/300], Train Loss: 0.001743
Validation Loss: 0.00117301
Epoch [39/300], Train Loss: 0.001617
Validation Loss: 0.00108817
Early stopping triggered

Evaluating model for: Dryer
Run 66/72 completed in 189.82 seconds with: {'MAE': np.float32(13.175412), 'MSE': np.float32(2278.1318), 'RMSE': np.float32(47.72978), 'SAE': np.float32(0.38459852), 'NDE': np.float32(0.40687197)}

Run 67/72: hidden=512, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Dryer
Dataset length: 1470 windows

Epoch [1/300], Train Loss: 0.011601
Validation Loss: 0.00827549
Epoch [2/300], Train Loss: 0.009935
Validation Loss: 0.00818089
Epoch [3/300], Train Loss: 0.009818
Validation Loss: 0.00815257
Epoch [4/300], Train Loss: 0.009991
Validation Loss: 0.00815694
Epoch [5/300], Train Loss: 0.010143
Validation Loss: 0.00815472
Epoch [6/300], Train Loss: 0.010416
Validation Loss: 0.00814607
Epoch [7/300], Train Loss: 0.010708
Validation Loss: 0.00812840
Epoch [8/300], Train Loss: 0.010636
Validation Loss: 0.00812173
Epoch [9/300], Train Loss: 0.009761
Validation Loss: 0.00797601
Epoch [10/300], Train Loss: 0.010334
Validation Loss: 0.00620503
Epoch [11/300], Train Loss: 0.008293
Validation Loss: 0.00391483
Epoch [12/300], Train Loss: 0.005254
Validation Loss: 0.00275252
Epoch [13/300], Train Loss: 0.004016
Validation Loss: 0.00291616
Epoch [14/300], Train Loss: 0.004033
Validation Loss: 0.00240835
Epoch [15/300], Train Loss: 0.003309
Validation Loss: 0.00197763
Epoch [16/300], Train Loss: 0.002950
Validation Loss: 0.00212184
Epoch [17/300], Train Loss: 0.002769
Validation Loss: 0.00189694
Epoch [18/300], Train Loss: 0.002601
Validation Loss: 0.00204884
Epoch [19/300], Train Loss: 0.002632
Validation Loss: 0.00191476
Epoch [20/300], Train Loss: 0.002920
Validation Loss: 0.00187045
Epoch [21/300], Train Loss: 0.002468
Validation Loss: 0.00198000
Epoch [22/300], Train Loss: 0.002699
Validation Loss: 0.00186792
Epoch [23/300], Train Loss: 0.002607
Validation Loss: 0.00175097
Epoch [24/300], Train Loss: 0.002658
Validation Loss: 0.00165993
Epoch [25/300], Train Loss: 0.002796
Validation Loss: 0.00156530
Epoch [26/300], Train Loss: 0.002363
Validation Loss: 0.00176046
Epoch [27/300], Train Loss: 0.002348
Validation Loss: 0.00150600
Epoch [28/300], Train Loss: 0.002409
Validation Loss: 0.00147054
Epoch [29/300], Train Loss: 0.002482
Validation Loss: 0.00141202
Epoch [30/300], Train Loss: 0.002124
Validation Loss: 0.00159077
Epoch [31/300], Train Loss: 0.002481
Validation Loss: 0.00138760
Epoch [32/300], Train Loss: 0.002234
Validation Loss: 0.00139834
Epoch [33/300], Train Loss: 0.002359
Validation Loss: 0.00145561
Epoch [34/300], Train Loss: 0.002303
Validation Loss: 0.00131205
Epoch [35/300], Train Loss: 0.002139
Validation Loss: 0.00134693
Epoch [36/300], Train Loss: 0.002144
Validation Loss: 0.00129964
Epoch [37/300], Train Loss: 0.001928
Validation Loss: 0.00143260
Epoch [38/300], Train Loss: 0.001717
Validation Loss: 0.00128665
Epoch [39/300], Train Loss: 0.001623
Validation Loss: 0.00138839
Epoch [40/300], Train Loss: 0.001555
Validation Loss: 0.00113737
Epoch [41/300], Train Loss: 0.001581
Validation Loss: 0.00109279
Epoch [42/300], Train Loss: 0.001302
Validation Loss: 0.00106004
Epoch [43/300], Train Loss: 0.001345
Validation Loss: 0.00123722
Epoch [44/300], Train Loss: 0.001406
Validation Loss: 0.00094132
Epoch [45/300], Train Loss: 0.001143
Validation Loss: 0.00107139
Epoch [46/300], Train Loss: 0.001151
Validation Loss: 0.00091837
Epoch [47/300], Train Loss: 0.001155
Validation Loss: 0.00098795
Epoch [48/300], Train Loss: 0.001037
Validation Loss: 0.00086458
Epoch [49/300], Train Loss: 0.001068
Validation Loss: 0.00084302
Epoch [50/300], Train Loss: 0.001027
Validation Loss: 0.00088077
Epoch [51/300], Train Loss: 0.000893
Validation Loss: 0.00081173
Epoch [52/300], Train Loss: 0.000880
Validation Loss: 0.00080427
Epoch [53/300], Train Loss: 0.000816
Validation Loss: 0.00080119
Epoch [54/300], Train Loss: 0.000831
Validation Loss: 0.00077689
Epoch [55/300], Train Loss: 0.000769
Validation Loss: 0.00073758
Epoch [56/300], Train Loss: 0.000880
Validation Loss: 0.00068134
Epoch [57/300], Train Loss: 0.000740
Validation Loss: 0.00063762
Epoch [58/300], Train Loss: 0.000795
Validation Loss: 0.00061733
Epoch [59/300], Train Loss: 0.000837
Validation Loss: 0.00067042
Epoch [60/300], Train Loss: 0.000786
Validation Loss: 0.00061550
Epoch [61/300], Train Loss: 0.000687
Validation Loss: 0.00062090
Epoch [62/300], Train Loss: 0.000707
Validation Loss: 0.00062366
Epoch [63/300], Train Loss: 0.000636
Validation Loss: 0.00058524
Epoch [64/300], Train Loss: 0.000655
Validation Loss: 0.00056557
Epoch [65/300], Train Loss: 0.000624
Validation Loss: 0.00056279
Epoch [66/300], Train Loss: 0.000584
Validation Loss: 0.00056970
Epoch [67/300], Train Loss: 0.000658
Validation Loss: 0.00054726
Epoch [68/300], Train Loss: 0.000592
Validation Loss: 0.00054614
Epoch [69/300], Train Loss: 0.000559
Validation Loss: 0.00055416
Epoch [70/300], Train Loss: 0.000551
Validation Loss: 0.00054600
Epoch [71/300], Train Loss: 0.000539
Validation Loss: 0.00054763
Epoch [72/300], Train Loss: 0.000630
Validation Loss: 0.00056971
Epoch [73/300], Train Loss: 0.000606
Validation Loss: 0.00054757
Epoch [74/300], Train Loss: 0.000586
Validation Loss: 0.00052514
Epoch [75/300], Train Loss: 0.000577
Validation Loss: 0.00053009
Epoch [76/300], Train Loss: 0.000573
Validation Loss: 0.00052996
Epoch [77/300], Train Loss: 0.000533
Validation Loss: 0.00053046
Epoch [78/300], Train Loss: 0.000572
Validation Loss: 0.00053877
Epoch [79/300], Train Loss: 0.000541
Validation Loss: 0.00053686
Epoch [80/300], Train Loss: 0.000538
Validation Loss: 0.00052985
Epoch [81/300], Train Loss: 0.000638
Validation Loss: 0.00053319
Epoch [82/300], Train Loss: 0.000621
Validation Loss: 0.00053940
Epoch [83/300], Train Loss: 0.000548
Validation Loss: 0.00052205
Epoch [84/300], Train Loss: 0.000508
Validation Loss: 0.00052544
Epoch [85/300], Train Loss: 0.000618
Validation Loss: 0.00052677
Epoch [86/300], Train Loss: 0.000678
Validation Loss: 0.00054545
Epoch [87/300], Train Loss: 0.000560
Validation Loss: 0.00053210
Epoch [88/300], Train Loss: 0.000646
Validation Loss: 0.00055206
Epoch [89/300], Train Loss: 0.000695
Validation Loss: 0.00052700
Epoch [90/300], Train Loss: 0.000554
Validation Loss: 0.00058509
Epoch [91/300], Train Loss: 0.000552
Validation Loss: 0.00047285
Epoch [92/300], Train Loss: 0.000502
Validation Loss: 0.00046716
Epoch [93/300], Train Loss: 0.000494
Validation Loss: 0.00048991
Epoch [94/300], Train Loss: 0.000510
Validation Loss: 0.00047668
Epoch [95/300], Train Loss: 0.000551
Validation Loss: 0.00046983
Epoch [96/300], Train Loss: 0.000579
Validation Loss: 0.00046849
Epoch [97/300], Train Loss: 0.000475
Validation Loss: 0.00047166
Epoch [98/300], Train Loss: 0.000524
Validation Loss: 0.00046650
Epoch [99/300], Train Loss: 0.000446
Validation Loss: 0.00044691
Epoch [100/300], Train Loss: 0.000471
Validation Loss: 0.00046238
Epoch [101/300], Train Loss: 0.000471
Validation Loss: 0.00041305
Epoch [102/300], Train Loss: 0.000407
Validation Loss: 0.00040356
Epoch [103/300], Train Loss: 0.000421
Validation Loss: 0.00038935
Epoch [104/300], Train Loss: 0.000397
Validation Loss: 0.00037995
Epoch [105/300], Train Loss: 0.000387
Validation Loss: 0.00037612
Epoch [106/300], Train Loss: 0.000415
Validation Loss: 0.00037346
Epoch [107/300], Train Loss: 0.000404
Validation Loss: 0.00037509
Epoch [108/300], Train Loss: 0.000407
Validation Loss: 0.00037625
Epoch [109/300], Train Loss: 0.000378
Validation Loss: 0.00036613
Epoch [110/300], Train Loss: 0.000403
Validation Loss: 0.00036966
Epoch [111/300], Train Loss: 0.000377
Validation Loss: 0.00036631
Epoch [112/300], Train Loss: 0.000395
Validation Loss: 0.00036713
Epoch [113/300], Train Loss: 0.000444
Validation Loss: 0.00037142
Epoch [114/300], Train Loss: 0.000399
Validation Loss: 0.00035636
Epoch [115/300], Train Loss: 0.000384
Validation Loss: 0.00035994
Epoch [116/300], Train Loss: 0.000433
Validation Loss: 0.00035498
Epoch [117/300], Train Loss: 0.000368
Validation Loss: 0.00036642
Epoch [118/300], Train Loss: 0.000398
Validation Loss: 0.00036043
Epoch [119/300], Train Loss: 0.000365
Validation Loss: 0.00035161
Epoch [120/300], Train Loss: 0.000371
Validation Loss: 0.00036014
Epoch [121/300], Train Loss: 0.000384
Validation Loss: 0.00035725
Epoch [122/300], Train Loss: 0.000357
Validation Loss: 0.00035176
Epoch [123/300], Train Loss: 0.000368
Validation Loss: 0.00035228
Epoch [124/300], Train Loss: 0.000363
Validation Loss: 0.00036306
Epoch [125/300], Train Loss: 0.000430
Validation Loss: 0.00035083
Epoch [126/300], Train Loss: 0.000374
Validation Loss: 0.00035303
Epoch [127/300], Train Loss: 0.000374
Validation Loss: 0.00035070
Epoch [128/300], Train Loss: 0.000372
Validation Loss: 0.00034857
Epoch [129/300], Train Loss: 0.000384
Validation Loss: 0.00034443
Epoch [130/300], Train Loss: 0.000379
Validation Loss: 0.00034548
Epoch [131/300], Train Loss: 0.000348
Validation Loss: 0.00034690
Epoch [132/300], Train Loss: 0.000367
Validation Loss: 0.00034629
Epoch [133/300], Train Loss: 0.000365
Validation Loss: 0.00034428
Epoch [134/300], Train Loss: 0.000345
Validation Loss: 0.00034198
Epoch [135/300], Train Loss: 0.000385
Validation Loss: 0.00034285
Epoch [136/300], Train Loss: 0.000373
Validation Loss: 0.00034141
Epoch [137/300], Train Loss: 0.000393
Validation Loss: 0.00033879
Epoch [138/300], Train Loss: 0.000382
Validation Loss: 0.00033301
Epoch [139/300], Train Loss: 0.000374
Validation Loss: 0.00034606
Epoch [140/300], Train Loss: 0.000362
Validation Loss: 0.00034535
Epoch [141/300], Train Loss: 0.000412
Validation Loss: 0.00046856
Epoch [142/300], Train Loss: 0.000374
Validation Loss: 0.00035083
Epoch [143/300], Train Loss: 0.000390
Validation Loss: 0.00034880
Epoch [144/300], Train Loss: 0.000433
Validation Loss: 0.00033666
Epoch [145/300], Train Loss: 0.000363
Validation Loss: 0.00032866
Epoch [146/300], Train Loss: 0.000366
Validation Loss: 0.00032971
Epoch [147/300], Train Loss: 0.000341
Validation Loss: 0.00032580
Epoch [148/300], Train Loss: 0.000344
Validation Loss: 0.00032429
Epoch [149/300], Train Loss: 0.000374
Validation Loss: 0.00032596
Epoch [150/300], Train Loss: 0.000331
Validation Loss: 0.00032231
Epoch [151/300], Train Loss: 0.000328
Validation Loss: 0.00032601
Epoch [152/300], Train Loss: 0.000395
Validation Loss: 0.00032202
Epoch [153/300], Train Loss: 0.000435
Validation Loss: 0.00032744
Epoch [154/300], Train Loss: 0.000366
Validation Loss: 0.00032443
Epoch [155/300], Train Loss: 0.000401
Validation Loss: 0.00032182
Epoch [156/300], Train Loss: 0.000349
Validation Loss: 0.00031345
Epoch [157/300], Train Loss: 0.000345
Validation Loss: 0.00031762
Epoch [158/300], Train Loss: 0.000324
Validation Loss: 0.00031435
Epoch [159/300], Train Loss: 0.000376
Validation Loss: 0.00031604
Epoch [160/300], Train Loss: 0.000372
Validation Loss: 0.00031218
Epoch [161/300], Train Loss: 0.000367
Validation Loss: 0.00031487
Epoch [162/300], Train Loss: 0.000367
Validation Loss: 0.00031128
Epoch [163/300], Train Loss: 0.000342
Validation Loss: 0.00031725
Epoch [164/300], Train Loss: 0.000327
Validation Loss: 0.00032140
Epoch [165/300], Train Loss: 0.000359
Validation Loss: 0.00031873
Epoch [166/300], Train Loss: 0.000364
Validation Loss: 0.00032339
Epoch [167/300], Train Loss: 0.000349
Validation Loss: 0.00031408
Epoch [168/300], Train Loss: 0.000321
Validation Loss: 0.00031574
Epoch [169/300], Train Loss: 0.000321
Validation Loss: 0.00031690
Epoch [170/300], Train Loss: 0.000334
Validation Loss: 0.00031032
Epoch [171/300], Train Loss: 0.000334
Validation Loss: 0.00031374
Epoch [172/300], Train Loss: 0.000334
Validation Loss: 0.00030715
Epoch [173/300], Train Loss: 0.000312
Validation Loss: 0.00030587
Epoch [174/300], Train Loss: 0.000313
Validation Loss: 0.00030416
Epoch [175/300], Train Loss: 0.000323
Validation Loss: 0.00030666
Epoch [176/300], Train Loss: 0.000310
Validation Loss: 0.00030588
Epoch [177/300], Train Loss: 0.000339
Validation Loss: 0.00030651
Epoch [178/300], Train Loss: 0.000309
Validation Loss: 0.00030526
Epoch [179/300], Train Loss: 0.000397
Validation Loss: 0.00029976
Epoch [180/300], Train Loss: 0.000313
Validation Loss: 0.00029421
Epoch [181/300], Train Loss: 0.000308
Validation Loss: 0.00029775
Epoch [182/300], Train Loss: 0.000325
Validation Loss: 0.00029959
Epoch [183/300], Train Loss: 0.000305
Validation Loss: 0.00029989
Epoch [184/300], Train Loss: 0.000411
Validation Loss: 0.00030545
Epoch [185/300], Train Loss: 0.000344
Validation Loss: 0.00030084
Epoch [186/300], Train Loss: 0.000311
Validation Loss: 0.00030579
Epoch [187/300], Train Loss: 0.000352
Validation Loss: 0.00029567
Epoch [188/300], Train Loss: 0.000321
Validation Loss: 0.00030500
Epoch [189/300], Train Loss: 0.000338
Validation Loss: 0.00029981
Epoch [190/300], Train Loss: 0.000306
Validation Loss: 0.00029849
Early stopping triggered

Evaluating model for: Dryer
Run 67/72 completed in 1207.76 seconds with: {'MAE': np.float32(2.2615137), 'MSE': np.float32(465.56186), 'RMSE': np.float32(21.576883), 'SAE': np.float32(0.02127493), 'NDE': np.float32(0.18393166)}

Run 68/72: hidden=512, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Dryer
Dataset length: 1470 windows

Epoch [1/300], Train Loss: 0.010718
Validation Loss: 0.00820446
Epoch [2/300], Train Loss: 0.009800
Validation Loss: 0.00814873
Epoch [3/300], Train Loss: 0.009825
Validation Loss: 0.00815778
Epoch [4/300], Train Loss: 0.009969
Validation Loss: 0.00815329
Epoch [5/300], Train Loss: 0.010142
Validation Loss: 0.00813716
Epoch [6/300], Train Loss: 0.010417
Validation Loss: 0.00811412
Epoch [7/300], Train Loss: 0.010588
Validation Loss: 0.00782478
Epoch [8/300], Train Loss: 0.008801
Validation Loss: 0.00650545
Epoch [9/300], Train Loss: 0.006740
Validation Loss: 0.00467975
Epoch [10/300], Train Loss: 0.005769
Validation Loss: 0.00297011
Epoch [11/300], Train Loss: 0.005095
Validation Loss: 0.00332231
Epoch [12/300], Train Loss: 0.003148
Validation Loss: 0.00192531
Epoch [13/300], Train Loss: 0.002670
Validation Loss: 0.00175563
Epoch [14/300], Train Loss: 0.002819
Validation Loss: 0.00194673
Epoch [15/300], Train Loss: 0.002726
Validation Loss: 0.00195181
Epoch [16/300], Train Loss: 0.002214
Validation Loss: 0.00181485
Epoch [17/300], Train Loss: 0.002102
Validation Loss: 0.00181772
Epoch [18/300], Train Loss: 0.002094
Validation Loss: 0.00169067
Epoch [19/300], Train Loss: 0.002062
Validation Loss: 0.00191432
Epoch [20/300], Train Loss: 0.002383
Validation Loss: 0.00164348
Epoch [21/300], Train Loss: 0.002204
Validation Loss: 0.00156984
Epoch [22/300], Train Loss: 0.002264
Validation Loss: 0.00157815
Epoch [23/300], Train Loss: 0.002149
Validation Loss: 0.00160839
Epoch [24/300], Train Loss: 0.002257
Validation Loss: 0.00162167
Epoch [25/300], Train Loss: 0.002230
Validation Loss: 0.00156134
Epoch [26/300], Train Loss: 0.001984
Validation Loss: 0.00157977
Epoch [27/300], Train Loss: 0.001799
Validation Loss: 0.00151603
Epoch [28/300], Train Loss: 0.001852
Validation Loss: 0.00292130
Epoch [29/300], Train Loss: 0.002076
Validation Loss: 0.00144465
Epoch [30/300], Train Loss: 0.001822
Validation Loss: 0.00145877
Epoch [31/300], Train Loss: 0.002001
Validation Loss: 0.00132631
Epoch [32/300], Train Loss: 0.001725
Validation Loss: 0.00131177
Epoch [33/300], Train Loss: 0.001700
Validation Loss: 0.00213872
Epoch [34/300], Train Loss: 0.001884
Validation Loss: 0.00122265
Epoch [35/300], Train Loss: 0.001532
Validation Loss: 0.00115261
Epoch [36/300], Train Loss: 0.001812
Validation Loss: 0.00111948
Epoch [37/300], Train Loss: 0.001615
Validation Loss: 0.00117666
Epoch [38/300], Train Loss: 0.001396
Validation Loss: 0.00119554
Epoch [39/300], Train Loss: 0.001330
Validation Loss: 0.00107956
Epoch [40/300], Train Loss: 0.001215
Validation Loss: 0.00104889
Epoch [41/300], Train Loss: 0.001318
Validation Loss: 0.00103426
Epoch [42/300], Train Loss: 0.001080
Validation Loss: 0.00096442
Epoch [43/300], Train Loss: 0.001067
Validation Loss: 0.00089441
Epoch [44/300], Train Loss: 0.001028
Validation Loss: 0.00092917
Epoch [45/300], Train Loss: 0.000730
Validation Loss: 0.00069300
Epoch [46/300], Train Loss: 0.000736
Validation Loss: 0.00066961
Epoch [47/300], Train Loss: 0.000837
Validation Loss: 0.00074385
Epoch [48/300], Train Loss: 0.000915
Validation Loss: 0.00078832
Epoch [49/300], Train Loss: 0.000818
Validation Loss: 0.00064430
Epoch [50/300], Train Loss: 0.000694
Validation Loss: 0.00063772
Epoch [51/300], Train Loss: 0.000773
Validation Loss: 0.00080434
Epoch [52/300], Train Loss: 0.000873
Validation Loss: 0.00066057
Epoch [53/300], Train Loss: 0.000739
Validation Loss: 0.00057388
Epoch [54/300], Train Loss: 0.000624
Validation Loss: 0.00059100
Epoch [55/300], Train Loss: 0.000595
Validation Loss: 0.00116161
Epoch [56/300], Train Loss: 0.001576
Validation Loss: 0.00087916
Epoch [57/300], Train Loss: 0.001234
Validation Loss: 0.00088135
Epoch [58/300], Train Loss: 0.001381
Validation Loss: 0.00072614
Epoch [59/300], Train Loss: 0.000887
Validation Loss: 0.00069721
Epoch [60/300], Train Loss: 0.000978
Validation Loss: 0.00078824
Epoch [61/300], Train Loss: 0.001029
Validation Loss: 0.00069921
Epoch [62/300], Train Loss: 0.000786
Validation Loss: 0.00065796
Epoch [63/300], Train Loss: 0.000720
Validation Loss: 0.00060862
Early stopping triggered

Evaluating model for: Dryer
Run 68/72 completed in 529.41 seconds with: {'MAE': np.float32(5.556058), 'MSE': np.float32(1132.9205), 'RMSE': np.float32(33.658886), 'SAE': np.float32(0.16727817), 'NDE': np.float32(0.28692478)}

Run 69/72: hidden=512, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Dryer
Dataset length: 746 windows

Epoch [1/300], Train Loss: 0.012348
Validation Loss: 0.00885558
Epoch [2/300], Train Loss: 0.011359
Validation Loss: 0.00883999
Epoch [3/300], Train Loss: 0.012171
Validation Loss: 0.00878423
Epoch [4/300], Train Loss: 0.011455
Validation Loss: 0.00871362
Epoch [5/300], Train Loss: 0.011551
Validation Loss: 0.00859584
Epoch [6/300], Train Loss: 0.011454
Validation Loss: 0.00841368
Epoch [7/300], Train Loss: 0.010546
Validation Loss: 0.00812960
Epoch [8/300], Train Loss: 0.011103
Validation Loss: 0.00760726
Epoch [9/300], Train Loss: 0.009606
Validation Loss: 0.00671733
Epoch [10/300], Train Loss: 0.007831
Validation Loss: 0.00538980
Epoch [11/300], Train Loss: 0.005325
Validation Loss: 0.00550988
Epoch [12/300], Train Loss: 0.004392
Validation Loss: 0.00397385
Epoch [13/300], Train Loss: 0.004377
Validation Loss: 0.00383807
Epoch [14/300], Train Loss: 0.003854
Validation Loss: 0.00329534
Epoch [15/300], Train Loss: 0.003364
Validation Loss: 0.00286866
Epoch [16/300], Train Loss: 0.003172
Validation Loss: 0.00286952
Epoch [17/300], Train Loss: 0.003382
Validation Loss: 0.00256897
Epoch [18/300], Train Loss: 0.003109
Validation Loss: 0.00243473
Epoch [19/300], Train Loss: 0.002705
Validation Loss: 0.00242914
Epoch [20/300], Train Loss: 0.002761
Validation Loss: 0.00210163
Epoch [21/300], Train Loss: 0.002521
Validation Loss: 0.00193185
Epoch [22/300], Train Loss: 0.002827
Validation Loss: 0.00176788
Epoch [23/300], Train Loss: 0.002539
Validation Loss: 0.00181169
Epoch [24/300], Train Loss: 0.002431
Validation Loss: 0.00180671
Epoch [25/300], Train Loss: 0.002431
Validation Loss: 0.00183594
Epoch [26/300], Train Loss: 0.002385
Validation Loss: 0.00182420
Epoch [27/300], Train Loss: 0.002369
Validation Loss: 0.00180777
Epoch [28/300], Train Loss: 0.002406
Validation Loss: 0.00184274
Epoch [29/300], Train Loss: 0.002259
Validation Loss: 0.00177451
Epoch [30/300], Train Loss: 0.002211
Validation Loss: 0.00173411
Epoch [31/300], Train Loss: 0.002082
Validation Loss: 0.00170976
Epoch [32/300], Train Loss: 0.002184
Validation Loss: 0.00165978
Epoch [33/300], Train Loss: 0.001998
Validation Loss: 0.00163010
Epoch [34/300], Train Loss: 0.001985
Validation Loss: 0.00156284
Epoch [35/300], Train Loss: 0.001948
Validation Loss: 0.00150251
Epoch [36/300], Train Loss: 0.002262
Validation Loss: 0.00215629
Epoch [37/300], Train Loss: 0.002364
Validation Loss: 0.00209944
Epoch [38/300], Train Loss: 0.002186
Validation Loss: 0.00171553
Epoch [39/300], Train Loss: 0.002192
Validation Loss: 0.00191325
Epoch [40/300], Train Loss: 0.001934
Validation Loss: 0.00175551
Epoch [41/300], Train Loss: 0.001978
Validation Loss: 0.00166783
Epoch [42/300], Train Loss: 0.001831
Validation Loss: 0.00149272
Epoch [43/300], Train Loss: 0.001819
Validation Loss: 0.00140760
Epoch [44/300], Train Loss: 0.001656
Validation Loss: 0.00131198
Epoch [45/300], Train Loss: 0.001666
Validation Loss: 0.00164260
Epoch [46/300], Train Loss: 0.001888
Validation Loss: 0.00158754
Epoch [47/300], Train Loss: 0.001818
Validation Loss: 0.00162844
Epoch [48/300], Train Loss: 0.001666
Validation Loss: 0.00143247
Epoch [49/300], Train Loss: 0.001636
Validation Loss: 0.00139596
Epoch [50/300], Train Loss: 0.001654
Validation Loss: 0.00133022
Epoch [51/300], Train Loss: 0.001619
Validation Loss: 0.00142341
Epoch [52/300], Train Loss: 0.001610
Validation Loss: 0.00144534
Epoch [53/300], Train Loss: 0.001569
Validation Loss: 0.00137396
Epoch [54/300], Train Loss: 0.001528
Validation Loss: 0.00133066
Early stopping triggered

Evaluating model for: Dryer
Run 69/72 completed in 100.13 seconds with: {'MAE': np.float32(3.827992), 'MSE': np.float32(791.8543), 'RMSE': np.float32(28.139906), 'SAE': np.float32(0.35536894), 'NDE': np.float32(0.44006482)}

Run 70/72: hidden=512, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Dryer
Dataset length: 746 windows

Epoch [1/300], Train Loss: 0.012280
Validation Loss: 0.00896565
Epoch [2/300], Train Loss: 0.011458
Validation Loss: 0.00895761
Epoch [3/300], Train Loss: 0.012300
Validation Loss: 0.00884297
Epoch [4/300], Train Loss: 0.011621
Validation Loss: 0.00882268
Epoch [5/300], Train Loss: 0.011773
Validation Loss: 0.00883604
Epoch [6/300], Train Loss: 0.011775
Validation Loss: 0.00869874
Epoch [7/300], Train Loss: 0.010943
Validation Loss: 0.00850889
Epoch [8/300], Train Loss: 0.011702
Validation Loss: 0.00811413
Epoch [9/300], Train Loss: 0.010292
Validation Loss: 0.00734250
Epoch [10/300], Train Loss: 0.008638
Validation Loss: 0.00704910
Epoch [11/300], Train Loss: 0.006687
Validation Loss: 0.00745637
Epoch [12/300], Train Loss: 0.005475
Validation Loss: 0.00501575
Epoch [13/300], Train Loss: 0.004887
Validation Loss: 0.00563522
Epoch [14/300], Train Loss: 0.004447
Validation Loss: 0.00413591
Epoch [15/300], Train Loss: 0.003815
Validation Loss: 0.00402603
Epoch [16/300], Train Loss: 0.003402
Validation Loss: 0.00348123
Epoch [17/300], Train Loss: 0.003357
Validation Loss: 0.00316043
Epoch [18/300], Train Loss: 0.003159
Validation Loss: 0.00282025
Epoch [19/300], Train Loss: 0.002916
Validation Loss: 0.00279432
Epoch [20/300], Train Loss: 0.002971
Validation Loss: 0.00249365
Epoch [21/300], Train Loss: 0.002810
Validation Loss: 0.00223084
Epoch [22/300], Train Loss: 0.002977
Validation Loss: 0.00238838
Epoch [23/300], Train Loss: 0.002760
Validation Loss: 0.00219415
Epoch [24/300], Train Loss: 0.002609
Validation Loss: 0.00230114
Epoch [25/300], Train Loss: 0.002601
Validation Loss: 0.00223678
Epoch [26/300], Train Loss: 0.002598
Validation Loss: 0.00196758
Epoch [27/300], Train Loss: 0.002821
Validation Loss: 0.00201463
Epoch [28/300], Train Loss: 0.002820
Validation Loss: 0.00260549
Epoch [29/300], Train Loss: 0.002735
Validation Loss: 0.00269786
Epoch [30/300], Train Loss: 0.002536
Validation Loss: 0.00234875
Epoch [31/300], Train Loss: 0.002372
Validation Loss: 0.00213736
Epoch [32/300], Train Loss: 0.002448
Validation Loss: 0.00189950
Epoch [33/300], Train Loss: 0.002266
Validation Loss: 0.00183867
Epoch [34/300], Train Loss: 0.002288
Validation Loss: 0.00183182
Epoch [35/300], Train Loss: 0.002341
Validation Loss: 0.00172458
Epoch [36/300], Train Loss: 0.002284
Validation Loss: 0.00184581
Epoch [37/300], Train Loss: 0.002315
Validation Loss: 0.00187997
Epoch [38/300], Train Loss: 0.002116
Validation Loss: 0.00204695
Epoch [39/300], Train Loss: 0.002105
Validation Loss: 0.00183715
Epoch [40/300], Train Loss: 0.001963
Validation Loss: 0.00177707
Epoch [41/300], Train Loss: 0.002024
Validation Loss: 0.00168098
Epoch [42/300], Train Loss: 0.001993
Validation Loss: 0.00169621
Epoch [43/300], Train Loss: 0.001961
Validation Loss: 0.00178911
Epoch [44/300], Train Loss: 0.001801
Validation Loss: 0.00163002
Epoch [45/300], Train Loss: 0.001774
Validation Loss: 0.00161300
Epoch [46/300], Train Loss: 0.001729
Validation Loss: 0.00160632
Epoch [47/300], Train Loss: 0.001787
Validation Loss: 0.00159482
Epoch [48/300], Train Loss: 0.001612
Validation Loss: 0.00140203
Epoch [49/300], Train Loss: 0.002091
Validation Loss: 0.00299050
Epoch [50/300], Train Loss: 0.002884
Validation Loss: 0.00254507
Epoch [51/300], Train Loss: 0.003231
Validation Loss: 0.00305805
Epoch [52/300], Train Loss: 0.002535
Validation Loss: 0.00226894
Epoch [53/300], Train Loss: 0.002600
Validation Loss: 0.00206771
Epoch [54/300], Train Loss: 0.002161
Validation Loss: 0.00198526
Epoch [55/300], Train Loss: 0.001829
Validation Loss: 0.00179597
Epoch [56/300], Train Loss: 0.001801
Validation Loss: 0.00156784
Epoch [57/300], Train Loss: 0.001678
Validation Loss: 0.00133765
Epoch [58/300], Train Loss: 0.001622
Validation Loss: 0.00146505
Epoch [59/300], Train Loss: 0.001598
Validation Loss: 0.00140156
Epoch [60/300], Train Loss: 0.001553
Validation Loss: 0.00134220
Epoch [61/300], Train Loss: 0.001591
Validation Loss: 0.00129235
Epoch [62/300], Train Loss: 0.001430
Validation Loss: 0.00128147
Epoch [63/300], Train Loss: 0.001412
Validation Loss: 0.00124861
Epoch [64/300], Train Loss: 0.001475
Validation Loss: 0.00121561
Epoch [65/300], Train Loss: 0.001473
Validation Loss: 0.00111238
Epoch [66/300], Train Loss: 0.001335
Validation Loss: 0.00110938
Epoch [67/300], Train Loss: 0.001381
Validation Loss: 0.00109678
Epoch [68/300], Train Loss: 0.001308
Validation Loss: 0.00101884
Epoch [69/300], Train Loss: 0.001382
Validation Loss: 0.00104699
Epoch [70/300], Train Loss: 0.001316
Validation Loss: 0.00104453
Epoch [71/300], Train Loss: 0.001333
Validation Loss: 0.00094068
Epoch [72/300], Train Loss: 0.001280
Validation Loss: 0.00103721
Epoch [73/300], Train Loss: 0.001237
Validation Loss: 0.00097004
Epoch [74/300], Train Loss: 0.001264
Validation Loss: 0.00092865
Epoch [75/300], Train Loss: 0.001215
Validation Loss: 0.00084052
Epoch [76/300], Train Loss: 0.001171
Validation Loss: 0.00085542
Epoch [77/300], Train Loss: 0.001108
Validation Loss: 0.00079167
Epoch [78/300], Train Loss: 0.001110
Validation Loss: 0.00078586
Epoch [79/300], Train Loss: 0.001092
Validation Loss: 0.00084484
Epoch [80/300], Train Loss: 0.000924
Validation Loss: 0.00070263
Epoch [81/300], Train Loss: 0.001027
Validation Loss: 0.00071931
Epoch [82/300], Train Loss: 0.000973
Validation Loss: 0.00072169
Epoch [83/300], Train Loss: 0.000985
Validation Loss: 0.00070995
Epoch [84/300], Train Loss: 0.000843
Validation Loss: 0.00069301
Epoch [85/300], Train Loss: 0.000830
Validation Loss: 0.00068916
Epoch [86/300], Train Loss: 0.000816
Validation Loss: 0.00068765
Epoch [87/300], Train Loss: 0.000816
Validation Loss: 0.00071986
Epoch [88/300], Train Loss: 0.000784
Validation Loss: 0.00073475
Epoch [89/300], Train Loss: 0.000768
Validation Loss: 0.00074355
Epoch [90/300], Train Loss: 0.000798
Validation Loss: 0.00071943
Epoch [91/300], Train Loss: 0.000732
Validation Loss: 0.00069752
Epoch [92/300], Train Loss: 0.000736
Validation Loss: 0.00067007
Epoch [93/300], Train Loss: 0.000758
Validation Loss: 0.00067564
Epoch [94/300], Train Loss: 0.000776
Validation Loss: 0.00068274
Epoch [95/300], Train Loss: 0.000745
Validation Loss: 0.00071565
Epoch [96/300], Train Loss: 0.000738
Validation Loss: 0.00071866
Epoch [97/300], Train Loss: 0.000717
Validation Loss: 0.00071109
Epoch [98/300], Train Loss: 0.000703
Validation Loss: 0.00068629
Epoch [99/300], Train Loss: 0.000718
Validation Loss: 0.00067822
Epoch [100/300], Train Loss: 0.000741
Validation Loss: 0.00069260
Epoch [101/300], Train Loss: 0.000704
Validation Loss: 0.00069663
Epoch [102/300], Train Loss: 0.000697
Validation Loss: 0.00069610
Early stopping triggered

Evaluating model for: Dryer
Run 70/72 completed in 253.68 seconds with: {'MAE': np.float32(3.7155817), 'MSE': np.float32(698.0329), 'RMSE': np.float32(26.420313), 'SAE': np.float32(0.25785768), 'NDE': np.float32(0.41317296)}

Run 71/72: hidden=512, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Dryer
Dataset length: 746 windows

Epoch [1/300], Train Loss: 0.012365
Validation Loss: 0.00890136
Epoch [2/300], Train Loss: 0.011468
Validation Loss: 0.00903813
Epoch [3/300], Train Loss: 0.012356
Validation Loss: 0.00890458
Epoch [4/300], Train Loss: 0.011687
Validation Loss: 0.00888584
Epoch [5/300], Train Loss: 0.011891
Validation Loss: 0.00889310
Epoch [6/300], Train Loss: 0.011963
Validation Loss: 0.00887692
Epoch [7/300], Train Loss: 0.011231
Validation Loss: 0.00882343
Epoch [8/300], Train Loss: 0.012332
Validation Loss: 0.00864164
Epoch [9/300], Train Loss: 0.011216
Validation Loss: 0.00829831
Epoch [10/300], Train Loss: 0.010188
Validation Loss: 0.00738468
Epoch [11/300], Train Loss: 0.007559
Validation Loss: 0.00589337
Epoch [12/300], Train Loss: 0.005242
Validation Loss: 0.00551655
Epoch [13/300], Train Loss: 0.004530
Validation Loss: 0.00471746
Epoch [14/300], Train Loss: 0.003708
Validation Loss: 0.00333987
Epoch [15/300], Train Loss: 0.003219
Validation Loss: 0.00296104
Epoch [16/300], Train Loss: 0.003014
Validation Loss: 0.00251832
Epoch [17/300], Train Loss: 0.002914
Validation Loss: 0.00237546
Epoch [18/300], Train Loss: 0.002784
Validation Loss: 0.00212967
Epoch [19/300], Train Loss: 0.002565
Validation Loss: 0.00206375
Epoch [20/300], Train Loss: 0.002487
Validation Loss: 0.00196864
Epoch [21/300], Train Loss: 0.002405
Validation Loss: 0.00190016
Epoch [22/300], Train Loss: 0.002489
Validation Loss: 0.00183517
Epoch [23/300], Train Loss: 0.002288
Validation Loss: 0.00172510
Epoch [24/300], Train Loss: 0.002131
Validation Loss: 0.00162122
Epoch [25/300], Train Loss: 0.002080
Validation Loss: 0.00173604
Epoch [26/300], Train Loss: 0.001998
Validation Loss: 0.00154553
Epoch [27/300], Train Loss: 0.002053
Validation Loss: 0.00159614
Epoch [28/300], Train Loss: 0.002104
Validation Loss: 0.00185268
Epoch [29/300], Train Loss: 0.001980
Validation Loss: 0.00149483
Epoch [30/300], Train Loss: 0.001790
Validation Loss: 0.00177985
Epoch [31/300], Train Loss: 0.001859
Validation Loss: 0.00154696
Epoch [32/300], Train Loss: 0.001891
Validation Loss: 0.00154504
Epoch [33/300], Train Loss: 0.001732
Validation Loss: 0.00151752
Epoch [34/300], Train Loss: 0.001756
Validation Loss: 0.00146748
Epoch [35/300], Train Loss: 0.001780
Validation Loss: 0.00152458
Epoch [36/300], Train Loss: 0.001796
Validation Loss: 0.00147631
Epoch [37/300], Train Loss: 0.001818
Validation Loss: 0.00152321
Epoch [38/300], Train Loss: 0.001690
Validation Loss: 0.00150448
Epoch [39/300], Train Loss: 0.001721
Validation Loss: 0.00154161
Epoch [40/300], Train Loss: 0.001605
Validation Loss: 0.00151345
Epoch [41/300], Train Loss: 0.001719
Validation Loss: 0.00149866
Epoch [42/300], Train Loss: 0.001665
Validation Loss: 0.00145264
Epoch [43/300], Train Loss: 0.001645
Validation Loss: 0.00149180
Epoch [44/300], Train Loss: 0.001508
Validation Loss: 0.00135650
Epoch [45/300], Train Loss: 0.001615
Validation Loss: 0.00145192
Epoch [46/300], Train Loss: 0.001777
Validation Loss: 0.00156051
Epoch [47/300], Train Loss: 0.001632
Validation Loss: 0.00139791
Epoch [48/300], Train Loss: 0.001514
Validation Loss: 0.00141349
Epoch [49/300], Train Loss: 0.001434
Validation Loss: 0.00136806
Epoch [50/300], Train Loss: 0.001437
Validation Loss: 0.00131984
Epoch [51/300], Train Loss: 0.001302
Validation Loss: 0.00123060
Epoch [52/300], Train Loss: 0.001227
Validation Loss: 0.00112070
Epoch [53/300], Train Loss: 0.001179
Validation Loss: 0.00106628
Epoch [54/300], Train Loss: 0.001113
Validation Loss: 0.00104765
Epoch [55/300], Train Loss: 0.002213
Validation Loss: 0.00103719
Epoch [56/300], Train Loss: 0.001693
Validation Loss: 0.00160633
Epoch [57/300], Train Loss: 0.001623
Validation Loss: 0.00151531
Epoch [58/300], Train Loss: 0.001384
Validation Loss: 0.00130042
Epoch [59/300], Train Loss: 0.001110
Validation Loss: 0.00098851
Epoch [60/300], Train Loss: 0.000870
Validation Loss: 0.00083778
Epoch [61/300], Train Loss: 0.001141
Validation Loss: 0.00082557
Epoch [62/300], Train Loss: 0.000944
Validation Loss: 0.00081405
Epoch [63/300], Train Loss: 0.000895
Validation Loss: 0.00084153
Epoch [64/300], Train Loss: 0.000922
Validation Loss: 0.00086440
Epoch [65/300], Train Loss: 0.000861
Validation Loss: 0.00086954
Epoch [66/300], Train Loss: 0.000790
Validation Loss: 0.00081211
Epoch [67/300], Train Loss: 0.000775
Validation Loss: 0.00077239
Epoch [68/300], Train Loss: 0.000764
Validation Loss: 0.00076021
Epoch [69/300], Train Loss: 0.000768
Validation Loss: 0.00074435
Epoch [70/300], Train Loss: 0.000733
Validation Loss: 0.00073308
Epoch [71/300], Train Loss: 0.000741
Validation Loss: 0.00073388
Epoch [72/300], Train Loss: 0.000718
Validation Loss: 0.00074068
Epoch [73/300], Train Loss: 0.000710
Validation Loss: 0.00072943
Epoch [74/300], Train Loss: 0.000743
Validation Loss: 0.00072204
Epoch [75/300], Train Loss: 0.000706
Validation Loss: 0.00070384
Epoch [76/300], Train Loss: 0.000709
Validation Loss: 0.00070308
Epoch [77/300], Train Loss: 0.000683
Validation Loss: 0.00070491
Epoch [78/300], Train Loss: 0.000690
Validation Loss: 0.00070513
Epoch [79/300], Train Loss: 0.000678
Validation Loss: 0.00069128
Epoch [80/300], Train Loss: 0.000676
Validation Loss: 0.00068844
Epoch [81/300], Train Loss: 0.000699
Validation Loss: 0.00070278
Epoch [82/300], Train Loss: 0.000684
Validation Loss: 0.00068774
Epoch [83/300], Train Loss: 0.000711
Validation Loss: 0.00068917
Epoch [84/300], Train Loss: 0.000688
Validation Loss: 0.00067314
Epoch [85/300], Train Loss: 0.000675
Validation Loss: 0.00068806
Epoch [86/300], Train Loss: 0.000677
Validation Loss: 0.00068390
Epoch [87/300], Train Loss: 0.000677
Validation Loss: 0.00068022
Epoch [88/300], Train Loss: 0.000658
Validation Loss: 0.00066213
Epoch [89/300], Train Loss: 0.000646
Validation Loss: 0.00068360
Epoch [90/300], Train Loss: 0.000680
Validation Loss: 0.00066933
Epoch [91/300], Train Loss: 0.000632
Validation Loss: 0.00067168
Epoch [92/300], Train Loss: 0.000636
Validation Loss: 0.00065321
Epoch [93/300], Train Loss: 0.000653
Validation Loss: 0.00065983
Epoch [94/300], Train Loss: 0.000671
Validation Loss: 0.00066316
Epoch [95/300], Train Loss: 0.000652
Validation Loss: 0.00067678
Epoch [96/300], Train Loss: 0.000642
Validation Loss: 0.00066665
Epoch [97/300], Train Loss: 0.000628
Validation Loss: 0.00065996
Epoch [98/300], Train Loss: 0.000612
Validation Loss: 0.00064776
Epoch [99/300], Train Loss: 0.000636
Validation Loss: 0.00064740
Epoch [100/300], Train Loss: 0.000655
Validation Loss: 0.00066653
Epoch [101/300], Train Loss: 0.000620
Validation Loss: 0.00064799
Epoch [102/300], Train Loss: 0.000608
Validation Loss: 0.00065225
Epoch [103/300], Train Loss: 0.000653
Validation Loss: 0.00064776
Epoch [104/300], Train Loss: 0.000602
Validation Loss: 0.00065732
Epoch [105/300], Train Loss: 0.000623
Validation Loss: 0.00066100
Epoch [106/300], Train Loss: 0.000612
Validation Loss: 0.00065697
Epoch [107/300], Train Loss: 0.000619
Validation Loss: 0.00063974
Epoch [108/300], Train Loss: 0.000619
Validation Loss: 0.00065303
Epoch [109/300], Train Loss: 0.000641
Validation Loss: 0.00067327
Epoch [110/300], Train Loss: 0.000602
Validation Loss: 0.00064448
Epoch [111/300], Train Loss: 0.000593
Validation Loss: 0.00064592
Epoch [112/300], Train Loss: 0.000616
Validation Loss: 0.00064299
Epoch [113/300], Train Loss: 0.000610
Validation Loss: 0.00064475
Epoch [114/300], Train Loss: 0.000611
Validation Loss: 0.00066634
Epoch [115/300], Train Loss: 0.000607
Validation Loss: 0.00063374
Epoch [116/300], Train Loss: 0.000580
Validation Loss: 0.00063874
Epoch [117/300], Train Loss: 0.000595
Validation Loss: 0.00064618
Epoch [118/300], Train Loss: 0.000628
Validation Loss: 0.00062479
Epoch [119/300], Train Loss: 0.000602
Validation Loss: 0.00061671
Epoch [120/300], Train Loss: 0.000609
Validation Loss: 0.00063789
Epoch [121/300], Train Loss: 0.000582
Validation Loss: 0.00062018
Epoch [122/300], Train Loss: 0.000567
Validation Loss: 0.00064283
Epoch [123/300], Train Loss: 0.000589
Validation Loss: 0.00063360
Epoch [124/300], Train Loss: 0.000604
Validation Loss: 0.00061270
Epoch [125/300], Train Loss: 0.000590
Validation Loss: 0.00067077
Epoch [126/300], Train Loss: 0.000567
Validation Loss: 0.00060884
Epoch [127/300], Train Loss: 0.000587
Validation Loss: 0.00060948
Epoch [128/300], Train Loss: 0.000583
Validation Loss: 0.00062396
Epoch [129/300], Train Loss: 0.000556
Validation Loss: 0.00061286
Epoch [130/300], Train Loss: 0.000567
Validation Loss: 0.00060875
Epoch [131/300], Train Loss: 0.000566
Validation Loss: 0.00061440
Epoch [132/300], Train Loss: 0.000597
Validation Loss: 0.00060053
Epoch [133/300], Train Loss: 0.000550
Validation Loss: 0.00061818
Epoch [134/300], Train Loss: 0.000554
Validation Loss: 0.00060220
Epoch [135/300], Train Loss: 0.000543
Validation Loss: 0.00058416
Epoch [136/300], Train Loss: 0.000540
Validation Loss: 0.00058020
Epoch [137/300], Train Loss: 0.000571
Validation Loss: 0.00058582
Epoch [138/300], Train Loss: 0.000552
Validation Loss: 0.00057690
Epoch [139/300], Train Loss: 0.000556
Validation Loss: 0.00056892
Epoch [140/300], Train Loss: 0.000546
Validation Loss: 0.00057257
Epoch [141/300], Train Loss: 0.000530
Validation Loss: 0.00056778
Epoch [142/300], Train Loss: 0.000537
Validation Loss: 0.00057576
Epoch [143/300], Train Loss: 0.000580
Validation Loss: 0.00055549
Epoch [144/300], Train Loss: 0.000523
Validation Loss: 0.00056696
Epoch [145/300], Train Loss: 0.000532
Validation Loss: 0.00054426
Epoch [146/300], Train Loss: 0.000564
Validation Loss: 0.00054200
Epoch [147/300], Train Loss: 0.000529
Validation Loss: 0.00053014
Epoch [148/300], Train Loss: 0.000507
Validation Loss: 0.00052972
Epoch [149/300], Train Loss: 0.000566
Validation Loss: 0.00051454
Epoch [150/300], Train Loss: 0.000527
Validation Loss: 0.00051667
Epoch [151/300], Train Loss: 0.000514
Validation Loss: 0.00049955
Epoch [152/300], Train Loss: 0.000519
Validation Loss: 0.00050226
Epoch [153/300], Train Loss: 0.000495
Validation Loss: 0.00049309
Epoch [154/300], Train Loss: 0.000495
Validation Loss: 0.00048946
Epoch [155/300], Train Loss: 0.000491
Validation Loss: 0.00048911
Epoch [156/300], Train Loss: 0.000490
Validation Loss: 0.00047365
Epoch [157/300], Train Loss: 0.000485
Validation Loss: 0.00047430
Epoch [158/300], Train Loss: 0.000496
Validation Loss: 0.00047984
Epoch [159/300], Train Loss: 0.000523
Validation Loss: 0.00046624
Epoch [160/300], Train Loss: 0.000491
Validation Loss: 0.00046508
Epoch [161/300], Train Loss: 0.000516
Validation Loss: 0.00045141
Epoch [162/300], Train Loss: 0.000504
Validation Loss: 0.00046679
Epoch [163/300], Train Loss: 0.000481
Validation Loss: 0.00046397
Epoch [164/300], Train Loss: 0.000482
Validation Loss: 0.00045938
Epoch [165/300], Train Loss: 0.000481
Validation Loss: 0.00045155
Epoch [166/300], Train Loss: 0.000471
Validation Loss: 0.00044540
Epoch [167/300], Train Loss: 0.000462
Validation Loss: 0.00044439
Epoch [168/300], Train Loss: 0.000477
Validation Loss: 0.00044379
Epoch [169/300], Train Loss: 0.000475
Validation Loss: 0.00042836
Epoch [170/300], Train Loss: 0.000470
Validation Loss: 0.00043458
Epoch [171/300], Train Loss: 0.000476
Validation Loss: 0.00044449
Epoch [172/300], Train Loss: 0.000467
Validation Loss: 0.00043917
Epoch [173/300], Train Loss: 0.000487
Validation Loss: 0.00044706
Epoch [174/300], Train Loss: 0.000474
Validation Loss: 0.00042750
Epoch [175/300], Train Loss: 0.000476
Validation Loss: 0.00044232
Epoch [176/300], Train Loss: 0.000480
Validation Loss: 0.00043394
Epoch [177/300], Train Loss: 0.000478
Validation Loss: 0.00042774
Epoch [178/300], Train Loss: 0.000470
Validation Loss: 0.00042846
Epoch [179/300], Train Loss: 0.000457
Validation Loss: 0.00043024
Epoch [180/300], Train Loss: 0.000498
Validation Loss: 0.00042009
Epoch [181/300], Train Loss: 0.000477
Validation Loss: 0.00042197
Epoch [182/300], Train Loss: 0.000455
Validation Loss: 0.00042175
Epoch [183/300], Train Loss: 0.000485
Validation Loss: 0.00042880
Epoch [184/300], Train Loss: 0.000465
Validation Loss: 0.00041939
Epoch [185/300], Train Loss: 0.000459
Validation Loss: 0.00041915
Epoch [186/300], Train Loss: 0.000446
Validation Loss: 0.00041553
Epoch [187/300], Train Loss: 0.000450
Validation Loss: 0.00042215
Epoch [188/300], Train Loss: 0.000458
Validation Loss: 0.00041525
Epoch [189/300], Train Loss: 0.000462
Validation Loss: 0.00041402
Epoch [190/300], Train Loss: 0.000463
Validation Loss: 0.00041870
Epoch [191/300], Train Loss: 0.000457
Validation Loss: 0.00042045
Epoch [192/300], Train Loss: 0.000455
Validation Loss: 0.00042105
Epoch [193/300], Train Loss: 0.000450
Validation Loss: 0.00041550
Epoch [194/300], Train Loss: 0.000465
Validation Loss: 0.00041161
Epoch [195/300], Train Loss: 0.000476
Validation Loss: 0.00040836
Epoch [196/300], Train Loss: 0.000459
Validation Loss: 0.00041526
Epoch [197/300], Train Loss: 0.000452
Validation Loss: 0.00041209
Epoch [198/300], Train Loss: 0.000457
Validation Loss: 0.00040749
Epoch [199/300], Train Loss: 0.000471
Validation Loss: 0.00040271
Epoch [200/300], Train Loss: 0.000433
Validation Loss: 0.00040397
Epoch [201/300], Train Loss: 0.000450
Validation Loss: 0.00040948
Epoch [202/300], Train Loss: 0.000468
Validation Loss: 0.00041061
Epoch [203/300], Train Loss: 0.000455
Validation Loss: 0.00041380
Epoch [204/300], Train Loss: 0.000441
Validation Loss: 0.00040107
Epoch [205/300], Train Loss: 0.000457
Validation Loss: 0.00039318
Epoch [206/300], Train Loss: 0.000482
Validation Loss: 0.00039838
Epoch [207/300], Train Loss: 0.000442
Validation Loss: 0.00039854
Epoch [208/300], Train Loss: 0.000472
Validation Loss: 0.00041704
Epoch [209/300], Train Loss: 0.000462
Validation Loss: 0.00040419
Epoch [210/300], Train Loss: 0.000431
Validation Loss: 0.00039766
Epoch [211/300], Train Loss: 0.000447
Validation Loss: 0.00039208
Epoch [212/300], Train Loss: 0.000450
Validation Loss: 0.00039664
Epoch [213/300], Train Loss: 0.000439
Validation Loss: 0.00041460
Epoch [214/300], Train Loss: 0.000439
Validation Loss: 0.00040213
Epoch [215/300], Train Loss: 0.000434
Validation Loss: 0.00039650
Epoch [216/300], Train Loss: 0.000440
Validation Loss: 0.00039151
Epoch [217/300], Train Loss: 0.000448
Validation Loss: 0.00039860
Epoch [218/300], Train Loss: 0.000461
Validation Loss: 0.00040153
Epoch [219/300], Train Loss: 0.000452
Validation Loss: 0.00040416
Epoch [220/300], Train Loss: 0.000441
Validation Loss: 0.00039580
Epoch [221/300], Train Loss: 0.000436
Validation Loss: 0.00039623
Epoch [222/300], Train Loss: 0.000446
Validation Loss: 0.00040193
Epoch [223/300], Train Loss: 0.000440
Validation Loss: 0.00038959
Epoch [224/300], Train Loss: 0.000428
Validation Loss: 0.00039138
Epoch [225/300], Train Loss: 0.000452
Validation Loss: 0.00038959
Epoch [226/300], Train Loss: 0.000459
Validation Loss: 0.00039852
Epoch [227/300], Train Loss: 0.000436
Validation Loss: 0.00039738
Epoch [228/300], Train Loss: 0.000418
Validation Loss: 0.00039486
Epoch [229/300], Train Loss: 0.000425
Validation Loss: 0.00038416
Epoch [230/300], Train Loss: 0.000436
Validation Loss: 0.00039900
Epoch [231/300], Train Loss: 0.000438
Validation Loss: 0.00038544
Epoch [232/300], Train Loss: 0.000418
Validation Loss: 0.00038364
Epoch [233/300], Train Loss: 0.000435
Validation Loss: 0.00038508
Epoch [234/300], Train Loss: 0.000444
Validation Loss: 0.00038629
Epoch [235/300], Train Loss: 0.000429
Validation Loss: 0.00039263
Epoch [236/300], Train Loss: 0.000419
Validation Loss: 0.00038409
Epoch [237/300], Train Loss: 0.000427
Validation Loss: 0.00038921
Epoch [238/300], Train Loss: 0.000445
Validation Loss: 0.00038497
Epoch [239/300], Train Loss: 0.000437
Validation Loss: 0.00038346
Epoch [240/300], Train Loss: 0.000427
Validation Loss: 0.00038589
Epoch [241/300], Train Loss: 0.000441
Validation Loss: 0.00037840
Epoch [242/300], Train Loss: 0.000426
Validation Loss: 0.00038082
Epoch [243/300], Train Loss: 0.000434
Validation Loss: 0.00038923
Epoch [244/300], Train Loss: 0.000436
Validation Loss: 0.00038365
Epoch [245/300], Train Loss: 0.000415
Validation Loss: 0.00038053
Epoch [246/300], Train Loss: 0.000410
Validation Loss: 0.00038307
Epoch [247/300], Train Loss: 0.000423
Validation Loss: 0.00038089
Epoch [248/300], Train Loss: 0.000416
Validation Loss: 0.00038016
Epoch [249/300], Train Loss: 0.000451
Validation Loss: 0.00037798
Epoch [250/300], Train Loss: 0.000443
Validation Loss: 0.00038024
Epoch [251/300], Train Loss: 0.000409
Validation Loss: 0.00038298
Epoch [252/300], Train Loss: 0.000448
Validation Loss: 0.00037895
Epoch [253/300], Train Loss: 0.000426
Validation Loss: 0.00037461
Epoch [254/300], Train Loss: 0.000433
Validation Loss: 0.00038163
Epoch [255/300], Train Loss: 0.000420
Validation Loss: 0.00037037
Epoch [256/300], Train Loss: 0.000432
Validation Loss: 0.00037335
Epoch [257/300], Train Loss: 0.000417
Validation Loss: 0.00037605
Epoch [258/300], Train Loss: 0.000445
Validation Loss: 0.00037901
Epoch [259/300], Train Loss: 0.000420
Validation Loss: 0.00037397
Epoch [260/300], Train Loss: 0.000423
Validation Loss: 0.00037694
Epoch [261/300], Train Loss: 0.000421
Validation Loss: 0.00036977
Epoch [262/300], Train Loss: 0.000430
Validation Loss: 0.00037713
Epoch [263/300], Train Loss: 0.000431
Validation Loss: 0.00037559
Epoch [264/300], Train Loss: 0.000425
Validation Loss: 0.00036906
Epoch [265/300], Train Loss: 0.000440
Validation Loss: 0.00037369
Epoch [266/300], Train Loss: 0.000423
Validation Loss: 0.00037438
Epoch [267/300], Train Loss: 0.000430
Validation Loss: 0.00037137
Epoch [268/300], Train Loss: 0.000411
Validation Loss: 0.00037645
Epoch [269/300], Train Loss: 0.000427
Validation Loss: 0.00037258
Epoch [270/300], Train Loss: 0.000428
Validation Loss: 0.00037328
Epoch [271/300], Train Loss: 0.000421
Validation Loss: 0.00037285
Epoch [272/300], Train Loss: 0.000426
Validation Loss: 0.00036374
Epoch [273/300], Train Loss: 0.000424
Validation Loss: 0.00036577
Epoch [274/300], Train Loss: 0.000415
Validation Loss: 0.00036688
Epoch [275/300], Train Loss: 0.000414
Validation Loss: 0.00036752
Epoch [276/300], Train Loss: 0.000396
Validation Loss: 0.00036774
Epoch [277/300], Train Loss: 0.000426
Validation Loss: 0.00036873
Epoch [278/300], Train Loss: 0.000407
Validation Loss: 0.00035896
Epoch [279/300], Train Loss: 0.000410
Validation Loss: 0.00036106
Epoch [280/300], Train Loss: 0.000413
Validation Loss: 0.00036710
Epoch [281/300], Train Loss: 0.000415
Validation Loss: 0.00036371
Epoch [282/300], Train Loss: 0.000410
Validation Loss: 0.00036780
Epoch [283/300], Train Loss: 0.000437
Validation Loss: 0.00037405
Epoch [284/300], Train Loss: 0.000407
Validation Loss: 0.00036896
Epoch [285/300], Train Loss: 0.000400
Validation Loss: 0.00036669
Epoch [286/300], Train Loss: 0.000399
Validation Loss: 0.00036285
Epoch [287/300], Train Loss: 0.000406
Validation Loss: 0.00035843
Epoch [288/300], Train Loss: 0.000410
Validation Loss: 0.00036130
Epoch [289/300], Train Loss: 0.000413
Validation Loss: 0.00035660
Epoch [290/300], Train Loss: 0.000418
Validation Loss: 0.00035008
Epoch [291/300], Train Loss: 0.000405
Validation Loss: 0.00035376
Epoch [292/300], Train Loss: 0.000425
Validation Loss: 0.00036077
Epoch [293/300], Train Loss: 0.000429
Validation Loss: 0.00035799
Epoch [294/300], Train Loss: 0.000396
Validation Loss: 0.00036117
Epoch [295/300], Train Loss: 0.000421
Validation Loss: 0.00036198
Epoch [296/300], Train Loss: 0.000414
Validation Loss: 0.00035753
Epoch [297/300], Train Loss: 0.000419
Validation Loss: 0.00035653
Epoch [298/300], Train Loss: 0.000407
Validation Loss: 0.00036365
Epoch [299/300], Train Loss: 0.000398
Validation Loss: 0.00036150
Epoch [300/300], Train Loss: 0.000412
Validation Loss: 0.00035289
Early stopping triggered

Evaluating model for: Dryer
Run 71/72 completed in 949.47 seconds with: {'MAE': np.float32(2.323736), 'MSE': np.float32(338.8599), 'RMSE': np.float32(18.408148), 'SAE': np.float32(0.0017691056), 'NDE': np.float32(0.28787512)}

Run 72/72: hidden=512, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Dryer
Dataset length: 746 windows

Epoch [1/300], Train Loss: 0.013853
Validation Loss: 0.00906644
Epoch [2/300], Train Loss: 0.011577
Validation Loss: 0.00914537
Epoch [3/300], Train Loss: 0.012465
Validation Loss: 0.00909378
Epoch [4/300], Train Loss: 0.011750
Validation Loss: 0.00892276
Epoch [5/300], Train Loss: 0.011938
Validation Loss: 0.00889853
Epoch [6/300], Train Loss: 0.012066
Validation Loss: 0.00889848
Epoch [7/300], Train Loss: 0.011355
Validation Loss: 0.00892933
Epoch [8/300], Train Loss: 0.012594
Validation Loss: 0.00892520
Epoch [9/300], Train Loss: 0.011842
Validation Loss: 0.00893743
Epoch [10/300], Train Loss: 0.011914
Validation Loss: 0.00892182
Epoch [11/300], Train Loss: 0.012052
Validation Loss: 0.00889802
Epoch [12/300], Train Loss: 0.011967
Validation Loss: 0.00889063
Epoch [13/300], Train Loss: 0.011869
Validation Loss: 0.00887363
Epoch [14/300], Train Loss: 0.011979
Validation Loss: 0.00883083
Epoch [15/300], Train Loss: 0.011339
Validation Loss: 0.00856036
Epoch [16/300], Train Loss: 0.010614
Validation Loss: 0.00694291
Epoch [17/300], Train Loss: 0.007067
Validation Loss: 0.00462666
Epoch [18/300], Train Loss: 0.005209
Validation Loss: 0.00421394
Epoch [19/300], Train Loss: 0.004629
Validation Loss: 0.00254113
Epoch [20/300], Train Loss: 0.004127
Validation Loss: 0.00232635
Epoch [21/300], Train Loss: 0.003209
Validation Loss: 0.00258334
Epoch [22/300], Train Loss: 0.003571
Validation Loss: 0.00251214
Epoch [23/300], Train Loss: 0.002948
Validation Loss: 0.00186672
Epoch [24/300], Train Loss: 0.002785
Validation Loss: 0.00179404
Epoch [25/300], Train Loss: 0.002755
Validation Loss: 0.00202426
Epoch [26/300], Train Loss: 0.002706
Validation Loss: 0.00177217
Epoch [27/300], Train Loss: 0.002686
Validation Loss: 0.00181468
Epoch [28/300], Train Loss: 0.002698
Validation Loss: 0.00202123
Epoch [29/300], Train Loss: 0.002559
Validation Loss: 0.00181903
Epoch [30/300], Train Loss: 0.002541
Validation Loss: 0.00184443
Epoch [31/300], Train Loss: 0.002427
Validation Loss: 0.00183644
Epoch [32/300], Train Loss: 0.002501
Validation Loss: 0.00178791
Epoch [33/300], Train Loss: 0.002461
Validation Loss: 0.00179404
Epoch [34/300], Train Loss: 0.002500
Validation Loss: 0.00184697
Epoch [35/300], Train Loss: 0.002459
Validation Loss: 0.00175793
Epoch [36/300], Train Loss: 0.002442
Validation Loss: 0.00175096
Epoch [37/300], Train Loss: 0.002377
Validation Loss: 0.00173256
Epoch [38/300], Train Loss: 0.002157
Validation Loss: 0.00168861
Epoch [39/300], Train Loss: 0.002092
Validation Loss: 0.00159993
Epoch [40/300], Train Loss: 0.001982
Validation Loss: 0.00160202
Epoch [41/300], Train Loss: 0.001844
Validation Loss: 0.00151057
Epoch [42/300], Train Loss: 0.001921
Validation Loss: 0.00168077
Epoch [43/300], Train Loss: 0.002197
Validation Loss: 0.00165287
Epoch [44/300], Train Loss: 0.002210
Validation Loss: 0.00182979
Epoch [45/300], Train Loss: 0.002048
Validation Loss: 0.00176534
Epoch [46/300], Train Loss: 0.002040
Validation Loss: 0.00186606
Epoch [47/300], Train Loss: 0.001956
Validation Loss: 0.00171179
Epoch [48/300], Train Loss: 0.001753
Validation Loss: 0.00144772
Epoch [49/300], Train Loss: 0.001633
Validation Loss: 0.00136483
Epoch [50/300], Train Loss: 0.001700
Validation Loss: 0.00116487
Epoch [51/300], Train Loss: 0.001637
Validation Loss: 0.00149160
Epoch [52/300], Train Loss: 0.001618
Validation Loss: 0.00154665
Epoch [53/300], Train Loss: 0.001580
Validation Loss: 0.00128664
Epoch [54/300], Train Loss: 0.001497
Validation Loss: 0.00119526
Epoch [55/300], Train Loss: 0.001446
Validation Loss: 0.00169882
Epoch [56/300], Train Loss: 0.001617
Validation Loss: 0.00089130
Epoch [57/300], Train Loss: 0.001704
Validation Loss: 0.00163545
Epoch [58/300], Train Loss: 0.002770
Validation Loss: 0.00274543
Epoch [59/300], Train Loss: 0.002764
Validation Loss: 0.00234678
Epoch [60/300], Train Loss: 0.002454
Validation Loss: 0.00231892
Epoch [61/300], Train Loss: 0.002572
Validation Loss: 0.00224574
Epoch [62/300], Train Loss: 0.002141
Validation Loss: 0.00218459
Epoch [63/300], Train Loss: 0.002131
Validation Loss: 0.00205541
Epoch [64/300], Train Loss: 0.002130
Validation Loss: 0.00198521
Epoch [65/300], Train Loss: 0.001964
Validation Loss: 0.00179499
Epoch [66/300], Train Loss: 0.001768
Validation Loss: 0.00174016
Early stopping triggered

Evaluating model for: Dryer
Run 72/72 completed in 277.33 seconds with: {'MAE': np.float32(3.9382846), 'MSE': np.float32(968.77246), 'RMSE': np.float32(31.12511), 'SAE': np.float32(0.3730679), 'NDE': np.float32(0.4867487)}
    hidden_size  seq_length  stride  num_layers  eval_result
50          512         120    0.25           4     2.061563
25          256         120    0.25           3     2.196939
66          512         720    0.25           4     2.261514
70          512         720    0.50           4     2.323736
3           128         120    0.25           5     2.616359
..          ...         ...     ...         ...          ...
36          256         360    0.50           2    13.127030
65          512         720    0.25           3    13.175412
35          256         360    0.25           5    13.659948
12          128         360    0.50           2    14.344554
23          128         720    0.50           5    27.807644

[72 rows x 5 columns]
