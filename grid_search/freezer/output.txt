Using device: cuda

Run 1/72: hidden=128, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Freezer
Dataset length: 14022 windows

Epoch [1/300], Train Loss: 0.007476
Validation Loss: 0.00581181
Epoch [2/300], Train Loss: 0.005924
Validation Loss: 0.00556905
Epoch [3/300], Train Loss: 0.005340
Validation Loss: 0.00472197
Epoch [4/300], Train Loss: 0.004507
Validation Loss: 0.00397165
Epoch [5/300], Train Loss: 0.003380
Validation Loss: 0.00283915
Epoch [6/300], Train Loss: 0.002771
Validation Loss: 0.00262802
Epoch [7/300], Train Loss: 0.002592
Validation Loss: 0.00251896
Epoch [8/300], Train Loss: 0.002486
Validation Loss: 0.00248492
Epoch [9/300], Train Loss: 0.002415
Validation Loss: 0.00238366
Epoch [10/300], Train Loss: 0.002184
Validation Loss: 0.00205109
Epoch [11/300], Train Loss: 0.001986
Validation Loss: 0.00192310
Epoch [12/300], Train Loss: 0.001946
Validation Loss: 0.00191243
Epoch [13/300], Train Loss: 0.001907
Validation Loss: 0.00186283
Epoch [14/300], Train Loss: 0.001874
Validation Loss: 0.00184276
Epoch [15/300], Train Loss: 0.001859
Validation Loss: 0.00182924
Epoch [16/300], Train Loss: 0.001834
Validation Loss: 0.00182045
Epoch [17/300], Train Loss: 0.001816
Validation Loss: 0.00180317
Epoch [18/300], Train Loss: 0.001797
Validation Loss: 0.00182182
Epoch [19/300], Train Loss: 0.001789
Validation Loss: 0.00179137
Epoch [20/300], Train Loss: 0.001768
Validation Loss: 0.00178098
Epoch [21/300], Train Loss: 0.001758
Validation Loss: 0.00174199
Epoch [22/300], Train Loss: 0.001742
Validation Loss: 0.00173016
Epoch [23/300], Train Loss: 0.001722
Validation Loss: 0.00175203
Epoch [24/300], Train Loss: 0.001718
Validation Loss: 0.00170706
Epoch [25/300], Train Loss: 0.001699
Validation Loss: 0.00170109
Epoch [26/300], Train Loss: 0.001688
Validation Loss: 0.00171352
Epoch [27/300], Train Loss: 0.001680
Validation Loss: 0.00167006
Epoch [28/300], Train Loss: 0.001656
Validation Loss: 0.00176483
Epoch [29/300], Train Loss: 0.001651
Validation Loss: 0.00164398
Epoch [30/300], Train Loss: 0.001643
Validation Loss: 0.00163448
Epoch [31/300], Train Loss: 0.001627
Validation Loss: 0.00161426
Epoch [32/300], Train Loss: 0.001633
Validation Loss: 0.00161722
Epoch [33/300], Train Loss: 0.001606
Validation Loss: 0.00161695
Epoch [34/300], Train Loss: 0.001595
Validation Loss: 0.00158146
Epoch [35/300], Train Loss: 0.001578
Validation Loss: 0.00157952
Epoch [36/300], Train Loss: 0.001578
Validation Loss: 0.00158465
Epoch [37/300], Train Loss: 0.001569
Validation Loss: 0.00155647
Epoch [38/300], Train Loss: 0.001568
Validation Loss: 0.00156533
Epoch [39/300], Train Loss: 0.001574
Validation Loss: 0.00156921
Epoch [40/300], Train Loss: 0.001546
Validation Loss: 0.00155421
Epoch [41/300], Train Loss: 0.001540
Validation Loss: 0.00151842
Epoch [42/300], Train Loss: 0.001531
Validation Loss: 0.00153737
Epoch [43/300], Train Loss: 0.001533
Validation Loss: 0.00154219
Epoch [44/300], Train Loss: 0.001512
Validation Loss: 0.00149334
Epoch [45/300], Train Loss: 0.001506
Validation Loss: 0.00148607
Epoch [46/300], Train Loss: 0.001490
Validation Loss: 0.00147849
Epoch [47/300], Train Loss: 0.001489
Validation Loss: 0.00152103
Epoch [48/300], Train Loss: 0.001475
Validation Loss: 0.00144562
Epoch [49/300], Train Loss: 0.001467
Validation Loss: 0.00145049
Epoch [50/300], Train Loss: 0.001451
Validation Loss: 0.00142296
Epoch [51/300], Train Loss: 0.001440
Validation Loss: 0.00146265
Epoch [52/300], Train Loss: 0.001425
Validation Loss: 0.00139776
Epoch [53/300], Train Loss: 0.001406
Validation Loss: 0.00138346
Epoch [54/300], Train Loss: 0.001397
Validation Loss: 0.00136053
Epoch [55/300], Train Loss: 0.001376
Validation Loss: 0.00132794
Epoch [56/300], Train Loss: 0.001346
Validation Loss: 0.00129396
Epoch [57/300], Train Loss: 0.001311
Validation Loss: 0.00125933
Epoch [58/300], Train Loss: 0.001297
Validation Loss: 0.00125025
Epoch [59/300], Train Loss: 0.001255
Validation Loss: 0.00117427
Epoch [60/300], Train Loss: 0.001195
Validation Loss: 0.00111466
Epoch [61/300], Train Loss: 0.001174
Validation Loss: 0.00108748
Epoch [62/300], Train Loss: 0.001116
Validation Loss: 0.00107273
Epoch [63/300], Train Loss: 0.001102
Validation Loss: 0.00104191
Epoch [64/300], Train Loss: 0.001076
Validation Loss: 0.00107475
Epoch [65/300], Train Loss: 0.001068
Validation Loss: 0.00102527
Epoch [66/300], Train Loss: 0.001041
Validation Loss: 0.00097245
Epoch [67/300], Train Loss: 0.001026
Validation Loss: 0.00099110
Epoch [68/300], Train Loss: 0.001011
Validation Loss: 0.00093717
Epoch [69/300], Train Loss: 0.001007
Validation Loss: 0.00093323
Epoch [70/300], Train Loss: 0.001000
Validation Loss: 0.00095168
Epoch [71/300], Train Loss: 0.000988
Validation Loss: 0.00094633
Epoch [72/300], Train Loss: 0.000974
Validation Loss: 0.00090599
Epoch [73/300], Train Loss: 0.000966
Validation Loss: 0.00090560
Epoch [74/300], Train Loss: 0.000959
Validation Loss: 0.00091952
Epoch [75/300], Train Loss: 0.000956
Validation Loss: 0.00089341
Epoch [76/300], Train Loss: 0.000948
Validation Loss: 0.00089221
Epoch [77/300], Train Loss: 0.000934
Validation Loss: 0.00088069
Epoch [78/300], Train Loss: 0.000937
Validation Loss: 0.00087452
Epoch [79/300], Train Loss: 0.000927
Validation Loss: 0.00088718
Epoch [80/300], Train Loss: 0.000924
Validation Loss: 0.00086807
Epoch [81/300], Train Loss: 0.000918
Validation Loss: 0.00085349
Epoch [82/300], Train Loss: 0.000915
Validation Loss: 0.00084892
Epoch [83/300], Train Loss: 0.000911
Validation Loss: 0.00092446
Epoch [84/300], Train Loss: 0.000916
Validation Loss: 0.00088541
Epoch [85/300], Train Loss: 0.000897
Validation Loss: 0.00083994
Epoch [86/300], Train Loss: 0.000897
Validation Loss: 0.00083346
Epoch [87/300], Train Loss: 0.000890
Validation Loss: 0.00083197
Epoch [88/300], Train Loss: 0.000883
Validation Loss: 0.00084766
Epoch [89/300], Train Loss: 0.000883
Validation Loss: 0.00085983
Epoch [90/300], Train Loss: 0.000876
Validation Loss: 0.00082753
Epoch [91/300], Train Loss: 0.000873
Validation Loss: 0.00081780
Epoch [92/300], Train Loss: 0.000870
Validation Loss: 0.00084850
Epoch [93/300], Train Loss: 0.000859
Validation Loss: 0.00081019
Epoch [94/300], Train Loss: 0.000861
Validation Loss: 0.00081149
Epoch [95/300], Train Loss: 0.000852
Validation Loss: 0.00081211
Epoch [96/300], Train Loss: 0.000857
Validation Loss: 0.00080682
Epoch [97/300], Train Loss: 0.000854
Validation Loss: 0.00079720
Epoch [98/300], Train Loss: 0.000855
Validation Loss: 0.00079886
Epoch [99/300], Train Loss: 0.000848
Validation Loss: 0.00080338
Epoch [100/300], Train Loss: 0.000842
Validation Loss: 0.00080847
Epoch [101/300], Train Loss: 0.000850
Validation Loss: 0.00081034
Epoch [102/300], Train Loss: 0.000843
Validation Loss: 0.00079260
Epoch [103/300], Train Loss: 0.000834
Validation Loss: 0.00076994
Epoch [104/300], Train Loss: 0.000825
Validation Loss: 0.00080723
Epoch [105/300], Train Loss: 0.000827
Validation Loss: 0.00081624
Epoch [106/300], Train Loss: 0.000824
Validation Loss: 0.00080424
Epoch [107/300], Train Loss: 0.000819
Validation Loss: 0.00077118
Epoch [108/300], Train Loss: 0.000823
Validation Loss: 0.00076590
Epoch [109/300], Train Loss: 0.000808
Validation Loss: 0.00078278
Epoch [110/300], Train Loss: 0.000813
Validation Loss: 0.00080979
Epoch [111/300], Train Loss: 0.000805
Validation Loss: 0.00076555
Epoch [112/300], Train Loss: 0.000811
Validation Loss: 0.00081674
Epoch [113/300], Train Loss: 0.000807
Validation Loss: 0.00075235
Epoch [114/300], Train Loss: 0.000798
Validation Loss: 0.00075503
Epoch [115/300], Train Loss: 0.000794
Validation Loss: 0.00075654
Epoch [116/300], Train Loss: 0.000801
Validation Loss: 0.00074556
Epoch [117/300], Train Loss: 0.000793
Validation Loss: 0.00079600
Epoch [118/300], Train Loss: 0.000795
Validation Loss: 0.00073474
Epoch [119/300], Train Loss: 0.000787
Validation Loss: 0.00074569
Epoch [120/300], Train Loss: 0.000787
Validation Loss: 0.00075320
Epoch [121/300], Train Loss: 0.000783
Validation Loss: 0.00072803
Epoch [122/300], Train Loss: 0.000779
Validation Loss: 0.00072223
Epoch [123/300], Train Loss: 0.000778
Validation Loss: 0.00072564
Epoch [124/300], Train Loss: 0.000777
Validation Loss: 0.00072101
Epoch [125/300], Train Loss: 0.000771
Validation Loss: 0.00071625
Epoch [126/300], Train Loss: 0.000770
Validation Loss: 0.00071793
Epoch [127/300], Train Loss: 0.000769
Validation Loss: 0.00071365
Epoch [128/300], Train Loss: 0.000773
Validation Loss: 0.00073147
Epoch [129/300], Train Loss: 0.000764
Validation Loss: 0.00070597
Epoch [130/300], Train Loss: 0.000766
Validation Loss: 0.00070470
Epoch [131/300], Train Loss: 0.000767
Validation Loss: 0.00073653
Epoch [132/300], Train Loss: 0.000758
Validation Loss: 0.00075748
Epoch [133/300], Train Loss: 0.000757
Validation Loss: 0.00070100
Epoch [134/300], Train Loss: 0.000751
Validation Loss: 0.00074900
Epoch [135/300], Train Loss: 0.000753
Validation Loss: 0.00078474
Epoch [136/300], Train Loss: 0.000751
Validation Loss: 0.00069717
Epoch [137/300], Train Loss: 0.000751
Validation Loss: 0.00069884
Epoch [138/300], Train Loss: 0.000749
Validation Loss: 0.00068504
Epoch [139/300], Train Loss: 0.000744
Validation Loss: 0.00069940
Epoch [140/300], Train Loss: 0.000745
Validation Loss: 0.00068589
Epoch [141/300], Train Loss: 0.000745
Validation Loss: 0.00068412
Epoch [142/300], Train Loss: 0.000750
Validation Loss: 0.00069751
Epoch [143/300], Train Loss: 0.000742
Validation Loss: 0.00070250
Epoch [144/300], Train Loss: 0.000732
Validation Loss: 0.00068805
Epoch [145/300], Train Loss: 0.000734
Validation Loss: 0.00069246
Epoch [146/300], Train Loss: 0.000732
Validation Loss: 0.00067435
Epoch [147/300], Train Loss: 0.000730
Validation Loss: 0.00068170
Epoch [148/300], Train Loss: 0.000740
Validation Loss: 0.00068641
Epoch [149/300], Train Loss: 0.000726
Validation Loss: 0.00070213
Epoch [150/300], Train Loss: 0.000727
Validation Loss: 0.00069026
Epoch [151/300], Train Loss: 0.000730
Validation Loss: 0.00072748
Epoch [152/300], Train Loss: 0.000725
Validation Loss: 0.00066846
Epoch [153/300], Train Loss: 0.000728
Validation Loss: 0.00070181
Epoch [154/300], Train Loss: 0.000723
Validation Loss: 0.00070019
Epoch [155/300], Train Loss: 0.000726
Validation Loss: 0.00066494
Epoch [156/300], Train Loss: 0.000716
Validation Loss: 0.00067194
Epoch [157/300], Train Loss: 0.000714
Validation Loss: 0.00066702
Epoch [158/300], Train Loss: 0.000717
Validation Loss: 0.00065816
Epoch [159/300], Train Loss: 0.000714
Validation Loss: 0.00068182
Epoch [160/300], Train Loss: 0.000715
Validation Loss: 0.00066915
Epoch [161/300], Train Loss: 0.000713
Validation Loss: 0.00065604
Epoch [162/300], Train Loss: 0.000713
Validation Loss: 0.00069142
Epoch [163/300], Train Loss: 0.000712
Validation Loss: 0.00068012
Epoch [164/300], Train Loss: 0.000708
Validation Loss: 0.00070640
Epoch [165/300], Train Loss: 0.000707
Validation Loss: 0.00065949
Epoch [166/300], Train Loss: 0.000703
Validation Loss: 0.00064956
Epoch [167/300], Train Loss: 0.000702
Validation Loss: 0.00065546
Epoch [168/300], Train Loss: 0.000706
Validation Loss: 0.00064951
Epoch [169/300], Train Loss: 0.000701
Validation Loss: 0.00066352
Epoch [170/300], Train Loss: 0.000710
Validation Loss: 0.00065177
Epoch [171/300], Train Loss: 0.000702
Validation Loss: 0.00065215
Epoch [172/300], Train Loss: 0.000697
Validation Loss: 0.00064505
Epoch [173/300], Train Loss: 0.000700
Validation Loss: 0.00065400
Epoch [174/300], Train Loss: 0.000693
Validation Loss: 0.00064070
Epoch [175/300], Train Loss: 0.000695
Validation Loss: 0.00063653
Epoch [176/300], Train Loss: 0.000689
Validation Loss: 0.00064735
Epoch [177/300], Train Loss: 0.000690
Validation Loss: 0.00068816
Epoch [178/300], Train Loss: 0.000689
Validation Loss: 0.00063780
Epoch [179/300], Train Loss: 0.000692
Validation Loss: 0.00064589
Epoch [180/300], Train Loss: 0.000685
Validation Loss: 0.00073785
Epoch [181/300], Train Loss: 0.000692
Validation Loss: 0.00064357
Epoch [182/300], Train Loss: 0.000684
Validation Loss: 0.00063668
Epoch [183/300], Train Loss: 0.000689
Validation Loss: 0.00063600
Epoch [184/300], Train Loss: 0.000686
Validation Loss: 0.00062854
Epoch [185/300], Train Loss: 0.000681
Validation Loss: 0.00070972
Epoch [186/300], Train Loss: 0.000688
Validation Loss: 0.00062635
Epoch [187/300], Train Loss: 0.000680
Validation Loss: 0.00063686
Epoch [188/300], Train Loss: 0.000677
Validation Loss: 0.00064878
Epoch [189/300], Train Loss: 0.000675
Validation Loss: 0.00064734
Epoch [190/300], Train Loss: 0.000679
Validation Loss: 0.00064080
Epoch [191/300], Train Loss: 0.000674
Validation Loss: 0.00062655
Epoch [192/300], Train Loss: 0.000673
Validation Loss: 0.00061808
Epoch [193/300], Train Loss: 0.000673
Validation Loss: 0.00062111
Epoch [194/300], Train Loss: 0.000674
Validation Loss: 0.00062691
Epoch [195/300], Train Loss: 0.000681
Validation Loss: 0.00063662
Epoch [196/300], Train Loss: 0.000673
Validation Loss: 0.00062919
Epoch [197/300], Train Loss: 0.000671
Validation Loss: 0.00061809
Epoch [198/300], Train Loss: 0.000669
Validation Loss: 0.00061649
Epoch [199/300], Train Loss: 0.000671
Validation Loss: 0.00064225
Epoch [200/300], Train Loss: 0.000675
Validation Loss: 0.00064674
Epoch [201/300], Train Loss: 0.000671
Validation Loss: 0.00063479
Epoch [202/300], Train Loss: 0.000668
Validation Loss: 0.00071643
Epoch [203/300], Train Loss: 0.000680
Validation Loss: 0.00064858
Epoch [204/300], Train Loss: 0.000670
Validation Loss: 0.00061946
Epoch [205/300], Train Loss: 0.000665
Validation Loss: 0.00061674
Epoch [206/300], Train Loss: 0.000664
Validation Loss: 0.00062558
Epoch [207/300], Train Loss: 0.000663
Validation Loss: 0.00060794
Epoch [208/300], Train Loss: 0.000674
Validation Loss: 0.00062506
Epoch [209/300], Train Loss: 0.000671
Validation Loss: 0.00062794
Epoch [210/300], Train Loss: 0.000664
Validation Loss: 0.00068618
Epoch [211/300], Train Loss: 0.000671
Validation Loss: 0.00061272
Epoch [212/300], Train Loss: 0.000662
Validation Loss: 0.00060810
Epoch [213/300], Train Loss: 0.000662
Validation Loss: 0.00061159
Epoch [214/300], Train Loss: 0.000661
Validation Loss: 0.00062083
Epoch [215/300], Train Loss: 0.000661
Validation Loss: 0.00062060
Epoch [216/300], Train Loss: 0.000659
Validation Loss: 0.00060396
Epoch [217/300], Train Loss: 0.000654
Validation Loss: 0.00061516
Epoch [218/300], Train Loss: 0.000661
Validation Loss: 0.00062045
Epoch [219/300], Train Loss: 0.000658
Validation Loss: 0.00062025
Epoch [220/300], Train Loss: 0.000654
Validation Loss: 0.00060615
Epoch [221/300], Train Loss: 0.000653
Validation Loss: 0.00061534
Epoch [222/300], Train Loss: 0.000673
Validation Loss: 0.00060784
Epoch [223/300], Train Loss: 0.000657
Validation Loss: 0.00061357
Epoch [224/300], Train Loss: 0.000656
Validation Loss: 0.00061079
Epoch [225/300], Train Loss: 0.000656
Validation Loss: 0.00060130
Epoch [226/300], Train Loss: 0.000651
Validation Loss: 0.00062146
Epoch [227/300], Train Loss: 0.000654
Validation Loss: 0.00061030
Epoch [228/300], Train Loss: 0.000649
Validation Loss: 0.00061083
Epoch [229/300], Train Loss: 0.000651
Validation Loss: 0.00061217
Epoch [230/300], Train Loss: 0.000648
Validation Loss: 0.00060718
Epoch [231/300], Train Loss: 0.000659
Validation Loss: 0.00060579
Epoch [232/300], Train Loss: 0.000650
Validation Loss: 0.00061084
Epoch [233/300], Train Loss: 0.000648
Validation Loss: 0.00060529
Epoch [234/300], Train Loss: 0.000651
Validation Loss: 0.00062733
Epoch [235/300], Train Loss: 0.000652
Validation Loss: 0.00059611
Epoch [236/300], Train Loss: 0.000657
Validation Loss: 0.00066839
Epoch [237/300], Train Loss: 0.000647
Validation Loss: 0.00060394
Epoch [238/300], Train Loss: 0.000647
Validation Loss: 0.00061276
Epoch [239/300], Train Loss: 0.000642
Validation Loss: 0.00060812
Epoch [240/300], Train Loss: 0.000645
Validation Loss: 0.00060307
Epoch [241/300], Train Loss: 0.000643
Validation Loss: 0.00061500
Epoch [242/300], Train Loss: 0.000641
Validation Loss: 0.00059508
Epoch [243/300], Train Loss: 0.000645
Validation Loss: 0.00059495
Epoch [244/300], Train Loss: 0.000643
Validation Loss: 0.00059048
Epoch [245/300], Train Loss: 0.000639
Validation Loss: 0.00059834
Epoch [246/300], Train Loss: 0.000642
Validation Loss: 0.00058893
Epoch [247/300], Train Loss: 0.000643
Validation Loss: 0.00059595
Epoch [248/300], Train Loss: 0.000642
Validation Loss: 0.00059894
Epoch [249/300], Train Loss: 0.000641
Validation Loss: 0.00063451
Epoch [250/300], Train Loss: 0.000640
Validation Loss: 0.00059165
Epoch [251/300], Train Loss: 0.000638
Validation Loss: 0.00059266
Epoch [252/300], Train Loss: 0.000638
Validation Loss: 0.00059241
Epoch [253/300], Train Loss: 0.000644
Validation Loss: 0.00060435
Epoch [254/300], Train Loss: 0.000639
Validation Loss: 0.00059545
Epoch [255/300], Train Loss: 0.000637
Validation Loss: 0.00058797
Epoch [256/300], Train Loss: 0.000636
Validation Loss: 0.00061468
Epoch [257/300], Train Loss: 0.000635
Validation Loss: 0.00058712
Epoch [258/300], Train Loss: 0.000637
Validation Loss: 0.00058657
Epoch [259/300], Train Loss: 0.000634
Validation Loss: 0.00058575
Epoch [260/300], Train Loss: 0.000635
Validation Loss: 0.00058423
Epoch [261/300], Train Loss: 0.000639
Validation Loss: 0.00060021
Epoch [262/300], Train Loss: 0.000635
Validation Loss: 0.00058717
Epoch [263/300], Train Loss: 0.000635
Validation Loss: 0.00058799
Epoch [264/300], Train Loss: 0.000631
Validation Loss: 0.00059122
Epoch [265/300], Train Loss: 0.000633
Validation Loss: 0.00058920
Epoch [266/300], Train Loss: 0.000632
Validation Loss: 0.00058831
Epoch [267/300], Train Loss: 0.000634
Validation Loss: 0.00058633
Epoch [268/300], Train Loss: 0.000633
Validation Loss: 0.00059058
Epoch [269/300], Train Loss: 0.000633
Validation Loss: 0.00058183
Epoch [270/300], Train Loss: 0.000630
Validation Loss: 0.00058392
Epoch [271/300], Train Loss: 0.000633
Validation Loss: 0.00058338
Epoch [272/300], Train Loss: 0.000632
Validation Loss: 0.00058169
Epoch [273/300], Train Loss: 0.000630
Validation Loss: 0.00058547
Epoch [274/300], Train Loss: 0.000631
Validation Loss: 0.00058487
Epoch [275/300], Train Loss: 0.000630
Validation Loss: 0.00060245
Epoch [276/300], Train Loss: 0.000631
Validation Loss: 0.00058103
Epoch [277/300], Train Loss: 0.000630
Validation Loss: 0.00058763
Epoch [278/300], Train Loss: 0.000628
Validation Loss: 0.00057671
Epoch [279/300], Train Loss: 0.000624
Validation Loss: 0.00058277
Epoch [280/300], Train Loss: 0.000631
Validation Loss: 0.00058030
Epoch [281/300], Train Loss: 0.000626
Validation Loss: 0.00057983
Epoch [282/300], Train Loss: 0.000625
Validation Loss: 0.00058556
Epoch [283/300], Train Loss: 0.000626
Validation Loss: 0.00057975
Epoch [284/300], Train Loss: 0.000626
Validation Loss: 0.00061183
Epoch [285/300], Train Loss: 0.000627
Validation Loss: 0.00057990
Epoch [286/300], Train Loss: 0.000626
Validation Loss: 0.00057959
Epoch [287/300], Train Loss: 0.000629
Validation Loss: 0.00058572
Epoch [288/300], Train Loss: 0.000625
Validation Loss: 0.00057274
Epoch [289/300], Train Loss: 0.000627
Validation Loss: 0.00057292
Epoch [290/300], Train Loss: 0.000623
Validation Loss: 0.00059124
Epoch [291/300], Train Loss: 0.000623
Validation Loss: 0.00057673
Epoch [292/300], Train Loss: 0.000624
Validation Loss: 0.00057677
Epoch [293/300], Train Loss: 0.000621
Validation Loss: 0.00057389
Epoch [294/300], Train Loss: 0.000622
Validation Loss: 0.00057121
Epoch [295/300], Train Loss: 0.000622
Validation Loss: 0.00058835
Epoch [296/300], Train Loss: 0.000622
Validation Loss: 0.00057430
Epoch [297/300], Train Loss: 0.000629
Validation Loss: 0.00058532
Epoch [298/300], Train Loss: 0.000621
Validation Loss: 0.00057026
Epoch [299/300], Train Loss: 0.000624
Validation Loss: 0.00058420
Epoch [300/300], Train Loss: 0.000620
Validation Loss: 0.00057421

Evaluating model for: Freezer
Run 1/72 completed in 3771.05 seconds with: {'MAE': np.float32(20.542892), 'MSE': np.float32(953.45337), 'RMSE': np.float32(30.87804), 'SAE': np.float32(0.0136254355), 'NDE': np.float32(0.23414885)}

Run 2/72: hidden=128, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Freezer
Dataset length: 14022 windows

Epoch [1/300], Train Loss: 0.007939
Validation Loss: 0.00582150
Epoch [2/300], Train Loss: 0.005877
Validation Loss: 0.00537731
Epoch [3/300], Train Loss: 0.004819
Validation Loss: 0.00400818
Epoch [4/300], Train Loss: 0.003307
Validation Loss: 0.00255813
Epoch [5/300], Train Loss: 0.002473
Validation Loss: 0.00232849
Epoch [6/300], Train Loss: 0.002256
Validation Loss: 0.00216387
Epoch [7/300], Train Loss: 0.002091
Validation Loss: 0.00205609
Epoch [8/300], Train Loss: 0.001999
Validation Loss: 0.00197906
Epoch [9/300], Train Loss: 0.001954
Validation Loss: 0.00193042
Epoch [10/300], Train Loss: 0.001923
Validation Loss: 0.00194948
Epoch [11/300], Train Loss: 0.001879
Validation Loss: 0.00187538
Epoch [12/300], Train Loss: 0.001869
Validation Loss: 0.00191290
Epoch [13/300], Train Loss: 0.001833
Validation Loss: 0.00182389
Epoch [14/300], Train Loss: 0.001805
Validation Loss: 0.00180553
Epoch [15/300], Train Loss: 0.001787
Validation Loss: 0.00180074
Epoch [16/300], Train Loss: 0.001765
Validation Loss: 0.00176191
Epoch [17/300], Train Loss: 0.001749
Validation Loss: 0.00174726
Epoch [18/300], Train Loss: 0.001725
Validation Loss: 0.00172955
Epoch [19/300], Train Loss: 0.001722
Validation Loss: 0.00172617
Epoch [20/300], Train Loss: 0.001708
Validation Loss: 0.00170678
Epoch [21/300], Train Loss: 0.001701
Validation Loss: 0.00168994
Epoch [22/300], Train Loss: 0.001689
Validation Loss: 0.00169192
Epoch [23/300], Train Loss: 0.001680
Validation Loss: 0.00166467
Epoch [24/300], Train Loss: 0.001670
Validation Loss: 0.00166756
Epoch [25/300], Train Loss: 0.001658
Validation Loss: 0.00164390
Epoch [26/300], Train Loss: 0.001646
Validation Loss: 0.00163355
Epoch [27/300], Train Loss: 0.001644
Validation Loss: 0.00166439
Epoch [28/300], Train Loss: 0.001635
Validation Loss: 0.00166646
Epoch [29/300], Train Loss: 0.001624
Validation Loss: 0.00160537
Epoch [30/300], Train Loss: 0.001608
Validation Loss: 0.00159649
Epoch [31/300], Train Loss: 0.001603
Validation Loss: 0.00159162
Epoch [32/300], Train Loss: 0.001597
Validation Loss: 0.00158963
Epoch [33/300], Train Loss: 0.001582
Validation Loss: 0.00156043
Epoch [34/300], Train Loss: 0.001575
Validation Loss: 0.00154660
Epoch [35/300], Train Loss: 0.001560
Validation Loss: 0.00154617
Epoch [36/300], Train Loss: 0.001559
Validation Loss: 0.00153862
Epoch [37/300], Train Loss: 0.001543
Validation Loss: 0.00153508
Epoch [38/300], Train Loss: 0.001542
Validation Loss: 0.00152469
Epoch [39/300], Train Loss: 0.001543
Validation Loss: 0.00154436
Epoch [40/300], Train Loss: 0.001528
Validation Loss: 0.00151967
Epoch [41/300], Train Loss: 0.001526
Validation Loss: 0.00151012
Epoch [42/300], Train Loss: 0.001524
Validation Loss: 0.00150484
Epoch [43/300], Train Loss: 0.001525
Validation Loss: 0.00152492
Epoch [44/300], Train Loss: 0.001520
Validation Loss: 0.00150193
Epoch [45/300], Train Loss: 0.001509
Validation Loss: 0.00150817
Epoch [46/300], Train Loss: 0.001507
Validation Loss: 0.00149116
Epoch [47/300], Train Loss: 0.001497
Validation Loss: 0.00150722
Epoch [48/300], Train Loss: 0.001503
Validation Loss: 0.00147454
Epoch [49/300], Train Loss: 0.001491
Validation Loss: 0.00159022
Epoch [50/300], Train Loss: 0.001490
Validation Loss: 0.00146670
Epoch [51/300], Train Loss: 0.001489
Validation Loss: 0.00147992
Epoch [52/300], Train Loss: 0.001475
Validation Loss: 0.00146964
Epoch [53/300], Train Loss: 0.001475
Validation Loss: 0.00151491
Epoch [54/300], Train Loss: 0.001484
Validation Loss: 0.00147097
Epoch [55/300], Train Loss: 0.001471
Validation Loss: 0.00145808
Epoch [56/300], Train Loss: 0.001463
Validation Loss: 0.00146888
Epoch [57/300], Train Loss: 0.001462
Validation Loss: 0.00144294
Epoch [58/300], Train Loss: 0.001466
Validation Loss: 0.00145179
Epoch [59/300], Train Loss: 0.001459
Validation Loss: 0.00144109
Epoch [60/300], Train Loss: 0.001454
Validation Loss: 0.00147394
Epoch [61/300], Train Loss: 0.001452
Validation Loss: 0.00143969
Epoch [62/300], Train Loss: 0.001446
Validation Loss: 0.00143816
Epoch [63/300], Train Loss: 0.001448
Validation Loss: 0.00142774
Epoch [64/300], Train Loss: 0.001445
Validation Loss: 0.00141962
Epoch [65/300], Train Loss: 0.001445
Validation Loss: 0.00142885
Epoch [66/300], Train Loss: 0.001450
Validation Loss: 0.00142435
Epoch [67/300], Train Loss: 0.001439
Validation Loss: 0.00143443
Epoch [68/300], Train Loss: 0.001432
Validation Loss: 0.00142466
Epoch [69/300], Train Loss: 0.001431
Validation Loss: 0.00141606
Epoch [70/300], Train Loss: 0.001424
Validation Loss: 0.00141200
Epoch [71/300], Train Loss: 0.001420
Validation Loss: 0.00141024
Epoch [72/300], Train Loss: 0.001428
Validation Loss: 0.00142452
Epoch [73/300], Train Loss: 0.001424
Validation Loss: 0.00140026
Epoch [74/300], Train Loss: 0.001415
Validation Loss: 0.00140029
Epoch [75/300], Train Loss: 0.001409
Validation Loss: 0.00140422
Epoch [76/300], Train Loss: 0.001409
Validation Loss: 0.00139030
Epoch [77/300], Train Loss: 0.001403
Validation Loss: 0.00140837
Epoch [78/300], Train Loss: 0.001401
Validation Loss: 0.00138668
Epoch [79/300], Train Loss: 0.001397
Validation Loss: 0.00138537
Epoch [80/300], Train Loss: 0.001386
Validation Loss: 0.00137208
Epoch [81/300], Train Loss: 0.001382
Validation Loss: 0.00138133
Epoch [82/300], Train Loss: 0.001379
Validation Loss: 0.00135153
Epoch [83/300], Train Loss: 0.001369
Validation Loss: 0.00134691
Epoch [84/300], Train Loss: 0.001370
Validation Loss: 0.00134983
Epoch [85/300], Train Loss: 0.001354
Validation Loss: 0.00133871
Epoch [86/300], Train Loss: 0.001347
Validation Loss: 0.00131697
Epoch [87/300], Train Loss: 0.001326
Validation Loss: 0.00129111
Epoch [88/300], Train Loss: 0.001307
Validation Loss: 0.00126226
Epoch [89/300], Train Loss: 0.001281
Validation Loss: 0.00122052
Epoch [90/300], Train Loss: 0.001233
Validation Loss: 0.00115777
Epoch [91/300], Train Loss: 0.001179
Validation Loss: 0.00108574
Epoch [92/300], Train Loss: 0.001104
Validation Loss: 0.00099808
Epoch [93/300], Train Loss: 0.001036
Validation Loss: 0.00094637
Epoch [94/300], Train Loss: 0.001008
Validation Loss: 0.00092914
Epoch [95/300], Train Loss: 0.000990
Validation Loss: 0.00091085
Epoch [96/300], Train Loss: 0.000971
Validation Loss: 0.00089350
Epoch [97/300], Train Loss: 0.000968
Validation Loss: 0.00089737
Epoch [98/300], Train Loss: 0.000960
Validation Loss: 0.00089002
Epoch [99/300], Train Loss: 0.000954
Validation Loss: 0.00096648
Epoch [100/300], Train Loss: 0.000943
Validation Loss: 0.00089392
Epoch [101/300], Train Loss: 0.000933
Validation Loss: 0.00086743
Epoch [102/300], Train Loss: 0.000926
Validation Loss: 0.00085448
Epoch [103/300], Train Loss: 0.000914
Validation Loss: 0.00084191
Epoch [104/300], Train Loss: 0.000907
Validation Loss: 0.00086809
Epoch [105/300], Train Loss: 0.000901
Validation Loss: 0.00086058
Epoch [106/300], Train Loss: 0.000894
Validation Loss: 0.00083651
Epoch [107/300], Train Loss: 0.000889
Validation Loss: 0.00082182
Epoch [108/300], Train Loss: 0.000888
Validation Loss: 0.00081693
Epoch [109/300], Train Loss: 0.000877
Validation Loss: 0.00080956
Epoch [110/300], Train Loss: 0.000874
Validation Loss: 0.00080721
Epoch [111/300], Train Loss: 0.000872
Validation Loss: 0.00084655
Epoch [112/300], Train Loss: 0.000869
Validation Loss: 0.00082657
Epoch [113/300], Train Loss: 0.000859
Validation Loss: 0.00079405
Epoch [114/300], Train Loss: 0.000857
Validation Loss: 0.00079582
Epoch [115/300], Train Loss: 0.000849
Validation Loss: 0.00078811
Epoch [116/300], Train Loss: 0.000846
Validation Loss: 0.00079800
Epoch [117/300], Train Loss: 0.000850
Validation Loss: 0.00081611
Epoch [118/300], Train Loss: 0.000842
Validation Loss: 0.00077590
Epoch [119/300], Train Loss: 0.000833
Validation Loss: 0.00078357
Epoch [120/300], Train Loss: 0.000828
Validation Loss: 0.00076955
Epoch [121/300], Train Loss: 0.000824
Validation Loss: 0.00076876
Epoch [122/300], Train Loss: 0.000817
Validation Loss: 0.00077108
Epoch [123/300], Train Loss: 0.000822
Validation Loss: 0.00075888
Epoch [124/300], Train Loss: 0.000815
Validation Loss: 0.00076534
Epoch [125/300], Train Loss: 0.000809
Validation Loss: 0.00074751
Epoch [126/300], Train Loss: 0.000806
Validation Loss: 0.00076325
Epoch [127/300], Train Loss: 0.000802
Validation Loss: 0.00073987
Epoch [128/300], Train Loss: 0.000795
Validation Loss: 0.00073675
Epoch [129/300], Train Loss: 0.000791
Validation Loss: 0.00072962
Epoch [130/300], Train Loss: 0.000790
Validation Loss: 0.00073717
Epoch [131/300], Train Loss: 0.000785
Validation Loss: 0.00072403
Epoch [132/300], Train Loss: 0.000781
Validation Loss: 0.00072322
Epoch [133/300], Train Loss: 0.000782
Validation Loss: 0.00074914
Epoch [134/300], Train Loss: 0.000779
Validation Loss: 0.00071556
Epoch [135/300], Train Loss: 0.000772
Validation Loss: 0.00073637
Epoch [136/300], Train Loss: 0.000772
Validation Loss: 0.00071572
Epoch [137/300], Train Loss: 0.000772
Validation Loss: 0.00072129
Epoch [138/300], Train Loss: 0.000764
Validation Loss: 0.00071561
Epoch [139/300], Train Loss: 0.000774
Validation Loss: 0.00074002
Epoch [140/300], Train Loss: 0.000764
Validation Loss: 0.00070007
Epoch [141/300], Train Loss: 0.000761
Validation Loss: 0.00070165
Epoch [142/300], Train Loss: 0.000755
Validation Loss: 0.00070133
Epoch [143/300], Train Loss: 0.000756
Validation Loss: 0.00072323
Epoch [144/300], Train Loss: 0.000752
Validation Loss: 0.00070650
Epoch [145/300], Train Loss: 0.000750
Validation Loss: 0.00070604
Epoch [146/300], Train Loss: 0.000749
Validation Loss: 0.00068697
Epoch [147/300], Train Loss: 0.000743
Validation Loss: 0.00069123
Epoch [148/300], Train Loss: 0.000751
Validation Loss: 0.00069389
Epoch [149/300], Train Loss: 0.000746
Validation Loss: 0.00070271
Epoch [150/300], Train Loss: 0.000744
Validation Loss: 0.00070051
Epoch [151/300], Train Loss: 0.000740
Validation Loss: 0.00067861
Epoch [152/300], Train Loss: 0.000741
Validation Loss: 0.00068397
Epoch [153/300], Train Loss: 0.000738
Validation Loss: 0.00068881
Epoch [154/300], Train Loss: 0.000734
Validation Loss: 0.00068997
Epoch [155/300], Train Loss: 0.000731
Validation Loss: 0.00068404
Epoch [156/300], Train Loss: 0.000730
Validation Loss: 0.00068550
Epoch [157/300], Train Loss: 0.000730
Validation Loss: 0.00067777
Epoch [158/300], Train Loss: 0.000727
Validation Loss: 0.00067030
Epoch [159/300], Train Loss: 0.000726
Validation Loss: 0.00068544
Epoch [160/300], Train Loss: 0.000726
Validation Loss: 0.00067704
Epoch [161/300], Train Loss: 0.000720
Validation Loss: 0.00068086
Epoch [162/300], Train Loss: 0.000723
Validation Loss: 0.00067681
Epoch [163/300], Train Loss: 0.000726
Validation Loss: 0.00066976
Epoch [164/300], Train Loss: 0.000718
Validation Loss: 0.00069716
Epoch [165/300], Train Loss: 0.000720
Validation Loss: 0.00067518
Epoch [166/300], Train Loss: 0.000712
Validation Loss: 0.00066319
Epoch [167/300], Train Loss: 0.000710
Validation Loss: 0.00066211
Epoch [168/300], Train Loss: 0.000708
Validation Loss: 0.00066331
Epoch [169/300], Train Loss: 0.000709
Validation Loss: 0.00066285
Epoch [170/300], Train Loss: 0.000708
Validation Loss: 0.00065952
Epoch [171/300], Train Loss: 0.000708
Validation Loss: 0.00066862
Epoch [172/300], Train Loss: 0.000708
Validation Loss: 0.00066630
Epoch [173/300], Train Loss: 0.000704
Validation Loss: 0.00065660
Epoch [174/300], Train Loss: 0.000704
Validation Loss: 0.00065515
Epoch [175/300], Train Loss: 0.000701
Validation Loss: 0.00067296
Epoch [176/300], Train Loss: 0.000712
Validation Loss: 0.00065580
Epoch [177/300], Train Loss: 0.000699
Validation Loss: 0.00065175
Epoch [178/300], Train Loss: 0.000700
Validation Loss: 0.00064925
Epoch [179/300], Train Loss: 0.000695
Validation Loss: 0.00067352
Epoch [180/300], Train Loss: 0.000695
Validation Loss: 0.00065924
Epoch [181/300], Train Loss: 0.000691
Validation Loss: 0.00065934
Epoch [182/300], Train Loss: 0.000690
Validation Loss: 0.00065045
Epoch [183/300], Train Loss: 0.000688
Validation Loss: 0.00065269
Epoch [184/300], Train Loss: 0.000689
Validation Loss: 0.00064477
Epoch [185/300], Train Loss: 0.000692
Validation Loss: 0.00064840
Epoch [186/300], Train Loss: 0.000691
Validation Loss: 0.00064561
Epoch [187/300], Train Loss: 0.000682
Validation Loss: 0.00065321
Epoch [188/300], Train Loss: 0.000684
Validation Loss: 0.00064851
Epoch [189/300], Train Loss: 0.000684
Validation Loss: 0.00064473
Epoch [190/300], Train Loss: 0.000680
Validation Loss: 0.00064503
Epoch [191/300], Train Loss: 0.000677
Validation Loss: 0.00063259
Epoch [192/300], Train Loss: 0.000674
Validation Loss: 0.00063185
Epoch [193/300], Train Loss: 0.000676
Validation Loss: 0.00063233
Epoch [194/300], Train Loss: 0.000673
Validation Loss: 0.00063661
Epoch [195/300], Train Loss: 0.000672
Validation Loss: 0.00062450
Epoch [196/300], Train Loss: 0.000676
Validation Loss: 0.00063698
Epoch [197/300], Train Loss: 0.000670
Validation Loss: 0.00062574
Epoch [198/300], Train Loss: 0.000667
Validation Loss: 0.00062754
Epoch [199/300], Train Loss: 0.000666
Validation Loss: 0.00062343
Epoch [200/300], Train Loss: 0.000669
Validation Loss: 0.00065146
Epoch [201/300], Train Loss: 0.000666
Validation Loss: 0.00062277
Epoch [202/300], Train Loss: 0.000667
Validation Loss: 0.00064111
Epoch [203/300], Train Loss: 0.000669
Validation Loss: 0.00062752
Epoch [204/300], Train Loss: 0.000662
Validation Loss: 0.00061551
Epoch [205/300], Train Loss: 0.000661
Validation Loss: 0.00062319
Epoch [206/300], Train Loss: 0.000658
Validation Loss: 0.00061805
Epoch [207/300], Train Loss: 0.000658
Validation Loss: 0.00061451
Epoch [208/300], Train Loss: 0.000664
Validation Loss: 0.00063562
Epoch [209/300], Train Loss: 0.000661
Validation Loss: 0.00061451
Epoch [210/300], Train Loss: 0.000658
Validation Loss: 0.00061935
Epoch [211/300], Train Loss: 0.000656
Validation Loss: 0.00060800
Epoch [212/300], Train Loss: 0.000653
Validation Loss: 0.00061650
Epoch [213/300], Train Loss: 0.000653
Validation Loss: 0.00061042
Epoch [214/300], Train Loss: 0.000652
Validation Loss: 0.00060605
Epoch [215/300], Train Loss: 0.000651
Validation Loss: 0.00060578
Epoch [216/300], Train Loss: 0.000648
Validation Loss: 0.00060188
Epoch [217/300], Train Loss: 0.000645
Validation Loss: 0.00060109
Epoch [218/300], Train Loss: 0.000645
Validation Loss: 0.00061017
Epoch [219/300], Train Loss: 0.000648
Validation Loss: 0.00060832
Epoch [220/300], Train Loss: 0.000646
Validation Loss: 0.00059784
Epoch [221/300], Train Loss: 0.000642
Validation Loss: 0.00060182
Epoch [222/300], Train Loss: 0.000642
Validation Loss: 0.00060769
Epoch [223/300], Train Loss: 0.000644
Validation Loss: 0.00060536
Epoch [224/300], Train Loss: 0.000644
Validation Loss: 0.00060832
Epoch [225/300], Train Loss: 0.000642
Validation Loss: 0.00060945
Epoch [226/300], Train Loss: 0.000641
Validation Loss: 0.00059331
Epoch [227/300], Train Loss: 0.000636
Validation Loss: 0.00060627
Epoch [228/300], Train Loss: 0.000634
Validation Loss: 0.00060277
Epoch [229/300], Train Loss: 0.000633
Validation Loss: 0.00059419
Epoch [230/300], Train Loss: 0.000633
Validation Loss: 0.00059993
Epoch [231/300], Train Loss: 0.000634
Validation Loss: 0.00059490
Epoch [232/300], Train Loss: 0.000634
Validation Loss: 0.00058578
Epoch [233/300], Train Loss: 0.000631
Validation Loss: 0.00058844
Epoch [234/300], Train Loss: 0.000634
Validation Loss: 0.00061442
Epoch [235/300], Train Loss: 0.000634
Validation Loss: 0.00058078
Epoch [236/300], Train Loss: 0.000632
Validation Loss: 0.00060422
Epoch [237/300], Train Loss: 0.000630
Validation Loss: 0.00058954
Epoch [238/300], Train Loss: 0.000632
Validation Loss: 0.00060134
Epoch [239/300], Train Loss: 0.000625
Validation Loss: 0.00060244
Epoch [240/300], Train Loss: 0.000626
Validation Loss: 0.00058643
Epoch [241/300], Train Loss: 0.000624
Validation Loss: 0.00058228
Epoch [242/300], Train Loss: 0.000627
Validation Loss: 0.00057509
Epoch [243/300], Train Loss: 0.000626
Validation Loss: 0.00058226
Epoch [244/300], Train Loss: 0.000627
Validation Loss: 0.00057952
Epoch [245/300], Train Loss: 0.000623
Validation Loss: 0.00059431
Epoch [246/300], Train Loss: 0.000623
Validation Loss: 0.00057950
Epoch [247/300], Train Loss: 0.000623
Validation Loss: 0.00057649
Epoch [248/300], Train Loss: 0.000622
Validation Loss: 0.00059136
Epoch [249/300], Train Loss: 0.000622
Validation Loss: 0.00056955
Epoch [250/300], Train Loss: 0.000627
Validation Loss: 0.00057374
Epoch [251/300], Train Loss: 0.000620
Validation Loss: 0.00057519
Epoch [252/300], Train Loss: 0.000619
Validation Loss: 0.00057824
Epoch [253/300], Train Loss: 0.000619
Validation Loss: 0.00057976
Epoch [254/300], Train Loss: 0.000619
Validation Loss: 0.00058518
Epoch [255/300], Train Loss: 0.000617
Validation Loss: 0.00056815
Epoch [256/300], Train Loss: 0.000616
Validation Loss: 0.00057614
Epoch [257/300], Train Loss: 0.000619
Validation Loss: 0.00056861
Epoch [258/300], Train Loss: 0.000613
Validation Loss: 0.00057796
Epoch [259/300], Train Loss: 0.000613
Validation Loss: 0.00056717
Epoch [260/300], Train Loss: 0.000613
Validation Loss: 0.00056558
Epoch [261/300], Train Loss: 0.000616
Validation Loss: 0.00059301
Epoch [262/300], Train Loss: 0.000612
Validation Loss: 0.00057368
Epoch [263/300], Train Loss: 0.000611
Validation Loss: 0.00059190
Epoch [264/300], Train Loss: 0.000610
Validation Loss: 0.00056234
Epoch [265/300], Train Loss: 0.000609
Validation Loss: 0.00056572
Epoch [266/300], Train Loss: 0.000609
Validation Loss: 0.00056768
Epoch [267/300], Train Loss: 0.000607
Validation Loss: 0.00056138
Epoch [268/300], Train Loss: 0.000607
Validation Loss: 0.00056073
Epoch [269/300], Train Loss: 0.000609
Validation Loss: 0.00057401
Epoch [270/300], Train Loss: 0.000611
Validation Loss: 0.00056372
Epoch [271/300], Train Loss: 0.000607
Validation Loss: 0.00056563
Epoch [272/300], Train Loss: 0.000606
Validation Loss: 0.00056405
Epoch [273/300], Train Loss: 0.000607
Validation Loss: 0.00056396
Epoch [274/300], Train Loss: 0.000607
Validation Loss: 0.00058538
Epoch [275/300], Train Loss: 0.000605
Validation Loss: 0.00057473
Epoch [276/300], Train Loss: 0.000606
Validation Loss: 0.00056189
Epoch [277/300], Train Loss: 0.000601
Validation Loss: 0.00055959
Epoch [278/300], Train Loss: 0.000603
Validation Loss: 0.00055466
Epoch [279/300], Train Loss: 0.000601
Validation Loss: 0.00056243
Epoch [280/300], Train Loss: 0.000602
Validation Loss: 0.00055039
Epoch [281/300], Train Loss: 0.000601
Validation Loss: 0.00055434
Epoch [282/300], Train Loss: 0.000601
Validation Loss: 0.00055411
Epoch [283/300], Train Loss: 0.000600
Validation Loss: 0.00057609
Epoch [284/300], Train Loss: 0.000599
Validation Loss: 0.00055081
Epoch [285/300], Train Loss: 0.000598
Validation Loss: 0.00055815
Epoch [286/300], Train Loss: 0.000600
Validation Loss: 0.00055663
Epoch [287/300], Train Loss: 0.000601
Validation Loss: 0.00054748
Epoch [288/300], Train Loss: 0.000598
Validation Loss: 0.00054957
Epoch [289/300], Train Loss: 0.000598
Validation Loss: 0.00054902
Epoch [290/300], Train Loss: 0.000596
Validation Loss: 0.00056440
Epoch [291/300], Train Loss: 0.000598
Validation Loss: 0.00054930
Epoch [292/300], Train Loss: 0.000594
Validation Loss: 0.00055106
Epoch [293/300], Train Loss: 0.000597
Validation Loss: 0.00055189
Epoch [294/300], Train Loss: 0.000597
Validation Loss: 0.00055261
Epoch [295/300], Train Loss: 0.000595
Validation Loss: 0.00056475
Epoch [296/300], Train Loss: 0.000595
Validation Loss: 0.00055038
Epoch [297/300], Train Loss: 0.000596
Validation Loss: 0.00056163
Early stopping triggered

Evaluating model for: Freezer
Run 2/72 completed in 3836.39 seconds with: {'MAE': np.float32(21.439991), 'MSE': np.float32(919.0816), 'RMSE': np.float32(30.316359), 'SAE': np.float32(0.022295969), 'NDE': np.float32(0.22988959)}

Run 3/72: hidden=128, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Freezer
Dataset length: 14022 windows

Epoch [1/300], Train Loss: 0.006208
Validation Loss: 0.00574337
Epoch [2/300], Train Loss: 0.005869
Validation Loss: 0.00540999
Epoch [3/300], Train Loss: 0.004083
Validation Loss: 0.00302607
Epoch [4/300], Train Loss: 0.002684
Validation Loss: 0.00244629
Epoch [5/300], Train Loss: 0.002294
Validation Loss: 0.00216314
Epoch [6/300], Train Loss: 0.002092
Validation Loss: 0.00203687
Epoch [7/300], Train Loss: 0.001994
Validation Loss: 0.00200547
Epoch [8/300], Train Loss: 0.001931
Validation Loss: 0.00192556
Epoch [9/300], Train Loss: 0.001897
Validation Loss: 0.00190127
Epoch [10/300], Train Loss: 0.001868
Validation Loss: 0.00187916
Epoch [11/300], Train Loss: 0.001840
Validation Loss: 0.00184243
Epoch [12/300], Train Loss: 0.001829
Validation Loss: 0.00186937
Epoch [13/300], Train Loss: 0.001805
Validation Loss: 0.00181341
Epoch [14/300], Train Loss: 0.001789
Validation Loss: 0.00179748
Epoch [15/300], Train Loss: 0.001781
Validation Loss: 0.00178973
Epoch [16/300], Train Loss: 0.001761
Validation Loss: 0.00179295
Epoch [17/300], Train Loss: 0.001745
Validation Loss: 0.00176598
Epoch [18/300], Train Loss: 0.001727
Validation Loss: 0.00177809
Epoch [19/300], Train Loss: 0.001718
Validation Loss: 0.00173085
Epoch [20/300], Train Loss: 0.001698
Validation Loss: 0.00174210
Epoch [21/300], Train Loss: 0.001691
Validation Loss: 0.00171178
Epoch [22/300], Train Loss: 0.001678
Validation Loss: 0.00169553
Epoch [23/300], Train Loss: 0.001662
Validation Loss: 0.00169259
Epoch [24/300], Train Loss: 0.001658
Validation Loss: 0.00168548
Epoch [25/300], Train Loss: 0.001645
Validation Loss: 0.00167685
Epoch [26/300], Train Loss: 0.001640
Validation Loss: 0.00168150
Epoch [27/300], Train Loss: 0.001634
Validation Loss: 0.00167030
Epoch [28/300], Train Loss: 0.001620
Validation Loss: 0.00169519
Epoch [29/300], Train Loss: 0.001613
Validation Loss: 0.00163265
Epoch [30/300], Train Loss: 0.001609
Validation Loss: 0.00162703
Epoch [31/300], Train Loss: 0.001595
Validation Loss: 0.00163781
Epoch [32/300], Train Loss: 0.001596
Validation Loss: 0.00161735
Epoch [33/300], Train Loss: 0.001587
Validation Loss: 0.00160536
Epoch [34/300], Train Loss: 0.001575
Validation Loss: 0.00158926
Epoch [35/300], Train Loss: 0.001572
Validation Loss: 0.00158067
Epoch [36/300], Train Loss: 0.001561
Validation Loss: 0.00158948
Epoch [37/300], Train Loss: 0.001553
Validation Loss: 0.00157133
Epoch [38/300], Train Loss: 0.001553
Validation Loss: 0.00155141
Epoch [39/300], Train Loss: 0.001588
Validation Loss: 0.00163421
Epoch [40/300], Train Loss: 0.001547
Validation Loss: 0.00158565
Epoch [41/300], Train Loss: 0.001540
Validation Loss: 0.00154114
Epoch [42/300], Train Loss: 0.001535
Validation Loss: 0.00154483
Epoch [43/300], Train Loss: 0.001549
Validation Loss: 0.00154101
Epoch [44/300], Train Loss: 0.001521
Validation Loss: 0.00152906
Epoch [45/300], Train Loss: 0.001526
Validation Loss: 0.00151911
Epoch [46/300], Train Loss: 0.001513
Validation Loss: 0.00152408
Epoch [47/300], Train Loss: 0.001533
Validation Loss: 0.00160383
Epoch [48/300], Train Loss: 0.001513
Validation Loss: 0.00151889
Epoch [49/300], Train Loss: 0.001509
Validation Loss: 0.00152105
Epoch [50/300], Train Loss: 0.001505
Validation Loss: 0.00152170
Epoch [51/300], Train Loss: 0.001508
Validation Loss: 0.00153005
Epoch [52/300], Train Loss: 0.001498
Validation Loss: 0.00153127
Epoch [53/300], Train Loss: 0.001507
Validation Loss: 0.00153818
Epoch [54/300], Train Loss: 0.001504
Validation Loss: 0.00152894
Epoch [55/300], Train Loss: 0.001504
Validation Loss: 0.00152753
Epoch [56/300], Train Loss: 0.001498
Validation Loss: 0.00152827
Epoch [57/300], Train Loss: 0.001486
Validation Loss: 0.00151149
Epoch [58/300], Train Loss: 0.001499
Validation Loss: 0.00153368
Epoch [59/300], Train Loss: 0.001489
Validation Loss: 0.00150367
Epoch [60/300], Train Loss: 0.001487
Validation Loss: 0.00151071
Epoch [61/300], Train Loss: 0.001488
Validation Loss: 0.00151176
Epoch [62/300], Train Loss: 0.001492
Validation Loss: 0.00165490
Epoch [63/300], Train Loss: 0.001519
Validation Loss: 0.00151549
Epoch [64/300], Train Loss: 0.001493
Validation Loss: 0.00148537
Epoch [65/300], Train Loss: 0.001481
Validation Loss: 0.00152846
Epoch [66/300], Train Loss: 0.001477
Validation Loss: 0.00149294
Epoch [67/300], Train Loss: 0.001474
Validation Loss: 0.00150209
Epoch [68/300], Train Loss: 0.001468
Validation Loss: 0.00148735
Epoch [69/300], Train Loss: 0.001469
Validation Loss: 0.00148253
Epoch [70/300], Train Loss: 0.001471
Validation Loss: 0.00148510
Epoch [71/300], Train Loss: 0.001472
Validation Loss: 0.00147709
Epoch [72/300], Train Loss: 0.001473
Validation Loss: 0.00152352
Epoch [73/300], Train Loss: 0.001475
Validation Loss: 0.00148676
Epoch [74/300], Train Loss: 0.001483
Validation Loss: 0.00146987
Epoch [75/300], Train Loss: 0.001461
Validation Loss: 0.00147577
Epoch [76/300], Train Loss: 0.001686
Validation Loss: 0.00200753
Epoch [77/300], Train Loss: 0.001643
Validation Loss: 0.00159555
Epoch [78/300], Train Loss: 0.001529
Validation Loss: 0.00157326
Epoch [79/300], Train Loss: 0.001513
Validation Loss: 0.00157561
Epoch [80/300], Train Loss: 0.001506
Validation Loss: 0.00156088
Epoch [81/300], Train Loss: 0.001499
Validation Loss: 0.00156767
Epoch [82/300], Train Loss: 0.001496
Validation Loss: 0.00154632
Epoch [83/300], Train Loss: 0.001494
Validation Loss: 0.00154697
Epoch [84/300], Train Loss: 0.001488
Validation Loss: 0.00154572
Early stopping triggered

Evaluating model for: Freezer
Run 3/72 completed in 1121.59 seconds with: {'MAE': np.float32(34.20347), 'MSE': np.float32(2513.0632), 'RMSE': np.float32(50.130463), 'SAE': np.float32(0.004441667), 'NDE': np.float32(0.3801404)}

Run 4/72: hidden=128, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Freezer
Dataset length: 14022 windows

Epoch [1/300], Train Loss: 0.007702
Validation Loss: 0.00585491
Epoch [2/300], Train Loss: 0.005781
Validation Loss: 0.00450851
Epoch [3/300], Train Loss: 0.003700
Validation Loss: 0.00292897
Epoch [4/300], Train Loss: 0.002676
Validation Loss: 0.00245493
Epoch [5/300], Train Loss: 0.002324
Validation Loss: 0.00220872
Epoch [6/300], Train Loss: 0.002138
Validation Loss: 0.00208940
Epoch [7/300], Train Loss: 0.002038
Validation Loss: 0.00202136
Epoch [8/300], Train Loss: 0.001988
Validation Loss: 0.00199154
Epoch [9/300], Train Loss: 0.001944
Validation Loss: 0.00192532
Epoch [10/300], Train Loss: 0.001913
Validation Loss: 0.00194884
Epoch [11/300], Train Loss: 0.001885
Validation Loss: 0.00187149
Epoch [12/300], Train Loss: 0.001899
Validation Loss: 0.00191096
Epoch [13/300], Train Loss: 0.001856
Validation Loss: 0.00185372
Epoch [14/300], Train Loss: 0.001832
Validation Loss: 0.00183978
Epoch [15/300], Train Loss: 0.001812
Validation Loss: 0.00183494
Epoch [16/300], Train Loss: 0.001792
Validation Loss: 0.00180698
Epoch [17/300], Train Loss: 0.001775
Validation Loss: 0.00180929
Epoch [18/300], Train Loss: 0.001759
Validation Loss: 0.00179313
Epoch [19/300], Train Loss: 0.001759
Validation Loss: 0.00178038
Epoch [20/300], Train Loss: 0.001746
Validation Loss: 0.00177307
Epoch [21/300], Train Loss: 0.001731
Validation Loss: 0.00174703
Epoch [22/300], Train Loss: 0.001726
Validation Loss: 0.00173991
Epoch [23/300], Train Loss: 0.001709
Validation Loss: 0.00173123
Epoch [24/300], Train Loss: 0.001712
Validation Loss: 0.00172107
Epoch [25/300], Train Loss: 0.001678
Validation Loss: 0.00172058
Epoch [26/300], Train Loss: 0.001665
Validation Loss: 0.00169865
Epoch [27/300], Train Loss: 0.001665
Validation Loss: 0.00175884
Epoch [28/300], Train Loss: 0.001654
Validation Loss: 0.00175307
Epoch [29/300], Train Loss: 0.001641
Validation Loss: 0.00167666
Epoch [30/300], Train Loss: 0.001635
Validation Loss: 0.00165992
Epoch [31/300], Train Loss: 0.001627
Validation Loss: 0.00168167
Epoch [32/300], Train Loss: 0.001616
Validation Loss: 0.00165894
Epoch [33/300], Train Loss: 0.001606
Validation Loss: 0.00165088
Epoch [34/300], Train Loss: 0.001603
Validation Loss: 0.00163306
Epoch [35/300], Train Loss: 0.001593
Validation Loss: 0.00162411
Epoch [36/300], Train Loss: 0.001587
Validation Loss: 0.00163210
Epoch [37/300], Train Loss: 0.001601
Validation Loss: 0.00165386
Epoch [38/300], Train Loss: 0.001589
Validation Loss: 0.00162687
Epoch [39/300], Train Loss: 0.001579
Validation Loss: 0.00163345
Epoch [40/300], Train Loss: 0.001569
Validation Loss: 0.00161002
Epoch [41/300], Train Loss: 0.001561
Validation Loss: 0.00159366
Epoch [42/300], Train Loss: 0.001559
Validation Loss: 0.00159831
Epoch [43/300], Train Loss: 0.001561
Validation Loss: 0.00159415
Epoch [44/300], Train Loss: 0.001554
Validation Loss: 0.00159142
Epoch [45/300], Train Loss: 0.001551
Validation Loss: 0.00157168
Epoch [46/300], Train Loss: 0.001533
Validation Loss: 0.00157265
Epoch [47/300], Train Loss: 0.001535
Validation Loss: 0.00159725
Epoch [48/300], Train Loss: 0.001528
Validation Loss: 0.00155185
Epoch [49/300], Train Loss: 0.001527
Validation Loss: 0.00155069
Epoch [50/300], Train Loss: 0.001519
Validation Loss: 0.00154917
Epoch [51/300], Train Loss: 0.001514
Validation Loss: 0.00155209
Epoch [52/300], Train Loss: 0.001509
Validation Loss: 0.00153386
Epoch [53/300], Train Loss: 0.001507
Validation Loss: 0.00155499
Epoch [54/300], Train Loss: 0.001501
Validation Loss: 0.00150863
Epoch [55/300], Train Loss: 0.001496
Validation Loss: 0.00149777
Epoch [56/300], Train Loss: 0.001496
Validation Loss: 0.00152565
Epoch [57/300], Train Loss: 0.001478
Validation Loss: 0.00148129
Epoch [58/300], Train Loss: 0.001494
Validation Loss: 0.00147587
Epoch [59/300], Train Loss: 0.001478
Validation Loss: 0.00146686
Epoch [60/300], Train Loss: 0.001476
Validation Loss: 0.00150064
Epoch [61/300], Train Loss: 0.001474
Validation Loss: 0.00147579
Epoch [62/300], Train Loss: 0.001468
Validation Loss: 0.00146770
Epoch [63/300], Train Loss: 0.001464
Validation Loss: 0.00147464
Epoch [64/300], Train Loss: 0.001470
Validation Loss: 0.00149110
Epoch [65/300], Train Loss: 0.001464
Validation Loss: 0.00150517
Epoch [66/300], Train Loss: 0.001460
Validation Loss: 0.00144942
Epoch [67/300], Train Loss: 0.001457
Validation Loss: 0.00145022
Epoch [68/300], Train Loss: 0.001446
Validation Loss: 0.00144535
Epoch [69/300], Train Loss: 0.001464
Validation Loss: 0.00146992
Epoch [70/300], Train Loss: 0.001442
Validation Loss: 0.00143966
Epoch [71/300], Train Loss: 0.001438
Validation Loss: 0.00143477
Epoch [72/300], Train Loss: 0.001438
Validation Loss: 0.00145705
Epoch [73/300], Train Loss: 0.001434
Validation Loss: 0.00144228
Epoch [74/300], Train Loss: 0.001431
Validation Loss: 0.00142709
Epoch [75/300], Train Loss: 0.001419
Validation Loss: 0.00142056
Epoch [76/300], Train Loss: 0.001422
Validation Loss: 0.00140677
Epoch [77/300], Train Loss: 0.001413
Validation Loss: 0.00141534
Epoch [78/300], Train Loss: 0.001410
Validation Loss: 0.00141975
Epoch [79/300], Train Loss: 0.001400
Validation Loss: 0.00141528
Epoch [80/300], Train Loss: 0.001391
Validation Loss: 0.00139534
Epoch [81/300], Train Loss: 0.001387
Validation Loss: 0.00141882
Epoch [82/300], Train Loss: 0.001372
Validation Loss: 0.00134486
Epoch [83/300], Train Loss: 0.001356
Validation Loss: 0.00132624
Epoch [84/300], Train Loss: 0.001329
Validation Loss: 0.00131009
Epoch [85/300], Train Loss: 0.001302
Validation Loss: 0.00126318
Epoch [86/300], Train Loss: 0.001241
Validation Loss: 0.00115862
Epoch [87/300], Train Loss: 0.001131
Validation Loss: 0.00101494
Epoch [88/300], Train Loss: 0.001026
Validation Loss: 0.00094351
Epoch [89/300], Train Loss: 0.000961
Validation Loss: 0.00087982
Epoch [90/300], Train Loss: 0.000926
Validation Loss: 0.00087728
Epoch [91/300], Train Loss: 0.000899
Validation Loss: 0.00082982
Epoch [92/300], Train Loss: 0.000872
Validation Loss: 0.00081591
Epoch [93/300], Train Loss: 0.000853
Validation Loss: 0.00081257
Epoch [94/300], Train Loss: 0.000838
Validation Loss: 0.00080474
Epoch [95/300], Train Loss: 0.000831
Validation Loss: 0.00080291
Epoch [96/300], Train Loss: 0.000824
Validation Loss: 0.00079223
Epoch [97/300], Train Loss: 0.000809
Validation Loss: 0.00077259
Epoch [98/300], Train Loss: 0.000801
Validation Loss: 0.00076164
Epoch [99/300], Train Loss: 0.000798
Validation Loss: 0.00075301
Epoch [100/300], Train Loss: 0.000785
Validation Loss: 0.00080451
Epoch [101/300], Train Loss: 0.000782
Validation Loss: 0.00076172
Epoch [102/300], Train Loss: 0.000778
Validation Loss: 0.00075127
Epoch [103/300], Train Loss: 0.000771
Validation Loss: 0.00073641
Epoch [104/300], Train Loss: 0.000763
Validation Loss: 0.00080646
Epoch [105/300], Train Loss: 0.000764
Validation Loss: 0.00079056
Epoch [106/300], Train Loss: 0.000764
Validation Loss: 0.00076512
Epoch [107/300], Train Loss: 0.000752
Validation Loss: 0.00072609
Epoch [108/300], Train Loss: 0.000752
Validation Loss: 0.00073894
Epoch [109/300], Train Loss: 0.000764
Validation Loss: 0.00073619
Epoch [110/300], Train Loss: 0.000745
Validation Loss: 0.00072737
Epoch [111/300], Train Loss: 0.000743
Validation Loss: 0.00072369
Epoch [112/300], Train Loss: 0.000743
Validation Loss: 0.00074111
Epoch [113/300], Train Loss: 0.000740
Validation Loss: 0.00072286
Epoch [114/300], Train Loss: 0.000737
Validation Loss: 0.00070946
Epoch [115/300], Train Loss: 0.000739
Validation Loss: 0.00075744
Epoch [116/300], Train Loss: 0.000737
Validation Loss: 0.00074703
Epoch [117/300], Train Loss: 0.000740
Validation Loss: 0.00072829
Epoch [118/300], Train Loss: 0.000725
Validation Loss: 0.00070260
Epoch [119/300], Train Loss: 0.000726
Validation Loss: 0.00071111
Epoch [120/300], Train Loss: 0.000727
Validation Loss: 0.00070100
Epoch [121/300], Train Loss: 0.000724
Validation Loss: 0.00069991
Epoch [122/300], Train Loss: 0.000724
Validation Loss: 0.00070142
Epoch [123/300], Train Loss: 0.000719
Validation Loss: 0.00071059
Epoch [124/300], Train Loss: 0.000714
Validation Loss: 0.00070602
Epoch [125/300], Train Loss: 0.000717
Validation Loss: 0.00071096
Epoch [126/300], Train Loss: 0.000716
Validation Loss: 0.00072103
Epoch [127/300], Train Loss: 0.000710
Validation Loss: 0.00068882
Epoch [128/300], Train Loss: 0.000711
Validation Loss: 0.00068853
Epoch [129/300], Train Loss: 0.000708
Validation Loss: 0.00068943
Epoch [130/300], Train Loss: 0.000706
Validation Loss: 0.00070891
Epoch [131/300], Train Loss: 0.000706
Validation Loss: 0.00069194
Epoch [132/300], Train Loss: 0.000708
Validation Loss: 0.00068962
Epoch [133/300], Train Loss: 0.000708
Validation Loss: 0.00068470
Epoch [134/300], Train Loss: 0.000707
Validation Loss: 0.00068949
Epoch [135/300], Train Loss: 0.000700
Validation Loss: 0.00070583
Epoch [136/300], Train Loss: 0.000705
Validation Loss: 0.00069211
Epoch [137/300], Train Loss: 0.000701
Validation Loss: 0.00071980
Epoch [138/300], Train Loss: 0.000694
Validation Loss: 0.00067904
Epoch [139/300], Train Loss: 0.000692
Validation Loss: 0.00071605
Epoch [140/300], Train Loss: 0.000690
Validation Loss: 0.00067046
Epoch [141/300], Train Loss: 0.000688
Validation Loss: 0.00068935
Epoch [142/300], Train Loss: 0.000694
Validation Loss: 0.00068608
Epoch [143/300], Train Loss: 0.000702
Validation Loss: 0.00071209
Epoch [144/300], Train Loss: 0.000687
Validation Loss: 0.00067208
Epoch [145/300], Train Loss: 0.000688
Validation Loss: 0.00069970
Epoch [146/300], Train Loss: 0.000681
Validation Loss: 0.00067074
Epoch [147/300], Train Loss: 0.000682
Validation Loss: 0.00067603
Epoch [148/300], Train Loss: 0.000690
Validation Loss: 0.00066898
Epoch [149/300], Train Loss: 0.000695
Validation Loss: 0.00068087
Epoch [150/300], Train Loss: 0.000681
Validation Loss: 0.00069107
Epoch [151/300], Train Loss: 0.000683
Validation Loss: 0.00067187
Epoch [152/300], Train Loss: 0.000678
Validation Loss: 0.00066447
Epoch [153/300], Train Loss: 0.000674
Validation Loss: 0.00067251
Epoch [154/300], Train Loss: 0.000672
Validation Loss: 0.00068535
Epoch [155/300], Train Loss: 0.000671
Validation Loss: 0.00065662
Epoch [156/300], Train Loss: 0.000669
Validation Loss: 0.00065428
Epoch [157/300], Train Loss: 0.000673
Validation Loss: 0.00071620
Epoch [158/300], Train Loss: 0.000678
Validation Loss: 0.00065511
Epoch [159/300], Train Loss: 0.000666
Validation Loss: 0.00074834
Epoch [160/300], Train Loss: 0.000677
Validation Loss: 0.00065227
Epoch [161/300], Train Loss: 0.000661
Validation Loss: 0.00065105
Epoch [162/300], Train Loss: 0.000667
Validation Loss: 0.00065992
Epoch [163/300], Train Loss: 0.000667
Validation Loss: 0.00067055
Epoch [164/300], Train Loss: 0.000660
Validation Loss: 0.00068053
Epoch [165/300], Train Loss: 0.000658
Validation Loss: 0.00065790
Epoch [166/300], Train Loss: 0.000662
Validation Loss: 0.00067361
Epoch [167/300], Train Loss: 0.000659
Validation Loss: 0.00073577
Epoch [168/300], Train Loss: 0.000665
Validation Loss: 0.00065000
Epoch [169/300], Train Loss: 0.000655
Validation Loss: 0.00066536
Epoch [170/300], Train Loss: 0.000653
Validation Loss: 0.00064627
Epoch [171/300], Train Loss: 0.000650
Validation Loss: 0.00065988
Epoch [172/300], Train Loss: 0.000671
Validation Loss: 0.00064725
Epoch [173/300], Train Loss: 0.000648
Validation Loss: 0.00065780
Epoch [174/300], Train Loss: 0.000650
Validation Loss: 0.00063330
Epoch [175/300], Train Loss: 0.000647
Validation Loss: 0.00063507
Epoch [176/300], Train Loss: 0.000646
Validation Loss: 0.00062363
Epoch [177/300], Train Loss: 0.000642
Validation Loss: 0.00065069
Epoch [178/300], Train Loss: 0.000642
Validation Loss: 0.00063676
Epoch [179/300], Train Loss: 0.000639
Validation Loss: 0.00064475
Epoch [180/300], Train Loss: 0.000640
Validation Loss: 0.00062485
Epoch [181/300], Train Loss: 0.000646
Validation Loss: 0.00073775
Epoch [182/300], Train Loss: 0.000648
Validation Loss: 0.00063200
Epoch [183/300], Train Loss: 0.000636
Validation Loss: 0.00065026
Epoch [184/300], Train Loss: 0.000639
Validation Loss: 0.00066016
Epoch [185/300], Train Loss: 0.000672
Validation Loss: 0.00064690
Epoch [186/300], Train Loss: 0.000640
Validation Loss: 0.00062985
Early stopping triggered

Evaluating model for: Freezer
Run 4/72 completed in 2488.45 seconds with: {'MAE': np.float32(22.908636), 'MSE': np.float32(989.80774), 'RMSE': np.float32(31.46121), 'SAE': np.float32(0.0076273815), 'NDE': np.float32(0.23857105)}

Run 5/72: hidden=128, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Freezer
Dataset length: 7026 windows

Epoch [1/300], Train Loss: 0.006551
Validation Loss: 0.00579224
Epoch [2/300], Train Loss: 0.005891
Validation Loss: 0.00571053
Epoch [3/300], Train Loss: 0.005750
Validation Loss: 0.00548962
Epoch [4/300], Train Loss: 0.005237
Validation Loss: 0.00441840
Epoch [5/300], Train Loss: 0.003777
Validation Loss: 0.00331809
Epoch [6/300], Train Loss: 0.003031
Validation Loss: 0.00281899
Epoch [7/300], Train Loss: 0.002593
Validation Loss: 0.00239582
Epoch [8/300], Train Loss: 0.002348
Validation Loss: 0.00226189
Epoch [9/300], Train Loss: 0.002253
Validation Loss: 0.00216021
Epoch [10/300], Train Loss: 0.002195
Validation Loss: 0.00211743
Epoch [11/300], Train Loss: 0.002158
Validation Loss: 0.00207237
Epoch [12/300], Train Loss: 0.002108
Validation Loss: 0.00203323
Epoch [13/300], Train Loss: 0.002069
Validation Loss: 0.00201284
Epoch [14/300], Train Loss: 0.002031
Validation Loss: 0.00197109
Epoch [15/300], Train Loss: 0.002011
Validation Loss: 0.00197737
Epoch [16/300], Train Loss: 0.001980
Validation Loss: 0.00191819
Epoch [17/300], Train Loss: 0.001962
Validation Loss: 0.00189194
Epoch [18/300], Train Loss: 0.001931
Validation Loss: 0.00186242
Epoch [19/300], Train Loss: 0.001916
Validation Loss: 0.00185744
Epoch [20/300], Train Loss: 0.001895
Validation Loss: 0.00182663
Epoch [21/300], Train Loss: 0.001887
Validation Loss: 0.00181360
Epoch [22/300], Train Loss: 0.001877
Validation Loss: 0.00180643
Epoch [23/300], Train Loss: 0.001854
Validation Loss: 0.00179243
Epoch [24/300], Train Loss: 0.001851
Validation Loss: 0.00178820
Epoch [25/300], Train Loss: 0.001835
Validation Loss: 0.00179675
Epoch [26/300], Train Loss: 0.001826
Validation Loss: 0.00176597
Epoch [27/300], Train Loss: 0.001817
Validation Loss: 0.00175862
Epoch [28/300], Train Loss: 0.001816
Validation Loss: 0.00179233
Epoch [29/300], Train Loss: 0.001808
Validation Loss: 0.00174478
Epoch [30/300], Train Loss: 0.001801
Validation Loss: 0.00174511
Epoch [31/300], Train Loss: 0.001790
Validation Loss: 0.00174091
Epoch [32/300], Train Loss: 0.001778
Validation Loss: 0.00173078
Epoch [33/300], Train Loss: 0.001776
Validation Loss: 0.00173227
Epoch [34/300], Train Loss: 0.001771
Validation Loss: 0.00172080
Epoch [35/300], Train Loss: 0.001763
Validation Loss: 0.00170820
Epoch [36/300], Train Loss: 0.001756
Validation Loss: 0.00171609
Epoch [37/300], Train Loss: 0.001752
Validation Loss: 0.00169953
Epoch [38/300], Train Loss: 0.001738
Validation Loss: 0.00171059
Epoch [39/300], Train Loss: 0.001735
Validation Loss: 0.00168743
Epoch [40/300], Train Loss: 0.001725
Validation Loss: 0.00168145
Epoch [41/300], Train Loss: 0.001725
Validation Loss: 0.00168316
Epoch [42/300], Train Loss: 0.001723
Validation Loss: 0.00167987
Epoch [43/300], Train Loss: 0.001717
Validation Loss: 0.00167006
Epoch [44/300], Train Loss: 0.001710
Validation Loss: 0.00166310
Epoch [45/300], Train Loss: 0.001706
Validation Loss: 0.00165955
Epoch [46/300], Train Loss: 0.001703
Validation Loss: 0.00165253
Epoch [47/300], Train Loss: 0.001694
Validation Loss: 0.00165490
Epoch [48/300], Train Loss: 0.001688
Validation Loss: 0.00165499
Epoch [49/300], Train Loss: 0.001681
Validation Loss: 0.00167359
Epoch [50/300], Train Loss: 0.001688
Validation Loss: 0.00167851
Epoch [51/300], Train Loss: 0.001690
Validation Loss: 0.00165144
Epoch [52/300], Train Loss: 0.001669
Validation Loss: 0.00163373
Epoch [53/300], Train Loss: 0.001667
Validation Loss: 0.00162981
Epoch [54/300], Train Loss: 0.001661
Validation Loss: 0.00162443
Epoch [55/300], Train Loss: 0.001654
Validation Loss: 0.00163559
Epoch [56/300], Train Loss: 0.001657
Validation Loss: 0.00161744
Epoch [57/300], Train Loss: 0.001659
Validation Loss: 0.00167303
Epoch [58/300], Train Loss: 0.001649
Validation Loss: 0.00161807
Epoch [59/300], Train Loss: 0.001641
Validation Loss: 0.00161116
Epoch [60/300], Train Loss: 0.001638
Validation Loss: 0.00160312
Epoch [61/300], Train Loss: 0.001633
Validation Loss: 0.00159854
Epoch [62/300], Train Loss: 0.001633
Validation Loss: 0.00161327
Epoch [63/300], Train Loss: 0.001631
Validation Loss: 0.00159448
Epoch [64/300], Train Loss: 0.001629
Validation Loss: 0.00161070
Epoch [65/300], Train Loss: 0.001617
Validation Loss: 0.00160896
Epoch [66/300], Train Loss: 0.001624
Validation Loss: 0.00158598
Epoch [67/300], Train Loss: 0.001617
Validation Loss: 0.00158188
Epoch [68/300], Train Loss: 0.001612
Validation Loss: 0.00157843
Epoch [69/300], Train Loss: 0.001608
Validation Loss: 0.00157188
Epoch [70/300], Train Loss: 0.001603
Validation Loss: 0.00157180
Epoch [71/300], Train Loss: 0.001599
Validation Loss: 0.00156901
Epoch [72/300], Train Loss: 0.001598
Validation Loss: 0.00156796
Epoch [73/300], Train Loss: 0.001593
Validation Loss: 0.00156007
Epoch [74/300], Train Loss: 0.001590
Validation Loss: 0.00156715
Epoch [75/300], Train Loss: 0.001594
Validation Loss: 0.00155890
Epoch [76/300], Train Loss: 0.001589
Validation Loss: 0.00156389
Epoch [77/300], Train Loss: 0.001584
Validation Loss: 0.00154699
Epoch [78/300], Train Loss: 0.001576
Validation Loss: 0.00154189
Epoch [79/300], Train Loss: 0.001575
Validation Loss: 0.00156241
Epoch [80/300], Train Loss: 0.001581
Validation Loss: 0.00156580
Epoch [81/300], Train Loss: 0.001574
Validation Loss: 0.00153955
Epoch [82/300], Train Loss: 0.001562
Validation Loss: 0.00154059
Epoch [83/300], Train Loss: 0.001563
Validation Loss: 0.00152222
Epoch [84/300], Train Loss: 0.001553
Validation Loss: 0.00152449
Epoch [85/300], Train Loss: 0.001551
Validation Loss: 0.00151734
Epoch [86/300], Train Loss: 0.001556
Validation Loss: 0.00154887
Epoch [87/300], Train Loss: 0.001548
Validation Loss: 0.00151496
Epoch [88/300], Train Loss: 0.001546
Validation Loss: 0.00151139
Epoch [89/300], Train Loss: 0.001541
Validation Loss: 0.00151042
Epoch [90/300], Train Loss: 0.001535
Validation Loss: 0.00149794
Epoch [91/300], Train Loss: 0.001526
Validation Loss: 0.00149720
Epoch [92/300], Train Loss: 0.001522
Validation Loss: 0.00148287
Epoch [93/300], Train Loss: 0.001515
Validation Loss: 0.00147630
Epoch [94/300], Train Loss: 0.001517
Validation Loss: 0.00147605
Epoch [95/300], Train Loss: 0.001514
Validation Loss: 0.00147305
Epoch [96/300], Train Loss: 0.001503
Validation Loss: 0.00146800
Epoch [97/300], Train Loss: 0.001503
Validation Loss: 0.00145765
Epoch [98/300], Train Loss: 0.001497
Validation Loss: 0.00146355
Epoch [99/300], Train Loss: 0.001489
Validation Loss: 0.00145024
Epoch [100/300], Train Loss: 0.001484
Validation Loss: 0.00144071
Epoch [101/300], Train Loss: 0.001482
Validation Loss: 0.00143469
Epoch [102/300], Train Loss: 0.001477
Validation Loss: 0.00142811
Epoch [103/300], Train Loss: 0.001475
Validation Loss: 0.00142833
Epoch [104/300], Train Loss: 0.001463
Validation Loss: 0.00141541
Epoch [105/300], Train Loss: 0.001455
Validation Loss: 0.00140300
Epoch [106/300], Train Loss: 0.001449
Validation Loss: 0.00142410
Epoch [107/300], Train Loss: 0.001451
Validation Loss: 0.00140671
Epoch [108/300], Train Loss: 0.001441
Validation Loss: 0.00138842
Epoch [109/300], Train Loss: 0.001431
Validation Loss: 0.00139305
Epoch [110/300], Train Loss: 0.001435
Validation Loss: 0.00136835
Epoch [111/300], Train Loss: 0.001422
Validation Loss: 0.00136542
Epoch [112/300], Train Loss: 0.001414
Validation Loss: 0.00135482
Epoch [113/300], Train Loss: 0.001414
Validation Loss: 0.00135578
Epoch [114/300], Train Loss: 0.001398
Validation Loss: 0.00135463
Epoch [115/300], Train Loss: 0.001394
Validation Loss: 0.00135142
Epoch [116/300], Train Loss: 0.001388
Validation Loss: 0.00133710
Epoch [117/300], Train Loss: 0.001377
Validation Loss: 0.00135773
Epoch [118/300], Train Loss: 0.001367
Validation Loss: 0.00129353
Epoch [119/300], Train Loss: 0.001357
Validation Loss: 0.00129690
Epoch [120/300], Train Loss: 0.001344
Validation Loss: 0.00127420
Epoch [121/300], Train Loss: 0.001337
Validation Loss: 0.00125989
Epoch [122/300], Train Loss: 0.001328
Validation Loss: 0.00126058
Epoch [123/300], Train Loss: 0.001318
Validation Loss: 0.00123300
Epoch [124/300], Train Loss: 0.001307
Validation Loss: 0.00121610
Epoch [125/300], Train Loss: 0.001297
Validation Loss: 0.00120345
Epoch [126/300], Train Loss: 0.001294
Validation Loss: 0.00119358
Epoch [127/300], Train Loss: 0.001278
Validation Loss: 0.00118541
Epoch [128/300], Train Loss: 0.001271
Validation Loss: 0.00115923
Epoch [129/300], Train Loss: 0.001252
Validation Loss: 0.00114791
Epoch [130/300], Train Loss: 0.001245
Validation Loss: 0.00113843
Epoch [131/300], Train Loss: 0.001238
Validation Loss: 0.00111303
Epoch [132/300], Train Loss: 0.001222
Validation Loss: 0.00109588
Epoch [133/300], Train Loss: 0.001207
Validation Loss: 0.00108547
Epoch [134/300], Train Loss: 0.001192
Validation Loss: 0.00108702
Epoch [135/300], Train Loss: 0.001186
Validation Loss: 0.00106287
Epoch [136/300], Train Loss: 0.001171
Validation Loss: 0.00106079
Epoch [137/300], Train Loss: 0.001168
Validation Loss: 0.00108094
Epoch [138/300], Train Loss: 0.001159
Validation Loss: 0.00102018
Epoch [139/300], Train Loss: 0.001147
Validation Loss: 0.00101571
Epoch [140/300], Train Loss: 0.001134
Validation Loss: 0.00100284
Epoch [141/300], Train Loss: 0.001129
Validation Loss: 0.00099977
Epoch [142/300], Train Loss: 0.001122
Validation Loss: 0.00100059
Epoch [143/300], Train Loss: 0.001121
Validation Loss: 0.00098638
Epoch [144/300], Train Loss: 0.001112
Validation Loss: 0.00098155
Epoch [145/300], Train Loss: 0.001115
Validation Loss: 0.00098268
Epoch [146/300], Train Loss: 0.001102
Validation Loss: 0.00098727
Epoch [147/300], Train Loss: 0.001090
Validation Loss: 0.00095396
Epoch [148/300], Train Loss: 0.001089
Validation Loss: 0.00096527
Epoch [149/300], Train Loss: 0.001079
Validation Loss: 0.00095120
Epoch [150/300], Train Loss: 0.001078
Validation Loss: 0.00094892
Epoch [151/300], Train Loss: 0.001078
Validation Loss: 0.00094386
Epoch [152/300], Train Loss: 0.001070
Validation Loss: 0.00094007
Epoch [153/300], Train Loss: 0.001066
Validation Loss: 0.00094136
Epoch [154/300], Train Loss: 0.001066
Validation Loss: 0.00093606
Epoch [155/300], Train Loss: 0.001054
Validation Loss: 0.00092760
Epoch [156/300], Train Loss: 0.001050
Validation Loss: 0.00091807
Epoch [157/300], Train Loss: 0.001048
Validation Loss: 0.00092180
Epoch [158/300], Train Loss: 0.001048
Validation Loss: 0.00091650
Epoch [159/300], Train Loss: 0.001040
Validation Loss: 0.00090555
Epoch [160/300], Train Loss: 0.001039
Validation Loss: 0.00090716
Epoch [161/300], Train Loss: 0.001033
Validation Loss: 0.00090533
Epoch [162/300], Train Loss: 0.001036
Validation Loss: 0.00090491
Epoch [163/300], Train Loss: 0.001030
Validation Loss: 0.00089121
Epoch [164/300], Train Loss: 0.001028
Validation Loss: 0.00091065
Epoch [165/300], Train Loss: 0.001028
Validation Loss: 0.00091277
Epoch [166/300], Train Loss: 0.001021
Validation Loss: 0.00089762
Epoch [167/300], Train Loss: 0.001019
Validation Loss: 0.00089048
Epoch [168/300], Train Loss: 0.001014
Validation Loss: 0.00088636
Epoch [169/300], Train Loss: 0.001014
Validation Loss: 0.00088022
Epoch [170/300], Train Loss: 0.001011
Validation Loss: 0.00092146
Epoch [171/300], Train Loss: 0.001012
Validation Loss: 0.00088021
Epoch [172/300], Train Loss: 0.001005
Validation Loss: 0.00088036
Epoch [173/300], Train Loss: 0.001007
Validation Loss: 0.00088753
Epoch [174/300], Train Loss: 0.001005
Validation Loss: 0.00087466
Epoch [175/300], Train Loss: 0.001001
Validation Loss: 0.00086960
Epoch [176/300], Train Loss: 0.000999
Validation Loss: 0.00087279
Epoch [177/300], Train Loss: 0.001001
Validation Loss: 0.00087087
Epoch [178/300], Train Loss: 0.000996
Validation Loss: 0.00086608
Epoch [179/300], Train Loss: 0.000994
Validation Loss: 0.00088973
Epoch [180/300], Train Loss: 0.000992
Validation Loss: 0.00088056
Epoch [181/300], Train Loss: 0.000987
Validation Loss: 0.00085962
Epoch [182/300], Train Loss: 0.000987
Validation Loss: 0.00087064
Epoch [183/300], Train Loss: 0.000986
Validation Loss: 0.00086335
Epoch [184/300], Train Loss: 0.000985
Validation Loss: 0.00085526
Epoch [185/300], Train Loss: 0.000978
Validation Loss: 0.00085897
Epoch [186/300], Train Loss: 0.000980
Validation Loss: 0.00085416
Epoch [187/300], Train Loss: 0.000981
Validation Loss: 0.00085023
Epoch [188/300], Train Loss: 0.000971
Validation Loss: 0.00086711
Epoch [189/300], Train Loss: 0.000984
Validation Loss: 0.00084711
Epoch [190/300], Train Loss: 0.000978
Validation Loss: 0.00084771
Epoch [191/300], Train Loss: 0.000974
Validation Loss: 0.00085130
Epoch [192/300], Train Loss: 0.000968
Validation Loss: 0.00084671
Epoch [193/300], Train Loss: 0.000972
Validation Loss: 0.00089488
Epoch [194/300], Train Loss: 0.000971
Validation Loss: 0.00087599
Epoch [195/300], Train Loss: 0.000972
Validation Loss: 0.00083886
Epoch [196/300], Train Loss: 0.000966
Validation Loss: 0.00083929
Epoch [197/300], Train Loss: 0.000964
Validation Loss: 0.00083987
Epoch [198/300], Train Loss: 0.000964
Validation Loss: 0.00085725
Epoch [199/300], Train Loss: 0.000962
Validation Loss: 0.00084428
Epoch [200/300], Train Loss: 0.000961
Validation Loss: 0.00084666
Epoch [201/300], Train Loss: 0.000959
Validation Loss: 0.00084181
Epoch [202/300], Train Loss: 0.000956
Validation Loss: 0.00083949
Epoch [203/300], Train Loss: 0.000962
Validation Loss: 0.00083188
Epoch [204/300], Train Loss: 0.000961
Validation Loss: 0.00085321
Epoch [205/300], Train Loss: 0.000964
Validation Loss: 0.00082756
Epoch [206/300], Train Loss: 0.000952
Validation Loss: 0.00083190
Epoch [207/300], Train Loss: 0.000950
Validation Loss: 0.00083286
Epoch [208/300], Train Loss: 0.000950
Validation Loss: 0.00086436
Epoch [209/300], Train Loss: 0.000953
Validation Loss: 0.00086285
Epoch [210/300], Train Loss: 0.000954
Validation Loss: 0.00083153
Epoch [211/300], Train Loss: 0.000946
Validation Loss: 0.00082794
Epoch [212/300], Train Loss: 0.000943
Validation Loss: 0.00082774
Epoch [213/300], Train Loss: 0.000947
Validation Loss: 0.00082626
Epoch [214/300], Train Loss: 0.000943
Validation Loss: 0.00082552
Epoch [215/300], Train Loss: 0.000946
Validation Loss: 0.00084098
Epoch [216/300], Train Loss: 0.000944
Validation Loss: 0.00082458
Epoch [217/300], Train Loss: 0.000940
Validation Loss: 0.00081596
Epoch [218/300], Train Loss: 0.000939
Validation Loss: 0.00082914
Epoch [219/300], Train Loss: 0.000939
Validation Loss: 0.00083921
Epoch [220/300], Train Loss: 0.000939
Validation Loss: 0.00081726
Epoch [221/300], Train Loss: 0.000938
Validation Loss: 0.00083195
Epoch [222/300], Train Loss: 0.000943
Validation Loss: 0.00081887
Epoch [223/300], Train Loss: 0.000934
Validation Loss: 0.00081955
Epoch [224/300], Train Loss: 0.000935
Validation Loss: 0.00081280
Epoch [225/300], Train Loss: 0.000936
Validation Loss: 0.00081146
Epoch [226/300], Train Loss: 0.000929
Validation Loss: 0.00081570
Epoch [227/300], Train Loss: 0.000930
Validation Loss: 0.00081331
Epoch [228/300], Train Loss: 0.000929
Validation Loss: 0.00081465
Epoch [229/300], Train Loss: 0.000930
Validation Loss: 0.00080919
Epoch [230/300], Train Loss: 0.000926
Validation Loss: 0.00081169
Epoch [231/300], Train Loss: 0.000927
Validation Loss: 0.00082879
Epoch [232/300], Train Loss: 0.000928
Validation Loss: 0.00080885
Epoch [233/300], Train Loss: 0.000926
Validation Loss: 0.00081267
Epoch [234/300], Train Loss: 0.000926
Validation Loss: 0.00080669
Epoch [235/300], Train Loss: 0.000926
Validation Loss: 0.00080486
Epoch [236/300], Train Loss: 0.000923
Validation Loss: 0.00080768
Epoch [237/300], Train Loss: 0.000924
Validation Loss: 0.00080776
Epoch [238/300], Train Loss: 0.000917
Validation Loss: 0.00080453
Epoch [239/300], Train Loss: 0.000918
Validation Loss: 0.00080263
Epoch [240/300], Train Loss: 0.000922
Validation Loss: 0.00080311
Epoch [241/300], Train Loss: 0.000925
Validation Loss: 0.00080369
Epoch [242/300], Train Loss: 0.000916
Validation Loss: 0.00079985
Epoch [243/300], Train Loss: 0.000916
Validation Loss: 0.00079842
Epoch [244/300], Train Loss: 0.000915
Validation Loss: 0.00079804
Epoch [245/300], Train Loss: 0.000914
Validation Loss: 0.00080237
Epoch [246/300], Train Loss: 0.000916
Validation Loss: 0.00080041
Epoch [247/300], Train Loss: 0.000913
Validation Loss: 0.00080122
Epoch [248/300], Train Loss: 0.000911
Validation Loss: 0.00080229
Epoch [249/300], Train Loss: 0.000912
Validation Loss: 0.00079959
Epoch [250/300], Train Loss: 0.000912
Validation Loss: 0.00080174
Epoch [251/300], Train Loss: 0.000912
Validation Loss: 0.00080196
Epoch [252/300], Train Loss: 0.000910
Validation Loss: 0.00079956
Epoch [253/300], Train Loss: 0.000910
Validation Loss: 0.00079975
Epoch [254/300], Train Loss: 0.000909
Validation Loss: 0.00079341
Epoch [255/300], Train Loss: 0.000913
Validation Loss: 0.00081173
Epoch [256/300], Train Loss: 0.000907
Validation Loss: 0.00080147
Epoch [257/300], Train Loss: 0.000908
Validation Loss: 0.00079646
Epoch [258/300], Train Loss: 0.000905
Validation Loss: 0.00079711
Epoch [259/300], Train Loss: 0.000902
Validation Loss: 0.00079104
Epoch [260/300], Train Loss: 0.000905
Validation Loss: 0.00082335
Epoch [261/300], Train Loss: 0.000907
Validation Loss: 0.00079231
Epoch [262/300], Train Loss: 0.000905
Validation Loss: 0.00079112
Epoch [263/300], Train Loss: 0.000905
Validation Loss: 0.00079100
Epoch [264/300], Train Loss: 0.000902
Validation Loss: 0.00078858
Epoch [265/300], Train Loss: 0.000902
Validation Loss: 0.00078834
Epoch [266/300], Train Loss: 0.000906
Validation Loss: 0.00081250
Epoch [267/300], Train Loss: 0.000902
Validation Loss: 0.00078633
Epoch [268/300], Train Loss: 0.000899
Validation Loss: 0.00078596
Epoch [269/300], Train Loss: 0.000901
Validation Loss: 0.00080431
Epoch [270/300], Train Loss: 0.000906
Validation Loss: 0.00078368
Epoch [271/300], Train Loss: 0.000897
Validation Loss: 0.00079648
Epoch [272/300], Train Loss: 0.000898
Validation Loss: 0.00078291
Epoch [273/300], Train Loss: 0.000894
Validation Loss: 0.00078386
Epoch [274/300], Train Loss: 0.000895
Validation Loss: 0.00078515
Epoch [275/300], Train Loss: 0.000894
Validation Loss: 0.00078720
Epoch [276/300], Train Loss: 0.000895
Validation Loss: 0.00078686
Epoch [277/300], Train Loss: 0.000894
Validation Loss: 0.00078296
Epoch [278/300], Train Loss: 0.000892
Validation Loss: 0.00078365
Epoch [279/300], Train Loss: 0.000890
Validation Loss: 0.00078805
Epoch [280/300], Train Loss: 0.000894
Validation Loss: 0.00078768
Epoch [281/300], Train Loss: 0.000890
Validation Loss: 0.00078427
Epoch [282/300], Train Loss: 0.000893
Validation Loss: 0.00078039
Epoch [283/300], Train Loss: 0.000892
Validation Loss: 0.00077911
Epoch [284/300], Train Loss: 0.000888
Validation Loss: 0.00078227
Epoch [285/300], Train Loss: 0.000886
Validation Loss: 0.00078007
Epoch [286/300], Train Loss: 0.000887
Validation Loss: 0.00077833
Epoch [287/300], Train Loss: 0.000887
Validation Loss: 0.00077884
Epoch [288/300], Train Loss: 0.000891
Validation Loss: 0.00077689
Epoch [289/300], Train Loss: 0.000887
Validation Loss: 0.00078159
Epoch [290/300], Train Loss: 0.000887
Validation Loss: 0.00078383
Epoch [291/300], Train Loss: 0.000887
Validation Loss: 0.00078082
Epoch [292/300], Train Loss: 0.000884
Validation Loss: 0.00077705
Epoch [293/300], Train Loss: 0.000883
Validation Loss: 0.00077536
Epoch [294/300], Train Loss: 0.000884
Validation Loss: 0.00077763
Epoch [295/300], Train Loss: 0.000884
Validation Loss: 0.00077945
Epoch [296/300], Train Loss: 0.000884
Validation Loss: 0.00077586
Epoch [297/300], Train Loss: 0.000880
Validation Loss: 0.00077257
Epoch [298/300], Train Loss: 0.000881
Validation Loss: 0.00077422
Epoch [299/300], Train Loss: 0.000882
Validation Loss: 0.00077553
Epoch [300/300], Train Loss: 0.000882
Validation Loss: 0.00077415

Evaluating model for: Freezer
Run 5/72 completed in 1908.92 seconds with: {'MAE': np.float32(25.03712), 'MSE': np.float32(1212.3276), 'RMSE': np.float32(34.818497), 'SAE': np.float32(0.020574935), 'NDE': np.float32(0.26959342)}

Run 6/72: hidden=128, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Freezer
Dataset length: 7026 windows

Epoch [1/300], Train Loss: 0.011983
Validation Loss: 0.00646841
Epoch [2/300], Train Loss: 0.006230
Validation Loss: 0.00598803
Epoch [3/300], Train Loss: 0.006130
Validation Loss: 0.00590035
Epoch [4/300], Train Loss: 0.006043
Validation Loss: 0.00577491
Epoch [5/300], Train Loss: 0.005766
Validation Loss: 0.00526236
Epoch [6/300], Train Loss: 0.005205
Validation Loss: 0.00480293
Epoch [7/300], Train Loss: 0.004491
Validation Loss: 0.00412226
Epoch [8/300], Train Loss: 0.003748
Validation Loss: 0.00345703
Epoch [9/300], Train Loss: 0.003225
Validation Loss: 0.00310740
Epoch [10/300], Train Loss: 0.002959
Validation Loss: 0.00293911
Epoch [11/300], Train Loss: 0.002748
Validation Loss: 0.00258983
Epoch [12/300], Train Loss: 0.002524
Validation Loss: 0.00240579
Epoch [13/300], Train Loss: 0.002366
Validation Loss: 0.00224668
Epoch [14/300], Train Loss: 0.002267
Validation Loss: 0.00216585
Epoch [15/300], Train Loss: 0.002200
Validation Loss: 0.00208825
Epoch [16/300], Train Loss: 0.002155
Validation Loss: 0.00214695
Epoch [17/300], Train Loss: 0.002142
Validation Loss: 0.00207066
Epoch [18/300], Train Loss: 0.002083
Validation Loss: 0.00198091
Epoch [19/300], Train Loss: 0.002050
Validation Loss: 0.00196088
Epoch [20/300], Train Loss: 0.002024
Validation Loss: 0.00191969
Epoch [21/300], Train Loss: 0.002011
Validation Loss: 0.00191523
Epoch [22/300], Train Loss: 0.001989
Validation Loss: 0.00189339
Epoch [23/300], Train Loss: 0.001968
Validation Loss: 0.00186977
Epoch [24/300], Train Loss: 0.001956
Validation Loss: 0.00187080
Epoch [25/300], Train Loss: 0.001938
Validation Loss: 0.00185983
Epoch [26/300], Train Loss: 0.001928
Validation Loss: 0.00183681
Epoch [27/300], Train Loss: 0.001914
Validation Loss: 0.00182609
Epoch [28/300], Train Loss: 0.001903
Validation Loss: 0.00184325
Epoch [29/300], Train Loss: 0.001892
Validation Loss: 0.00181091
Epoch [30/300], Train Loss: 0.001886
Validation Loss: 0.00180393
Epoch [31/300], Train Loss: 0.001877
Validation Loss: 0.00178877
Epoch [32/300], Train Loss: 0.001855
Validation Loss: 0.00178596
Epoch [33/300], Train Loss: 0.001853
Validation Loss: 0.00178010
Epoch [34/300], Train Loss: 0.001842
Validation Loss: 0.00177452
Epoch [35/300], Train Loss: 0.001834
Validation Loss: 0.00175414
Epoch [36/300], Train Loss: 0.001828
Validation Loss: 0.00175315
Epoch [37/300], Train Loss: 0.001817
Validation Loss: 0.00175394
Epoch [38/300], Train Loss: 0.001798
Validation Loss: 0.00172868
Epoch [39/300], Train Loss: 0.001788
Validation Loss: 0.00171736
Epoch [40/300], Train Loss: 0.001773
Validation Loss: 0.00169836
Epoch [41/300], Train Loss: 0.001769
Validation Loss: 0.00169599
Epoch [42/300], Train Loss: 0.001765
Validation Loss: 0.00170321
Epoch [43/300], Train Loss: 0.001770
Validation Loss: 0.00170825
Epoch [44/300], Train Loss: 0.001751
Validation Loss: 0.00167421
Epoch [45/300], Train Loss: 0.001739
Validation Loss: 0.00167049
Epoch [46/300], Train Loss: 0.001746
Validation Loss: 0.00167273
Epoch [47/300], Train Loss: 0.001742
Validation Loss: 0.00168504
Epoch [48/300], Train Loss: 0.001735
Validation Loss: 0.00167756
Epoch [49/300], Train Loss: 0.001722
Validation Loss: 0.00167115
Epoch [50/300], Train Loss: 0.001736
Validation Loss: 0.00169672
Epoch [51/300], Train Loss: 0.001730
Validation Loss: 0.00170158
Epoch [52/300], Train Loss: 0.001713
Validation Loss: 0.00164538
Epoch [53/300], Train Loss: 0.001705
Validation Loss: 0.00163937
Epoch [54/300], Train Loss: 0.001696
Validation Loss: 0.00163801
Epoch [55/300], Train Loss: 0.001688
Validation Loss: 0.00164995
Epoch [56/300], Train Loss: 0.001692
Validation Loss: 0.00164721
Epoch [57/300], Train Loss: 0.001694
Validation Loss: 0.00168862
Epoch [58/300], Train Loss: 0.001676
Validation Loss: 0.00165772
Epoch [59/300], Train Loss: 0.001683
Validation Loss: 0.00163330
Epoch [60/300], Train Loss: 0.001678
Validation Loss: 0.00162100
Epoch [61/300], Train Loss: 0.001666
Validation Loss: 0.00161483
Epoch [62/300], Train Loss: 0.001665
Validation Loss: 0.00161572
Epoch [63/300], Train Loss: 0.001662
Validation Loss: 0.00160464
Epoch [64/300], Train Loss: 0.001662
Validation Loss: 0.00162086
Epoch [65/300], Train Loss: 0.001650
Validation Loss: 0.00162377
Epoch [66/300], Train Loss: 0.001659
Validation Loss: 0.00159678
Epoch [67/300], Train Loss: 0.001645
Validation Loss: 0.00159414
Epoch [68/300], Train Loss: 0.001638
Validation Loss: 0.00159702
Epoch [69/300], Train Loss: 0.001634
Validation Loss: 0.00161259
Epoch [70/300], Train Loss: 0.001641
Validation Loss: 0.00159178
Epoch [71/300], Train Loss: 0.001629
Validation Loss: 0.00158903
Epoch [72/300], Train Loss: 0.001625
Validation Loss: 0.00159242
Epoch [73/300], Train Loss: 0.001624
Validation Loss: 0.00158618
Epoch [74/300], Train Loss: 0.001618
Validation Loss: 0.00158919
Epoch [75/300], Train Loss: 0.001622
Validation Loss: 0.00157777
Epoch [76/300], Train Loss: 0.001614
Validation Loss: 0.00159624
Epoch [77/300], Train Loss: 0.001620
Validation Loss: 0.00157306
Epoch [78/300], Train Loss: 0.001608
Validation Loss: 0.00156784
Epoch [79/300], Train Loss: 0.001605
Validation Loss: 0.00161086
Epoch [80/300], Train Loss: 0.001615
Validation Loss: 0.00157619
Epoch [81/300], Train Loss: 0.001607
Validation Loss: 0.00157250
Epoch [82/300], Train Loss: 0.001598
Validation Loss: 0.00157649
Epoch [83/300], Train Loss: 0.001602
Validation Loss: 0.00155905
Epoch [84/300], Train Loss: 0.001597
Validation Loss: 0.00156625
Epoch [85/300], Train Loss: 0.001597
Validation Loss: 0.00157346
Epoch [86/300], Train Loss: 0.001605
Validation Loss: 0.00162139
Epoch [87/300], Train Loss: 0.001594
Validation Loss: 0.00156010
Epoch [88/300], Train Loss: 0.001594
Validation Loss: 0.00156300
Epoch [89/300], Train Loss: 0.001591
Validation Loss: 0.00157556
Epoch [90/300], Train Loss: 0.001586
Validation Loss: 0.00155530
Epoch [91/300], Train Loss: 0.001579
Validation Loss: 0.00156782
Epoch [92/300], Train Loss: 0.001577
Validation Loss: 0.00154877
Epoch [93/300], Train Loss: 0.001577
Validation Loss: 0.00155328
Epoch [94/300], Train Loss: 0.001577
Validation Loss: 0.00154441
Epoch [95/300], Train Loss: 0.001588
Validation Loss: 0.00155899
Epoch [96/300], Train Loss: 0.001574
Validation Loss: 0.00155329
Epoch [97/300], Train Loss: 0.001569
Validation Loss: 0.00154359
Epoch [98/300], Train Loss: 0.001567
Validation Loss: 0.00153680
Epoch [99/300], Train Loss: 0.001560
Validation Loss: 0.00154448
Epoch [100/300], Train Loss: 0.001564
Validation Loss: 0.00153757
Epoch [101/300], Train Loss: 0.001566
Validation Loss: 0.00153283
Epoch [102/300], Train Loss: 0.001562
Validation Loss: 0.00153229
Epoch [103/300], Train Loss: 0.001561
Validation Loss: 0.00154220
Epoch [104/300], Train Loss: 0.001559
Validation Loss: 0.00154093
Epoch [105/300], Train Loss: 0.001555
Validation Loss: 0.00152688
Epoch [106/300], Train Loss: 0.001560
Validation Loss: 0.00155283
Epoch [107/300], Train Loss: 0.001555
Validation Loss: 0.00153881
Epoch [108/300], Train Loss: 0.001552
Validation Loss: 0.00153494
Epoch [109/300], Train Loss: 0.001545
Validation Loss: 0.00153758
Epoch [110/300], Train Loss: 0.001550
Validation Loss: 0.00152588
Epoch [111/300], Train Loss: 0.001544
Validation Loss: 0.00152557
Epoch [112/300], Train Loss: 0.001543
Validation Loss: 0.00152027
Epoch [113/300], Train Loss: 0.001552
Validation Loss: 0.00155535
Epoch [114/300], Train Loss: 0.001544
Validation Loss: 0.00155546
Epoch [115/300], Train Loss: 0.001539
Validation Loss: 0.00155940
Epoch [116/300], Train Loss: 0.001540
Validation Loss: 0.00154688
Epoch [117/300], Train Loss: 0.001540
Validation Loss: 0.00156034
Epoch [118/300], Train Loss: 0.001532
Validation Loss: 0.00151873
Epoch [119/300], Train Loss: 0.001532
Validation Loss: 0.00154935
Epoch [120/300], Train Loss: 0.001532
Validation Loss: 0.00152006
Epoch [121/300], Train Loss: 0.001528
Validation Loss: 0.00151795
Epoch [122/300], Train Loss: 0.001528
Validation Loss: 0.00153776
Epoch [123/300], Train Loss: 0.001526
Validation Loss: 0.00152689
Epoch [124/300], Train Loss: 0.001525
Validation Loss: 0.00152475
Epoch [125/300], Train Loss: 0.001522
Validation Loss: 0.00150687
Epoch [126/300], Train Loss: 0.001522
Validation Loss: 0.00152763
Epoch [127/300], Train Loss: 0.001522
Validation Loss: 0.00152489
Epoch [128/300], Train Loss: 0.001528
Validation Loss: 0.00152534
Epoch [129/300], Train Loss: 0.001515
Validation Loss: 0.00150483
Epoch [130/300], Train Loss: 0.001522
Validation Loss: 0.00150623
Epoch [131/300], Train Loss: 0.001518
Validation Loss: 0.00151033
Epoch [132/300], Train Loss: 0.001513
Validation Loss: 0.00150718
Epoch [133/300], Train Loss: 0.001519
Validation Loss: 0.00149921
Epoch [134/300], Train Loss: 0.001512
Validation Loss: 0.00149714
Epoch [135/300], Train Loss: 0.001512
Validation Loss: 0.00151604
Epoch [136/300], Train Loss: 0.001503
Validation Loss: 0.00150403
Epoch [137/300], Train Loss: 0.001505
Validation Loss: 0.00151707
Epoch [138/300], Train Loss: 0.001506
Validation Loss: 0.00149761
Epoch [139/300], Train Loss: 0.001503
Validation Loss: 0.00149941
Epoch [140/300], Train Loss: 0.001499
Validation Loss: 0.00149972
Epoch [141/300], Train Loss: 0.001497
Validation Loss: 0.00149360
Epoch [142/300], Train Loss: 0.001502
Validation Loss: 0.00152032
Epoch [143/300], Train Loss: 0.001500
Validation Loss: 0.00151113
Epoch [144/300], Train Loss: 0.001495
Validation Loss: 0.00149709
Epoch [145/300], Train Loss: 0.001504
Validation Loss: 0.00149883
Epoch [146/300], Train Loss: 0.001491
Validation Loss: 0.00151474
Epoch [147/300], Train Loss: 0.001495
Validation Loss: 0.00149800
Epoch [148/300], Train Loss: 0.001495
Validation Loss: 0.00150831
Epoch [149/300], Train Loss: 0.001484
Validation Loss: 0.00150188
Epoch [150/300], Train Loss: 0.001489
Validation Loss: 0.00149059
Epoch [151/300], Train Loss: 0.001489
Validation Loss: 0.00149144
Epoch [152/300], Train Loss: 0.001483
Validation Loss: 0.00148718
Epoch [153/300], Train Loss: 0.001484
Validation Loss: 0.00150904
Epoch [154/300], Train Loss: 0.001488
Validation Loss: 0.00148903
Epoch [155/300], Train Loss: 0.001478
Validation Loss: 0.00149404
Epoch [156/300], Train Loss: 0.001479
Validation Loss: 0.00148767
Epoch [157/300], Train Loss: 0.001474
Validation Loss: 0.00148602
Epoch [158/300], Train Loss: 0.001476
Validation Loss: 0.00148536
Epoch [159/300], Train Loss: 0.001474
Validation Loss: 0.00148719
Epoch [160/300], Train Loss: 0.001473
Validation Loss: 0.00148213
Epoch [161/300], Train Loss: 0.001470
Validation Loss: 0.00149891
Epoch [162/300], Train Loss: 0.001478
Validation Loss: 0.00148650
Epoch [163/300], Train Loss: 0.001472
Validation Loss: 0.00147949
Epoch [164/300], Train Loss: 0.001469
Validation Loss: 0.00147574
Epoch [165/300], Train Loss: 0.001469
Validation Loss: 0.00150249
Epoch [166/300], Train Loss: 0.001466
Validation Loss: 0.00148624
Epoch [167/300], Train Loss: 0.001462
Validation Loss: 0.00148174
Epoch [168/300], Train Loss: 0.001464
Validation Loss: 0.00147749
Epoch [169/300], Train Loss: 0.001461
Validation Loss: 0.00147235
Epoch [170/300], Train Loss: 0.001463
Validation Loss: 0.00149310
Epoch [171/300], Train Loss: 0.001458
Validation Loss: 0.00147544
Epoch [172/300], Train Loss: 0.001458
Validation Loss: 0.00146880
Epoch [173/300], Train Loss: 0.001458
Validation Loss: 0.00146907
Epoch [174/300], Train Loss: 0.001462
Validation Loss: 0.00146952
Epoch [175/300], Train Loss: 0.001456
Validation Loss: 0.00146498
Epoch [176/300], Train Loss: 0.001453
Validation Loss: 0.00146328
Epoch [177/300], Train Loss: 0.001449
Validation Loss: 0.00146844
Epoch [178/300], Train Loss: 0.001451
Validation Loss: 0.00146007
Epoch [179/300], Train Loss: 0.001449
Validation Loss: 0.00148709
Epoch [180/300], Train Loss: 0.001448
Validation Loss: 0.00148445
Epoch [181/300], Train Loss: 0.001448
Validation Loss: 0.00145473
Epoch [182/300], Train Loss: 0.001453
Validation Loss: 0.00146425
Epoch [183/300], Train Loss: 0.001451
Validation Loss: 0.00147712
Epoch [184/300], Train Loss: 0.001446
Validation Loss: 0.00145485
Epoch [185/300], Train Loss: 0.001444
Validation Loss: 0.00145595
Epoch [186/300], Train Loss: 0.001439
Validation Loss: 0.00145720
Epoch [187/300], Train Loss: 0.001442
Validation Loss: 0.00144449
Epoch [188/300], Train Loss: 0.001436
Validation Loss: 0.00145062
Epoch [189/300], Train Loss: 0.001438
Validation Loss: 0.00145554
Epoch [190/300], Train Loss: 0.001444
Validation Loss: 0.00144091
Epoch [191/300], Train Loss: 0.001435
Validation Loss: 0.00144963
Epoch [192/300], Train Loss: 0.001429
Validation Loss: 0.00144943
Epoch [193/300], Train Loss: 0.001430
Validation Loss: 0.00147638
Epoch [194/300], Train Loss: 0.001436
Validation Loss: 0.00147084
Epoch [195/300], Train Loss: 0.001429
Validation Loss: 0.00143809
Epoch [196/300], Train Loss: 0.001425
Validation Loss: 0.00143699
Epoch [197/300], Train Loss: 0.001424
Validation Loss: 0.00143251
Epoch [198/300], Train Loss: 0.001423
Validation Loss: 0.00144301
Epoch [199/300], Train Loss: 0.001424
Validation Loss: 0.00143814
Epoch [200/300], Train Loss: 0.001425
Validation Loss: 0.00144839
Epoch [201/300], Train Loss: 0.001424
Validation Loss: 0.00144560
Epoch [202/300], Train Loss: 0.001420
Validation Loss: 0.00143098
Epoch [203/300], Train Loss: 0.001421
Validation Loss: 0.00142574
Epoch [204/300], Train Loss: 0.001416
Validation Loss: 0.00143896
Epoch [205/300], Train Loss: 0.001426
Validation Loss: 0.00142422
Epoch [206/300], Train Loss: 0.001414
Validation Loss: 0.00142998
Epoch [207/300], Train Loss: 0.001410
Validation Loss: 0.00142335
Epoch [208/300], Train Loss: 0.001413
Validation Loss: 0.00145785
Epoch [209/300], Train Loss: 0.001418
Validation Loss: 0.00146629
Epoch [210/300], Train Loss: 0.001411
Validation Loss: 0.00142327
Epoch [211/300], Train Loss: 0.001405
Validation Loss: 0.00142810
Epoch [212/300], Train Loss: 0.001399
Validation Loss: 0.00141905
Epoch [213/300], Train Loss: 0.001403
Validation Loss: 0.00141344
Epoch [214/300], Train Loss: 0.001405
Validation Loss: 0.00140358
Epoch [215/300], Train Loss: 0.001403
Validation Loss: 0.00143568
Epoch [216/300], Train Loss: 0.001399
Validation Loss: 0.00142488
Epoch [217/300], Train Loss: 0.001404
Validation Loss: 0.00140760
Epoch [218/300], Train Loss: 0.001392
Validation Loss: 0.00141452
Epoch [219/300], Train Loss: 0.001395
Validation Loss: 0.00143935
Epoch [220/300], Train Loss: 0.001401
Validation Loss: 0.00140329
Epoch [221/300], Train Loss: 0.001390
Validation Loss: 0.00141024
Epoch [222/300], Train Loss: 0.001400
Validation Loss: 0.00140568
Epoch [223/300], Train Loss: 0.001390
Validation Loss: 0.00140345
Epoch [224/300], Train Loss: 0.001386
Validation Loss: 0.00140028
Epoch [225/300], Train Loss: 0.001391
Validation Loss: 0.00139844
Epoch [226/300], Train Loss: 0.001382
Validation Loss: 0.00140093
Epoch [227/300], Train Loss: 0.001381
Validation Loss: 0.00139375
Epoch [228/300], Train Loss: 0.001380
Validation Loss: 0.00139238
Epoch [229/300], Train Loss: 0.001382
Validation Loss: 0.00139043
Epoch [230/300], Train Loss: 0.001375
Validation Loss: 0.00138798
Epoch [231/300], Train Loss: 0.001377
Validation Loss: 0.00141794
Epoch [232/300], Train Loss: 0.001384
Validation Loss: 0.00139494
Epoch [233/300], Train Loss: 0.001380
Validation Loss: 0.00138584
Epoch [234/300], Train Loss: 0.001373
Validation Loss: 0.00138262
Epoch [235/300], Train Loss: 0.001370
Validation Loss: 0.00137919
Epoch [236/300], Train Loss: 0.001372
Validation Loss: 0.00138382
Epoch [237/300], Train Loss: 0.001370
Validation Loss: 0.00137651
Epoch [238/300], Train Loss: 0.001365
Validation Loss: 0.00137401
Epoch [239/300], Train Loss: 0.001366
Validation Loss: 0.00137283
Epoch [240/300], Train Loss: 0.001364
Validation Loss: 0.00137586
Epoch [241/300], Train Loss: 0.001366
Validation Loss: 0.00136822
Epoch [242/300], Train Loss: 0.001361
Validation Loss: 0.00136549
Epoch [243/300], Train Loss: 0.001355
Validation Loss: 0.00136353
Epoch [244/300], Train Loss: 0.001355
Validation Loss: 0.00136123
Epoch [245/300], Train Loss: 0.001353
Validation Loss: 0.00136866
Epoch [246/300], Train Loss: 0.001350
Validation Loss: 0.00135853
Epoch [247/300], Train Loss: 0.001348
Validation Loss: 0.00135609
Epoch [248/300], Train Loss: 0.001349
Validation Loss: 0.00135858
Epoch [249/300], Train Loss: 0.001350
Validation Loss: 0.00135581
Epoch [250/300], Train Loss: 0.001342
Validation Loss: 0.00135317
Epoch [251/300], Train Loss: 0.001349
Validation Loss: 0.00134672
Epoch [252/300], Train Loss: 0.001340
Validation Loss: 0.00134561
Epoch [253/300], Train Loss: 0.001342
Validation Loss: 0.00134631
Epoch [254/300], Train Loss: 0.001335
Validation Loss: 0.00134654
Epoch [255/300], Train Loss: 0.001341
Validation Loss: 0.00136454
Epoch [256/300], Train Loss: 0.001335
Validation Loss: 0.00134099
Epoch [257/300], Train Loss: 0.001332
Validation Loss: 0.00133797
Epoch [258/300], Train Loss: 0.001331
Validation Loss: 0.00133096
Epoch [259/300], Train Loss: 0.001326
Validation Loss: 0.00132808
Epoch [260/300], Train Loss: 0.001327
Validation Loss: 0.00134917
Epoch [261/300], Train Loss: 0.001321
Validation Loss: 0.00132158
Epoch [262/300], Train Loss: 0.001321
Validation Loss: 0.00131795
Epoch [263/300], Train Loss: 0.001319
Validation Loss: 0.00131500
Epoch [264/300], Train Loss: 0.001314
Validation Loss: 0.00131230
Epoch [265/300], Train Loss: 0.001314
Validation Loss: 0.00130899
Epoch [266/300], Train Loss: 0.001312
Validation Loss: 0.00134507
Epoch [267/300], Train Loss: 0.001314
Validation Loss: 0.00130191
Epoch [268/300], Train Loss: 0.001301
Validation Loss: 0.00130121
Epoch [269/300], Train Loss: 0.001311
Validation Loss: 0.00129901
Epoch [270/300], Train Loss: 0.001302
Validation Loss: 0.00129582
Epoch [271/300], Train Loss: 0.001292
Validation Loss: 0.00131365
Epoch [272/300], Train Loss: 0.001296
Validation Loss: 0.00128575
Epoch [273/300], Train Loss: 0.001290
Validation Loss: 0.00129096
Epoch [274/300], Train Loss: 0.001288
Validation Loss: 0.00128348
Epoch [275/300], Train Loss: 0.001285
Validation Loss: 0.00127463
Epoch [276/300], Train Loss: 0.001317
Validation Loss: 0.00128501
Epoch [277/300], Train Loss: 0.001293
Validation Loss: 0.00126824
Epoch [278/300], Train Loss: 0.001283
Validation Loss: 0.00127143
Epoch [279/300], Train Loss: 0.001277
Validation Loss: 0.00126741
Epoch [280/300], Train Loss: 0.001274
Validation Loss: 0.00126528
Epoch [281/300], Train Loss: 0.001268
Validation Loss: 0.00125388
Epoch [282/300], Train Loss: 0.001263
Validation Loss: 0.00125002
Epoch [283/300], Train Loss: 0.001268
Validation Loss: 0.00124480
Epoch [284/300], Train Loss: 0.001256
Validation Loss: 0.00124360
Epoch [285/300], Train Loss: 0.001256
Validation Loss: 0.00123805
Epoch [286/300], Train Loss: 0.001252
Validation Loss: 0.00123263
Epoch [287/300], Train Loss: 0.001249
Validation Loss: 0.00123050
Epoch [288/300], Train Loss: 0.001245
Validation Loss: 0.00122503
Epoch [289/300], Train Loss: 0.001244
Validation Loss: 0.00121936
Epoch [290/300], Train Loss: 0.001236
Validation Loss: 0.00121916
Epoch [291/300], Train Loss: 0.001237
Validation Loss: 0.00121291
Epoch [292/300], Train Loss: 0.001231
Validation Loss: 0.00121078
Epoch [293/300], Train Loss: 0.001227
Validation Loss: 0.00120281
Epoch [294/300], Train Loss: 0.001222
Validation Loss: 0.00119700
Epoch [295/300], Train Loss: 0.001221
Validation Loss: 0.00119440
Epoch [296/300], Train Loss: 0.001214
Validation Loss: 0.00118805
Epoch [297/300], Train Loss: 0.001212
Validation Loss: 0.00117887
Epoch [298/300], Train Loss: 0.001208
Validation Loss: 0.00117692
Epoch [299/300], Train Loss: 0.001207
Validation Loss: 0.00117279
Epoch [300/300], Train Loss: 0.001199
Validation Loss: 0.00116141

Evaluating model for: Freezer
Run 6/72 completed in 1932.72 seconds with: {'MAE': np.float32(28.930153), 'MSE': np.float32(1787.0594), 'RMSE': np.float32(42.273624), 'SAE': np.float32(0.021778712), 'NDE': np.float32(0.32731718)}

Run 7/72: hidden=128, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Freezer
Dataset length: 7026 windows

Epoch [1/300], Train Loss: 0.006053
Validation Loss: 0.00579125
Epoch [2/300], Train Loss: 0.005901
Validation Loss: 0.00576137
Epoch [3/300], Train Loss: 0.005694
Validation Loss: 0.00487567
Epoch [4/300], Train Loss: 0.003497
Validation Loss: 0.00280899
Epoch [5/300], Train Loss: 0.002634
Validation Loss: 0.00250732
Epoch [6/300], Train Loss: 0.002434
Validation Loss: 0.00241883
Epoch [7/300], Train Loss: 0.002338
Validation Loss: 0.00231321
Epoch [8/300], Train Loss: 0.002227
Validation Loss: 0.00213236
Epoch [9/300], Train Loss: 0.002136
Validation Loss: 0.00206777
Epoch [10/300], Train Loss: 0.002097
Validation Loss: 0.00203601
Epoch [11/300], Train Loss: 0.002058
Validation Loss: 0.00198937
Epoch [12/300], Train Loss: 0.002005
Validation Loss: 0.00195039
Epoch [13/300], Train Loss: 0.001970
Validation Loss: 0.00195612
Epoch [14/300], Train Loss: 0.001943
Validation Loss: 0.00189321
Epoch [15/300], Train Loss: 0.001918
Validation Loss: 0.00190505
Epoch [16/300], Train Loss: 0.001904
Validation Loss: 0.00185783
Epoch [17/300], Train Loss: 0.001890
Validation Loss: 0.00184208
Epoch [18/300], Train Loss: 0.001867
Validation Loss: 0.00182553
Epoch [19/300], Train Loss: 0.001856
Validation Loss: 0.00181580
Epoch [20/300], Train Loss: 0.001842
Validation Loss: 0.00179243
Epoch [21/300], Train Loss: 0.001832
Validation Loss: 0.00178261
Epoch [22/300], Train Loss: 0.001825
Validation Loss: 0.00177512
Epoch [23/300], Train Loss: 0.001801
Validation Loss: 0.00176444
Epoch [24/300], Train Loss: 0.001800
Validation Loss: 0.00176142
Epoch [25/300], Train Loss: 0.001781
Validation Loss: 0.00177076
Epoch [26/300], Train Loss: 0.001782
Validation Loss: 0.00174020
Epoch [27/300], Train Loss: 0.001769
Validation Loss: 0.00173404
Epoch [28/300], Train Loss: 0.001762
Validation Loss: 0.00175498
Epoch [29/300], Train Loss: 0.001757
Validation Loss: 0.00171826
Epoch [30/300], Train Loss: 0.001754
Validation Loss: 0.00171884
Epoch [31/300], Train Loss: 0.001743
Validation Loss: 0.00171292
Epoch [32/300], Train Loss: 0.001732
Validation Loss: 0.00170661
Epoch [33/300], Train Loss: 0.001728
Validation Loss: 0.00171176
Epoch [34/300], Train Loss: 0.001721
Validation Loss: 0.00170012
Epoch [35/300], Train Loss: 0.001717
Validation Loss: 0.00168271
Epoch [36/300], Train Loss: 0.001712
Validation Loss: 0.00168873
Epoch [37/300], Train Loss: 0.001707
Validation Loss: 0.00169110
Epoch [38/300], Train Loss: 0.001693
Validation Loss: 0.00167223
Epoch [39/300], Train Loss: 0.001683
Validation Loss: 0.00166124
Epoch [40/300], Train Loss: 0.001671
Validation Loss: 0.00164851
Epoch [41/300], Train Loss: 0.001669
Validation Loss: 0.00164348
Epoch [42/300], Train Loss: 0.001668
Validation Loss: 0.00167783
Epoch [43/300], Train Loss: 0.001682
Validation Loss: 0.00167574
Epoch [44/300], Train Loss: 0.001656
Validation Loss: 0.00163165
Epoch [45/300], Train Loss: 0.001640
Validation Loss: 0.00162823
Epoch [46/300], Train Loss: 0.001643
Validation Loss: 0.00162929
Epoch [47/300], Train Loss: 0.001642
Validation Loss: 0.00162905
Epoch [48/300], Train Loss: 0.001633
Validation Loss: 0.00164321
Epoch [49/300], Train Loss: 0.001622
Validation Loss: 0.00163848
Epoch [50/300], Train Loss: 0.001635
Validation Loss: 0.00168865
Epoch [51/300], Train Loss: 0.001638
Validation Loss: 0.00164351
Epoch [52/300], Train Loss: 0.001611
Validation Loss: 0.00161616
Epoch [53/300], Train Loss: 0.001610
Validation Loss: 0.00161351
Epoch [54/300], Train Loss: 0.001600
Validation Loss: 0.00161462
Epoch [55/300], Train Loss: 0.001597
Validation Loss: 0.00162526
Epoch [56/300], Train Loss: 0.001597
Validation Loss: 0.00161710
Epoch [57/300], Train Loss: 0.001599
Validation Loss: 0.00165490
Epoch [58/300], Train Loss: 0.001593
Validation Loss: 0.00162143
Epoch [59/300], Train Loss: 0.001590
Validation Loss: 0.00161712
Epoch [60/300], Train Loss: 0.001589
Validation Loss: 0.00159554
Epoch [61/300], Train Loss: 0.001585
Validation Loss: 0.00160478
Epoch [62/300], Train Loss: 0.001577
Validation Loss: 0.00160561
Epoch [63/300], Train Loss: 0.001576
Validation Loss: 0.00160648
Epoch [64/300], Train Loss: 0.001576
Validation Loss: 0.00160455
Epoch [65/300], Train Loss: 0.001568
Validation Loss: 0.00160871
Epoch [66/300], Train Loss: 0.001577
Validation Loss: 0.00159718
Epoch [67/300], Train Loss: 0.001569
Validation Loss: 0.00159200
Epoch [68/300], Train Loss: 0.001573
Validation Loss: 0.00157938
Epoch [69/300], Train Loss: 0.001564
Validation Loss: 0.00157670
Epoch [70/300], Train Loss: 0.001562
Validation Loss: 0.00158271
Epoch [71/300], Train Loss: 0.001557
Validation Loss: 0.00160498
Epoch [72/300], Train Loss: 0.001566
Validation Loss: 0.00159609
Epoch [73/300], Train Loss: 0.001565
Validation Loss: 0.00157539
Epoch [74/300], Train Loss: 0.001555
Validation Loss: 0.00160776
Epoch [75/300], Train Loss: 0.001560
Validation Loss: 0.00157441
Epoch [76/300], Train Loss: 0.001550
Validation Loss: 0.00157814
Epoch [77/300], Train Loss: 0.001547
Validation Loss: 0.00156941
Epoch [78/300], Train Loss: 0.001539
Validation Loss: 0.00156021
Epoch [79/300], Train Loss: 0.001535
Validation Loss: 0.00158740
Epoch [80/300], Train Loss: 0.001550
Validation Loss: 0.00158281
Epoch [81/300], Train Loss: 0.001544
Validation Loss: 0.00159022
Epoch [82/300], Train Loss: 0.001533
Validation Loss: 0.00157096
Epoch [83/300], Train Loss: 0.001536
Validation Loss: 0.00155254
Epoch [84/300], Train Loss: 0.001530
Validation Loss: 0.00156607
Epoch [85/300], Train Loss: 0.001529
Validation Loss: 0.00155010
Epoch [86/300], Train Loss: 0.001534
Validation Loss: 0.00163027
Epoch [87/300], Train Loss: 0.001528
Validation Loss: 0.00155764
Epoch [88/300], Train Loss: 0.001527
Validation Loss: 0.00155365
Epoch [89/300], Train Loss: 0.001524
Validation Loss: 0.00156125
Epoch [90/300], Train Loss: 0.001519
Validation Loss: 0.00157128
Epoch [91/300], Train Loss: 0.001513
Validation Loss: 0.00154887
Epoch [92/300], Train Loss: 0.001512
Validation Loss: 0.00155320
Epoch [93/300], Train Loss: 0.001512
Validation Loss: 0.00155076
Epoch [94/300], Train Loss: 0.001516
Validation Loss: 0.00154375
Epoch [95/300], Train Loss: 0.001516
Validation Loss: 0.00155050
Epoch [96/300], Train Loss: 0.001505
Validation Loss: 0.00155157
Epoch [97/300], Train Loss: 0.001507
Validation Loss: 0.00153684
Epoch [98/300], Train Loss: 0.001509
Validation Loss: 0.00153023
Epoch [99/300], Train Loss: 0.001504
Validation Loss: 0.00152705
Epoch [100/300], Train Loss: 0.001509
Validation Loss: 0.00152834
Epoch [101/300], Train Loss: 0.001502
Validation Loss: 0.00152795
Epoch [102/300], Train Loss: 0.001510
Validation Loss: 0.00153196
Epoch [103/300], Train Loss: 0.001502
Validation Loss: 0.00153725
Epoch [104/300], Train Loss: 0.001511
Validation Loss: 0.00153923
Epoch [105/300], Train Loss: 0.001499
Validation Loss: 0.00153269
Epoch [106/300], Train Loss: 0.001494
Validation Loss: 0.00154003
Epoch [107/300], Train Loss: 0.001497
Validation Loss: 0.00153736
Epoch [108/300], Train Loss: 0.001493
Validation Loss: 0.00153444
Epoch [109/300], Train Loss: 0.001492
Validation Loss: 0.00153135
Early stopping triggered

Evaluating model for: Freezer
Run 7/72 completed in 708.76 seconds with: {'MAE': np.float32(32.35029), 'MSE': np.float32(2307.0815), 'RMSE': np.float32(48.03209), 'SAE': np.float32(0.022304682), 'NDE': np.float32(0.37190393)}

Run 8/72: hidden=128, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Freezer
Dataset length: 7026 windows

Epoch [1/300], Train Loss: 0.007493
Validation Loss: 0.00589534
Epoch [2/300], Train Loss: 0.006019
Validation Loss: 0.00586300
Epoch [3/300], Train Loss: 0.006003
Validation Loss: 0.00583925
Epoch [4/300], Train Loss: 0.005966
Validation Loss: 0.00573974
Epoch [5/300], Train Loss: 0.004996
Validation Loss: 0.00392273
Epoch [6/300], Train Loss: 0.003538
Validation Loss: 0.00329445
Epoch [7/300], Train Loss: 0.003054
Validation Loss: 0.00303233
Epoch [8/300], Train Loss: 0.002758
Validation Loss: 0.00265335
Epoch [9/300], Train Loss: 0.002566
Validation Loss: 0.00250061
Epoch [10/300], Train Loss: 0.002455
Validation Loss: 0.00241644
Epoch [11/300], Train Loss: 0.002391
Validation Loss: 0.00225184
Epoch [12/300], Train Loss: 0.002268
Validation Loss: 0.00215813
Epoch [13/300], Train Loss: 0.002212
Validation Loss: 0.00212089
Epoch [14/300], Train Loss: 0.002122
Validation Loss: 0.00201930
Epoch [15/300], Train Loss: 0.002053
Validation Loss: 0.00206017
Epoch [16/300], Train Loss: 0.001979
Validation Loss: 0.00192498
Epoch [17/300], Train Loss: 0.001961
Validation Loss: 0.00190892
Epoch [18/300], Train Loss: 0.001930
Validation Loss: 0.00183539
Epoch [19/300], Train Loss: 0.001906
Validation Loss: 0.00185039
Epoch [20/300], Train Loss: 0.001903
Validation Loss: 0.00182624
Epoch [21/300], Train Loss: 0.001878
Validation Loss: 0.00178495
Epoch [22/300], Train Loss: 0.001861
Validation Loss: 0.00176412
Epoch [23/300], Train Loss: 0.001847
Validation Loss: 0.00176554
Epoch [24/300], Train Loss: 0.001843
Validation Loss: 0.00179131
Epoch [25/300], Train Loss: 0.001821
Validation Loss: 0.00174936
Epoch [26/300], Train Loss: 0.001810
Validation Loss: 0.00175450
Epoch [27/300], Train Loss: 0.001807
Validation Loss: 0.00174381
Epoch [28/300], Train Loss: 0.001805
Validation Loss: 0.00175882
Epoch [29/300], Train Loss: 0.001785
Validation Loss: 0.00171185
Epoch [30/300], Train Loss: 0.001790
Validation Loss: 0.00172193
Epoch [31/300], Train Loss: 0.001776
Validation Loss: 0.00170303
Epoch [32/300], Train Loss: 0.001759
Validation Loss: 0.00170934
Epoch [33/300], Train Loss: 0.001756
Validation Loss: 0.00170895
Epoch [34/300], Train Loss: 0.001755
Validation Loss: 0.00170895
Epoch [35/300], Train Loss: 0.001741
Validation Loss: 0.00166954
Epoch [36/300], Train Loss: 0.001728
Validation Loss: 0.00167880
Epoch [37/300], Train Loss: 0.001725
Validation Loss: 0.00165922
Epoch [38/300], Train Loss: 0.001706
Validation Loss: 0.00168621
Epoch [39/300], Train Loss: 0.001702
Validation Loss: 0.00168411
Epoch [40/300], Train Loss: 0.001692
Validation Loss: 0.00166489
Epoch [41/300], Train Loss: 0.001691
Validation Loss: 0.00165477
Epoch [42/300], Train Loss: 0.001688
Validation Loss: 0.00168692
Epoch [43/300], Train Loss: 0.001701
Validation Loss: 0.00165207
Epoch [44/300], Train Loss: 0.001676
Validation Loss: 0.00164124
Epoch [45/300], Train Loss: 0.001670
Validation Loss: 0.00163794
Epoch [46/300], Train Loss: 0.001674
Validation Loss: 0.00165324
Epoch [47/300], Train Loss: 0.001667
Validation Loss: 0.00165898
Epoch [48/300], Train Loss: 0.001658
Validation Loss: 0.00164235
Epoch [49/300], Train Loss: 0.001654
Validation Loss: 0.00163515
Epoch [50/300], Train Loss: 0.001664
Validation Loss: 0.00166581
Epoch [51/300], Train Loss: 0.001663
Validation Loss: 0.00166556
Epoch [52/300], Train Loss: 0.001644
Validation Loss: 0.00162264
Epoch [53/300], Train Loss: 0.001640
Validation Loss: 0.00161170
Epoch [54/300], Train Loss: 0.001631
Validation Loss: 0.00161689
Epoch [55/300], Train Loss: 0.001628
Validation Loss: 0.00163527
Epoch [56/300], Train Loss: 0.001627
Validation Loss: 0.00161515
Epoch [57/300], Train Loss: 0.001629
Validation Loss: 0.00163602
Epoch [58/300], Train Loss: 0.001619
Validation Loss: 0.00160268
Epoch [59/300], Train Loss: 0.001616
Validation Loss: 0.00161608
Epoch [60/300], Train Loss: 0.001618
Validation Loss: 0.00158604
Epoch [61/300], Train Loss: 0.001608
Validation Loss: 0.00161111
Epoch [62/300], Train Loss: 0.001602
Validation Loss: 0.00160228
Epoch [63/300], Train Loss: 0.001602
Validation Loss: 0.00159367
Epoch [64/300], Train Loss: 0.001598
Validation Loss: 0.00164730
Epoch [65/300], Train Loss: 0.001597
Validation Loss: 0.00159735
Epoch [66/300], Train Loss: 0.001598
Validation Loss: 0.00159680
Epoch [67/300], Train Loss: 0.001586
Validation Loss: 0.00158477
Epoch [68/300], Train Loss: 0.001581
Validation Loss: 0.00157745
Epoch [69/300], Train Loss: 0.001578
Validation Loss: 0.00156314
Epoch [70/300], Train Loss: 0.001576
Validation Loss: 0.00156018
Epoch [71/300], Train Loss: 0.001579
Validation Loss: 0.00158580
Epoch [72/300], Train Loss: 0.001572
Validation Loss: 0.00156862
Epoch [73/300], Train Loss: 0.001572
Validation Loss: 0.00156064
Epoch [74/300], Train Loss: 0.001565
Validation Loss: 0.00157362
Epoch [75/300], Train Loss: 0.001569
Validation Loss: 0.00155069
Epoch [76/300], Train Loss: 0.001562
Validation Loss: 0.00157401
Epoch [77/300], Train Loss: 0.001564
Validation Loss: 0.00155384
Epoch [78/300], Train Loss: 0.001553
Validation Loss: 0.00155150
Epoch [79/300], Train Loss: 0.001554
Validation Loss: 0.00158269
Epoch [80/300], Train Loss: 0.001567
Validation Loss: 0.00157235
Epoch [81/300], Train Loss: 0.001560
Validation Loss: 0.00157628
Epoch [82/300], Train Loss: 0.001552
Validation Loss: 0.00157109
Epoch [83/300], Train Loss: 0.001551
Validation Loss: 0.00154608
Epoch [84/300], Train Loss: 0.001542
Validation Loss: 0.00155597
Epoch [85/300], Train Loss: 0.001542
Validation Loss: 0.00155003
Epoch [86/300], Train Loss: 0.001548
Validation Loss: 0.00157499
Epoch [87/300], Train Loss: 0.001536
Validation Loss: 0.00154899
Epoch [88/300], Train Loss: 0.001542
Validation Loss: 0.00153524
Epoch [89/300], Train Loss: 0.001534
Validation Loss: 0.00155222
Epoch [90/300], Train Loss: 0.001537
Validation Loss: 0.00155535
Epoch [91/300], Train Loss: 0.001534
Validation Loss: 0.00153885
Epoch [92/300], Train Loss: 0.001528
Validation Loss: 0.00153654
Epoch [93/300], Train Loss: 0.001532
Validation Loss: 0.00154050
Epoch [94/300], Train Loss: 0.001535
Validation Loss: 0.00153919
Epoch [95/300], Train Loss: 0.001532
Validation Loss: 0.00153824
Epoch [96/300], Train Loss: 0.001527
Validation Loss: 0.00162694
Epoch [97/300], Train Loss: 0.001568
Validation Loss: 0.00157005
Epoch [98/300], Train Loss: 0.001549
Validation Loss: 0.00155890
Early stopping triggered

Evaluating model for: Freezer
Run 8/72 completed in 662.01 seconds with: {'MAE': np.float32(33.1037), 'MSE': np.float32(2406.3823), 'RMSE': np.float32(49.05489), 'SAE': np.float32(0.035580225), 'NDE': np.float32(0.37982333)}

Run 9/72: hidden=128, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Freezer
Dataset length: 4614 windows

Epoch [1/300], Train Loss: 0.006632
Validation Loss: 0.00563535
Epoch [2/300], Train Loss: 0.005906
Validation Loss: 0.00557051
Epoch [3/300], Train Loss: 0.005847
Validation Loss: 0.00552683
Epoch [4/300], Train Loss: 0.005774
Validation Loss: 0.00544885
Epoch [5/300], Train Loss: 0.005642
Validation Loss: 0.00524796
Epoch [6/300], Train Loss: 0.005390
Validation Loss: 0.00485448
Epoch [7/300], Train Loss: 0.004825
Validation Loss: 0.00436218
Epoch [8/300], Train Loss: 0.004230
Validation Loss: 0.00369744
Epoch [9/300], Train Loss: 0.003464
Validation Loss: 0.00294268
Epoch [10/300], Train Loss: 0.002797
Validation Loss: 0.00261895
Epoch [11/300], Train Loss: 0.002580
Validation Loss: 0.00244317
Epoch [12/300], Train Loss: 0.002430
Validation Loss: 0.00230688
Epoch [13/300], Train Loss: 0.002348
Validation Loss: 0.00217166
Epoch [14/300], Train Loss: 0.002262
Validation Loss: 0.00209220
Epoch [15/300], Train Loss: 0.002199
Validation Loss: 0.00204422
Epoch [16/300], Train Loss: 0.002128
Validation Loss: 0.00197996
Epoch [17/300], Train Loss: 0.002067
Validation Loss: 0.00189806
Epoch [18/300], Train Loss: 0.002004
Validation Loss: 0.00185104
Epoch [19/300], Train Loss: 0.001966
Validation Loss: 0.00182609
Epoch [20/300], Train Loss: 0.001938
Validation Loss: 0.00180481
Epoch [21/300], Train Loss: 0.001918
Validation Loss: 0.00178427
Epoch [22/300], Train Loss: 0.001890
Validation Loss: 0.00176042
Epoch [23/300], Train Loss: 0.001877
Validation Loss: 0.00174386
Epoch [24/300], Train Loss: 0.001863
Validation Loss: 0.00172684
Epoch [25/300], Train Loss: 0.001836
Validation Loss: 0.00171244
Epoch [26/300], Train Loss: 0.001823
Validation Loss: 0.00169971
Epoch [27/300], Train Loss: 0.001811
Validation Loss: 0.00169139
Epoch [28/300], Train Loss: 0.001808
Validation Loss: 0.00170807
Epoch [29/300], Train Loss: 0.001797
Validation Loss: 0.00167604
Epoch [30/300], Train Loss: 0.001792
Validation Loss: 0.00168941
Epoch [31/300], Train Loss: 0.001789
Validation Loss: 0.00167491
Epoch [32/300], Train Loss: 0.001775
Validation Loss: 0.00165784
Epoch [33/300], Train Loss: 0.001769
Validation Loss: 0.00166313
Epoch [34/300], Train Loss: 0.001756
Validation Loss: 0.00164954
Epoch [35/300], Train Loss: 0.001764
Validation Loss: 0.00164538
Epoch [36/300], Train Loss: 0.001746
Validation Loss: 0.00163465
Epoch [37/300], Train Loss: 0.001735
Validation Loss: 0.00163074
Epoch [38/300], Train Loss: 0.001736
Validation Loss: 0.00163829
Epoch [39/300], Train Loss: 0.001726
Validation Loss: 0.00161448
Epoch [40/300], Train Loss: 0.001718
Validation Loss: 0.00161170
Epoch [41/300], Train Loss: 0.001726
Validation Loss: 0.00160801
Epoch [42/300], Train Loss: 0.001711
Validation Loss: 0.00159896
Epoch [43/300], Train Loss: 0.001703
Validation Loss: 0.00158862
Epoch [44/300], Train Loss: 0.001698
Validation Loss: 0.00158487
Epoch [45/300], Train Loss: 0.001702
Validation Loss: 0.00158773
Epoch [46/300], Train Loss: 0.001690
Validation Loss: 0.00158060
Epoch [47/300], Train Loss: 0.001688
Validation Loss: 0.00157433
Epoch [48/300], Train Loss: 0.001680
Validation Loss: 0.00156688
Epoch [49/300], Train Loss: 0.001677
Validation Loss: 0.00156478
Epoch [50/300], Train Loss: 0.001675
Validation Loss: 0.00158447
Epoch [51/300], Train Loss: 0.001668
Validation Loss: 0.00156135
Epoch [52/300], Train Loss: 0.001671
Validation Loss: 0.00157190
Epoch [53/300], Train Loss: 0.001671
Validation Loss: 0.00158740
Epoch [54/300], Train Loss: 0.001667
Validation Loss: 0.00156499
Epoch [55/300], Train Loss: 0.001662
Validation Loss: 0.00154882
Epoch [56/300], Train Loss: 0.001660
Validation Loss: 0.00156715
Epoch [57/300], Train Loss: 0.001650
Validation Loss: 0.00154419
Epoch [58/300], Train Loss: 0.001646
Validation Loss: 0.00154451
Epoch [59/300], Train Loss: 0.001647
Validation Loss: 0.00153749
Epoch [60/300], Train Loss: 0.001646
Validation Loss: 0.00153606
Epoch [61/300], Train Loss: 0.001637
Validation Loss: 0.00153419
Epoch [62/300], Train Loss: 0.001635
Validation Loss: 0.00153081
Epoch [63/300], Train Loss: 0.001646
Validation Loss: 0.00155465
Epoch [64/300], Train Loss: 0.001633
Validation Loss: 0.00154263
Epoch [65/300], Train Loss: 0.001631
Validation Loss: 0.00153142
Epoch [66/300], Train Loss: 0.001627
Validation Loss: 0.00152130
Epoch [67/300], Train Loss: 0.001626
Validation Loss: 0.00151732
Epoch [68/300], Train Loss: 0.001621
Validation Loss: 0.00151556
Epoch [69/300], Train Loss: 0.001618
Validation Loss: 0.00152048
Epoch [70/300], Train Loss: 0.001615
Validation Loss: 0.00152065
Epoch [71/300], Train Loss: 0.001611
Validation Loss: 0.00150874
Epoch [72/300], Train Loss: 0.001614
Validation Loss: 0.00151452
Epoch [73/300], Train Loss: 0.001611
Validation Loss: 0.00152460
Epoch [74/300], Train Loss: 0.001609
Validation Loss: 0.00151176
Epoch [75/300], Train Loss: 0.001610
Validation Loss: 0.00151152
Epoch [76/300], Train Loss: 0.001604
Validation Loss: 0.00150225
Epoch [77/300], Train Loss: 0.001595
Validation Loss: 0.00149036
Epoch [78/300], Train Loss: 0.001593
Validation Loss: 0.00149625
Epoch [79/300], Train Loss: 0.001598
Validation Loss: 0.00150709
Epoch [80/300], Train Loss: 0.001603
Validation Loss: 0.00151782
Epoch [81/300], Train Loss: 0.001583
Validation Loss: 0.00148246
Epoch [82/300], Train Loss: 0.001584
Validation Loss: 0.00148559
Epoch [83/300], Train Loss: 0.001580
Validation Loss: 0.00148412
Epoch [84/300], Train Loss: 0.001572
Validation Loss: 0.00147449
Epoch [85/300], Train Loss: 0.001575
Validation Loss: 0.00148542
Epoch [86/300], Train Loss: 0.001575
Validation Loss: 0.00149348
Epoch [87/300], Train Loss: 0.001574
Validation Loss: 0.00146661
Epoch [88/300], Train Loss: 0.001566
Validation Loss: 0.00146795
Epoch [89/300], Train Loss: 0.001567
Validation Loss: 0.00146084
Epoch [90/300], Train Loss: 0.001574
Validation Loss: 0.00148129
Epoch [91/300], Train Loss: 0.001572
Validation Loss: 0.00147476
Epoch [92/300], Train Loss: 0.001557
Validation Loss: 0.00146205
Epoch [93/300], Train Loss: 0.001558
Validation Loss: 0.00145383
Epoch [94/300], Train Loss: 0.001548
Validation Loss: 0.00145095
Epoch [95/300], Train Loss: 0.001548
Validation Loss: 0.00145725
Epoch [96/300], Train Loss: 0.001551
Validation Loss: 0.00145990
Epoch [97/300], Train Loss: 0.001543
Validation Loss: 0.00144387
Epoch [98/300], Train Loss: 0.001537
Validation Loss: 0.00144291
Epoch [99/300], Train Loss: 0.001541
Validation Loss: 0.00144237
Epoch [100/300], Train Loss: 0.001539
Validation Loss: 0.00146108
Epoch [101/300], Train Loss: 0.001546
Validation Loss: 0.00147391
Epoch [102/300], Train Loss: 0.001539
Validation Loss: 0.00143381
Epoch [103/300], Train Loss: 0.001540
Validation Loss: 0.00143254
Epoch [104/300], Train Loss: 0.001524
Validation Loss: 0.00142792
Epoch [105/300], Train Loss: 0.001528
Validation Loss: 0.00143657
Epoch [106/300], Train Loss: 0.001530
Validation Loss: 0.00142840
Epoch [107/300], Train Loss: 0.001520
Validation Loss: 0.00143127
Epoch [108/300], Train Loss: 0.001522
Validation Loss: 0.00143126
Epoch [109/300], Train Loss: 0.001517
Validation Loss: 0.00142232
Epoch [110/300], Train Loss: 0.001519
Validation Loss: 0.00141924
Epoch [111/300], Train Loss: 0.001513
Validation Loss: 0.00142233
Epoch [112/300], Train Loss: 0.001511
Validation Loss: 0.00141781
Epoch [113/300], Train Loss: 0.001520
Validation Loss: 0.00142413
Epoch [114/300], Train Loss: 0.001513
Validation Loss: 0.00140625
Epoch [115/300], Train Loss: 0.001506
Validation Loss: 0.00140847
Epoch [116/300], Train Loss: 0.001507
Validation Loss: 0.00141510
Epoch [117/300], Train Loss: 0.001503
Validation Loss: 0.00140170
Epoch [118/300], Train Loss: 0.001501
Validation Loss: 0.00141131
Epoch [119/300], Train Loss: 0.001498
Validation Loss: 0.00139575
Epoch [120/300], Train Loss: 0.001495
Validation Loss: 0.00140319
Epoch [121/300], Train Loss: 0.001494
Validation Loss: 0.00140163
Epoch [122/300], Train Loss: 0.001489
Validation Loss: 0.00139026
Epoch [123/300], Train Loss: 0.001488
Validation Loss: 0.00139165
Epoch [124/300], Train Loss: 0.001484
Validation Loss: 0.00139742
Epoch [125/300], Train Loss: 0.001484
Validation Loss: 0.00138738
Epoch [126/300], Train Loss: 0.001476
Validation Loss: 0.00137968
Epoch [127/300], Train Loss: 0.001472
Validation Loss: 0.00137149
Epoch [128/300], Train Loss: 0.001466
Validation Loss: 0.00137129
Epoch [129/300], Train Loss: 0.001471
Validation Loss: 0.00136540
Epoch [130/300], Train Loss: 0.001472
Validation Loss: 0.00136355
Epoch [131/300], Train Loss: 0.001463
Validation Loss: 0.00137220
Epoch [132/300], Train Loss: 0.001473
Validation Loss: 0.00141005
Epoch [133/300], Train Loss: 0.001472
Validation Loss: 0.00137018
Epoch [134/300], Train Loss: 0.001466
Validation Loss: 0.00138322
Epoch [135/300], Train Loss: 0.001457
Validation Loss: 0.00135205
Epoch [136/300], Train Loss: 0.001447
Validation Loss: 0.00134383
Epoch [137/300], Train Loss: 0.001445
Validation Loss: 0.00135789
Epoch [138/300], Train Loss: 0.001442
Validation Loss: 0.00134803
Epoch [139/300], Train Loss: 0.001439
Validation Loss: 0.00133646
Epoch [140/300], Train Loss: 0.001438
Validation Loss: 0.00133505
Epoch [141/300], Train Loss: 0.001441
Validation Loss: 0.00134424
Epoch [142/300], Train Loss: 0.001443
Validation Loss: 0.00133536
Epoch [143/300], Train Loss: 0.001430
Validation Loss: 0.00133892
Epoch [144/300], Train Loss: 0.001428
Validation Loss: 0.00131676
Epoch [145/300], Train Loss: 0.001425
Validation Loss: 0.00132612
Epoch [146/300], Train Loss: 0.001418
Validation Loss: 0.00131273
Epoch [147/300], Train Loss: 0.001414
Validation Loss: 0.00131775
Epoch [148/300], Train Loss: 0.001422
Validation Loss: 0.00131455
Epoch [149/300], Train Loss: 0.001411
Validation Loss: 0.00131572
Epoch [150/300], Train Loss: 0.001407
Validation Loss: 0.00130713
Epoch [151/300], Train Loss: 0.001401
Validation Loss: 0.00130452
Epoch [152/300], Train Loss: 0.001399
Validation Loss: 0.00129781
Epoch [153/300], Train Loss: 0.001397
Validation Loss: 0.00129787
Epoch [154/300], Train Loss: 0.001400
Validation Loss: 0.00131149
Epoch [155/300], Train Loss: 0.001391
Validation Loss: 0.00128850
Epoch [156/300], Train Loss: 0.001386
Validation Loss: 0.00128815
Epoch [157/300], Train Loss: 0.001385
Validation Loss: 0.00129720
Epoch [158/300], Train Loss: 0.001381
Validation Loss: 0.00129718
Epoch [159/300], Train Loss: 0.001384
Validation Loss: 0.00128110
Epoch [160/300], Train Loss: 0.001375
Validation Loss: 0.00126600
Epoch [161/300], Train Loss: 0.001379
Validation Loss: 0.00126669
Epoch [162/300], Train Loss: 0.001374
Validation Loss: 0.00129104
Epoch [163/300], Train Loss: 0.001390
Validation Loss: 0.00130605
Epoch [164/300], Train Loss: 0.001367
Validation Loss: 0.00125962
Epoch [165/300], Train Loss: 0.001360
Validation Loss: 0.00126224
Epoch [166/300], Train Loss: 0.001354
Validation Loss: 0.00124654
Epoch [167/300], Train Loss: 0.001369
Validation Loss: 0.00125021
Epoch [168/300], Train Loss: 0.001356
Validation Loss: 0.00126378
Epoch [169/300], Train Loss: 0.001353
Validation Loss: 0.00126534
Epoch [170/300], Train Loss: 0.001356
Validation Loss: 0.00126188
Epoch [171/300], Train Loss: 0.001353
Validation Loss: 0.00127041
Epoch [172/300], Train Loss: 0.001356
Validation Loss: 0.00123643
Epoch [173/300], Train Loss: 0.001343
Validation Loss: 0.00123136
Epoch [174/300], Train Loss: 0.001345
Validation Loss: 0.00125980
Epoch [175/300], Train Loss: 0.001334
Validation Loss: 0.00123941
Epoch [176/300], Train Loss: 0.001332
Validation Loss: 0.00123974
Epoch [177/300], Train Loss: 0.001331
Validation Loss: 0.00124010
Epoch [178/300], Train Loss: 0.001325
Validation Loss: 0.00122235
Epoch [179/300], Train Loss: 0.001359
Validation Loss: 0.00140049
Epoch [180/300], Train Loss: 0.001408
Validation Loss: 0.00125017
Epoch [181/300], Train Loss: 0.001336
Validation Loss: 0.00124212
Epoch [182/300], Train Loss: 0.001317
Validation Loss: 0.00121856
Epoch [183/300], Train Loss: 0.001310
Validation Loss: 0.00120653
Epoch [184/300], Train Loss: 0.001308
Validation Loss: 0.00120667
Epoch [185/300], Train Loss: 0.001308
Validation Loss: 0.00123051
Epoch [186/300], Train Loss: 0.001309
Validation Loss: 0.00121818
Epoch [187/300], Train Loss: 0.001323
Validation Loss: 0.00122443
Epoch [188/300], Train Loss: 0.001307
Validation Loss: 0.00123381
Epoch [189/300], Train Loss: 0.001306
Validation Loss: 0.00121980
Epoch [190/300], Train Loss: 0.001309
Validation Loss: 0.00120654
Epoch [191/300], Train Loss: 0.001296
Validation Loss: 0.00120125
Epoch [192/300], Train Loss: 0.001293
Validation Loss: 0.00120095
Epoch [193/300], Train Loss: 0.001296
Validation Loss: 0.00118080
Epoch [194/300], Train Loss: 0.001290
Validation Loss: 0.00117819
Epoch [195/300], Train Loss: 0.001293
Validation Loss: 0.00117305
Epoch [196/300], Train Loss: 0.001280
Validation Loss: 0.00117139
Epoch [197/300], Train Loss: 0.001282
Validation Loss: 0.00116858
Epoch [198/300], Train Loss: 0.001287
Validation Loss: 0.00119666
Epoch [199/300], Train Loss: 0.001281
Validation Loss: 0.00118454
Epoch [200/300], Train Loss: 0.001273
Validation Loss: 0.00116189
Epoch [201/300], Train Loss: 0.001277
Validation Loss: 0.00118398
Epoch [202/300], Train Loss: 0.001266
Validation Loss: 0.00115862
Epoch [203/300], Train Loss: 0.001272
Validation Loss: 0.00115220
Epoch [204/300], Train Loss: 0.001264
Validation Loss: 0.00116795
Epoch [205/300], Train Loss: 0.001257
Validation Loss: 0.00114877
Epoch [206/300], Train Loss: 0.001258
Validation Loss: 0.00114929
Epoch [207/300], Train Loss: 0.001256
Validation Loss: 0.00113603
Epoch [208/300], Train Loss: 0.001267
Validation Loss: 0.00120478
Epoch [209/300], Train Loss: 0.001250
Validation Loss: 0.00114487
Epoch [210/300], Train Loss: 0.001250
Validation Loss: 0.00115335
Epoch [211/300], Train Loss: 0.001243
Validation Loss: 0.00113291
Epoch [212/300], Train Loss: 0.001252
Validation Loss: 0.00113004
Epoch [213/300], Train Loss: 0.001238
Validation Loss: 0.00112819
Epoch [214/300], Train Loss: 0.001228
Validation Loss: 0.00112416
Epoch [215/300], Train Loss: 0.001263
Validation Loss: 0.00114145
Epoch [216/300], Train Loss: 0.001229
Validation Loss: 0.00112250
Epoch [217/300], Train Loss: 0.001230
Validation Loss: 0.00111256
Epoch [218/300], Train Loss: 0.001225
Validation Loss: 0.00111937
Epoch [219/300], Train Loss: 0.001224
Validation Loss: 0.00114436
Epoch [220/300], Train Loss: 0.001212
Validation Loss: 0.00111491
Epoch [221/300], Train Loss: 0.001233
Validation Loss: 0.00112672
Epoch [222/300], Train Loss: 0.001220
Validation Loss: 0.00114505
Epoch [223/300], Train Loss: 0.001213
Validation Loss: 0.00109090
Epoch [224/300], Train Loss: 0.001202
Validation Loss: 0.00110164
Epoch [225/300], Train Loss: 0.001200
Validation Loss: 0.00108989
Epoch [226/300], Train Loss: 0.001196
Validation Loss: 0.00108042
Epoch [227/300], Train Loss: 0.001201
Validation Loss: 0.00107478
Epoch [228/300], Train Loss: 0.001189
Validation Loss: 0.00108036
Epoch [229/300], Train Loss: 0.001183
Validation Loss: 0.00106759
Epoch [230/300], Train Loss: 0.001184
Validation Loss: 0.00106710
Epoch [231/300], Train Loss: 0.001183
Validation Loss: 0.00107889
Epoch [232/300], Train Loss: 0.001176
Validation Loss: 0.00105931
Epoch [233/300], Train Loss: 0.001172
Validation Loss: 0.00105696
Epoch [234/300], Train Loss: 0.001168
Validation Loss: 0.00107350
Epoch [235/300], Train Loss: 0.001171
Validation Loss: 0.00104778
Epoch [236/300], Train Loss: 0.001163
Validation Loss: 0.00104726
Epoch [237/300], Train Loss: 0.001158
Validation Loss: 0.00104692
Epoch [238/300], Train Loss: 0.001167
Validation Loss: 0.00104545
Epoch [239/300], Train Loss: 0.001154
Validation Loss: 0.00104054
Epoch [240/300], Train Loss: 0.001146
Validation Loss: 0.00103370
Epoch [241/300], Train Loss: 0.001143
Validation Loss: 0.00102719
Epoch [242/300], Train Loss: 0.001143
Validation Loss: 0.00103275
Epoch [243/300], Train Loss: 0.001144
Validation Loss: 0.00102916
Epoch [244/300], Train Loss: 0.001131
Validation Loss: 0.00101333
Epoch [245/300], Train Loss: 0.001132
Validation Loss: 0.00101941
Epoch [246/300], Train Loss: 0.001127
Validation Loss: 0.00101195
Epoch [247/300], Train Loss: 0.001123
Validation Loss: 0.00102723
Epoch [248/300], Train Loss: 0.001119
Validation Loss: 0.00100008
Epoch [249/300], Train Loss: 0.001114
Validation Loss: 0.00099098
Epoch [250/300], Train Loss: 0.001118
Validation Loss: 0.00099913
Epoch [251/300], Train Loss: 0.001122
Validation Loss: 0.00098957
Epoch [252/300], Train Loss: 0.001109
Validation Loss: 0.00099217
Epoch [253/300], Train Loss: 0.001109
Validation Loss: 0.00098274
Epoch [254/300], Train Loss: 0.001108
Validation Loss: 0.00099533
Epoch [255/300], Train Loss: 0.001092
Validation Loss: 0.00097212
Epoch [256/300], Train Loss: 0.001087
Validation Loss: 0.00099162
Epoch [257/300], Train Loss: 0.001092
Validation Loss: 0.00097043
Epoch [258/300], Train Loss: 0.001089
Validation Loss: 0.00098960
Epoch [259/300], Train Loss: 0.001081
Validation Loss: 0.00096004
Epoch [260/300], Train Loss: 0.001088
Validation Loss: 0.00096213
Epoch [261/300], Train Loss: 0.001097
Validation Loss: 0.00097547
Epoch [262/300], Train Loss: 0.001074
Validation Loss: 0.00094840
Epoch [263/300], Train Loss: 0.001073
Validation Loss: 0.00094915
Epoch [264/300], Train Loss: 0.001070
Validation Loss: 0.00097376
Epoch [265/300], Train Loss: 0.001065
Validation Loss: 0.00094183
Epoch [266/300], Train Loss: 0.001062
Validation Loss: 0.00093561
Epoch [267/300], Train Loss: 0.001057
Validation Loss: 0.00093683
Epoch [268/300], Train Loss: 0.001057
Validation Loss: 0.00093014
Epoch [269/300], Train Loss: 0.001051
Validation Loss: 0.00092356
Epoch [270/300], Train Loss: 0.001049
Validation Loss: 0.00092437
Epoch [271/300], Train Loss: 0.001049
Validation Loss: 0.00092104
Epoch [272/300], Train Loss: 0.001052
Validation Loss: 0.00092473
Epoch [273/300], Train Loss: 0.001041
Validation Loss: 0.00091866
Epoch [274/300], Train Loss: 0.001050
Validation Loss: 0.00091477
Epoch [275/300], Train Loss: 0.001050
Validation Loss: 0.00090818
Epoch [276/300], Train Loss: 0.001038
Validation Loss: 0.00090644
Epoch [277/300], Train Loss: 0.001030
Validation Loss: 0.00091426
Epoch [278/300], Train Loss: 0.001033
Validation Loss: 0.00090843
Epoch [279/300], Train Loss: 0.001037
Validation Loss: 0.00092397
Epoch [280/300], Train Loss: 0.001026
Validation Loss: 0.00090213
Epoch [281/300], Train Loss: 0.001018
Validation Loss: 0.00089612
Epoch [282/300], Train Loss: 0.001017
Validation Loss: 0.00088697
Epoch [283/300], Train Loss: 0.001014
Validation Loss: 0.00088977
Epoch [284/300], Train Loss: 0.001037
Validation Loss: 0.00100365
Epoch [285/300], Train Loss: 0.001104
Validation Loss: 0.00094832
Epoch [286/300], Train Loss: 0.001049
Validation Loss: 0.00092409
Epoch [287/300], Train Loss: 0.001034
Validation Loss: 0.00091271
Epoch [288/300], Train Loss: 0.001032
Validation Loss: 0.00092852
Epoch [289/300], Train Loss: 0.001018
Validation Loss: 0.00090552
Epoch [290/300], Train Loss: 0.001014
Validation Loss: 0.00088572
Epoch [291/300], Train Loss: 0.001009
Validation Loss: 0.00089211
Epoch [292/300], Train Loss: 0.001005
Validation Loss: 0.00087962
Epoch [293/300], Train Loss: 0.001006
Validation Loss: 0.00087695
Epoch [294/300], Train Loss: 0.001006
Validation Loss: 0.00089044
Epoch [295/300], Train Loss: 0.001001
Validation Loss: 0.00087485
Epoch [296/300], Train Loss: 0.001005
Validation Loss: 0.00086994
Epoch [297/300], Train Loss: 0.001002
Validation Loss: 0.00087859
Epoch [298/300], Train Loss: 0.000998
Validation Loss: 0.00086760
Epoch [299/300], Train Loss: 0.000996
Validation Loss: 0.00086584
Epoch [300/300], Train Loss: 0.000998
Validation Loss: 0.00086771

Evaluating model for: Freezer
Run 9/72 completed in 1326.81 seconds with: {'MAE': np.float32(27.925592), 'MSE': np.float32(1537.91), 'RMSE': np.float32(39.216198), 'SAE': np.float32(0.0060313493), 'NDE': np.float32(0.2926489)}

Run 10/72: hidden=128, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Freezer
Dataset length: 4614 windows

Epoch [1/300], Train Loss: 0.008666
Validation Loss: 0.00577921
Epoch [2/300], Train Loss: 0.006047
Validation Loss: 0.00565058
Epoch [3/300], Train Loss: 0.005964
Validation Loss: 0.00564141
Epoch [4/300], Train Loss: 0.005920
Validation Loss: 0.00560678
Epoch [5/300], Train Loss: 0.005851
Validation Loss: 0.00549228
Epoch [6/300], Train Loss: 0.005702
Validation Loss: 0.00520848
Epoch [7/300], Train Loss: 0.004968
Validation Loss: 0.00416652
Epoch [8/300], Train Loss: 0.004006
Validation Loss: 0.00350967
Epoch [9/300], Train Loss: 0.003302
Validation Loss: 0.00289356
Epoch [10/300], Train Loss: 0.002666
Validation Loss: 0.00244553
Epoch [11/300], Train Loss: 0.002402
Validation Loss: 0.00225977
Epoch [12/300], Train Loss: 0.002245
Validation Loss: 0.00211159
Epoch [13/300], Train Loss: 0.002145
Validation Loss: 0.00201046
Epoch [14/300], Train Loss: 0.002069
Validation Loss: 0.00192405
Epoch [15/300], Train Loss: 0.002031
Validation Loss: 0.00190160
Epoch [16/300], Train Loss: 0.002003
Validation Loss: 0.00186434
Epoch [17/300], Train Loss: 0.001984
Validation Loss: 0.00184442
Epoch [18/300], Train Loss: 0.001968
Validation Loss: 0.00184057
Epoch [19/300], Train Loss: 0.001944
Validation Loss: 0.00181484
Epoch [20/300], Train Loss: 0.001931
Validation Loss: 0.00179439
Epoch [21/300], Train Loss: 0.001918
Validation Loss: 0.00179966
Epoch [22/300], Train Loss: 0.001886
Validation Loss: 0.00175589
Epoch [23/300], Train Loss: 0.001872
Validation Loss: 0.00174666
Epoch [24/300], Train Loss: 0.001849
Validation Loss: 0.00171957
Epoch [25/300], Train Loss: 0.001828
Validation Loss: 0.00170308
Epoch [26/300], Train Loss: 0.001814
Validation Loss: 0.00169958
Epoch [27/300], Train Loss: 0.001805
Validation Loss: 0.00168756
Epoch [28/300], Train Loss: 0.001801
Validation Loss: 0.00168259
Epoch [29/300], Train Loss: 0.001788
Validation Loss: 0.00168728
Epoch [30/300], Train Loss: 0.001796
Validation Loss: 0.00169102
Epoch [31/300], Train Loss: 0.001787
Validation Loss: 0.00167498
Epoch [32/300], Train Loss: 0.001779
Validation Loss: 0.00166373
Epoch [33/300], Train Loss: 0.001772
Validation Loss: 0.00166829
Epoch [34/300], Train Loss: 0.001762
Validation Loss: 0.00165766
Epoch [35/300], Train Loss: 0.001763
Validation Loss: 0.00165709
Epoch [36/300], Train Loss: 0.001751
Validation Loss: 0.00164351
Epoch [37/300], Train Loss: 0.001746
Validation Loss: 0.00164182
Epoch [38/300], Train Loss: 0.001746
Validation Loss: 0.00164715
Epoch [39/300], Train Loss: 0.001742
Validation Loss: 0.00163145
Epoch [40/300], Train Loss: 0.001740
Validation Loss: 0.00163503
Epoch [41/300], Train Loss: 0.001741
Validation Loss: 0.00163394
Epoch [42/300], Train Loss: 0.001733
Validation Loss: 0.00162196
Epoch [43/300], Train Loss: 0.001727
Validation Loss: 0.00162141
Epoch [44/300], Train Loss: 0.001724
Validation Loss: 0.00162168
Epoch [45/300], Train Loss: 0.001729
Validation Loss: 0.00160879
Epoch [46/300], Train Loss: 0.001720
Validation Loss: 0.00161788
Epoch [47/300], Train Loss: 0.001716
Validation Loss: 0.00161514
Epoch [48/300], Train Loss: 0.001709
Validation Loss: 0.00159823
Epoch [49/300], Train Loss: 0.001702
Validation Loss: 0.00159076
Epoch [50/300], Train Loss: 0.001705
Validation Loss: 0.00158673
Epoch [51/300], Train Loss: 0.001698
Validation Loss: 0.00158903
Epoch [52/300], Train Loss: 0.001691
Validation Loss: 0.00157262
Epoch [53/300], Train Loss: 0.001691
Validation Loss: 0.00157334
Epoch [54/300], Train Loss: 0.001680
Validation Loss: 0.00155768
Epoch [55/300], Train Loss: 0.001666
Validation Loss: 0.00155071
Epoch [56/300], Train Loss: 0.001670
Validation Loss: 0.00157856
Epoch [57/300], Train Loss: 0.001668
Validation Loss: 0.00154005
Epoch [58/300], Train Loss: 0.001658
Validation Loss: 0.00156767
Epoch [59/300], Train Loss: 0.001662
Validation Loss: 0.00153973
Epoch [60/300], Train Loss: 0.001656
Validation Loss: 0.00153497
Epoch [61/300], Train Loss: 0.001650
Validation Loss: 0.00153676
Epoch [62/300], Train Loss: 0.001649
Validation Loss: 0.00153549
Epoch [63/300], Train Loss: 0.001654
Validation Loss: 0.00155933
Epoch [64/300], Train Loss: 0.001646
Validation Loss: 0.00154585
Epoch [65/300], Train Loss: 0.001652
Validation Loss: 0.00154508
Epoch [66/300], Train Loss: 0.001640
Validation Loss: 0.00152349
Epoch [67/300], Train Loss: 0.001637
Validation Loss: 0.00152222
Epoch [68/300], Train Loss: 0.001636
Validation Loss: 0.00151794
Epoch [69/300], Train Loss: 0.001636
Validation Loss: 0.00152293
Epoch [70/300], Train Loss: 0.001633
Validation Loss: 0.00152268
Epoch [71/300], Train Loss: 0.001629
Validation Loss: 0.00151208
Epoch [72/300], Train Loss: 0.001629
Validation Loss: 0.00152013
Epoch [73/300], Train Loss: 0.001639
Validation Loss: 0.00152875
Epoch [74/300], Train Loss: 0.001623
Validation Loss: 0.00151740
Epoch [75/300], Train Loss: 0.001629
Validation Loss: 0.00151820
Epoch [76/300], Train Loss: 0.001621
Validation Loss: 0.00150777
Epoch [77/300], Train Loss: 0.001615
Validation Loss: 0.00150936
Epoch [78/300], Train Loss: 0.001618
Validation Loss: 0.00150972
Epoch [79/300], Train Loss: 0.001624
Validation Loss: 0.00153460
Epoch [80/300], Train Loss: 0.001614
Validation Loss: 0.00151645
Epoch [81/300], Train Loss: 0.001609
Validation Loss: 0.00150247
Epoch [82/300], Train Loss: 0.001612
Validation Loss: 0.00150514
Epoch [83/300], Train Loss: 0.001606
Validation Loss: 0.00150027
Epoch [84/300], Train Loss: 0.001605
Validation Loss: 0.00149876
Epoch [85/300], Train Loss: 0.001605
Validation Loss: 0.00150556
Epoch [86/300], Train Loss: 0.001606
Validation Loss: 0.00150584
Epoch [87/300], Train Loss: 0.001609
Validation Loss: 0.00150220
Epoch [88/300], Train Loss: 0.001608
Validation Loss: 0.00150045
Epoch [89/300], Train Loss: 0.001607
Validation Loss: 0.00149758
Epoch [90/300], Train Loss: 0.001615
Validation Loss: 0.00149179
Epoch [91/300], Train Loss: 0.001599
Validation Loss: 0.00149596
Epoch [92/300], Train Loss: 0.001590
Validation Loss: 0.00149282
Epoch [93/300], Train Loss: 0.001591
Validation Loss: 0.00148601
Epoch [94/300], Train Loss: 0.001586
Validation Loss: 0.00148263
Epoch [95/300], Train Loss: 0.001587
Validation Loss: 0.00147771
Epoch [96/300], Train Loss: 0.001587
Validation Loss: 0.00147902
Epoch [97/300], Train Loss: 0.001583
Validation Loss: 0.00147069
Epoch [98/300], Train Loss: 0.001575
Validation Loss: 0.00146890
Epoch [99/300], Train Loss: 0.001580
Validation Loss: 0.00146400
Epoch [100/300], Train Loss: 0.001583
Validation Loss: 0.00147162
Epoch [101/300], Train Loss: 0.001586
Validation Loss: 0.00149387
Epoch [102/300], Train Loss: 0.001580
Validation Loss: 0.00146365
Epoch [103/300], Train Loss: 0.001569
Validation Loss: 0.00146626
Epoch [104/300], Train Loss: 0.001564
Validation Loss: 0.00145576
Epoch [105/300], Train Loss: 0.001568
Validation Loss: 0.00145905
Epoch [106/300], Train Loss: 0.001563
Validation Loss: 0.00145204
Epoch [107/300], Train Loss: 0.001559
Validation Loss: 0.00144704
Epoch [108/300], Train Loss: 0.001559
Validation Loss: 0.00145150
Epoch [109/300], Train Loss: 0.001569
Validation Loss: 0.00146170
Epoch [110/300], Train Loss: 0.001552
Validation Loss: 0.00144100
Epoch [111/300], Train Loss: 0.001553
Validation Loss: 0.00144297
Epoch [112/300], Train Loss: 0.001548
Validation Loss: 0.00145362
Epoch [113/300], Train Loss: 0.001560
Validation Loss: 0.00145114
Epoch [114/300], Train Loss: 0.001549
Validation Loss: 0.00143684
Epoch [115/300], Train Loss: 0.001547
Validation Loss: 0.00144512
Epoch [116/300], Train Loss: 0.001549
Validation Loss: 0.00144360
Epoch [117/300], Train Loss: 0.001543
Validation Loss: 0.00143777
Epoch [118/300], Train Loss: 0.001544
Validation Loss: 0.00144345
Epoch [119/300], Train Loss: 0.001542
Validation Loss: 0.00143207
Epoch [120/300], Train Loss: 0.001541
Validation Loss: 0.00143593
Epoch [121/300], Train Loss: 0.001547
Validation Loss: 0.00143284
Epoch [122/300], Train Loss: 0.001542
Validation Loss: 0.00145129
Epoch [123/300], Train Loss: 0.001544
Validation Loss: 0.00143366
Epoch [124/300], Train Loss: 0.001542
Validation Loss: 0.00143127
Epoch [125/300], Train Loss: 0.001535
Validation Loss: 0.00142850
Epoch [126/300], Train Loss: 0.001539
Validation Loss: 0.00144268
Epoch [127/300], Train Loss: 0.001534
Validation Loss: 0.00142598
Epoch [128/300], Train Loss: 0.001528
Validation Loss: 0.00143257
Epoch [129/300], Train Loss: 0.001536
Validation Loss: 0.00142773
Epoch [130/300], Train Loss: 0.001535
Validation Loss: 0.00142366
Epoch [131/300], Train Loss: 0.001535
Validation Loss: 0.00144576
Epoch [132/300], Train Loss: 0.001532
Validation Loss: 0.00143520
Epoch [133/300], Train Loss: 0.001531
Validation Loss: 0.00142677
Epoch [134/300], Train Loss: 0.001528
Validation Loss: 0.00142942
Epoch [135/300], Train Loss: 0.001528
Validation Loss: 0.00142924
Epoch [136/300], Train Loss: 0.001519
Validation Loss: 0.00142070
Epoch [137/300], Train Loss: 0.001520
Validation Loss: 0.00142068
Epoch [138/300], Train Loss: 0.001525
Validation Loss: 0.00145985
Epoch [139/300], Train Loss: 0.001533
Validation Loss: 0.00142874
Epoch [140/300], Train Loss: 0.001524
Validation Loss: 0.00142202
Epoch [141/300], Train Loss: 0.001520
Validation Loss: 0.00141746
Epoch [142/300], Train Loss: 0.001517
Validation Loss: 0.00142102
Epoch [143/300], Train Loss: 0.001516
Validation Loss: 0.00144351
Epoch [144/300], Train Loss: 0.001523
Validation Loss: 0.00141556
Epoch [145/300], Train Loss: 0.001516
Validation Loss: 0.00141421
Epoch [146/300], Train Loss: 0.001519
Validation Loss: 0.00143847
Epoch [147/300], Train Loss: 0.001524
Validation Loss: 0.00143835
Epoch [148/300], Train Loss: 0.001514
Validation Loss: 0.00141411
Epoch [149/300], Train Loss: 0.001509
Validation Loss: 0.00141622
Epoch [150/300], Train Loss: 0.001606
Validation Loss: 0.00148693
Epoch [151/300], Train Loss: 0.001553
Validation Loss: 0.00144779
Epoch [152/300], Train Loss: 0.001530
Validation Loss: 0.00143607
Epoch [153/300], Train Loss: 0.001530
Validation Loss: 0.00142870
Epoch [154/300], Train Loss: 0.001524
Validation Loss: 0.00142162
Epoch [155/300], Train Loss: 0.001518
Validation Loss: 0.00142284
Epoch [156/300], Train Loss: 0.001516
Validation Loss: 0.00141737
Epoch [157/300], Train Loss: 0.001513
Validation Loss: 0.00141598
Epoch [158/300], Train Loss: 0.001514
Validation Loss: 0.00142210
Early stopping triggered

Evaluating model for: Freezer
Run 10/72 completed in 748.87 seconds with: {'MAE': np.float32(34.385277), 'MSE': np.float32(2520.3079), 'RMSE': np.float32(50.202667), 'SAE': np.float32(0.009107868), 'NDE': np.float32(0.37463492)}

Run 11/72: hidden=128, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Freezer
Dataset length: 4614 windows

Epoch [1/300], Train Loss: 0.008141
Validation Loss: 0.00572816
Epoch [2/300], Train Loss: 0.006013
Validation Loss: 0.00565591
Epoch [3/300], Train Loss: 0.005958
Validation Loss: 0.00565141
Epoch [4/300], Train Loss: 0.005938
Validation Loss: 0.00564589
Epoch [5/300], Train Loss: 0.005907
Validation Loss: 0.00558948
Epoch [6/300], Train Loss: 0.005854
Validation Loss: 0.00549946
Epoch [7/300], Train Loss: 0.005364
Validation Loss: 0.00441815
Epoch [8/300], Train Loss: 0.003993
Validation Loss: 0.00352581
Epoch [9/300], Train Loss: 0.003240
Validation Loss: 0.00288297
Epoch [10/300], Train Loss: 0.002780
Validation Loss: 0.00260356
Epoch [11/300], Train Loss: 0.002544
Validation Loss: 0.00242854
Epoch [12/300], Train Loss: 0.002370
Validation Loss: 0.00217332
Epoch [13/300], Train Loss: 0.002387
Validation Loss: 0.00241477
Epoch [14/300], Train Loss: 0.002235
Validation Loss: 0.00212309
Epoch [15/300], Train Loss: 0.002105
Validation Loss: 0.00208737
Epoch [16/300], Train Loss: 0.002067
Validation Loss: 0.00204725
Epoch [17/300], Train Loss: 0.002056
Validation Loss: 0.00202806
Epoch [18/300], Train Loss: 0.002046
Validation Loss: 0.00201353
Epoch [19/300], Train Loss: 0.002036
Validation Loss: 0.00200284
Epoch [20/300], Train Loss: 0.002015
Validation Loss: 0.00199345
Epoch [21/300], Train Loss: 0.002102
Validation Loss: 0.00211765
Epoch [22/300], Train Loss: 0.002050
Validation Loss: 0.00200701
Epoch [23/300], Train Loss: 0.001986
Validation Loss: 0.00198118
Epoch [24/300], Train Loss: 0.001976
Validation Loss: 0.00193072
Epoch [25/300], Train Loss: 0.001952
Validation Loss: 0.00191905
Epoch [26/300], Train Loss: 0.001963
Validation Loss: 0.00192950
Epoch [27/300], Train Loss: 0.001942
Validation Loss: 0.00189708
Epoch [28/300], Train Loss: 0.001921
Validation Loss: 0.00187241
Epoch [29/300], Train Loss: 0.001929
Validation Loss: 0.00194046
Epoch [30/300], Train Loss: 0.001916
Validation Loss: 0.00186585
Epoch [31/300], Train Loss: 0.001892
Validation Loss: 0.00185143
Epoch [32/300], Train Loss: 0.001911
Validation Loss: 0.00283960
Epoch [33/300], Train Loss: 0.002256
Validation Loss: 0.00197312
Epoch [34/300], Train Loss: 0.001978
Validation Loss: 0.00188791
Epoch [35/300], Train Loss: 0.001937
Validation Loss: 0.00185107
Epoch [36/300], Train Loss: 0.001909
Validation Loss: 0.00183314
Epoch [37/300], Train Loss: 0.001892
Validation Loss: 0.00182142
Epoch [38/300], Train Loss: 0.001886
Validation Loss: 0.00180885
Epoch [39/300], Train Loss: 0.001878
Validation Loss: 0.00179818
Epoch [40/300], Train Loss: 0.001864
Validation Loss: 0.00180351
Epoch [41/300], Train Loss: 0.001857
Validation Loss: 0.00181347
Epoch [42/300], Train Loss: 0.001855
Validation Loss: 0.00177798
Epoch [43/300], Train Loss: 0.001838
Validation Loss: 0.00177744
Epoch [44/300], Train Loss: 0.001834
Validation Loss: 0.00178229
Epoch [45/300], Train Loss: 0.001838
Validation Loss: 0.00177316
Epoch [46/300], Train Loss: 0.001823
Validation Loss: 0.00174929
Epoch [47/300], Train Loss: 0.001816
Validation Loss: 0.00174736
Epoch [48/300], Train Loss: 0.001812
Validation Loss: 0.00173997
Epoch [49/300], Train Loss: 0.001804
Validation Loss: 0.00173184
Epoch [50/300], Train Loss: 0.001811
Validation Loss: 0.00174310
Epoch [51/300], Train Loss: 0.001791
Validation Loss: 0.00171133
Epoch [52/300], Train Loss: 0.001787
Validation Loss: 0.00170765
Epoch [53/300], Train Loss: 0.001790
Validation Loss: 0.00170847
Epoch [54/300], Train Loss: 0.001771
Validation Loss: 0.00168468
Epoch [55/300], Train Loss: 0.001868
Validation Loss: 0.00174602
Epoch [56/300], Train Loss: 0.001830
Validation Loss: 0.00175197
Epoch [57/300], Train Loss: 0.001810
Validation Loss: 0.00169344
Epoch [58/300], Train Loss: 0.001799
Validation Loss: 0.00168127
Epoch [59/300], Train Loss: 0.001797
Validation Loss: 0.00171715
Epoch [60/300], Train Loss: 0.001799
Validation Loss: 0.00172456
Epoch [61/300], Train Loss: 0.001788
Validation Loss: 0.00171352
Epoch [62/300], Train Loss: 0.001786
Validation Loss: 0.00172532
Epoch [63/300], Train Loss: 0.001778
Validation Loss: 0.00171355
Epoch [64/300], Train Loss: 0.001779
Validation Loss: 0.00170811
Epoch [65/300], Train Loss: 0.001779
Validation Loss: 0.00170765
Epoch [66/300], Train Loss: 0.001773
Validation Loss: 0.00170768
Epoch [67/300], Train Loss: 0.001813
Validation Loss: 0.00174637
Epoch [68/300], Train Loss: 0.001801
Validation Loss: 0.00173831
Early stopping triggered

Evaluating model for: Freezer
Run 11/72 completed in 335.98 seconds with: {'MAE': np.float32(37.19375), 'MSE': np.float32(3009.7227), 'RMSE': np.float32(54.86094), 'SAE': np.float32(0.02777501), 'NDE': np.float32(0.40939713)}

Run 12/72: hidden=128, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Freezer
Dataset length: 4614 windows

Epoch [1/300], Train Loss: 0.013288
Validation Loss: 0.00716068
Epoch [2/300], Train Loss: 0.006425
Validation Loss: 0.00569838
Epoch [3/300], Train Loss: 0.006046
Validation Loss: 0.00569677
Epoch [4/300], Train Loss: 0.006012
Validation Loss: 0.00567502
Epoch [5/300], Train Loss: 0.005973
Validation Loss: 0.00560007
Epoch [6/300], Train Loss: 0.005856
Validation Loss: 0.00529646
Epoch [7/300], Train Loss: 0.004929
Validation Loss: 0.00406561
Epoch [8/300], Train Loss: 0.003928
Validation Loss: 0.00342930
Epoch [9/300], Train Loss: 0.003431
Validation Loss: 0.00314458
Epoch [10/300], Train Loss: 0.003123
Validation Loss: 0.00292502
Epoch [11/300], Train Loss: 0.002905
Validation Loss: 0.00273379
Epoch [12/300], Train Loss: 0.002673
Validation Loss: 0.00246318
Epoch [13/300], Train Loss: 0.002413
Validation Loss: 0.00216090
Epoch [14/300], Train Loss: 0.002189
Validation Loss: 0.00200246
Epoch [15/300], Train Loss: 0.002084
Validation Loss: 0.00193255
Epoch [16/300], Train Loss: 0.002028
Validation Loss: 0.00191654
Epoch [17/300], Train Loss: 0.002009
Validation Loss: 0.00184655
Epoch [18/300], Train Loss: 0.001982
Validation Loss: 0.00185312
Epoch [19/300], Train Loss: 0.001953
Validation Loss: 0.00182303
Epoch [20/300], Train Loss: 0.001964
Validation Loss: 0.00179187
Epoch [21/300], Train Loss: 0.001940
Validation Loss: 0.00179217
Epoch [22/300], Train Loss: 0.001909
Validation Loss: 0.00175843
Epoch [23/300], Train Loss: 0.001923
Validation Loss: 0.00175526
Epoch [24/300], Train Loss: 0.001897
Validation Loss: 0.00174050
Epoch [25/300], Train Loss: 0.001880
Validation Loss: 0.00172526
Epoch [26/300], Train Loss: 0.001868
Validation Loss: 0.00171389
Epoch [27/300], Train Loss: 0.001858
Validation Loss: 0.00171060
Epoch [28/300], Train Loss: 0.001852
Validation Loss: 0.00170362
Epoch [29/300], Train Loss: 0.001844
Validation Loss: 0.00170699
Epoch [30/300], Train Loss: 0.001847
Validation Loss: 0.00170626
Epoch [31/300], Train Loss: 0.001835
Validation Loss: 0.00167649
Epoch [32/300], Train Loss: 0.001820
Validation Loss: 0.00167389
Epoch [33/300], Train Loss: 0.001827
Validation Loss: 0.00167030
Epoch [34/300], Train Loss: 0.001811
Validation Loss: 0.00166624
Epoch [35/300], Train Loss: 0.001813
Validation Loss: 0.00166502
Epoch [36/300], Train Loss: 0.001797
Validation Loss: 0.00164298
Epoch [37/300], Train Loss: 0.001791
Validation Loss: 0.00165670
Epoch [38/300], Train Loss: 0.001790
Validation Loss: 0.00164510
Epoch [39/300], Train Loss: 0.001780
Validation Loss: 0.00163019
Epoch [40/300], Train Loss: 0.001774
Validation Loss: 0.00162286
Epoch [41/300], Train Loss: 0.001776
Validation Loss: 0.00162803
Epoch [42/300], Train Loss: 0.001772
Validation Loss: 0.00161727
Epoch [43/300], Train Loss: 0.001757
Validation Loss: 0.00160908
Epoch [44/300], Train Loss: 0.001751
Validation Loss: 0.00162064
Epoch [45/300], Train Loss: 0.001758
Validation Loss: 0.00160374
Epoch [46/300], Train Loss: 0.001741
Validation Loss: 0.00159884
Epoch [47/300], Train Loss: 0.001742
Validation Loss: 0.00161782
Epoch [48/300], Train Loss: 0.001739
Validation Loss: 0.00159613
Epoch [49/300], Train Loss: 0.001733
Validation Loss: 0.00159443
Epoch [50/300], Train Loss: 0.001735
Validation Loss: 0.00160881
Epoch [51/300], Train Loss: 0.001728
Validation Loss: 0.00158706
Epoch [52/300], Train Loss: 0.001733
Validation Loss: 0.00160086
Epoch [53/300], Train Loss: 0.001725
Validation Loss: 0.00162495
Epoch [54/300], Train Loss: 0.001713
Validation Loss: 0.00157873
Epoch [55/300], Train Loss: 0.001709
Validation Loss: 0.00156366
Epoch [56/300], Train Loss: 0.001705
Validation Loss: 0.00157100
Epoch [57/300], Train Loss: 0.001693
Validation Loss: 0.00155381
Epoch [58/300], Train Loss: 0.001687
Validation Loss: 0.00155458
Epoch [59/300], Train Loss: 0.001693
Validation Loss: 0.00154847
Epoch [60/300], Train Loss: 0.001685
Validation Loss: 0.00154366
Epoch [61/300], Train Loss: 0.001678
Validation Loss: 0.00154213
Epoch [62/300], Train Loss: 0.001669
Validation Loss: 0.00153744
Epoch [63/300], Train Loss: 0.001683
Validation Loss: 0.00155834
Epoch [64/300], Train Loss: 0.001708
Validation Loss: 0.00161237
Epoch [65/300], Train Loss: 0.001683
Validation Loss: 0.00153998
Epoch [66/300], Train Loss: 0.001671
Validation Loss: 0.00153529
Epoch [67/300], Train Loss: 0.001665
Validation Loss: 0.00154106
Epoch [68/300], Train Loss: 0.001658
Validation Loss: 0.00151757
Epoch [69/300], Train Loss: 0.001652
Validation Loss: 0.00153695
Epoch [70/300], Train Loss: 0.001659
Validation Loss: 0.00153781
Epoch [71/300], Train Loss: 0.001651
Validation Loss: 0.00151686
Epoch [72/300], Train Loss: 0.001648
Validation Loss: 0.00151435
Epoch [73/300], Train Loss: 0.001650
Validation Loss: 0.00152649
Epoch [74/300], Train Loss: 0.001653
Validation Loss: 0.00150940
Epoch [75/300], Train Loss: 0.001639
Validation Loss: 0.00150435
Epoch [76/300], Train Loss: 0.001625
Validation Loss: 0.00149955
Epoch [77/300], Train Loss: 0.001616
Validation Loss: 0.00148483
Epoch [78/300], Train Loss: 0.001615
Validation Loss: 0.00150236
Epoch [79/300], Train Loss: 0.001614
Validation Loss: 0.00151570
Epoch [80/300], Train Loss: 0.001619
Validation Loss: 0.00149263
Epoch [81/300], Train Loss: 0.001600
Validation Loss: 0.00148104
Epoch [82/300], Train Loss: 0.001597
Validation Loss: 0.00147240
Epoch [83/300], Train Loss: 0.001594
Validation Loss: 0.00147291
Epoch [84/300], Train Loss: 0.001589
Validation Loss: 0.00149085
Epoch [85/300], Train Loss: 0.001602
Validation Loss: 0.00147940
Epoch [86/300], Train Loss: 0.001596
Validation Loss: 0.00149407
Epoch [87/300], Train Loss: 0.001599
Validation Loss: 0.00147521
Epoch [88/300], Train Loss: 0.001618
Validation Loss: 0.00150641
Epoch [89/300], Train Loss: 0.001620
Validation Loss: 0.00148688
Epoch [90/300], Train Loss: 0.001614
Validation Loss: 0.00147247
Epoch [91/300], Train Loss: 0.001590
Validation Loss: 0.00147237
Epoch [92/300], Train Loss: 0.001575
Validation Loss: 0.00146301
Epoch [93/300], Train Loss: 0.001577
Validation Loss: 0.00146055
Epoch [94/300], Train Loss: 0.001569
Validation Loss: 0.00144611
Epoch [95/300], Train Loss: 0.001563
Validation Loss: 0.00145082
Epoch [96/300], Train Loss: 0.001564
Validation Loss: 0.00145317
Epoch [97/300], Train Loss: 0.001559
Validation Loss: 0.00143468
Epoch [98/300], Train Loss: 0.001555
Validation Loss: 0.00143687
Epoch [99/300], Train Loss: 0.001559
Validation Loss: 0.00143864
Epoch [100/300], Train Loss: 0.001561
Validation Loss: 0.00147270
Epoch [101/300], Train Loss: 0.001633
Validation Loss: 0.00153308
Epoch [102/300], Train Loss: 0.001574
Validation Loss: 0.00145045
Epoch [103/300], Train Loss: 0.001562
Validation Loss: 0.00144870
Epoch [104/300], Train Loss: 0.001561
Validation Loss: 0.00144397
Epoch [105/300], Train Loss: 0.001554
Validation Loss: 0.00144625
Epoch [106/300], Train Loss: 0.001555
Validation Loss: 0.00143076
Epoch [107/300], Train Loss: 0.001543
Validation Loss: 0.00144137
Epoch [108/300], Train Loss: 0.001549
Validation Loss: 0.00143174
Epoch [109/300], Train Loss: 0.001545
Validation Loss: 0.00145697
Epoch [110/300], Train Loss: 0.001552
Validation Loss: 0.00142995
Epoch [111/300], Train Loss: 0.001547
Validation Loss: 0.00144547
Epoch [112/300], Train Loss: 0.001541
Validation Loss: 0.00143379
Epoch [113/300], Train Loss: 0.001551
Validation Loss: 0.00143271
Epoch [114/300], Train Loss: 0.001549
Validation Loss: 0.00143832
Epoch [115/300], Train Loss: 0.001553
Validation Loss: 0.00146797
Epoch [116/300], Train Loss: 0.001544
Validation Loss: 0.00143236
Epoch [117/300], Train Loss: 0.001533
Validation Loss: 0.00142746
Epoch [118/300], Train Loss: 0.001535
Validation Loss: 0.00143215
Epoch [119/300], Train Loss: 0.001529
Validation Loss: 0.00142235
Epoch [120/300], Train Loss: 0.001528
Validation Loss: 0.00142328
Epoch [121/300], Train Loss: 0.001531
Validation Loss: 0.00143041
Epoch [122/300], Train Loss: 0.001532
Validation Loss: 0.00145805
Epoch [123/300], Train Loss: 0.001534
Validation Loss: 0.00141937
Epoch [124/300], Train Loss: 0.001531
Validation Loss: 0.00142094
Epoch [125/300], Train Loss: 0.001522
Validation Loss: 0.00141930
Epoch [126/300], Train Loss: 0.001521
Validation Loss: 0.00141544
Epoch [127/300], Train Loss: 0.001522
Validation Loss: 0.00140679
Epoch [128/300], Train Loss: 0.001515
Validation Loss: 0.00142541
Epoch [129/300], Train Loss: 0.001520
Validation Loss: 0.00142253
Epoch [130/300], Train Loss: 0.001525
Validation Loss: 0.00142400
Epoch [131/300], Train Loss: 0.001515
Validation Loss: 0.00142221
Epoch [132/300], Train Loss: 0.001519
Validation Loss: 0.00142251
Epoch [133/300], Train Loss: 0.001516
Validation Loss: 0.00141005
Epoch [134/300], Train Loss: 0.001525
Validation Loss: 0.00143513
Epoch [135/300], Train Loss: 0.001517
Validation Loss: 0.00141976
Epoch [136/300], Train Loss: 0.001513
Validation Loss: 0.00142974
Epoch [137/300], Train Loss: 0.001506
Validation Loss: 0.00141954
Early stopping triggered

Evaluating model for: Freezer
Run 12/72 completed in 706.89 seconds with: {'MAE': np.float32(34.194424), 'MSE': np.float32(2494.124), 'RMSE': np.float32(49.941204), 'SAE': np.float32(0.008940857), 'NDE': np.float32(0.3726838)}

Run 13/72: hidden=128, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Freezer
Dataset length: 2322 windows

Epoch [1/300], Train Loss: 0.006380
Validation Loss: 0.00540630
Epoch [2/300], Train Loss: 0.005929
Validation Loss: 0.00556360
Epoch [3/300], Train Loss: 0.005879
Validation Loss: 0.00542909
Epoch [4/300], Train Loss: 0.005842
Validation Loss: 0.00540618
Epoch [5/300], Train Loss: 0.005799
Validation Loss: 0.00537502
Epoch [6/300], Train Loss: 0.005757
Validation Loss: 0.00534056
Epoch [7/300], Train Loss: 0.005693
Validation Loss: 0.00525713
Epoch [8/300], Train Loss: 0.005585
Validation Loss: 0.00515597
Epoch [9/300], Train Loss: 0.005383
Validation Loss: 0.00488118
Epoch [10/300], Train Loss: 0.005006
Validation Loss: 0.00460393
Epoch [11/300], Train Loss: 0.004578
Validation Loss: 0.00425533
Epoch [12/300], Train Loss: 0.004225
Validation Loss: 0.00398504
Epoch [13/300], Train Loss: 0.003971
Validation Loss: 0.00376530
Epoch [14/300], Train Loss: 0.003623
Validation Loss: 0.00337443
Epoch [15/300], Train Loss: 0.003210
Validation Loss: 0.00295864
Epoch [16/300], Train Loss: 0.002815
Validation Loss: 0.00259079
Epoch [17/300], Train Loss: 0.002472
Validation Loss: 0.00241566
Epoch [18/300], Train Loss: 0.002327
Validation Loss: 0.00234006
Epoch [19/300], Train Loss: 0.002295
Validation Loss: 0.00220726
Epoch [20/300], Train Loss: 0.002201
Validation Loss: 0.00219555
Epoch [21/300], Train Loss: 0.002180
Validation Loss: 0.00220735
Epoch [22/300], Train Loss: 0.002152
Validation Loss: 0.00217588
Epoch [23/300], Train Loss: 0.002134
Validation Loss: 0.00218621
Epoch [24/300], Train Loss: 0.002063
Validation Loss: 0.00211222
Epoch [25/300], Train Loss: 0.002025
Validation Loss: 0.00208361
Epoch [26/300], Train Loss: 0.001996
Validation Loss: 0.00203223
Epoch [27/300], Train Loss: 0.001993
Validation Loss: 0.00201834
Epoch [28/300], Train Loss: 0.001927
Validation Loss: 0.00198805
Epoch [29/300], Train Loss: 0.001924
Validation Loss: 0.00197957
Epoch [30/300], Train Loss: 0.001930
Validation Loss: 0.00197070
Epoch [31/300], Train Loss: 0.001903
Validation Loss: 0.00196116
Epoch [32/300], Train Loss: 0.001883
Validation Loss: 0.00195364
Epoch [33/300], Train Loss: 0.001893
Validation Loss: 0.00197045
Epoch [34/300], Train Loss: 0.001899
Validation Loss: 0.00193671
Epoch [35/300], Train Loss: 0.001879
Validation Loss: 0.00193348
Epoch [36/300], Train Loss: 0.001863
Validation Loss: 0.00192551
Epoch [37/300], Train Loss: 0.001881
Validation Loss: 0.00192585
Epoch [38/300], Train Loss: 0.001847
Validation Loss: 0.00191433
Epoch [39/300], Train Loss: 0.001851
Validation Loss: 0.00191282
Epoch [40/300], Train Loss: 0.001847
Validation Loss: 0.00196528
Epoch [41/300], Train Loss: 0.001833
Validation Loss: 0.00190033
Epoch [42/300], Train Loss: 0.001815
Validation Loss: 0.00189732
Epoch [43/300], Train Loss: 0.001810
Validation Loss: 0.00188906
Epoch [44/300], Train Loss: 0.001818
Validation Loss: 0.00187618
Epoch [45/300], Train Loss: 0.001805
Validation Loss: 0.00187460
Epoch [46/300], Train Loss: 0.001793
Validation Loss: 0.00186921
Epoch [47/300], Train Loss: 0.001791
Validation Loss: 0.00186732
Epoch [48/300], Train Loss: 0.001779
Validation Loss: 0.00185835
Epoch [49/300], Train Loss: 0.001779
Validation Loss: 0.00185135
Epoch [50/300], Train Loss: 0.001773
Validation Loss: 0.00184668
Epoch [51/300], Train Loss: 0.001761
Validation Loss: 0.00185078
Epoch [52/300], Train Loss: 0.001742
Validation Loss: 0.00183451
Epoch [53/300], Train Loss: 0.001761
Validation Loss: 0.00183641
Epoch [54/300], Train Loss: 0.001732
Validation Loss: 0.00184657
Epoch [55/300], Train Loss: 0.001741
Validation Loss: 0.00181973
Epoch [56/300], Train Loss: 0.001732
Validation Loss: 0.00184379
Epoch [57/300], Train Loss: 0.001741
Validation Loss: 0.00181235
Epoch [58/300], Train Loss: 0.001729
Validation Loss: 0.00181683
Epoch [59/300], Train Loss: 0.001727
Validation Loss: 0.00180668
Epoch [60/300], Train Loss: 0.001736
Validation Loss: 0.00179775
Epoch [61/300], Train Loss: 0.001724
Validation Loss: 0.00179156
Epoch [62/300], Train Loss: 0.001696
Validation Loss: 0.00178980
Epoch [63/300], Train Loss: 0.001686
Validation Loss: 0.00178503
Epoch [64/300], Train Loss: 0.001714
Validation Loss: 0.00178306
Epoch [65/300], Train Loss: 0.001684
Validation Loss: 0.00177705
Epoch [66/300], Train Loss: 0.001680
Validation Loss: 0.00177526
Epoch [67/300], Train Loss: 0.001677
Validation Loss: 0.00177112
Epoch [68/300], Train Loss: 0.001683
Validation Loss: 0.00177487
Epoch [69/300], Train Loss: 0.001683
Validation Loss: 0.00177057
Epoch [70/300], Train Loss: 0.001663
Validation Loss: 0.00177388
Epoch [71/300], Train Loss: 0.001664
Validation Loss: 0.00179069
Epoch [72/300], Train Loss: 0.001671
Validation Loss: 0.00179539
Epoch [73/300], Train Loss: 0.001693
Validation Loss: 0.00175556
Epoch [74/300], Train Loss: 0.001680
Validation Loss: 0.00175525
Epoch [75/300], Train Loss: 0.001662
Validation Loss: 0.00174964
Epoch [76/300], Train Loss: 0.001665
Validation Loss: 0.00175666
Epoch [77/300], Train Loss: 0.001662
Validation Loss: 0.00175068
Epoch [78/300], Train Loss: 0.001645
Validation Loss: 0.00174716
Epoch [79/300], Train Loss: 0.001659
Validation Loss: 0.00174638
Epoch [80/300], Train Loss: 0.001638
Validation Loss: 0.00175574
Epoch [81/300], Train Loss: 0.001655
Validation Loss: 0.00175078
Epoch [82/300], Train Loss: 0.001654
Validation Loss: 0.00174205
Epoch [83/300], Train Loss: 0.001648
Validation Loss: 0.00173489
Epoch [84/300], Train Loss: 0.001637
Validation Loss: 0.00173958
Epoch [85/300], Train Loss: 0.001646
Validation Loss: 0.00173466
Epoch [86/300], Train Loss: 0.001634
Validation Loss: 0.00173312
Epoch [87/300], Train Loss: 0.001626
Validation Loss: 0.00173109
Epoch [88/300], Train Loss: 0.001659
Validation Loss: 0.00173811
Epoch [89/300], Train Loss: 0.001636
Validation Loss: 0.00173418
Epoch [90/300], Train Loss: 0.001615
Validation Loss: 0.00173225
Epoch [91/300], Train Loss: 0.001625
Validation Loss: 0.00173309
Epoch [92/300], Train Loss: 0.001625
Validation Loss: 0.00172492
Epoch [93/300], Train Loss: 0.001603
Validation Loss: 0.00174179
Epoch [94/300], Train Loss: 0.001624
Validation Loss: 0.00172566
Epoch [95/300], Train Loss: 0.001621
Validation Loss: 0.00172771
Epoch [96/300], Train Loss: 0.001624
Validation Loss: 0.00173392
Epoch [97/300], Train Loss: 0.001632
Validation Loss: 0.00172258
Epoch [98/300], Train Loss: 0.001615
Validation Loss: 0.00173207
Epoch [99/300], Train Loss: 0.001615
Validation Loss: 0.00172599
Epoch [100/300], Train Loss: 0.001619
Validation Loss: 0.00171994
Epoch [101/300], Train Loss: 0.001612
Validation Loss: 0.00172215
Epoch [102/300], Train Loss: 0.001612
Validation Loss: 0.00171967
Epoch [103/300], Train Loss: 0.001603
Validation Loss: 0.00171198
Epoch [104/300], Train Loss: 0.001608
Validation Loss: 0.00171795
Epoch [105/300], Train Loss: 0.001590
Validation Loss: 0.00171571
Epoch [106/300], Train Loss: 0.001606
Validation Loss: 0.00171023
Epoch [107/300], Train Loss: 0.001606
Validation Loss: 0.00171159
Epoch [108/300], Train Loss: 0.001593
Validation Loss: 0.00171253
Epoch [109/300], Train Loss: 0.001599
Validation Loss: 0.00171094
Epoch [110/300], Train Loss: 0.001587
Validation Loss: 0.00170749
Epoch [111/300], Train Loss: 0.001582
Validation Loss: 0.00171427
Epoch [112/300], Train Loss: 0.001574
Validation Loss: 0.00170548
Epoch [113/300], Train Loss: 0.001595
Validation Loss: 0.00173142
Epoch [114/300], Train Loss: 0.001609
Validation Loss: 0.00173547
Epoch [115/300], Train Loss: 0.001614
Validation Loss: 0.00170585
Epoch [116/300], Train Loss: 0.001603
Validation Loss: 0.00171382
Epoch [117/300], Train Loss: 0.001596
Validation Loss: 0.00170665
Epoch [118/300], Train Loss: 0.001584
Validation Loss: 0.00170289
Epoch [119/300], Train Loss: 0.001576
Validation Loss: 0.00170426
Epoch [120/300], Train Loss: 0.001600
Validation Loss: 0.00170040
Epoch [121/300], Train Loss: 0.001597
Validation Loss: 0.00169757
Epoch [122/300], Train Loss: 0.001594
Validation Loss: 0.00170406
Epoch [123/300], Train Loss: 0.001575
Validation Loss: 0.00169891
Epoch [124/300], Train Loss: 0.001572
Validation Loss: 0.00169867
Epoch [125/300], Train Loss: 0.001562
Validation Loss: 0.00169595
Epoch [126/300], Train Loss: 0.001580
Validation Loss: 0.00169939
Epoch [127/300], Train Loss: 0.001598
Validation Loss: 0.00169898
Epoch [128/300], Train Loss: 0.001577
Validation Loss: 0.00169510
Epoch [129/300], Train Loss: 0.001565
Validation Loss: 0.00169609
Epoch [130/300], Train Loss: 0.001573
Validation Loss: 0.00170487
Epoch [131/300], Train Loss: 0.001575
Validation Loss: 0.00169467
Epoch [132/300], Train Loss: 0.001582
Validation Loss: 0.00170910
Epoch [133/300], Train Loss: 0.001556
Validation Loss: 0.00169870
Epoch [134/300], Train Loss: 0.001570
Validation Loss: 0.00169427
Epoch [135/300], Train Loss: 0.001559
Validation Loss: 0.00168889
Epoch [136/300], Train Loss: 0.001570
Validation Loss: 0.00170355
Epoch [137/300], Train Loss: 0.001565
Validation Loss: 0.00168616
Epoch [138/300], Train Loss: 0.001563
Validation Loss: 0.00168932
Epoch [139/300], Train Loss: 0.001558
Validation Loss: 0.00168822
Epoch [140/300], Train Loss: 0.001546
Validation Loss: 0.00168374
Epoch [141/300], Train Loss: 0.001558
Validation Loss: 0.00168754
Epoch [142/300], Train Loss: 0.001560
Validation Loss: 0.00168069
Epoch [143/300], Train Loss: 0.001548
Validation Loss: 0.00168406
Epoch [144/300], Train Loss: 0.001558
Validation Loss: 0.00168362
Epoch [145/300], Train Loss: 0.001544
Validation Loss: 0.00168020
Epoch [146/300], Train Loss: 0.001548
Validation Loss: 0.00167975
Epoch [147/300], Train Loss: 0.001540
Validation Loss: 0.00168475
Epoch [148/300], Train Loss: 0.001544
Validation Loss: 0.00168045
Epoch [149/300], Train Loss: 0.001568
Validation Loss: 0.00168609
Epoch [150/300], Train Loss: 0.001537
Validation Loss: 0.00168008
Epoch [151/300], Train Loss: 0.001553
Validation Loss: 0.00168432
Epoch [152/300], Train Loss: 0.001546
Validation Loss: 0.00168654
Epoch [153/300], Train Loss: 0.001548
Validation Loss: 0.00168319
Epoch [154/300], Train Loss: 0.001543
Validation Loss: 0.00167153
Epoch [155/300], Train Loss: 0.001552
Validation Loss: 0.00167043
Epoch [156/300], Train Loss: 0.001550
Validation Loss: 0.00167493
Epoch [157/300], Train Loss: 0.001575
Validation Loss: 0.00167399
Epoch [158/300], Train Loss: 0.001544
Validation Loss: 0.00167170
Epoch [159/300], Train Loss: 0.001542
Validation Loss: 0.00167579
Epoch [160/300], Train Loss: 0.001539
Validation Loss: 0.00167168
Epoch [161/300], Train Loss: 0.001538
Validation Loss: 0.00166835
Epoch [162/300], Train Loss: 0.001554
Validation Loss: 0.00167140
Epoch [163/300], Train Loss: 0.001525
Validation Loss: 0.00167544
Epoch [164/300], Train Loss: 0.001556
Validation Loss: 0.00167090
Epoch [165/300], Train Loss: 0.001543
Validation Loss: 0.00166797
Epoch [166/300], Train Loss: 0.001551
Validation Loss: 0.00166595
Epoch [167/300], Train Loss: 0.001540
Validation Loss: 0.00166618
Epoch [168/300], Train Loss: 0.001534
Validation Loss: 0.00166607
Epoch [169/300], Train Loss: 0.001538
Validation Loss: 0.00166550
Epoch [170/300], Train Loss: 0.001528
Validation Loss: 0.00166394
Epoch [171/300], Train Loss: 0.001542
Validation Loss: 0.00166678
Epoch [172/300], Train Loss: 0.001523
Validation Loss: 0.00166055
Epoch [173/300], Train Loss: 0.001515
Validation Loss: 0.00166321
Epoch [174/300], Train Loss: 0.001531
Validation Loss: 0.00166335
Epoch [175/300], Train Loss: 0.001523
Validation Loss: 0.00166399
Epoch [176/300], Train Loss: 0.001529
Validation Loss: 0.00166467
Epoch [177/300], Train Loss: 0.001535
Validation Loss: 0.00166642
Epoch [178/300], Train Loss: 0.001526
Validation Loss: 0.00166003
Epoch [179/300], Train Loss: 0.001531
Validation Loss: 0.00166079
Epoch [180/300], Train Loss: 0.001516
Validation Loss: 0.00165833
Epoch [181/300], Train Loss: 0.001524
Validation Loss: 0.00166019
Epoch [182/300], Train Loss: 0.001516
Validation Loss: 0.00165559
Epoch [183/300], Train Loss: 0.001527
Validation Loss: 0.00165787
Epoch [184/300], Train Loss: 0.001537
Validation Loss: 0.00166063
Epoch [185/300], Train Loss: 0.001517
Validation Loss: 0.00165435
Epoch [186/300], Train Loss: 0.001524
Validation Loss: 0.00165535
Epoch [187/300], Train Loss: 0.001551
Validation Loss: 0.00165800
Epoch [188/300], Train Loss: 0.001523
Validation Loss: 0.00165541
Epoch [189/300], Train Loss: 0.001533
Validation Loss: 0.00165525
Epoch [190/300], Train Loss: 0.001524
Validation Loss: 0.00165323
Epoch [191/300], Train Loss: 0.001534
Validation Loss: 0.00165765
Epoch [192/300], Train Loss: 0.001507
Validation Loss: 0.00165391
Epoch [193/300], Train Loss: 0.001515
Validation Loss: 0.00165529
Epoch [194/300], Train Loss: 0.001523
Validation Loss: 0.00165336
Epoch [195/300], Train Loss: 0.001520
Validation Loss: 0.00164781
Epoch [196/300], Train Loss: 0.001518
Validation Loss: 0.00165116
Epoch [197/300], Train Loss: 0.001507
Validation Loss: 0.00165858
Epoch [198/300], Train Loss: 0.001519
Validation Loss: 0.00164893
Epoch [199/300], Train Loss: 0.001508
Validation Loss: 0.00166188
Epoch [200/300], Train Loss: 0.001531
Validation Loss: 0.00165386
Epoch [201/300], Train Loss: 0.001514
Validation Loss: 0.00165259
Epoch [202/300], Train Loss: 0.001513
Validation Loss: 0.00164866
Epoch [203/300], Train Loss: 0.001524
Validation Loss: 0.00164886
Epoch [204/300], Train Loss: 0.001534
Validation Loss: 0.00164797
Epoch [205/300], Train Loss: 0.001515
Validation Loss: 0.00165306
Early stopping triggered

Evaluating model for: Freezer
Run 13/72 completed in 455.60 seconds with: {'MAE': np.float32(37.752106), 'MSE': np.float32(2928.373), 'RMSE': np.float32(54.114445), 'SAE': np.float32(0.037649024), 'NDE': np.float32(0.37932244)}

Run 14/72: hidden=128, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Freezer
Dataset length: 2322 windows

Epoch [1/300], Train Loss: 0.006666
Validation Loss: 0.00540408
Epoch [2/300], Train Loss: 0.005938
Validation Loss: 0.00558902
Epoch [3/300], Train Loss: 0.005885
Validation Loss: 0.00543649
Epoch [4/300], Train Loss: 0.005849
Validation Loss: 0.00541688
Epoch [5/300], Train Loss: 0.005812
Validation Loss: 0.00539287
Epoch [6/300], Train Loss: 0.005773
Validation Loss: 0.00535733
Epoch [7/300], Train Loss: 0.005699
Validation Loss: 0.00525447
Epoch [8/300], Train Loss: 0.005541
Validation Loss: 0.00512577
Epoch [9/300], Train Loss: 0.005228
Validation Loss: 0.00481143
Epoch [10/300], Train Loss: 0.004913
Validation Loss: 0.00468553
Epoch [11/300], Train Loss: 0.004824
Validation Loss: 0.00452511
Epoch [12/300], Train Loss: 0.004615
Validation Loss: 0.00433847
Epoch [13/300], Train Loss: 0.004475
Validation Loss: 0.00413860
Epoch [14/300], Train Loss: 0.004193
Validation Loss: 0.00388848
Epoch [15/300], Train Loss: 0.003886
Validation Loss: 0.00355432
Epoch [16/300], Train Loss: 0.003510
Validation Loss: 0.00301055
Epoch [17/300], Train Loss: 0.003038
Validation Loss: 0.00264027
Epoch [18/300], Train Loss: 0.002786
Validation Loss: 0.00246922
Epoch [19/300], Train Loss: 0.002680
Validation Loss: 0.00236949
Epoch [20/300], Train Loss: 0.002557
Validation Loss: 0.00233772
Epoch [21/300], Train Loss: 0.002485
Validation Loss: 0.00228060
Epoch [22/300], Train Loss: 0.002434
Validation Loss: 0.00222731
Epoch [23/300], Train Loss: 0.002382
Validation Loss: 0.00225580
Epoch [24/300], Train Loss: 0.002284
Validation Loss: 0.00219521
Epoch [25/300], Train Loss: 0.002239
Validation Loss: 0.00216599
Epoch [26/300], Train Loss: 0.002165
Validation Loss: 0.00213025
Epoch [27/300], Train Loss: 0.002143
Validation Loss: 0.00210139
Epoch [28/300], Train Loss: 0.002083
Validation Loss: 0.00208624
Epoch [29/300], Train Loss: 0.002046
Validation Loss: 0.00209349
Epoch [30/300], Train Loss: 0.002040
Validation Loss: 0.00208245
Epoch [31/300], Train Loss: 0.002015
Validation Loss: 0.00205866
Epoch [32/300], Train Loss: 0.001985
Validation Loss: 0.00205251
Epoch [33/300], Train Loss: 0.001997
Validation Loss: 0.00204974
Epoch [34/300], Train Loss: 0.001993
Validation Loss: 0.00203114
Epoch [35/300], Train Loss: 0.001972
Validation Loss: 0.00202908
Epoch [36/300], Train Loss: 0.001959
Validation Loss: 0.00202231
Epoch [37/300], Train Loss: 0.001987
Validation Loss: 0.00201652
Epoch [38/300], Train Loss: 0.001953
Validation Loss: 0.00201201
Epoch [39/300], Train Loss: 0.001954
Validation Loss: 0.00199661
Epoch [40/300], Train Loss: 0.001936
Validation Loss: 0.00204858
Epoch [41/300], Train Loss: 0.001927
Validation Loss: 0.00201210
Epoch [42/300], Train Loss: 0.001909
Validation Loss: 0.00199633
Epoch [43/300], Train Loss: 0.001908
Validation Loss: 0.00197483
Epoch [44/300], Train Loss: 0.001935
Validation Loss: 0.00197762
Epoch [45/300], Train Loss: 0.001906
Validation Loss: 0.00196860
Epoch [46/300], Train Loss: 0.001885
Validation Loss: 0.00195372
Epoch [47/300], Train Loss: 0.001881
Validation Loss: 0.00196107
Epoch [48/300], Train Loss: 0.001872
Validation Loss: 0.00194119
Epoch [49/300], Train Loss: 0.001864
Validation Loss: 0.00194556
Epoch [50/300], Train Loss: 0.001857
Validation Loss: 0.00193683
Epoch [51/300], Train Loss: 0.001849
Validation Loss: 0.00193769
Epoch [52/300], Train Loss: 0.001825
Validation Loss: 0.00191977
Epoch [53/300], Train Loss: 0.001843
Validation Loss: 0.00192404
Epoch [54/300], Train Loss: 0.001810
Validation Loss: 0.00193585
Epoch [55/300], Train Loss: 0.001833
Validation Loss: 0.00191090
Epoch [56/300], Train Loss: 0.001815
Validation Loss: 0.00192627
Epoch [57/300], Train Loss: 0.001820
Validation Loss: 0.00189880
Epoch [58/300], Train Loss: 0.001803
Validation Loss: 0.00190925
Epoch [59/300], Train Loss: 0.001800
Validation Loss: 0.00189140
Epoch [60/300], Train Loss: 0.001812
Validation Loss: 0.00187515
Epoch [61/300], Train Loss: 0.001797
Validation Loss: 0.00185595
Epoch [62/300], Train Loss: 0.001753
Validation Loss: 0.00185739
Epoch [63/300], Train Loss: 0.001747
Validation Loss: 0.00185501
Epoch [64/300], Train Loss: 0.001770
Validation Loss: 0.00183940
Epoch [65/300], Train Loss: 0.001737
Validation Loss: 0.00184556
Epoch [66/300], Train Loss: 0.001733
Validation Loss: 0.00183438
Epoch [67/300], Train Loss: 0.001726
Validation Loss: 0.00182310
Epoch [68/300], Train Loss: 0.001732
Validation Loss: 0.00182846
Epoch [69/300], Train Loss: 0.001728
Validation Loss: 0.00181636
Epoch [70/300], Train Loss: 0.001702
Validation Loss: 0.00181692
Epoch [71/300], Train Loss: 0.001703
Validation Loss: 0.00181863
Epoch [72/300], Train Loss: 0.001713
Validation Loss: 0.00184140
Epoch [73/300], Train Loss: 0.001725
Validation Loss: 0.00180278
Epoch [74/300], Train Loss: 0.001720
Validation Loss: 0.00179284
Epoch [75/300], Train Loss: 0.001704
Validation Loss: 0.00179715
Epoch [76/300], Train Loss: 0.001701
Validation Loss: 0.00179239
Epoch [77/300], Train Loss: 0.001701
Validation Loss: 0.00179595
Epoch [78/300], Train Loss: 0.001677
Validation Loss: 0.00178703
Epoch [79/300], Train Loss: 0.001687
Validation Loss: 0.00178456
Epoch [80/300], Train Loss: 0.001678
Validation Loss: 0.00178671
Epoch [81/300], Train Loss: 0.001688
Validation Loss: 0.00178099
Epoch [82/300], Train Loss: 0.001681
Validation Loss: 0.00177686
Epoch [83/300], Train Loss: 0.001673
Validation Loss: 0.00177153
Epoch [84/300], Train Loss: 0.001666
Validation Loss: 0.00177468
Epoch [85/300], Train Loss: 0.001677
Validation Loss: 0.00176670
Epoch [86/300], Train Loss: 0.001659
Validation Loss: 0.00177148
Epoch [87/300], Train Loss: 0.001658
Validation Loss: 0.00176972
Epoch [88/300], Train Loss: 0.001683
Validation Loss: 0.00177308
Epoch [89/300], Train Loss: 0.001666
Validation Loss: 0.00175787
Epoch [90/300], Train Loss: 0.001640
Validation Loss: 0.00175944
Epoch [91/300], Train Loss: 0.001643
Validation Loss: 0.00175951
Epoch [92/300], Train Loss: 0.001650
Validation Loss: 0.00175741
Epoch [93/300], Train Loss: 0.001623
Validation Loss: 0.00175999
Epoch [94/300], Train Loss: 0.001642
Validation Loss: 0.00175170
Epoch [95/300], Train Loss: 0.001635
Validation Loss: 0.00174440
Epoch [96/300], Train Loss: 0.001636
Validation Loss: 0.00178210
Epoch [97/300], Train Loss: 0.001649
Validation Loss: 0.00174728
Epoch [98/300], Train Loss: 0.001643
Validation Loss: 0.00174386
Epoch [99/300], Train Loss: 0.001621
Validation Loss: 0.00174138
Epoch [100/300], Train Loss: 0.001633
Validation Loss: 0.00173643
Epoch [101/300], Train Loss: 0.001619
Validation Loss: 0.00172662
Epoch [102/300], Train Loss: 0.001625
Validation Loss: 0.00174487
Epoch [103/300], Train Loss: 0.001610
Validation Loss: 0.00173000
Epoch [104/300], Train Loss: 0.001615
Validation Loss: 0.00172161
Epoch [105/300], Train Loss: 0.001595
Validation Loss: 0.00173179
Epoch [106/300], Train Loss: 0.001607
Validation Loss: 0.00172458
Epoch [107/300], Train Loss: 0.001612
Validation Loss: 0.00171872
Epoch [108/300], Train Loss: 0.001614
Validation Loss: 0.00172020
Epoch [109/300], Train Loss: 0.001604
Validation Loss: 0.00172331
Epoch [110/300], Train Loss: 0.001593
Validation Loss: 0.00170836
Epoch [111/300], Train Loss: 0.001583
Validation Loss: 0.00171071
Epoch [112/300], Train Loss: 0.001576
Validation Loss: 0.00174132
Epoch [113/300], Train Loss: 0.001616
Validation Loss: 0.00175316
Epoch [114/300], Train Loss: 0.001617
Validation Loss: 0.00170438
Epoch [115/300], Train Loss: 0.001605
Validation Loss: 0.00173733
Epoch [116/300], Train Loss: 0.001614
Validation Loss: 0.00170517
Epoch [117/300], Train Loss: 0.001610
Validation Loss: 0.00172086
Epoch [118/300], Train Loss: 0.001582
Validation Loss: 0.00171267
Epoch [119/300], Train Loss: 0.001581
Validation Loss: 0.00169049
Epoch [120/300], Train Loss: 0.001599
Validation Loss: 0.00169826
Epoch [121/300], Train Loss: 0.001600
Validation Loss: 0.00168771
Epoch [122/300], Train Loss: 0.001593
Validation Loss: 0.00168992
Epoch [123/300], Train Loss: 0.001571
Validation Loss: 0.00169202
Epoch [124/300], Train Loss: 0.001571
Validation Loss: 0.00168557
Epoch [125/300], Train Loss: 0.001560
Validation Loss: 0.00168771
Epoch [126/300], Train Loss: 0.001587
Validation Loss: 0.00170783
Epoch [127/300], Train Loss: 0.001598
Validation Loss: 0.00169093
Epoch [128/300], Train Loss: 0.001576
Validation Loss: 0.00168923
Epoch [129/300], Train Loss: 0.001564
Validation Loss: 0.00169459
Epoch [130/300], Train Loss: 0.001575
Validation Loss: 0.00167247
Epoch [131/300], Train Loss: 0.001584
Validation Loss: 0.00170599
Epoch [132/300], Train Loss: 0.001581
Validation Loss: 0.00173588
Epoch [133/300], Train Loss: 0.001553
Validation Loss: 0.00168057
Epoch [134/300], Train Loss: 0.001560
Validation Loss: 0.00167594
Epoch [135/300], Train Loss: 0.001550
Validation Loss: 0.00167205
Epoch [136/300], Train Loss: 0.001561
Validation Loss: 0.00167589
Epoch [137/300], Train Loss: 0.001560
Validation Loss: 0.00167845
Epoch [138/300], Train Loss: 0.001553
Validation Loss: 0.00167512
Epoch [139/300], Train Loss: 0.001551
Validation Loss: 0.00166587
Epoch [140/300], Train Loss: 0.001542
Validation Loss: 0.00166052
Epoch [141/300], Train Loss: 0.001555
Validation Loss: 0.00167613
Epoch [142/300], Train Loss: 0.001547
Validation Loss: 0.00167266
Epoch [143/300], Train Loss: 0.001540
Validation Loss: 0.00166743
Epoch [144/300], Train Loss: 0.001556
Validation Loss: 0.00166131
Epoch [145/300], Train Loss: 0.001535
Validation Loss: 0.00166190
Epoch [146/300], Train Loss: 0.001555
Validation Loss: 0.00167139
Epoch [147/300], Train Loss: 0.001548
Validation Loss: 0.00172342
Epoch [148/300], Train Loss: 0.001539
Validation Loss: 0.00165851
Epoch [149/300], Train Loss: 0.001549
Validation Loss: 0.00165654
Epoch [150/300], Train Loss: 0.001523
Validation Loss: 0.00165412
Epoch [151/300], Train Loss: 0.001537
Validation Loss: 0.00164957
Epoch [152/300], Train Loss: 0.001530
Validation Loss: 0.00165440
Epoch [153/300], Train Loss: 0.001528
Validation Loss: 0.00165614
Epoch [154/300], Train Loss: 0.001521
Validation Loss: 0.00164805
Epoch [155/300], Train Loss: 0.001536
Validation Loss: 0.00165861
Epoch [156/300], Train Loss: 0.001535
Validation Loss: 0.00164943
Epoch [157/300], Train Loss: 0.001563
Validation Loss: 0.00164781
Epoch [158/300], Train Loss: 0.001536
Validation Loss: 0.00165094
Epoch [159/300], Train Loss: 0.001522
Validation Loss: 0.00164942
Epoch [160/300], Train Loss: 0.001520
Validation Loss: 0.00164353
Epoch [161/300], Train Loss: 0.001519
Validation Loss: 0.00164044
Epoch [162/300], Train Loss: 0.001536
Validation Loss: 0.00164701
Epoch [163/300], Train Loss: 0.001509
Validation Loss: 0.00164235
Epoch [164/300], Train Loss: 0.001531
Validation Loss: 0.00165192
Epoch [165/300], Train Loss: 0.001526
Validation Loss: 0.00167182
Epoch [166/300], Train Loss: 0.001535
Validation Loss: 0.00166138
Epoch [167/300], Train Loss: 0.001522
Validation Loss: 0.00164111
Epoch [168/300], Train Loss: 0.001510
Validation Loss: 0.00163962
Epoch [169/300], Train Loss: 0.001523
Validation Loss: 0.00167123
Epoch [170/300], Train Loss: 0.001514
Validation Loss: 0.00163937
Epoch [171/300], Train Loss: 0.001521
Validation Loss: 0.00163809
Epoch [172/300], Train Loss: 0.001504
Validation Loss: 0.00163589
Epoch [173/300], Train Loss: 0.001497
Validation Loss: 0.00163950
Epoch [174/300], Train Loss: 0.001514
Validation Loss: 0.00165058
Epoch [175/300], Train Loss: 0.001507
Validation Loss: 0.00164511
Epoch [176/300], Train Loss: 0.001509
Validation Loss: 0.00164631
Epoch [177/300], Train Loss: 0.001516
Validation Loss: 0.00164952
Epoch [178/300], Train Loss: 0.001501
Validation Loss: 0.00164780
Epoch [179/300], Train Loss: 0.001512
Validation Loss: 0.00166018
Epoch [180/300], Train Loss: 0.001503
Validation Loss: 0.00165352
Epoch [181/300], Train Loss: 0.001496
Validation Loss: 0.00164629
Epoch [182/300], Train Loss: 0.001506
Validation Loss: 0.00163498
Epoch [183/300], Train Loss: 0.001512
Validation Loss: 0.00165223
Epoch [184/300], Train Loss: 0.001520
Validation Loss: 0.00163487
Epoch [185/300], Train Loss: 0.001498
Validation Loss: 0.00163564
Epoch [186/300], Train Loss: 0.001504
Validation Loss: 0.00163082
Epoch [187/300], Train Loss: 0.001533
Validation Loss: 0.00163827
Epoch [188/300], Train Loss: 0.001503
Validation Loss: 0.00163086
Epoch [189/300], Train Loss: 0.001510
Validation Loss: 0.00163214
Epoch [190/300], Train Loss: 0.001502
Validation Loss: 0.00163167
Epoch [191/300], Train Loss: 0.001516
Validation Loss: 0.00163390
Epoch [192/300], Train Loss: 0.001489
Validation Loss: 0.00163361
Epoch [193/300], Train Loss: 0.001496
Validation Loss: 0.00162951
Epoch [194/300], Train Loss: 0.001501
Validation Loss: 0.00163005
Epoch [195/300], Train Loss: 0.001497
Validation Loss: 0.00162625
Epoch [196/300], Train Loss: 0.001495
Validation Loss: 0.00162622
Epoch [197/300], Train Loss: 0.001481
Validation Loss: 0.00162915
Epoch [198/300], Train Loss: 0.001489
Validation Loss: 0.00162466
Epoch [199/300], Train Loss: 0.001483
Validation Loss: 0.00163465
Epoch [200/300], Train Loss: 0.001508
Validation Loss: 0.00162335
Epoch [201/300], Train Loss: 0.001507
Validation Loss: 0.00162391
Epoch [202/300], Train Loss: 0.001497
Validation Loss: 0.00162760
Epoch [203/300], Train Loss: 0.001505
Validation Loss: 0.00162718
Epoch [204/300], Train Loss: 0.001511
Validation Loss: 0.00162842
Epoch [205/300], Train Loss: 0.001495
Validation Loss: 0.00162110
Epoch [206/300], Train Loss: 0.001501
Validation Loss: 0.00164089
Epoch [207/300], Train Loss: 0.001507
Validation Loss: 0.00164862
Epoch [208/300], Train Loss: 0.001492
Validation Loss: 0.00161747
Epoch [209/300], Train Loss: 0.001478
Validation Loss: 0.00163550
Epoch [210/300], Train Loss: 0.001475
Validation Loss: 0.00162183
Epoch [211/300], Train Loss: 0.001489
Validation Loss: 0.00161861
Epoch [212/300], Train Loss: 0.001491
Validation Loss: 0.00161798
Epoch [213/300], Train Loss: 0.001488
Validation Loss: 0.00161902
Epoch [214/300], Train Loss: 0.001486
Validation Loss: 0.00161884
Epoch [215/300], Train Loss: 0.001479
Validation Loss: 0.00161963
Epoch [216/300], Train Loss: 0.001491
Validation Loss: 0.00163125
Epoch [217/300], Train Loss: 0.001489
Validation Loss: 0.00163160
Epoch [218/300], Train Loss: 0.001495
Validation Loss: 0.00162313
Early stopping triggered

Evaluating model for: Freezer
Run 14/72 completed in 517.14 seconds with: {'MAE': np.float32(37.712643), 'MSE': np.float32(2940.351), 'RMSE': np.float32(54.225002), 'SAE': np.float32(0.02106059), 'NDE': np.float32(0.38009742)}

Run 15/72: hidden=128, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Freezer
Dataset length: 2322 windows

Epoch [1/300], Train Loss: 0.014778
Validation Loss: 0.01011371
Epoch [2/300], Train Loss: 0.009772
Validation Loss: 0.00639234
Epoch [3/300], Train Loss: 0.006436
Validation Loss: 0.00587930
Epoch [4/300], Train Loss: 0.006078
Validation Loss: 0.00547679
Epoch [5/300], Train Loss: 0.005993
Validation Loss: 0.00544455
Epoch [6/300], Train Loss: 0.005959
Validation Loss: 0.00551709
Epoch [7/300], Train Loss: 0.005956
Validation Loss: 0.00546456
Epoch [8/300], Train Loss: 0.005941
Validation Loss: 0.00543853
Epoch [9/300], Train Loss: 0.005912
Validation Loss: 0.00541680
Epoch [10/300], Train Loss: 0.005836
Validation Loss: 0.00539076
Epoch [11/300], Train Loss: 0.005741
Validation Loss: 0.00522922
Epoch [12/300], Train Loss: 0.005452
Validation Loss: 0.00482217
Epoch [13/300], Train Loss: 0.005021
Validation Loss: 0.00440621
Epoch [14/300], Train Loss: 0.004231
Validation Loss: 0.00336752
Epoch [15/300], Train Loss: 0.003398
Validation Loss: 0.00315011
Epoch [16/300], Train Loss: 0.003218
Validation Loss: 0.00305421
Epoch [17/300], Train Loss: 0.003139
Validation Loss: 0.00292717
Epoch [18/300], Train Loss: 0.003013
Validation Loss: 0.00288432
Epoch [19/300], Train Loss: 0.002955
Validation Loss: 0.00281722
Epoch [20/300], Train Loss: 0.002843
Validation Loss: 0.00273555
Epoch [21/300], Train Loss: 0.002764
Validation Loss: 0.00272962
Epoch [22/300], Train Loss: 0.002690
Validation Loss: 0.00258144
Epoch [23/300], Train Loss: 0.002592
Validation Loss: 0.00251529
Epoch [24/300], Train Loss: 0.002479
Validation Loss: 0.00244032
Epoch [25/300], Train Loss: 0.002410
Validation Loss: 0.00239145
Epoch [26/300], Train Loss: 0.002356
Validation Loss: 0.00233281
Epoch [27/300], Train Loss: 0.002321
Validation Loss: 0.00230788
Epoch [28/300], Train Loss: 0.002257
Validation Loss: 0.00225904
Epoch [29/300], Train Loss: 0.002236
Validation Loss: 0.00222499
Epoch [30/300], Train Loss: 0.002195
Validation Loss: 0.00221028
Epoch [31/300], Train Loss: 0.002145
Validation Loss: 0.00215249
Epoch [32/300], Train Loss: 0.002091
Validation Loss: 0.00213992
Epoch [33/300], Train Loss: 0.002089
Validation Loss: 0.00212377
Epoch [34/300], Train Loss: 0.002066
Validation Loss: 0.00206800
Epoch [35/300], Train Loss: 0.002018
Validation Loss: 0.00203995
Epoch [36/300], Train Loss: 0.001998
Validation Loss: 0.00204380
Epoch [37/300], Train Loss: 0.002006
Validation Loss: 0.00201146
Epoch [38/300], Train Loss: 0.001963
Validation Loss: 0.00199547
Epoch [39/300], Train Loss: 0.001962
Validation Loss: 0.00197636
Epoch [40/300], Train Loss: 0.001948
Validation Loss: 0.00200976
Epoch [41/300], Train Loss: 0.001938
Validation Loss: 0.00196949
Epoch [42/300], Train Loss: 0.001891
Validation Loss: 0.00193964
Epoch [43/300], Train Loss: 0.001888
Validation Loss: 0.00194101
Epoch [44/300], Train Loss: 0.001896
Validation Loss: 0.00192230
Epoch [45/300], Train Loss: 0.001882
Validation Loss: 0.00191674
Epoch [46/300], Train Loss: 0.001868
Validation Loss: 0.00192440
Epoch [47/300], Train Loss: 0.001856
Validation Loss: 0.00192343
Epoch [48/300], Train Loss: 0.001853
Validation Loss: 0.00190228
Epoch [49/300], Train Loss: 0.001848
Validation Loss: 0.00189068
Epoch [50/300], Train Loss: 0.001830
Validation Loss: 0.00189002
Epoch [51/300], Train Loss: 0.001828
Validation Loss: 0.00188351
Epoch [52/300], Train Loss: 0.001802
Validation Loss: 0.00189178
Epoch [53/300], Train Loss: 0.001828
Validation Loss: 0.00188653
Epoch [54/300], Train Loss: 0.001801
Validation Loss: 0.00189127
Epoch [55/300], Train Loss: 0.001870
Validation Loss: 0.00190279
Epoch [56/300], Train Loss: 0.001824
Validation Loss: 0.00188287
Epoch [57/300], Train Loss: 0.001835
Validation Loss: 0.00188153
Epoch [58/300], Train Loss: 0.001807
Validation Loss: 0.00187532
Epoch [59/300], Train Loss: 0.001818
Validation Loss: 0.00186449
Epoch [60/300], Train Loss: 0.001825
Validation Loss: 0.00187296
Epoch [61/300], Train Loss: 0.001809
Validation Loss: 0.00185636
Epoch [62/300], Train Loss: 0.001783
Validation Loss: 0.00185590
Epoch [63/300], Train Loss: 0.001778
Validation Loss: 0.00185766
Epoch [64/300], Train Loss: 0.001798
Validation Loss: 0.00184697
Epoch [65/300], Train Loss: 0.001762
Validation Loss: 0.00186065
Epoch [66/300], Train Loss: 0.001775
Validation Loss: 0.00184326
Epoch [67/300], Train Loss: 0.001768
Validation Loss: 0.00185167
Epoch [68/300], Train Loss: 0.001777
Validation Loss: 0.00185444
Epoch [69/300], Train Loss: 0.001778
Validation Loss: 0.00184939
Epoch [70/300], Train Loss: 0.001752
Validation Loss: 0.00183976
Epoch [71/300], Train Loss: 0.001751
Validation Loss: 0.00189284
Epoch [72/300], Train Loss: 0.001770
Validation Loss: 0.00184996
Epoch [73/300], Train Loss: 0.001793
Validation Loss: 0.00184346
Epoch [74/300], Train Loss: 0.001771
Validation Loss: 0.00183098
Epoch [75/300], Train Loss: 0.001759
Validation Loss: 0.00183810
Epoch [76/300], Train Loss: 0.001765
Validation Loss: 0.00182844
Epoch [77/300], Train Loss: 0.001754
Validation Loss: 0.00183525
Epoch [78/300], Train Loss: 0.001735
Validation Loss: 0.00183393
Epoch [79/300], Train Loss: 0.001748
Validation Loss: 0.00182318
Epoch [80/300], Train Loss: 0.001728
Validation Loss: 0.00184528
Epoch [81/300], Train Loss: 0.001748
Validation Loss: 0.00183910
Epoch [82/300], Train Loss: 0.001748
Validation Loss: 0.00182014
Epoch [83/300], Train Loss: 0.001748
Validation Loss: 0.00186237
Epoch [84/300], Train Loss: 0.001752
Validation Loss: 0.00182717
Epoch [85/300], Train Loss: 0.001746
Validation Loss: 0.00180942
Epoch [86/300], Train Loss: 0.001729
Validation Loss: 0.00181660
Epoch [87/300], Train Loss: 0.001721
Validation Loss: 0.00181070
Epoch [88/300], Train Loss: 0.001747
Validation Loss: 0.00181653
Epoch [89/300], Train Loss: 0.001727
Validation Loss: 0.00181199
Epoch [90/300], Train Loss: 0.001709
Validation Loss: 0.00181329
Epoch [91/300], Train Loss: 0.001720
Validation Loss: 0.00181331
Epoch [92/300], Train Loss: 0.001717
Validation Loss: 0.00180301
Epoch [93/300], Train Loss: 0.001695
Validation Loss: 0.00181475
Epoch [94/300], Train Loss: 0.001715
Validation Loss: 0.00180592
Epoch [95/300], Train Loss: 0.001720
Validation Loss: 0.00181742
Epoch [96/300], Train Loss: 0.001723
Validation Loss: 0.00185856
Epoch [97/300], Train Loss: 0.001748
Validation Loss: 0.00180775
Epoch [98/300], Train Loss: 0.001716
Validation Loss: 0.00181898
Epoch [99/300], Train Loss: 0.001710
Validation Loss: 0.00180046
Epoch [100/300], Train Loss: 0.001711
Validation Loss: 0.00180598
Epoch [101/300], Train Loss: 0.001708
Validation Loss: 0.00180230
Epoch [102/300], Train Loss: 0.001707
Validation Loss: 0.00179778
Epoch [103/300], Train Loss: 0.001688
Validation Loss: 0.00179250
Epoch [104/300], Train Loss: 0.001695
Validation Loss: 0.00179335
Epoch [105/300], Train Loss: 0.001679
Validation Loss: 0.00179299
Epoch [106/300], Train Loss: 0.001694
Validation Loss: 0.00178475
Epoch [107/300], Train Loss: 0.001695
Validation Loss: 0.00179500
Epoch [108/300], Train Loss: 0.001686
Validation Loss: 0.00178620
Epoch [109/300], Train Loss: 0.001688
Validation Loss: 0.00178630
Epoch [110/300], Train Loss: 0.001672
Validation Loss: 0.00178617
Epoch [111/300], Train Loss: 0.001669
Validation Loss: 0.00179106
Epoch [112/300], Train Loss: 0.001661
Validation Loss: 0.00178146
Epoch [113/300], Train Loss: 0.001686
Validation Loss: 0.00180127
Epoch [114/300], Train Loss: 0.001704
Validation Loss: 0.00181102
Epoch [115/300], Train Loss: 0.001703
Validation Loss: 0.00177804
Epoch [116/300], Train Loss: 0.001694
Validation Loss: 0.00179015
Epoch [117/300], Train Loss: 0.001684
Validation Loss: 0.00178237
Epoch [118/300], Train Loss: 0.001671
Validation Loss: 0.00177559
Epoch [119/300], Train Loss: 0.001670
Validation Loss: 0.00177983
Epoch [120/300], Train Loss: 0.001695
Validation Loss: 0.00178549
Epoch [121/300], Train Loss: 0.001687
Validation Loss: 0.00177306
Epoch [122/300], Train Loss: 0.001681
Validation Loss: 0.00177908
Epoch [123/300], Train Loss: 0.001663
Validation Loss: 0.00178460
Epoch [124/300], Train Loss: 0.001662
Validation Loss: 0.00177568
Epoch [125/300], Train Loss: 0.001651
Validation Loss: 0.00176910
Epoch [126/300], Train Loss: 0.001670
Validation Loss: 0.00177164
Epoch [127/300], Train Loss: 0.001684
Validation Loss: 0.00177012
Epoch [128/300], Train Loss: 0.001665
Validation Loss: 0.00176467
Epoch [129/300], Train Loss: 0.001654
Validation Loss: 0.00177426
Epoch [130/300], Train Loss: 0.001659
Validation Loss: 0.00177651
Epoch [131/300], Train Loss: 0.001666
Validation Loss: 0.00177218
Epoch [132/300], Train Loss: 0.001661
Validation Loss: 0.00176688
Epoch [133/300], Train Loss: 0.001641
Validation Loss: 0.00177679
Epoch [134/300], Train Loss: 0.001658
Validation Loss: 0.00177031
Epoch [135/300], Train Loss: 0.001647
Validation Loss: 0.00176984
Epoch [136/300], Train Loss: 0.001658
Validation Loss: 0.00178648
Epoch [137/300], Train Loss: 0.001659
Validation Loss: 0.00175974
Epoch [138/300], Train Loss: 0.001651
Validation Loss: 0.00176412
Epoch [139/300], Train Loss: 0.001647
Validation Loss: 0.00176068
Epoch [140/300], Train Loss: 0.001629
Validation Loss: 0.00175651
Epoch [141/300], Train Loss: 0.001647
Validation Loss: 0.00177334
Epoch [142/300], Train Loss: 0.001646
Validation Loss: 0.00174827
Epoch [143/300], Train Loss: 0.001632
Validation Loss: 0.00176566
Epoch [144/300], Train Loss: 0.001642
Validation Loss: 0.00175324
Epoch [145/300], Train Loss: 0.001627
Validation Loss: 0.00175795
Epoch [146/300], Train Loss: 0.001633
Validation Loss: 0.00175726
Epoch [147/300], Train Loss: 0.001635
Validation Loss: 0.00176680
Epoch [148/300], Train Loss: 0.001627
Validation Loss: 0.00176696
Epoch [149/300], Train Loss: 0.001654
Validation Loss: 0.00176340
Epoch [150/300], Train Loss: 0.001619
Validation Loss: 0.00176535
Epoch [151/300], Train Loss: 0.001631
Validation Loss: 0.00176058
Epoch [152/300], Train Loss: 0.001619
Validation Loss: 0.00177105
Early stopping triggered

Evaluating model for: Freezer
Run 15/72 completed in 381.42 seconds with: {'MAE': np.float32(38.77481), 'MSE': np.float32(3104.3984), 'RMSE': np.float32(55.71713), 'SAE': np.float32(0.007404174), 'NDE': np.float32(0.39055666)}

Run 16/72: hidden=128, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Freezer
Dataset length: 2322 windows

Epoch [1/300], Train Loss: 0.008654
Validation Loss: 0.00630206
Epoch [2/300], Train Loss: 0.006598
Validation Loss: 0.00539915
Epoch [3/300], Train Loss: 0.005917
Validation Loss: 0.00564496
Epoch [4/300], Train Loss: 0.005885
Validation Loss: 0.00544720
Epoch [5/300], Train Loss: 0.005874
Validation Loss: 0.00543689
Epoch [6/300], Train Loss: 0.005874
Validation Loss: 0.00547217
Epoch [7/300], Train Loss: 0.005880
Validation Loss: 0.00547004
Epoch [8/300], Train Loss: 0.005870
Validation Loss: 0.00543552
Epoch [9/300], Train Loss: 0.005856
Validation Loss: 0.00543593
Epoch [10/300], Train Loss: 0.005778
Validation Loss: 0.00539417
Epoch [11/300], Train Loss: 0.005562
Validation Loss: 0.00499736
Epoch [12/300], Train Loss: 0.004329
Validation Loss: 0.00338254
Epoch [13/300], Train Loss: 0.003305
Validation Loss: 0.00299105
Epoch [14/300], Train Loss: 0.003006
Validation Loss: 0.00280870
Epoch [15/300], Train Loss: 0.002783
Validation Loss: 0.00266476
Epoch [16/300], Train Loss: 0.002689
Validation Loss: 0.00263304
Epoch [17/300], Train Loss: 0.002586
Validation Loss: 0.00244443
Epoch [18/300], Train Loss: 0.002471
Validation Loss: 0.00237465
Epoch [19/300], Train Loss: 0.002424
Validation Loss: 0.00234229
Epoch [20/300], Train Loss: 0.002355
Validation Loss: 0.00230419
Epoch [21/300], Train Loss: 0.002324
Validation Loss: 0.00229710
Epoch [22/300], Train Loss: 0.002296
Validation Loss: 0.00225273
Epoch [23/300], Train Loss: 0.002264
Validation Loss: 0.00221981
Epoch [24/300], Train Loss: 0.002208
Validation Loss: 0.00223506
Epoch [25/300], Train Loss: 0.002199
Validation Loss: 0.00219135
Epoch [26/300], Train Loss: 0.002194
Validation Loss: 0.00222807
Epoch [27/300], Train Loss: 0.002270
Validation Loss: 0.00220584
Epoch [28/300], Train Loss: 0.002171
Validation Loss: 0.00224471
Epoch [29/300], Train Loss: 0.002170
Validation Loss: 0.00219155
Epoch [30/300], Train Loss: 0.002139
Validation Loss: 0.00212280
Epoch [31/300], Train Loss: 0.002098
Validation Loss: 0.00212552
Epoch [32/300], Train Loss: 0.002085
Validation Loss: 0.00212617
Epoch [33/300], Train Loss: 0.002108
Validation Loss: 0.00211071
Epoch [34/300], Train Loss: 0.002106
Validation Loss: 0.00213530
Epoch [35/300], Train Loss: 0.002024
Validation Loss: 0.00202841
Epoch [36/300], Train Loss: 0.001981
Validation Loss: 0.00205340
Epoch [37/300], Train Loss: 0.001974
Validation Loss: 0.00198851
Epoch [38/300], Train Loss: 0.001920
Validation Loss: 0.00197537
Epoch [39/300], Train Loss: 0.001919
Validation Loss: 0.00205037
Epoch [40/300], Train Loss: 0.001903
Validation Loss: 0.00200620
Epoch [41/300], Train Loss: 0.001870
Validation Loss: 0.00196372
Epoch [42/300], Train Loss: 0.001881
Validation Loss: 0.00202502
Epoch [43/300], Train Loss: 0.001877
Validation Loss: 0.00197164
Epoch [44/300], Train Loss: 0.001875
Validation Loss: 0.00210336
Epoch [45/300], Train Loss: 0.001912
Validation Loss: 0.00202026
Epoch [46/300], Train Loss: 0.001833
Validation Loss: 0.00195109
Epoch [47/300], Train Loss: 0.001817
Validation Loss: 0.00194243
Epoch [48/300], Train Loss: 0.001794
Validation Loss: 0.00191148
Epoch [49/300], Train Loss: 0.001772
Validation Loss: 0.00189673
Epoch [50/300], Train Loss: 0.001754
Validation Loss: 0.00186243
Epoch [51/300], Train Loss: 0.001746
Validation Loss: 0.00185331
Epoch [52/300], Train Loss: 0.001711
Validation Loss: 0.00185514
Epoch [53/300], Train Loss: 0.001738
Validation Loss: 0.00183498
Epoch [54/300], Train Loss: 0.001694
Validation Loss: 0.00181300
Epoch [55/300], Train Loss: 0.001698
Validation Loss: 0.00180726
Epoch [56/300], Train Loss: 0.001679
Validation Loss: 0.00182187
Epoch [57/300], Train Loss: 0.001701
Validation Loss: 0.00180431
Epoch [58/300], Train Loss: 0.001682
Validation Loss: 0.00180595
Epoch [59/300], Train Loss: 0.001686
Validation Loss: 0.00182420
Epoch [60/300], Train Loss: 0.001708
Validation Loss: 0.00179188
Epoch [61/300], Train Loss: 0.001693
Validation Loss: 0.00180398
Epoch [62/300], Train Loss: 0.001667
Validation Loss: 0.00179266
Epoch [63/300], Train Loss: 0.001663
Validation Loss: 0.00180147
Epoch [64/300], Train Loss: 0.001689
Validation Loss: 0.00179098
Epoch [65/300], Train Loss: 0.001663
Validation Loss: 0.00179425
Epoch [66/300], Train Loss: 0.001660
Validation Loss: 0.00179381
Epoch [67/300], Train Loss: 0.001661
Validation Loss: 0.00179193
Epoch [68/300], Train Loss: 0.001668
Validation Loss: 0.00180326
Epoch [69/300], Train Loss: 0.001669
Validation Loss: 0.00179028
Epoch [70/300], Train Loss: 0.001648
Validation Loss: 0.00179630
Epoch [71/300], Train Loss: 0.001650
Validation Loss: 0.00180043
Epoch [72/300], Train Loss: 0.001664
Validation Loss: 0.00179036
Epoch [73/300], Train Loss: 0.001688
Validation Loss: 0.00179902
Epoch [74/300], Train Loss: 0.001673
Validation Loss: 0.00178890
Epoch [75/300], Train Loss: 0.001661
Validation Loss: 0.00178343
Epoch [76/300], Train Loss: 0.001665
Validation Loss: 0.00179147
Epoch [77/300], Train Loss: 0.001659
Validation Loss: 0.00177967
Epoch [78/300], Train Loss: 0.001646
Validation Loss: 0.00178951
Epoch [79/300], Train Loss: 0.001688
Validation Loss: 0.00188776
Epoch [80/300], Train Loss: 0.001741
Validation Loss: 0.00188809
Epoch [81/300], Train Loss: 0.001719
Validation Loss: 0.00179794
Epoch [82/300], Train Loss: 0.001702
Validation Loss: 0.00180043
Epoch [83/300], Train Loss: 0.001684
Validation Loss: 0.00177932
Epoch [84/300], Train Loss: 0.001664
Validation Loss: 0.00178186
Epoch [85/300], Train Loss: 0.001670
Validation Loss: 0.00177453
Epoch [86/300], Train Loss: 0.001653
Validation Loss: 0.00177367
Epoch [87/300], Train Loss: 0.001680
Validation Loss: 0.00180477
Epoch [88/300], Train Loss: 0.001697
Validation Loss: 0.00178198
Epoch [89/300], Train Loss: 0.001659
Validation Loss: 0.00176965
Epoch [90/300], Train Loss: 0.001640
Validation Loss: 0.00177546
Epoch [91/300], Train Loss: 0.001641
Validation Loss: 0.00177763
Epoch [92/300], Train Loss: 0.001645
Validation Loss: 0.00176707
Epoch [93/300], Train Loss: 0.001622
Validation Loss: 0.00179295
Epoch [94/300], Train Loss: 0.001644
Validation Loss: 0.00178255
Epoch [95/300], Train Loss: 0.001646
Validation Loss: 0.00176702
Epoch [96/300], Train Loss: 0.001633
Validation Loss: 0.00176764
Epoch [97/300], Train Loss: 0.001638
Validation Loss: 0.00176961
Epoch [98/300], Train Loss: 0.001634
Validation Loss: 0.00177310
Epoch [99/300], Train Loss: 0.001622
Validation Loss: 0.00176054
Epoch [100/300], Train Loss: 0.001645
Validation Loss: 0.00178360
Epoch [101/300], Train Loss: 0.001652
Validation Loss: 0.00177076
Epoch [102/300], Train Loss: 0.001642
Validation Loss: 0.00175857
Epoch [103/300], Train Loss: 0.001620
Validation Loss: 0.00176750
Epoch [104/300], Train Loss: 0.001630
Validation Loss: 0.00177472
Epoch [105/300], Train Loss: 0.001614
Validation Loss: 0.00177559
Epoch [106/300], Train Loss: 0.001637
Validation Loss: 0.00176704
Epoch [107/300], Train Loss: 0.001644
Validation Loss: 0.00176332
Epoch [108/300], Train Loss: 0.001625
Validation Loss: 0.00177700
Epoch [109/300], Train Loss: 0.001622
Validation Loss: 0.00176087
Epoch [110/300], Train Loss: 0.001613
Validation Loss: 0.00176338
Epoch [111/300], Train Loss: 0.001609
Validation Loss: 0.00176761
Epoch [112/300], Train Loss: 0.001601
Validation Loss: 0.00175995
Early stopping triggered

Evaluating model for: Freezer
Run 16/72 completed in 291.68 seconds with: {'MAE': np.float32(38.988655), 'MSE': np.float32(3136.6755), 'RMSE': np.float32(56.00603), 'SAE': np.float32(0.00028717626), 'NDE': np.float32(0.39258176)}

Run 17/72: hidden=128, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Freezer
Dataset length: 2262 windows

Epoch [1/300], Train Loss: 0.013105
Validation Loss: 0.01126129
Epoch [2/300], Train Loss: 0.009090
Validation Loss: 0.00801712
Epoch [3/300], Train Loss: 0.006763
Validation Loss: 0.00623193
Epoch [4/300], Train Loss: 0.005939
Validation Loss: 0.00592362
Epoch [5/300], Train Loss: 0.005883
Validation Loss: 0.00590155
Epoch [6/300], Train Loss: 0.005834
Validation Loss: 0.00590344
Epoch [7/300], Train Loss: 0.005862
Validation Loss: 0.00587758
Epoch [8/300], Train Loss: 0.005798
Validation Loss: 0.00584981
Epoch [9/300], Train Loss: 0.005802
Validation Loss: 0.00583548
Epoch [10/300], Train Loss: 0.005837
Validation Loss: 0.00580742
Epoch [11/300], Train Loss: 0.005736
Validation Loss: 0.00577215
Epoch [12/300], Train Loss: 0.005819
Validation Loss: 0.00572837
Epoch [13/300], Train Loss: 0.005786
Validation Loss: 0.00567097
Epoch [14/300], Train Loss: 0.005612
Validation Loss: 0.00558846
Epoch [15/300], Train Loss: 0.005565
Validation Loss: 0.00546175
Epoch [16/300], Train Loss: 0.005352
Validation Loss: 0.00529115
Epoch [17/300], Train Loss: 0.005230
Validation Loss: 0.00501253
Epoch [18/300], Train Loss: 0.004875
Validation Loss: 0.00482086
Epoch [19/300], Train Loss: 0.004671
Validation Loss: 0.00455535
Epoch [20/300], Train Loss: 0.004470
Validation Loss: 0.00437722
Epoch [21/300], Train Loss: 0.004313
Validation Loss: 0.00407053
Epoch [22/300], Train Loss: 0.004016
Validation Loss: 0.00389695
Epoch [23/300], Train Loss: 0.003769
Validation Loss: 0.00354927
Epoch [24/300], Train Loss: 0.003548
Validation Loss: 0.00327198
Epoch [25/300], Train Loss: 0.003273
Validation Loss: 0.00330323
Epoch [26/300], Train Loss: 0.003229
Validation Loss: 0.00275698
Epoch [27/300], Train Loss: 0.002865
Validation Loss: 0.00253998
Epoch [28/300], Train Loss: 0.002614
Validation Loss: 0.00237783
Epoch [29/300], Train Loss: 0.002598
Validation Loss: 0.00232257
Epoch [30/300], Train Loss: 0.002481
Validation Loss: 0.00227171
Epoch [31/300], Train Loss: 0.002358
Validation Loss: 0.00225128
Epoch [32/300], Train Loss: 0.002361
Validation Loss: 0.00222815
Epoch [33/300], Train Loss: 0.002370
Validation Loss: 0.00219324
Epoch [34/300], Train Loss: 0.002249
Validation Loss: 0.00213255
Epoch [35/300], Train Loss: 0.002334
Validation Loss: 0.00210233
Epoch [36/300], Train Loss: 0.002218
Validation Loss: 0.00207304
Epoch [37/300], Train Loss: 0.002176
Validation Loss: 0.00204954
Epoch [38/300], Train Loss: 0.002149
Validation Loss: 0.00203056
Epoch [39/300], Train Loss: 0.002125
Validation Loss: 0.00199742
Epoch [40/300], Train Loss: 0.002082
Validation Loss: 0.00197879
Epoch [41/300], Train Loss: 0.002035
Validation Loss: 0.00195983
Epoch [42/300], Train Loss: 0.002038
Validation Loss: 0.00194125
Epoch [43/300], Train Loss: 0.002012
Validation Loss: 0.00193562
Epoch [44/300], Train Loss: 0.002042
Validation Loss: 0.00191908
Epoch [45/300], Train Loss: 0.001971
Validation Loss: 0.00189764
Epoch [46/300], Train Loss: 0.002021
Validation Loss: 0.00190067
Epoch [47/300], Train Loss: 0.001950
Validation Loss: 0.00187032
Epoch [48/300], Train Loss: 0.001981
Validation Loss: 0.00185082
Epoch [49/300], Train Loss: 0.001989
Validation Loss: 0.00184773
Epoch [50/300], Train Loss: 0.001943
Validation Loss: 0.00183441
Epoch [51/300], Train Loss: 0.001872
Validation Loss: 0.00180688
Epoch [52/300], Train Loss: 0.001888
Validation Loss: 0.00179654
Epoch [53/300], Train Loss: 0.001849
Validation Loss: 0.00178148
Epoch [54/300], Train Loss: 0.001916
Validation Loss: 0.00177445
Epoch [55/300], Train Loss: 0.001901
Validation Loss: 0.00175801
Epoch [56/300], Train Loss: 0.001813
Validation Loss: 0.00175320
Epoch [57/300], Train Loss: 0.001861
Validation Loss: 0.00174902
Epoch [58/300], Train Loss: 0.001844
Validation Loss: 0.00174388
Epoch [59/300], Train Loss: 0.001826
Validation Loss: 0.00173307
Epoch [60/300], Train Loss: 0.001843
Validation Loss: 0.00172694
Epoch [61/300], Train Loss: 0.001840
Validation Loss: 0.00171991
Epoch [62/300], Train Loss: 0.001840
Validation Loss: 0.00171636
Epoch [63/300], Train Loss: 0.001832
Validation Loss: 0.00173805
Epoch [64/300], Train Loss: 0.001811
Validation Loss: 0.00171672
Epoch [65/300], Train Loss: 0.001830
Validation Loss: 0.00171181
Epoch [66/300], Train Loss: 0.001834
Validation Loss: 0.00170770
Epoch [67/300], Train Loss: 0.001826
Validation Loss: 0.00170803
Epoch [68/300], Train Loss: 0.001901
Validation Loss: 0.00170076
Epoch [69/300], Train Loss: 0.001863
Validation Loss: 0.00171600
Epoch [70/300], Train Loss: 0.001773
Validation Loss: 0.00169751
Epoch [71/300], Train Loss: 0.001804
Validation Loss: 0.00169881
Epoch [72/300], Train Loss: 0.001782
Validation Loss: 0.00169395
Epoch [73/300], Train Loss: 0.001707
Validation Loss: 0.00168949
Epoch [74/300], Train Loss: 0.001893
Validation Loss: 0.00168911
Epoch [75/300], Train Loss: 0.001829
Validation Loss: 0.00169345
Epoch [76/300], Train Loss: 0.001796
Validation Loss: 0.00171212
Epoch [77/300], Train Loss: 0.001784
Validation Loss: 0.00169632
Epoch [78/300], Train Loss: 0.001786
Validation Loss: 0.00169454
Epoch [79/300], Train Loss: 0.001738
Validation Loss: 0.00167730
Epoch [80/300], Train Loss: 0.001832
Validation Loss: 0.00167668
Epoch [81/300], Train Loss: 0.001751
Validation Loss: 0.00167281
Epoch [82/300], Train Loss: 0.001756
Validation Loss: 0.00168621
Epoch [83/300], Train Loss: 0.001795
Validation Loss: 0.00169426
Epoch [84/300], Train Loss: 0.001694
Validation Loss: 0.00166906
Epoch [85/300], Train Loss: 0.001736
Validation Loss: 0.00166623
Epoch [86/300], Train Loss: 0.001769
Validation Loss: 0.00166523
Epoch [87/300], Train Loss: 0.001769
Validation Loss: 0.00166623
Epoch [88/300], Train Loss: 0.001766
Validation Loss: 0.00166400
Epoch [89/300], Train Loss: 0.001756
Validation Loss: 0.00166401
Epoch [90/300], Train Loss: 0.001790
Validation Loss: 0.00166025
Epoch [91/300], Train Loss: 0.001721
Validation Loss: 0.00165686
Epoch [92/300], Train Loss: 0.001720
Validation Loss: 0.00166149
Epoch [93/300], Train Loss: 0.001787
Validation Loss: 0.00165213
Epoch [94/300], Train Loss: 0.001750
Validation Loss: 0.00165466
Epoch [95/300], Train Loss: 0.001787
Validation Loss: 0.00164850
Epoch [96/300], Train Loss: 0.001846
Validation Loss: 0.00165751
Epoch [97/300], Train Loss: 0.001680
Validation Loss: 0.00165109
Epoch [98/300], Train Loss: 0.001771
Validation Loss: 0.00164533
Epoch [99/300], Train Loss: 0.001757
Validation Loss: 0.00164300
Epoch [100/300], Train Loss: 0.001707
Validation Loss: 0.00163171
Epoch [101/300], Train Loss: 0.001691
Validation Loss: 0.00163667
Epoch [102/300], Train Loss: 0.001748
Validation Loss: 0.00162307
Epoch [103/300], Train Loss: 0.001698
Validation Loss: 0.00162079
Epoch [104/300], Train Loss: 0.001695
Validation Loss: 0.00161376
Epoch [105/300], Train Loss: 0.001677
Validation Loss: 0.00161287
Epoch [106/300], Train Loss: 0.001654
Validation Loss: 0.00161733
Epoch [107/300], Train Loss: 0.001662
Validation Loss: 0.00161204
Epoch [108/300], Train Loss: 0.001713
Validation Loss: 0.00160522
Epoch [109/300], Train Loss: 0.001714
Validation Loss: 0.00162147
Epoch [110/300], Train Loss: 0.001674
Validation Loss: 0.00160971
Epoch [111/300], Train Loss: 0.001688
Validation Loss: 0.00160271
Epoch [112/300], Train Loss: 0.001669
Validation Loss: 0.00162253
Epoch [113/300], Train Loss: 0.001702
Validation Loss: 0.00160127
Epoch [114/300], Train Loss: 0.001683
Validation Loss: 0.00159927
Epoch [115/300], Train Loss: 0.001728
Validation Loss: 0.00160755
Epoch [116/300], Train Loss: 0.001706
Validation Loss: 0.00159915
Epoch [117/300], Train Loss: 0.001712
Validation Loss: 0.00163259
Epoch [118/300], Train Loss: 0.001677
Validation Loss: 0.00159863
Epoch [119/300], Train Loss: 0.001744
Validation Loss: 0.00158634
Epoch [120/300], Train Loss: 0.001662
Validation Loss: 0.00159410
Epoch [121/300], Train Loss: 0.001696
Validation Loss: 0.00158720
Epoch [122/300], Train Loss: 0.001709
Validation Loss: 0.00158847
Epoch [123/300], Train Loss: 0.001661
Validation Loss: 0.00158169
Epoch [124/300], Train Loss: 0.001694
Validation Loss: 0.00158662
Epoch [125/300], Train Loss: 0.001711
Validation Loss: 0.00158337
Epoch [126/300], Train Loss: 0.001667
Validation Loss: 0.00159115
Epoch [127/300], Train Loss: 0.001697
Validation Loss: 0.00159000
Epoch [128/300], Train Loss: 0.001651
Validation Loss: 0.00158309
Epoch [129/300], Train Loss: 0.001656
Validation Loss: 0.00158091
Epoch [130/300], Train Loss: 0.001723
Validation Loss: 0.00157584
Epoch [131/300], Train Loss: 0.001690
Validation Loss: 0.00158344
Epoch [132/300], Train Loss: 0.001635
Validation Loss: 0.00157510
Epoch [133/300], Train Loss: 0.001643
Validation Loss: 0.00157027
Epoch [134/300], Train Loss: 0.001636
Validation Loss: 0.00157088
Epoch [135/300], Train Loss: 0.001709
Validation Loss: 0.00157116
Epoch [136/300], Train Loss: 0.001633
Validation Loss: 0.00157138
Epoch [137/300], Train Loss: 0.001654
Validation Loss: 0.00156870
Epoch [138/300], Train Loss: 0.001675
Validation Loss: 0.00156641
Epoch [139/300], Train Loss: 0.001618
Validation Loss: 0.00158679
Epoch [140/300], Train Loss: 0.001619
Validation Loss: 0.00156846
Epoch [141/300], Train Loss: 0.001680
Validation Loss: 0.00156317
Epoch [142/300], Train Loss: 0.001627
Validation Loss: 0.00156501
Epoch [143/300], Train Loss: 0.001654
Validation Loss: 0.00156547
Epoch [144/300], Train Loss: 0.001681
Validation Loss: 0.00156089
Epoch [145/300], Train Loss: 0.001694
Validation Loss: 0.00156331
Epoch [146/300], Train Loss: 0.001649
Validation Loss: 0.00156125
Epoch [147/300], Train Loss: 0.001695
Validation Loss: 0.00156344
Epoch [148/300], Train Loss: 0.001659
Validation Loss: 0.00156810
Epoch [149/300], Train Loss: 0.001646
Validation Loss: 0.00155990
Epoch [150/300], Train Loss: 0.001609
Validation Loss: 0.00156140
Epoch [151/300], Train Loss: 0.001712
Validation Loss: 0.00155590
Epoch [152/300], Train Loss: 0.001698
Validation Loss: 0.00156883
Epoch [153/300], Train Loss: 0.001683
Validation Loss: 0.00157273
Epoch [154/300], Train Loss: 0.001670
Validation Loss: 0.00155373
Epoch [155/300], Train Loss: 0.001740
Validation Loss: 0.00157191
Epoch [156/300], Train Loss: 0.001669
Validation Loss: 0.00156101
Epoch [157/300], Train Loss: 0.001653
Validation Loss: 0.00157640
Epoch [158/300], Train Loss: 0.001768
Validation Loss: 0.00159327
Epoch [159/300], Train Loss: 0.001692
Validation Loss: 0.00157249
Epoch [160/300], Train Loss: 0.001628
Validation Loss: 0.00156640
Epoch [161/300], Train Loss: 0.001688
Validation Loss: 0.00156333
Epoch [162/300], Train Loss: 0.001607
Validation Loss: 0.00156028
Epoch [163/300], Train Loss: 0.001700
Validation Loss: 0.00155410
Epoch [164/300], Train Loss: 0.001617
Validation Loss: 0.00155912
Early stopping triggered

Evaluating model for: Freezer
Run 17/72 completed in 409.00 seconds with: {'MAE': np.float32(33.217297), 'MSE': np.float32(2382.8772), 'RMSE': np.float32(48.814724), 'SAE': np.float32(0.013085042), 'NDE': np.float32(0.36464113)}

Run 18/72: hidden=128, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Freezer
Dataset length: 2262 windows

Epoch [1/300], Train Loss: 0.006992
Validation Loss: 0.00615525
Epoch [2/300], Train Loss: 0.005843
Validation Loss: 0.00592785
Epoch [3/300], Train Loss: 0.005768
Validation Loss: 0.00590331
Epoch [4/300], Train Loss: 0.005826
Validation Loss: 0.00591706
Epoch [5/300], Train Loss: 0.005823
Validation Loss: 0.00587496
Epoch [6/300], Train Loss: 0.005790
Validation Loss: 0.00585830
Epoch [7/300], Train Loss: 0.005820
Validation Loss: 0.00583158
Epoch [8/300], Train Loss: 0.005732
Validation Loss: 0.00577847
Epoch [9/300], Train Loss: 0.005696
Validation Loss: 0.00569116
Epoch [10/300], Train Loss: 0.005617
Validation Loss: 0.00548287
Epoch [11/300], Train Loss: 0.005198
Validation Loss: 0.00491459
Epoch [12/300], Train Loss: 0.004595
Validation Loss: 0.00433863
Epoch [13/300], Train Loss: 0.004138
Validation Loss: 0.00385960
Epoch [14/300], Train Loss: 0.003716
Validation Loss: 0.00335909
Epoch [15/300], Train Loss: 0.003216
Validation Loss: 0.00285371
Epoch [16/300], Train Loss: 0.002796
Validation Loss: 0.00249136
Epoch [17/300], Train Loss: 0.002573
Validation Loss: 0.00232346
Epoch [18/300], Train Loss: 0.002444
Validation Loss: 0.00223437
Epoch [19/300], Train Loss: 0.002277
Validation Loss: 0.00219849
Epoch [20/300], Train Loss: 0.002302
Validation Loss: 0.00213877
Epoch [21/300], Train Loss: 0.002257
Validation Loss: 0.00211770
Epoch [22/300], Train Loss: 0.002205
Validation Loss: 0.00206357
Epoch [23/300], Train Loss: 0.002032
Validation Loss: 0.00202040
Epoch [24/300], Train Loss: 0.002036
Validation Loss: 0.00200904
Epoch [25/300], Train Loss: 0.001978
Validation Loss: 0.00208259
Epoch [26/300], Train Loss: 0.002008
Validation Loss: 0.00196343
Epoch [27/300], Train Loss: 0.001948
Validation Loss: 0.00195346
Epoch [28/300], Train Loss: 0.001916
Validation Loss: 0.00197541
Epoch [29/300], Train Loss: 0.002042
Validation Loss: 0.00193471
Epoch [30/300], Train Loss: 0.001973
Validation Loss: 0.00192177
Epoch [31/300], Train Loss: 0.001904
Validation Loss: 0.00191245
Epoch [32/300], Train Loss: 0.001930
Validation Loss: 0.00191344
Epoch [33/300], Train Loss: 0.001971
Validation Loss: 0.00189798
Epoch [34/300], Train Loss: 0.001889
Validation Loss: 0.00188454
Epoch [35/300], Train Loss: 0.002015
Validation Loss: 0.00189292
Epoch [36/300], Train Loss: 0.001927
Validation Loss: 0.00186968
Epoch [37/300], Train Loss: 0.001906
Validation Loss: 0.00187923
Epoch [38/300], Train Loss: 0.001905
Validation Loss: 0.00185982
Epoch [39/300], Train Loss: 0.001896
Validation Loss: 0.00185352
Epoch [40/300], Train Loss: 0.001876
Validation Loss: 0.00184522
Epoch [41/300], Train Loss: 0.001844
Validation Loss: 0.00183899
Epoch [42/300], Train Loss: 0.001856
Validation Loss: 0.00183151
Epoch [43/300], Train Loss: 0.001833
Validation Loss: 0.00184393
Epoch [44/300], Train Loss: 0.001890
Validation Loss: 0.00185786
Epoch [45/300], Train Loss: 0.001820
Validation Loss: 0.00184050
Epoch [46/300], Train Loss: 0.001883
Validation Loss: 0.00180591
Epoch [47/300], Train Loss: 0.001818
Validation Loss: 0.00180145
Epoch [48/300], Train Loss: 0.001853
Validation Loss: 0.00179635
Epoch [49/300], Train Loss: 0.001883
Validation Loss: 0.00179899
Epoch [50/300], Train Loss: 0.001834
Validation Loss: 0.00178427
Epoch [51/300], Train Loss: 0.001771
Validation Loss: 0.00177695
Epoch [52/300], Train Loss: 0.001807
Validation Loss: 0.00176701
Epoch [53/300], Train Loss: 0.001759
Validation Loss: 0.00176062
Epoch [54/300], Train Loss: 0.001836
Validation Loss: 0.00175333
Epoch [55/300], Train Loss: 0.001826
Validation Loss: 0.00175125
Epoch [56/300], Train Loss: 0.001755
Validation Loss: 0.00173639
Epoch [57/300], Train Loss: 0.001792
Validation Loss: 0.00174182
Epoch [58/300], Train Loss: 0.001778
Validation Loss: 0.00171843
Epoch [59/300], Train Loss: 0.001754
Validation Loss: 0.00171516
Epoch [60/300], Train Loss: 0.001774
Validation Loss: 0.00170156
Epoch [61/300], Train Loss: 0.001766
Validation Loss: 0.00169980
Epoch [62/300], Train Loss: 0.001758
Validation Loss: 0.00168653
Epoch [63/300], Train Loss: 0.001748
Validation Loss: 0.00170404
Epoch [64/300], Train Loss: 0.001731
Validation Loss: 0.00168767
Epoch [65/300], Train Loss: 0.001752
Validation Loss: 0.00167682
Epoch [66/300], Train Loss: 0.001759
Validation Loss: 0.00166384
Epoch [67/300], Train Loss: 0.001742
Validation Loss: 0.00166979
Epoch [68/300], Train Loss: 0.001802
Validation Loss: 0.00165558
Epoch [69/300], Train Loss: 0.001766
Validation Loss: 0.00164993
Epoch [70/300], Train Loss: 0.001685
Validation Loss: 0.00164434
Epoch [71/300], Train Loss: 0.001711
Validation Loss: 0.00164129
Epoch [72/300], Train Loss: 0.001692
Validation Loss: 0.00163703
Epoch [73/300], Train Loss: 0.001615
Validation Loss: 0.00163095
Epoch [74/300], Train Loss: 0.001807
Validation Loss: 0.00163279
Epoch [75/300], Train Loss: 0.001747
Validation Loss: 0.00162734
Epoch [76/300], Train Loss: 0.001699
Validation Loss: 0.00162696
Epoch [77/300], Train Loss: 0.001683
Validation Loss: 0.00162548
Epoch [78/300], Train Loss: 0.001691
Validation Loss: 0.00163144
Epoch [79/300], Train Loss: 0.001635
Validation Loss: 0.00159810
Epoch [80/300], Train Loss: 0.001724
Validation Loss: 0.00159675
Epoch [81/300], Train Loss: 0.001655
Validation Loss: 0.00159409
Epoch [82/300], Train Loss: 0.001653
Validation Loss: 0.00158950
Epoch [83/300], Train Loss: 0.001683
Validation Loss: 0.00158606
Epoch [84/300], Train Loss: 0.001591
Validation Loss: 0.00158465
Epoch [85/300], Train Loss: 0.001638
Validation Loss: 0.00157392
Epoch [86/300], Train Loss: 0.001666
Validation Loss: 0.00157221
Epoch [87/300], Train Loss: 0.001664
Validation Loss: 0.00159634
Epoch [88/300], Train Loss: 0.001664
Validation Loss: 0.00157935
Epoch [89/300], Train Loss: 0.001644
Validation Loss: 0.00157843
Epoch [90/300], Train Loss: 0.001681
Validation Loss: 0.00156600
Epoch [91/300], Train Loss: 0.001618
Validation Loss: 0.00156302
Epoch [92/300], Train Loss: 0.001616
Validation Loss: 0.00156122
Epoch [93/300], Train Loss: 0.001673
Validation Loss: 0.00156420
Epoch [94/300], Train Loss: 0.001645
Validation Loss: 0.00156134
Epoch [95/300], Train Loss: 0.001680
Validation Loss: 0.00155566
Epoch [96/300], Train Loss: 0.001734
Validation Loss: 0.00156700
Epoch [97/300], Train Loss: 0.001580
Validation Loss: 0.00156453
Epoch [98/300], Train Loss: 0.001667
Validation Loss: 0.00156861
Epoch [99/300], Train Loss: 0.001659
Validation Loss: 0.00156132
Epoch [100/300], Train Loss: 0.001613
Validation Loss: 0.00155473
Epoch [101/300], Train Loss: 0.001599
Validation Loss: 0.00155543
Epoch [102/300], Train Loss: 0.001659
Validation Loss: 0.00155164
Epoch [103/300], Train Loss: 0.001606
Validation Loss: 0.00154400
Epoch [104/300], Train Loss: 0.001601
Validation Loss: 0.00154155
Epoch [105/300], Train Loss: 0.001588
Validation Loss: 0.00154213
Epoch [106/300], Train Loss: 0.001570
Validation Loss: 0.00154176
Epoch [107/300], Train Loss: 0.001571
Validation Loss: 0.00153879
Epoch [108/300], Train Loss: 0.001623
Validation Loss: 0.00153934
Epoch [109/300], Train Loss: 0.001627
Validation Loss: 0.00154948
Epoch [110/300], Train Loss: 0.001588
Validation Loss: 0.00154233
Epoch [111/300], Train Loss: 0.001603
Validation Loss: 0.00153399
Epoch [112/300], Train Loss: 0.001589
Validation Loss: 0.00156948
Epoch [113/300], Train Loss: 0.001608
Validation Loss: 0.00153199
Epoch [114/300], Train Loss: 0.001601
Validation Loss: 0.00153046
Epoch [115/300], Train Loss: 0.001632
Validation Loss: 0.00152674
Epoch [116/300], Train Loss: 0.001610
Validation Loss: 0.00153907
Epoch [117/300], Train Loss: 0.001624
Validation Loss: 0.00152803
Epoch [118/300], Train Loss: 0.001571
Validation Loss: 0.00152426
Epoch [119/300], Train Loss: 0.001646
Validation Loss: 0.00151812
Epoch [120/300], Train Loss: 0.001571
Validation Loss: 0.00153911
Epoch [121/300], Train Loss: 0.001606
Validation Loss: 0.00151944
Epoch [122/300], Train Loss: 0.001620
Validation Loss: 0.00152496
Epoch [123/300], Train Loss: 0.001569
Validation Loss: 0.00151224
Epoch [124/300], Train Loss: 0.001606
Validation Loss: 0.00150764
Epoch [125/300], Train Loss: 0.001613
Validation Loss: 0.00150783
Epoch [126/300], Train Loss: 0.001578
Validation Loss: 0.00154816
Epoch [127/300], Train Loss: 0.001605
Validation Loss: 0.00150001
Epoch [128/300], Train Loss: 0.001553
Validation Loss: 0.00151190
Epoch [129/300], Train Loss: 0.001560
Validation Loss: 0.00149449
Epoch [130/300], Train Loss: 0.001629
Validation Loss: 0.00150759
Epoch [131/300], Train Loss: 0.001583
Validation Loss: 0.00150449
Epoch [132/300], Train Loss: 0.001537
Validation Loss: 0.00149058
Epoch [133/300], Train Loss: 0.001547
Validation Loss: 0.00150719
Epoch [134/300], Train Loss: 0.001540
Validation Loss: 0.00149212
Epoch [135/300], Train Loss: 0.001611
Validation Loss: 0.00150484
Epoch [136/300], Train Loss: 0.001537
Validation Loss: 0.00148547
Epoch [137/300], Train Loss: 0.001560
Validation Loss: 0.00148853
Epoch [138/300], Train Loss: 0.001579
Validation Loss: 0.00149414
Epoch [139/300], Train Loss: 0.001517
Validation Loss: 0.00148809
Epoch [140/300], Train Loss: 0.001513
Validation Loss: 0.00149582
Epoch [141/300], Train Loss: 0.001594
Validation Loss: 0.00149263
Epoch [142/300], Train Loss: 0.001524
Validation Loss: 0.00149026
Epoch [143/300], Train Loss: 0.001552
Validation Loss: 0.00148571
Epoch [144/300], Train Loss: 0.001580
Validation Loss: 0.00148320
Epoch [145/300], Train Loss: 0.001599
Validation Loss: 0.00148573
Epoch [146/300], Train Loss: 0.001552
Validation Loss: 0.00148062
Epoch [147/300], Train Loss: 0.001589
Validation Loss: 0.00150408
Epoch [148/300], Train Loss: 0.001561
Validation Loss: 0.00147961
Epoch [149/300], Train Loss: 0.001531
Validation Loss: 0.00148105
Epoch [150/300], Train Loss: 0.001506
Validation Loss: 0.00147567
Epoch [151/300], Train Loss: 0.001598
Validation Loss: 0.00146880
Epoch [152/300], Train Loss: 0.001615
Validation Loss: 0.00147672
Epoch [153/300], Train Loss: 0.001577
Validation Loss: 0.00147227
Epoch [154/300], Train Loss: 0.001564
Validation Loss: 0.00147828
Epoch [155/300], Train Loss: 0.001624
Validation Loss: 0.00147034
Epoch [156/300], Train Loss: 0.001546
Validation Loss: 0.00147695
Epoch [157/300], Train Loss: 0.001534
Validation Loss: 0.00146346
Epoch [158/300], Train Loss: 0.001573
Validation Loss: 0.00147100
Epoch [159/300], Train Loss: 0.001556
Validation Loss: 0.00146441
Epoch [160/300], Train Loss: 0.001506
Validation Loss: 0.00146645
Epoch [161/300], Train Loss: 0.001567
Validation Loss: 0.00146601
Epoch [162/300], Train Loss: 0.001488
Validation Loss: 0.00146255
Epoch [163/300], Train Loss: 0.001589
Validation Loss: 0.00146985
Epoch [164/300], Train Loss: 0.001506
Validation Loss: 0.00147150
Epoch [165/300], Train Loss: 0.001491
Validation Loss: 0.00146189
Epoch [166/300], Train Loss: 0.001496
Validation Loss: 0.00146462
Epoch [167/300], Train Loss: 0.001487
Validation Loss: 0.00146002
Epoch [168/300], Train Loss: 0.001563
Validation Loss: 0.00146338
Epoch [169/300], Train Loss: 0.001520
Validation Loss: 0.00146585
Epoch [170/300], Train Loss: 0.001554
Validation Loss: 0.00145767
Epoch [171/300], Train Loss: 0.001549
Validation Loss: 0.00145837
Epoch [172/300], Train Loss: 0.001540
Validation Loss: 0.00146818
Epoch [173/300], Train Loss: 0.001570
Validation Loss: 0.00146606
Epoch [174/300], Train Loss: 0.001509
Validation Loss: 0.00146066
Epoch [175/300], Train Loss: 0.001515
Validation Loss: 0.00146334
Epoch [176/300], Train Loss: 0.001527
Validation Loss: 0.00146274
Epoch [177/300], Train Loss: 0.001545
Validation Loss: 0.00146055
Epoch [178/300], Train Loss: 0.001504
Validation Loss: 0.00146049
Epoch [179/300], Train Loss: 0.001497
Validation Loss: 0.00146244
Epoch [180/300], Train Loss: 0.001551
Validation Loss: 0.00151624
Early stopping triggered

Evaluating model for: Freezer
Run 18/72 completed in 475.42 seconds with: {'MAE': np.float32(33.00778), 'MSE': np.float32(2362.1047), 'RMSE': np.float32(48.60149), 'SAE': np.float32(0.04695942), 'NDE': np.float32(0.36304832)}

Run 19/72: hidden=128, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Freezer
Dataset length: 2262 windows

Epoch [1/300], Train Loss: 0.006561
Validation Loss: 0.00607073
Epoch [2/300], Train Loss: 0.005790
Validation Loss: 0.00590503
Epoch [3/300], Train Loss: 0.005749
Validation Loss: 0.00590348
Epoch [4/300], Train Loss: 0.005818
Validation Loss: 0.00592211
Epoch [5/300], Train Loss: 0.005827
Validation Loss: 0.00589885
Epoch [6/300], Train Loss: 0.005807
Validation Loss: 0.00589588
Epoch [7/300], Train Loss: 0.005855
Validation Loss: 0.00589513
Epoch [8/300], Train Loss: 0.005803
Validation Loss: 0.00588314
Epoch [9/300], Train Loss: 0.005816
Validation Loss: 0.00587858
Epoch [10/300], Train Loss: 0.005863
Validation Loss: 0.00585832
Epoch [11/300], Train Loss: 0.005763
Validation Loss: 0.00581163
Epoch [12/300], Train Loss: 0.005798
Validation Loss: 0.00567269
Epoch [13/300], Train Loss: 0.005543
Validation Loss: 0.00525571
Epoch [14/300], Train Loss: 0.004803
Validation Loss: 0.00429050
Epoch [15/300], Train Loss: 0.003990
Validation Loss: 0.00389412
Epoch [16/300], Train Loss: 0.003595
Validation Loss: 0.00354309
Epoch [17/300], Train Loss: 0.003405
Validation Loss: 0.00321398
Epoch [18/300], Train Loss: 0.003173
Validation Loss: 0.00302294
Epoch [19/300], Train Loss: 0.002931
Validation Loss: 0.00292351
Epoch [20/300], Train Loss: 0.002884
Validation Loss: 0.00278377
Epoch [21/300], Train Loss: 0.002865
Validation Loss: 0.00270680
Epoch [22/300], Train Loss: 0.002812
Validation Loss: 0.00268501
Epoch [23/300], Train Loss: 0.002566
Validation Loss: 0.00258752
Epoch [24/300], Train Loss: 0.002591
Validation Loss: 0.00253245
Epoch [25/300], Train Loss: 0.002518
Validation Loss: 0.00263270
Epoch [26/300], Train Loss: 0.002551
Validation Loss: 0.00244894
Epoch [27/300], Train Loss: 0.002398
Validation Loss: 0.00238763
Epoch [28/300], Train Loss: 0.002312
Validation Loss: 0.00223111
Epoch [29/300], Train Loss: 0.002304
Validation Loss: 0.00217964
Epoch [30/300], Train Loss: 0.002248
Validation Loss: 0.00212015
Epoch [31/300], Train Loss: 0.002091
Validation Loss: 0.00208959
Epoch [32/300], Train Loss: 0.002087
Validation Loss: 0.00208481
Epoch [33/300], Train Loss: 0.002092
Validation Loss: 0.00206311
Epoch [34/300], Train Loss: 0.002645
Validation Loss: 0.00332746
Epoch [35/300], Train Loss: 0.002753
Validation Loss: 0.00233960
Epoch [36/300], Train Loss: 0.002381
Validation Loss: 0.00223122
Epoch [37/300], Train Loss: 0.002282
Validation Loss: 0.00218439
Epoch [38/300], Train Loss: 0.002235
Validation Loss: 0.00215895
Epoch [39/300], Train Loss: 0.002276
Validation Loss: 0.00230749
Epoch [40/300], Train Loss: 0.002284
Validation Loss: 0.00222008
Epoch [41/300], Train Loss: 0.002225
Validation Loss: 0.00218731
Epoch [42/300], Train Loss: 0.002197
Validation Loss: 0.00216993
Epoch [43/300], Train Loss: 0.002168
Validation Loss: 0.00214183
Early stopping triggered

Evaluating model for: Freezer
Run 19/72 completed in 121.95 seconds with: {'MAE': np.float32(39.02987), 'MSE': np.float32(3266.084), 'RMSE': np.float32(57.149662), 'SAE': np.float32(0.07175733), 'NDE': np.float32(0.4269023)}

Run 20/72: hidden=128, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Freezer
Dataset length: 2262 windows

Epoch [1/300], Train Loss: 0.006882
Validation Loss: 0.00620475
Epoch [2/300], Train Loss: 0.005851
Validation Loss: 0.00591924
Epoch [3/300], Train Loss: 0.005772
Validation Loss: 0.00591062
Epoch [4/300], Train Loss: 0.005841
Validation Loss: 0.00593438
Epoch [5/300], Train Loss: 0.005847
Validation Loss: 0.00590514
Epoch [6/300], Train Loss: 0.005832
Validation Loss: 0.00590533
Epoch [7/300], Train Loss: 0.005880
Validation Loss: 0.00590698
Epoch [8/300], Train Loss: 0.005831
Validation Loss: 0.00589771
Epoch [9/300], Train Loss: 0.005850
Validation Loss: 0.00589908
Epoch [10/300], Train Loss: 0.005902
Validation Loss: 0.00588802
Epoch [11/300], Train Loss: 0.005816
Validation Loss: 0.00586197
Epoch [12/300], Train Loss: 0.005886
Validation Loss: 0.00575426
Epoch [13/300], Train Loss: 0.005479
Validation Loss: 0.00459632
Epoch [14/300], Train Loss: 0.004158
Validation Loss: 0.00347785
Epoch [15/300], Train Loss: 0.003453
Validation Loss: 0.00308800
Epoch [16/300], Train Loss: 0.003133
Validation Loss: 0.00293058
Epoch [17/300], Train Loss: 0.003064
Validation Loss: 0.00285377
Epoch [18/300], Train Loss: 0.002948
Validation Loss: 0.00275874
Epoch [19/300], Train Loss: 0.002813
Validation Loss: 0.00272007
Epoch [20/300], Train Loss: 0.002789
Validation Loss: 0.00262597
Epoch [21/300], Train Loss: 0.002734
Validation Loss: 0.00249518
Epoch [22/300], Train Loss: 0.002529
Validation Loss: 0.00236726
Epoch [23/300], Train Loss: 0.002229
Validation Loss: 0.00202929
Epoch [24/300], Train Loss: 0.002134
Validation Loss: 0.00197627
Epoch [25/300], Train Loss: 0.002002
Validation Loss: 0.00194655
Epoch [26/300], Train Loss: 0.001991
Validation Loss: 0.00190167
Epoch [27/300], Train Loss: 0.001982
Validation Loss: 0.00189881
Epoch [28/300], Train Loss: 0.001974
Validation Loss: 0.00196469
Epoch [29/300], Train Loss: 0.002089
Validation Loss: 0.00189136
Epoch [30/300], Train Loss: 0.001978
Validation Loss: 0.00188756
Epoch [31/300], Train Loss: 0.001937
Validation Loss: 0.00187869
Epoch [32/300], Train Loss: 0.001950
Validation Loss: 0.00186216
Epoch [33/300], Train Loss: 0.001959
Validation Loss: 0.00181383
Epoch [34/300], Train Loss: 0.001897
Validation Loss: 0.00188483
Epoch [35/300], Train Loss: 0.002036
Validation Loss: 0.00179399
Epoch [36/300], Train Loss: 0.001957
Validation Loss: 0.00182383
Epoch [37/300], Train Loss: 0.001914
Validation Loss: 0.00183529
Epoch [38/300], Train Loss: 0.001895
Validation Loss: 0.00180122
Epoch [39/300], Train Loss: 0.001908
Validation Loss: 0.00182308
Epoch [40/300], Train Loss: 0.001902
Validation Loss: 0.00183846
Epoch [41/300], Train Loss: 0.001906
Validation Loss: 0.00185610
Epoch [42/300], Train Loss: 0.001912
Validation Loss: 0.00183320
Epoch [43/300], Train Loss: 0.001862
Validation Loss: 0.00179113
Epoch [44/300], Train Loss: 0.002097
Validation Loss: 0.00309920
Epoch [45/300], Train Loss: 0.002836
Validation Loss: 0.00248360
Epoch [46/300], Train Loss: 0.002371
Validation Loss: 0.00213486
Epoch [47/300], Train Loss: 0.002172
Validation Loss: 0.00210236
Epoch [48/300], Train Loss: 0.002153
Validation Loss: 0.00207321
Epoch [49/300], Train Loss: 0.002164
Validation Loss: 0.00204823
Epoch [50/300], Train Loss: 0.002093
Validation Loss: 0.00203242
Epoch [51/300], Train Loss: 0.002068
Validation Loss: 0.00203205
Epoch [52/300], Train Loss: 0.002095
Validation Loss: 0.00204022
Epoch [53/300], Train Loss: 0.002042
Validation Loss: 0.00201927
Early stopping triggered

Evaluating model for: Freezer
Run 20/72 completed in 153.15 seconds with: {'MAE': np.float32(38.36692), 'MSE': np.float32(3161.3857), 'RMSE': np.float32(56.2262), 'SAE': np.float32(0.058795255), 'NDE': np.float32(0.42000413)}

Run 21/72: hidden=128, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Freezer
Dataset length: 1146 windows

Epoch [1/300], Train Loss: 0.006250
Validation Loss: 0.00601282
Epoch [2/300], Train Loss: 0.005969
Validation Loss: 0.00588628
Epoch [3/300], Train Loss: 0.006040
Validation Loss: 0.00586177
Epoch [4/300], Train Loss: 0.006085
Validation Loss: 0.00583968
Epoch [5/300], Train Loss: 0.005858
Validation Loss: 0.00582035
Epoch [6/300], Train Loss: 0.005886
Validation Loss: 0.00580904
Epoch [7/300], Train Loss: 0.005695
Validation Loss: 0.00578234
Epoch [8/300], Train Loss: 0.005693
Validation Loss: 0.00575239
Epoch [9/300], Train Loss: 0.005812
Validation Loss: 0.00572145
Epoch [10/300], Train Loss: 0.005678
Validation Loss: 0.00565272
Epoch [11/300], Train Loss: 0.005599
Validation Loss: 0.00558319
Epoch [12/300], Train Loss: 0.005394
Validation Loss: 0.00549554
Epoch [13/300], Train Loss: 0.005550
Validation Loss: 0.00543332
Epoch [14/300], Train Loss: 0.005214
Validation Loss: 0.00520454
Epoch [15/300], Train Loss: 0.005033
Validation Loss: 0.00501751
Epoch [16/300], Train Loss: 0.004791
Validation Loss: 0.00466880
Epoch [17/300], Train Loss: 0.004365
Validation Loss: 0.00429337
Epoch [18/300], Train Loss: 0.003898
Validation Loss: 0.00385968
Epoch [19/300], Train Loss: 0.003650
Validation Loss: 0.00359720
Epoch [20/300], Train Loss: 0.003466
Validation Loss: 0.00344967
Epoch [21/300], Train Loss: 0.003216
Validation Loss: 0.00339912
Epoch [22/300], Train Loss: 0.003204
Validation Loss: 0.00319191
Epoch [23/300], Train Loss: 0.003056
Validation Loss: 0.00302247
Epoch [24/300], Train Loss: 0.002838
Validation Loss: 0.00308312
Epoch [25/300], Train Loss: 0.002918
Validation Loss: 0.00282888
Epoch [26/300], Train Loss: 0.002595
Validation Loss: 0.00272806
Epoch [27/300], Train Loss: 0.002577
Validation Loss: 0.00265597
Epoch [28/300], Train Loss: 0.002514
Validation Loss: 0.00260204
Epoch [29/300], Train Loss: 0.002489
Validation Loss: 0.00253509
Epoch [30/300], Train Loss: 0.002379
Validation Loss: 0.00248400
Epoch [31/300], Train Loss: 0.002341
Validation Loss: 0.00244928
Epoch [32/300], Train Loss: 0.002304
Validation Loss: 0.00242704
Epoch [33/300], Train Loss: 0.002303
Validation Loss: 0.00241499
Epoch [34/300], Train Loss: 0.002329
Validation Loss: 0.00238339
Epoch [35/300], Train Loss: 0.002200
Validation Loss: 0.00236890
Epoch [36/300], Train Loss: 0.002166
Validation Loss: 0.00235145
Epoch [37/300], Train Loss: 0.002222
Validation Loss: 0.00234174
Epoch [38/300], Train Loss: 0.002276
Validation Loss: 0.00236691
Epoch [39/300], Train Loss: 0.002251
Validation Loss: 0.00230505
Epoch [40/300], Train Loss: 0.002137
Validation Loss: 0.00233717
Epoch [41/300], Train Loss: 0.002243
Validation Loss: 0.00228707
Epoch [42/300], Train Loss: 0.002082
Validation Loss: 0.00227436
Epoch [43/300], Train Loss: 0.002092
Validation Loss: 0.00223440
Epoch [44/300], Train Loss: 0.002009
Validation Loss: 0.00223308
Epoch [45/300], Train Loss: 0.002137
Validation Loss: 0.00226885
Epoch [46/300], Train Loss: 0.002104
Validation Loss: 0.00220436
Epoch [47/300], Train Loss: 0.002071
Validation Loss: 0.00221531
Epoch [48/300], Train Loss: 0.002127
Validation Loss: 0.00220108
Epoch [49/300], Train Loss: 0.002004
Validation Loss: 0.00223415
Epoch [50/300], Train Loss: 0.002060
Validation Loss: 0.00217058
Epoch [51/300], Train Loss: 0.002022
Validation Loss: 0.00216843
Epoch [52/300], Train Loss: 0.001979
Validation Loss: 0.00216229
Epoch [53/300], Train Loss: 0.002017
Validation Loss: 0.00218947
Epoch [54/300], Train Loss: 0.001945
Validation Loss: 0.00217229
Epoch [55/300], Train Loss: 0.001996
Validation Loss: 0.00215206
Epoch [56/300], Train Loss: 0.001987
Validation Loss: 0.00213493
Epoch [57/300], Train Loss: 0.001972
Validation Loss: 0.00213249
Epoch [58/300], Train Loss: 0.001984
Validation Loss: 0.00212367
Epoch [59/300], Train Loss: 0.001971
Validation Loss: 0.00214454
Epoch [60/300], Train Loss: 0.001960
Validation Loss: 0.00213273
Epoch [61/300], Train Loss: 0.001945
Validation Loss: 0.00211680
Epoch [62/300], Train Loss: 0.001912
Validation Loss: 0.00211370
Epoch [63/300], Train Loss: 0.001948
Validation Loss: 0.00211915
Epoch [64/300], Train Loss: 0.001912
Validation Loss: 0.00212048
Epoch [65/300], Train Loss: 0.001959
Validation Loss: 0.00210320
Epoch [66/300], Train Loss: 0.001937
Validation Loss: 0.00209844
Epoch [67/300], Train Loss: 0.001862
Validation Loss: 0.00210851
Epoch [68/300], Train Loss: 0.001964
Validation Loss: 0.00214981
Epoch [69/300], Train Loss: 0.001889
Validation Loss: 0.00209204
Epoch [70/300], Train Loss: 0.001958
Validation Loss: 0.00212957
Epoch [71/300], Train Loss: 0.002053
Validation Loss: 0.00212923
Epoch [72/300], Train Loss: 0.001819
Validation Loss: 0.00208841
Epoch [73/300], Train Loss: 0.001937
Validation Loss: 0.00210310
Epoch [74/300], Train Loss: 0.001900
Validation Loss: 0.00208114
Epoch [75/300], Train Loss: 0.001992
Validation Loss: 0.00210875
Epoch [76/300], Train Loss: 0.001849
Validation Loss: 0.00207154
Epoch [77/300], Train Loss: 0.002037
Validation Loss: 0.00207111
Epoch [78/300], Train Loss: 0.001907
Validation Loss: 0.00210276
Epoch [79/300], Train Loss: 0.001904
Validation Loss: 0.00206782
Epoch [80/300], Train Loss: 0.001912
Validation Loss: 0.00206577
Epoch [81/300], Train Loss: 0.001883
Validation Loss: 0.00206539
Epoch [82/300], Train Loss: 0.001852
Validation Loss: 0.00206849
Epoch [83/300], Train Loss: 0.001780
Validation Loss: 0.00206237
Epoch [84/300], Train Loss: 0.001819
Validation Loss: 0.00205978
Epoch [85/300], Train Loss: 0.001862
Validation Loss: 0.00205067
Epoch [86/300], Train Loss: 0.001900
Validation Loss: 0.00205634
Epoch [87/300], Train Loss: 0.001932
Validation Loss: 0.00207515
Epoch [88/300], Train Loss: 0.001932
Validation Loss: 0.00207387
Epoch [89/300], Train Loss: 0.001778
Validation Loss: 0.00205082
Epoch [90/300], Train Loss: 0.001856
Validation Loss: 0.00204231
Epoch [91/300], Train Loss: 0.001943
Validation Loss: 0.00205078
Epoch [92/300], Train Loss: 0.001932
Validation Loss: 0.00203277
Epoch [93/300], Train Loss: 0.001888
Validation Loss: 0.00204250
Epoch [94/300], Train Loss: 0.001878
Validation Loss: 0.00203399
Epoch [95/300], Train Loss: 0.001883
Validation Loss: 0.00204060
Epoch [96/300], Train Loss: 0.001888
Validation Loss: 0.00205491
Epoch [97/300], Train Loss: 0.001877
Validation Loss: 0.00202667
Epoch [98/300], Train Loss: 0.001842
Validation Loss: 0.00204860
Epoch [99/300], Train Loss: 0.001877
Validation Loss: 0.00203532
Epoch [100/300], Train Loss: 0.001846
Validation Loss: 0.00202861
Epoch [101/300], Train Loss: 0.001839
Validation Loss: 0.00204836
Epoch [102/300], Train Loss: 0.001907
Validation Loss: 0.00203568
Epoch [103/300], Train Loss: 0.001865
Validation Loss: 0.00201330
Epoch [104/300], Train Loss: 0.001796
Validation Loss: 0.00201082
Epoch [105/300], Train Loss: 0.001854
Validation Loss: 0.00200668
Epoch [106/300], Train Loss: 0.001833
Validation Loss: 0.00202427
Epoch [107/300], Train Loss: 0.001943
Validation Loss: 0.00202869
Epoch [108/300], Train Loss: 0.001896
Validation Loss: 0.00200877
Epoch [109/300], Train Loss: 0.001867
Validation Loss: 0.00201664
Epoch [110/300], Train Loss: 0.001830
Validation Loss: 0.00200424
Epoch [111/300], Train Loss: 0.001788
Validation Loss: 0.00201182
Epoch [112/300], Train Loss: 0.001768
Validation Loss: 0.00200776
Epoch [113/300], Train Loss: 0.001795
Validation Loss: 0.00199159
Epoch [114/300], Train Loss: 0.001792
Validation Loss: 0.00199259
Epoch [115/300], Train Loss: 0.001712
Validation Loss: 0.00199936
Epoch [116/300], Train Loss: 0.001806
Validation Loss: 0.00199491
Epoch [117/300], Train Loss: 0.001799
Validation Loss: 0.00200377
Epoch [118/300], Train Loss: 0.001744
Validation Loss: 0.00199010
Epoch [119/300], Train Loss: 0.001738
Validation Loss: 0.00198715
Epoch [120/300], Train Loss: 0.001840
Validation Loss: 0.00199016
Epoch [121/300], Train Loss: 0.001793
Validation Loss: 0.00198073
Epoch [122/300], Train Loss: 0.001833
Validation Loss: 0.00198110
Epoch [123/300], Train Loss: 0.001761
Validation Loss: 0.00198935
Epoch [124/300], Train Loss: 0.001845
Validation Loss: 0.00197739
Epoch [125/300], Train Loss: 0.001737
Validation Loss: 0.00198539
Epoch [126/300], Train Loss: 0.001832
Validation Loss: 0.00199905
Epoch [127/300], Train Loss: 0.001853
Validation Loss: 0.00197277
Epoch [128/300], Train Loss: 0.001712
Validation Loss: 0.00197135
Epoch [129/300], Train Loss: 0.001791
Validation Loss: 0.00198145
Epoch [130/300], Train Loss: 0.001857
Validation Loss: 0.00197340
Epoch [131/300], Train Loss: 0.001727
Validation Loss: 0.00196669
Epoch [132/300], Train Loss: 0.001801
Validation Loss: 0.00197222
Epoch [133/300], Train Loss: 0.001723
Validation Loss: 0.00196400
Epoch [134/300], Train Loss: 0.001776
Validation Loss: 0.00196702
Epoch [135/300], Train Loss: 0.001792
Validation Loss: 0.00195925
Epoch [136/300], Train Loss: 0.001729
Validation Loss: 0.00195931
Epoch [137/300], Train Loss: 0.001752
Validation Loss: 0.00196597
Epoch [138/300], Train Loss: 0.001724
Validation Loss: 0.00195889
Epoch [139/300], Train Loss: 0.001781
Validation Loss: 0.00198104
Epoch [140/300], Train Loss: 0.001767
Validation Loss: 0.00195457
Epoch [141/300], Train Loss: 0.001720
Validation Loss: 0.00195634
Epoch [142/300], Train Loss: 0.001820
Validation Loss: 0.00194680
Epoch [143/300], Train Loss: 0.001774
Validation Loss: 0.00194593
Epoch [144/300], Train Loss: 0.001763
Validation Loss: 0.00194585
Epoch [145/300], Train Loss: 0.001755
Validation Loss: 0.00196230
Epoch [146/300], Train Loss: 0.001743
Validation Loss: 0.00194493
Epoch [147/300], Train Loss: 0.001839
Validation Loss: 0.00194954
Epoch [148/300], Train Loss: 0.001754
Validation Loss: 0.00194403
Epoch [149/300], Train Loss: 0.001816
Validation Loss: 0.00193881
Epoch [150/300], Train Loss: 0.001681
Validation Loss: 0.00194110
Epoch [151/300], Train Loss: 0.001703
Validation Loss: 0.00193998
Epoch [152/300], Train Loss: 0.001736
Validation Loss: 0.00193595
Epoch [153/300], Train Loss: 0.001691
Validation Loss: 0.00193422
Epoch [154/300], Train Loss: 0.001752
Validation Loss: 0.00194077
Epoch [155/300], Train Loss: 0.001805
Validation Loss: 0.00193176
Epoch [156/300], Train Loss: 0.001709
Validation Loss: 0.00193134
Epoch [157/300], Train Loss: 0.001771
Validation Loss: 0.00193243
Epoch [158/300], Train Loss: 0.001815
Validation Loss: 0.00193560
Epoch [159/300], Train Loss: 0.001767
Validation Loss: 0.00193309
Epoch [160/300], Train Loss: 0.001699
Validation Loss: 0.00193290
Epoch [161/300], Train Loss: 0.001869
Validation Loss: 0.00192882
Epoch [162/300], Train Loss: 0.001792
Validation Loss: 0.00192466
Epoch [163/300], Train Loss: 0.001750
Validation Loss: 0.00192679
Epoch [164/300], Train Loss: 0.001686
Validation Loss: 0.00191869
Epoch [165/300], Train Loss: 0.001743
Validation Loss: 0.00191912
Epoch [166/300], Train Loss: 0.001774
Validation Loss: 0.00192281
Epoch [167/300], Train Loss: 0.001760
Validation Loss: 0.00192454
Epoch [168/300], Train Loss: 0.001761
Validation Loss: 0.00193279
Epoch [169/300], Train Loss: 0.001774
Validation Loss: 0.00191865
Epoch [170/300], Train Loss: 0.001726
Validation Loss: 0.00192321
Epoch [171/300], Train Loss: 0.001693
Validation Loss: 0.00192491
Epoch [172/300], Train Loss: 0.001663
Validation Loss: 0.00191830
Epoch [173/300], Train Loss: 0.001770
Validation Loss: 0.00193277
Epoch [174/300], Train Loss: 0.001706
Validation Loss: 0.00192002
Epoch [175/300], Train Loss: 0.001652
Validation Loss: 0.00192299
Epoch [176/300], Train Loss: 0.001738
Validation Loss: 0.00191417
Epoch [177/300], Train Loss: 0.001658
Validation Loss: 0.00191639
Epoch [178/300], Train Loss: 0.001667
Validation Loss: 0.00191300
Epoch [179/300], Train Loss: 0.001670
Validation Loss: 0.00191338
Epoch [180/300], Train Loss: 0.001757
Validation Loss: 0.00191420
Epoch [181/300], Train Loss: 0.001744
Validation Loss: 0.00191051
Epoch [182/300], Train Loss: 0.001711
Validation Loss: 0.00190685
Epoch [183/300], Train Loss: 0.001756
Validation Loss: 0.00193139
Epoch [184/300], Train Loss: 0.001744
Validation Loss: 0.00192292
Epoch [185/300], Train Loss: 0.001773
Validation Loss: 0.00191539
Epoch [186/300], Train Loss: 0.001791
Validation Loss: 0.00190746
Epoch [187/300], Train Loss: 0.001776
Validation Loss: 0.00190943
Epoch [188/300], Train Loss: 0.001770
Validation Loss: 0.00190912
Epoch [189/300], Train Loss: 0.001701
Validation Loss: 0.00190554
Epoch [190/300], Train Loss: 0.001720
Validation Loss: 0.00191215
Epoch [191/300], Train Loss: 0.001682
Validation Loss: 0.00190590
Epoch [192/300], Train Loss: 0.001752
Validation Loss: 0.00190389
Epoch [193/300], Train Loss: 0.001798
Validation Loss: 0.00190684
Epoch [194/300], Train Loss: 0.001715
Validation Loss: 0.00190193
Epoch [195/300], Train Loss: 0.001675
Validation Loss: 0.00190100
Epoch [196/300], Train Loss: 0.001808
Validation Loss: 0.00190552
Epoch [197/300], Train Loss: 0.001749
Validation Loss: 0.00189905
Epoch [198/300], Train Loss: 0.001649
Validation Loss: 0.00190291
Epoch [199/300], Train Loss: 0.001605
Validation Loss: 0.00189625
Epoch [200/300], Train Loss: 0.001742
Validation Loss: 0.00190353
Epoch [201/300], Train Loss: 0.001804
Validation Loss: 0.00189647
Epoch [202/300], Train Loss: 0.001746
Validation Loss: 0.00189461
Epoch [203/300], Train Loss: 0.001636
Validation Loss: 0.00190441
Epoch [204/300], Train Loss: 0.001759
Validation Loss: 0.00189743
Epoch [205/300], Train Loss: 0.001650
Validation Loss: 0.00189692
Epoch [206/300], Train Loss: 0.001807
Validation Loss: 0.00189525
Epoch [207/300], Train Loss: 0.001700
Validation Loss: 0.00189707
Epoch [208/300], Train Loss: 0.001665
Validation Loss: 0.00189442
Epoch [209/300], Train Loss: 0.001825
Validation Loss: 0.00189092
Epoch [210/300], Train Loss: 0.001742
Validation Loss: 0.00188678
Epoch [211/300], Train Loss: 0.001644
Validation Loss: 0.00188645
Epoch [212/300], Train Loss: 0.001666
Validation Loss: 0.00189068
Epoch [213/300], Train Loss: 0.001625
Validation Loss: 0.00188897
Epoch [214/300], Train Loss: 0.001712
Validation Loss: 0.00189242
Epoch [215/300], Train Loss: 0.001643
Validation Loss: 0.00189407
Epoch [216/300], Train Loss: 0.001691
Validation Loss: 0.00189345
Epoch [217/300], Train Loss: 0.001750
Validation Loss: 0.00188934
Epoch [218/300], Train Loss: 0.001786
Validation Loss: 0.00189198
Epoch [219/300], Train Loss: 0.001737
Validation Loss: 0.00188913
Epoch [220/300], Train Loss: 0.001698
Validation Loss: 0.00189125
Epoch [221/300], Train Loss: 0.001705
Validation Loss: 0.00188677
Early stopping triggered

Evaluating model for: Freezer
Run 21/72 completed in 274.82 seconds with: {'MAE': np.float32(32.489082), 'MSE': np.float32(2297.3044), 'RMSE': np.float32(47.930202), 'SAE': np.float32(0.004117313), 'NDE': np.float32(0.3767711)}

Run 22/72: hidden=128, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Freezer
Dataset length: 1146 windows

Epoch [1/300], Train Loss: 0.014699
Validation Loss: 0.01350597
Epoch [2/300], Train Loss: 0.012079
Validation Loss: 0.01105741
Epoch [3/300], Train Loss: 0.010196
Validation Loss: 0.00896527
Epoch [4/300], Train Loss: 0.008276
Validation Loss: 0.00720505
Epoch [5/300], Train Loss: 0.006564
Validation Loss: 0.00606329
Epoch [6/300], Train Loss: 0.006042
Validation Loss: 0.00592119
Epoch [7/300], Train Loss: 0.006018
Validation Loss: 0.00590860
Epoch [8/300], Train Loss: 0.005926
Validation Loss: 0.00589149
Epoch [9/300], Train Loss: 0.006073
Validation Loss: 0.00594908
Epoch [10/300], Train Loss: 0.005978
Validation Loss: 0.00589448
Epoch [11/300], Train Loss: 0.005936
Validation Loss: 0.00585656
Epoch [12/300], Train Loss: 0.005803
Validation Loss: 0.00584455
Epoch [13/300], Train Loss: 0.006059
Validation Loss: 0.00587206
Epoch [14/300], Train Loss: 0.005867
Validation Loss: 0.00584034
Epoch [15/300], Train Loss: 0.005883
Validation Loss: 0.00583208
Epoch [16/300], Train Loss: 0.005873
Validation Loss: 0.00581717
Epoch [17/300], Train Loss: 0.005848
Validation Loss: 0.00579631
Epoch [18/300], Train Loss: 0.005843
Validation Loss: 0.00578322
Epoch [19/300], Train Loss: 0.005797
Validation Loss: 0.00575996
Epoch [20/300], Train Loss: 0.005807
Validation Loss: 0.00573815
Epoch [21/300], Train Loss: 0.005637
Validation Loss: 0.00570805
Epoch [22/300], Train Loss: 0.005690
Validation Loss: 0.00570543
Epoch [23/300], Train Loss: 0.005704
Validation Loss: 0.00563272
Epoch [24/300], Train Loss: 0.005570
Validation Loss: 0.00554585
Epoch [25/300], Train Loss: 0.005586
Validation Loss: 0.00549956
Epoch [26/300], Train Loss: 0.005317
Validation Loss: 0.00534625
Epoch [27/300], Train Loss: 0.005304
Validation Loss: 0.00524104
Epoch [28/300], Train Loss: 0.005273
Validation Loss: 0.00518931
Epoch [29/300], Train Loss: 0.005093
Validation Loss: 0.00507253
Epoch [30/300], Train Loss: 0.004961
Validation Loss: 0.00500469
Epoch [31/300], Train Loss: 0.004927
Validation Loss: 0.00487673
Epoch [32/300], Train Loss: 0.004699
Validation Loss: 0.00482206
Epoch [33/300], Train Loss: 0.004649
Validation Loss: 0.00462186
Epoch [34/300], Train Loss: 0.004479
Validation Loss: 0.00455022
Epoch [35/300], Train Loss: 0.004356
Validation Loss: 0.00427872
Epoch [36/300], Train Loss: 0.004054
Validation Loss: 0.00408760
Epoch [37/300], Train Loss: 0.003953
Validation Loss: 0.00381986
Epoch [38/300], Train Loss: 0.003746
Validation Loss: 0.00348155
Epoch [39/300], Train Loss: 0.003481
Validation Loss: 0.00321959
Epoch [40/300], Train Loss: 0.003189
Validation Loss: 0.00301290
Epoch [41/300], Train Loss: 0.003137
Validation Loss: 0.00288867
Epoch [42/300], Train Loss: 0.002902
Validation Loss: 0.00281551
Epoch [43/300], Train Loss: 0.002884
Validation Loss: 0.00289210
Epoch [44/300], Train Loss: 0.002850
Validation Loss: 0.00280292
Epoch [45/300], Train Loss: 0.002914
Validation Loss: 0.00276831
Epoch [46/300], Train Loss: 0.002832
Validation Loss: 0.00271951
Epoch [47/300], Train Loss: 0.002799
Validation Loss: 0.00278407
Epoch [48/300], Train Loss: 0.002837
Validation Loss: 0.00265326
Epoch [49/300], Train Loss: 0.002658
Validation Loss: 0.00276400
Epoch [50/300], Train Loss: 0.002728
Validation Loss: 0.00266990
Epoch [51/300], Train Loss: 0.002743
Validation Loss: 0.00256657
Epoch [52/300], Train Loss: 0.002587
Validation Loss: 0.00254743
Epoch [53/300], Train Loss: 0.002569
Validation Loss: 0.00248101
Epoch [54/300], Train Loss: 0.002528
Validation Loss: 0.00245006
Epoch [55/300], Train Loss: 0.002501
Validation Loss: 0.00246194
Epoch [56/300], Train Loss: 0.002479
Validation Loss: 0.00242444
Epoch [57/300], Train Loss: 0.002421
Validation Loss: 0.00237752
Epoch [58/300], Train Loss: 0.002409
Validation Loss: 0.00237289
Epoch [59/300], Train Loss: 0.002412
Validation Loss: 0.00233338
Epoch [60/300], Train Loss: 0.002349
Validation Loss: 0.00232724
Epoch [61/300], Train Loss: 0.002318
Validation Loss: 0.00230989
Epoch [62/300], Train Loss: 0.002255
Validation Loss: 0.00228676
Epoch [63/300], Train Loss: 0.002266
Validation Loss: 0.00227315
Epoch [64/300], Train Loss: 0.002236
Validation Loss: 0.00224350
Epoch [65/300], Train Loss: 0.002237
Validation Loss: 0.00224752
Epoch [66/300], Train Loss: 0.002235
Validation Loss: 0.00222376
Epoch [67/300], Train Loss: 0.002138
Validation Loss: 0.00221035
Epoch [68/300], Train Loss: 0.002215
Validation Loss: 0.00219085
Epoch [69/300], Train Loss: 0.002101
Validation Loss: 0.00218046
Epoch [70/300], Train Loss: 0.002197
Validation Loss: 0.00224379
Epoch [71/300], Train Loss: 0.002279
Validation Loss: 0.00216594
Epoch [72/300], Train Loss: 0.002041
Validation Loss: 0.00213765
Epoch [73/300], Train Loss: 0.002139
Validation Loss: 0.00213531
Epoch [74/300], Train Loss: 0.002072
Validation Loss: 0.00211148
Epoch [75/300], Train Loss: 0.002144
Validation Loss: 0.00209425
Epoch [76/300], Train Loss: 0.001978
Validation Loss: 0.00208453
Epoch [77/300], Train Loss: 0.002138
Validation Loss: 0.00206424
Epoch [78/300], Train Loss: 0.002002
Validation Loss: 0.00206129
Epoch [79/300], Train Loss: 0.001996
Validation Loss: 0.00205576
Epoch [80/300], Train Loss: 0.002002
Validation Loss: 0.00203152
Epoch [81/300], Train Loss: 0.001968
Validation Loss: 0.00204329
Epoch [82/300], Train Loss: 0.001926
Validation Loss: 0.00203478
Epoch [83/300], Train Loss: 0.001832
Validation Loss: 0.00202052
Epoch [84/300], Train Loss: 0.001868
Validation Loss: 0.00201702
Epoch [85/300], Train Loss: 0.001913
Validation Loss: 0.00200792
Epoch [86/300], Train Loss: 0.001965
Validation Loss: 0.00204244
Epoch [87/300], Train Loss: 0.001969
Validation Loss: 0.00200222
Epoch [88/300], Train Loss: 0.001965
Validation Loss: 0.00203827
Epoch [89/300], Train Loss: 0.001820
Validation Loss: 0.00198831
Epoch [90/300], Train Loss: 0.001883
Validation Loss: 0.00200062
Epoch [91/300], Train Loss: 0.001951
Validation Loss: 0.00199374
Epoch [92/300], Train Loss: 0.001970
Validation Loss: 0.00198144
Epoch [93/300], Train Loss: 0.001915
Validation Loss: 0.00199179
Epoch [94/300], Train Loss: 0.001909
Validation Loss: 0.00198617
Epoch [95/300], Train Loss: 0.001901
Validation Loss: 0.00197684
Epoch [96/300], Train Loss: 0.001917
Validation Loss: 0.00201737
Epoch [97/300], Train Loss: 0.001911
Validation Loss: 0.00196932
Epoch [98/300], Train Loss: 0.001865
Validation Loss: 0.00197842
Epoch [99/300], Train Loss: 0.001894
Validation Loss: 0.00198552
Epoch [100/300], Train Loss: 0.001875
Validation Loss: 0.00197261
Epoch [101/300], Train Loss: 0.001852
Validation Loss: 0.00198386
Epoch [102/300], Train Loss: 0.001920
Validation Loss: 0.00198831
Epoch [103/300], Train Loss: 0.001878
Validation Loss: 0.00196228
Epoch [104/300], Train Loss: 0.001809
Validation Loss: 0.00196519
Epoch [105/300], Train Loss: 0.001873
Validation Loss: 0.00197634
Epoch [106/300], Train Loss: 0.001872
Validation Loss: 0.00198282
Epoch [107/300], Train Loss: 0.001959
Validation Loss: 0.00199701
Epoch [108/300], Train Loss: 0.001930
Validation Loss: 0.00198301
Epoch [109/300], Train Loss: 0.001889
Validation Loss: 0.00196411
Epoch [110/300], Train Loss: 0.001840
Validation Loss: 0.00197094
Epoch [111/300], Train Loss: 0.001807
Validation Loss: 0.00196442
Epoch [112/300], Train Loss: 0.001793
Validation Loss: 0.00196154
Epoch [113/300], Train Loss: 0.001807
Validation Loss: 0.00195437
Epoch [114/300], Train Loss: 0.001813
Validation Loss: 0.00195887
Epoch [115/300], Train Loss: 0.001740
Validation Loss: 0.00195988
Epoch [116/300], Train Loss: 0.001822
Validation Loss: 0.00196012
Epoch [117/300], Train Loss: 0.001816
Validation Loss: 0.00196622
Epoch [118/300], Train Loss: 0.001770
Validation Loss: 0.00195614
Epoch [119/300], Train Loss: 0.001770
Validation Loss: 0.00195976
Epoch [120/300], Train Loss: 0.001868
Validation Loss: 0.00195891
Epoch [121/300], Train Loss: 0.001806
Validation Loss: 0.00195367
Epoch [122/300], Train Loss: 0.001875
Validation Loss: 0.00195498
Epoch [123/300], Train Loss: 0.001804
Validation Loss: 0.00195684
Epoch [124/300], Train Loss: 0.001872
Validation Loss: 0.00195233
Epoch [125/300], Train Loss: 0.001768
Validation Loss: 0.00197797
Epoch [126/300], Train Loss: 0.001861
Validation Loss: 0.00197282
Epoch [127/300], Train Loss: 0.001890
Validation Loss: 0.00194646
Epoch [128/300], Train Loss: 0.001742
Validation Loss: 0.00196315
Epoch [129/300], Train Loss: 0.001815
Validation Loss: 0.00197662
Epoch [130/300], Train Loss: 0.001898
Validation Loss: 0.00195440
Epoch [131/300], Train Loss: 0.001766
Validation Loss: 0.00196476
Epoch [132/300], Train Loss: 0.001844
Validation Loss: 0.00195250
Epoch [133/300], Train Loss: 0.001773
Validation Loss: 0.00194454
Epoch [134/300], Train Loss: 0.001810
Validation Loss: 0.00194600
Epoch [135/300], Train Loss: 0.001828
Validation Loss: 0.00194541
Epoch [136/300], Train Loss: 0.001767
Validation Loss: 0.00195196
Epoch [137/300], Train Loss: 0.001786
Validation Loss: 0.00194736
Epoch [138/300], Train Loss: 0.001767
Validation Loss: 0.00195297
Epoch [139/300], Train Loss: 0.001817
Validation Loss: 0.00196047
Epoch [140/300], Train Loss: 0.001809
Validation Loss: 0.00194105
Epoch [141/300], Train Loss: 0.001765
Validation Loss: 0.00192802
Epoch [142/300], Train Loss: 0.001845
Validation Loss: 0.00193288
Epoch [143/300], Train Loss: 0.001805
Validation Loss: 0.00193414
Epoch [144/300], Train Loss: 0.001797
Validation Loss: 0.00193368
Epoch [145/300], Train Loss: 0.001793
Validation Loss: 0.00195448
Epoch [146/300], Train Loss: 0.001788
Validation Loss: 0.00193695
Epoch [147/300], Train Loss: 0.001886
Validation Loss: 0.00193086
Epoch [148/300], Train Loss: 0.001790
Validation Loss: 0.00192502
Epoch [149/300], Train Loss: 0.001843
Validation Loss: 0.00192463
Epoch [150/300], Train Loss: 0.001720
Validation Loss: 0.00193206
Epoch [151/300], Train Loss: 0.001744
Validation Loss: 0.00192037
Epoch [152/300], Train Loss: 0.001775
Validation Loss: 0.00192102
Epoch [153/300], Train Loss: 0.001732
Validation Loss: 0.00192149
Epoch [154/300], Train Loss: 0.001788
Validation Loss: 0.00191984
Epoch [155/300], Train Loss: 0.001846
Validation Loss: 0.00191388
Epoch [156/300], Train Loss: 0.001753
Validation Loss: 0.00191548
Epoch [157/300], Train Loss: 0.001812
Validation Loss: 0.00191783
Epoch [158/300], Train Loss: 0.001864
Validation Loss: 0.00191368
Epoch [159/300], Train Loss: 0.001797
Validation Loss: 0.00191624
Epoch [160/300], Train Loss: 0.001732
Validation Loss: 0.00190538
Epoch [161/300], Train Loss: 0.001893
Validation Loss: 0.00191126
Epoch [162/300], Train Loss: 0.001829
Validation Loss: 0.00190761
Epoch [163/300], Train Loss: 0.001789
Validation Loss: 0.00190463
Epoch [164/300], Train Loss: 0.001726
Validation Loss: 0.00189876
Epoch [165/300], Train Loss: 0.001774
Validation Loss: 0.00190029
Epoch [166/300], Train Loss: 0.001801
Validation Loss: 0.00189962
Epoch [167/300], Train Loss: 0.001810
Validation Loss: 0.00191086
Epoch [168/300], Train Loss: 0.001804
Validation Loss: 0.00190763
Epoch [169/300], Train Loss: 0.001793
Validation Loss: 0.00192714
Epoch [170/300], Train Loss: 0.001768
Validation Loss: 0.00189676
Epoch [171/300], Train Loss: 0.001732
Validation Loss: 0.00189720
Epoch [172/300], Train Loss: 0.001691
Validation Loss: 0.00190696
Epoch [173/300], Train Loss: 0.001805
Validation Loss: 0.00191060
Epoch [174/300], Train Loss: 0.001738
Validation Loss: 0.00190191
Epoch [175/300], Train Loss: 0.001689
Validation Loss: 0.00190251
Epoch [176/300], Train Loss: 0.001767
Validation Loss: 0.00189770
Epoch [177/300], Train Loss: 0.001689
Validation Loss: 0.00189121
Epoch [178/300], Train Loss: 0.001694
Validation Loss: 0.00188476
Epoch [179/300], Train Loss: 0.001696
Validation Loss: 0.00189596
Epoch [180/300], Train Loss: 0.001789
Validation Loss: 0.00188562
Epoch [181/300], Train Loss: 0.001776
Validation Loss: 0.00188312
Epoch [182/300], Train Loss: 0.001739
Validation Loss: 0.00188328
Epoch [183/300], Train Loss: 0.001782
Validation Loss: 0.00189602
Epoch [184/300], Train Loss: 0.001771
Validation Loss: 0.00189074
Epoch [185/300], Train Loss: 0.001799
Validation Loss: 0.00188245
Epoch [186/300], Train Loss: 0.001816
Validation Loss: 0.00189184
Epoch [187/300], Train Loss: 0.001819
Validation Loss: 0.00187543
Epoch [188/300], Train Loss: 0.001794
Validation Loss: 0.00187863
Epoch [189/300], Train Loss: 0.001716
Validation Loss: 0.00187921
Epoch [190/300], Train Loss: 0.001748
Validation Loss: 0.00188287
Epoch [191/300], Train Loss: 0.001712
Validation Loss: 0.00187440
Epoch [192/300], Train Loss: 0.001778
Validation Loss: 0.00187258
Epoch [193/300], Train Loss: 0.001823
Validation Loss: 0.00187401
Epoch [194/300], Train Loss: 0.001730
Validation Loss: 0.00187051
Epoch [195/300], Train Loss: 0.001708
Validation Loss: 0.00187480
Epoch [196/300], Train Loss: 0.001840
Validation Loss: 0.00186801
Epoch [197/300], Train Loss: 0.001786
Validation Loss: 0.00186833
Epoch [198/300], Train Loss: 0.001671
Validation Loss: 0.00187389
Epoch [199/300], Train Loss: 0.001626
Validation Loss: 0.00186675
Epoch [200/300], Train Loss: 0.001783
Validation Loss: 0.00186831
Epoch [201/300], Train Loss: 0.001840
Validation Loss: 0.00186278
Epoch [202/300], Train Loss: 0.001761
Validation Loss: 0.00186953
Epoch [203/300], Train Loss: 0.001656
Validation Loss: 0.00186985
Epoch [204/300], Train Loss: 0.001791
Validation Loss: 0.00186687
Epoch [205/300], Train Loss: 0.001672
Validation Loss: 0.00186721
Epoch [206/300], Train Loss: 0.001846
Validation Loss: 0.00186065
Epoch [207/300], Train Loss: 0.001719
Validation Loss: 0.00186716
Epoch [208/300], Train Loss: 0.001687
Validation Loss: 0.00186046
Epoch [209/300], Train Loss: 0.001836
Validation Loss: 0.00185925
Epoch [210/300], Train Loss: 0.001755
Validation Loss: 0.00185761
Epoch [211/300], Train Loss: 0.001657
Validation Loss: 0.00185829
Epoch [212/300], Train Loss: 0.001693
Validation Loss: 0.00185852
Epoch [213/300], Train Loss: 0.001640
Validation Loss: 0.00185749
Epoch [214/300], Train Loss: 0.001729
Validation Loss: 0.00185558
Epoch [215/300], Train Loss: 0.001658
Validation Loss: 0.00185692
Epoch [216/300], Train Loss: 0.001708
Validation Loss: 0.00185808
Epoch [217/300], Train Loss: 0.001765
Validation Loss: 0.00185840
Epoch [218/300], Train Loss: 0.001791
Validation Loss: 0.00186013
Epoch [219/300], Train Loss: 0.001759
Validation Loss: 0.00185809
Epoch [220/300], Train Loss: 0.001722
Validation Loss: 0.00185707
Epoch [221/300], Train Loss: 0.001730
Validation Loss: 0.00185644
Epoch [222/300], Train Loss: 0.001691
Validation Loss: 0.00185580
Epoch [223/300], Train Loss: 0.001844
Validation Loss: 0.00185463
Epoch [224/300], Train Loss: 0.001727
Validation Loss: 0.00185573
Epoch [225/300], Train Loss: 0.001653
Validation Loss: 0.00185486
Epoch [226/300], Train Loss: 0.001685
Validation Loss: 0.00185258
Epoch [227/300], Train Loss: 0.001740
Validation Loss: 0.00185495
Epoch [228/300], Train Loss: 0.001652
Validation Loss: 0.00185282
Epoch [229/300], Train Loss: 0.001628
Validation Loss: 0.00185147
Epoch [230/300], Train Loss: 0.001745
Validation Loss: 0.00185631
Epoch [231/300], Train Loss: 0.001665
Validation Loss: 0.00185186
Epoch [232/300], Train Loss: 0.001715
Validation Loss: 0.00185240
Epoch [233/300], Train Loss: 0.001720
Validation Loss: 0.00185485
Epoch [234/300], Train Loss: 0.001727
Validation Loss: 0.00185424
Epoch [235/300], Train Loss: 0.001799
Validation Loss: 0.00185436
Epoch [236/300], Train Loss: 0.001740
Validation Loss: 0.00185308
Epoch [237/300], Train Loss: 0.001762
Validation Loss: 0.00185407
Epoch [238/300], Train Loss: 0.001615
Validation Loss: 0.00185083
Epoch [239/300], Train Loss: 0.001719
Validation Loss: 0.00185139
Epoch [240/300], Train Loss: 0.001687
Validation Loss: 0.00184983
Epoch [241/300], Train Loss: 0.001712
Validation Loss: 0.00185272
Epoch [242/300], Train Loss: 0.001729
Validation Loss: 0.00185205
Epoch [243/300], Train Loss: 0.001600
Validation Loss: 0.00185053
Epoch [244/300], Train Loss: 0.001737
Validation Loss: 0.00184904
Epoch [245/300], Train Loss: 0.001687
Validation Loss: 0.00184947
Epoch [246/300], Train Loss: 0.001690
Validation Loss: 0.00185136
Epoch [247/300], Train Loss: 0.001609
Validation Loss: 0.00184868
Epoch [248/300], Train Loss: 0.001691
Validation Loss: 0.00184949
Epoch [249/300], Train Loss: 0.001682
Validation Loss: 0.00184956
Epoch [250/300], Train Loss: 0.001729
Validation Loss: 0.00185033
Epoch [251/300], Train Loss: 0.001691
Validation Loss: 0.00185053
Epoch [252/300], Train Loss: 0.001675
Validation Loss: 0.00184886
Epoch [253/300], Train Loss: 0.001658
Validation Loss: 0.00184986
Epoch [254/300], Train Loss: 0.001783
Validation Loss: 0.00184985
Epoch [255/300], Train Loss: 0.001809
Validation Loss: 0.00184993
Epoch [256/300], Train Loss: 0.001726
Validation Loss: 0.00184971
Epoch [257/300], Train Loss: 0.001717
Validation Loss: 0.00184787
Epoch [258/300], Train Loss: 0.001743
Validation Loss: 0.00184756
Epoch [259/300], Train Loss: 0.001656
Validation Loss: 0.00185030
Epoch [260/300], Train Loss: 0.001629
Validation Loss: 0.00184869
Epoch [261/300], Train Loss: 0.001658
Validation Loss: 0.00184975
Epoch [262/300], Train Loss: 0.001614
Validation Loss: 0.00185117
Epoch [263/300], Train Loss: 0.001732
Validation Loss: 0.00184911
Epoch [264/300], Train Loss: 0.001780
Validation Loss: 0.00184956
Epoch [265/300], Train Loss: 0.001882
Validation Loss: 0.00184875
Epoch [266/300], Train Loss: 0.001726
Validation Loss: 0.00184945
Epoch [267/300], Train Loss: 0.001702
Validation Loss: 0.00184711
Epoch [268/300], Train Loss: 0.001701
Validation Loss: 0.00184825
Epoch [269/300], Train Loss: 0.001696
Validation Loss: 0.00184845
Epoch [270/300], Train Loss: 0.001633
Validation Loss: 0.00184819
Epoch [271/300], Train Loss: 0.001787
Validation Loss: 0.00184970
Epoch [272/300], Train Loss: 0.001714
Validation Loss: 0.00184585
Epoch [273/300], Train Loss: 0.001641
Validation Loss: 0.00184615
Epoch [274/300], Train Loss: 0.001754
Validation Loss: 0.00184588
Epoch [275/300], Train Loss: 0.001708
Validation Loss: 0.00184344
Epoch [276/300], Train Loss: 0.001768
Validation Loss: 0.00184965
Epoch [277/300], Train Loss: 0.001770
Validation Loss: 0.00184874
Epoch [278/300], Train Loss: 0.001696
Validation Loss: 0.00185097
Epoch [279/300], Train Loss: 0.001671
Validation Loss: 0.00185089
Epoch [280/300], Train Loss: 0.001665
Validation Loss: 0.00185047
Epoch [281/300], Train Loss: 0.001727
Validation Loss: 0.00184835
Epoch [282/300], Train Loss: 0.001622
Validation Loss: 0.00184546
Epoch [283/300], Train Loss: 0.001703
Validation Loss: 0.00184485
Epoch [284/300], Train Loss: 0.001610
Validation Loss: 0.00184607
Epoch [285/300], Train Loss: 0.001666
Validation Loss: 0.00185062
Early stopping triggered

Evaluating model for: Freezer
Run 22/72 completed in 381.87 seconds with: {'MAE': np.float32(31.733559), 'MSE': np.float32(2180.658), 'RMSE': np.float32(46.697517), 'SAE': np.float32(0.0037924722), 'NDE': np.float32(0.36708117)}

Run 23/72: hidden=128, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Freezer
Dataset length: 1146 windows

Epoch [1/300], Train Loss: 0.012758
Validation Loss: 0.01170692
Epoch [2/300], Train Loss: 0.010446
Validation Loss: 0.00953928
Epoch [3/300], Train Loss: 0.008784
Validation Loss: 0.00768075
Epoch [4/300], Train Loss: 0.007138
Validation Loss: 0.00631274
Epoch [5/300], Train Loss: 0.006051
Validation Loss: 0.00589344
Epoch [6/300], Train Loss: 0.006071
Validation Loss: 0.00593550
Epoch [7/300], Train Loss: 0.005914
Validation Loss: 0.00588164
Epoch [8/300], Train Loss: 0.005857
Validation Loss: 0.00593188
Epoch [9/300], Train Loss: 0.006049
Validation Loss: 0.00594115
Epoch [10/300], Train Loss: 0.005951
Validation Loss: 0.00588818
Epoch [11/300], Train Loss: 0.005921
Validation Loss: 0.00587122
Epoch [12/300], Train Loss: 0.005796
Validation Loss: 0.00586825
Epoch [13/300], Train Loss: 0.006064
Validation Loss: 0.00591042
Epoch [14/300], Train Loss: 0.005874
Validation Loss: 0.00587231
Epoch [15/300], Train Loss: 0.005895
Validation Loss: 0.00586563
Epoch [16/300], Train Loss: 0.005890
Validation Loss: 0.00585603
Epoch [17/300], Train Loss: 0.005876
Validation Loss: 0.00584117
Epoch [18/300], Train Loss: 0.005876
Validation Loss: 0.00583296
Epoch [19/300], Train Loss: 0.005834
Validation Loss: 0.00581592
Epoch [20/300], Train Loss: 0.005856
Validation Loss: 0.00579616
Epoch [21/300], Train Loss: 0.005688
Validation Loss: 0.00576484
Epoch [22/300], Train Loss: 0.005745
Validation Loss: 0.00576086
Epoch [23/300], Train Loss: 0.005755
Validation Loss: 0.00567136
Epoch [24/300], Train Loss: 0.005602
Validation Loss: 0.00559226
Epoch [25/300], Train Loss: 0.005675
Validation Loss: 0.00565047
Epoch [26/300], Train Loss: 0.005487
Validation Loss: 0.00553828
Epoch [27/300], Train Loss: 0.005579
Validation Loss: 0.00550786
Epoch [28/300], Train Loss: 0.005599
Validation Loss: 0.00540976
Epoch [29/300], Train Loss: 0.005437
Validation Loss: 0.00533342
Epoch [30/300], Train Loss: 0.005327
Validation Loss: 0.00522096
Epoch [31/300], Train Loss: 0.005225
Validation Loss: 0.00490529
Epoch [32/300], Train Loss: 0.004803
Validation Loss: 0.00431253
Epoch [33/300], Train Loss: 0.003877
Validation Loss: 0.00365376
Epoch [34/300], Train Loss: 0.003649
Validation Loss: 0.00355905
Epoch [35/300], Train Loss: 0.003422
Validation Loss: 0.00344542
Epoch [36/300], Train Loss: 0.003340
Validation Loss: 0.00345501
Epoch [37/300], Train Loss: 0.003398
Validation Loss: 0.00331659
Epoch [38/300], Train Loss: 0.003311
Validation Loss: 0.00319764
Epoch [39/300], Train Loss: 0.003234
Validation Loss: 0.00312774
Epoch [40/300], Train Loss: 0.003060
Validation Loss: 0.00311192
Epoch [41/300], Train Loss: 0.003188
Validation Loss: 0.00309832
Epoch [42/300], Train Loss: 0.003053
Validation Loss: 0.00303684
Epoch [43/300], Train Loss: 0.003158
Validation Loss: 0.00298875
Epoch [44/300], Train Loss: 0.002981
Validation Loss: 0.00302353
Epoch [45/300], Train Loss: 0.003092
Validation Loss: 0.00294655
Epoch [46/300], Train Loss: 0.003024
Validation Loss: 0.00292451
Epoch [47/300], Train Loss: 0.002940
Validation Loss: 0.00291053
Epoch [48/300], Train Loss: 0.003023
Validation Loss: 0.00288172
Epoch [49/300], Train Loss: 0.002880
Validation Loss: 0.00288014
Epoch [50/300], Train Loss: 0.003016
Validation Loss: 0.00287830
Epoch [51/300], Train Loss: 0.002996
Validation Loss: 0.00287120
Epoch [52/300], Train Loss: 0.002860
Validation Loss: 0.00282745
Epoch [53/300], Train Loss: 0.002904
Validation Loss: 0.00281520
Epoch [54/300], Train Loss: 0.002852
Validation Loss: 0.00280038
Epoch [55/300], Train Loss: 0.002920
Validation Loss: 0.00278595
Epoch [56/300], Train Loss: 0.002835
Validation Loss: 0.00277916
Epoch [57/300], Train Loss: 0.002859
Validation Loss: 0.00275932
Epoch [58/300], Train Loss: 0.002795
Validation Loss: 0.00274638
Epoch [59/300], Train Loss: 0.002899
Validation Loss: 0.00274039
Epoch [60/300], Train Loss: 0.002830
Validation Loss: 0.00271937
Epoch [61/300], Train Loss: 0.002783
Validation Loss: 0.00270536
Epoch [62/300], Train Loss: 0.002767
Validation Loss: 0.00268476
Epoch [63/300], Train Loss: 0.002702
Validation Loss: 0.00266307
Epoch [64/300], Train Loss: 0.002727
Validation Loss: 0.00265130
Epoch [65/300], Train Loss: 0.002631
Validation Loss: 0.00263477
Epoch [66/300], Train Loss: 0.002626
Validation Loss: 0.00259763
Epoch [67/300], Train Loss: 0.002556
Validation Loss: 0.00256072
Epoch [68/300], Train Loss: 0.002587
Validation Loss: 0.00252187
Epoch [69/300], Train Loss: 0.002442
Validation Loss: 0.00248242
Epoch [70/300], Train Loss: 0.002579
Validation Loss: 0.00250815
Epoch [71/300], Train Loss: 0.002667
Validation Loss: 0.00249111
Epoch [72/300], Train Loss: 0.002345
Validation Loss: 0.00243372
Epoch [73/300], Train Loss: 0.002437
Validation Loss: 0.00237063
Epoch [74/300], Train Loss: 0.002337
Validation Loss: 0.00228417
Epoch [75/300], Train Loss: 0.002354
Validation Loss: 0.00225135
Epoch [76/300], Train Loss: 0.002172
Validation Loss: 0.00222721
Epoch [77/300], Train Loss: 0.002324
Validation Loss: 0.00220662
Epoch [78/300], Train Loss: 0.002165
Validation Loss: 0.00218872
Epoch [79/300], Train Loss: 0.002160
Validation Loss: 0.00217713
Epoch [80/300], Train Loss: 0.002177
Validation Loss: 0.00216126
Epoch [81/300], Train Loss: 0.002105
Validation Loss: 0.00216813
Epoch [82/300], Train Loss: 0.002072
Validation Loss: 0.00212857
Epoch [83/300], Train Loss: 0.001926
Validation Loss: 0.00213458
Epoch [84/300], Train Loss: 0.001968
Validation Loss: 0.00211362
Epoch [85/300], Train Loss: 0.001988
Validation Loss: 0.00209834
Epoch [86/300], Train Loss: 0.002056
Validation Loss: 0.00214387
Epoch [87/300], Train Loss: 0.002023
Validation Loss: 0.00212246
Epoch [88/300], Train Loss: 0.002018
Validation Loss: 0.00209149
Epoch [89/300], Train Loss: 0.001873
Validation Loss: 0.00208523
Epoch [90/300], Train Loss: 0.001926
Validation Loss: 0.00204606
Epoch [91/300], Train Loss: 0.001976
Validation Loss: 0.00203761
Epoch [92/300], Train Loss: 0.001968
Validation Loss: 0.00202000
Epoch [93/300], Train Loss: 0.001911
Validation Loss: 0.00202296
Epoch [94/300], Train Loss: 0.001905
Validation Loss: 0.00200583
Epoch [95/300], Train Loss: 0.001881
Validation Loss: 0.00200748
Epoch [96/300], Train Loss: 0.001886
Validation Loss: 0.00202891
Epoch [97/300], Train Loss: 0.001885
Validation Loss: 0.00199553
Epoch [98/300], Train Loss: 0.001837
Validation Loss: 0.00200541
Epoch [99/300], Train Loss: 0.001868
Validation Loss: 0.00201491
Epoch [100/300], Train Loss: 0.001831
Validation Loss: 0.00199747
Epoch [101/300], Train Loss: 0.001823
Validation Loss: 0.00198834
Epoch [102/300], Train Loss: 0.001880
Validation Loss: 0.00198736
Epoch [103/300], Train Loss: 0.001819
Validation Loss: 0.00196417
Epoch [104/300], Train Loss: 0.001765
Validation Loss: 0.00197419
Epoch [105/300], Train Loss: 0.001817
Validation Loss: 0.00197192
Epoch [106/300], Train Loss: 0.001824
Validation Loss: 0.00198379
Epoch [107/300], Train Loss: 0.001913
Validation Loss: 0.00199876
Epoch [108/300], Train Loss: 0.001888
Validation Loss: 0.00198226
Epoch [109/300], Train Loss: 0.001850
Validation Loss: 0.00196501
Epoch [110/300], Train Loss: 0.001782
Validation Loss: 0.00196644
Epoch [111/300], Train Loss: 0.001752
Validation Loss: 0.00195256
Epoch [112/300], Train Loss: 0.001732
Validation Loss: 0.00196283
Epoch [113/300], Train Loss: 0.001751
Validation Loss: 0.00194794
Epoch [114/300], Train Loss: 0.001756
Validation Loss: 0.00194697
Epoch [115/300], Train Loss: 0.001699
Validation Loss: 0.00195100
Epoch [116/300], Train Loss: 0.001751
Validation Loss: 0.00194856
Epoch [117/300], Train Loss: 0.001760
Validation Loss: 0.00194591
Epoch [118/300], Train Loss: 0.001716
Validation Loss: 0.00194229
Epoch [119/300], Train Loss: 0.001727
Validation Loss: 0.00195250
Epoch [120/300], Train Loss: 0.001803
Validation Loss: 0.00194736
Epoch [121/300], Train Loss: 0.001758
Validation Loss: 0.00193812
Epoch [122/300], Train Loss: 0.001829
Validation Loss: 0.00193633
Epoch [123/300], Train Loss: 0.001750
Validation Loss: 0.00194843
Epoch [124/300], Train Loss: 0.001803
Validation Loss: 0.00193684
Epoch [125/300], Train Loss: 0.001713
Validation Loss: 0.00195435
Epoch [126/300], Train Loss: 0.001813
Validation Loss: 0.00196525
Epoch [127/300], Train Loss: 0.001842
Validation Loss: 0.00192932
Epoch [128/300], Train Loss: 0.001686
Validation Loss: 0.00193955
Epoch [129/300], Train Loss: 0.001756
Validation Loss: 0.00197157
Epoch [130/300], Train Loss: 0.001843
Validation Loss: 0.00192592
Epoch [131/300], Train Loss: 0.001730
Validation Loss: 0.00194684
Epoch [132/300], Train Loss: 0.001799
Validation Loss: 0.00194651
Epoch [133/300], Train Loss: 0.001721
Validation Loss: 0.00192228
Epoch [134/300], Train Loss: 0.001757
Validation Loss: 0.00193124
Epoch [135/300], Train Loss: 0.001761
Validation Loss: 0.00192388
Epoch [136/300], Train Loss: 0.001720
Validation Loss: 0.00192385
Epoch [137/300], Train Loss: 0.001730
Validation Loss: 0.00193194
Epoch [138/300], Train Loss: 0.001722
Validation Loss: 0.00192494
Epoch [139/300], Train Loss: 0.001767
Validation Loss: 0.00193360
Epoch [140/300], Train Loss: 0.001756
Validation Loss: 0.00191733
Epoch [141/300], Train Loss: 0.001712
Validation Loss: 0.00191654
Epoch [142/300], Train Loss: 0.001789
Validation Loss: 0.00191898
Epoch [143/300], Train Loss: 0.001754
Validation Loss: 0.00191509
Epoch [144/300], Train Loss: 0.001715
Validation Loss: 0.00191473
Epoch [145/300], Train Loss: 0.001726
Validation Loss: 0.00193369
Epoch [146/300], Train Loss: 0.001729
Validation Loss: 0.00192017
Epoch [147/300], Train Loss: 0.001845
Validation Loss: 0.00191925
Epoch [148/300], Train Loss: 0.001747
Validation Loss: 0.00191411
Epoch [149/300], Train Loss: 0.001765
Validation Loss: 0.00191140
Epoch [150/300], Train Loss: 0.001668
Validation Loss: 0.00191274
Epoch [151/300], Train Loss: 0.001682
Validation Loss: 0.00191272
Epoch [152/300], Train Loss: 0.001738
Validation Loss: 0.00191346
Epoch [153/300], Train Loss: 0.001691
Validation Loss: 0.00190716
Epoch [154/300], Train Loss: 0.001750
Validation Loss: 0.00191545
Epoch [155/300], Train Loss: 0.001803
Validation Loss: 0.00191044
Epoch [156/300], Train Loss: 0.001713
Validation Loss: 0.00190832
Epoch [157/300], Train Loss: 0.001768
Validation Loss: 0.00191092
Epoch [158/300], Train Loss: 0.001818
Validation Loss: 0.00190527
Epoch [159/300], Train Loss: 0.001748
Validation Loss: 0.00190853
Epoch [160/300], Train Loss: 0.001683
Validation Loss: 0.00190745
Epoch [161/300], Train Loss: 0.001844
Validation Loss: 0.00191276
Epoch [162/300], Train Loss: 0.001783
Validation Loss: 0.00190278
Epoch [163/300], Train Loss: 0.001724
Validation Loss: 0.00191108
Epoch [164/300], Train Loss: 0.001681
Validation Loss: 0.00190276
Epoch [165/300], Train Loss: 0.001715
Validation Loss: 0.00190148
Epoch [166/300], Train Loss: 0.001754
Validation Loss: 0.00190542
Epoch [167/300], Train Loss: 0.001738
Validation Loss: 0.00190467
Epoch [168/300], Train Loss: 0.001741
Validation Loss: 0.00190503
Epoch [169/300], Train Loss: 0.001744
Validation Loss: 0.00190107
Epoch [170/300], Train Loss: 0.001707
Validation Loss: 0.00190460
Epoch [171/300], Train Loss: 0.001674
Validation Loss: 0.00190809
Epoch [172/300], Train Loss: 0.001646
Validation Loss: 0.00189861
Epoch [173/300], Train Loss: 0.001752
Validation Loss: 0.00191345
Epoch [174/300], Train Loss: 0.001705
Validation Loss: 0.00190122
Epoch [175/300], Train Loss: 0.001641
Validation Loss: 0.00190809
Epoch [176/300], Train Loss: 0.001727
Validation Loss: 0.00189939
Epoch [177/300], Train Loss: 0.001640
Validation Loss: 0.00190018
Epoch [178/300], Train Loss: 0.001656
Validation Loss: 0.00190116
Epoch [179/300], Train Loss: 0.001653
Validation Loss: 0.00190240
Epoch [180/300], Train Loss: 0.001769
Validation Loss: 0.00189737
Epoch [181/300], Train Loss: 0.001743
Validation Loss: 0.00189853
Epoch [182/300], Train Loss: 0.001692
Validation Loss: 0.00189478
Epoch [183/300], Train Loss: 0.001749
Validation Loss: 0.00192137
Epoch [184/300], Train Loss: 0.001707
Validation Loss: 0.00190835
Epoch [185/300], Train Loss: 0.001751
Validation Loss: 0.00191027
Epoch [186/300], Train Loss: 0.001773
Validation Loss: 0.00190398
Epoch [187/300], Train Loss: 0.001779
Validation Loss: 0.00189435
Epoch [188/300], Train Loss: 0.001761
Validation Loss: 0.00189138
Epoch [189/300], Train Loss: 0.001681
Validation Loss: 0.00189224
Epoch [190/300], Train Loss: 0.001709
Validation Loss: 0.00190031
Epoch [191/300], Train Loss: 0.001683
Validation Loss: 0.00189619
Epoch [192/300], Train Loss: 0.001740
Validation Loss: 0.00189245
Epoch [193/300], Train Loss: 0.001794
Validation Loss: 0.00189419
Epoch [194/300], Train Loss: 0.001705
Validation Loss: 0.00189105
Epoch [195/300], Train Loss: 0.001677
Validation Loss: 0.00188175
Epoch [196/300], Train Loss: 0.001809
Validation Loss: 0.00189009
Epoch [197/300], Train Loss: 0.001746
Validation Loss: 0.00188394
Epoch [198/300], Train Loss: 0.001646
Validation Loss: 0.00189099
Epoch [199/300], Train Loss: 0.001586
Validation Loss: 0.00189189
Epoch [200/300], Train Loss: 0.001760
Validation Loss: 0.00188200
Epoch [201/300], Train Loss: 0.001870
Validation Loss: 0.00191365
Epoch [202/300], Train Loss: 0.001802
Validation Loss: 0.00190230
Epoch [203/300], Train Loss: 0.001671
Validation Loss: 0.00193669
Epoch [204/300], Train Loss: 0.001787
Validation Loss: 0.00190466
Epoch [205/300], Train Loss: 0.001657
Validation Loss: 0.00190135
Early stopping triggered

Evaluating model for: Freezer
Run 23/72 completed in 284.78 seconds with: {'MAE': np.float32(32.631786), 'MSE': np.float32(2313.9797), 'RMSE': np.float32(48.103844), 'SAE': np.float32(0.033078864), 'NDE': np.float32(0.378136)}

Run 24/72: hidden=128, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Freezer
Dataset length: 1146 windows

Epoch [1/300], Train Loss: 0.006051
Validation Loss: 0.00588031
Epoch [2/300], Train Loss: 0.005944
Validation Loss: 0.00587425
Epoch [3/300], Train Loss: 0.006045
Validation Loss: 0.00587613
Epoch [4/300], Train Loss: 0.006111
Validation Loss: 0.00588220
Epoch [5/300], Train Loss: 0.005909
Validation Loss: 0.00587347
Epoch [6/300], Train Loss: 0.005964
Validation Loss: 0.00587822
Epoch [7/300], Train Loss: 0.005805
Validation Loss: 0.00588054
Epoch [8/300], Train Loss: 0.005832
Validation Loss: 0.00588884
Epoch [9/300], Train Loss: 0.005985
Validation Loss: 0.00589962
Epoch [10/300], Train Loss: 0.005915
Validation Loss: 0.00587760
Epoch [11/300], Train Loss: 0.005890
Validation Loss: 0.00587322
Epoch [12/300], Train Loss: 0.005762
Validation Loss: 0.00587312
Epoch [13/300], Train Loss: 0.006042
Validation Loss: 0.00591497
Epoch [14/300], Train Loss: 0.005857
Validation Loss: 0.00587191
Epoch [15/300], Train Loss: 0.005878
Validation Loss: 0.00587079
Epoch [16/300], Train Loss: 0.005871
Validation Loss: 0.00586593
Epoch [17/300], Train Loss: 0.005850
Validation Loss: 0.00584666
Epoch [18/300], Train Loss: 0.005840
Validation Loss: 0.00581836
Epoch [19/300], Train Loss: 0.005752
Validation Loss: 0.00572292
Epoch [20/300], Train Loss: 0.005604
Validation Loss: 0.00545957
Epoch [21/300], Train Loss: 0.004980
Validation Loss: 0.00465012
Epoch [22/300], Train Loss: 0.004026
Validation Loss: 0.00353994
Epoch [23/300], Train Loss: 0.003545
Validation Loss: 0.00348519
Epoch [24/300], Train Loss: 0.003247
Validation Loss: 0.00335868
Epoch [25/300], Train Loss: 0.003243
Validation Loss: 0.00310735
Epoch [26/300], Train Loss: 0.002963
Validation Loss: 0.00299914
Epoch [27/300], Train Loss: 0.002952
Validation Loss: 0.00291289
Epoch [28/300], Train Loss: 0.002914
Validation Loss: 0.00284330
Epoch [29/300], Train Loss: 0.002806
Validation Loss: 0.00279288
Epoch [30/300], Train Loss: 0.002744
Validation Loss: 0.00278582
Epoch [31/300], Train Loss: 0.002769
Validation Loss: 0.00270262
Epoch [32/300], Train Loss: 0.002673
Validation Loss: 0.00267369
Epoch [33/300], Train Loss: 0.002690
Validation Loss: 0.00267698
Epoch [34/300], Train Loss: 0.002695
Validation Loss: 0.00261925
Epoch [35/300], Train Loss: 0.002630
Validation Loss: 0.00266920
Epoch [36/300], Train Loss: 0.002560
Validation Loss: 0.00263658
Epoch [37/300], Train Loss: 0.002695
Validation Loss: 0.00257917
Epoch [38/300], Train Loss: 0.002657
Validation Loss: 0.00255344
Epoch [39/300], Train Loss: 0.002602
Validation Loss: 0.00251037
Epoch [40/300], Train Loss: 0.002488
Validation Loss: 0.00252345
Epoch [41/300], Train Loss: 0.002592
Validation Loss: 0.00254251
Epoch [42/300], Train Loss: 0.002463
Validation Loss: 0.00249549
Epoch [43/300], Train Loss: 0.002585
Validation Loss: 0.00250933
Epoch [44/300], Train Loss: 0.002506
Validation Loss: 0.00251269
Epoch [45/300], Train Loss: 0.002581
Validation Loss: 0.00242685
Epoch [46/300], Train Loss: 0.002487
Validation Loss: 0.00240366
Epoch [47/300], Train Loss: 0.002448
Validation Loss: 0.00240149
Epoch [48/300], Train Loss: 0.002448
Validation Loss: 0.00239602
Epoch [49/300], Train Loss: 0.002377
Validation Loss: 0.00237388
Epoch [50/300], Train Loss: 0.002428
Validation Loss: 0.00240992
Epoch [51/300], Train Loss: 0.002469
Validation Loss: 0.00235335
Epoch [52/300], Train Loss: 0.002353
Validation Loss: 0.00235259
Epoch [53/300], Train Loss: 0.002402
Validation Loss: 0.00233666
Epoch [54/300], Train Loss: 0.002332
Validation Loss: 0.00232346
Epoch [55/300], Train Loss: 0.002275
Validation Loss: 0.00232314
Epoch [56/300], Train Loss: 0.002343
Validation Loss: 0.00230955
Epoch [57/300], Train Loss: 0.002297
Validation Loss: 0.00230163
Epoch [58/300], Train Loss: 0.002352
Validation Loss: 0.00230651
Epoch [59/300], Train Loss: 0.002301
Validation Loss: 0.00229285
Epoch [60/300], Train Loss: 0.002289
Validation Loss: 0.00227743
Epoch [61/300], Train Loss: 0.002309
Validation Loss: 0.00230094
Epoch [62/300], Train Loss: 0.002259
Validation Loss: 0.00228691
Epoch [63/300], Train Loss: 0.002296
Validation Loss: 0.00226270
Epoch [64/300], Train Loss: 0.002245
Validation Loss: 0.00226511
Epoch [65/300], Train Loss: 0.002251
Validation Loss: 0.00227313
Epoch [66/300], Train Loss: 0.002265
Validation Loss: 0.00227225
Epoch [67/300], Train Loss: 0.002205
Validation Loss: 0.00224622
Epoch [68/300], Train Loss: 0.002261
Validation Loss: 0.00223423
Epoch [69/300], Train Loss: 0.002167
Validation Loss: 0.00222545
Epoch [70/300], Train Loss: 0.002315
Validation Loss: 0.00227290
Epoch [71/300], Train Loss: 0.002406
Validation Loss: 0.00228106
Epoch [72/300], Train Loss: 0.002150
Validation Loss: 0.00228317
Epoch [73/300], Train Loss: 0.002295
Validation Loss: 0.00224422
Epoch [74/300], Train Loss: 0.002208
Validation Loss: 0.00220661
Epoch [75/300], Train Loss: 0.002282
Validation Loss: 0.00219997
Epoch [76/300], Train Loss: 0.002112
Validation Loss: 0.00220062
Epoch [77/300], Train Loss: 0.002308
Validation Loss: 0.00219614
Epoch [78/300], Train Loss: 0.002151
Validation Loss: 0.00218688
Epoch [79/300], Train Loss: 0.002186
Validation Loss: 0.00218280
Epoch [80/300], Train Loss: 0.002199
Validation Loss: 0.00217962
Epoch [81/300], Train Loss: 0.002151
Validation Loss: 0.00218480
Epoch [82/300], Train Loss: 0.002130
Validation Loss: 0.00217899
Epoch [83/300], Train Loss: 0.002013
Validation Loss: 0.00217888
Epoch [84/300], Train Loss: 0.002071
Validation Loss: 0.00217493
Epoch [85/300], Train Loss: 0.002104
Validation Loss: 0.00216933
Epoch [86/300], Train Loss: 0.002207
Validation Loss: 0.00219408
Epoch [87/300], Train Loss: 0.002173
Validation Loss: 0.00221305
Epoch [88/300], Train Loss: 0.002145
Validation Loss: 0.00217441
Epoch [89/300], Train Loss: 0.002043
Validation Loss: 0.00218523
Epoch [90/300], Train Loss: 0.002125
Validation Loss: 0.00215727
Epoch [91/300], Train Loss: 0.002137
Validation Loss: 0.00214912
Epoch [92/300], Train Loss: 0.002134
Validation Loss: 0.00214476
Epoch [93/300], Train Loss: 0.002129
Validation Loss: 0.00214354
Epoch [94/300], Train Loss: 0.002149
Validation Loss: 0.00214536
Epoch [95/300], Train Loss: 0.002142
Validation Loss: 0.00215075
Epoch [96/300], Train Loss: 0.002126
Validation Loss: 0.00213184
Epoch [97/300], Train Loss: 0.002121
Validation Loss: 0.00213791
Epoch [98/300], Train Loss: 0.002094
Validation Loss: 0.00214629
Epoch [99/300], Train Loss: 0.002094
Validation Loss: 0.00213230
Epoch [100/300], Train Loss: 0.002097
Validation Loss: 0.00211902
Epoch [101/300], Train Loss: 0.002049
Validation Loss: 0.00211993
Epoch [102/300], Train Loss: 0.002103
Validation Loss: 0.00210850
Epoch [103/300], Train Loss: 0.002067
Validation Loss: 0.00210078
Epoch [104/300], Train Loss: 0.001978
Validation Loss: 0.00208837
Epoch [105/300], Train Loss: 0.002032
Validation Loss: 0.00208531
Epoch [106/300], Train Loss: 0.002041
Validation Loss: 0.00209628
Epoch [107/300], Train Loss: 0.002127
Validation Loss: 0.00209047
Epoch [108/300], Train Loss: 0.002084
Validation Loss: 0.00210448
Epoch [109/300], Train Loss: 0.002048
Validation Loss: 0.00210882
Epoch [110/300], Train Loss: 0.002015
Validation Loss: 0.00206335
Epoch [111/300], Train Loss: 0.001926
Validation Loss: 0.00206196
Epoch [112/300], Train Loss: 0.001921
Validation Loss: 0.00205833
Epoch [113/300], Train Loss: 0.001935
Validation Loss: 0.00218195
Epoch [114/300], Train Loss: 0.002024
Validation Loss: 0.00215954
Epoch [115/300], Train Loss: 0.001944
Validation Loss: 0.00213661
Epoch [116/300], Train Loss: 0.002003
Validation Loss: 0.00211008
Epoch [117/300], Train Loss: 0.001985
Validation Loss: 0.00208083
Epoch [118/300], Train Loss: 0.001942
Validation Loss: 0.00209106
Epoch [119/300], Train Loss: 0.001926
Validation Loss: 0.00208068
Epoch [120/300], Train Loss: 0.001993
Validation Loss: 0.00209324
Epoch [121/300], Train Loss: 0.001935
Validation Loss: 0.00206253
Epoch [122/300], Train Loss: 0.002018
Validation Loss: 0.00208879
Early stopping triggered

Evaluating model for: Freezer
Run 24/72 completed in 181.57 seconds with: {'MAE': np.float32(37.129307), 'MSE': np.float32(2973.5938), 'RMSE': np.float32(54.530666), 'SAE': np.float32(0.07023487), 'NDE': np.float32(0.4286562)}

Run 25/72: hidden=256, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Freezer
Dataset length: 14022 windows

Epoch [1/300], Train Loss: 0.007411
Validation Loss: 0.00549593
Epoch [2/300], Train Loss: 0.004872
Validation Loss: 0.00410486
Epoch [3/300], Train Loss: 0.003254
Validation Loss: 0.00266002
Epoch [4/300], Train Loss: 0.002431
Validation Loss: 0.00229089
Epoch [5/300], Train Loss: 0.002204
Validation Loss: 0.00209228
Epoch [6/300], Train Loss: 0.002039
Validation Loss: 0.00198089
Epoch [7/300], Train Loss: 0.001965
Validation Loss: 0.00196617
Epoch [8/300], Train Loss: 0.001912
Validation Loss: 0.00190305
Epoch [9/300], Train Loss: 0.001885
Validation Loss: 0.00187837
Epoch [10/300], Train Loss: 0.001862
Validation Loss: 0.00185672
Epoch [11/300], Train Loss: 0.001831
Validation Loss: 0.00182963
Epoch [12/300], Train Loss: 0.001821
Validation Loss: 0.00185766
Epoch [13/300], Train Loss: 0.001791
Validation Loss: 0.00178586
Epoch [14/300], Train Loss: 0.001770
Validation Loss: 0.00177588
Epoch [15/300], Train Loss: 0.001757
Validation Loss: 0.00175960
Epoch [16/300], Train Loss: 0.001736
Validation Loss: 0.00175517
Epoch [17/300], Train Loss: 0.001719
Validation Loss: 0.00173550
Epoch [18/300], Train Loss: 0.001698
Validation Loss: 0.00174640
Epoch [19/300], Train Loss: 0.001693
Validation Loss: 0.00169845
Epoch [20/300], Train Loss: 0.001675
Validation Loss: 0.00169856
Epoch [21/300], Train Loss: 0.001676
Validation Loss: 0.00167796
Epoch [22/300], Train Loss: 0.001657
Validation Loss: 0.00169442
Epoch [23/300], Train Loss: 0.001638
Validation Loss: 0.00166658
Epoch [24/300], Train Loss: 0.001640
Validation Loss: 0.00164151
Epoch [25/300], Train Loss: 0.001616
Validation Loss: 0.00163615
Epoch [26/300], Train Loss: 0.001608
Validation Loss: 0.00164582
Epoch [27/300], Train Loss: 0.001612
Validation Loss: 0.00162680
Epoch [28/300], Train Loss: 0.001593
Validation Loss: 0.00168236
Epoch [29/300], Train Loss: 0.001594
Validation Loss: 0.00158514
Epoch [30/300], Train Loss: 0.001582
Validation Loss: 0.00157635
Epoch [31/300], Train Loss: 0.001568
Validation Loss: 0.00157970
Epoch [32/300], Train Loss: 0.001571
Validation Loss: 0.00158985
Epoch [33/300], Train Loss: 0.001563
Validation Loss: 0.00156212
Epoch [34/300], Train Loss: 0.001559
Validation Loss: 0.00155659
Epoch [35/300], Train Loss: 0.001541
Validation Loss: 0.00154665
Epoch [36/300], Train Loss: 0.001551
Validation Loss: 0.00157647
Epoch [37/300], Train Loss: 0.001550
Validation Loss: 0.00154677
Epoch [38/300], Train Loss: 0.001541
Validation Loss: 0.00153553
Epoch [39/300], Train Loss: 0.001543
Validation Loss: 0.00154005
Epoch [40/300], Train Loss: 0.001517
Validation Loss: 0.00153016
Epoch [41/300], Train Loss: 0.001520
Validation Loss: 0.00151668
Epoch [42/300], Train Loss: 0.001510
Validation Loss: 0.00150570
Epoch [43/300], Train Loss: 0.001519
Validation Loss: 0.00152436
Epoch [44/300], Train Loss: 0.001507
Validation Loss: 0.00149203
Epoch [45/300], Train Loss: 0.001497
Validation Loss: 0.00149662
Epoch [46/300], Train Loss: 0.001488
Validation Loss: 0.00148835
Epoch [47/300], Train Loss: 0.001489
Validation Loss: 0.00154275
Epoch [48/300], Train Loss: 0.001487
Validation Loss: 0.00147442
Epoch [49/300], Train Loss: 0.001481
Validation Loss: 0.00147765
Epoch [50/300], Train Loss: 0.001472
Validation Loss: 0.00146293
Epoch [51/300], Train Loss: 0.001467
Validation Loss: 0.00149011
Epoch [52/300], Train Loss: 0.001462
Validation Loss: 0.00147743
Epoch [53/300], Train Loss: 0.001457
Validation Loss: 0.00149102
Epoch [54/300], Train Loss: 0.001459
Validation Loss: 0.00143952
Epoch [55/300], Train Loss: 0.001454
Validation Loss: 0.00145735
Epoch [56/300], Train Loss: 0.001448
Validation Loss: 0.00145365
Epoch [57/300], Train Loss: 0.001433
Validation Loss: 0.00142776
Epoch [58/300], Train Loss: 0.001446
Validation Loss: 0.00144872
Epoch [59/300], Train Loss: 0.001435
Validation Loss: 0.00142336
Epoch [60/300], Train Loss: 0.001417
Validation Loss: 0.00141125
Epoch [61/300], Train Loss: 0.001422
Validation Loss: 0.00141675
Epoch [62/300], Train Loss: 0.001405
Validation Loss: 0.00141729
Epoch [63/300], Train Loss: 0.001408
Validation Loss: 0.00139326
Epoch [64/300], Train Loss: 0.001397
Validation Loss: 0.00138780
Epoch [65/300], Train Loss: 0.001385
Validation Loss: 0.00138005
Epoch [66/300], Train Loss: 0.001376
Validation Loss: 0.00136469
Epoch [67/300], Train Loss: 0.001361
Validation Loss: 0.00140346
Epoch [68/300], Train Loss: 0.001352
Validation Loss: 0.00132506
Epoch [69/300], Train Loss: 0.001326
Validation Loss: 0.00131487
Epoch [70/300], Train Loss: 0.001300
Validation Loss: 0.00128200
Epoch [71/300], Train Loss: 0.001266
Validation Loss: 0.00122788
Epoch [72/300], Train Loss: 0.001215
Validation Loss: 0.00118129
Epoch [73/300], Train Loss: 0.001139
Validation Loss: 0.00110735
Epoch [74/300], Train Loss: 0.001067
Validation Loss: 0.00103645
Epoch [75/300], Train Loss: 0.000988
Validation Loss: 0.00094412
Epoch [76/300], Train Loss: 0.000963
Validation Loss: 0.00091592
Epoch [77/300], Train Loss: 0.000923
Validation Loss: 0.00088380
Epoch [78/300], Train Loss: 0.000907
Validation Loss: 0.00087117
Epoch [79/300], Train Loss: 0.000893
Validation Loss: 0.00085853
Epoch [80/300], Train Loss: 0.000880
Validation Loss: 0.00084561
Epoch [81/300], Train Loss: 0.000873
Validation Loss: 0.00083878
Epoch [82/300], Train Loss: 0.000867
Validation Loss: 0.00082884
Epoch [83/300], Train Loss: 0.000856
Validation Loss: 0.00085731
Epoch [84/300], Train Loss: 0.000859
Validation Loss: 0.00087933
Epoch [85/300], Train Loss: 0.000852
Validation Loss: 0.00081822
Epoch [86/300], Train Loss: 0.000848
Validation Loss: 0.00082391
Epoch [87/300], Train Loss: 0.000832
Validation Loss: 0.00080356
Epoch [88/300], Train Loss: 0.000831
Validation Loss: 0.00081492
Epoch [89/300], Train Loss: 0.000822
Validation Loss: 0.00079790
Epoch [90/300], Train Loss: 0.000815
Validation Loss: 0.00079471
Epoch [91/300], Train Loss: 0.000815
Validation Loss: 0.00077646
Epoch [92/300], Train Loss: 0.000802
Validation Loss: 0.00077026
Epoch [93/300], Train Loss: 0.000795
Validation Loss: 0.00078232
Epoch [94/300], Train Loss: 0.000801
Validation Loss: 0.00082447
Epoch [95/300], Train Loss: 0.000795
Validation Loss: 0.00076661
Epoch [96/300], Train Loss: 0.000790
Validation Loss: 0.00078473
Epoch [97/300], Train Loss: 0.000792
Validation Loss: 0.00076082
Epoch [98/300], Train Loss: 0.000778
Validation Loss: 0.00075690
Epoch [99/300], Train Loss: 0.000785
Validation Loss: 0.00075871
Epoch [100/300], Train Loss: 0.000772
Validation Loss: 0.00075942
Epoch [101/300], Train Loss: 0.000778
Validation Loss: 0.00074485
Epoch [102/300], Train Loss: 0.000774
Validation Loss: 0.00075624
Epoch [103/300], Train Loss: 0.000764
Validation Loss: 0.00073837
Epoch [104/300], Train Loss: 0.000763
Validation Loss: 0.00076329
Epoch [105/300], Train Loss: 0.000764
Validation Loss: 0.00074385
Epoch [106/300], Train Loss: 0.000762
Validation Loss: 0.00076158
Epoch [107/300], Train Loss: 0.000749
Validation Loss: 0.00073046
Epoch [108/300], Train Loss: 0.000757
Validation Loss: 0.00074500
Epoch [109/300], Train Loss: 0.000745
Validation Loss: 0.00072721
Epoch [110/300], Train Loss: 0.000746
Validation Loss: 0.00073990
Epoch [111/300], Train Loss: 0.000743
Validation Loss: 0.00073957
Epoch [112/300], Train Loss: 0.000743
Validation Loss: 0.00072385
Epoch [113/300], Train Loss: 0.000741
Validation Loss: 0.00071964
Epoch [114/300], Train Loss: 0.000734
Validation Loss: 0.00071073
Epoch [115/300], Train Loss: 0.000736
Validation Loss: 0.00070487
Epoch [116/300], Train Loss: 0.000731
Validation Loss: 0.00071065
Epoch [117/300], Train Loss: 0.000735
Validation Loss: 0.00076028
Epoch [118/300], Train Loss: 0.000730
Validation Loss: 0.00069564
Epoch [119/300], Train Loss: 0.000725
Validation Loss: 0.00069433
Epoch [120/300], Train Loss: 0.000722
Validation Loss: 0.00070981
Epoch [121/300], Train Loss: 0.000722
Validation Loss: 0.00069585
Epoch [122/300], Train Loss: 0.000716
Validation Loss: 0.00068622
Epoch [123/300], Train Loss: 0.000729
Validation Loss: 0.00069124
Epoch [124/300], Train Loss: 0.000723
Validation Loss: 0.00074389
Epoch [125/300], Train Loss: 0.000724
Validation Loss: 0.00068545
Epoch [126/300], Train Loss: 0.000708
Validation Loss: 0.00067506
Epoch [127/300], Train Loss: 0.000702
Validation Loss: 0.00068395
Epoch [128/300], Train Loss: 0.000715
Validation Loss: 0.00069078
Epoch [129/300], Train Loss: 0.000708
Validation Loss: 0.00066976
Epoch [130/300], Train Loss: 0.000704
Validation Loss: 0.00067519
Epoch [131/300], Train Loss: 0.000703
Validation Loss: 0.00068378
Epoch [132/300], Train Loss: 0.000692
Validation Loss: 0.00071838
Epoch [133/300], Train Loss: 0.000694
Validation Loss: 0.00065584
Epoch [134/300], Train Loss: 0.000691
Validation Loss: 0.00067035
Epoch [135/300], Train Loss: 0.000689
Validation Loss: 0.00072665
Epoch [136/300], Train Loss: 0.000692
Validation Loss: 0.00066462
Epoch [137/300], Train Loss: 0.000690
Validation Loss: 0.00064892
Epoch [138/300], Train Loss: 0.000680
Validation Loss: 0.00064121
Epoch [139/300], Train Loss: 0.000687
Validation Loss: 0.00064495
Epoch [140/300], Train Loss: 0.000671
Validation Loss: 0.00064332
Epoch [141/300], Train Loss: 0.000675
Validation Loss: 0.00065261
Epoch [142/300], Train Loss: 0.000672
Validation Loss: 0.00063681
Epoch [143/300], Train Loss: 0.000668
Validation Loss: 0.00065966
Epoch [144/300], Train Loss: 0.000665
Validation Loss: 0.00063183
Epoch [145/300], Train Loss: 0.000670
Validation Loss: 0.00062735
Epoch [146/300], Train Loss: 0.000665
Validation Loss: 0.00062905
Epoch [147/300], Train Loss: 0.000664
Validation Loss: 0.00062639
Epoch [148/300], Train Loss: 0.000656
Validation Loss: 0.00063082
Epoch [149/300], Train Loss: 0.000669
Validation Loss: 0.00062829
Epoch [150/300], Train Loss: 0.000655
Validation Loss: 0.00061497
Epoch [151/300], Train Loss: 0.000653
Validation Loss: 0.00061877
Epoch [152/300], Train Loss: 0.000680
Validation Loss: 0.00064259
Epoch [153/300], Train Loss: 0.000659
Validation Loss: 0.00061892
Epoch [154/300], Train Loss: 0.000663
Validation Loss: 0.00065675
Epoch [155/300], Train Loss: 0.000654
Validation Loss: 0.00062431
Epoch [156/300], Train Loss: 0.000644
Validation Loss: 0.00061585
Epoch [157/300], Train Loss: 0.000651
Validation Loss: 0.00063892
Epoch [158/300], Train Loss: 0.000643
Validation Loss: 0.00061960
Epoch [159/300], Train Loss: 0.000639
Validation Loss: 0.00060490
Epoch [160/300], Train Loss: 0.000646
Validation Loss: 0.00061595
Epoch [161/300], Train Loss: 0.000636
Validation Loss: 0.00060383
Epoch [162/300], Train Loss: 0.000634
Validation Loss: 0.00064081
Epoch [163/300], Train Loss: 0.000641
Validation Loss: 0.00064918
Epoch [164/300], Train Loss: 0.000644
Validation Loss: 0.00066653
Epoch [165/300], Train Loss: 0.000630
Validation Loss: 0.00060365
Epoch [166/300], Train Loss: 0.000626
Validation Loss: 0.00063069
Epoch [167/300], Train Loss: 0.000629
Validation Loss: 0.00059588
Epoch [168/300], Train Loss: 0.000626
Validation Loss: 0.00062463
Epoch [169/300], Train Loss: 0.000628
Validation Loss: 0.00062232
Epoch [170/300], Train Loss: 0.000623
Validation Loss: 0.00061693
Epoch [171/300], Train Loss: 0.000630
Validation Loss: 0.00059113
Epoch [172/300], Train Loss: 0.000620
Validation Loss: 0.00059224
Epoch [173/300], Train Loss: 0.000617
Validation Loss: 0.00058604
Epoch [174/300], Train Loss: 0.000620
Validation Loss: 0.00058937
Epoch [175/300], Train Loss: 0.000621
Validation Loss: 0.00061985
Epoch [176/300], Train Loss: 0.000618
Validation Loss: 0.00066864
Epoch [177/300], Train Loss: 0.000625
Validation Loss: 0.00059378
Epoch [178/300], Train Loss: 0.000612
Validation Loss: 0.00058719
Epoch [179/300], Train Loss: 0.000612
Validation Loss: 0.00057458
Epoch [180/300], Train Loss: 0.000629
Validation Loss: 0.00060816
Epoch [181/300], Train Loss: 0.000611
Validation Loss: 0.00062770
Epoch [182/300], Train Loss: 0.000610
Validation Loss: 0.00058300
Epoch [183/300], Train Loss: 0.000608
Validation Loss: 0.00058650
Epoch [184/300], Train Loss: 0.000604
Validation Loss: 0.00059354
Epoch [185/300], Train Loss: 0.000604
Validation Loss: 0.00059562
Epoch [186/300], Train Loss: 0.000614
Validation Loss: 0.00058125
Epoch [187/300], Train Loss: 0.000596
Validation Loss: 0.00058630
Epoch [188/300], Train Loss: 0.000600
Validation Loss: 0.00058911
Epoch [189/300], Train Loss: 0.000604
Validation Loss: 0.00063243
Early stopping triggered

Evaluating model for: Freezer
Run 25/72 completed in 2729.75 seconds with: {'MAE': np.float32(21.909859), 'MSE': np.float32(988.86304), 'RMSE': np.float32(31.446192), 'SAE': np.float32(0.014678295), 'NDE': np.float32(0.23845711)}

Run 26/72: hidden=256, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Freezer
Dataset length: 14022 windows

Epoch [1/300], Train Loss: 0.005727
Validation Loss: 0.00464198
Epoch [2/300], Train Loss: 0.003703
Validation Loss: 0.00254735
Epoch [3/300], Train Loss: 0.002398
Validation Loss: 0.00224202
Epoch [4/300], Train Loss: 0.002092
Validation Loss: 0.00200340
Epoch [5/300], Train Loss: 0.001957
Validation Loss: 0.00193174
Epoch [6/300], Train Loss: 0.001885
Validation Loss: 0.00187221
Epoch [7/300], Train Loss: 0.001823
Validation Loss: 0.00186897
Epoch [8/300], Train Loss: 0.001783
Validation Loss: 0.00181535
Epoch [9/300], Train Loss: 0.001762
Validation Loss: 0.00178972
Epoch [10/300], Train Loss: 0.001745
Validation Loss: 0.00178122
Epoch [11/300], Train Loss: 0.001721
Validation Loss: 0.00175137
Epoch [12/300], Train Loss: 0.001717
Validation Loss: 0.00177444
Epoch [13/300], Train Loss: 0.001696
Validation Loss: 0.00173539
Epoch [14/300], Train Loss: 0.001685
Validation Loss: 0.00172180
Epoch [15/300], Train Loss: 0.001678
Validation Loss: 0.00171024
Epoch [16/300], Train Loss: 0.001661
Validation Loss: 0.00170773
Epoch [17/300], Train Loss: 0.001646
Validation Loss: 0.00168832
Epoch [18/300], Train Loss: 0.001630
Validation Loss: 0.00168740
Epoch [19/300], Train Loss: 0.001627
Validation Loss: 0.00164599
Epoch [20/300], Train Loss: 0.001604
Validation Loss: 0.00163912
Epoch [21/300], Train Loss: 0.001604
Validation Loss: 0.00162530
Epoch [22/300], Train Loss: 0.001581
Validation Loss: 0.00160854
Epoch [23/300], Train Loss: 0.001573
Validation Loss: 0.00163893
Epoch [24/300], Train Loss: 0.001564
Validation Loss: 0.00159594
Epoch [25/300], Train Loss: 0.001556
Validation Loss: 0.00160605
Epoch [26/300], Train Loss: 0.001547
Validation Loss: 0.00159484
Epoch [27/300], Train Loss: 0.001546
Validation Loss: 0.00157247
Epoch [28/300], Train Loss: 0.001527
Validation Loss: 0.00166262
Epoch [29/300], Train Loss: 0.001527
Validation Loss: 0.00155117
Epoch [30/300], Train Loss: 0.001529
Validation Loss: 0.00153791
Epoch [31/300], Train Loss: 0.001505
Validation Loss: 0.00152289
Epoch [32/300], Train Loss: 0.001524
Validation Loss: 0.00152171
Epoch [33/300], Train Loss: 0.001496
Validation Loss: 0.00151648
Epoch [34/300], Train Loss: 0.001490
Validation Loss: 0.00149157
Epoch [35/300], Train Loss: 0.001480
Validation Loss: 0.00149771
Epoch [36/300], Train Loss: 0.001479
Validation Loss: 0.00150531
Epoch [37/300], Train Loss: 0.001471
Validation Loss: 0.00147787
Epoch [38/300], Train Loss: 0.001474
Validation Loss: 0.00150092
Epoch [39/300], Train Loss: 0.001491
Validation Loss: 0.00148878
Epoch [40/300], Train Loss: 0.001460
Validation Loss: 0.00149180
Epoch [41/300], Train Loss: 0.001460
Validation Loss: 0.00146009
Epoch [42/300], Train Loss: 0.001446
Validation Loss: 0.00146327
Epoch [43/300], Train Loss: 0.001457
Validation Loss: 0.00147389
Epoch [44/300], Train Loss: 0.001436
Validation Loss: 0.00143729
Epoch [45/300], Train Loss: 0.001432
Validation Loss: 0.00143865
Epoch [46/300], Train Loss: 0.001420
Validation Loss: 0.00142594
Epoch [47/300], Train Loss: 0.001416
Validation Loss: 0.00149546
Epoch [48/300], Train Loss: 0.001407
Validation Loss: 0.00140744
Epoch [49/300], Train Loss: 0.001396
Validation Loss: 0.00139839
Epoch [50/300], Train Loss: 0.001383
Validation Loss: 0.00137967
Epoch [51/300], Train Loss: 0.001367
Validation Loss: 0.00141497
Epoch [52/300], Train Loss: 0.001346
Validation Loss: 0.00135608
Epoch [53/300], Train Loss: 0.001334
Validation Loss: 0.00132758
Epoch [54/300], Train Loss: 0.001299
Validation Loss: 0.00127211
Epoch [55/300], Train Loss: 0.001249
Validation Loss: 0.00120872
Epoch [56/300], Train Loss: 0.001174
Validation Loss: 0.00109987
Epoch [57/300], Train Loss: 0.001080
Validation Loss: 0.00100076
Epoch [58/300], Train Loss: 0.001024
Validation Loss: 0.00098948
Epoch [59/300], Train Loss: 0.000977
Validation Loss: 0.00095242
Epoch [60/300], Train Loss: 0.000921
Validation Loss: 0.00088648
Epoch [61/300], Train Loss: 0.000907
Validation Loss: 0.00086259
Epoch [62/300], Train Loss: 0.000882
Validation Loss: 0.00085710
Epoch [63/300], Train Loss: 0.000873
Validation Loss: 0.00083344
Epoch [64/300], Train Loss: 0.000858
Validation Loss: 0.00082709
Epoch [65/300], Train Loss: 0.000836
Validation Loss: 0.00081242
Epoch [66/300], Train Loss: 0.000826
Validation Loss: 0.00079460
Epoch [67/300], Train Loss: 0.000815
Validation Loss: 0.00082970
Epoch [68/300], Train Loss: 0.000804
Validation Loss: 0.00077501
Epoch [69/300], Train Loss: 0.000796
Validation Loss: 0.00076704
Epoch [70/300], Train Loss: 0.000789
Validation Loss: 0.00075881
Epoch [71/300], Train Loss: 0.000794
Validation Loss: 0.00076407
Epoch [72/300], Train Loss: 0.000782
Validation Loss: 0.00076504
Epoch [73/300], Train Loss: 0.000784
Validation Loss: 0.00077358
Epoch [74/300], Train Loss: 0.000778
Validation Loss: 0.00075580
Epoch [75/300], Train Loss: 0.000760
Validation Loss: 0.00075717
Epoch [76/300], Train Loss: 0.000769
Validation Loss: 0.00075004
Epoch [77/300], Train Loss: 0.000756
Validation Loss: 0.00075330
Epoch [78/300], Train Loss: 0.000751
Validation Loss: 0.00073673
Epoch [79/300], Train Loss: 0.000763
Validation Loss: 0.00076684
Epoch [80/300], Train Loss: 0.000750
Validation Loss: 0.00072494
Epoch [81/300], Train Loss: 0.000748
Validation Loss: 0.00074328
Epoch [82/300], Train Loss: 0.000742
Validation Loss: 0.00072013
Epoch [83/300], Train Loss: 0.000768
Validation Loss: 0.00082107
Epoch [84/300], Train Loss: 0.000750
Validation Loss: 0.00073990
Epoch [85/300], Train Loss: 0.000738
Validation Loss: 0.00073014
Epoch [86/300], Train Loss: 0.000743
Validation Loss: 0.00072128
Epoch [87/300], Train Loss: 0.000727
Validation Loss: 0.00070774
Epoch [88/300], Train Loss: 0.000737
Validation Loss: 0.00075186
Epoch [89/300], Train Loss: 0.000729
Validation Loss: 0.00070883
Epoch [90/300], Train Loss: 0.000727
Validation Loss: 0.00074702
Epoch [91/300], Train Loss: 0.000728
Validation Loss: 0.00069640
Epoch [92/300], Train Loss: 0.000717
Validation Loss: 0.00069453
Epoch [93/300], Train Loss: 0.000711
Validation Loss: 0.00071104
Epoch [94/300], Train Loss: 0.000708
Validation Loss: 0.00070826
Epoch [95/300], Train Loss: 0.000765
Validation Loss: 0.00074773
Epoch [96/300], Train Loss: 0.000720
Validation Loss: 0.00071164
Epoch [97/300], Train Loss: 0.000716
Validation Loss: 0.00070708
Epoch [98/300], Train Loss: 0.000709
Validation Loss: 0.00069324
Epoch [99/300], Train Loss: 0.000707
Validation Loss: 0.00071795
Epoch [100/300], Train Loss: 0.000699
Validation Loss: 0.00070427
Epoch [101/300], Train Loss: 0.000704
Validation Loss: 0.00067761
Epoch [102/300], Train Loss: 0.000697
Validation Loss: 0.00067096
Epoch [103/300], Train Loss: 0.000691
Validation Loss: 0.00066383
Epoch [104/300], Train Loss: 0.000690
Validation Loss: 0.00069255
Epoch [105/300], Train Loss: 0.000690
Validation Loss: 0.00069246
Epoch [106/300], Train Loss: 0.000687
Validation Loss: 0.00070283
Epoch [107/300], Train Loss: 0.000685
Validation Loss: 0.00065139
Epoch [108/300], Train Loss: 0.000689
Validation Loss: 0.00065384
Epoch [109/300], Train Loss: 0.000675
Validation Loss: 0.00066356
Epoch [110/300], Train Loss: 0.000672
Validation Loss: 0.00064797
Epoch [111/300], Train Loss: 0.000672
Validation Loss: 0.00071029
Epoch [112/300], Train Loss: 0.000688
Validation Loss: 0.00070793
Epoch [113/300], Train Loss: 0.000671
Validation Loss: 0.00067127
Epoch [114/300], Train Loss: 0.000676
Validation Loss: 0.00066367
Epoch [115/300], Train Loss: 0.000686
Validation Loss: 0.00082277
Epoch [116/300], Train Loss: 0.000703
Validation Loss: 0.00069108
Epoch [117/300], Train Loss: 0.000666
Validation Loss: 0.00071015
Epoch [118/300], Train Loss: 0.000659
Validation Loss: 0.00063533
Epoch [119/300], Train Loss: 0.000653
Validation Loss: 0.00064901
Epoch [120/300], Train Loss: 0.000657
Validation Loss: 0.00064628
Epoch [121/300], Train Loss: 0.000652
Validation Loss: 0.00063323
Epoch [122/300], Train Loss: 0.000640
Validation Loss: 0.00063671
Epoch [123/300], Train Loss: 0.000647
Validation Loss: 0.00062357
Epoch [124/300], Train Loss: 0.000669
Validation Loss: 0.00063670
Epoch [125/300], Train Loss: 0.000636
Validation Loss: 0.00062740
Epoch [126/300], Train Loss: 0.000638
Validation Loss: 0.00062654
Epoch [127/300], Train Loss: 0.000637
Validation Loss: 0.00061595
Epoch [128/300], Train Loss: 0.000659
Validation Loss: 0.00087266
Epoch [129/300], Train Loss: 0.000723
Validation Loss: 0.00069031
Epoch [130/300], Train Loss: 0.000681
Validation Loss: 0.00065884
Epoch [131/300], Train Loss: 0.000665
Validation Loss: 0.00068011
Epoch [132/300], Train Loss: 0.000643
Validation Loss: 0.00064810
Epoch [133/300], Train Loss: 0.000632
Validation Loss: 0.00060887
Epoch [134/300], Train Loss: 0.000629
Validation Loss: 0.00061330
Epoch [135/300], Train Loss: 0.000628
Validation Loss: 0.00060857
Epoch [136/300], Train Loss: 0.000619
Validation Loss: 0.00061333
Epoch [137/300], Train Loss: 0.000617
Validation Loss: 0.00060242
Epoch [138/300], Train Loss: 0.000625
Validation Loss: 0.00060775
Epoch [139/300], Train Loss: 0.000685
Validation Loss: 0.00067379
Epoch [140/300], Train Loss: 0.000636
Validation Loss: 0.00063467
Epoch [141/300], Train Loss: 0.000625
Validation Loss: 0.00061136
Epoch [142/300], Train Loss: 0.000620
Validation Loss: 0.00060967
Epoch [143/300], Train Loss: 0.000613
Validation Loss: 0.00059956
Epoch [144/300], Train Loss: 0.000614
Validation Loss: 0.00059489
Epoch [145/300], Train Loss: 0.000615
Validation Loss: 0.00060851
Epoch [146/300], Train Loss: 0.000605
Validation Loss: 0.00060770
Epoch [147/300], Train Loss: 0.000612
Validation Loss: 0.00060573
Epoch [148/300], Train Loss: 0.000614
Validation Loss: 0.00058745
Epoch [149/300], Train Loss: 0.000602
Validation Loss: 0.00058301
Epoch [150/300], Train Loss: 0.000602
Validation Loss: 0.00061595
Epoch [151/300], Train Loss: 0.000599
Validation Loss: 0.00057950
Epoch [152/300], Train Loss: 0.000620
Validation Loss: 0.00070721
Epoch [153/300], Train Loss: 0.000606
Validation Loss: 0.00057967
Epoch [154/300], Train Loss: 0.000589
Validation Loss: 0.00060537
Epoch [155/300], Train Loss: 0.000600
Validation Loss: 0.00067036
Epoch [156/300], Train Loss: 0.000592
Validation Loss: 0.00057090
Epoch [157/300], Train Loss: 0.000587
Validation Loss: 0.00058046
Epoch [158/300], Train Loss: 0.000586
Validation Loss: 0.00059687
Epoch [159/300], Train Loss: 0.000583
Validation Loss: 0.00056159
Epoch [160/300], Train Loss: 0.000586
Validation Loss: 0.00057816
Epoch [161/300], Train Loss: 0.000584
Validation Loss: 0.00056822
Epoch [162/300], Train Loss: 0.000584
Validation Loss: 0.00058054
Epoch [163/300], Train Loss: 0.000678
Validation Loss: 0.00086869
Epoch [164/300], Train Loss: 0.000717
Validation Loss: 0.00071079
Epoch [165/300], Train Loss: 0.000666
Validation Loss: 0.00066511
Epoch [166/300], Train Loss: 0.000650
Validation Loss: 0.00064594
Epoch [167/300], Train Loss: 0.000641
Validation Loss: 0.00064086
Epoch [168/300], Train Loss: 0.000627
Validation Loss: 0.00062958
Epoch [169/300], Train Loss: 0.000621
Validation Loss: 0.00062285
Early stopping triggered

Evaluating model for: Freezer
Run 26/72 completed in 2727.53 seconds with: {'MAE': np.float32(22.30383), 'MSE': np.float32(984.0056), 'RMSE': np.float32(31.368864), 'SAE': np.float32(0.0053081117), 'NDE': np.float32(0.23787077)}

Run 27/72: hidden=256, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Freezer
Dataset length: 14022 windows

Epoch [1/300], Train Loss: 0.006007
Validation Loss: 0.00565295
Epoch [2/300], Train Loss: 0.004136
Validation Loss: 0.00265498
Epoch [3/300], Train Loss: 0.002249
Validation Loss: 0.00212856
Epoch [4/300], Train Loss: 0.002011
Validation Loss: 0.00199363
Epoch [5/300], Train Loss: 0.001922
Validation Loss: 0.00193359
Epoch [6/300], Train Loss: 0.001851
Validation Loss: 0.00188300
Epoch [7/300], Train Loss: 0.001812
Validation Loss: 0.00187178
Epoch [8/300], Train Loss: 0.001777
Validation Loss: 0.00181048
Epoch [9/300], Train Loss: 0.001756
Validation Loss: 0.00178596
Epoch [10/300], Train Loss: 0.001743
Validation Loss: 0.00179441
Epoch [11/300], Train Loss: 0.001715
Validation Loss: 0.00175582
Epoch [12/300], Train Loss: 0.001715
Validation Loss: 0.00178785
Epoch [13/300], Train Loss: 0.001685
Validation Loss: 0.00171960
Epoch [14/300], Train Loss: 0.001668
Validation Loss: 0.00170587
Epoch [15/300], Train Loss: 0.001655
Validation Loss: 0.00168536
Epoch [16/300], Train Loss: 0.001634
Validation Loss: 0.00168129
Epoch [17/300], Train Loss: 0.001624
Validation Loss: 0.00164990
Epoch [18/300], Train Loss: 0.001596
Validation Loss: 0.00165886
Epoch [19/300], Train Loss: 0.001611
Validation Loss: 0.00164741
Epoch [20/300], Train Loss: 0.001578
Validation Loss: 0.00162767
Epoch [21/300], Train Loss: 0.001561
Validation Loss: 0.00157961
Epoch [22/300], Train Loss: 0.001573
Validation Loss: 0.00160920
Epoch [23/300], Train Loss: 0.001563
Validation Loss: 0.00159262
Epoch [24/300], Train Loss: 0.001535
Validation Loss: 0.00155384
Epoch [25/300], Train Loss: 0.001520
Validation Loss: 0.00153740
Epoch [26/300], Train Loss: 0.001494
Validation Loss: 0.00150746
Epoch [27/300], Train Loss: 0.001489
Validation Loss: 0.00149471
Epoch [28/300], Train Loss: 0.001470
Validation Loss: 0.00155323
Epoch [29/300], Train Loss: 0.001470
Validation Loss: 0.00146114
Epoch [30/300], Train Loss: 0.001445
Validation Loss: 0.00142883
Epoch [31/300], Train Loss: 0.001419
Validation Loss: 0.00141766
Epoch [32/300], Train Loss: 0.001395
Validation Loss: 0.00136854
Epoch [33/300], Train Loss: 0.001371
Validation Loss: 0.00134010
Epoch [34/300], Train Loss: 0.001297
Validation Loss: 0.00122920
Epoch [35/300], Train Loss: 0.001215
Validation Loss: 0.00117293
Epoch [36/300], Train Loss: 0.001158
Validation Loss: 0.00112311
Epoch [37/300], Train Loss: 0.001098
Validation Loss: 0.00105207
Epoch [38/300], Train Loss: 0.001046
Validation Loss: 0.00098780
Epoch [39/300], Train Loss: 0.001017
Validation Loss: 0.00095905
Epoch [40/300], Train Loss: 0.000943
Validation Loss: 0.00092344
Epoch [41/300], Train Loss: 0.000914
Validation Loss: 0.00087882
Epoch [42/300], Train Loss: 0.000876
Validation Loss: 0.00091310
Epoch [43/300], Train Loss: 0.000866
Validation Loss: 0.00087734
Epoch [44/300], Train Loss: 0.000832
Validation Loss: 0.00080147
Epoch [45/300], Train Loss: 0.000814
Validation Loss: 0.00077012
Epoch [46/300], Train Loss: 0.000792
Validation Loss: 0.00075514
Epoch [47/300], Train Loss: 0.000774
Validation Loss: 0.00079969
Epoch [48/300], Train Loss: 0.000768
Validation Loss: 0.00074327
Epoch [49/300], Train Loss: 0.000753
Validation Loss: 0.00072280
Epoch [50/300], Train Loss: 0.000746
Validation Loss: 0.00072554
Epoch [51/300], Train Loss: 0.000737
Validation Loss: 0.00072673
Epoch [52/300], Train Loss: 0.000726
Validation Loss: 0.00070738
Epoch [53/300], Train Loss: 0.000724
Validation Loss: 0.00071345
Epoch [54/300], Train Loss: 0.000724
Validation Loss: 0.00070160
Epoch [55/300], Train Loss: 0.000718
Validation Loss: 0.00067782
Epoch [56/300], Train Loss: 0.000703
Validation Loss: 0.00072177
Epoch [57/300], Train Loss: 0.000701
Validation Loss: 0.00091881
Epoch [58/300], Train Loss: 0.000731
Validation Loss: 0.00066443
Epoch [59/300], Train Loss: 0.000695
Validation Loss: 0.00068829
Epoch [60/300], Train Loss: 0.000688
Validation Loss: 0.00066969
Epoch [61/300], Train Loss: 0.000688
Validation Loss: 0.00067711
Epoch [62/300], Train Loss: 0.000678
Validation Loss: 0.00064900
Epoch [63/300], Train Loss: 0.000672
Validation Loss: 0.00063665
Epoch [64/300], Train Loss: 0.000679
Validation Loss: 0.00063828
Epoch [65/300], Train Loss: 0.000674
Validation Loss: 0.00085094
Epoch [66/300], Train Loss: 0.000683
Validation Loss: 0.00065516
Epoch [67/300], Train Loss: 0.000660
Validation Loss: 0.00063709
Epoch [68/300], Train Loss: 0.000651
Validation Loss: 0.00062224
Epoch [69/300], Train Loss: 0.000654
Validation Loss: 0.00061882
Epoch [70/300], Train Loss: 0.000649
Validation Loss: 0.00061204
Epoch [71/300], Train Loss: 0.000681
Validation Loss: 0.00067215
Epoch [72/300], Train Loss: 0.000659
Validation Loss: 0.00062240
Epoch [73/300], Train Loss: 0.000651
Validation Loss: 0.00062900
Epoch [74/300], Train Loss: 0.000644
Validation Loss: 0.00061961
Epoch [75/300], Train Loss: 0.000634
Validation Loss: 0.00064799
Epoch [76/300], Train Loss: 0.000640
Validation Loss: 0.00062025
Epoch [77/300], Train Loss: 0.000635
Validation Loss: 0.00060721
Epoch [78/300], Train Loss: 0.000639
Validation Loss: 0.00060531
Epoch [79/300], Train Loss: 0.000696
Validation Loss: 0.00080317
Epoch [80/300], Train Loss: 0.000732
Validation Loss: 0.00074041
Epoch [81/300], Train Loss: 0.000690
Validation Loss: 0.00071116
Epoch [82/300], Train Loss: 0.000653
Validation Loss: 0.00062725
Epoch [83/300], Train Loss: 0.000635
Validation Loss: 0.00060886
Epoch [84/300], Train Loss: 0.000623
Validation Loss: 0.00061189
Epoch [85/300], Train Loss: 0.000618
Validation Loss: 0.00059733
Epoch [86/300], Train Loss: 0.000625
Validation Loss: 0.00063587
Epoch [87/300], Train Loss: 0.000613
Validation Loss: 0.00058344
Epoch [88/300], Train Loss: 0.000611
Validation Loss: 0.00059655
Epoch [89/300], Train Loss: 0.000607
Validation Loss: 0.00058316
Epoch [90/300], Train Loss: 0.000609
Validation Loss: 0.00060130
Epoch [91/300], Train Loss: 0.000606
Validation Loss: 0.00057870
Epoch [92/300], Train Loss: 0.000599
Validation Loss: 0.00058307
Epoch [93/300], Train Loss: 0.000606
Validation Loss: 0.00057226
Epoch [94/300], Train Loss: 0.000595
Validation Loss: 0.00058144
Epoch [95/300], Train Loss: 0.000602
Validation Loss: 0.00057962
Epoch [96/300], Train Loss: 0.000593
Validation Loss: 0.00057117
Epoch [97/300], Train Loss: 0.000639
Validation Loss: 0.00061600
Epoch [98/300], Train Loss: 0.000591
Validation Loss: 0.00056687
Epoch [99/300], Train Loss: 0.000606
Validation Loss: 0.00081017
Epoch [100/300], Train Loss: 0.000606
Validation Loss: 0.00057130
Epoch [101/300], Train Loss: 0.000589
Validation Loss: 0.00057142
Epoch [102/300], Train Loss: 0.000585
Validation Loss: 0.00055434
Epoch [103/300], Train Loss: 0.000584
Validation Loss: 0.00055134
Epoch [104/300], Train Loss: 0.000579
Validation Loss: 0.00055739
Epoch [105/300], Train Loss: 0.000599
Validation Loss: 0.00069855
Epoch [106/300], Train Loss: 0.000600
Validation Loss: 0.00055197
Epoch [107/300], Train Loss: 0.000578
Validation Loss: 0.00061887
Epoch [108/300], Train Loss: 0.000587
Validation Loss: 0.00055386
Epoch [109/300], Train Loss: 0.000617
Validation Loss: 0.00058629
Epoch [110/300], Train Loss: 0.000579
Validation Loss: 0.00055110
Epoch [111/300], Train Loss: 0.000573
Validation Loss: 0.00058047
Epoch [112/300], Train Loss: 0.000575
Validation Loss: 0.00054630
Epoch [113/300], Train Loss: 0.000565
Validation Loss: 0.00053852
Epoch [114/300], Train Loss: 0.000558
Validation Loss: 0.00054517
Epoch [115/300], Train Loss: 0.000563
Validation Loss: 0.00053260
Epoch [116/300], Train Loss: 0.000556
Validation Loss: 0.00054908
Epoch [117/300], Train Loss: 0.000556
Validation Loss: 0.00054097
Epoch [118/300], Train Loss: 0.000603
Validation Loss: 0.00090921
Epoch [119/300], Train Loss: 0.000718
Validation Loss: 0.00069498
Epoch [120/300], Train Loss: 0.000668
Validation Loss: 0.00065441
Epoch [121/300], Train Loss: 0.000645
Validation Loss: 0.00065009
Epoch [122/300], Train Loss: 0.000638
Validation Loss: 0.00064051
Epoch [123/300], Train Loss: 0.000635
Validation Loss: 0.00064696
Epoch [124/300], Train Loss: 0.000628
Validation Loss: 0.00063667
Epoch [125/300], Train Loss: 0.000620
Validation Loss: 0.00062610
Early stopping triggered

Evaluating model for: Freezer
Run 27/72 completed in 2118.59 seconds with: {'MAE': np.float32(22.757202), 'MSE': np.float32(956.33453), 'RMSE': np.float32(30.92466), 'SAE': np.float32(0.0071412153), 'NDE': np.float32(0.23450232)}

Run 28/72: hidden=256, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Freezer
Dataset length: 14022 windows

Epoch [1/300], Train Loss: 0.006825
Validation Loss: 0.00580865
Epoch [2/300], Train Loss: 0.005622
Validation Loss: 0.00459147
Epoch [3/300], Train Loss: 0.003678
Validation Loss: 0.00297570
Epoch [4/300], Train Loss: 0.002866
Validation Loss: 0.00270906
Epoch [5/300], Train Loss: 0.002538
Validation Loss: 0.00234049
Epoch [6/300], Train Loss: 0.002122
Validation Loss: 0.00205454
Epoch [7/300], Train Loss: 0.001929
Validation Loss: 0.00204109
Epoch [8/300], Train Loss: 0.001876
Validation Loss: 0.00193515
Epoch [9/300], Train Loss: 0.001835
Validation Loss: 0.00185443
Epoch [10/300], Train Loss: 0.001803
Validation Loss: 0.00182215
Epoch [11/300], Train Loss: 0.001778
Validation Loss: 0.00179182
Epoch [12/300], Train Loss: 0.001758
Validation Loss: 0.00175616
Epoch [13/300], Train Loss: 0.001720
Validation Loss: 0.00174590
Epoch [14/300], Train Loss: 0.001696
Validation Loss: 0.00170747
Epoch [15/300], Train Loss: 0.001678
Validation Loss: 0.00167717
Epoch [16/300], Train Loss: 0.001653
Validation Loss: 0.00167182
Epoch [17/300], Train Loss: 0.001622
Validation Loss: 0.00162363
Epoch [18/300], Train Loss: 0.001606
Validation Loss: 0.00162965
Epoch [19/300], Train Loss: 0.001613
Validation Loss: 0.00166155
Epoch [20/300], Train Loss: 0.001604
Validation Loss: 0.00159640
Epoch [21/300], Train Loss: 0.001596
Validation Loss: 0.00157372
Epoch [22/300], Train Loss: 0.001572
Validation Loss: 0.00156742
Epoch [23/300], Train Loss: 0.001557
Validation Loss: 0.00159060
Epoch [24/300], Train Loss: 0.001557
Validation Loss: 0.00156930
Epoch [25/300], Train Loss: 0.001548
Validation Loss: 0.00158563
Epoch [26/300], Train Loss: 0.001545
Validation Loss: 0.00156831
Epoch [27/300], Train Loss: 0.001538
Validation Loss: 0.00156517
Epoch [28/300], Train Loss: 0.001524
Validation Loss: 0.00165696
Epoch [29/300], Train Loss: 0.001513
Validation Loss: 0.00154944
Epoch [30/300], Train Loss: 0.001515
Validation Loss: 0.00151446
Epoch [31/300], Train Loss: 0.001504
Validation Loss: 0.00150943
Epoch [32/300], Train Loss: 0.001518
Validation Loss: 0.00149323
Epoch [33/300], Train Loss: 0.001490
Validation Loss: 0.00150229
Epoch [34/300], Train Loss: 0.001482
Validation Loss: 0.00149010
Epoch [35/300], Train Loss: 0.001472
Validation Loss: 0.00148393
Epoch [36/300], Train Loss: 0.001474
Validation Loss: 0.00151470
Epoch [37/300], Train Loss: 0.001465
Validation Loss: 0.00147637
Epoch [38/300], Train Loss: 0.001455
Validation Loss: 0.00147166
Epoch [39/300], Train Loss: 0.001484
Validation Loss: 0.00147519
Epoch [40/300], Train Loss: 0.001438
Validation Loss: 0.00146629
Epoch [41/300], Train Loss: 0.001429
Validation Loss: 0.00143205
Epoch [42/300], Train Loss: 0.001413
Validation Loss: 0.00142286
Epoch [43/300], Train Loss: 0.001416
Validation Loss: 0.00138837
Epoch [44/300], Train Loss: 0.001394
Validation Loss: 0.00136786
Epoch [45/300], Train Loss: 0.001376
Validation Loss: 0.00133303
Epoch [46/300], Train Loss: 0.001370
Validation Loss: 0.00131198
Epoch [47/300], Train Loss: 0.001322
Validation Loss: 0.00138632
Epoch [48/300], Train Loss: 0.001271
Validation Loss: 0.00121301
Epoch [49/300], Train Loss: 0.001201
Validation Loss: 0.00111496
Epoch [50/300], Train Loss: 0.001098
Validation Loss: 0.00100089
Epoch [51/300], Train Loss: 0.001011
Validation Loss: 0.00099641
Epoch [52/300], Train Loss: 0.000954
Validation Loss: 0.00095829
Epoch [53/300], Train Loss: 0.000907
Validation Loss: 0.00090717
Epoch [54/300], Train Loss: 0.000866
Validation Loss: 0.00081813
Epoch [55/300], Train Loss: 0.000848
Validation Loss: 0.00078216
Epoch [56/300], Train Loss: 0.000826
Validation Loss: 0.00080671
Epoch [57/300], Train Loss: 0.000796
Validation Loss: 0.00078102
Epoch [58/300], Train Loss: 0.000791
Validation Loss: 0.00073996
Epoch [59/300], Train Loss: 0.000779
Validation Loss: 0.00071555
Epoch [60/300], Train Loss: 0.000770
Validation Loss: 0.00073657
Epoch [61/300], Train Loss: 0.000770
Validation Loss: 0.00073708
Epoch [62/300], Train Loss: 0.000749
Validation Loss: 0.00073321
Epoch [63/300], Train Loss: 0.000755
Validation Loss: 0.00083036
Epoch [64/300], Train Loss: 0.000779
Validation Loss: 0.00071730
Epoch [65/300], Train Loss: 0.000735
Validation Loss: 0.00069995
Epoch [66/300], Train Loss: 0.000734
Validation Loss: 0.00069151
Epoch [67/300], Train Loss: 0.000729
Validation Loss: 0.00070720
Epoch [68/300], Train Loss: 0.000719
Validation Loss: 0.00067914
Epoch [69/300], Train Loss: 0.000720
Validation Loss: 0.00068890
Epoch [70/300], Train Loss: 0.000755
Validation Loss: 0.00072019
Epoch [71/300], Train Loss: 0.000732
Validation Loss: 0.00069368
Epoch [72/300], Train Loss: 0.000722
Validation Loss: 0.00069021
Epoch [73/300], Train Loss: 0.000715
Validation Loss: 0.00067430
Epoch [74/300], Train Loss: 0.000706
Validation Loss: 0.00069882
Epoch [75/300], Train Loss: 0.000690
Validation Loss: 0.00068528
Epoch [76/300], Train Loss: 0.000694
Validation Loss: 0.00064913
Epoch [77/300], Train Loss: 0.000685
Validation Loss: 0.00067378
Epoch [78/300], Train Loss: 0.000689
Validation Loss: 0.00065967
Epoch [79/300], Train Loss: 0.000682
Validation Loss: 0.00064537
Epoch [80/300], Train Loss: 0.000694
Validation Loss: 0.00070448
Epoch [81/300], Train Loss: 0.000683
Validation Loss: 0.00069572
Epoch [82/300], Train Loss: 0.000674
Validation Loss: 0.00062108
Epoch [83/300], Train Loss: 0.000665
Validation Loss: 0.00063119
Epoch [84/300], Train Loss: 0.000660
Validation Loss: 0.00102467
Epoch [85/300], Train Loss: 0.000686
Validation Loss: 0.00063880
Epoch [86/300], Train Loss: 0.000664
Validation Loss: 0.00063481
Epoch [87/300], Train Loss: 0.000657
Validation Loss: 0.00061689
Epoch [88/300], Train Loss: 0.000667
Validation Loss: 0.00066081
Epoch [89/300], Train Loss: 0.000653
Validation Loss: 0.00062162
Epoch [90/300], Train Loss: 0.000658
Validation Loss: 0.00065567
Epoch [91/300], Train Loss: 0.000660
Validation Loss: 0.00062722
Epoch [92/300], Train Loss: 0.000639
Validation Loss: 0.00061528
Epoch [93/300], Train Loss: 0.000635
Validation Loss: 0.00060038
Epoch [94/300], Train Loss: 0.000646
Validation Loss: 0.00072532
Epoch [95/300], Train Loss: 0.000657
Validation Loss: 0.00064142
Epoch [96/300], Train Loss: 0.000648
Validation Loss: 0.00060465
Epoch [97/300], Train Loss: 0.000639
Validation Loss: 0.00060603
Epoch [98/300], Train Loss: 0.000695
Validation Loss: 0.00065224
Epoch [99/300], Train Loss: 0.000838
Validation Loss: 0.00073627
Epoch [100/300], Train Loss: 0.000697
Validation Loss: 0.00072067
Epoch [101/300], Train Loss: 0.000667
Validation Loss: 0.00064767
Epoch [102/300], Train Loss: 0.000671
Validation Loss: 0.00065159
Epoch [103/300], Train Loss: 0.000647
Validation Loss: 0.00061143
Early stopping triggered

Evaluating model for: Freezer
Run 28/72 completed in 1992.53 seconds with: {'MAE': np.float32(22.770514), 'MSE': np.float32(998.9948), 'RMSE': np.float32(31.606878), 'SAE': np.float32(0.0019702308), 'NDE': np.float32(0.23967563)}

Run 29/72: hidden=256, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Freezer
Dataset length: 7026 windows

Epoch [1/300], Train Loss: 0.006282
Validation Loss: 0.00579071
Epoch [2/300], Train Loss: 0.005764
Validation Loss: 0.00546822
Epoch [3/300], Train Loss: 0.005045
Validation Loss: 0.00461615
Epoch [4/300], Train Loss: 0.004066
Validation Loss: 0.00346115
Epoch [5/300], Train Loss: 0.002939
Validation Loss: 0.00273188
Epoch [6/300], Train Loss: 0.002595
Validation Loss: 0.00256535
Epoch [7/300], Train Loss: 0.002433
Validation Loss: 0.00234755
Epoch [8/300], Train Loss: 0.002289
Validation Loss: 0.00229801
Epoch [9/300], Train Loss: 0.002148
Validation Loss: 0.00200053
Epoch [10/300], Train Loss: 0.002019
Validation Loss: 0.00192227
Epoch [11/300], Train Loss: 0.001959
Validation Loss: 0.00193570
Epoch [12/300], Train Loss: 0.001947
Validation Loss: 0.00190774
Epoch [13/300], Train Loss: 0.001940
Validation Loss: 0.00187335
Epoch [14/300], Train Loss: 0.001896
Validation Loss: 0.00187903
Epoch [15/300], Train Loss: 0.001904
Validation Loss: 0.00192479
Epoch [16/300], Train Loss: 0.001891
Validation Loss: 0.00181496
Epoch [17/300], Train Loss: 0.001865
Validation Loss: 0.00181968
Epoch [18/300], Train Loss: 0.001847
Validation Loss: 0.00179985
Epoch [19/300], Train Loss: 0.001835
Validation Loss: 0.00177695
Epoch [20/300], Train Loss: 0.001825
Validation Loss: 0.00180622
Epoch [21/300], Train Loss: 0.001827
Validation Loss: 0.00178737
Epoch [22/300], Train Loss: 0.001800
Validation Loss: 0.00175912
Epoch [23/300], Train Loss: 0.001807
Validation Loss: 0.00174844
Epoch [24/300], Train Loss: 0.001800
Validation Loss: 0.00173827
Epoch [25/300], Train Loss: 0.001791
Validation Loss: 0.00178395
Epoch [26/300], Train Loss: 0.001769
Validation Loss: 0.00173857
Epoch [27/300], Train Loss: 0.001765
Validation Loss: 0.00172353
Epoch [28/300], Train Loss: 0.001776
Validation Loss: 0.00173162
Epoch [29/300], Train Loss: 0.001752
Validation Loss: 0.00171730
Epoch [30/300], Train Loss: 0.001761
Validation Loss: 0.00170655
Epoch [31/300], Train Loss: 0.001740
Validation Loss: 0.00173035
Epoch [32/300], Train Loss: 0.001741
Validation Loss: 0.00171726
Epoch [33/300], Train Loss: 0.001739
Validation Loss: 0.00168100
Epoch [34/300], Train Loss: 0.001715
Validation Loss: 0.00168358
Epoch [35/300], Train Loss: 0.001706
Validation Loss: 0.00168520
Epoch [36/300], Train Loss: 0.001704
Validation Loss: 0.00166414
Epoch [37/300], Train Loss: 0.001706
Validation Loss: 0.00169257
Epoch [38/300], Train Loss: 0.001697
Validation Loss: 0.00166770
Epoch [39/300], Train Loss: 0.001681
Validation Loss: 0.00167315
Epoch [40/300], Train Loss: 0.001662
Validation Loss: 0.00164327
Epoch [41/300], Train Loss: 0.001661
Validation Loss: 0.00167703
Epoch [42/300], Train Loss: 0.001663
Validation Loss: 0.00165917
Epoch [43/300], Train Loss: 0.001671
Validation Loss: 0.00166498
Epoch [44/300], Train Loss: 0.001645
Validation Loss: 0.00162929
Epoch [45/300], Train Loss: 0.001633
Validation Loss: 0.00161816
Epoch [46/300], Train Loss: 0.001633
Validation Loss: 0.00164348
Epoch [47/300], Train Loss: 0.001621
Validation Loss: 0.00160220
Epoch [48/300], Train Loss: 0.001621
Validation Loss: 0.00160940
Epoch [49/300], Train Loss: 0.001643
Validation Loss: 0.00159631
Epoch [50/300], Train Loss: 0.001608
Validation Loss: 0.00161754
Epoch [51/300], Train Loss: 0.001606
Validation Loss: 0.00163740
Epoch [52/300], Train Loss: 0.001604
Validation Loss: 0.00160320
Epoch [53/300], Train Loss: 0.001611
Validation Loss: 0.00159686
Epoch [54/300], Train Loss: 0.001596
Validation Loss: 0.00158567
Epoch [55/300], Train Loss: 0.001588
Validation Loss: 0.00157412
Epoch [56/300], Train Loss: 0.001571
Validation Loss: 0.00156338
Epoch [57/300], Train Loss: 0.001578
Validation Loss: 0.00156544
Epoch [58/300], Train Loss: 0.001575
Validation Loss: 0.00159527
Epoch [59/300], Train Loss: 0.001586
Validation Loss: 0.00156011
Epoch [60/300], Train Loss: 0.001558
Validation Loss: 0.00154371
Epoch [61/300], Train Loss: 0.001557
Validation Loss: 0.00154013
Epoch [62/300], Train Loss: 0.001563
Validation Loss: 0.00155769
Epoch [63/300], Train Loss: 0.001540
Validation Loss: 0.00153282
Epoch [64/300], Train Loss: 0.001541
Validation Loss: 0.00153437
Epoch [65/300], Train Loss: 0.001540
Validation Loss: 0.00154829
Epoch [66/300], Train Loss: 0.001549
Validation Loss: 0.00157966
Epoch [67/300], Train Loss: 0.001546
Validation Loss: 0.00151909
Epoch [68/300], Train Loss: 0.001513
Validation Loss: 0.00157818
Epoch [69/300], Train Loss: 0.001519
Validation Loss: 0.00149927
Epoch [70/300], Train Loss: 0.001519
Validation Loss: 0.00150624
Epoch [71/300], Train Loss: 0.001502
Validation Loss: 0.00151928
Epoch [72/300], Train Loss: 0.001488
Validation Loss: 0.00150459
Epoch [73/300], Train Loss: 0.001494
Validation Loss: 0.00151082
Epoch [74/300], Train Loss: 0.001482
Validation Loss: 0.00147605
Epoch [75/300], Train Loss: 0.001472
Validation Loss: 0.00147243
Epoch [76/300], Train Loss: 0.001476
Validation Loss: 0.00146781
Epoch [77/300], Train Loss: 0.001464
Validation Loss: 0.00144876
Epoch [78/300], Train Loss: 0.001449
Validation Loss: 0.00145801
Epoch [79/300], Train Loss: 0.001439
Validation Loss: 0.00143839
Epoch [80/300], Train Loss: 0.001435
Validation Loss: 0.00142906
Epoch [81/300], Train Loss: 0.001424
Validation Loss: 0.00142463
Epoch [82/300], Train Loss: 0.001437
Validation Loss: 0.00139058
Epoch [83/300], Train Loss: 0.001406
Validation Loss: 0.00140210
Epoch [84/300], Train Loss: 0.001401
Validation Loss: 0.00142306
Epoch [85/300], Train Loss: 0.001376
Validation Loss: 0.00136541
Epoch [86/300], Train Loss: 0.001358
Validation Loss: 0.00133499
Epoch [87/300], Train Loss: 0.001339
Validation Loss: 0.00129631
Epoch [88/300], Train Loss: 0.001337
Validation Loss: 0.00129553
Epoch [89/300], Train Loss: 0.001298
Validation Loss: 0.00128716
Epoch [90/300], Train Loss: 0.001280
Validation Loss: 0.00126095
Epoch [91/300], Train Loss: 0.001250
Validation Loss: 0.00118355
Epoch [92/300], Train Loss: 0.001228
Validation Loss: 0.00117923
Epoch [93/300], Train Loss: 0.001192
Validation Loss: 0.00111171
Epoch [94/300], Train Loss: 0.001173
Validation Loss: 0.00108256
Epoch [95/300], Train Loss: 0.001146
Validation Loss: 0.00107506
Epoch [96/300], Train Loss: 0.001157
Validation Loss: 0.00105028
Epoch [97/300], Train Loss: 0.001108
Validation Loss: 0.00101471
Epoch [98/300], Train Loss: 0.001085
Validation Loss: 0.00099429
Epoch [99/300], Train Loss: 0.001098
Validation Loss: 0.00098667
Epoch [100/300], Train Loss: 0.001064
Validation Loss: 0.00099279
Epoch [101/300], Train Loss: 0.001054
Validation Loss: 0.00095296
Epoch [102/300], Train Loss: 0.001053
Validation Loss: 0.00095477
Epoch [103/300], Train Loss: 0.001064
Validation Loss: 0.00095053
Epoch [104/300], Train Loss: 0.001028
Validation Loss: 0.00093623
Epoch [105/300], Train Loss: 0.001021
Validation Loss: 0.00092860
Epoch [106/300], Train Loss: 0.001020
Validation Loss: 0.00092354
Epoch [107/300], Train Loss: 0.001008
Validation Loss: 0.00092869
Epoch [108/300], Train Loss: 0.001004
Validation Loss: 0.00091927
Epoch [109/300], Train Loss: 0.001002
Validation Loss: 0.00091626
Epoch [110/300], Train Loss: 0.000995
Validation Loss: 0.00090730
Epoch [111/300], Train Loss: 0.000987
Validation Loss: 0.00090421
Epoch [112/300], Train Loss: 0.000989
Validation Loss: 0.00087770
Epoch [113/300], Train Loss: 0.000992
Validation Loss: 0.00091451
Epoch [114/300], Train Loss: 0.000981
Validation Loss: 0.00090059
Epoch [115/300], Train Loss: 0.000989
Validation Loss: 0.00089281
Epoch [116/300], Train Loss: 0.000968
Validation Loss: 0.00089402
Epoch [117/300], Train Loss: 0.000967
Validation Loss: 0.00091344
Epoch [118/300], Train Loss: 0.000971
Validation Loss: 0.00086434
Epoch [119/300], Train Loss: 0.000956
Validation Loss: 0.00087059
Epoch [120/300], Train Loss: 0.000961
Validation Loss: 0.00086115
Epoch [121/300], Train Loss: 0.000951
Validation Loss: 0.00096457
Epoch [122/300], Train Loss: 0.000957
Validation Loss: 0.00084713
Epoch [123/300], Train Loss: 0.000944
Validation Loss: 0.00085365
Epoch [124/300], Train Loss: 0.000949
Validation Loss: 0.00087133
Epoch [125/300], Train Loss: 0.000949
Validation Loss: 0.00084108
Epoch [126/300], Train Loss: 0.000945
Validation Loss: 0.00084187
Epoch [127/300], Train Loss: 0.000937
Validation Loss: 0.00084899
Epoch [128/300], Train Loss: 0.000940
Validation Loss: 0.00083680
Epoch [129/300], Train Loss: 0.000928
Validation Loss: 0.00084450
Epoch [130/300], Train Loss: 0.000927
Validation Loss: 0.00084157
Epoch [131/300], Train Loss: 0.000937
Validation Loss: 0.00086035
Epoch [132/300], Train Loss: 0.000927
Validation Loss: 0.00083139
Epoch [133/300], Train Loss: 0.000926
Validation Loss: 0.00082900
Epoch [134/300], Train Loss: 0.000918
Validation Loss: 0.00083478
Epoch [135/300], Train Loss: 0.000927
Validation Loss: 0.00087099
Epoch [136/300], Train Loss: 0.000920
Validation Loss: 0.00083020
Epoch [137/300], Train Loss: 0.000910
Validation Loss: 0.00085795
Epoch [138/300], Train Loss: 0.000916
Validation Loss: 0.00082093
Epoch [139/300], Train Loss: 0.000916
Validation Loss: 0.00083067
Epoch [140/300], Train Loss: 0.000904
Validation Loss: 0.00081770
Epoch [141/300], Train Loss: 0.000906
Validation Loss: 0.00084452
Epoch [142/300], Train Loss: 0.000901
Validation Loss: 0.00082994
Epoch [143/300], Train Loss: 0.000900
Validation Loss: 0.00082333
Epoch [144/300], Train Loss: 0.000905
Validation Loss: 0.00082346
Epoch [145/300], Train Loss: 0.000908
Validation Loss: 0.00082792
Epoch [146/300], Train Loss: 0.000898
Validation Loss: 0.00081156
Epoch [147/300], Train Loss: 0.000892
Validation Loss: 0.00081702
Epoch [148/300], Train Loss: 0.000904
Validation Loss: 0.00083236
Epoch [149/300], Train Loss: 0.000894
Validation Loss: 0.00081163
Epoch [150/300], Train Loss: 0.000891
Validation Loss: 0.00081721
Epoch [151/300], Train Loss: 0.000902
Validation Loss: 0.00080975
Epoch [152/300], Train Loss: 0.000887
Validation Loss: 0.00082788
Epoch [153/300], Train Loss: 0.000892
Validation Loss: 0.00083553
Epoch [154/300], Train Loss: 0.000894
Validation Loss: 0.00081160
Epoch [155/300], Train Loss: 0.000885
Validation Loss: 0.00082240
Epoch [156/300], Train Loss: 0.000879
Validation Loss: 0.00080513
Epoch [157/300], Train Loss: 0.000882
Validation Loss: 0.00081241
Epoch [158/300], Train Loss: 0.000894
Validation Loss: 0.00081295
Epoch [159/300], Train Loss: 0.000889
Validation Loss: 0.00080689
Epoch [160/300], Train Loss: 0.000880
Validation Loss: 0.00080154
Epoch [161/300], Train Loss: 0.000882
Validation Loss: 0.00080868
Epoch [162/300], Train Loss: 0.000889
Validation Loss: 0.00081187
Epoch [163/300], Train Loss: 0.000877
Validation Loss: 0.00081312
Epoch [164/300], Train Loss: 0.000879
Validation Loss: 0.00080371
Epoch [165/300], Train Loss: 0.000879
Validation Loss: 0.00082490
Epoch [166/300], Train Loss: 0.000869
Validation Loss: 0.00079126
Epoch [167/300], Train Loss: 0.000870
Validation Loss: 0.00083308
Epoch [168/300], Train Loss: 0.000876
Validation Loss: 0.00079167
Epoch [169/300], Train Loss: 0.000871
Validation Loss: 0.00078963
Epoch [170/300], Train Loss: 0.000864
Validation Loss: 0.00082640
Epoch [171/300], Train Loss: 0.000863
Validation Loss: 0.00078666
Epoch [172/300], Train Loss: 0.000861
Validation Loss: 0.00080383
Epoch [173/300], Train Loss: 0.000867
Validation Loss: 0.00078742
Epoch [174/300], Train Loss: 0.000862
Validation Loss: 0.00078939
Epoch [175/300], Train Loss: 0.000865
Validation Loss: 0.00078885
Epoch [176/300], Train Loss: 0.000861
Validation Loss: 0.00078556
Epoch [177/300], Train Loss: 0.000857
Validation Loss: 0.00080696
Epoch [178/300], Train Loss: 0.000856
Validation Loss: 0.00080632
Epoch [179/300], Train Loss: 0.000858
Validation Loss: 0.00078080
Epoch [180/300], Train Loss: 0.000855
Validation Loss: 0.00079414
Epoch [181/300], Train Loss: 0.000857
Validation Loss: 0.00078489
Epoch [182/300], Train Loss: 0.000857
Validation Loss: 0.00078567
Epoch [183/300], Train Loss: 0.000860
Validation Loss: 0.00079041
Epoch [184/300], Train Loss: 0.000854
Validation Loss: 0.00077609
Epoch [185/300], Train Loss: 0.000846
Validation Loss: 0.00078964
Epoch [186/300], Train Loss: 0.000846
Validation Loss: 0.00078162
Epoch [187/300], Train Loss: 0.000849
Validation Loss: 0.00078301
Epoch [188/300], Train Loss: 0.000845
Validation Loss: 0.00084313
Epoch [189/300], Train Loss: 0.000848
Validation Loss: 0.00077703
Epoch [190/300], Train Loss: 0.000850
Validation Loss: 0.00077402
Epoch [191/300], Train Loss: 0.000845
Validation Loss: 0.00077641
Epoch [192/300], Train Loss: 0.000842
Validation Loss: 0.00078459
Epoch [193/300], Train Loss: 0.000851
Validation Loss: 0.00077605
Epoch [194/300], Train Loss: 0.000841
Validation Loss: 0.00079990
Epoch [195/300], Train Loss: 0.000846
Validation Loss: 0.00078295
Epoch [196/300], Train Loss: 0.000842
Validation Loss: 0.00077274
Epoch [197/300], Train Loss: 0.000836
Validation Loss: 0.00077029
Epoch [198/300], Train Loss: 0.000833
Validation Loss: 0.00077364
Epoch [199/300], Train Loss: 0.000838
Validation Loss: 0.00079073
Epoch [200/300], Train Loss: 0.000837
Validation Loss: 0.00078005
Epoch [201/300], Train Loss: 0.000832
Validation Loss: 0.00079591
Epoch [202/300], Train Loss: 0.000842
Validation Loss: 0.00076902
Epoch [203/300], Train Loss: 0.000842
Validation Loss: 0.00077053
Epoch [204/300], Train Loss: 0.000837
Validation Loss: 0.00076594
Epoch [205/300], Train Loss: 0.000831
Validation Loss: 0.00077881
Epoch [206/300], Train Loss: 0.000832
Validation Loss: 0.00077501
Epoch [207/300], Train Loss: 0.000837
Validation Loss: 0.00076891
Epoch [208/300], Train Loss: 0.000825
Validation Loss: 0.00081082
Epoch [209/300], Train Loss: 0.000830
Validation Loss: 0.00076869
Epoch [210/300], Train Loss: 0.000829
Validation Loss: 0.00076148
Epoch [211/300], Train Loss: 0.000823
Validation Loss: 0.00076036
Epoch [212/300], Train Loss: 0.000820
Validation Loss: 0.00076622
Epoch [213/300], Train Loss: 0.000823
Validation Loss: 0.00077010
Epoch [214/300], Train Loss: 0.000823
Validation Loss: 0.00075616
Epoch [215/300], Train Loss: 0.000820
Validation Loss: 0.00075739
Epoch [216/300], Train Loss: 0.000822
Validation Loss: 0.00080723
Epoch [217/300], Train Loss: 0.000829
Validation Loss: 0.00075451
Epoch [218/300], Train Loss: 0.000818
Validation Loss: 0.00077603
Epoch [219/300], Train Loss: 0.000819
Validation Loss: 0.00077193
Epoch [220/300], Train Loss: 0.000823
Validation Loss: 0.00075926
Epoch [221/300], Train Loss: 0.000817
Validation Loss: 0.00076551
Epoch [222/300], Train Loss: 0.000814
Validation Loss: 0.00080049
Epoch [223/300], Train Loss: 0.000825
Validation Loss: 0.00075527
Epoch [224/300], Train Loss: 0.000816
Validation Loss: 0.00075783
Epoch [225/300], Train Loss: 0.000813
Validation Loss: 0.00076141
Epoch [226/300], Train Loss: 0.000813
Validation Loss: 0.00075514
Epoch [227/300], Train Loss: 0.000813
Validation Loss: 0.00075525
Early stopping triggered

Evaluating model for: Freezer
Run 29/72 completed in 1640.96 seconds with: {'MAE': np.float32(24.235859), 'MSE': np.float32(1137.2468), 'RMSE': np.float32(33.72309), 'SAE': np.float32(0.0015084416), 'NDE': np.float32(0.26111192)}

Run 30/72: hidden=256, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Freezer
Dataset length: 7026 windows

Epoch [1/300], Train Loss: 0.008567
Validation Loss: 0.00596945
Epoch [2/300], Train Loss: 0.006046
Validation Loss: 0.00590171
Epoch [3/300], Train Loss: 0.005965
Validation Loss: 0.00578810
Epoch [4/300], Train Loss: 0.005608
Validation Loss: 0.00497177
Epoch [5/300], Train Loss: 0.004353
Validation Loss: 0.00379965
Epoch [6/300], Train Loss: 0.003483
Validation Loss: 0.00330707
Epoch [7/300], Train Loss: 0.002935
Validation Loss: 0.00287116
Epoch [8/300], Train Loss: 0.002700
Validation Loss: 0.00266731
Epoch [9/300], Train Loss: 0.002538
Validation Loss: 0.00256156
Epoch [10/300], Train Loss: 0.002425
Validation Loss: 0.00237443
Epoch [11/300], Train Loss: 0.002351
Validation Loss: 0.00228455
Epoch [12/300], Train Loss: 0.002248
Validation Loss: 0.00218446
Epoch [13/300], Train Loss: 0.002169
Validation Loss: 0.00211296
Epoch [14/300], Train Loss: 0.002120
Validation Loss: 0.00204661
Epoch [15/300], Train Loss: 0.002080
Validation Loss: 0.00202431
Epoch [16/300], Train Loss: 0.002026
Validation Loss: 0.00203197
Epoch [17/300], Train Loss: 0.001988
Validation Loss: 0.00195227
Epoch [18/300], Train Loss: 0.001966
Validation Loss: 0.00197343
Epoch [19/300], Train Loss: 0.001924
Validation Loss: 0.00188651
Epoch [20/300], Train Loss: 0.001910
Validation Loss: 0.00187011
Epoch [21/300], Train Loss: 0.001915
Validation Loss: 0.00184931
Epoch [22/300], Train Loss: 0.001875
Validation Loss: 0.00182914
Epoch [23/300], Train Loss: 0.001856
Validation Loss: 0.00181908
Epoch [24/300], Train Loss: 0.001850
Validation Loss: 0.00181036
Epoch [25/300], Train Loss: 0.001847
Validation Loss: 0.00180482
Epoch [26/300], Train Loss: 0.001824
Validation Loss: 0.00181083
Epoch [27/300], Train Loss: 0.001823
Validation Loss: 0.00177433
Epoch [28/300], Train Loss: 0.001818
Validation Loss: 0.00178921
Epoch [29/300], Train Loss: 0.001805
Validation Loss: 0.00175058
Epoch [30/300], Train Loss: 0.001794
Validation Loss: 0.00174638
Epoch [31/300], Train Loss: 0.001789
Validation Loss: 0.00176120
Epoch [32/300], Train Loss: 0.001774
Validation Loss: 0.00173934
Epoch [33/300], Train Loss: 0.001778
Validation Loss: 0.00175193
Epoch [34/300], Train Loss: 0.001759
Validation Loss: 0.00172861
Epoch [35/300], Train Loss: 0.001749
Validation Loss: 0.00173207
Epoch [36/300], Train Loss: 0.001745
Validation Loss: 0.00173621
Epoch [37/300], Train Loss: 0.001752
Validation Loss: 0.00173577
Epoch [38/300], Train Loss: 0.001733
Validation Loss: 0.00169326
Epoch [39/300], Train Loss: 0.001720
Validation Loss: 0.00170012
Epoch [40/300], Train Loss: 0.001704
Validation Loss: 0.00167320
Epoch [41/300], Train Loss: 0.001701
Validation Loss: 0.00167893
Epoch [42/300], Train Loss: 0.001708
Validation Loss: 0.00166095
Epoch [43/300], Train Loss: 0.001690
Validation Loss: 0.00165378
Epoch [44/300], Train Loss: 0.001678
Validation Loss: 0.00166047
Epoch [45/300], Train Loss: 0.001669
Validation Loss: 0.00163676
Epoch [46/300], Train Loss: 0.001680
Validation Loss: 0.00163481
Epoch [47/300], Train Loss: 0.001671
Validation Loss: 0.00165724
Epoch [48/300], Train Loss: 0.001662
Validation Loss: 0.00163015
Epoch [49/300], Train Loss: 0.001658
Validation Loss: 0.00167746
Epoch [50/300], Train Loss: 0.001660
Validation Loss: 0.00162410
Epoch [51/300], Train Loss: 0.001644
Validation Loss: 0.00168672
Epoch [52/300], Train Loss: 0.001648
Validation Loss: 0.00160831
Epoch [53/300], Train Loss: 0.001627
Validation Loss: 0.00161625
Epoch [54/300], Train Loss: 0.001617
Validation Loss: 0.00160973
Epoch [55/300], Train Loss: 0.001610
Validation Loss: 0.00160708
Epoch [56/300], Train Loss: 0.001607
Validation Loss: 0.00159821
Epoch [57/300], Train Loss: 0.001602
Validation Loss: 0.00159026
Epoch [58/300], Train Loss: 0.001598
Validation Loss: 0.00160176
Epoch [59/300], Train Loss: 0.001602
Validation Loss: 0.00158375
Epoch [60/300], Train Loss: 0.001591
Validation Loss: 0.00157860
Epoch [61/300], Train Loss: 0.001586
Validation Loss: 0.00160436
Epoch [62/300], Train Loss: 0.001590
Validation Loss: 0.00157788
Epoch [63/300], Train Loss: 0.001582
Validation Loss: 0.00158009
Epoch [64/300], Train Loss: 0.001581
Validation Loss: 0.00157783
Epoch [65/300], Train Loss: 0.001570
Validation Loss: 0.00161054
Epoch [66/300], Train Loss: 0.001581
Validation Loss: 0.00156647
Epoch [67/300], Train Loss: 0.001568
Validation Loss: 0.00155933
Epoch [68/300], Train Loss: 0.001560
Validation Loss: 0.00157636
Epoch [69/300], Train Loss: 0.001569
Validation Loss: 0.00154513
Epoch [70/300], Train Loss: 0.001554
Validation Loss: 0.00156084
Epoch [71/300], Train Loss: 0.001551
Validation Loss: 0.00155562
Epoch [72/300], Train Loss: 0.001545
Validation Loss: 0.00155260
Epoch [73/300], Train Loss: 0.001544
Validation Loss: 0.00157069
Epoch [74/300], Train Loss: 0.001537
Validation Loss: 0.00155577
Epoch [75/300], Train Loss: 0.001535
Validation Loss: 0.00154448
Epoch [76/300], Train Loss: 0.001533
Validation Loss: 0.00155397
Epoch [77/300], Train Loss: 0.001532
Validation Loss: 0.00153587
Epoch [78/300], Train Loss: 0.001521
Validation Loss: 0.00156579
Epoch [79/300], Train Loss: 0.001514
Validation Loss: 0.00154494
Epoch [80/300], Train Loss: 0.001520
Validation Loss: 0.00152691
Epoch [81/300], Train Loss: 0.001519
Validation Loss: 0.00154772
Epoch [82/300], Train Loss: 0.001532
Validation Loss: 0.00153679
Epoch [83/300], Train Loss: 0.001510
Validation Loss: 0.00154744
Epoch [84/300], Train Loss: 0.001525
Validation Loss: 0.00150835
Epoch [85/300], Train Loss: 0.001504
Validation Loss: 0.00151266
Epoch [86/300], Train Loss: 0.001505
Validation Loss: 0.00150599
Epoch [87/300], Train Loss: 0.001506
Validation Loss: 0.00150764
Epoch [88/300], Train Loss: 0.001529
Validation Loss: 0.00157480
Epoch [89/300], Train Loss: 0.001504
Validation Loss: 0.00151343
Epoch [90/300], Train Loss: 0.001493
Validation Loss: 0.00150916
Epoch [91/300], Train Loss: 0.001487
Validation Loss: 0.00152463
Epoch [92/300], Train Loss: 0.001502
Validation Loss: 0.00153003
Epoch [93/300], Train Loss: 0.001495
Validation Loss: 0.00150078
Epoch [94/300], Train Loss: 0.001490
Validation Loss: 0.00150888
Epoch [95/300], Train Loss: 0.001476
Validation Loss: 0.00149633
Epoch [96/300], Train Loss: 0.001476
Validation Loss: 0.00148639
Epoch [97/300], Train Loss: 0.001476
Validation Loss: 0.00148531
Epoch [98/300], Train Loss: 0.001472
Validation Loss: 0.00148411
Epoch [99/300], Train Loss: 0.001472
Validation Loss: 0.00148305
Epoch [100/300], Train Loss: 0.001464
Validation Loss: 0.00150009
Epoch [101/300], Train Loss: 0.001466
Validation Loss: 0.00147810
Epoch [102/300], Train Loss: 0.001465
Validation Loss: 0.00151456
Epoch [103/300], Train Loss: 0.001468
Validation Loss: 0.00148374
Epoch [104/300], Train Loss: 0.001461
Validation Loss: 0.00149061
Epoch [105/300], Train Loss: 0.001460
Validation Loss: 0.00148180
Epoch [106/300], Train Loss: 0.001457
Validation Loss: 0.00151140
Epoch [107/300], Train Loss: 0.001464
Validation Loss: 0.00148801
Epoch [108/300], Train Loss: 0.001450
Validation Loss: 0.00149172
Epoch [109/300], Train Loss: 0.001445
Validation Loss: 0.00148402
Epoch [110/300], Train Loss: 0.001449
Validation Loss: 0.00147011
Epoch [111/300], Train Loss: 0.001442
Validation Loss: 0.00145865
Epoch [112/300], Train Loss: 0.001439
Validation Loss: 0.00146172
Epoch [113/300], Train Loss: 0.001437
Validation Loss: 0.00147537
Epoch [114/300], Train Loss: 0.001434
Validation Loss: 0.00150307
Epoch [115/300], Train Loss: 0.001437
Validation Loss: 0.00147730
Epoch [116/300], Train Loss: 0.001431
Validation Loss: 0.00146243
Epoch [117/300], Train Loss: 0.001423
Validation Loss: 0.00153146
Epoch [118/300], Train Loss: 0.001440
Validation Loss: 0.00145162
Epoch [119/300], Train Loss: 0.001430
Validation Loss: 0.00144743
Epoch [120/300], Train Loss: 0.001424
Validation Loss: 0.00144491
Epoch [121/300], Train Loss: 0.001426
Validation Loss: 0.00146781
Epoch [122/300], Train Loss: 0.001419
Validation Loss: 0.00144457
Epoch [123/300], Train Loss: 0.001412
Validation Loss: 0.00145070
Epoch [124/300], Train Loss: 0.001421
Validation Loss: 0.00143509
Epoch [125/300], Train Loss: 0.001410
Validation Loss: 0.00142587
Epoch [126/300], Train Loss: 0.001407
Validation Loss: 0.00142468
Epoch [127/300], Train Loss: 0.001410
Validation Loss: 0.00144681
Epoch [128/300], Train Loss: 0.001398
Validation Loss: 0.00142660
Epoch [129/300], Train Loss: 0.001398
Validation Loss: 0.00144429
Epoch [130/300], Train Loss: 0.001408
Validation Loss: 0.00142343
Epoch [131/300], Train Loss: 0.001404
Validation Loss: 0.00142529
Epoch [132/300], Train Loss: 0.001395
Validation Loss: 0.00140581
Epoch [133/300], Train Loss: 0.001388
Validation Loss: 0.00141575
Epoch [134/300], Train Loss: 0.001386
Validation Loss: 0.00140747
Epoch [135/300], Train Loss: 0.001388
Validation Loss: 0.00143361
Epoch [136/300], Train Loss: 0.001376
Validation Loss: 0.00140047
Epoch [137/300], Train Loss: 0.001378
Validation Loss: 0.00141598
Epoch [138/300], Train Loss: 0.001370
Validation Loss: 0.00139697
Epoch [139/300], Train Loss: 0.001390
Validation Loss: 0.00140068
Epoch [140/300], Train Loss: 0.001367
Validation Loss: 0.00138160
Epoch [141/300], Train Loss: 0.001363
Validation Loss: 0.00141143
Epoch [142/300], Train Loss: 0.001362
Validation Loss: 0.00139490
Epoch [143/300], Train Loss: 0.001358
Validation Loss: 0.00138656
Epoch [144/300], Train Loss: 0.001356
Validation Loss: 0.00138137
Epoch [145/300], Train Loss: 0.001347
Validation Loss: 0.00139539
Epoch [146/300], Train Loss: 0.001343
Validation Loss: 0.00137000
Epoch [147/300], Train Loss: 0.001342
Validation Loss: 0.00136185
Epoch [148/300], Train Loss: 0.001338
Validation Loss: 0.00138085
Epoch [149/300], Train Loss: 0.001327
Validation Loss: 0.00136465
Epoch [150/300], Train Loss: 0.001319
Validation Loss: 0.00135710
Epoch [151/300], Train Loss: 0.001352
Validation Loss: 0.00135656
Epoch [152/300], Train Loss: 0.001331
Validation Loss: 0.00137702
Epoch [153/300], Train Loss: 0.001337
Validation Loss: 0.00133390
Epoch [154/300], Train Loss: 0.001309
Validation Loss: 0.00133087
Epoch [155/300], Train Loss: 0.001302
Validation Loss: 0.00132605
Epoch [156/300], Train Loss: 0.001294
Validation Loss: 0.00130937
Epoch [157/300], Train Loss: 0.001303
Validation Loss: 0.00130555
Epoch [158/300], Train Loss: 0.001285
Validation Loss: 0.00130151
Epoch [159/300], Train Loss: 0.001279
Validation Loss: 0.00129786
Epoch [160/300], Train Loss: 0.001271
Validation Loss: 0.00126874
Epoch [161/300], Train Loss: 0.001261
Validation Loss: 0.00125799
Epoch [162/300], Train Loss: 0.001263
Validation Loss: 0.00125694
Epoch [163/300], Train Loss: 0.001236
Validation Loss: 0.00124967
Epoch [164/300], Train Loss: 0.001241
Validation Loss: 0.00123000
Epoch [165/300], Train Loss: 0.001221
Validation Loss: 0.00123302
Epoch [166/300], Train Loss: 0.001201
Validation Loss: 0.00120839
Epoch [167/300], Train Loss: 0.001197
Validation Loss: 0.00122599
Epoch [168/300], Train Loss: 0.001191
Validation Loss: 0.00119075
Epoch [169/300], Train Loss: 0.001199
Validation Loss: 0.00117573
Epoch [170/300], Train Loss: 0.001165
Validation Loss: 0.00117178
Epoch [171/300], Train Loss: 0.001147
Validation Loss: 0.00112741
Epoch [172/300], Train Loss: 0.001136
Validation Loss: 0.00112029
Epoch [173/300], Train Loss: 0.001125
Validation Loss: 0.00109377
Epoch [174/300], Train Loss: 0.001114
Validation Loss: 0.00108845
Epoch [175/300], Train Loss: 0.001098
Validation Loss: 0.00108063
Epoch [176/300], Train Loss: 0.001101
Validation Loss: 0.00118885
Epoch [177/300], Train Loss: 0.001174
Validation Loss: 0.00107775
Epoch [178/300], Train Loss: 0.001108
Validation Loss: 0.00103549
Epoch [179/300], Train Loss: 0.001072
Validation Loss: 0.00103157
Epoch [180/300], Train Loss: 0.001043
Validation Loss: 0.00100154
Epoch [181/300], Train Loss: 0.001024
Validation Loss: 0.00098074
Epoch [182/300], Train Loss: 0.001025
Validation Loss: 0.00103673
Epoch [183/300], Train Loss: 0.001084
Validation Loss: 0.00099471
Epoch [184/300], Train Loss: 0.001044
Validation Loss: 0.00095591
Epoch [185/300], Train Loss: 0.001021
Validation Loss: 0.00095417
Epoch [186/300], Train Loss: 0.001001
Validation Loss: 0.00093550
Epoch [187/300], Train Loss: 0.000989
Validation Loss: 0.00093217
Epoch [188/300], Train Loss: 0.000972
Validation Loss: 0.00092474
Epoch [189/300], Train Loss: 0.000999
Validation Loss: 0.00095173
Epoch [190/300], Train Loss: 0.001021
Validation Loss: 0.00091210
Epoch [191/300], Train Loss: 0.000986
Validation Loss: 0.00090037
Epoch [192/300], Train Loss: 0.000971
Validation Loss: 0.00089757
Epoch [193/300], Train Loss: 0.000957
Validation Loss: 0.00091794
Epoch [194/300], Train Loss: 0.000949
Validation Loss: 0.00091906
Epoch [195/300], Train Loss: 0.000943
Validation Loss: 0.00088574
Epoch [196/300], Train Loss: 0.000935
Validation Loss: 0.00088899
Epoch [197/300], Train Loss: 0.000926
Validation Loss: 0.00086057
Epoch [198/300], Train Loss: 0.000917
Validation Loss: 0.00085271
Epoch [199/300], Train Loss: 0.000925
Validation Loss: 0.00085119
Epoch [200/300], Train Loss: 0.000913
Validation Loss: 0.00084575
Epoch [201/300], Train Loss: 0.000906
Validation Loss: 0.00086572
Epoch [202/300], Train Loss: 0.000907
Validation Loss: 0.00084146
Epoch [203/300], Train Loss: 0.000907
Validation Loss: 0.00083865
Epoch [204/300], Train Loss: 0.000907
Validation Loss: 0.00083830
Epoch [205/300], Train Loss: 0.000893
Validation Loss: 0.00084713
Epoch [206/300], Train Loss: 0.000898
Validation Loss: 0.00083485
Epoch [207/300], Train Loss: 0.000899
Validation Loss: 0.00082574
Epoch [208/300], Train Loss: 0.000893
Validation Loss: 0.00086530
Epoch [209/300], Train Loss: 0.000892
Validation Loss: 0.00082974
Epoch [210/300], Train Loss: 0.000884
Validation Loss: 0.00081685
Epoch [211/300], Train Loss: 0.000903
Validation Loss: 0.00082953
Epoch [212/300], Train Loss: 0.000888
Validation Loss: 0.00082355
Epoch [213/300], Train Loss: 0.000889
Validation Loss: 0.00081821
Epoch [214/300], Train Loss: 0.000874
Validation Loss: 0.00081810
Epoch [215/300], Train Loss: 0.000869
Validation Loss: 0.00081418
Epoch [216/300], Train Loss: 0.000869
Validation Loss: 0.00081191
Epoch [217/300], Train Loss: 0.000866
Validation Loss: 0.00080126
Epoch [218/300], Train Loss: 0.000859
Validation Loss: 0.00081682
Epoch [219/300], Train Loss: 0.000862
Validation Loss: 0.00079755
Epoch [220/300], Train Loss: 0.000861
Validation Loss: 0.00079979
Epoch [221/300], Train Loss: 0.000858
Validation Loss: 0.00081214
Epoch [222/300], Train Loss: 0.000854
Validation Loss: 0.00081955
Epoch [223/300], Train Loss: 0.000873
Validation Loss: 0.00080906
Epoch [224/300], Train Loss: 0.000855
Validation Loss: 0.00078762
Epoch [225/300], Train Loss: 0.000851
Validation Loss: 0.00079724
Epoch [226/300], Train Loss: 0.000847
Validation Loss: 0.00078781
Epoch [227/300], Train Loss: 0.000841
Validation Loss: 0.00078574
Epoch [228/300], Train Loss: 0.000840
Validation Loss: 0.00078863
Epoch [229/300], Train Loss: 0.000843
Validation Loss: 0.00078455
Epoch [230/300], Train Loss: 0.000851
Validation Loss: 0.00077878
Epoch [231/300], Train Loss: 0.000854
Validation Loss: 0.00078868
Epoch [232/300], Train Loss: 0.000843
Validation Loss: 0.00077497
Epoch [233/300], Train Loss: 0.000834
Validation Loss: 0.00077517
Epoch [234/300], Train Loss: 0.000835
Validation Loss: 0.00076943
Epoch [235/300], Train Loss: 0.000833
Validation Loss: 0.00077609
Epoch [236/300], Train Loss: 0.000842
Validation Loss: 0.00078659
Epoch [237/300], Train Loss: 0.000841
Validation Loss: 0.00076709
Epoch [238/300], Train Loss: 0.000833
Validation Loss: 0.00077367
Epoch [239/300], Train Loss: 0.000831
Validation Loss: 0.00076690
Epoch [240/300], Train Loss: 0.000828
Validation Loss: 0.00076886
Epoch [241/300], Train Loss: 0.000840
Validation Loss: 0.00079013
Epoch [242/300], Train Loss: 0.000826
Validation Loss: 0.00077079
Epoch [243/300], Train Loss: 0.000835
Validation Loss: 0.00083820
Epoch [244/300], Train Loss: 0.000908
Validation Loss: 0.00079107
Epoch [245/300], Train Loss: 0.000858
Validation Loss: 0.00077975
Epoch [246/300], Train Loss: 0.000840
Validation Loss: 0.00078586
Epoch [247/300], Train Loss: 0.000825
Validation Loss: 0.00076955
Epoch [248/300], Train Loss: 0.000822
Validation Loss: 0.00076910
Epoch [249/300], Train Loss: 0.000820
Validation Loss: 0.00075989
Epoch [250/300], Train Loss: 0.000813
Validation Loss: 0.00076157
Epoch [251/300], Train Loss: 0.000816
Validation Loss: 0.00076483
Epoch [252/300], Train Loss: 0.000816
Validation Loss: 0.00075911
Epoch [253/300], Train Loss: 0.000830
Validation Loss: 0.00077348
Epoch [254/300], Train Loss: 0.000812
Validation Loss: 0.00075829
Epoch [255/300], Train Loss: 0.000820
Validation Loss: 0.00076647
Epoch [256/300], Train Loss: 0.000821
Validation Loss: 0.00076275
Epoch [257/300], Train Loss: 0.000811
Validation Loss: 0.00076585
Epoch [258/300], Train Loss: 0.000811
Validation Loss: 0.00083398
Epoch [259/300], Train Loss: 0.000831
Validation Loss: 0.00075451
Epoch [260/300], Train Loss: 0.000810
Validation Loss: 0.00077571
Epoch [261/300], Train Loss: 0.000809
Validation Loss: 0.00079391
Epoch [262/300], Train Loss: 0.000859
Validation Loss: 0.00076548
Epoch [263/300], Train Loss: 0.000824
Validation Loss: 0.00075527
Epoch [264/300], Train Loss: 0.000812
Validation Loss: 0.00075315
Epoch [265/300], Train Loss: 0.000807
Validation Loss: 0.00076126
Epoch [266/300], Train Loss: 0.000801
Validation Loss: 0.00076999
Epoch [267/300], Train Loss: 0.000803
Validation Loss: 0.00075857
Epoch [268/300], Train Loss: 0.000801
Validation Loss: 0.00075015
Epoch [269/300], Train Loss: 0.000805
Validation Loss: 0.00078416
Epoch [270/300], Train Loss: 0.000810
Validation Loss: 0.00077821
Epoch [271/300], Train Loss: 0.000799
Validation Loss: 0.00078753
Epoch [272/300], Train Loss: 0.000812
Validation Loss: 0.00076606
Epoch [273/300], Train Loss: 0.000799
Validation Loss: 0.00075859
Epoch [274/300], Train Loss: 0.000794
Validation Loss: 0.00074738
Epoch [275/300], Train Loss: 0.000795
Validation Loss: 0.00074795
Epoch [276/300], Train Loss: 0.000793
Validation Loss: 0.00074713
Epoch [277/300], Train Loss: 0.000791
Validation Loss: 0.00075262
Epoch [278/300], Train Loss: 0.000792
Validation Loss: 0.00075160
Epoch [279/300], Train Loss: 0.000793
Validation Loss: 0.00074533
Epoch [280/300], Train Loss: 0.000795
Validation Loss: 0.00075122
Epoch [281/300], Train Loss: 0.000790
Validation Loss: 0.00074762
Epoch [282/300], Train Loss: 0.000794
Validation Loss: 0.00074277
Epoch [283/300], Train Loss: 0.000787
Validation Loss: 0.00074377
Epoch [284/300], Train Loss: 0.000788
Validation Loss: 0.00074239
Epoch [285/300], Train Loss: 0.000790
Validation Loss: 0.00074685
Epoch [286/300], Train Loss: 0.000789
Validation Loss: 0.00074638
Epoch [287/300], Train Loss: 0.000790
Validation Loss: 0.00074218
Epoch [288/300], Train Loss: 0.000792
Validation Loss: 0.00075690
Epoch [289/300], Train Loss: 0.000789
Validation Loss: 0.00076288
Epoch [290/300], Train Loss: 0.000787
Validation Loss: 0.00079183
Epoch [291/300], Train Loss: 0.000793
Validation Loss: 0.00074266
Epoch [292/300], Train Loss: 0.000788
Validation Loss: 0.00074092
Epoch [293/300], Train Loss: 0.000784
Validation Loss: 0.00073855
Epoch [294/300], Train Loss: 0.000781
Validation Loss: 0.00074410
Epoch [295/300], Train Loss: 0.000781
Validation Loss: 0.00074670
Epoch [296/300], Train Loss: 0.000787
Validation Loss: 0.00074202
Epoch [297/300], Train Loss: 0.000780
Validation Loss: 0.00073778
Epoch [298/300], Train Loss: 0.000782
Validation Loss: 0.00073669
Epoch [299/300], Train Loss: 0.000783
Validation Loss: 0.00073293
Epoch [300/300], Train Loss: 0.000780
Validation Loss: 0.00075374

Evaluating model for: Freezer
Run 30/72 completed in 2359.84 seconds with: {'MAE': np.float32(24.4765), 'MSE': np.float32(1164.4434), 'RMSE': np.float32(34.12394), 'SAE': np.float32(0.05103743), 'NDE': np.float32(0.26421565)}

Run 31/72: hidden=256, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Freezer
Dataset length: 7026 windows

Epoch [1/300], Train Loss: 0.006794
Validation Loss: 0.00586771
Epoch [2/300], Train Loss: 0.005936
Validation Loss: 0.00580902
Epoch [3/300], Train Loss: 0.005725
Validation Loss: 0.00495344
Epoch [4/300], Train Loss: 0.004205
Validation Loss: 0.00376867
Epoch [5/300], Train Loss: 0.003067
Validation Loss: 0.00268982
Epoch [6/300], Train Loss: 0.002442
Validation Loss: 0.00243673
Epoch [7/300], Train Loss: 0.002199
Validation Loss: 0.00212542
Epoch [8/300], Train Loss: 0.002055
Validation Loss: 0.00207085
Epoch [9/300], Train Loss: 0.001985
Validation Loss: 0.00193548
Epoch [10/300], Train Loss: 0.001940
Validation Loss: 0.00189188
Epoch [11/300], Train Loss: 0.001913
Validation Loss: 0.00190706
Epoch [12/300], Train Loss: 0.001906
Validation Loss: 0.00185392
Epoch [13/300], Train Loss: 0.001872
Validation Loss: 0.00183895
Epoch [14/300], Train Loss: 0.001859
Validation Loss: 0.00186082
Epoch [15/300], Train Loss: 0.001878
Validation Loss: 0.00184611
Epoch [16/300], Train Loss: 0.001844
Validation Loss: 0.00185840
Epoch [17/300], Train Loss: 0.001819
Validation Loss: 0.00179414
Epoch [18/300], Train Loss: 0.001814
Validation Loss: 0.00183923
Epoch [19/300], Train Loss: 0.001791
Validation Loss: 0.00176114
Epoch [20/300], Train Loss: 0.001788
Validation Loss: 0.00175037
Epoch [21/300], Train Loss: 0.001793
Validation Loss: 0.00173858
Epoch [22/300], Train Loss: 0.001767
Validation Loss: 0.00172874
Epoch [23/300], Train Loss: 0.001756
Validation Loss: 0.00173854
Epoch [24/300], Train Loss: 0.001754
Validation Loss: 0.00171894
Epoch [25/300], Train Loss: 0.001747
Validation Loss: 0.00172545
Epoch [26/300], Train Loss: 0.001730
Validation Loss: 0.00171994
Epoch [27/300], Train Loss: 0.001734
Validation Loss: 0.00168862
Epoch [28/300], Train Loss: 0.001738
Validation Loss: 0.00170885
Epoch [29/300], Train Loss: 0.001724
Validation Loss: 0.00166539
Epoch [30/300], Train Loss: 0.001703
Validation Loss: 0.00166438
Epoch [31/300], Train Loss: 0.001694
Validation Loss: 0.00170250
Epoch [32/300], Train Loss: 0.001692
Validation Loss: 0.00165006
Epoch [33/300], Train Loss: 0.001699
Validation Loss: 0.00166133
Epoch [34/300], Train Loss: 0.001661
Validation Loss: 0.00164873
Epoch [35/300], Train Loss: 0.001661
Validation Loss: 0.00165789
Epoch [36/300], Train Loss: 0.001646
Validation Loss: 0.00161906
Epoch [37/300], Train Loss: 0.001649
Validation Loss: 0.00164199
Epoch [38/300], Train Loss: 0.001637
Validation Loss: 0.00163141
Epoch [39/300], Train Loss: 0.001628
Validation Loss: 0.00165327
Epoch [40/300], Train Loss: 0.001631
Validation Loss: 0.00164444
Epoch [41/300], Train Loss: 0.001637
Validation Loss: 0.00163146
Epoch [42/300], Train Loss: 0.001619
Validation Loss: 0.00162386
Epoch [43/300], Train Loss: 0.001608
Validation Loss: 0.00159879
Epoch [44/300], Train Loss: 0.001591
Validation Loss: 0.00160409
Epoch [45/300], Train Loss: 0.001595
Validation Loss: 0.00160375
Epoch [46/300], Train Loss: 0.001616
Validation Loss: 0.00161272
Epoch [47/300], Train Loss: 0.001596
Validation Loss: 0.00159256
Epoch [48/300], Train Loss: 0.001581
Validation Loss: 0.00161461
Epoch [49/300], Train Loss: 0.001604
Validation Loss: 0.00161750
Epoch [50/300], Train Loss: 0.001588
Validation Loss: 0.00161214
Epoch [51/300], Train Loss: 0.001574
Validation Loss: 0.00163314
Epoch [52/300], Train Loss: 0.001582
Validation Loss: 0.00158759
Epoch [53/300], Train Loss: 0.001577
Validation Loss: 0.00157253
Epoch [54/300], Train Loss: 0.001559
Validation Loss: 0.00158197
Epoch [55/300], Train Loss: 0.001551
Validation Loss: 0.00164778
Epoch [56/300], Train Loss: 0.001551
Validation Loss: 0.00158864
Epoch [57/300], Train Loss: 0.001550
Validation Loss: 0.00160044
Epoch [58/300], Train Loss: 0.001567
Validation Loss: 0.00158749
Epoch [59/300], Train Loss: 0.001556
Validation Loss: 0.00155998
Epoch [60/300], Train Loss: 0.001550
Validation Loss: 0.00156978
Epoch [61/300], Train Loss: 0.001545
Validation Loss: 0.00156330
Epoch [62/300], Train Loss: 0.001554
Validation Loss: 0.00156530
Epoch [63/300], Train Loss: 0.001536
Validation Loss: 0.00155006
Epoch [64/300], Train Loss: 0.001542
Validation Loss: 0.00156946
Epoch [65/300], Train Loss: 0.001533
Validation Loss: 0.00158516
Epoch [66/300], Train Loss: 0.001553
Validation Loss: 0.00155795
Epoch [67/300], Train Loss: 0.001537
Validation Loss: 0.00156719
Epoch [68/300], Train Loss: 0.001525
Validation Loss: 0.00159651
Epoch [69/300], Train Loss: 0.001533
Validation Loss: 0.00155533
Epoch [70/300], Train Loss: 0.001518
Validation Loss: 0.00153408
Epoch [71/300], Train Loss: 0.001515
Validation Loss: 0.00165362
Epoch [72/300], Train Loss: 0.001536
Validation Loss: 0.00156428
Epoch [73/300], Train Loss: 0.001517
Validation Loss: 0.00157913
Epoch [74/300], Train Loss: 0.001517
Validation Loss: 0.00155835
Epoch [75/300], Train Loss: 0.001516
Validation Loss: 0.00154474
Epoch [76/300], Train Loss: 0.001517
Validation Loss: 0.00156882
Epoch [77/300], Train Loss: 0.001512
Validation Loss: 0.00154754
Epoch [78/300], Train Loss: 0.001512
Validation Loss: 0.00155065
Epoch [79/300], Train Loss: 0.001507
Validation Loss: 0.00155273
Epoch [80/300], Train Loss: 0.001511
Validation Loss: 0.00152917
Epoch [81/300], Train Loss: 0.001509
Validation Loss: 0.00153160
Epoch [82/300], Train Loss: 0.001500
Validation Loss: 0.00154328
Epoch [83/300], Train Loss: 0.001500
Validation Loss: 0.00153893
Epoch [84/300], Train Loss: 0.001505
Validation Loss: 0.00152357
Epoch [85/300], Train Loss: 0.001498
Validation Loss: 0.00152840
Epoch [86/300], Train Loss: 0.001491
Validation Loss: 0.00154910
Epoch [87/300], Train Loss: 0.001492
Validation Loss: 0.00152442
Epoch [88/300], Train Loss: 0.001518
Validation Loss: 0.00160462
Epoch [89/300], Train Loss: 0.001505
Validation Loss: 0.00151642
Epoch [90/300], Train Loss: 0.001553
Validation Loss: 0.00158381
Epoch [91/300], Train Loss: 0.001537
Validation Loss: 0.00157898
Epoch [92/300], Train Loss: 0.001529
Validation Loss: 0.00153626
Epoch [93/300], Train Loss: 0.001502
Validation Loss: 0.00152565
Epoch [94/300], Train Loss: 0.001504
Validation Loss: 0.00151542
Epoch [95/300], Train Loss: 0.001492
Validation Loss: 0.00152109
Epoch [96/300], Train Loss: 0.001487
Validation Loss: 0.00151627
Epoch [97/300], Train Loss: 0.001482
Validation Loss: 0.00150761
Epoch [98/300], Train Loss: 0.001477
Validation Loss: 0.00150120
Epoch [99/300], Train Loss: 0.001478
Validation Loss: 0.00150739
Epoch [100/300], Train Loss: 0.001480
Validation Loss: 0.00151852
Epoch [101/300], Train Loss: 0.001476
Validation Loss: 0.00150793
Epoch [102/300], Train Loss: 0.001502
Validation Loss: 0.00151442
Epoch [103/300], Train Loss: 0.001484
Validation Loss: 0.00151144
Epoch [104/300], Train Loss: 0.001471
Validation Loss: 0.00150372
Epoch [105/300], Train Loss: 0.001468
Validation Loss: 0.00149561
Epoch [106/300], Train Loss: 0.001463
Validation Loss: 0.00151769
Epoch [107/300], Train Loss: 0.001466
Validation Loss: 0.00152050
Epoch [108/300], Train Loss: 0.001464
Validation Loss: 0.00150816
Epoch [109/300], Train Loss: 0.001456
Validation Loss: 0.00151398
Epoch [110/300], Train Loss: 0.001461
Validation Loss: 0.00150890
Epoch [111/300], Train Loss: 0.001463
Validation Loss: 0.00148778
Epoch [112/300], Train Loss: 0.001475
Validation Loss: 0.00152109
Epoch [113/300], Train Loss: 0.001473
Validation Loss: 0.00151802
Epoch [114/300], Train Loss: 0.001458
Validation Loss: 0.00156507
Epoch [115/300], Train Loss: 0.001461
Validation Loss: 0.00152150
Epoch [116/300], Train Loss: 0.001450
Validation Loss: 0.00153583
Epoch [117/300], Train Loss: 0.001452
Validation Loss: 0.00163230
Epoch [118/300], Train Loss: 0.001458
Validation Loss: 0.00149303
Epoch [119/300], Train Loss: 0.001450
Validation Loss: 0.00149979
Epoch [120/300], Train Loss: 0.001447
Validation Loss: 0.00150684
Epoch [121/300], Train Loss: 0.001446
Validation Loss: 0.00149201
Early stopping triggered

Evaluating model for: Freezer
Run 31/72 completed in 1024.89 seconds with: {'MAE': np.float32(32.180477), 'MSE': np.float32(2283.6292), 'RMSE': np.float32(47.78733), 'SAE': np.float32(0.056457497), 'NDE': np.float32(0.37000886)}

Run 32/72: hidden=256, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Freezer
Dataset length: 7026 windows

Epoch [1/300], Train Loss: 0.008710
Validation Loss: 0.00602505
Epoch [2/300], Train Loss: 0.006072
Validation Loss: 0.00593381
Epoch [3/300], Train Loss: 0.006035
Validation Loss: 0.00588128
Epoch [4/300], Train Loss: 0.005233
Validation Loss: 0.00368281
Epoch [5/300], Train Loss: 0.003437
Validation Loss: 0.00322551
Epoch [6/300], Train Loss: 0.003000
Validation Loss: 0.00285379
Epoch [7/300], Train Loss: 0.002695
Validation Loss: 0.00263938
Epoch [8/300], Train Loss: 0.002533
Validation Loss: 0.00242700
Epoch [9/300], Train Loss: 0.002345
Validation Loss: 0.00229768
Epoch [10/300], Train Loss: 0.002240
Validation Loss: 0.00215506
Epoch [11/300], Train Loss: 0.002110
Validation Loss: 0.00216318
Epoch [12/300], Train Loss: 0.002045
Validation Loss: 0.00200733
Epoch [13/300], Train Loss: 0.001992
Validation Loss: 0.00197530
Epoch [14/300], Train Loss: 0.001981
Validation Loss: 0.00203197
Epoch [15/300], Train Loss: 0.001962
Validation Loss: 0.00192064
Epoch [16/300], Train Loss: 0.001949
Validation Loss: 0.00200766
Epoch [17/300], Train Loss: 0.001938
Validation Loss: 0.00195087
Epoch [18/300], Train Loss: 0.001915
Validation Loss: 0.00189493
Epoch [19/300], Train Loss: 0.001881
Validation Loss: 0.00185972
Epoch [20/300], Train Loss: 0.001858
Validation Loss: 0.00182827
Epoch [21/300], Train Loss: 0.001855
Validation Loss: 0.00184059
Epoch [22/300], Train Loss: 0.001825
Validation Loss: 0.00180315
Epoch [23/300], Train Loss: 0.001816
Validation Loss: 0.00180107
Epoch [24/300], Train Loss: 0.001797
Validation Loss: 0.00177058
Epoch [25/300], Train Loss: 0.001788
Validation Loss: 0.00177895
Epoch [26/300], Train Loss: 0.001771
Validation Loss: 0.00174287
Epoch [27/300], Train Loss: 0.001764
Validation Loss: 0.00177546
Epoch [28/300], Train Loss: 0.001766
Validation Loss: 0.00179048
Epoch [29/300], Train Loss: 0.001745
Validation Loss: 0.00173305
Epoch [30/300], Train Loss: 0.001735
Validation Loss: 0.00172868
Epoch [31/300], Train Loss: 0.001739
Validation Loss: 0.00174084
Epoch [32/300], Train Loss: 0.001740
Validation Loss: 0.00171560
Epoch [33/300], Train Loss: 0.001717
Validation Loss: 0.00171575
Epoch [34/300], Train Loss: 0.001699
Validation Loss: 0.00170895
Epoch [35/300], Train Loss: 0.001678
Validation Loss: 0.00172137
Epoch [36/300], Train Loss: 0.001663
Validation Loss: 0.00168574
Epoch [37/300], Train Loss: 0.001678
Validation Loss: 0.00165368
Epoch [38/300], Train Loss: 0.001662
Validation Loss: 0.00166939
Epoch [39/300], Train Loss: 0.001643
Validation Loss: 0.00166787
Epoch [40/300], Train Loss: 0.001637
Validation Loss: 0.00162723
Epoch [41/300], Train Loss: 0.001634
Validation Loss: 0.00163921
Epoch [42/300], Train Loss: 0.001632
Validation Loss: 0.00165271
Epoch [43/300], Train Loss: 0.001631
Validation Loss: 0.00163060
Epoch [44/300], Train Loss: 0.001656
Validation Loss: 0.00165513
Epoch [45/300], Train Loss: 0.001619
Validation Loss: 0.00160625
Epoch [46/300], Train Loss: 0.001619
Validation Loss: 0.00161554
Epoch [47/300], Train Loss: 0.001616
Validation Loss: 0.00162528
Epoch [48/300], Train Loss: 0.001598
Validation Loss: 0.00160313
Epoch [49/300], Train Loss: 0.001609
Validation Loss: 0.00163867
Epoch [50/300], Train Loss: 0.001599
Validation Loss: 0.00160526
Epoch [51/300], Train Loss: 0.001585
Validation Loss: 0.00162884
Epoch [52/300], Train Loss: 0.001582
Validation Loss: 0.00160941
Epoch [53/300], Train Loss: 0.001576
Validation Loss: 0.00158927
Epoch [54/300], Train Loss: 0.001567
Validation Loss: 0.00159934
Epoch [55/300], Train Loss: 0.001558
Validation Loss: 0.00163313
Epoch [56/300], Train Loss: 0.001563
Validation Loss: 0.00158864
Epoch [57/300], Train Loss: 0.001555
Validation Loss: 0.00159354
Epoch [58/300], Train Loss: 0.001555
Validation Loss: 0.00158967
Epoch [59/300], Train Loss: 0.001574
Validation Loss: 0.00157249
Epoch [60/300], Train Loss: 0.001555
Validation Loss: 0.00156420
Epoch [61/300], Train Loss: 0.001545
Validation Loss: 0.00160729
Epoch [62/300], Train Loss: 0.001540
Validation Loss: 0.00157496
Epoch [63/300], Train Loss: 0.001537
Validation Loss: 0.00157747
Epoch [64/300], Train Loss: 0.001548
Validation Loss: 0.00161011
Epoch [65/300], Train Loss: 0.001536
Validation Loss: 0.00159065
Epoch [66/300], Train Loss: 0.001538
Validation Loss: 0.00157793
Epoch [67/300], Train Loss: 0.001535
Validation Loss: 0.00155196
Epoch [68/300], Train Loss: 0.001518
Validation Loss: 0.00157458
Epoch [69/300], Train Loss: 0.001529
Validation Loss: 0.00155888
Epoch [70/300], Train Loss: 0.001520
Validation Loss: 0.00155232
Epoch [71/300], Train Loss: 0.001524
Validation Loss: 0.00161638
Epoch [72/300], Train Loss: 0.001528
Validation Loss: 0.00154088
Epoch [73/300], Train Loss: 0.001506
Validation Loss: 0.00157764
Epoch [74/300], Train Loss: 0.001513
Validation Loss: 0.00155612
Epoch [75/300], Train Loss: 0.001511
Validation Loss: 0.00154056
Epoch [76/300], Train Loss: 0.001507
Validation Loss: 0.00157386
Epoch [77/300], Train Loss: 0.001517
Validation Loss: 0.00154461
Epoch [78/300], Train Loss: 0.001497
Validation Loss: 0.00153976
Epoch [79/300], Train Loss: 0.001501
Validation Loss: 0.00155873
Epoch [80/300], Train Loss: 0.001499
Validation Loss: 0.00152961
Epoch [81/300], Train Loss: 0.001529
Validation Loss: 0.00167256
Epoch [82/300], Train Loss: 0.001568
Validation Loss: 0.00156377
Epoch [83/300], Train Loss: 0.001536
Validation Loss: 0.00155883
Epoch [84/300], Train Loss: 0.001517
Validation Loss: 0.00153487
Epoch [85/300], Train Loss: 0.001506
Validation Loss: 0.00152267
Epoch [86/300], Train Loss: 0.001506
Validation Loss: 0.00158240
Epoch [87/300], Train Loss: 0.001504
Validation Loss: 0.00151537
Epoch [88/300], Train Loss: 0.001511
Validation Loss: 0.00156356
Epoch [89/300], Train Loss: 0.001506
Validation Loss: 0.00152826
Epoch [90/300], Train Loss: 0.001489
Validation Loss: 0.00155321
Epoch [91/300], Train Loss: 0.001480
Validation Loss: 0.00154216
Epoch [92/300], Train Loss: 0.001486
Validation Loss: 0.00151161
Epoch [93/300], Train Loss: 0.001477
Validation Loss: 0.00151461
Epoch [94/300], Train Loss: 0.001484
Validation Loss: 0.00152282
Epoch [95/300], Train Loss: 0.001487
Validation Loss: 0.00153383
Epoch [96/300], Train Loss: 0.001481
Validation Loss: 0.00153416
Epoch [97/300], Train Loss: 0.001477
Validation Loss: 0.00150299
Epoch [98/300], Train Loss: 0.001476
Validation Loss: 0.00150771
Epoch [99/300], Train Loss: 0.001468
Validation Loss: 0.00150079
Epoch [100/300], Train Loss: 0.001471
Validation Loss: 0.00153096
Epoch [101/300], Train Loss: 0.001473
Validation Loss: 0.00150233
Epoch [102/300], Train Loss: 0.001475
Validation Loss: 0.00149598
Epoch [103/300], Train Loss: 0.001471
Validation Loss: 0.00153461
Epoch [104/300], Train Loss: 0.001467
Validation Loss: 0.00153284
Epoch [105/300], Train Loss: 0.001491
Validation Loss: 0.00150757
Epoch [106/300], Train Loss: 0.001464
Validation Loss: 0.00151021
Epoch [107/300], Train Loss: 0.001469
Validation Loss: 0.00150525
Epoch [108/300], Train Loss: 0.001458
Validation Loss: 0.00149769
Epoch [109/300], Train Loss: 0.001453
Validation Loss: 0.00152282
Epoch [110/300], Train Loss: 0.001456
Validation Loss: 0.00149636
Epoch [111/300], Train Loss: 0.001461
Validation Loss: 0.00149928
Epoch [112/300], Train Loss: 0.001452
Validation Loss: 0.00150501
Early stopping triggered

Evaluating model for: Freezer
Run 32/72 completed in 1087.57 seconds with: {'MAE': np.float32(32.156387), 'MSE': np.float32(2297.8254), 'RMSE': np.float32(47.93564), 'SAE': np.float32(0.032810315), 'NDE': np.float32(0.3711571)}

Run 33/72: hidden=256, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Freezer
Dataset length: 4614 windows

Epoch [1/300], Train Loss: 0.008489
Validation Loss: 0.00605340
Epoch [2/300], Train Loss: 0.005978
Validation Loss: 0.00552535
Epoch [3/300], Train Loss: 0.005686
Validation Loss: 0.00523124
Epoch [4/300], Train Loss: 0.005130
Validation Loss: 0.00431452
Epoch [5/300], Train Loss: 0.004025
Validation Loss: 0.00362745
Epoch [6/300], Train Loss: 0.003479
Validation Loss: 0.00324290
Epoch [7/300], Train Loss: 0.003029
Validation Loss: 0.00275517
Epoch [8/300], Train Loss: 0.002552
Validation Loss: 0.00249053
Epoch [9/300], Train Loss: 0.002390
Validation Loss: 0.00227402
Epoch [10/300], Train Loss: 0.002264
Validation Loss: 0.00219334
Epoch [11/300], Train Loss: 0.002195
Validation Loss: 0.00213725
Epoch [12/300], Train Loss: 0.002131
Validation Loss: 0.00205379
Epoch [13/300], Train Loss: 0.002076
Validation Loss: 0.00198893
Epoch [14/300], Train Loss: 0.002023
Validation Loss: 0.00193705
Epoch [15/300], Train Loss: 0.001985
Validation Loss: 0.00189159
Epoch [16/300], Train Loss: 0.001978
Validation Loss: 0.00188761
Epoch [17/300], Train Loss: 0.001936
Validation Loss: 0.00182157
Epoch [18/300], Train Loss: 0.001883
Validation Loss: 0.00179191
Epoch [19/300], Train Loss: 0.001865
Validation Loss: 0.00177368
Epoch [20/300], Train Loss: 0.001844
Validation Loss: 0.00174206
Epoch [21/300], Train Loss: 0.001816
Validation Loss: 0.00172301
Epoch [22/300], Train Loss: 0.001799
Validation Loss: 0.00169443
Epoch [23/300], Train Loss: 0.001805
Validation Loss: 0.00168785
Epoch [24/300], Train Loss: 0.001801
Validation Loss: 0.00168651
Epoch [25/300], Train Loss: 0.001772
Validation Loss: 0.00166924
Epoch [26/300], Train Loss: 0.001751
Validation Loss: 0.00165430
Epoch [27/300], Train Loss: 0.001741
Validation Loss: 0.00164233
Epoch [28/300], Train Loss: 0.001735
Validation Loss: 0.00164010
Epoch [29/300], Train Loss: 0.001725
Validation Loss: 0.00165072
Epoch [30/300], Train Loss: 0.001716
Validation Loss: 0.00164066
Epoch [31/300], Train Loss: 0.001722
Validation Loss: 0.00162366
Epoch [32/300], Train Loss: 0.001711
Validation Loss: 0.00160579
Epoch [33/300], Train Loss: 0.001696
Validation Loss: 0.00162350
Epoch [34/300], Train Loss: 0.001680
Validation Loss: 0.00158943
Epoch [35/300], Train Loss: 0.001679
Validation Loss: 0.00158134
Epoch [36/300], Train Loss: 0.001670
Validation Loss: 0.00157755
Epoch [37/300], Train Loss: 0.001657
Validation Loss: 0.00156979
Epoch [38/300], Train Loss: 0.001671
Validation Loss: 0.00160274
Epoch [39/300], Train Loss: 0.001653
Validation Loss: 0.00155732
Epoch [40/300], Train Loss: 0.001648
Validation Loss: 0.00155383
Epoch [41/300], Train Loss: 0.001656
Validation Loss: 0.00159256
Epoch [42/300], Train Loss: 0.001644
Validation Loss: 0.00154172
Epoch [43/300], Train Loss: 0.001628
Validation Loss: 0.00155849
Epoch [44/300], Train Loss: 0.001631
Validation Loss: 0.00153533
Epoch [45/300], Train Loss: 0.001639
Validation Loss: 0.00152519
Epoch [46/300], Train Loss: 0.001613
Validation Loss: 0.00152341
Epoch [47/300], Train Loss: 0.001615
Validation Loss: 0.00151664
Epoch [48/300], Train Loss: 0.001609
Validation Loss: 0.00151087
Epoch [49/300], Train Loss: 0.001604
Validation Loss: 0.00150291
Epoch [50/300], Train Loss: 0.001603
Validation Loss: 0.00152480
Epoch [51/300], Train Loss: 0.001596
Validation Loss: 0.00149357
Epoch [52/300], Train Loss: 0.001596
Validation Loss: 0.00153257
Epoch [53/300], Train Loss: 0.001607
Validation Loss: 0.00155981
Epoch [54/300], Train Loss: 0.001588
Validation Loss: 0.00148139
Epoch [55/300], Train Loss: 0.001572
Validation Loss: 0.00148626
Epoch [56/300], Train Loss: 0.001583
Validation Loss: 0.00149952
Epoch [57/300], Train Loss: 0.001570
Validation Loss: 0.00148093
Epoch [58/300], Train Loss: 0.001575
Validation Loss: 0.00149205
Epoch [59/300], Train Loss: 0.001563
Validation Loss: 0.00146752
Epoch [60/300], Train Loss: 0.001565
Validation Loss: 0.00146106
Epoch [61/300], Train Loss: 0.001555
Validation Loss: 0.00146872
Epoch [62/300], Train Loss: 0.001548
Validation Loss: 0.00145840
Epoch [63/300], Train Loss: 0.001550
Validation Loss: 0.00145760
Epoch [64/300], Train Loss: 0.001541
Validation Loss: 0.00146111
Epoch [65/300], Train Loss: 0.001547
Validation Loss: 0.00145316
Epoch [66/300], Train Loss: 0.001535
Validation Loss: 0.00144895
Epoch [67/300], Train Loss: 0.001541
Validation Loss: 0.00148194
Epoch [68/300], Train Loss: 0.001528
Validation Loss: 0.00144172
Epoch [69/300], Train Loss: 0.001525
Validation Loss: 0.00145518
Epoch [70/300], Train Loss: 0.001534
Validation Loss: 0.00145653
Epoch [71/300], Train Loss: 0.001539
Validation Loss: 0.00147207
Epoch [72/300], Train Loss: 0.001537
Validation Loss: 0.00144035
Epoch [73/300], Train Loss: 0.001522
Validation Loss: 0.00144273
Epoch [74/300], Train Loss: 0.001519
Validation Loss: 0.00144946
Epoch [75/300], Train Loss: 0.001517
Validation Loss: 0.00148162
Epoch [76/300], Train Loss: 0.001511
Validation Loss: 0.00142255
Epoch [77/300], Train Loss: 0.001498
Validation Loss: 0.00144250
Epoch [78/300], Train Loss: 0.001502
Validation Loss: 0.00142304
Epoch [79/300], Train Loss: 0.001497
Validation Loss: 0.00142492
Epoch [80/300], Train Loss: 0.001506
Validation Loss: 0.00142175
Epoch [81/300], Train Loss: 0.001488
Validation Loss: 0.00141713
Epoch [82/300], Train Loss: 0.001489
Validation Loss: 0.00141617
Epoch [83/300], Train Loss: 0.001482
Validation Loss: 0.00141375
Epoch [84/300], Train Loss: 0.001500
Validation Loss: 0.00141159
Epoch [85/300], Train Loss: 0.001485
Validation Loss: 0.00144522
Epoch [86/300], Train Loss: 0.001482
Validation Loss: 0.00141596
Epoch [87/300], Train Loss: 0.001473
Validation Loss: 0.00140373
Epoch [88/300], Train Loss: 0.001475
Validation Loss: 0.00140155
Epoch [89/300], Train Loss: 0.001469
Validation Loss: 0.00139665
Epoch [90/300], Train Loss: 0.001475
Validation Loss: 0.00140993
Epoch [91/300], Train Loss: 0.001487
Validation Loss: 0.00141986
Epoch [92/300], Train Loss: 0.001467
Validation Loss: 0.00139783
Epoch [93/300], Train Loss: 0.001462
Validation Loss: 0.00138485
Epoch [94/300], Train Loss: 0.001461
Validation Loss: 0.00139305
Epoch [95/300], Train Loss: 0.001457
Validation Loss: 0.00147684
Epoch [96/300], Train Loss: 0.001684
Validation Loss: 0.00153591
Epoch [97/300], Train Loss: 0.001576
Validation Loss: 0.00150479
Epoch [98/300], Train Loss: 0.001549
Validation Loss: 0.00149755
Epoch [99/300], Train Loss: 0.001545
Validation Loss: 0.00148118
Epoch [100/300], Train Loss: 0.001536
Validation Loss: 0.00148220
Epoch [101/300], Train Loss: 0.001531
Validation Loss: 0.00148966
Epoch [102/300], Train Loss: 0.001522
Validation Loss: 0.00147410
Epoch [103/300], Train Loss: 0.001526
Validation Loss: 0.00147223
Early stopping triggered

Evaluating model for: Freezer
Run 33/72 completed in 663.80 seconds with: {'MAE': np.float32(34.324795), 'MSE': np.float32(2547.6255), 'RMSE': np.float32(50.474007), 'SAE': np.float32(0.035928823), 'NDE': np.float32(0.3766598)}

Run 34/72: hidden=256, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Freezer
Dataset length: 4614 windows

Epoch [1/300], Train Loss: 0.007487
Validation Loss: 0.00594542
Epoch [2/300], Train Loss: 0.005957
Validation Loss: 0.00563867
Epoch [3/300], Train Loss: 0.005900
Validation Loss: 0.00557327
Epoch [4/300], Train Loss: 0.005815
Validation Loss: 0.00542356
Epoch [5/300], Train Loss: 0.005302
Validation Loss: 0.00429619
Epoch [6/300], Train Loss: 0.004314
Validation Loss: 0.00367341
Epoch [7/300], Train Loss: 0.003441
Validation Loss: 0.00294156
Epoch [8/300], Train Loss: 0.002689
Validation Loss: 0.00244320
Epoch [9/300], Train Loss: 0.002420
Validation Loss: 0.00226539
Epoch [10/300], Train Loss: 0.002253
Validation Loss: 0.00216782
Epoch [11/300], Train Loss: 0.002163
Validation Loss: 0.00209058
Epoch [12/300], Train Loss: 0.002109
Validation Loss: 0.00206899
Epoch [13/300], Train Loss: 0.002116
Validation Loss: 0.00211601
Epoch [14/300], Train Loss: 0.002967
Validation Loss: 0.00332592
Epoch [15/300], Train Loss: 0.002449
Validation Loss: 0.00223769
Epoch [16/300], Train Loss: 0.002205
Validation Loss: 0.00211993
Epoch [17/300], Train Loss: 0.002141
Validation Loss: 0.00206776
Epoch [18/300], Train Loss: 0.002087
Validation Loss: 0.00202518
Epoch [19/300], Train Loss: 0.002041
Validation Loss: 0.00199955
Epoch [20/300], Train Loss: 0.001994
Validation Loss: 0.00192631
Epoch [21/300], Train Loss: 0.001964
Validation Loss: 0.00191328
Epoch [22/300], Train Loss: 0.001931
Validation Loss: 0.00186221
Epoch [23/300], Train Loss: 0.001910
Validation Loss: 0.00183520
Epoch [24/300], Train Loss: 0.001887
Validation Loss: 0.00180415
Epoch [25/300], Train Loss: 0.001849
Validation Loss: 0.00178799
Epoch [26/300], Train Loss: 0.001828
Validation Loss: 0.00177442
Epoch [27/300], Train Loss: 0.001804
Validation Loss: 0.00174865
Epoch [28/300], Train Loss: 0.001797
Validation Loss: 0.00173984
Epoch [29/300], Train Loss: 0.001777
Validation Loss: 0.00173010
Epoch [30/300], Train Loss: 0.001776
Validation Loss: 0.00173965
Epoch [31/300], Train Loss: 0.001786
Validation Loss: 0.00170751
Epoch [32/300], Train Loss: 0.001768
Validation Loss: 0.00169432
Epoch [33/300], Train Loss: 0.001743
Validation Loss: 0.00168826
Epoch [34/300], Train Loss: 0.001730
Validation Loss: 0.00167064
Epoch [35/300], Train Loss: 0.001727
Validation Loss: 0.00165120
Epoch [36/300], Train Loss: 0.001708
Validation Loss: 0.00162110
Epoch [37/300], Train Loss: 0.001689
Validation Loss: 0.00160888
Epoch [38/300], Train Loss: 0.001692
Validation Loss: 0.00161091
Epoch [39/300], Train Loss: 0.001677
Validation Loss: 0.00158984
Epoch [40/300], Train Loss: 0.001702
Validation Loss: 0.00160077
Epoch [41/300], Train Loss: 0.001674
Validation Loss: 0.00158861
Epoch [42/300], Train Loss: 0.001668
Validation Loss: 0.00157927
Epoch [43/300], Train Loss: 0.001658
Validation Loss: 0.00157060
Epoch [44/300], Train Loss: 0.001656
Validation Loss: 0.00157681
Epoch [45/300], Train Loss: 0.001659
Validation Loss: 0.00156655
Epoch [46/300], Train Loss: 0.001647
Validation Loss: 0.00155826
Epoch [47/300], Train Loss: 0.001753
Validation Loss: 0.00173181
Epoch [48/300], Train Loss: 0.001722
Validation Loss: 0.00162977
Epoch [49/300], Train Loss: 0.001687
Validation Loss: 0.00160816
Epoch [50/300], Train Loss: 0.001678
Validation Loss: 0.00161057
Epoch [51/300], Train Loss: 0.001663
Validation Loss: 0.00157197
Epoch [52/300], Train Loss: 0.001660
Validation Loss: 0.00158821
Epoch [53/300], Train Loss: 0.001662
Validation Loss: 0.00161911
Epoch [54/300], Train Loss: 0.001647
Validation Loss: 0.00155506
Epoch [55/300], Train Loss: 0.001637
Validation Loss: 0.00155179
Epoch [56/300], Train Loss: 0.001643
Validation Loss: 0.00157503
Epoch [57/300], Train Loss: 0.001671
Validation Loss: 0.00156453
Epoch [58/300], Train Loss: 0.001631
Validation Loss: 0.00155226
Epoch [59/300], Train Loss: 0.001630
Validation Loss: 0.00154168
Epoch [60/300], Train Loss: 0.001634
Validation Loss: 0.00153486
Epoch [61/300], Train Loss: 0.001626
Validation Loss: 0.00154784
Epoch [62/300], Train Loss: 0.001618
Validation Loss: 0.00153125
Epoch [63/300], Train Loss: 0.001637
Validation Loss: 0.00154368
Epoch [64/300], Train Loss: 0.001617
Validation Loss: 0.00154867
Epoch [65/300], Train Loss: 0.001627
Validation Loss: 0.00153193
Epoch [66/300], Train Loss: 0.001616
Validation Loss: 0.00152442
Epoch [67/300], Train Loss: 0.001613
Validation Loss: 0.00154356
Epoch [68/300], Train Loss: 0.001608
Validation Loss: 0.00152190
Epoch [69/300], Train Loss: 0.001610
Validation Loss: 0.00153213
Epoch [70/300], Train Loss: 0.001610
Validation Loss: 0.00152704
Epoch [71/300], Train Loss: 0.001601
Validation Loss: 0.00151946
Epoch [72/300], Train Loss: 0.001600
Validation Loss: 0.00152063
Epoch [73/300], Train Loss: 0.001596
Validation Loss: 0.00150887
Epoch [74/300], Train Loss: 0.001601
Validation Loss: 0.00151978
Epoch [75/300], Train Loss: 0.001602
Validation Loss: 0.00153759
Epoch [76/300], Train Loss: 0.001593
Validation Loss: 0.00149172
Epoch [77/300], Train Loss: 0.001573
Validation Loss: 0.00149115
Epoch [78/300], Train Loss: 0.001570
Validation Loss: 0.00149303
Epoch [79/300], Train Loss: 0.001575
Validation Loss: 0.00148685
Epoch [80/300], Train Loss: 0.001587
Validation Loss: 0.00149464
Epoch [81/300], Train Loss: 0.001571
Validation Loss: 0.00148028
Epoch [82/300], Train Loss: 0.001570
Validation Loss: 0.00147265
Epoch [83/300], Train Loss: 0.001558
Validation Loss: 0.00147486
Epoch [84/300], Train Loss: 0.001554
Validation Loss: 0.00147777
Epoch [85/300], Train Loss: 0.001557
Validation Loss: 0.00151382
Epoch [86/300], Train Loss: 0.001579
Validation Loss: 0.00148636
Epoch [87/300], Train Loss: 0.001549
Validation Loss: 0.00147060
Epoch [88/300], Train Loss: 0.001553
Validation Loss: 0.00146356
Epoch [89/300], Train Loss: 0.001545
Validation Loss: 0.00146637
Epoch [90/300], Train Loss: 0.001542
Validation Loss: 0.00145367
Epoch [91/300], Train Loss: 0.001542
Validation Loss: 0.00145534
Epoch [92/300], Train Loss: 0.001549
Validation Loss: 0.00146470
Epoch [93/300], Train Loss: 0.001537
Validation Loss: 0.00144136
Epoch [94/300], Train Loss: 0.001529
Validation Loss: 0.00144158
Epoch [95/300], Train Loss: 0.001525
Validation Loss: 0.00144187
Epoch [96/300], Train Loss: 0.001531
Validation Loss: 0.00143788
Epoch [97/300], Train Loss: 0.001517
Validation Loss: 0.00142940
Epoch [98/300], Train Loss: 0.001547
Validation Loss: 0.00157580
Epoch [99/300], Train Loss: 0.001585
Validation Loss: 0.00149220
Epoch [100/300], Train Loss: 0.001532
Validation Loss: 0.00144597
Epoch [101/300], Train Loss: 0.001513
Validation Loss: 0.00143991
Epoch [102/300], Train Loss: 0.001570
Validation Loss: 0.00156403
Epoch [103/300], Train Loss: 0.001564
Validation Loss: 0.00151756
Epoch [104/300], Train Loss: 0.001519
Validation Loss: 0.00142039
Epoch [105/300], Train Loss: 0.001520
Validation Loss: 0.00143152
Epoch [106/300], Train Loss: 0.001526
Validation Loss: 0.00144041
Epoch [107/300], Train Loss: 0.001525
Validation Loss: 0.00142045
Epoch [108/300], Train Loss: 0.001518
Validation Loss: 0.00142509
Epoch [109/300], Train Loss: 0.001501
Validation Loss: 0.00140852
Epoch [110/300], Train Loss: 0.001498
Validation Loss: 0.00143995
Epoch [111/300], Train Loss: 0.001493
Validation Loss: 0.00146445
Epoch [112/300], Train Loss: 0.001501
Validation Loss: 0.00141935
Epoch [113/300], Train Loss: 0.001577
Validation Loss: 0.00149168
Epoch [114/300], Train Loss: 0.001529
Validation Loss: 0.00266799
Epoch [115/300], Train Loss: 0.002171
Validation Loss: 0.00155563
Epoch [116/300], Train Loss: 0.001576
Validation Loss: 0.00146495
Epoch [117/300], Train Loss: 0.001522
Validation Loss: 0.00145111
Epoch [118/300], Train Loss: 0.001513
Validation Loss: 0.00144461
Epoch [119/300], Train Loss: 0.001504
Validation Loss: 0.00143116
Early stopping triggered

Evaluating model for: Freezer
Run 34/72 completed in 877.61 seconds with: {'MAE': np.float32(34.384613), 'MSE': np.float32(2509.523), 'RMSE': np.float32(50.09514), 'SAE': np.float32(0.025078239), 'NDE': np.float32(0.37383255)}

Run 35/72: hidden=256, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Freezer
Dataset length: 4614 windows

Epoch [1/300], Train Loss: 0.008011
Validation Loss: 0.00591420
Epoch [2/300], Train Loss: 0.005954
Validation Loss: 0.00566111
Epoch [3/300], Train Loss: 0.005896
Validation Loss: 0.00555359
Epoch [4/300], Train Loss: 0.005569
Validation Loss: 0.00460204
Epoch [5/300], Train Loss: 0.003940
Validation Loss: 0.00300164
Epoch [6/300], Train Loss: 0.002692
Validation Loss: 0.00241536
Epoch [7/300], Train Loss: 0.002429
Validation Loss: 0.00231315
Epoch [8/300], Train Loss: 0.002327
Validation Loss: 0.00225398
Epoch [9/300], Train Loss: 0.002220
Validation Loss: 0.00215530
Epoch [10/300], Train Loss: 0.002113
Validation Loss: 0.00199185
Epoch [11/300], Train Loss: 0.002015
Validation Loss: 0.00191969
Epoch [12/300], Train Loss: 0.001939
Validation Loss: 0.00183666
Epoch [13/300], Train Loss: 0.001897
Validation Loss: 0.00181305
Epoch [14/300], Train Loss: 0.001890
Validation Loss: 0.00178734
Epoch [15/300], Train Loss: 0.001852
Validation Loss: 0.00177505
Epoch [16/300], Train Loss: 0.001863
Validation Loss: 0.00180471
Epoch [17/300], Train Loss: 0.001834
Validation Loss: 0.00173579
Epoch [18/300], Train Loss: 0.001803
Validation Loss: 0.00173913
Epoch [19/300], Train Loss: 0.001799
Validation Loss: 0.00174279
Epoch [20/300], Train Loss: 0.001797
Validation Loss: 0.00172380
Epoch [21/300], Train Loss: 0.001776
Validation Loss: 0.00174467
Epoch [22/300], Train Loss: 0.001771
Validation Loss: 0.00169413
Epoch [23/300], Train Loss: 0.001776
Validation Loss: 0.00168653
Epoch [24/300], Train Loss: 0.001767
Validation Loss: 0.00168383
Epoch [25/300], Train Loss: 0.001743
Validation Loss: 0.00166481
Epoch [26/300], Train Loss: 0.001731
Validation Loss: 0.00165479
Epoch [27/300], Train Loss: 0.001724
Validation Loss: 0.00164449
Epoch [28/300], Train Loss: 0.001735
Validation Loss: 0.00167285
Epoch [29/300], Train Loss: 0.001716
Validation Loss: 0.00166934
Epoch [30/300], Train Loss: 0.001703
Validation Loss: 0.00167804
Epoch [31/300], Train Loss: 0.001728
Validation Loss: 0.00161823
Epoch [32/300], Train Loss: 0.001688
Validation Loss: 0.00162291
Epoch [33/300], Train Loss: 0.001672
Validation Loss: 0.00158123
Epoch [34/300], Train Loss: 0.001666
Validation Loss: 0.00157119
Epoch [35/300], Train Loss: 0.001676
Validation Loss: 0.00157493
Epoch [36/300], Train Loss: 0.001655
Validation Loss: 0.00157229
Epoch [37/300], Train Loss: 0.001646
Validation Loss: 0.00156539
Epoch [38/300], Train Loss: 0.001670
Validation Loss: 0.00158789
Epoch [39/300], Train Loss: 0.001648
Validation Loss: 0.00155622
Epoch [40/300], Train Loss: 0.001643
Validation Loss: 0.00155368
Epoch [41/300], Train Loss: 0.001650
Validation Loss: 0.00156861
Epoch [42/300], Train Loss: 0.001644
Validation Loss: 0.00153947
Epoch [43/300], Train Loss: 0.001633
Validation Loss: 0.00153411
Epoch [44/300], Train Loss: 0.001640
Validation Loss: 0.00155020
Epoch [45/300], Train Loss: 0.001633
Validation Loss: 0.00153695
Epoch [46/300], Train Loss: 0.001629
Validation Loss: 0.00154389
Epoch [47/300], Train Loss: 0.001629
Validation Loss: 0.00154134
Epoch [48/300], Train Loss: 0.001623
Validation Loss: 0.00152977
Epoch [49/300], Train Loss: 0.001623
Validation Loss: 0.00152474
Epoch [50/300], Train Loss: 0.001622
Validation Loss: 0.00155276
Epoch [51/300], Train Loss: 0.001613
Validation Loss: 0.00151818
Epoch [52/300], Train Loss: 0.001631
Validation Loss: 0.00158510
Epoch [53/300], Train Loss: 0.001636
Validation Loss: 0.00156887
Epoch [54/300], Train Loss: 0.001611
Validation Loss: 0.00151119
Epoch [55/300], Train Loss: 0.001605
Validation Loss: 0.00152612
Epoch [56/300], Train Loss: 0.001611
Validation Loss: 0.00153424
Epoch [57/300], Train Loss: 0.001601
Validation Loss: 0.00150022
Epoch [58/300], Train Loss: 0.001590
Validation Loss: 0.00150468
Epoch [59/300], Train Loss: 0.001590
Validation Loss: 0.00149466
Epoch [60/300], Train Loss: 0.001597
Validation Loss: 0.00148772
Epoch [61/300], Train Loss: 0.001579
Validation Loss: 0.00148979
Epoch [62/300], Train Loss: 0.001566
Validation Loss: 0.00146839
Epoch [63/300], Train Loss: 0.001570
Validation Loss: 0.00148468
Epoch [64/300], Train Loss: 0.001564
Validation Loss: 0.00150538
Epoch [65/300], Train Loss: 0.001577
Validation Loss: 0.00148265
Epoch [66/300], Train Loss: 0.001557
Validation Loss: 0.00146271
Epoch [67/300], Train Loss: 0.001555
Validation Loss: 0.00148560
Epoch [68/300], Train Loss: 0.001553
Validation Loss: 0.00147813
Epoch [69/300], Train Loss: 0.001555
Validation Loss: 0.00146882
Epoch [70/300], Train Loss: 0.001543
Validation Loss: 0.00145331
Epoch [71/300], Train Loss: 0.001532
Validation Loss: 0.00146431
Epoch [72/300], Train Loss: 0.001530
Validation Loss: 0.00144964
Epoch [73/300], Train Loss: 0.001520
Validation Loss: 0.00143907
Epoch [74/300], Train Loss: 0.001528
Validation Loss: 0.00145496
Epoch [75/300], Train Loss: 0.001526
Validation Loss: 0.00149102
Epoch [76/300], Train Loss: 0.001519
Validation Loss: 0.00143493
Epoch [77/300], Train Loss: 0.001518
Validation Loss: 0.00143735
Epoch [78/300], Train Loss: 0.001513
Validation Loss: 0.00144860
Epoch [79/300], Train Loss: 0.001518
Validation Loss: 0.00144046
Epoch [80/300], Train Loss: 0.001527
Validation Loss: 0.00144586
Epoch [81/300], Train Loss: 0.001517
Validation Loss: 0.00143284
Epoch [82/300], Train Loss: 0.001513
Validation Loss: 0.00145119
Epoch [83/300], Train Loss: 0.001510
Validation Loss: 0.00143379
Epoch [84/300], Train Loss: 0.001499
Validation Loss: 0.00142890
Epoch [85/300], Train Loss: 0.001502
Validation Loss: 0.00147264
Epoch [86/300], Train Loss: 0.001506
Validation Loss: 0.00143963
Epoch [87/300], Train Loss: 0.001497
Validation Loss: 0.00142021
Epoch [88/300], Train Loss: 0.001502
Validation Loss: 0.00143643
Epoch [89/300], Train Loss: 0.001502
Validation Loss: 0.00142486
Epoch [90/300], Train Loss: 0.001499
Validation Loss: 0.00142495
Epoch [91/300], Train Loss: 0.001498
Validation Loss: 0.00142184
Epoch [92/300], Train Loss: 0.001502
Validation Loss: 0.00141189
Epoch [93/300], Train Loss: 0.001488
Validation Loss: 0.00141546
Epoch [94/300], Train Loss: 0.001486
Validation Loss: 0.00141193
Epoch [95/300], Train Loss: 0.001488
Validation Loss: 0.00142147
Epoch [96/300], Train Loss: 0.001481
Validation Loss: 0.00141405
Epoch [97/300], Train Loss: 0.001481
Validation Loss: 0.00140304
Epoch [98/300], Train Loss: 0.001477
Validation Loss: 0.00141490
Epoch [99/300], Train Loss: 0.001483
Validation Loss: 0.00140537
Epoch [100/300], Train Loss: 0.001481
Validation Loss: 0.00141510
Epoch [101/300], Train Loss: 0.001477
Validation Loss: 0.00142429
Epoch [102/300], Train Loss: 0.001472
Validation Loss: 0.00140846
Epoch [103/300], Train Loss: 0.001494
Validation Loss: 0.00141704
Epoch [104/300], Train Loss: 0.001469
Validation Loss: 0.00140832
Epoch [105/300], Train Loss: 0.001473
Validation Loss: 0.00140699
Epoch [106/300], Train Loss: 0.001478
Validation Loss: 0.00140774
Epoch [107/300], Train Loss: 0.001465
Validation Loss: 0.00139548
Epoch [108/300], Train Loss: 0.001472
Validation Loss: 0.00140178
Epoch [109/300], Train Loss: 0.001462
Validation Loss: 0.00139948
Epoch [110/300], Train Loss: 0.001464
Validation Loss: 0.00142784
Epoch [111/300], Train Loss: 0.001465
Validation Loss: 0.00143401
Epoch [112/300], Train Loss: 0.001468
Validation Loss: 0.00140505
Epoch [113/300], Train Loss: 0.001481
Validation Loss: 0.00141270
Epoch [114/300], Train Loss: 0.001482
Validation Loss: 0.00153558
Epoch [115/300], Train Loss: 0.001508
Validation Loss: 0.00141925
Epoch [116/300], Train Loss: 0.001467
Validation Loss: 0.00141421
Epoch [117/300], Train Loss: 0.001479
Validation Loss: 0.00148144
Early stopping triggered

Evaluating model for: Freezer
Run 35/72 completed in 980.34 seconds with: {'MAE': np.float32(34.46922), 'MSE': np.float32(2567.6191), 'RMSE': np.float32(50.67168), 'SAE': np.float32(0.020378137), 'NDE': np.float32(0.37813488)}

Run 36/72: hidden=256, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Freezer
Dataset length: 4614 windows

Epoch [1/300], Train Loss: 0.005953
Validation Loss: 0.00561252
Epoch [2/300], Train Loss: 0.005899
Validation Loss: 0.00561903
Epoch [3/300], Train Loss: 0.005888
Validation Loss: 0.00557438
Epoch [4/300], Train Loss: 0.005201
Validation Loss: 0.00389647
Epoch [5/300], Train Loss: 0.003515
Validation Loss: 0.00305083
Epoch [6/300], Train Loss: 0.002800
Validation Loss: 0.00264338
Epoch [7/300], Train Loss: 0.002504
Validation Loss: 0.00237502
Epoch [8/300], Train Loss: 0.002312
Validation Loss: 0.00218567
Epoch [9/300], Train Loss: 0.002150
Validation Loss: 0.00205914
Epoch [10/300], Train Loss: 0.002007
Validation Loss: 0.00189844
Epoch [11/300], Train Loss: 0.001959
Validation Loss: 0.00186620
Epoch [12/300], Train Loss: 0.001910
Validation Loss: 0.00184039
Epoch [13/300], Train Loss: 0.001874
Validation Loss: 0.00180517
Epoch [14/300], Train Loss: 0.001886
Validation Loss: 0.00179997
Epoch [15/300], Train Loss: 0.001838
Validation Loss: 0.00176573
Epoch [16/300], Train Loss: 0.001844
Validation Loss: 0.00180238
Epoch [17/300], Train Loss: 0.001807
Validation Loss: 0.00171819
Epoch [18/300], Train Loss: 0.001771
Validation Loss: 0.00171975
Epoch [19/300], Train Loss: 0.001770
Validation Loss: 0.00172206
Epoch [20/300], Train Loss: 0.001771
Validation Loss: 0.00169714
Epoch [21/300], Train Loss: 0.001746
Validation Loss: 0.00172622
Epoch [22/300], Train Loss: 0.001743
Validation Loss: 0.00167682
Epoch [23/300], Train Loss: 0.001750
Validation Loss: 0.00168192
Epoch [24/300], Train Loss: 0.001749
Validation Loss: 0.00167089
Epoch [25/300], Train Loss: 0.001720
Validation Loss: 0.00164667
Epoch [26/300], Train Loss: 0.001704
Validation Loss: 0.00164119
Epoch [27/300], Train Loss: 0.001697
Validation Loss: 0.00162504
Epoch [28/300], Train Loss: 0.001708
Validation Loss: 0.00164304
Epoch [29/300], Train Loss: 0.001681
Validation Loss: 0.00164706
Epoch [30/300], Train Loss: 0.001677
Validation Loss: 0.00160841
Epoch [31/300], Train Loss: 0.001672
Validation Loss: 0.00157332
Epoch [32/300], Train Loss: 0.001656
Validation Loss: 0.00158389
Epoch [33/300], Train Loss: 0.001641
Validation Loss: 0.00154660
Epoch [34/300], Train Loss: 0.001629
Validation Loss: 0.00153739
Epoch [35/300], Train Loss: 0.001624
Validation Loss: 0.00153408
Epoch [36/300], Train Loss: 0.001614
Validation Loss: 0.00154314
Epoch [37/300], Train Loss: 0.001609
Validation Loss: 0.00152829
Epoch [38/300], Train Loss: 0.001609
Validation Loss: 0.00153710
Epoch [39/300], Train Loss: 0.001607
Validation Loss: 0.00155069
Epoch [40/300], Train Loss: 0.001632
Validation Loss: 0.00153231
Epoch [41/300], Train Loss: 0.001641
Validation Loss: 0.00173132
Epoch [42/300], Train Loss: 0.001670
Validation Loss: 0.00157529
Epoch [43/300], Train Loss: 0.001610
Validation Loss: 0.00153534
Epoch [44/300], Train Loss: 0.001587
Validation Loss: 0.00153138
Epoch [45/300], Train Loss: 0.001585
Validation Loss: 0.00149088
Epoch [46/300], Train Loss: 0.001570
Validation Loss: 0.00150447
Epoch [47/300], Train Loss: 0.001592
Validation Loss: 0.00159253
Epoch [48/300], Train Loss: 0.001588
Validation Loss: 0.00149148
Epoch [49/300], Train Loss: 0.001563
Validation Loss: 0.00149181
Epoch [50/300], Train Loss: 0.001556
Validation Loss: 0.00150982
Epoch [51/300], Train Loss: 0.001550
Validation Loss: 0.00147321
Epoch [52/300], Train Loss: 0.001548
Validation Loss: 0.00150189
Epoch [53/300], Train Loss: 0.001558
Validation Loss: 0.00156329
Epoch [54/300], Train Loss: 0.001547
Validation Loss: 0.00146814
Epoch [55/300], Train Loss: 0.001533
Validation Loss: 0.00146034
Epoch [56/300], Train Loss: 0.001545
Validation Loss: 0.00148673
Epoch [57/300], Train Loss: 0.001526
Validation Loss: 0.00147271
Epoch [58/300], Train Loss: 0.001530
Validation Loss: 0.00146986
Epoch [59/300], Train Loss: 0.001520
Validation Loss: 0.00145082
Epoch [60/300], Train Loss: 0.001519
Validation Loss: 0.00148085
Epoch [61/300], Train Loss: 0.001518
Validation Loss: 0.00152467
Epoch [62/300], Train Loss: 0.001520
Validation Loss: 0.00148911
Epoch [63/300], Train Loss: 0.001509
Validation Loss: 0.00146549
Epoch [64/300], Train Loss: 0.001517
Validation Loss: 0.00149996
Epoch [65/300], Train Loss: 0.001541
Validation Loss: 0.00147027
Epoch [66/300], Train Loss: 0.001512
Validation Loss: 0.00146780
Epoch [67/300], Train Loss: 0.001511
Validation Loss: 0.00147193
Epoch [68/300], Train Loss: 0.001510
Validation Loss: 0.00144749
Epoch [69/300], Train Loss: 0.001505
Validation Loss: 0.00143943
Epoch [70/300], Train Loss: 0.001510
Validation Loss: 0.00144485
Epoch [71/300], Train Loss: 0.001504
Validation Loss: 0.00146430
Epoch [72/300], Train Loss: 0.001507
Validation Loss: 0.00144175
Epoch [73/300], Train Loss: 0.001495
Validation Loss: 0.00142782
Epoch [74/300], Train Loss: 0.001496
Validation Loss: 0.00142386
Epoch [75/300], Train Loss: 0.001496
Validation Loss: 0.00148542
Epoch [76/300], Train Loss: 0.001521
Validation Loss: 0.00143736
Epoch [77/300], Train Loss: 0.001492
Validation Loss: 0.00143364
Epoch [78/300], Train Loss: 0.001490
Validation Loss: 0.00142977
Epoch [79/300], Train Loss: 0.001490
Validation Loss: 0.00144052
Epoch [80/300], Train Loss: 0.001501
Validation Loss: 0.00142872
Epoch [81/300], Train Loss: 0.001488
Validation Loss: 0.00144382
Epoch [82/300], Train Loss: 0.001497
Validation Loss: 0.00142139
Epoch [83/300], Train Loss: 0.001493
Validation Loss: 0.00141014
Epoch [84/300], Train Loss: 0.001484
Validation Loss: 0.00144799
Epoch [85/300], Train Loss: 0.001501
Validation Loss: 0.00147507
Epoch [86/300], Train Loss: 0.001510
Validation Loss: 0.00146833
Epoch [87/300], Train Loss: 0.001490
Validation Loss: 0.00142218
Epoch [88/300], Train Loss: 0.001483
Validation Loss: 0.00143074
Epoch [89/300], Train Loss: 0.001482
Validation Loss: 0.00141841
Epoch [90/300], Train Loss: 0.001475
Validation Loss: 0.00141539
Epoch [91/300], Train Loss: 0.001481
Validation Loss: 0.00142890
Epoch [92/300], Train Loss: 0.001480
Validation Loss: 0.00140522
Epoch [93/300], Train Loss: 0.001473
Validation Loss: 0.00141004
Epoch [94/300], Train Loss: 0.001471
Validation Loss: 0.00141375
Epoch [95/300], Train Loss: 0.001469
Validation Loss: 0.00141608
Epoch [96/300], Train Loss: 0.001477
Validation Loss: 0.00144028
Epoch [97/300], Train Loss: 0.001491
Validation Loss: 0.00142191
Epoch [98/300], Train Loss: 0.001481
Validation Loss: 0.00141536
Epoch [99/300], Train Loss: 0.001474
Validation Loss: 0.00142054
Epoch [100/300], Train Loss: 0.001474
Validation Loss: 0.00142742
Epoch [101/300], Train Loss: 0.001481
Validation Loss: 0.00145773
Epoch [102/300], Train Loss: 0.001553
Validation Loss: 0.00153749
Early stopping triggered

Evaluating model for: Freezer
Run 36/72 completed in 1081.83 seconds with: {'MAE': np.float32(35.720104), 'MSE': np.float32(2643.2795), 'RMSE': np.float32(51.412834), 'SAE': np.float32(0.09755403), 'NDE': np.float32(0.3836657)}

Run 37/72: hidden=256, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Freezer
Dataset length: 2322 windows

Epoch [1/300], Train Loss: 0.009008
Validation Loss: 0.00577218
Epoch [2/300], Train Loss: 0.006136
Validation Loss: 0.00583225
Epoch [3/300], Train Loss: 0.005951
Validation Loss: 0.00542273
Epoch [4/300], Train Loss: 0.005882
Validation Loss: 0.00543526
Epoch [5/300], Train Loss: 0.005836
Validation Loss: 0.00542350
Epoch [6/300], Train Loss: 0.005810
Validation Loss: 0.00539372
Epoch [7/300], Train Loss: 0.005771
Validation Loss: 0.00533652
Epoch [8/300], Train Loss: 0.005706
Validation Loss: 0.00529502
Epoch [9/300], Train Loss: 0.005593
Validation Loss: 0.00512243
Epoch [10/300], Train Loss: 0.005434
Validation Loss: 0.00511388
Epoch [11/300], Train Loss: 0.005299
Validation Loss: 0.00498098
Epoch [12/300], Train Loss: 0.005118
Validation Loss: 0.00472232
Epoch [13/300], Train Loss: 0.004910
Validation Loss: 0.00448892
Epoch [14/300], Train Loss: 0.004499
Validation Loss: 0.00417062
Epoch [15/300], Train Loss: 0.003923
Validation Loss: 0.00339619
Epoch [16/300], Train Loss: 0.003178
Validation Loss: 0.00265389
Epoch [17/300], Train Loss: 0.002718
Validation Loss: 0.00245637
Epoch [18/300], Train Loss: 0.002534
Validation Loss: 0.00256296
Epoch [19/300], Train Loss: 0.002474
Validation Loss: 0.00226812
Epoch [20/300], Train Loss: 0.002339
Validation Loss: 0.00232030
Epoch [21/300], Train Loss: 0.002287
Validation Loss: 0.00225217
Epoch [22/300], Train Loss: 0.002229
Validation Loss: 0.00217970
Epoch [23/300], Train Loss: 0.002233
Validation Loss: 0.00215746
Epoch [24/300], Train Loss: 0.002120
Validation Loss: 0.00214727
Epoch [25/300], Train Loss: 0.002045
Validation Loss: 0.00207483
Epoch [26/300], Train Loss: 0.001983
Validation Loss: 0.00199980
Epoch [27/300], Train Loss: 0.001943
Validation Loss: 0.00197377
Epoch [28/300], Train Loss: 0.001914
Validation Loss: 0.00194225
Epoch [29/300], Train Loss: 0.001901
Validation Loss: 0.00196225
Epoch [30/300], Train Loss: 0.001881
Validation Loss: 0.00192680
Epoch [31/300], Train Loss: 0.001850
Validation Loss: 0.00189945
Epoch [32/300], Train Loss: 0.001827
Validation Loss: 0.00190303
Epoch [33/300], Train Loss: 0.001833
Validation Loss: 0.00190157
Epoch [34/300], Train Loss: 0.001825
Validation Loss: 0.00187675
Epoch [35/300], Train Loss: 0.001800
Validation Loss: 0.00187591
Epoch [36/300], Train Loss: 0.001801
Validation Loss: 0.00185023
Epoch [37/300], Train Loss: 0.001826
Validation Loss: 0.00187322
Epoch [38/300], Train Loss: 0.001780
Validation Loss: 0.00183618
Epoch [39/300], Train Loss: 0.001771
Validation Loss: 0.00184079
Epoch [40/300], Train Loss: 0.001759
Validation Loss: 0.00182015
Epoch [41/300], Train Loss: 0.001743
Validation Loss: 0.00182302
Epoch [42/300], Train Loss: 0.001751
Validation Loss: 0.00185956
Epoch [43/300], Train Loss: 0.001738
Validation Loss: 0.00180757
Epoch [44/300], Train Loss: 0.001746
Validation Loss: 0.00179948
Epoch [45/300], Train Loss: 0.001734
Validation Loss: 0.00179673
Epoch [46/300], Train Loss: 0.001717
Validation Loss: 0.00179531
Epoch [47/300], Train Loss: 0.001724
Validation Loss: 0.00179597
Epoch [48/300], Train Loss: 0.001706
Validation Loss: 0.00180686
Epoch [49/300], Train Loss: 0.001714
Validation Loss: 0.00179919
Epoch [50/300], Train Loss: 0.001718
Validation Loss: 0.00180550
Epoch [51/300], Train Loss: 0.001706
Validation Loss: 0.00177835
Epoch [52/300], Train Loss: 0.001684
Validation Loss: 0.00181027
Epoch [53/300], Train Loss: 0.001715
Validation Loss: 0.00177244
Epoch [54/300], Train Loss: 0.001677
Validation Loss: 0.00178783
Epoch [55/300], Train Loss: 0.001689
Validation Loss: 0.00176958
Epoch [56/300], Train Loss: 0.001694
Validation Loss: 0.00176550
Epoch [57/300], Train Loss: 0.001715
Validation Loss: 0.00176582
Epoch [58/300], Train Loss: 0.001688
Validation Loss: 0.00177109
Epoch [59/300], Train Loss: 0.001673
Validation Loss: 0.00175987
Epoch [60/300], Train Loss: 0.001707
Validation Loss: 0.00175232
Epoch [61/300], Train Loss: 0.001695
Validation Loss: 0.00176287
Epoch [62/300], Train Loss: 0.001660
Validation Loss: 0.00175169
Epoch [63/300], Train Loss: 0.001671
Validation Loss: 0.00175108
Epoch [64/300], Train Loss: 0.001694
Validation Loss: 0.00175541
Epoch [65/300], Train Loss: 0.001651
Validation Loss: 0.00175423
Epoch [66/300], Train Loss: 0.001658
Validation Loss: 0.00176873
Epoch [67/300], Train Loss: 0.001657
Validation Loss: 0.00178662
Epoch [68/300], Train Loss: 0.001662
Validation Loss: 0.00176739
Epoch [69/300], Train Loss: 0.001657
Validation Loss: 0.00175503
Epoch [70/300], Train Loss: 0.001645
Validation Loss: 0.00176163
Epoch [71/300], Train Loss: 0.001632
Validation Loss: 0.00174076
Epoch [72/300], Train Loss: 0.001643
Validation Loss: 0.00174311
Epoch [73/300], Train Loss: 0.001658
Validation Loss: 0.00175471
Epoch [74/300], Train Loss: 0.001657
Validation Loss: 0.00173682
Epoch [75/300], Train Loss: 0.001641
Validation Loss: 0.00173876
Epoch [76/300], Train Loss: 0.001644
Validation Loss: 0.00173168
Epoch [77/300], Train Loss: 0.001641
Validation Loss: 0.00174258
Epoch [78/300], Train Loss: 0.001630
Validation Loss: 0.00174448
Epoch [79/300], Train Loss: 0.001645
Validation Loss: 0.00174867
Epoch [80/300], Train Loss: 0.001614
Validation Loss: 0.00174387
Epoch [81/300], Train Loss: 0.001629
Validation Loss: 0.00173120
Epoch [82/300], Train Loss: 0.001628
Validation Loss: 0.00172591
Epoch [83/300], Train Loss: 0.001624
Validation Loss: 0.00173176
Epoch [84/300], Train Loss: 0.001615
Validation Loss: 0.00172256
Epoch [85/300], Train Loss: 0.001627
Validation Loss: 0.00172193
Epoch [86/300], Train Loss: 0.001619
Validation Loss: 0.00173034
Epoch [87/300], Train Loss: 0.001610
Validation Loss: 0.00173271
Epoch [88/300], Train Loss: 0.001659
Validation Loss: 0.00171948
Epoch [89/300], Train Loss: 0.001613
Validation Loss: 0.00172662
Epoch [90/300], Train Loss: 0.001609
Validation Loss: 0.00173877
Epoch [91/300], Train Loss: 0.001622
Validation Loss: 0.00172381
Epoch [92/300], Train Loss: 0.001630
Validation Loss: 0.00171456
Epoch [93/300], Train Loss: 0.001592
Validation Loss: 0.00174585
Epoch [94/300], Train Loss: 0.001611
Validation Loss: 0.00174377
Epoch [95/300], Train Loss: 0.001607
Validation Loss: 0.00171259
Epoch [96/300], Train Loss: 0.001596
Validation Loss: 0.00173007
Epoch [97/300], Train Loss: 0.001615
Validation Loss: 0.00172123
Epoch [98/300], Train Loss: 0.001604
Validation Loss: 0.00171537
Epoch [99/300], Train Loss: 0.001593
Validation Loss: 0.00170633
Epoch [100/300], Train Loss: 0.001616
Validation Loss: 0.00172590
Epoch [101/300], Train Loss: 0.001601
Validation Loss: 0.00171243
Epoch [102/300], Train Loss: 0.001606
Validation Loss: 0.00172746
Epoch [103/300], Train Loss: 0.001589
Validation Loss: 0.00172476
Epoch [104/300], Train Loss: 0.001601
Validation Loss: 0.00172508
Epoch [105/300], Train Loss: 0.001574
Validation Loss: 0.00171728
Epoch [106/300], Train Loss: 0.001588
Validation Loss: 0.00169894
Epoch [107/300], Train Loss: 0.001583
Validation Loss: 0.00170805
Epoch [108/300], Train Loss: 0.001588
Validation Loss: 0.00171355
Epoch [109/300], Train Loss: 0.001583
Validation Loss: 0.00170045
Epoch [110/300], Train Loss: 0.001571
Validation Loss: 0.00170115
Epoch [111/300], Train Loss: 0.001564
Validation Loss: 0.00169815
Epoch [112/300], Train Loss: 0.001558
Validation Loss: 0.00170522
Epoch [113/300], Train Loss: 0.001574
Validation Loss: 0.00172390
Epoch [114/300], Train Loss: 0.001588
Validation Loss: 0.00169378
Epoch [115/300], Train Loss: 0.001583
Validation Loss: 0.00170124
Epoch [116/300], Train Loss: 0.001580
Validation Loss: 0.00169560
Epoch [117/300], Train Loss: 0.001574
Validation Loss: 0.00169078
Epoch [118/300], Train Loss: 0.001560
Validation Loss: 0.00169476
Epoch [119/300], Train Loss: 0.001560
Validation Loss: 0.00169340
Epoch [120/300], Train Loss: 0.001585
Validation Loss: 0.00168829
Epoch [121/300], Train Loss: 0.001586
Validation Loss: 0.00171785
Epoch [122/300], Train Loss: 0.001581
Validation Loss: 0.00169165
Epoch [123/300], Train Loss: 0.001558
Validation Loss: 0.00168966
Epoch [124/300], Train Loss: 0.001556
Validation Loss: 0.00169485
Epoch [125/300], Train Loss: 0.001550
Validation Loss: 0.00169375
Epoch [126/300], Train Loss: 0.001565
Validation Loss: 0.00168601
Epoch [127/300], Train Loss: 0.001568
Validation Loss: 0.00169243
Epoch [128/300], Train Loss: 0.001558
Validation Loss: 0.00169632
Epoch [129/300], Train Loss: 0.001565
Validation Loss: 0.00171839
Epoch [130/300], Train Loss: 0.001556
Validation Loss: 0.00168939
Epoch [131/300], Train Loss: 0.001553
Validation Loss: 0.00168249
Epoch [132/300], Train Loss: 0.001560
Validation Loss: 0.00168812
Epoch [133/300], Train Loss: 0.001538
Validation Loss: 0.00167772
Epoch [134/300], Train Loss: 0.001555
Validation Loss: 0.00167833
Epoch [135/300], Train Loss: 0.001546
Validation Loss: 0.00167913
Epoch [136/300], Train Loss: 0.001556
Validation Loss: 0.00168516
Epoch [137/300], Train Loss: 0.001546
Validation Loss: 0.00169831
Epoch [138/300], Train Loss: 0.001547
Validation Loss: 0.00167891
Epoch [139/300], Train Loss: 0.001544
Validation Loss: 0.00167839
Epoch [140/300], Train Loss: 0.001536
Validation Loss: 0.00168287
Epoch [141/300], Train Loss: 0.001550
Validation Loss: 0.00167509
Epoch [142/300], Train Loss: 0.001544
Validation Loss: 0.00167629
Epoch [143/300], Train Loss: 0.001535
Validation Loss: 0.00167277
Epoch [144/300], Train Loss: 0.001541
Validation Loss: 0.00167064
Epoch [145/300], Train Loss: 0.001530
Validation Loss: 0.00167536
Epoch [146/300], Train Loss: 0.001534
Validation Loss: 0.00169077
Epoch [147/300], Train Loss: 0.001531
Validation Loss: 0.00168112
Epoch [148/300], Train Loss: 0.001525
Validation Loss: 0.00167565
Epoch [149/300], Train Loss: 0.001559
Validation Loss: 0.00166875
Epoch [150/300], Train Loss: 0.001519
Validation Loss: 0.00166657
Epoch [151/300], Train Loss: 0.001534
Validation Loss: 0.00167451
Epoch [152/300], Train Loss: 0.001524
Validation Loss: 0.00166601
Epoch [153/300], Train Loss: 0.001538
Validation Loss: 0.00172555
Epoch [154/300], Train Loss: 0.001539
Validation Loss: 0.00166415
Epoch [155/300], Train Loss: 0.001541
Validation Loss: 0.00166232
Epoch [156/300], Train Loss: 0.001537
Validation Loss: 0.00166359
Epoch [157/300], Train Loss: 0.001559
Validation Loss: 0.00166474
Epoch [158/300], Train Loss: 0.001527
Validation Loss: 0.00165903
Epoch [159/300], Train Loss: 0.001521
Validation Loss: 0.00166087
Epoch [160/300], Train Loss: 0.001517
Validation Loss: 0.00165852
Epoch [161/300], Train Loss: 0.001525
Validation Loss: 0.00166481
Epoch [162/300], Train Loss: 0.001533
Validation Loss: 0.00169014
Epoch [163/300], Train Loss: 0.001518
Validation Loss: 0.00165539
Epoch [164/300], Train Loss: 0.001525
Validation Loss: 0.00166621
Epoch [165/300], Train Loss: 0.001521
Validation Loss: 0.00167061
Epoch [166/300], Train Loss: 0.001528
Validation Loss: 0.00165630
Epoch [167/300], Train Loss: 0.001525
Validation Loss: 0.00165414
Epoch [168/300], Train Loss: 0.001512
Validation Loss: 0.00165856
Epoch [169/300], Train Loss: 0.001525
Validation Loss: 0.00165037
Epoch [170/300], Train Loss: 0.001510
Validation Loss: 0.00165688
Epoch [171/300], Train Loss: 0.001530
Validation Loss: 0.00164636
Epoch [172/300], Train Loss: 0.001501
Validation Loss: 0.00164519
Epoch [173/300], Train Loss: 0.001491
Validation Loss: 0.00164621
Epoch [174/300], Train Loss: 0.001509
Validation Loss: 0.00165417
Epoch [175/300], Train Loss: 0.001502
Validation Loss: 0.00164530
Epoch [176/300], Train Loss: 0.001505
Validation Loss: 0.00164429
Epoch [177/300], Train Loss: 0.001503
Validation Loss: 0.00164149
Epoch [178/300], Train Loss: 0.001503
Validation Loss: 0.00164063
Epoch [179/300], Train Loss: 0.001519
Validation Loss: 0.00164056
Epoch [180/300], Train Loss: 0.001499
Validation Loss: 0.00164062
Epoch [181/300], Train Loss: 0.001495
Validation Loss: 0.00164106
Epoch [182/300], Train Loss: 0.001490
Validation Loss: 0.00163835
Epoch [183/300], Train Loss: 0.001499
Validation Loss: 0.00164972
Epoch [184/300], Train Loss: 0.001512
Validation Loss: 0.00164160
Epoch [185/300], Train Loss: 0.001489
Validation Loss: 0.00163781
Epoch [186/300], Train Loss: 0.001495
Validation Loss: 0.00163346
Epoch [187/300], Train Loss: 0.001522
Validation Loss: 0.00163399
Epoch [188/300], Train Loss: 0.001503
Validation Loss: 0.00163810
Epoch [189/300], Train Loss: 0.001513
Validation Loss: 0.00163005
Epoch [190/300], Train Loss: 0.001492
Validation Loss: 0.00162906
Epoch [191/300], Train Loss: 0.001503
Validation Loss: 0.00162798
Epoch [192/300], Train Loss: 0.001478
Validation Loss: 0.00162712
Epoch [193/300], Train Loss: 0.001486
Validation Loss: 0.00162731
Epoch [194/300], Train Loss: 0.001493
Validation Loss: 0.00162480
Epoch [195/300], Train Loss: 0.001488
Validation Loss: 0.00162526
Epoch [196/300], Train Loss: 0.001485
Validation Loss: 0.00162393
Epoch [197/300], Train Loss: 0.001476
Validation Loss: 0.00162555
Epoch [198/300], Train Loss: 0.001490
Validation Loss: 0.00163178
Epoch [199/300], Train Loss: 0.001480
Validation Loss: 0.00164645
Epoch [200/300], Train Loss: 0.001502
Validation Loss: 0.00162617
Epoch [201/300], Train Loss: 0.001494
Validation Loss: 0.00165611
Epoch [202/300], Train Loss: 0.001496
Validation Loss: 0.00162377
Epoch [203/300], Train Loss: 0.001489
Validation Loss: 0.00162976
Epoch [204/300], Train Loss: 0.001508
Validation Loss: 0.00162806
Epoch [205/300], Train Loss: 0.001483
Validation Loss: 0.00163753
Epoch [206/300], Train Loss: 0.001502
Validation Loss: 0.00168382
Epoch [207/300], Train Loss: 0.001503
Validation Loss: 0.00162458
Epoch [208/300], Train Loss: 0.001492
Validation Loss: 0.00166050
Epoch [209/300], Train Loss: 0.001483
Validation Loss: 0.00162275
Epoch [210/300], Train Loss: 0.001464
Validation Loss: 0.00162020
Epoch [211/300], Train Loss: 0.001479
Validation Loss: 0.00162367
Epoch [212/300], Train Loss: 0.001479
Validation Loss: 0.00161666
Epoch [213/300], Train Loss: 0.001471
Validation Loss: 0.00161194
Epoch [214/300], Train Loss: 0.001472
Validation Loss: 0.00162013
Epoch [215/300], Train Loss: 0.001471
Validation Loss: 0.00161141
Epoch [216/300], Train Loss: 0.001476
Validation Loss: 0.00161225
Epoch [217/300], Train Loss: 0.001474
Validation Loss: 0.00161273
Epoch [218/300], Train Loss: 0.001477
Validation Loss: 0.00161293
Epoch [219/300], Train Loss: 0.001462
Validation Loss: 0.00160680
Epoch [220/300], Train Loss: 0.001481
Validation Loss: 0.00160614
Epoch [221/300], Train Loss: 0.001485
Validation Loss: 0.00160557
Epoch [222/300], Train Loss: 0.001461
Validation Loss: 0.00160741
Epoch [223/300], Train Loss: 0.001477
Validation Loss: 0.00160772
Epoch [224/300], Train Loss: 0.001465
Validation Loss: 0.00161640
Epoch [225/300], Train Loss: 0.001486
Validation Loss: 0.00160203
Epoch [226/300], Train Loss: 0.001460
Validation Loss: 0.00160958
Epoch [227/300], Train Loss: 0.001483
Validation Loss: 0.00160339
Epoch [228/300], Train Loss: 0.001458
Validation Loss: 0.00161318
Epoch [229/300], Train Loss: 0.001467
Validation Loss: 0.00160840
Epoch [230/300], Train Loss: 0.001464
Validation Loss: 0.00159964
Epoch [231/300], Train Loss: 0.001447
Validation Loss: 0.00159792
Epoch [232/300], Train Loss: 0.001460
Validation Loss: 0.00159756
Epoch [233/300], Train Loss: 0.001463
Validation Loss: 0.00160286
Epoch [234/300], Train Loss: 0.001476
Validation Loss: 0.00159784
Epoch [235/300], Train Loss: 0.001471
Validation Loss: 0.00160216
Epoch [236/300], Train Loss: 0.001458
Validation Loss: 0.00159601
Epoch [237/300], Train Loss: 0.001463
Validation Loss: 0.00160771
Epoch [238/300], Train Loss: 0.001465
Validation Loss: 0.00159403
Epoch [239/300], Train Loss: 0.001441
Validation Loss: 0.00159376
Epoch [240/300], Train Loss: 0.001465
Validation Loss: 0.00159044
Epoch [241/300], Train Loss: 0.001453
Validation Loss: 0.00159671
Epoch [242/300], Train Loss: 0.001462
Validation Loss: 0.00158909
Epoch [243/300], Train Loss: 0.001462
Validation Loss: 0.00158592
Epoch [244/300], Train Loss: 0.001463
Validation Loss: 0.00159231
Epoch [245/300], Train Loss: 0.001445
Validation Loss: 0.00159135
Epoch [246/300], Train Loss: 0.001443
Validation Loss: 0.00158539
Epoch [247/300], Train Loss: 0.001447
Validation Loss: 0.00160373
Epoch [248/300], Train Loss: 0.001443
Validation Loss: 0.00158419
Epoch [249/300], Train Loss: 0.001447
Validation Loss: 0.00159459
Epoch [250/300], Train Loss: 0.001455
Validation Loss: 0.00159150
Epoch [251/300], Train Loss: 0.001462
Validation Loss: 0.00158494
Epoch [252/300], Train Loss: 0.001448
Validation Loss: 0.00159557
Epoch [253/300], Train Loss: 0.001443
Validation Loss: 0.00158779
Epoch [254/300], Train Loss: 0.001444
Validation Loss: 0.00158492
Epoch [255/300], Train Loss: 0.001447
Validation Loss: 0.00157758
Epoch [256/300], Train Loss: 0.001443
Validation Loss: 0.00158135
Epoch [257/300], Train Loss: 0.001450
Validation Loss: 0.00157640
Epoch [258/300], Train Loss: 0.001430
Validation Loss: 0.00158018
Epoch [259/300], Train Loss: 0.001444
Validation Loss: 0.00164265
Epoch [260/300], Train Loss: 0.001456
Validation Loss: 0.00158605
Epoch [261/300], Train Loss: 0.001448
Validation Loss: 0.00158147
Epoch [262/300], Train Loss: 0.001440
Validation Loss: 0.00159558
Epoch [263/300], Train Loss: 0.001448
Validation Loss: 0.00157711
Epoch [264/300], Train Loss: 0.001451
Validation Loss: 0.00157204
Epoch [265/300], Train Loss: 0.001424
Validation Loss: 0.00158321
Epoch [266/300], Train Loss: 0.001424
Validation Loss: 0.00157612
Epoch [267/300], Train Loss: 0.001433
Validation Loss: 0.00159495
Epoch [268/300], Train Loss: 0.001442
Validation Loss: 0.00157300
Epoch [269/300], Train Loss: 0.001443
Validation Loss: 0.00158800
Epoch [270/300], Train Loss: 0.001434
Validation Loss: 0.00157626
Epoch [271/300], Train Loss: 0.001428
Validation Loss: 0.00158020
Epoch [272/300], Train Loss: 0.001427
Validation Loss: 0.00158008
Epoch [273/300], Train Loss: 0.001424
Validation Loss: 0.00157516
Epoch [274/300], Train Loss: 0.001460
Validation Loss: 0.00158554
Early stopping triggered

Evaluating model for: Freezer
Run 37/72 completed in 863.77 seconds with: {'MAE': np.float32(36.636066), 'MSE': np.float32(2825.2014), 'RMSE': np.float32(53.152622), 'SAE': np.float32(0.03575273), 'NDE': np.float32(0.37258044)}

Run 38/72: hidden=256, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Freezer
Dataset length: 2322 windows

Epoch [1/300], Train Loss: 0.011746
Validation Loss: 0.00672667
Epoch [2/300], Train Loss: 0.006508
Validation Loss: 0.00602335
Epoch [3/300], Train Loss: 0.006006
Validation Loss: 0.00540838
Epoch [4/300], Train Loss: 0.005913
Validation Loss: 0.00546982
Epoch [5/300], Train Loss: 0.005857
Validation Loss: 0.00542501
Epoch [6/300], Train Loss: 0.005833
Validation Loss: 0.00540514
Epoch [7/300], Train Loss: 0.005783
Validation Loss: 0.00530600
Epoch [8/300], Train Loss: 0.005680
Validation Loss: 0.00522316
Epoch [9/300], Train Loss: 0.005367
Validation Loss: 0.00469948
Epoch [10/300], Train Loss: 0.004877
Validation Loss: 0.00434490
Epoch [11/300], Train Loss: 0.004456
Validation Loss: 0.00375385
Epoch [12/300], Train Loss: 0.003615
Validation Loss: 0.00313804
Epoch [13/300], Train Loss: 0.003149
Validation Loss: 0.00273858
Epoch [14/300], Train Loss: 0.002730
Validation Loss: 0.00240741
Epoch [15/300], Train Loss: 0.002486
Validation Loss: 0.00234360
Epoch [16/300], Train Loss: 0.002411
Validation Loss: 0.00229387
Epoch [17/300], Train Loss: 0.002341
Validation Loss: 0.00235111
Epoch [18/300], Train Loss: 0.002319
Validation Loss: 0.00229895
Epoch [19/300], Train Loss: 0.002307
Validation Loss: 0.00227433
Epoch [20/300], Train Loss: 0.002255
Validation Loss: 0.00225344
Epoch [21/300], Train Loss: 0.002247
Validation Loss: 0.00227895
Epoch [22/300], Train Loss: 0.002212
Validation Loss: 0.00223687
Epoch [23/300], Train Loss: 0.002186
Validation Loss: 0.00222594
Epoch [24/300], Train Loss: 0.002121
Validation Loss: 0.00217677
Epoch [25/300], Train Loss: 0.002105
Validation Loss: 0.00214619
Epoch [26/300], Train Loss: 0.002066
Validation Loss: 0.00209377
Epoch [27/300], Train Loss: 0.002057
Validation Loss: 0.00211128
Epoch [28/300], Train Loss: 0.001975
Validation Loss: 0.00202415
Epoch [29/300], Train Loss: 0.001966
Validation Loss: 0.00201529
Epoch [30/300], Train Loss: 0.001942
Validation Loss: 0.00198854
Epoch [31/300], Train Loss: 0.001912
Validation Loss: 0.00197189
Epoch [32/300], Train Loss: 0.001887
Validation Loss: 0.00197065
Epoch [33/300], Train Loss: 0.001899
Validation Loss: 0.00199279
Epoch [34/300], Train Loss: 0.001901
Validation Loss: 0.00198252
Epoch [35/300], Train Loss: 0.001889
Validation Loss: 0.00195401
Epoch [36/300], Train Loss: 0.001876
Validation Loss: 0.00192547
Epoch [37/300], Train Loss: 0.001862
Validation Loss: 0.00192199
Epoch [38/300], Train Loss: 0.001834
Validation Loss: 0.00190752
Epoch [39/300], Train Loss: 0.001830
Validation Loss: 0.00192783
Epoch [40/300], Train Loss: 0.001827
Validation Loss: 0.00188670
Epoch [41/300], Train Loss: 0.001787
Validation Loss: 0.00188083
Epoch [42/300], Train Loss: 0.001799
Validation Loss: 0.00193858
Epoch [43/300], Train Loss: 0.001790
Validation Loss: 0.00188244
Epoch [44/300], Train Loss: 0.001794
Validation Loss: 0.00185598
Epoch [45/300], Train Loss: 0.001774
Validation Loss: 0.00186143
Epoch [46/300], Train Loss: 0.001769
Validation Loss: 0.00184826
Epoch [47/300], Train Loss: 0.001770
Validation Loss: 0.00184463
Epoch [48/300], Train Loss: 0.001751
Validation Loss: 0.00186090
Epoch [49/300], Train Loss: 0.001750
Validation Loss: 0.00183421
Epoch [50/300], Train Loss: 0.001745
Validation Loss: 0.00184915
Epoch [51/300], Train Loss: 0.001743
Validation Loss: 0.00182337
Epoch [52/300], Train Loss: 0.001728
Validation Loss: 0.00186040
Epoch [53/300], Train Loss: 0.001752
Validation Loss: 0.00181969
Epoch [54/300], Train Loss: 0.001717
Validation Loss: 0.00182452
Epoch [55/300], Train Loss: 0.001717
Validation Loss: 0.00181351
Epoch [56/300], Train Loss: 0.001715
Validation Loss: 0.00182956
Epoch [57/300], Train Loss: 0.001741
Validation Loss: 0.00180625
Epoch [58/300], Train Loss: 0.001697
Validation Loss: 0.00180979
Epoch [59/300], Train Loss: 0.001695
Validation Loss: 0.00178843
Epoch [60/300], Train Loss: 0.001737
Validation Loss: 0.00178757
Epoch [61/300], Train Loss: 0.001720
Validation Loss: 0.00179957
Epoch [62/300], Train Loss: 0.001693
Validation Loss: 0.00178064
Epoch [63/300], Train Loss: 0.001690
Validation Loss: 0.00180231
Epoch [64/300], Train Loss: 0.001699
Validation Loss: 0.00176962
Epoch [65/300], Train Loss: 0.001653
Validation Loss: 0.00180241
Epoch [66/300], Train Loss: 0.001677
Validation Loss: 0.00182875
Epoch [67/300], Train Loss: 0.001707
Validation Loss: 0.00181590
Epoch [68/300], Train Loss: 0.001680
Validation Loss: 0.00177366
Epoch [69/300], Train Loss: 0.001659
Validation Loss: 0.00176184
Epoch [70/300], Train Loss: 0.001650
Validation Loss: 0.00180929
Epoch [71/300], Train Loss: 0.001655
Validation Loss: 0.00179861
Epoch [72/300], Train Loss: 0.001655
Validation Loss: 0.00176071
Epoch [73/300], Train Loss: 0.001658
Validation Loss: 0.00175752
Epoch [74/300], Train Loss: 0.001665
Validation Loss: 0.00176480
Epoch [75/300], Train Loss: 0.001642
Validation Loss: 0.00175739
Epoch [76/300], Train Loss: 0.001653
Validation Loss: 0.00175260
Epoch [77/300], Train Loss: 0.001644
Validation Loss: 0.00178560
Epoch [78/300], Train Loss: 0.001641
Validation Loss: 0.00176255
Epoch [79/300], Train Loss: 0.001641
Validation Loss: 0.00175684
Epoch [80/300], Train Loss: 0.001625
Validation Loss: 0.00174584
Epoch [81/300], Train Loss: 0.001631
Validation Loss: 0.00174576
Epoch [82/300], Train Loss: 0.001629
Validation Loss: 0.00174988
Epoch [83/300], Train Loss: 0.001632
Validation Loss: 0.00175880
Epoch [84/300], Train Loss: 0.001618
Validation Loss: 0.00173783
Epoch [85/300], Train Loss: 0.001634
Validation Loss: 0.00174688
Epoch [86/300], Train Loss: 0.001615
Validation Loss: 0.00174319
Epoch [87/300], Train Loss: 0.001610
Validation Loss: 0.00175191
Epoch [88/300], Train Loss: 0.001656
Validation Loss: 0.00174804
Epoch [89/300], Train Loss: 0.001621
Validation Loss: 0.00174749
Epoch [90/300], Train Loss: 0.001626
Validation Loss: 0.00178111
Epoch [91/300], Train Loss: 0.001630
Validation Loss: 0.00173999
Epoch [92/300], Train Loss: 0.001613
Validation Loss: 0.00173522
Epoch [93/300], Train Loss: 0.001587
Validation Loss: 0.00175165
Epoch [94/300], Train Loss: 0.001605
Validation Loss: 0.00175658
Epoch [95/300], Train Loss: 0.001606
Validation Loss: 0.00173329
Epoch [96/300], Train Loss: 0.001593
Validation Loss: 0.00175298
Epoch [97/300], Train Loss: 0.001613
Validation Loss: 0.00174817
Epoch [98/300], Train Loss: 0.001609
Validation Loss: 0.00173231
Epoch [99/300], Train Loss: 0.001596
Validation Loss: 0.00175147
Epoch [100/300], Train Loss: 0.001608
Validation Loss: 0.00173676
Epoch [101/300], Train Loss: 0.001597
Validation Loss: 0.00172420
Epoch [102/300], Train Loss: 0.001603
Validation Loss: 0.00173329
Epoch [103/300], Train Loss: 0.001599
Validation Loss: 0.00174015
Epoch [104/300], Train Loss: 0.001606
Validation Loss: 0.00175157
Epoch [105/300], Train Loss: 0.001580
Validation Loss: 0.00172767
Epoch [106/300], Train Loss: 0.001587
Validation Loss: 0.00171522
Epoch [107/300], Train Loss: 0.001589
Validation Loss: 0.00172159
Epoch [108/300], Train Loss: 0.001589
Validation Loss: 0.00171780
Epoch [109/300], Train Loss: 0.001586
Validation Loss: 0.00171414
Epoch [110/300], Train Loss: 0.001590
Validation Loss: 0.00173340
Epoch [111/300], Train Loss: 0.001568
Validation Loss: 0.00171158
Epoch [112/300], Train Loss: 0.001568
Validation Loss: 0.00171137
Epoch [113/300], Train Loss: 0.001574
Validation Loss: 0.00173435
Epoch [114/300], Train Loss: 0.001592
Validation Loss: 0.00170538
Epoch [115/300], Train Loss: 0.001585
Validation Loss: 0.00172141
Epoch [116/300], Train Loss: 0.001582
Validation Loss: 0.00170280
Epoch [117/300], Train Loss: 0.001578
Validation Loss: 0.00170298
Epoch [118/300], Train Loss: 0.001566
Validation Loss: 0.00170428
Epoch [119/300], Train Loss: 0.001584
Validation Loss: 0.00170787
Epoch [120/300], Train Loss: 0.001585
Validation Loss: 0.00170005
Epoch [121/300], Train Loss: 0.001585
Validation Loss: 0.00172420
Epoch [122/300], Train Loss: 0.001579
Validation Loss: 0.00170796
Epoch [123/300], Train Loss: 0.001552
Validation Loss: 0.00170683
Epoch [124/300], Train Loss: 0.001556
Validation Loss: 0.00169599
Epoch [125/300], Train Loss: 0.001541
Validation Loss: 0.00169112
Epoch [126/300], Train Loss: 0.001559
Validation Loss: 0.00169892
Epoch [127/300], Train Loss: 0.001563
Validation Loss: 0.00169609
Epoch [128/300], Train Loss: 0.001552
Validation Loss: 0.00169965
Epoch [129/300], Train Loss: 0.001562
Validation Loss: 0.00171709
Epoch [130/300], Train Loss: 0.001551
Validation Loss: 0.00170226
Epoch [131/300], Train Loss: 0.001542
Validation Loss: 0.00167394
Epoch [132/300], Train Loss: 0.001574
Validation Loss: 0.00169067
Epoch [133/300], Train Loss: 0.001530
Validation Loss: 0.00167490
Epoch [134/300], Train Loss: 0.001544
Validation Loss: 0.00166515
Epoch [135/300], Train Loss: 0.001531
Validation Loss: 0.00167563
Epoch [136/300], Train Loss: 0.001544
Validation Loss: 0.00168628
Epoch [137/300], Train Loss: 0.001538
Validation Loss: 0.00169700
Epoch [138/300], Train Loss: 0.001534
Validation Loss: 0.00168857
Epoch [139/300], Train Loss: 0.001532
Validation Loss: 0.00166070
Epoch [140/300], Train Loss: 0.001523
Validation Loss: 0.00168344
Epoch [141/300], Train Loss: 0.001531
Validation Loss: 0.00166803
Epoch [142/300], Train Loss: 0.001531
Validation Loss: 0.00166896
Epoch [143/300], Train Loss: 0.001524
Validation Loss: 0.00166147
Epoch [144/300], Train Loss: 0.001530
Validation Loss: 0.00165667
Epoch [145/300], Train Loss: 0.001518
Validation Loss: 0.00167425
Epoch [146/300], Train Loss: 0.001524
Validation Loss: 0.00167625
Epoch [147/300], Train Loss: 0.001515
Validation Loss: 0.00168138
Epoch [148/300], Train Loss: 0.001511
Validation Loss: 0.00165582
Epoch [149/300], Train Loss: 0.001540
Validation Loss: 0.00165443
Epoch [150/300], Train Loss: 0.001502
Validation Loss: 0.00164788
Epoch [151/300], Train Loss: 0.001523
Validation Loss: 0.00165900
Epoch [152/300], Train Loss: 0.001509
Validation Loss: 0.00165187
Epoch [153/300], Train Loss: 0.001517
Validation Loss: 0.00168395
Epoch [154/300], Train Loss: 0.001529
Validation Loss: 0.00164657
Epoch [155/300], Train Loss: 0.001525
Validation Loss: 0.00164939
Epoch [156/300], Train Loss: 0.001520
Validation Loss: 0.00165392
Epoch [157/300], Train Loss: 0.001538
Validation Loss: 0.00166240
Epoch [158/300], Train Loss: 0.001506
Validation Loss: 0.00166184
Epoch [159/300], Train Loss: 0.001498
Validation Loss: 0.00165806
Epoch [160/300], Train Loss: 0.001494
Validation Loss: 0.00163887
Epoch [161/300], Train Loss: 0.001509
Validation Loss: 0.00166319
Epoch [162/300], Train Loss: 0.001517
Validation Loss: 0.00168963
Epoch [163/300], Train Loss: 0.001502
Validation Loss: 0.00163137
Epoch [164/300], Train Loss: 0.001510
Validation Loss: 0.00166312
Epoch [165/300], Train Loss: 0.001502
Validation Loss: 0.00169100
Epoch [166/300], Train Loss: 0.001506
Validation Loss: 0.00163240
Epoch [167/300], Train Loss: 0.001506
Validation Loss: 0.00166499
Epoch [168/300], Train Loss: 0.001491
Validation Loss: 0.00166040
Epoch [169/300], Train Loss: 0.001505
Validation Loss: 0.00166082
Epoch [170/300], Train Loss: 0.001486
Validation Loss: 0.00164102
Epoch [171/300], Train Loss: 0.001509
Validation Loss: 0.00164364
Epoch [172/300], Train Loss: 0.001478
Validation Loss: 0.00164761
Epoch [173/300], Train Loss: 0.001469
Validation Loss: 0.00163760
Early stopping triggered

Evaluating model for: Freezer
Run 38/72 completed in 641.00 seconds with: {'MAE': np.float32(37.36483), 'MSE': np.float32(2906.925), 'RMSE': np.float32(53.91591), 'SAE': np.float32(0.010454256), 'NDE': np.float32(0.37793073)}

Run 39/72: hidden=256, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Freezer
Dataset length: 2322 windows

Epoch [1/300], Train Loss: 0.005995
Validation Loss: 0.00565029
Epoch [2/300], Train Loss: 0.005880
Validation Loss: 0.00540613
Epoch [3/300], Train Loss: 0.005852
Validation Loss: 0.00548116
Epoch [4/300], Train Loss: 0.005833
Validation Loss: 0.00540598
Epoch [5/300], Train Loss: 0.005797
Validation Loss: 0.00541049
Epoch [6/300], Train Loss: 0.005639
Validation Loss: 0.00521452
Epoch [7/300], Train Loss: 0.005221
Validation Loss: 0.00490166
Epoch [8/300], Train Loss: 0.004993
Validation Loss: 0.00490582
Epoch [9/300], Train Loss: 0.004722
Validation Loss: 0.00435078
Epoch [10/300], Train Loss: 0.004241
Validation Loss: 0.00392565
Epoch [11/300], Train Loss: 0.003623
Validation Loss: 0.00307433
Epoch [12/300], Train Loss: 0.002822
Validation Loss: 0.00273112
Epoch [13/300], Train Loss: 0.002487
Validation Loss: 0.00222999
Epoch [14/300], Train Loss: 0.002294
Validation Loss: 0.00220747
Epoch [15/300], Train Loss: 0.002203
Validation Loss: 0.00219717
Epoch [16/300], Train Loss: 0.002095
Validation Loss: 0.00214378
Epoch [17/300], Train Loss: 0.002035
Validation Loss: 0.00210540
Epoch [18/300], Train Loss: 0.001984
Validation Loss: 0.00207466
Epoch [19/300], Train Loss: 0.001974
Validation Loss: 0.00200777
Epoch [20/300], Train Loss: 0.001904
Validation Loss: 0.00202136
Epoch [21/300], Train Loss: 0.001882
Validation Loss: 0.00196135
Epoch [22/300], Train Loss: 0.001867
Validation Loss: 0.00194924
Epoch [23/300], Train Loss: 0.001898
Validation Loss: 0.00194238
Epoch [24/300], Train Loss: 0.001824
Validation Loss: 0.00192711
Epoch [25/300], Train Loss: 0.001842
Validation Loss: 0.00192036
Epoch [26/300], Train Loss: 0.001849
Validation Loss: 0.00194648
Epoch [27/300], Train Loss: 0.001840
Validation Loss: 0.00190493
Epoch [28/300], Train Loss: 0.001803
Validation Loss: 0.00190250
Epoch [29/300], Train Loss: 0.001807
Validation Loss: 0.00191193
Epoch [30/300], Train Loss: 0.001781
Validation Loss: 0.00188361
Epoch [31/300], Train Loss: 0.001761
Validation Loss: 0.00185707
Epoch [32/300], Train Loss: 0.001740
Validation Loss: 0.00186346
Epoch [33/300], Train Loss: 0.001750
Validation Loss: 0.00186929
Epoch [34/300], Train Loss: 0.001743
Validation Loss: 0.00184477
Epoch [35/300], Train Loss: 0.001713
Validation Loss: 0.00183223
Epoch [36/300], Train Loss: 0.001728
Validation Loss: 0.00182287
Epoch [37/300], Train Loss: 0.001758
Validation Loss: 0.00184586
Epoch [38/300], Train Loss: 0.001705
Validation Loss: 0.00179736
Epoch [39/300], Train Loss: 0.001691
Validation Loss: 0.00180528
Epoch [40/300], Train Loss: 0.001682
Validation Loss: 0.00178579
Epoch [41/300], Train Loss: 0.001668
Validation Loss: 0.00180748
Epoch [42/300], Train Loss: 0.001685
Validation Loss: 0.00185326
Epoch [43/300], Train Loss: 0.001669
Validation Loss: 0.00178900
Epoch [44/300], Train Loss: 0.001679
Validation Loss: 0.00177897
Epoch [45/300], Train Loss: 0.001667
Validation Loss: 0.00177984
Epoch [46/300], Train Loss: 0.001652
Validation Loss: 0.00177302
Epoch [47/300], Train Loss: 0.001656
Validation Loss: 0.00178555
Epoch [48/300], Train Loss: 0.001649
Validation Loss: 0.00181258
Epoch [49/300], Train Loss: 0.001655
Validation Loss: 0.00178910
Epoch [50/300], Train Loss: 0.001658
Validation Loss: 0.00179009
Epoch [51/300], Train Loss: 0.001649
Validation Loss: 0.00176989
Epoch [52/300], Train Loss: 0.001629
Validation Loss: 0.00181915
Epoch [53/300], Train Loss: 0.001665
Validation Loss: 0.00176616
Epoch [54/300], Train Loss: 0.001628
Validation Loss: 0.00179765
Epoch [55/300], Train Loss: 0.001644
Validation Loss: 0.00176192
Epoch [56/300], Train Loss: 0.001639
Validation Loss: 0.00178814
Epoch [57/300], Train Loss: 0.001665
Validation Loss: 0.00175650
Epoch [58/300], Train Loss: 0.001626
Validation Loss: 0.00177728
Epoch [59/300], Train Loss: 0.001627
Validation Loss: 0.00174903
Epoch [60/300], Train Loss: 0.001660
Validation Loss: 0.00174976
Epoch [61/300], Train Loss: 0.001653
Validation Loss: 0.00177276
Epoch [62/300], Train Loss: 0.001618
Validation Loss: 0.00174911
Epoch [63/300], Train Loss: 0.001621
Validation Loss: 0.00176108
Epoch [64/300], Train Loss: 0.001642
Validation Loss: 0.00174531
Epoch [65/300], Train Loss: 0.001608
Validation Loss: 0.00175758
Epoch [66/300], Train Loss: 0.001622
Validation Loss: 0.00175982
Epoch [67/300], Train Loss: 0.001616
Validation Loss: 0.00178176
Epoch [68/300], Train Loss: 0.001625
Validation Loss: 0.00175849
Epoch [69/300], Train Loss: 0.001617
Validation Loss: 0.00174435
Epoch [70/300], Train Loss: 0.001604
Validation Loss: 0.00177542
Epoch [71/300], Train Loss: 0.001592
Validation Loss: 0.00174969
Epoch [72/300], Train Loss: 0.001599
Validation Loss: 0.00174071
Epoch [73/300], Train Loss: 0.001614
Validation Loss: 0.00175062
Epoch [74/300], Train Loss: 0.001620
Validation Loss: 0.00173076
Epoch [75/300], Train Loss: 0.001599
Validation Loss: 0.00174583
Epoch [76/300], Train Loss: 0.001597
Validation Loss: 0.00173006
Epoch [77/300], Train Loss: 0.001597
Validation Loss: 0.00174902
Epoch [78/300], Train Loss: 0.001589
Validation Loss: 0.00175049
Epoch [79/300], Train Loss: 0.001597
Validation Loss: 0.00173531
Epoch [80/300], Train Loss: 0.001567
Validation Loss: 0.00172780
Epoch [81/300], Train Loss: 0.001580
Validation Loss: 0.00171595
Epoch [82/300], Train Loss: 0.001577
Validation Loss: 0.00172490
Epoch [83/300], Train Loss: 0.001580
Validation Loss: 0.00173850
Epoch [84/300], Train Loss: 0.001566
Validation Loss: 0.00171499
Epoch [85/300], Train Loss: 0.001577
Validation Loss: 0.00171368
Epoch [86/300], Train Loss: 0.001560
Validation Loss: 0.00170618
Epoch [87/300], Train Loss: 0.001549
Validation Loss: 0.00171332
Epoch [88/300], Train Loss: 0.001593
Validation Loss: 0.00170519
Epoch [89/300], Train Loss: 0.001554
Validation Loss: 0.00171226
Epoch [90/300], Train Loss: 0.001549
Validation Loss: 0.00171863
Epoch [91/300], Train Loss: 0.001565
Validation Loss: 0.00172427
Epoch [92/300], Train Loss: 0.001592
Validation Loss: 0.00170219
Epoch [93/300], Train Loss: 0.001546
Validation Loss: 0.00173712
Epoch [94/300], Train Loss: 0.001544
Validation Loss: 0.00171105
Epoch [95/300], Train Loss: 0.001549
Validation Loss: 0.00169937
Epoch [96/300], Train Loss: 0.001539
Validation Loss: 0.00169441
Epoch [97/300], Train Loss: 0.001551
Validation Loss: 0.00168853
Epoch [98/300], Train Loss: 0.001540
Validation Loss: 0.00168744
Epoch [99/300], Train Loss: 0.001532
Validation Loss: 0.00167007
Epoch [100/300], Train Loss: 0.001544
Validation Loss: 0.00169356
Epoch [101/300], Train Loss: 0.001547
Validation Loss: 0.00166786
Epoch [102/300], Train Loss: 0.001533
Validation Loss: 0.00168428
Epoch [103/300], Train Loss: 0.001509
Validation Loss: 0.00168637
Epoch [104/300], Train Loss: 0.001541
Validation Loss: 0.00168377
Epoch [105/300], Train Loss: 0.001500
Validation Loss: 0.00164308
Epoch [106/300], Train Loss: 0.001511
Validation Loss: 0.00164958
Epoch [107/300], Train Loss: 0.001523
Validation Loss: 0.00169251
Epoch [108/300], Train Loss: 0.001514
Validation Loss: 0.00167528
Epoch [109/300], Train Loss: 0.001509
Validation Loss: 0.00165449
Epoch [110/300], Train Loss: 0.001507
Validation Loss: 0.00167350
Epoch [111/300], Train Loss: 0.001489
Validation Loss: 0.00166207
Epoch [112/300], Train Loss: 0.001524
Validation Loss: 0.00170711
Epoch [113/300], Train Loss: 0.001523
Validation Loss: 0.00168468
Epoch [114/300], Train Loss: 0.001529
Validation Loss: 0.00164743
Epoch [115/300], Train Loss: 0.001508
Validation Loss: 0.00166673
Early stopping triggered

Evaluating model for: Freezer
Run 39/72 completed in 486.52 seconds with: {'MAE': np.float32(38.05216), 'MSE': np.float32(3011.852), 'RMSE': np.float32(54.880344), 'SAE': np.float32(0.058737468), 'NDE': np.float32(0.38469112)}

Run 40/72: hidden=256, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Freezer
Dataset length: 2322 windows

Epoch [1/300], Train Loss: 0.009155
Validation Loss: 0.00573140
Epoch [2/300], Train Loss: 0.006119
Validation Loss: 0.00574401
Epoch [3/300], Train Loss: 0.005913
Validation Loss: 0.00541195
Epoch [4/300], Train Loss: 0.005897
Validation Loss: 0.00550366
Epoch [5/300], Train Loss: 0.005859
Validation Loss: 0.00543671
Epoch [6/300], Train Loss: 0.005842
Validation Loss: 0.00544388
Epoch [7/300], Train Loss: 0.005745
Validation Loss: 0.00519878
Epoch [8/300], Train Loss: 0.005035
Validation Loss: 0.00421870
Epoch [9/300], Train Loss: 0.004360
Validation Loss: 0.00406448
Epoch [10/300], Train Loss: 0.004090
Validation Loss: 0.00389696
Epoch [11/300], Train Loss: 0.003992
Validation Loss: 0.00373865
Epoch [12/300], Train Loss: 0.003736
Validation Loss: 0.00358781
Epoch [13/300], Train Loss: 0.003623
Validation Loss: 0.00339948
Epoch [14/300], Train Loss: 0.003358
Validation Loss: 0.00318260
Epoch [15/300], Train Loss: 0.003143
Validation Loss: 0.00297126
Epoch [16/300], Train Loss: 0.002936
Validation Loss: 0.00290033
Epoch [17/300], Train Loss: 0.002972
Validation Loss: 0.00289993
Epoch [18/300], Train Loss: 0.002773
Validation Loss: 0.00275521
Epoch [19/300], Train Loss: 0.002617
Validation Loss: 0.00281726
Epoch [20/300], Train Loss: 0.002531
Validation Loss: 0.00260558
Epoch [21/300], Train Loss: 0.002453
Validation Loss: 0.00261511
Epoch [22/300], Train Loss: 0.002460
Validation Loss: 0.00250099
Epoch [23/300], Train Loss: 0.002363
Validation Loss: 0.00251068
Epoch [24/300], Train Loss: 0.002310
Validation Loss: 0.00246278
Epoch [25/300], Train Loss: 0.002333
Validation Loss: 0.00265837
Epoch [26/300], Train Loss: 0.002502
Validation Loss: 0.00259755
Epoch [27/300], Train Loss: 0.002332
Validation Loss: 0.00240975
Epoch [28/300], Train Loss: 0.002264
Validation Loss: 0.00238969
Epoch [29/300], Train Loss: 0.002207
Validation Loss: 0.00238583
Epoch [30/300], Train Loss: 0.002165
Validation Loss: 0.00231061
Epoch [31/300], Train Loss: 0.002167
Validation Loss: 0.00234086
Epoch [32/300], Train Loss: 0.002150
Validation Loss: 0.00232787
Epoch [33/300], Train Loss: 0.002311
Validation Loss: 0.00271917
Epoch [34/300], Train Loss: 0.002418
Validation Loss: 0.00241682
Epoch [35/300], Train Loss: 0.002170
Validation Loss: 0.00227862
Epoch [36/300], Train Loss: 0.002139
Validation Loss: 0.00229274
Epoch [37/300], Train Loss: 0.002110
Validation Loss: 0.00224648
Epoch [38/300], Train Loss: 0.002060
Validation Loss: 0.00223862
Epoch [39/300], Train Loss: 0.002162
Validation Loss: 0.00251363
Epoch [40/300], Train Loss: 0.002276
Validation Loss: 0.00232487
Epoch [41/300], Train Loss: 0.002080
Validation Loss: 0.00221312
Epoch [42/300], Train Loss: 0.002047
Validation Loss: 0.00223425
Epoch [43/300], Train Loss: 0.002007
Validation Loss: 0.00219625
Epoch [44/300], Train Loss: 0.001992
Validation Loss: 0.00220380
Epoch [45/300], Train Loss: 0.002006
Validation Loss: 0.00223078
Epoch [46/300], Train Loss: 0.002009
Validation Loss: 0.00214678
Epoch [47/300], Train Loss: 0.002037
Validation Loss: 0.00215441
Epoch [48/300], Train Loss: 0.002011
Validation Loss: 0.00217884
Epoch [49/300], Train Loss: 0.002046
Validation Loss: 0.00220235
Epoch [50/300], Train Loss: 0.001984
Validation Loss: 0.00214314
Epoch [51/300], Train Loss: 0.001981
Validation Loss: 0.00216229
Epoch [52/300], Train Loss: 0.001947
Validation Loss: 0.00220129
Epoch [53/300], Train Loss: 0.002165
Validation Loss: 0.00224832
Epoch [54/300], Train Loss: 0.002002
Validation Loss: 0.00215799
Epoch [55/300], Train Loss: 0.001980
Validation Loss: 0.00211842
Epoch [56/300], Train Loss: 0.001910
Validation Loss: 0.00210238
Epoch [57/300], Train Loss: 0.001936
Validation Loss: 0.00205812
Epoch [58/300], Train Loss: 0.001912
Validation Loss: 0.00207424
Epoch [59/300], Train Loss: 0.001912
Validation Loss: 0.00204315
Epoch [60/300], Train Loss: 0.001923
Validation Loss: 0.00214907
Epoch [61/300], Train Loss: 0.001966
Validation Loss: 0.00209813
Epoch [62/300], Train Loss: 0.001896
Validation Loss: 0.00209727
Epoch [63/300], Train Loss: 0.001885
Validation Loss: 0.00207458
Epoch [64/300], Train Loss: 0.001937
Validation Loss: 0.00206014
Epoch [65/300], Train Loss: 0.001873
Validation Loss: 0.00204122
Epoch [66/300], Train Loss: 0.001862
Validation Loss: 0.00202263
Epoch [67/300], Train Loss: 0.001851
Validation Loss: 0.00203619
Epoch [68/300], Train Loss: 0.001881
Validation Loss: 0.00205488
Epoch [69/300], Train Loss: 0.001869
Validation Loss: 0.00203538
Epoch [70/300], Train Loss: 0.001838
Validation Loss: 0.00200420
Epoch [71/300], Train Loss: 0.002361
Validation Loss: 0.00261946
Epoch [72/300], Train Loss: 0.002250
Validation Loss: 0.00218623
Epoch [73/300], Train Loss: 0.002056
Validation Loss: 0.00206587
Epoch [74/300], Train Loss: 0.001988
Validation Loss: 0.00205436
Epoch [75/300], Train Loss: 0.001976
Validation Loss: 0.00206067
Epoch [76/300], Train Loss: 0.001959
Validation Loss: 0.00205101
Epoch [77/300], Train Loss: 0.001942
Validation Loss: 0.00204749
Epoch [78/300], Train Loss: 0.001918
Validation Loss: 0.00206493
Epoch [79/300], Train Loss: 0.001933
Validation Loss: 0.00203409
Epoch [80/300], Train Loss: 0.001905
Validation Loss: 0.00206110
Early stopping triggered

Evaluating model for: Freezer
Run 40/72 completed in 426.79 seconds with: {'MAE': np.float32(42.16363), 'MSE': np.float32(3667.0364), 'RMSE': np.float32(60.55606), 'SAE': np.float32(0.014727767), 'NDE': np.float32(0.42447582)}

Run 41/72: hidden=256, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Freezer
Dataset length: 2262 windows

Epoch [1/300], Train Loss: 0.007271
Validation Loss: 0.00598772
Epoch [2/300], Train Loss: 0.005873
Validation Loss: 0.00592233
Epoch [3/300], Train Loss: 0.005742
Validation Loss: 0.00593085
Epoch [4/300], Train Loss: 0.005788
Validation Loss: 0.00582884
Epoch [5/300], Train Loss: 0.005722
Validation Loss: 0.00575525
Epoch [6/300], Train Loss: 0.005602
Validation Loss: 0.00563017
Epoch [7/300], Train Loss: 0.005514
Validation Loss: 0.00544467
Epoch [8/300], Train Loss: 0.005189
Validation Loss: 0.00509685
Epoch [9/300], Train Loss: 0.004806
Validation Loss: 0.00480813
Epoch [10/300], Train Loss: 0.004588
Validation Loss: 0.00451848
Epoch [11/300], Train Loss: 0.004251
Validation Loss: 0.00419481
Epoch [12/300], Train Loss: 0.003953
Validation Loss: 0.00383476
Epoch [13/300], Train Loss: 0.003527
Validation Loss: 0.00319076
Epoch [14/300], Train Loss: 0.002996
Validation Loss: 0.00267468
Epoch [15/300], Train Loss: 0.002689
Validation Loss: 0.00254264
Epoch [16/300], Train Loss: 0.002644
Validation Loss: 0.00247065
Epoch [17/300], Train Loss: 0.002535
Validation Loss: 0.00233303
Epoch [18/300], Train Loss: 0.002471
Validation Loss: 0.00228939
Epoch [19/300], Train Loss: 0.002347
Validation Loss: 0.00226281
Epoch [20/300], Train Loss: 0.002401
Validation Loss: 0.00222245
Epoch [21/300], Train Loss: 0.002404
Validation Loss: 0.00233691
Epoch [22/300], Train Loss: 0.002431
Validation Loss: 0.00214748
Epoch [23/300], Train Loss: 0.002208
Validation Loss: 0.00212603
Epoch [24/300], Train Loss: 0.002224
Validation Loss: 0.00206892
Epoch [25/300], Train Loss: 0.002128
Validation Loss: 0.00224586
Epoch [26/300], Train Loss: 0.002126
Validation Loss: 0.00198831
Epoch [27/300], Train Loss: 0.002000
Validation Loss: 0.00187874
Epoch [28/300], Train Loss: 0.001881
Validation Loss: 0.00208272
Epoch [29/300], Train Loss: 0.002013
Validation Loss: 0.00181211
Epoch [30/300], Train Loss: 0.001933
Validation Loss: 0.00185035
Epoch [31/300], Train Loss: 0.001860
Validation Loss: 0.00178489
Epoch [32/300], Train Loss: 0.001868
Validation Loss: 0.00177087
Epoch [33/300], Train Loss: 0.001901
Validation Loss: 0.00181399
Epoch [34/300], Train Loss: 0.001854
Validation Loss: 0.00180060
Epoch [35/300], Train Loss: 0.001945
Validation Loss: 0.00173276
Epoch [36/300], Train Loss: 0.001840
Validation Loss: 0.00173423
Epoch [37/300], Train Loss: 0.001823
Validation Loss: 0.00172592
Epoch [38/300], Train Loss: 0.001800
Validation Loss: 0.00173280
Epoch [39/300], Train Loss: 0.001822
Validation Loss: 0.00171012
Epoch [40/300], Train Loss: 0.001786
Validation Loss: 0.00173604
Epoch [41/300], Train Loss: 0.001754
Validation Loss: 0.00169694
Epoch [42/300], Train Loss: 0.001783
Validation Loss: 0.00169539
Epoch [43/300], Train Loss: 0.001743
Validation Loss: 0.00170505
Epoch [44/300], Train Loss: 0.001782
Validation Loss: 0.00172179
Epoch [45/300], Train Loss: 0.001728
Validation Loss: 0.00170756
Epoch [46/300], Train Loss: 0.001788
Validation Loss: 0.00170003
Epoch [47/300], Train Loss: 0.001753
Validation Loss: 0.00167662
Epoch [48/300], Train Loss: 0.001766
Validation Loss: 0.00169818
Epoch [49/300], Train Loss: 0.001806
Validation Loss: 0.00167198
Epoch [50/300], Train Loss: 0.001752
Validation Loss: 0.00170242
Epoch [51/300], Train Loss: 0.001753
Validation Loss: 0.00171859
Epoch [52/300], Train Loss: 0.001770
Validation Loss: 0.00167311
Epoch [53/300], Train Loss: 0.001734
Validation Loss: 0.00165429
Epoch [54/300], Train Loss: 0.001800
Validation Loss: 0.00166327
Epoch [55/300], Train Loss: 0.001781
Validation Loss: 0.00166048
Epoch [56/300], Train Loss: 0.001714
Validation Loss: 0.00165370
Epoch [57/300], Train Loss: 0.001736
Validation Loss: 0.00164670
Epoch [58/300], Train Loss: 0.001727
Validation Loss: 0.00167387
Epoch [59/300], Train Loss: 0.001711
Validation Loss: 0.00164304
Epoch [60/300], Train Loss: 0.001748
Validation Loss: 0.00167951
Epoch [61/300], Train Loss: 0.001739
Validation Loss: 0.00164605
Epoch [62/300], Train Loss: 0.001727
Validation Loss: 0.00163631
Epoch [63/300], Train Loss: 0.001718
Validation Loss: 0.00167872
Epoch [64/300], Train Loss: 0.001712
Validation Loss: 0.00163132
Epoch [65/300], Train Loss: 0.001719
Validation Loss: 0.00163406
Epoch [66/300], Train Loss: 0.001731
Validation Loss: 0.00164235
Epoch [67/300], Train Loss: 0.001727
Validation Loss: 0.00163407
Epoch [68/300], Train Loss: 0.001783
Validation Loss: 0.00162445
Epoch [69/300], Train Loss: 0.001760
Validation Loss: 0.00162362
Epoch [70/300], Train Loss: 0.001693
Validation Loss: 0.00162300
Epoch [71/300], Train Loss: 0.001711
Validation Loss: 0.00165332
Epoch [72/300], Train Loss: 0.001703
Validation Loss: 0.00164602
Epoch [73/300], Train Loss: 0.001628
Validation Loss: 0.00161817
Epoch [74/300], Train Loss: 0.001804
Validation Loss: 0.00161497
Epoch [75/300], Train Loss: 0.001732
Validation Loss: 0.00161046
Epoch [76/300], Train Loss: 0.001700
Validation Loss: 0.00163208
Epoch [77/300], Train Loss: 0.001695
Validation Loss: 0.00167495
Epoch [78/300], Train Loss: 0.001717
Validation Loss: 0.00163193
Epoch [79/300], Train Loss: 0.001654
Validation Loss: 0.00160559
Epoch [80/300], Train Loss: 0.001730
Validation Loss: 0.00160192
Epoch [81/300], Train Loss: 0.001663
Validation Loss: 0.00163518
Epoch [82/300], Train Loss: 0.001668
Validation Loss: 0.00164149
Epoch [83/300], Train Loss: 0.001720
Validation Loss: 0.00162845
Epoch [84/300], Train Loss: 0.001609
Validation Loss: 0.00159812
Epoch [85/300], Train Loss: 0.001651
Validation Loss: 0.00159385
Epoch [86/300], Train Loss: 0.001679
Validation Loss: 0.00159130
Epoch [87/300], Train Loss: 0.001683
Validation Loss: 0.00158926
Epoch [88/300], Train Loss: 0.001678
Validation Loss: 0.00158669
Epoch [89/300], Train Loss: 0.001654
Validation Loss: 0.00162391
Epoch [90/300], Train Loss: 0.001702
Validation Loss: 0.00160369
Epoch [91/300], Train Loss: 0.001634
Validation Loss: 0.00163579
Epoch [92/300], Train Loss: 0.001627
Validation Loss: 0.00157796
Epoch [93/300], Train Loss: 0.001695
Validation Loss: 0.00159769
Epoch [94/300], Train Loss: 0.001661
Validation Loss: 0.00157973
Epoch [95/300], Train Loss: 0.001696
Validation Loss: 0.00158498
Epoch [96/300], Train Loss: 0.001749
Validation Loss: 0.00158003
Epoch [97/300], Train Loss: 0.001588
Validation Loss: 0.00156766
Epoch [98/300], Train Loss: 0.001687
Validation Loss: 0.00156848
Epoch [99/300], Train Loss: 0.001667
Validation Loss: 0.00157301
Epoch [100/300], Train Loss: 0.001623
Validation Loss: 0.00156519
Epoch [101/300], Train Loss: 0.001613
Validation Loss: 0.00157104
Epoch [102/300], Train Loss: 0.001661
Validation Loss: 0.00156880
Epoch [103/300], Train Loss: 0.001621
Validation Loss: 0.00156337
Epoch [104/300], Train Loss: 0.001617
Validation Loss: 0.00154879
Epoch [105/300], Train Loss: 0.001600
Validation Loss: 0.00155054
Epoch [106/300], Train Loss: 0.001580
Validation Loss: 0.00154598
Epoch [107/300], Train Loss: 0.001575
Validation Loss: 0.00157505
Epoch [108/300], Train Loss: 0.001637
Validation Loss: 0.00154840
Epoch [109/300], Train Loss: 0.001647
Validation Loss: 0.00155720
Epoch [110/300], Train Loss: 0.001600
Validation Loss: 0.00155213
Epoch [111/300], Train Loss: 0.001612
Validation Loss: 0.00155537
Epoch [112/300], Train Loss: 0.001593
Validation Loss: 0.00153748
Epoch [113/300], Train Loss: 0.001616
Validation Loss: 0.00154778
Epoch [114/300], Train Loss: 0.001615
Validation Loss: 0.00153158
Epoch [115/300], Train Loss: 0.001645
Validation Loss: 0.00153231
Epoch [116/300], Train Loss: 0.001628
Validation Loss: 0.00156822
Epoch [117/300], Train Loss: 0.001641
Validation Loss: 0.00153964
Epoch [118/300], Train Loss: 0.001595
Validation Loss: 0.00155038
Epoch [119/300], Train Loss: 0.001686
Validation Loss: 0.00153764
Epoch [120/300], Train Loss: 0.001598
Validation Loss: 0.00153146
Epoch [121/300], Train Loss: 0.001623
Validation Loss: 0.00153310
Epoch [122/300], Train Loss: 0.001631
Validation Loss: 0.00152961
Epoch [123/300], Train Loss: 0.001586
Validation Loss: 0.00152873
Epoch [124/300], Train Loss: 0.001616
Validation Loss: 0.00154418
Epoch [125/300], Train Loss: 0.001635
Validation Loss: 0.00152465
Epoch [126/300], Train Loss: 0.001595
Validation Loss: 0.00152600
Epoch [127/300], Train Loss: 0.001622
Validation Loss: 0.00155363
Epoch [128/300], Train Loss: 0.001585
Validation Loss: 0.00152628
Epoch [129/300], Train Loss: 0.001588
Validation Loss: 0.00151508
Epoch [130/300], Train Loss: 0.001658
Validation Loss: 0.00152789
Epoch [131/300], Train Loss: 0.001626
Validation Loss: 0.00152566
Epoch [132/300], Train Loss: 0.001572
Validation Loss: 0.00152827
Epoch [133/300], Train Loss: 0.001580
Validation Loss: 0.00151320
Epoch [134/300], Train Loss: 0.001573
Validation Loss: 0.00151008
Epoch [135/300], Train Loss: 0.001651
Validation Loss: 0.00155713
Epoch [136/300], Train Loss: 0.001571
Validation Loss: 0.00151113
Epoch [137/300], Train Loss: 0.001586
Validation Loss: 0.00150796
Epoch [138/300], Train Loss: 0.001606
Validation Loss: 0.00150583
Epoch [139/300], Train Loss: 0.001540
Validation Loss: 0.00152264
Epoch [140/300], Train Loss: 0.001537
Validation Loss: 0.00151820
Epoch [141/300], Train Loss: 0.001623
Validation Loss: 0.00151944
Epoch [142/300], Train Loss: 0.001559
Validation Loss: 0.00150523
Epoch [143/300], Train Loss: 0.001572
Validation Loss: 0.00150692
Epoch [144/300], Train Loss: 0.001602
Validation Loss: 0.00152637
Epoch [145/300], Train Loss: 0.001644
Validation Loss: 0.00151017
Epoch [146/300], Train Loss: 0.001582
Validation Loss: 0.00149477
Epoch [147/300], Train Loss: 0.001614
Validation Loss: 0.00153274
Epoch [148/300], Train Loss: 0.001588
Validation Loss: 0.00149908
Epoch [149/300], Train Loss: 0.001563
Validation Loss: 0.00149351
Epoch [150/300], Train Loss: 0.001532
Validation Loss: 0.00149679
Epoch [151/300], Train Loss: 0.001626
Validation Loss: 0.00149068
Epoch [152/300], Train Loss: 0.001611
Validation Loss: 0.00149071
Epoch [153/300], Train Loss: 0.001598
Validation Loss: 0.00150059
Epoch [154/300], Train Loss: 0.001593
Validation Loss: 0.00150029
Epoch [155/300], Train Loss: 0.001659
Validation Loss: 0.00149033
Epoch [156/300], Train Loss: 0.001584
Validation Loss: 0.00149432
Epoch [157/300], Train Loss: 0.001568
Validation Loss: 0.00148743
Epoch [158/300], Train Loss: 0.001601
Validation Loss: 0.00149724
Epoch [159/300], Train Loss: 0.001589
Validation Loss: 0.00148575
Epoch [160/300], Train Loss: 0.001537
Validation Loss: 0.00149167
Epoch [161/300], Train Loss: 0.001598
Validation Loss: 0.00148421
Epoch [162/300], Train Loss: 0.001519
Validation Loss: 0.00148576
Epoch [163/300], Train Loss: 0.001625
Validation Loss: 0.00148644
Epoch [164/300], Train Loss: 0.001529
Validation Loss: 0.00152735
Epoch [165/300], Train Loss: 0.001529
Validation Loss: 0.00148174
Epoch [166/300], Train Loss: 0.001531
Validation Loss: 0.00148572
Epoch [167/300], Train Loss: 0.001522
Validation Loss: 0.00147925
Epoch [168/300], Train Loss: 0.001597
Validation Loss: 0.00148196
Epoch [169/300], Train Loss: 0.001546
Validation Loss: 0.00147989
Epoch [170/300], Train Loss: 0.001584
Validation Loss: 0.00147928
Epoch [171/300], Train Loss: 0.001577
Validation Loss: 0.00147588
Epoch [172/300], Train Loss: 0.001568
Validation Loss: 0.00148088
Epoch [173/300], Train Loss: 0.001594
Validation Loss: 0.00148095
Epoch [174/300], Train Loss: 0.001538
Validation Loss: 0.00148518
Epoch [175/300], Train Loss: 0.001553
Validation Loss: 0.00149437
Epoch [176/300], Train Loss: 0.001573
Validation Loss: 0.00147661
Epoch [177/300], Train Loss: 0.001579
Validation Loss: 0.00149262
Epoch [178/300], Train Loss: 0.001550
Validation Loss: 0.00148774
Epoch [179/300], Train Loss: 0.001545
Validation Loss: 0.00147150
Epoch [180/300], Train Loss: 0.001589
Validation Loss: 0.00152345
Epoch [181/300], Train Loss: 0.001540
Validation Loss: 0.00147343
Epoch [182/300], Train Loss: 0.001623
Validation Loss: 0.00147084
Epoch [183/300], Train Loss: 0.001564
Validation Loss: 0.00146951
Epoch [184/300], Train Loss: 0.001627
Validation Loss: 0.00147071
Epoch [185/300], Train Loss: 0.001606
Validation Loss: 0.00147016
Epoch [186/300], Train Loss: 0.001556
Validation Loss: 0.00146606
Epoch [187/300], Train Loss: 0.001514
Validation Loss: 0.00147295
Epoch [188/300], Train Loss: 0.001551
Validation Loss: 0.00146912
Epoch [189/300], Train Loss: 0.001560
Validation Loss: 0.00146572
Epoch [190/300], Train Loss: 0.001542
Validation Loss: 0.00148242
Epoch [191/300], Train Loss: 0.001613
Validation Loss: 0.00146753
Epoch [192/300], Train Loss: 0.001606
Validation Loss: 0.00149745
Epoch [193/300], Train Loss: 0.001604
Validation Loss: 0.00147210
Epoch [194/300], Train Loss: 0.001529
Validation Loss: 0.00147443
Epoch [195/300], Train Loss: 0.001596
Validation Loss: 0.00147829
Epoch [196/300], Train Loss: 0.001598
Validation Loss: 0.00146565
Epoch [197/300], Train Loss: 0.001539
Validation Loss: 0.00146384
Epoch [198/300], Train Loss: 0.001522
Validation Loss: 0.00146065
Epoch [199/300], Train Loss: 0.001542
Validation Loss: 0.00146218
Epoch [200/300], Train Loss: 0.001609
Validation Loss: 0.00146749
Epoch [201/300], Train Loss: 0.001521
Validation Loss: 0.00147004
Epoch [202/300], Train Loss: 0.001584
Validation Loss: 0.00145826
Epoch [203/300], Train Loss: 0.001534
Validation Loss: 0.00146580
Epoch [204/300], Train Loss: 0.001550
Validation Loss: 0.00146701
Epoch [205/300], Train Loss: 0.001539
Validation Loss: 0.00146176
Epoch [206/300], Train Loss: 0.001563
Validation Loss: 0.00146711
Epoch [207/300], Train Loss: 0.001525
Validation Loss: 0.00146442
Epoch [208/300], Train Loss: 0.001526
Validation Loss: 0.00146589
Epoch [209/300], Train Loss: 0.001537
Validation Loss: 0.00145837
Epoch [210/300], Train Loss: 0.001506
Validation Loss: 0.00146333
Epoch [211/300], Train Loss: 0.001499
Validation Loss: 0.00145414
Epoch [212/300], Train Loss: 0.001549
Validation Loss: 0.00145228
Epoch [213/300], Train Loss: 0.001574
Validation Loss: 0.00145291
Epoch [214/300], Train Loss: 0.001558
Validation Loss: 0.00145430
Epoch [215/300], Train Loss: 0.001522
Validation Loss: 0.00146729
Epoch [216/300], Train Loss: 0.001557
Validation Loss: 0.00144910
Epoch [217/300], Train Loss: 0.001497
Validation Loss: 0.00144903
Epoch [218/300], Train Loss: 0.001528
Validation Loss: 0.00146260
Epoch [219/300], Train Loss: 0.001539
Validation Loss: 0.00144861
Epoch [220/300], Train Loss: 0.001562
Validation Loss: 0.00145703
Epoch [221/300], Train Loss: 0.001564
Validation Loss: 0.00144367
Epoch [222/300], Train Loss: 0.001510
Validation Loss: 0.00145106
Epoch [223/300], Train Loss: 0.001516
Validation Loss: 0.00144854
Epoch [224/300], Train Loss: 0.001535
Validation Loss: 0.00144591
Epoch [225/300], Train Loss: 0.001509
Validation Loss: 0.00144929
Epoch [226/300], Train Loss: 0.001466
Validation Loss: 0.00148361
Epoch [227/300], Train Loss: 0.001554
Validation Loss: 0.00144989
Epoch [228/300], Train Loss: 0.001544
Validation Loss: 0.00144226
Epoch [229/300], Train Loss: 0.001552
Validation Loss: 0.00144334
Epoch [230/300], Train Loss: 0.001524
Validation Loss: 0.00144037
Epoch [231/300], Train Loss: 0.001505
Validation Loss: 0.00144452
Epoch [232/300], Train Loss: 0.001466
Validation Loss: 0.00143858
Epoch [233/300], Train Loss: 0.001538
Validation Loss: 0.00144024
Epoch [234/300], Train Loss: 0.001512
Validation Loss: 0.00145204
Epoch [235/300], Train Loss: 0.001532
Validation Loss: 0.00144111
Epoch [236/300], Train Loss: 0.001454
Validation Loss: 0.00146026
Epoch [237/300], Train Loss: 0.001515
Validation Loss: 0.00145766
Epoch [238/300], Train Loss: 0.001551
Validation Loss: 0.00143652
Epoch [239/300], Train Loss: 0.001486
Validation Loss: 0.00144008
Epoch [240/300], Train Loss: 0.001514
Validation Loss: 0.00143947
Epoch [241/300], Train Loss: 0.001485
Validation Loss: 0.00144247
Epoch [242/300], Train Loss: 0.001561
Validation Loss: 0.00143778
Epoch [243/300], Train Loss: 0.001524
Validation Loss: 0.00143439
Epoch [244/300], Train Loss: 0.001542
Validation Loss: 0.00145274
Epoch [245/300], Train Loss: 0.001515
Validation Loss: 0.00143493
Epoch [246/300], Train Loss: 0.001494
Validation Loss: 0.00143709
Epoch [247/300], Train Loss: 0.001509
Validation Loss: 0.00143275
Epoch [248/300], Train Loss: 0.001491
Validation Loss: 0.00143309
Epoch [249/300], Train Loss: 0.001531
Validation Loss: 0.00143585
Epoch [250/300], Train Loss: 0.001504
Validation Loss: 0.00143109
Epoch [251/300], Train Loss: 0.001474
Validation Loss: 0.00143532
Epoch [252/300], Train Loss: 0.001519
Validation Loss: 0.00142942
Epoch [253/300], Train Loss: 0.001477
Validation Loss: 0.00144704
Epoch [254/300], Train Loss: 0.001579
Validation Loss: 0.00143778
Epoch [255/300], Train Loss: 0.001487
Validation Loss: 0.00142728
Epoch [256/300], Train Loss: 0.001488
Validation Loss: 0.00144112
Epoch [257/300], Train Loss: 0.001490
Validation Loss: 0.00143214
Epoch [258/300], Train Loss: 0.001502
Validation Loss: 0.00143241
Epoch [259/300], Train Loss: 0.001486
Validation Loss: 0.00142963
Epoch [260/300], Train Loss: 0.001440
Validation Loss: 0.00142456
Epoch [261/300], Train Loss: 0.001564
Validation Loss: 0.00146325
Epoch [262/300], Train Loss: 0.001533
Validation Loss: 0.00145757
Epoch [263/300], Train Loss: 0.001483
Validation Loss: 0.00144599
Epoch [264/300], Train Loss: 0.001498
Validation Loss: 0.00142635
Epoch [265/300], Train Loss: 0.001471
Validation Loss: 0.00141747
Epoch [266/300], Train Loss: 0.001446
Validation Loss: 0.00142355
Epoch [267/300], Train Loss: 0.001453
Validation Loss: 0.00142572
Epoch [268/300], Train Loss: 0.001491
Validation Loss: 0.00143305
Epoch [269/300], Train Loss: 0.001438
Validation Loss: 0.00144020
Epoch [270/300], Train Loss: 0.001486
Validation Loss: 0.00142143
Epoch [271/300], Train Loss: 0.001486
Validation Loss: 0.00142808
Epoch [272/300], Train Loss: 0.001499
Validation Loss: 0.00142089
Epoch [273/300], Train Loss: 0.001437
Validation Loss: 0.00142328
Epoch [274/300], Train Loss: 0.001498
Validation Loss: 0.00142073
Epoch [275/300], Train Loss: 0.001458
Validation Loss: 0.00142015
Early stopping triggered

Evaluating model for: Freezer
Run 41/72 completed in 1131.27 seconds with: {'MAE': np.float32(31.906609), 'MSE': np.float32(2203.194), 'RMSE': np.float32(46.938194), 'SAE': np.float32(0.008934824), 'NDE': np.float32(0.3506237)}

Run 42/72: hidden=256, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Freezer
Dataset length: 2262 windows

Epoch [1/300], Train Loss: 0.011625
Validation Loss: 0.00782177
Epoch [2/300], Train Loss: 0.006402
Validation Loss: 0.00615347
Epoch [3/300], Train Loss: 0.005808
Validation Loss: 0.00599769
Epoch [4/300], Train Loss: 0.005874
Validation Loss: 0.00589182
Epoch [5/300], Train Loss: 0.005811
Validation Loss: 0.00583861
Epoch [6/300], Train Loss: 0.005748
Validation Loss: 0.00577793
Epoch [7/300], Train Loss: 0.005708
Validation Loss: 0.00565415
Epoch [8/300], Train Loss: 0.005498
Validation Loss: 0.00543264
Epoch [9/300], Train Loss: 0.005130
Validation Loss: 0.00478420
Epoch [10/300], Train Loss: 0.004553
Validation Loss: 0.00441299
Epoch [11/300], Train Loss: 0.004166
Validation Loss: 0.00392376
Epoch [12/300], Train Loss: 0.003918
Validation Loss: 0.00359158
Epoch [13/300], Train Loss: 0.003474
Validation Loss: 0.00323800
Epoch [14/300], Train Loss: 0.003045
Validation Loss: 0.00263309
Epoch [15/300], Train Loss: 0.002696
Validation Loss: 0.00248626
Epoch [16/300], Train Loss: 0.002524
Validation Loss: 0.00235426
Epoch [17/300], Train Loss: 0.002415
Validation Loss: 0.00231278
Epoch [18/300], Train Loss: 0.002371
Validation Loss: 0.00223945
Epoch [19/300], Train Loss: 0.002247
Validation Loss: 0.00221969
Epoch [20/300], Train Loss: 0.002250
Validation Loss: 0.00215725
Epoch [21/300], Train Loss: 0.002206
Validation Loss: 0.00213828
Epoch [22/300], Train Loss: 0.002266
Validation Loss: 0.00211380
Epoch [23/300], Train Loss: 0.002158
Validation Loss: 0.00209457
Epoch [24/300], Train Loss: 0.002303
Validation Loss: 0.00231768
Epoch [25/300], Train Loss: 0.002287
Validation Loss: 0.00277570
Epoch [26/300], Train Loss: 0.002632
Validation Loss: 0.00217463
Epoch [27/300], Train Loss: 0.002185
Validation Loss: 0.00222185
Epoch [28/300], Train Loss: 0.002133
Validation Loss: 0.00210445
Epoch [29/300], Train Loss: 0.002189
Validation Loss: 0.00211178
Epoch [30/300], Train Loss: 0.002140
Validation Loss: 0.00207572
Epoch [31/300], Train Loss: 0.002063
Validation Loss: 0.00208306
Epoch [32/300], Train Loss: 0.002070
Validation Loss: 0.00207484
Epoch [33/300], Train Loss: 0.002125
Validation Loss: 0.00204220
Epoch [34/300], Train Loss: 0.002012
Validation Loss: 0.00204192
Epoch [35/300], Train Loss: 0.002155
Validation Loss: 0.00203749
Epoch [36/300], Train Loss: 0.002066
Validation Loss: 0.00201455
Epoch [37/300], Train Loss: 0.002022
Validation Loss: 0.00196722
Epoch [38/300], Train Loss: 0.002007
Validation Loss: 0.00196507
Epoch [39/300], Train Loss: 0.002006
Validation Loss: 0.00196262
Epoch [40/300], Train Loss: 0.001988
Validation Loss: 0.00194584
Epoch [41/300], Train Loss: 0.001939
Validation Loss: 0.00193618
Epoch [42/300], Train Loss: 0.001955
Validation Loss: 0.00192894
Epoch [43/300], Train Loss: 0.001941
Validation Loss: 0.00192051
Epoch [44/300], Train Loss: 0.001976
Validation Loss: 0.00190789
Epoch [45/300], Train Loss: 0.001906
Validation Loss: 0.00189831
Epoch [46/300], Train Loss: 0.001971
Validation Loss: 0.00190685
Epoch [47/300], Train Loss: 0.001903
Validation Loss: 0.00187900
Epoch [48/300], Train Loss: 0.001917
Validation Loss: 0.00188337
Epoch [49/300], Train Loss: 0.001960
Validation Loss: 0.00185987
Epoch [50/300], Train Loss: 0.001895
Validation Loss: 0.00185951
Epoch [51/300], Train Loss: 0.001835
Validation Loss: 0.00184194
Epoch [52/300], Train Loss: 0.001866
Validation Loss: 0.00184294
Epoch [53/300], Train Loss: 0.001827
Validation Loss: 0.00182804
Epoch [54/300], Train Loss: 0.001904
Validation Loss: 0.00180482
Epoch [55/300], Train Loss: 0.001880
Validation Loss: 0.00181557
Epoch [56/300], Train Loss: 0.001811
Validation Loss: 0.00179077
Epoch [57/300], Train Loss: 0.001851
Validation Loss: 0.00178835
Epoch [58/300], Train Loss: 0.001841
Validation Loss: 0.00179304
Epoch [59/300], Train Loss: 0.001815
Validation Loss: 0.00177382
Epoch [60/300], Train Loss: 0.001833
Validation Loss: 0.00176852
Epoch [61/300], Train Loss: 0.001830
Validation Loss: 0.00176645
Epoch [62/300], Train Loss: 0.001829
Validation Loss: 0.00175995
Epoch [63/300], Train Loss: 0.001824
Validation Loss: 0.00181166
Epoch [64/300], Train Loss: 0.001806
Validation Loss: 0.00175749
Epoch [65/300], Train Loss: 0.001829
Validation Loss: 0.00175085
Epoch [66/300], Train Loss: 0.001830
Validation Loss: 0.00175067
Epoch [67/300], Train Loss: 0.001821
Validation Loss: 0.00174279
Epoch [68/300], Train Loss: 0.001884
Validation Loss: 0.00175021
Epoch [69/300], Train Loss: 0.001850
Validation Loss: 0.00174956
Epoch [70/300], Train Loss: 0.001771
Validation Loss: 0.00173206
Epoch [71/300], Train Loss: 0.001797
Validation Loss: 0.00173246
Epoch [72/300], Train Loss: 0.001778
Validation Loss: 0.00172982
Epoch [73/300], Train Loss: 0.001702
Validation Loss: 0.00172834
Epoch [74/300], Train Loss: 0.001900
Validation Loss: 0.00172985
Epoch [75/300], Train Loss: 0.001834
Validation Loss: 0.00171728
Epoch [76/300], Train Loss: 0.001787
Validation Loss: 0.00172661
Epoch [77/300], Train Loss: 0.001772
Validation Loss: 0.00173769
Epoch [78/300], Train Loss: 0.001777
Validation Loss: 0.00173556
Epoch [79/300], Train Loss: 0.001723
Validation Loss: 0.00170471
Epoch [80/300], Train Loss: 0.001816
Validation Loss: 0.00169863
Epoch [81/300], Train Loss: 0.001740
Validation Loss: 0.00169758
Epoch [82/300], Train Loss: 0.001733
Validation Loss: 0.00169610
Epoch [83/300], Train Loss: 0.001774
Validation Loss: 0.00169193
Epoch [84/300], Train Loss: 0.001671
Validation Loss: 0.00166781
Epoch [85/300], Train Loss: 0.001707
Validation Loss: 0.00165450
Epoch [86/300], Train Loss: 0.001737
Validation Loss: 0.00164464
Epoch [87/300], Train Loss: 0.001737
Validation Loss: 0.00165981
Epoch [88/300], Train Loss: 0.001729
Validation Loss: 0.00163923
Epoch [89/300], Train Loss: 0.001709
Validation Loss: 0.00164428
Epoch [90/300], Train Loss: 0.001747
Validation Loss: 0.00163786
Epoch [91/300], Train Loss: 0.001686
Validation Loss: 0.00162961
Epoch [92/300], Train Loss: 0.001679
Validation Loss: 0.00163721
Epoch [93/300], Train Loss: 0.001743
Validation Loss: 0.00162566
Epoch [94/300], Train Loss: 0.001715
Validation Loss: 0.00162377
Epoch [95/300], Train Loss: 0.001739
Validation Loss: 0.00161954
Epoch [96/300], Train Loss: 0.001805
Validation Loss: 0.00162770
Epoch [97/300], Train Loss: 0.001639
Validation Loss: 0.00163029
Epoch [98/300], Train Loss: 0.001726
Validation Loss: 0.00163006
Epoch [99/300], Train Loss: 0.001724
Validation Loss: 0.00161576
Epoch [100/300], Train Loss: 0.001669
Validation Loss: 0.00162007
Epoch [101/300], Train Loss: 0.001652
Validation Loss: 0.00161764
Epoch [102/300], Train Loss: 0.001715
Validation Loss: 0.00160515
Epoch [103/300], Train Loss: 0.001662
Validation Loss: 0.00160962
Epoch [104/300], Train Loss: 0.001662
Validation Loss: 0.00160446
Epoch [105/300], Train Loss: 0.001646
Validation Loss: 0.00160132
Epoch [106/300], Train Loss: 0.001632
Validation Loss: 0.00158861
Epoch [107/300], Train Loss: 0.001625
Validation Loss: 0.00160338
Epoch [108/300], Train Loss: 0.001680
Validation Loss: 0.00159981
Epoch [109/300], Train Loss: 0.001685
Validation Loss: 0.00161611
Epoch [110/300], Train Loss: 0.001655
Validation Loss: 0.00160187
Epoch [111/300], Train Loss: 0.001662
Validation Loss: 0.00159334
Epoch [112/300], Train Loss: 0.001645
Validation Loss: 0.00161471
Epoch [113/300], Train Loss: 0.001669
Validation Loss: 0.00158892
Epoch [114/300], Train Loss: 0.001659
Validation Loss: 0.00158803
Epoch [115/300], Train Loss: 0.001692
Validation Loss: 0.00158798
Epoch [116/300], Train Loss: 0.001667
Validation Loss: 0.00159616
Epoch [117/300], Train Loss: 0.001684
Validation Loss: 0.00159367
Epoch [118/300], Train Loss: 0.001631
Validation Loss: 0.00158200
Epoch [119/300], Train Loss: 0.001702
Validation Loss: 0.00158008
Epoch [120/300], Train Loss: 0.001633
Validation Loss: 0.00159627
Epoch [121/300], Train Loss: 0.001679
Validation Loss: 0.00158404
Epoch [122/300], Train Loss: 0.001680
Validation Loss: 0.00158064
Epoch [123/300], Train Loss: 0.001627
Validation Loss: 0.00157238
Epoch [124/300], Train Loss: 0.001666
Validation Loss: 0.00156145
Epoch [125/300], Train Loss: 0.001702
Validation Loss: 0.00156966
Epoch [126/300], Train Loss: 0.001638
Validation Loss: 0.00159710
Epoch [127/300], Train Loss: 0.001674
Validation Loss: 0.00156235
Epoch [128/300], Train Loss: 0.001618
Validation Loss: 0.00158165
Epoch [129/300], Train Loss: 0.001620
Validation Loss: 0.00157196
Epoch [130/300], Train Loss: 0.001690
Validation Loss: 0.00156470
Epoch [131/300], Train Loss: 0.001646
Validation Loss: 0.00156574
Epoch [132/300], Train Loss: 0.001594
Validation Loss: 0.00155270
Epoch [133/300], Train Loss: 0.001609
Validation Loss: 0.00154594
Epoch [134/300], Train Loss: 0.001598
Validation Loss: 0.00156522
Epoch [135/300], Train Loss: 0.001670
Validation Loss: 0.00157761
Epoch [136/300], Train Loss: 0.001594
Validation Loss: 0.00154345
Epoch [137/300], Train Loss: 0.001618
Validation Loss: 0.00154519
Epoch [138/300], Train Loss: 0.001641
Validation Loss: 0.00156058
Epoch [139/300], Train Loss: 0.001575
Validation Loss: 0.00154719
Epoch [140/300], Train Loss: 0.001569
Validation Loss: 0.00156445
Epoch [141/300], Train Loss: 0.001661
Validation Loss: 0.00155923
Epoch [142/300], Train Loss: 0.001587
Validation Loss: 0.00155709
Epoch [143/300], Train Loss: 0.001619
Validation Loss: 0.00154194
Epoch [144/300], Train Loss: 0.001639
Validation Loss: 0.00154149
Epoch [145/300], Train Loss: 0.001663
Validation Loss: 0.00154581
Epoch [146/300], Train Loss: 0.001614
Validation Loss: 0.00153913
Epoch [147/300], Train Loss: 0.001647
Validation Loss: 0.00157331
Epoch [148/300], Train Loss: 0.001620
Validation Loss: 0.00153353
Epoch [149/300], Train Loss: 0.001597
Validation Loss: 0.00153932
Epoch [150/300], Train Loss: 0.001569
Validation Loss: 0.00152865
Epoch [151/300], Train Loss: 0.001667
Validation Loss: 0.00152914
Epoch [152/300], Train Loss: 0.001661
Validation Loss: 0.00153977
Epoch [153/300], Train Loss: 0.001640
Validation Loss: 0.00153573
Epoch [154/300], Train Loss: 0.001623
Validation Loss: 0.00153942
Epoch [155/300], Train Loss: 0.001695
Validation Loss: 0.00152529
Epoch [156/300], Train Loss: 0.001606
Validation Loss: 0.00154465
Epoch [157/300], Train Loss: 0.001601
Validation Loss: 0.00152962
Epoch [158/300], Train Loss: 0.001633
Validation Loss: 0.00154666
Epoch [159/300], Train Loss: 0.001617
Validation Loss: 0.00154005
Epoch [160/300], Train Loss: 0.001577
Validation Loss: 0.00153021
Epoch [161/300], Train Loss: 0.001633
Validation Loss: 0.00152953
Epoch [162/300], Train Loss: 0.001551
Validation Loss: 0.00152954
Epoch [163/300], Train Loss: 0.001651
Validation Loss: 0.00152230
Epoch [164/300], Train Loss: 0.001571
Validation Loss: 0.00155378
Epoch [165/300], Train Loss: 0.001560
Validation Loss: 0.00152108
Epoch [166/300], Train Loss: 0.001562
Validation Loss: 0.00154166
Epoch [167/300], Train Loss: 0.001550
Validation Loss: 0.00152105
Epoch [168/300], Train Loss: 0.001633
Validation Loss: 0.00152214
Epoch [169/300], Train Loss: 0.001590
Validation Loss: 0.00152473
Epoch [170/300], Train Loss: 0.001617
Validation Loss: 0.00152616
Epoch [171/300], Train Loss: 0.001609
Validation Loss: 0.00151770
Epoch [172/300], Train Loss: 0.001605
Validation Loss: 0.00152772
Epoch [173/300], Train Loss: 0.001630
Validation Loss: 0.00151785
Epoch [174/300], Train Loss: 0.001569
Validation Loss: 0.00151676
Epoch [175/300], Train Loss: 0.001577
Validation Loss: 0.00151770
Epoch [176/300], Train Loss: 0.001598
Validation Loss: 0.00151532
Epoch [177/300], Train Loss: 0.001605
Validation Loss: 0.00151515
Epoch [178/300], Train Loss: 0.001570
Validation Loss: 0.00151572
Epoch [179/300], Train Loss: 0.001569
Validation Loss: 0.00151865
Epoch [180/300], Train Loss: 0.001610
Validation Loss: 0.00153296
Epoch [181/300], Train Loss: 0.001564
Validation Loss: 0.00151355
Epoch [182/300], Train Loss: 0.001651
Validation Loss: 0.00154629
Epoch [183/300], Train Loss: 0.001599
Validation Loss: 0.00150991
Epoch [184/300], Train Loss: 0.001664
Validation Loss: 0.00151843
Epoch [185/300], Train Loss: 0.001636
Validation Loss: 0.00151436
Epoch [186/300], Train Loss: 0.001585
Validation Loss: 0.00150770
Epoch [187/300], Train Loss: 0.001543
Validation Loss: 0.00151194
Epoch [188/300], Train Loss: 0.001574
Validation Loss: 0.00152876
Epoch [189/300], Train Loss: 0.001596
Validation Loss: 0.00151491
Epoch [190/300], Train Loss: 0.001566
Validation Loss: 0.00150707
Epoch [191/300], Train Loss: 0.001623
Validation Loss: 0.00151214
Epoch [192/300], Train Loss: 0.001611
Validation Loss: 0.00151577
Epoch [193/300], Train Loss: 0.001610
Validation Loss: 0.00150974
Epoch [194/300], Train Loss: 0.001547
Validation Loss: 0.00150722
Epoch [195/300], Train Loss: 0.001617
Validation Loss: 0.00149936
Epoch [196/300], Train Loss: 0.001608
Validation Loss: 0.00150240
Epoch [197/300], Train Loss: 0.001563
Validation Loss: 0.00150316
Epoch [198/300], Train Loss: 0.001543
Validation Loss: 0.00150423
Epoch [199/300], Train Loss: 0.001566
Validation Loss: 0.00150361
Epoch [200/300], Train Loss: 0.001640
Validation Loss: 0.00150637
Epoch [201/300], Train Loss: 0.001547
Validation Loss: 0.00149342
Epoch [202/300], Train Loss: 0.001600
Validation Loss: 0.00149011
Epoch [203/300], Train Loss: 0.001550
Validation Loss: 0.00150534
Epoch [204/300], Train Loss: 0.001579
Validation Loss: 0.00149727
Epoch [205/300], Train Loss: 0.001561
Validation Loss: 0.00148546
Epoch [206/300], Train Loss: 0.001584
Validation Loss: 0.00151094
Epoch [207/300], Train Loss: 0.001540
Validation Loss: 0.00149166
Epoch [208/300], Train Loss: 0.001759
Validation Loss: 0.00181145
Epoch [209/300], Train Loss: 0.001965
Validation Loss: 0.00177563
Epoch [210/300], Train Loss: 0.001754
Validation Loss: 0.00161645
Epoch [211/300], Train Loss: 0.001657
Validation Loss: 0.00158788
Epoch [212/300], Train Loss: 0.001677
Validation Loss: 0.00155046
Epoch [213/300], Train Loss: 0.001693
Validation Loss: 0.00154001
Epoch [214/300], Train Loss: 0.001670
Validation Loss: 0.00152900
Epoch [215/300], Train Loss: 0.001615
Validation Loss: 0.00151790
Early stopping triggered

Evaluating model for: Freezer
Run 42/72 completed in 1144.85 seconds with: {'MAE': np.float32(33.00964), 'MSE': np.float32(2386.81), 'RMSE': np.float32(48.854992), 'SAE': np.float32(0.006869017), 'NDE': np.float32(0.36494192)}

Run 43/72: hidden=256, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Freezer
Dataset length: 2262 windows

Epoch [1/300], Train Loss: 0.007900
Validation Loss: 0.00602965
Epoch [2/300], Train Loss: 0.005874
Validation Loss: 0.00589836
Epoch [3/300], Train Loss: 0.005774
Validation Loss: 0.00594944
Epoch [4/300], Train Loss: 0.005826
Validation Loss: 0.00587927
Epoch [5/300], Train Loss: 0.005805
Validation Loss: 0.00585943
Epoch [6/300], Train Loss: 0.005762
Validation Loss: 0.00579771
Epoch [7/300], Train Loss: 0.005713
Validation Loss: 0.00559436
Epoch [8/300], Train Loss: 0.005203
Validation Loss: 0.00451392
Epoch [9/300], Train Loss: 0.004089
Validation Loss: 0.00348403
Epoch [10/300], Train Loss: 0.003112
Validation Loss: 0.00283871
Epoch [11/300], Train Loss: 0.002719
Validation Loss: 0.00243647
Epoch [12/300], Train Loss: 0.002513
Validation Loss: 0.00223471
Epoch [13/300], Train Loss: 0.002360
Validation Loss: 0.00213891
Epoch [14/300], Train Loss: 0.002222
Validation Loss: 0.00208888
Epoch [15/300], Train Loss: 0.002144
Validation Loss: 0.00204288
Epoch [16/300], Train Loss: 0.002067
Validation Loss: 0.00202643
Epoch [17/300], Train Loss: 0.002098
Validation Loss: 0.00197608
Epoch [18/300], Train Loss: 0.002052
Validation Loss: 0.00194470
Epoch [19/300], Train Loss: 0.001957
Validation Loss: 0.00193206
Epoch [20/300], Train Loss: 0.002004
Validation Loss: 0.00191193
Epoch [21/300], Train Loss: 0.001983
Validation Loss: 0.00195020
Epoch [22/300], Train Loss: 0.001991
Validation Loss: 0.00189578
Epoch [23/300], Train Loss: 0.001878
Validation Loss: 0.00187194
Epoch [24/300], Train Loss: 0.001903
Validation Loss: 0.00187506
Epoch [25/300], Train Loss: 0.001857
Validation Loss: 0.00188324
Epoch [26/300], Train Loss: 0.001875
Validation Loss: 0.00183147
Epoch [27/300], Train Loss: 0.001851
Validation Loss: 0.00182898
Epoch [28/300], Train Loss: 0.001822
Validation Loss: 0.00186708
Epoch [29/300], Train Loss: 0.001936
Validation Loss: 0.00181996
Epoch [30/300], Train Loss: 0.001884
Validation Loss: 0.00180189
Epoch [31/300], Train Loss: 0.001811
Validation Loss: 0.00178485
Epoch [32/300], Train Loss: 0.001839
Validation Loss: 0.00177745
Epoch [33/300], Train Loss: 0.001851
Validation Loss: 0.00176859
Epoch [34/300], Train Loss: 0.001788
Validation Loss: 0.00174777
Epoch [35/300], Train Loss: 0.001906
Validation Loss: 0.00172283
Epoch [36/300], Train Loss: 0.001807
Validation Loss: 0.00171602
Epoch [37/300], Train Loss: 0.001785
Validation Loss: 0.00170119
Epoch [38/300], Train Loss: 0.001759
Validation Loss: 0.00170440
Epoch [39/300], Train Loss: 0.001773
Validation Loss: 0.00172103
Epoch [40/300], Train Loss: 0.001743
Validation Loss: 0.00169320
Epoch [41/300], Train Loss: 0.001728
Validation Loss: 0.00167535
Epoch [42/300], Train Loss: 0.001741
Validation Loss: 0.00167306
Epoch [43/300], Train Loss: 0.001703
Validation Loss: 0.00167768
Epoch [44/300], Train Loss: 0.001759
Validation Loss: 0.00168244
Epoch [45/300], Train Loss: 0.001686
Validation Loss: 0.00169120
Epoch [46/300], Train Loss: 0.001768
Validation Loss: 0.00167304
Epoch [47/300], Train Loss: 0.001702
Validation Loss: 0.00164807
Epoch [48/300], Train Loss: 0.001738
Validation Loss: 0.00165458
Epoch [49/300], Train Loss: 0.001760
Validation Loss: 0.00165440
Epoch [50/300], Train Loss: 0.001719
Validation Loss: 0.00164303
Epoch [51/300], Train Loss: 0.001657
Validation Loss: 0.00164957
Epoch [52/300], Train Loss: 0.001698
Validation Loss: 0.00167924
Epoch [53/300], Train Loss: 0.001667
Validation Loss: 0.00165514
Epoch [54/300], Train Loss: 0.001740
Validation Loss: 0.00163007
Epoch [55/300], Train Loss: 0.001724
Validation Loss: 0.00163557
Epoch [56/300], Train Loss: 0.001655
Validation Loss: 0.00162224
Epoch [57/300], Train Loss: 0.001689
Validation Loss: 0.00162112
Epoch [58/300], Train Loss: 0.001680
Validation Loss: 0.00161675
Epoch [59/300], Train Loss: 0.001657
Validation Loss: 0.00160590
Epoch [60/300], Train Loss: 0.001687
Validation Loss: 0.00158683
Epoch [61/300], Train Loss: 0.001672
Validation Loss: 0.00159249
Epoch [62/300], Train Loss: 0.001668
Validation Loss: 0.00157508
Epoch [63/300], Train Loss: 0.001654
Validation Loss: 0.00157957
Epoch [64/300], Train Loss: 0.001628
Validation Loss: 0.00156360
Epoch [65/300], Train Loss: 0.001662
Validation Loss: 0.00156303
Epoch [66/300], Train Loss: 0.001673
Validation Loss: 0.00157888
Epoch [67/300], Train Loss: 0.001669
Validation Loss: 0.00159007
Epoch [68/300], Train Loss: 0.001728
Validation Loss: 0.00156096
Epoch [69/300], Train Loss: 0.001698
Validation Loss: 0.00155397
Epoch [70/300], Train Loss: 0.001607
Validation Loss: 0.00155419
Epoch [71/300], Train Loss: 0.001636
Validation Loss: 0.00155231
Epoch [72/300], Train Loss: 0.001622
Validation Loss: 0.00155621
Epoch [73/300], Train Loss: 0.001555
Validation Loss: 0.00154807
Epoch [74/300], Train Loss: 0.001738
Validation Loss: 0.00155659
Epoch [75/300], Train Loss: 0.001673
Validation Loss: 0.00155285
Epoch [76/300], Train Loss: 0.001633
Validation Loss: 0.00155581
Epoch [77/300], Train Loss: 0.001623
Validation Loss: 0.00153726
Epoch [78/300], Train Loss: 0.001630
Validation Loss: 0.00156843
Epoch [79/300], Train Loss: 0.001586
Validation Loss: 0.00153039
Epoch [80/300], Train Loss: 0.001672
Validation Loss: 0.00152677
Epoch [81/300], Train Loss: 0.001605
Validation Loss: 0.00154868
Epoch [82/300], Train Loss: 0.001614
Validation Loss: 0.00154115
Epoch [83/300], Train Loss: 0.001639
Validation Loss: 0.00153342
Epoch [84/300], Train Loss: 0.001547
Validation Loss: 0.00152831
Epoch [85/300], Train Loss: 0.001594
Validation Loss: 0.00152409
Epoch [86/300], Train Loss: 0.001628
Validation Loss: 0.00151907
Epoch [87/300], Train Loss: 0.001628
Validation Loss: 0.00154840
Epoch [88/300], Train Loss: 0.001629
Validation Loss: 0.00153911
Epoch [89/300], Train Loss: 0.001606
Validation Loss: 0.00153782
Epoch [90/300], Train Loss: 0.001655
Validation Loss: 0.00152975
Epoch [91/300], Train Loss: 0.001589
Validation Loss: 0.00151602
Epoch [92/300], Train Loss: 0.001587
Validation Loss: 0.00152948
Epoch [93/300], Train Loss: 0.001639
Validation Loss: 0.00151389
Epoch [94/300], Train Loss: 0.001613
Validation Loss: 0.00151539
Epoch [95/300], Train Loss: 0.001641
Validation Loss: 0.00151080
Epoch [96/300], Train Loss: 0.001706
Validation Loss: 0.00151356
Epoch [97/300], Train Loss: 0.001542
Validation Loss: 0.00151323
Epoch [98/300], Train Loss: 0.001637
Validation Loss: 0.00152274
Epoch [99/300], Train Loss: 0.001622
Validation Loss: 0.00150917
Epoch [100/300], Train Loss: 0.001573
Validation Loss: 0.00150580
Epoch [101/300], Train Loss: 0.001561
Validation Loss: 0.00150390
Epoch [102/300], Train Loss: 0.001619
Validation Loss: 0.00151935
Epoch [103/300], Train Loss: 0.001573
Validation Loss: 0.00150222
Epoch [104/300], Train Loss: 0.001565
Validation Loss: 0.00149927
Epoch [105/300], Train Loss: 0.001557
Validation Loss: 0.00150128
Epoch [106/300], Train Loss: 0.001538
Validation Loss: 0.00149800
Epoch [107/300], Train Loss: 0.001535
Validation Loss: 0.00149686
Epoch [108/300], Train Loss: 0.001593
Validation Loss: 0.00149280
Epoch [109/300], Train Loss: 0.001598
Validation Loss: 0.00151224
Epoch [110/300], Train Loss: 0.001558
Validation Loss: 0.00150015
Epoch [111/300], Train Loss: 0.001562
Validation Loss: 0.00151106
Epoch [112/300], Train Loss: 0.001554
Validation Loss: 0.00151640
Epoch [113/300], Train Loss: 0.001569
Validation Loss: 0.00148516
Epoch [114/300], Train Loss: 0.001559
Validation Loss: 0.00147893
Epoch [115/300], Train Loss: 0.001601
Validation Loss: 0.00148957
Epoch [116/300], Train Loss: 0.001580
Validation Loss: 0.00151210
Epoch [117/300], Train Loss: 0.001593
Validation Loss: 0.00147772
Epoch [118/300], Train Loss: 0.001528
Validation Loss: 0.00147223
Epoch [119/300], Train Loss: 0.001603
Validation Loss: 0.00146594
Epoch [120/300], Train Loss: 0.001528
Validation Loss: 0.00146489
Epoch [121/300], Train Loss: 0.001567
Validation Loss: 0.00146809
Epoch [122/300], Train Loss: 0.001578
Validation Loss: 0.00149519
Epoch [123/300], Train Loss: 0.001528
Validation Loss: 0.00145811
Epoch [124/300], Train Loss: 0.001561
Validation Loss: 0.00148248
Epoch [125/300], Train Loss: 0.001591
Validation Loss: 0.00147732
Epoch [126/300], Train Loss: 0.001534
Validation Loss: 0.00146471
Epoch [127/300], Train Loss: 0.001555
Validation Loss: 0.00144351
Epoch [128/300], Train Loss: 0.001504
Validation Loss: 0.00145645
Epoch [129/300], Train Loss: 0.001508
Validation Loss: 0.00144462
Epoch [130/300], Train Loss: 0.001577
Validation Loss: 0.00144494
Epoch [131/300], Train Loss: 0.001539
Validation Loss: 0.00144402
Epoch [132/300], Train Loss: 0.001480
Validation Loss: 0.00144157
Epoch [133/300], Train Loss: 0.001492
Validation Loss: 0.00144718
Epoch [134/300], Train Loss: 0.001483
Validation Loss: 0.00143762
Epoch [135/300], Train Loss: 0.001552
Validation Loss: 0.00146745
Epoch [136/300], Train Loss: 0.001480
Validation Loss: 0.00143854
Epoch [137/300], Train Loss: 0.001499
Validation Loss: 0.00143604
Epoch [138/300], Train Loss: 0.001519
Validation Loss: 0.00144563
Epoch [139/300], Train Loss: 0.001464
Validation Loss: 0.00144305
Epoch [140/300], Train Loss: 0.001448
Validation Loss: 0.00143694
Epoch [141/300], Train Loss: 0.001537
Validation Loss: 0.00145032
Epoch [142/300], Train Loss: 0.001458
Validation Loss: 0.00144504
Epoch [143/300], Train Loss: 0.001490
Validation Loss: 0.00143470
Epoch [144/300], Train Loss: 0.001522
Validation Loss: 0.00143686
Epoch [145/300], Train Loss: 0.001539
Validation Loss: 0.00143821
Epoch [146/300], Train Loss: 0.001497
Validation Loss: 0.00144436
Epoch [147/300], Train Loss: 0.001538
Validation Loss: 0.00148886
Epoch [148/300], Train Loss: 0.001500
Validation Loss: 0.00143294
Epoch [149/300], Train Loss: 0.001472
Validation Loss: 0.00143225
Epoch [150/300], Train Loss: 0.001441
Validation Loss: 0.00142762
Epoch [151/300], Train Loss: 0.001544
Validation Loss: 0.00145608
Epoch [152/300], Train Loss: 0.001537
Validation Loss: 0.00144412
Epoch [153/300], Train Loss: 0.001531
Validation Loss: 0.00143912
Epoch [154/300], Train Loss: 0.001510
Validation Loss: 0.00143877
Epoch [155/300], Train Loss: 0.001565
Validation Loss: 0.00143536
Epoch [156/300], Train Loss: 0.001496
Validation Loss: 0.00145385
Epoch [157/300], Train Loss: 0.001483
Validation Loss: 0.00143168
Epoch [158/300], Train Loss: 0.001506
Validation Loss: 0.00142535
Epoch [159/300], Train Loss: 0.001499
Validation Loss: 0.00143064
Epoch [160/300], Train Loss: 0.001454
Validation Loss: 0.00142351
Epoch [161/300], Train Loss: 0.001509
Validation Loss: 0.00142956
Epoch [162/300], Train Loss: 0.001436
Validation Loss: 0.00143033
Epoch [163/300], Train Loss: 0.001539
Validation Loss: 0.00142398
Epoch [164/300], Train Loss: 0.001449
Validation Loss: 0.00144422
Epoch [165/300], Train Loss: 0.001436
Validation Loss: 0.00143982
Epoch [166/300], Train Loss: 0.001446
Validation Loss: 0.00142747
Epoch [167/300], Train Loss: 0.001432
Validation Loss: 0.00143261
Epoch [168/300], Train Loss: 0.001512
Validation Loss: 0.00141875
Epoch [169/300], Train Loss: 0.001462
Validation Loss: 0.00143073
Epoch [170/300], Train Loss: 0.001498
Validation Loss: 0.00142107
Epoch [171/300], Train Loss: 0.001498
Validation Loss: 0.00142353
Epoch [172/300], Train Loss: 0.001490
Validation Loss: 0.00142340
Epoch [173/300], Train Loss: 0.001520
Validation Loss: 0.00142763
Epoch [174/300], Train Loss: 0.001463
Validation Loss: 0.00142247
Epoch [175/300], Train Loss: 0.001548
Validation Loss: 0.00149293
Epoch [176/300], Train Loss: 0.001590
Validation Loss: 0.00147677
Epoch [177/300], Train Loss: 0.001553
Validation Loss: 0.00144361
Epoch [178/300], Train Loss: 0.001492
Validation Loss: 0.00144945
Early stopping triggered

Evaluating model for: Freezer
Run 43/72 completed in 1141.73 seconds with: {'MAE': np.float32(32.144432), 'MSE': np.float32(2249.0635), 'RMSE': np.float32(47.424294), 'SAE': np.float32(0.009282294), 'NDE': np.float32(0.35425475)}

Run 44/72: hidden=256, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Freezer
Dataset length: 2262 windows

Epoch [1/300], Train Loss: 0.005810
Validation Loss: 0.00589739
Epoch [2/300], Train Loss: 0.005709
Validation Loss: 0.00591555
Epoch [3/300], Train Loss: 0.005756
Validation Loss: 0.00590303
Epoch [4/300], Train Loss: 0.005810
Validation Loss: 0.00590920
Epoch [5/300], Train Loss: 0.005819
Validation Loss: 0.00589649
Epoch [6/300], Train Loss: 0.005808
Validation Loss: 0.00589506
Epoch [7/300], Train Loss: 0.005848
Validation Loss: 0.00588022
Epoch [8/300], Train Loss: 0.005781
Validation Loss: 0.00583467
Epoch [9/300], Train Loss: 0.005469
Validation Loss: 0.00456867
Epoch [10/300], Train Loss: 0.003296
Validation Loss: 0.00270633
Epoch [11/300], Train Loss: 0.002669
Validation Loss: 0.00257847
Epoch [12/300], Train Loss: 0.002496
Validation Loss: 0.00241645
Epoch [13/300], Train Loss: 0.002427
Validation Loss: 0.00236001
Epoch [14/300], Train Loss: 0.002390
Validation Loss: 0.00232203
Epoch [15/300], Train Loss: 0.002361
Validation Loss: 0.00230831
Epoch [16/300], Train Loss: 0.002356
Validation Loss: 0.00228315
Epoch [17/300], Train Loss: 0.002361
Validation Loss: 0.00227222
Epoch [18/300], Train Loss: 0.002341
Validation Loss: 0.00224457
Epoch [19/300], Train Loss: 0.002238
Validation Loss: 0.00223860
Epoch [20/300], Train Loss: 0.002309
Validation Loss: 0.00221833
Epoch [21/300], Train Loss: 0.002288
Validation Loss: 0.00233487
Epoch [22/300], Train Loss: 0.002382
Validation Loss: 0.00218397
Epoch [23/300], Train Loss: 0.002192
Validation Loss: 0.00220319
Epoch [24/300], Train Loss: 0.002232
Validation Loss: 0.00216754
Epoch [25/300], Train Loss: 0.002157
Validation Loss: 0.00228449
Epoch [26/300], Train Loss: 0.002211
Validation Loss: 0.00208809
Epoch [27/300], Train Loss: 0.002110
Validation Loss: 0.00207603
Epoch [28/300], Train Loss: 0.002069
Validation Loss: 0.00209781
Epoch [29/300], Train Loss: 0.002173
Validation Loss: 0.00197293
Epoch [30/300], Train Loss: 0.002039
Validation Loss: 0.00194640
Epoch [31/300], Train Loss: 0.001927
Validation Loss: 0.00186193
Epoch [32/300], Train Loss: 0.001911
Validation Loss: 0.00183029
Epoch [33/300], Train Loss: 0.001923
Validation Loss: 0.00180362
Epoch [34/300], Train Loss: 0.001828
Validation Loss: 0.00179534
Epoch [35/300], Train Loss: 0.001946
Validation Loss: 0.00182241
Epoch [36/300], Train Loss: 0.001870
Validation Loss: 0.00182996
Epoch [37/300], Train Loss: 0.001840
Validation Loss: 0.00178645
Epoch [38/300], Train Loss: 0.001808
Validation Loss: 0.00179532
Epoch [39/300], Train Loss: 0.001826
Validation Loss: 0.00175949
Epoch [40/300], Train Loss: 0.001787
Validation Loss: 0.00175588
Epoch [41/300], Train Loss: 0.001765
Validation Loss: 0.00174969
Epoch [42/300], Train Loss: 0.001778
Validation Loss: 0.00174131
Epoch [43/300], Train Loss: 0.001739
Validation Loss: 0.00174164
Epoch [44/300], Train Loss: 0.001793
Validation Loss: 0.00172736
Epoch [45/300], Train Loss: 0.001716
Validation Loss: 0.00171451
Epoch [46/300], Train Loss: 0.001797
Validation Loss: 0.00172887
Epoch [47/300], Train Loss: 0.001736
Validation Loss: 0.00170805
Epoch [48/300], Train Loss: 0.001768
Validation Loss: 0.00170420
Epoch [49/300], Train Loss: 0.001798
Validation Loss: 0.00173395
Epoch [50/300], Train Loss: 0.001753
Validation Loss: 0.00170619
Epoch [51/300], Train Loss: 0.001725
Validation Loss: 0.00168867
Epoch [52/300], Train Loss: 0.001761
Validation Loss: 0.00173755
Epoch [53/300], Train Loss: 0.001699
Validation Loss: 0.00168036
Epoch [54/300], Train Loss: 0.001778
Validation Loss: 0.00167023
Epoch [55/300], Train Loss: 0.001753
Validation Loss: 0.00168797
Epoch [56/300], Train Loss: 0.001689
Validation Loss: 0.00164469
Epoch [57/300], Train Loss: 0.001705
Validation Loss: 0.00165751
Epoch [58/300], Train Loss: 0.001707
Validation Loss: 0.00162105
Epoch [59/300], Train Loss: 0.001666
Validation Loss: 0.00164428
Epoch [60/300], Train Loss: 0.001711
Validation Loss: 0.00163308
Epoch [61/300], Train Loss: 0.001695
Validation Loss: 0.00160408
Epoch [62/300], Train Loss: 0.001681
Validation Loss: 0.00160070
Epoch [63/300], Train Loss: 0.001670
Validation Loss: 0.00163259
Epoch [64/300], Train Loss: 0.001665
Validation Loss: 0.00160282
Epoch [65/300], Train Loss: 0.001698
Validation Loss: 0.00160578
Epoch [66/300], Train Loss: 0.001707
Validation Loss: 0.00159765
Epoch [67/300], Train Loss: 0.001692
Validation Loss: 0.00161658
Epoch [68/300], Train Loss: 0.001749
Validation Loss: 0.00156833
Epoch [69/300], Train Loss: 0.001714
Validation Loss: 0.00158792
Epoch [70/300], Train Loss: 0.001635
Validation Loss: 0.00157942
Epoch [71/300], Train Loss: 0.001666
Validation Loss: 0.00156269
Epoch [72/300], Train Loss: 0.001647
Validation Loss: 0.00158054
Epoch [73/300], Train Loss: 0.001580
Validation Loss: 0.00155835
Epoch [74/300], Train Loss: 0.001770
Validation Loss: 0.00157598
Epoch [75/300], Train Loss: 0.001692
Validation Loss: 0.00155264
Epoch [76/300], Train Loss: 0.001645
Validation Loss: 0.00155495
Epoch [77/300], Train Loss: 0.001646
Validation Loss: 0.00156650
Epoch [78/300], Train Loss: 0.001674
Validation Loss: 0.00156285
Epoch [79/300], Train Loss: 0.001590
Validation Loss: 0.00152415
Epoch [80/300], Train Loss: 0.001680
Validation Loss: 0.00157871
Epoch [81/300], Train Loss: 0.001658
Validation Loss: 0.00157586
Epoch [82/300], Train Loss: 0.001624
Validation Loss: 0.00152500
Epoch [83/300], Train Loss: 0.001644
Validation Loss: 0.00152623
Epoch [84/300], Train Loss: 0.001555
Validation Loss: 0.00153254
Epoch [85/300], Train Loss: 0.001610
Validation Loss: 0.00152851
Epoch [86/300], Train Loss: 0.001625
Validation Loss: 0.00151206
Epoch [87/300], Train Loss: 0.001625
Validation Loss: 0.00153099
Epoch [88/300], Train Loss: 0.001617
Validation Loss: 0.00150747
Epoch [89/300], Train Loss: 0.001598
Validation Loss: 0.00150956
Epoch [90/300], Train Loss: 0.001634
Validation Loss: 0.00151804
Epoch [91/300], Train Loss: 0.001577
Validation Loss: 0.00151131
Epoch [92/300], Train Loss: 0.001575
Validation Loss: 0.00150176
Epoch [93/300], Train Loss: 0.001625
Validation Loss: 0.00150149
Epoch [94/300], Train Loss: 0.001598
Validation Loss: 0.00151497
Epoch [95/300], Train Loss: 0.001633
Validation Loss: 0.00150146
Epoch [96/300], Train Loss: 0.001709
Validation Loss: 0.00151769
Epoch [97/300], Train Loss: 0.001537
Validation Loss: 0.00149538
Epoch [98/300], Train Loss: 0.001622
Validation Loss: 0.00148956
Epoch [99/300], Train Loss: 0.001607
Validation Loss: 0.00151247
Epoch [100/300], Train Loss: 0.001555
Validation Loss: 0.00149863
Epoch [101/300], Train Loss: 0.001538
Validation Loss: 0.00151631
Epoch [102/300], Train Loss: 0.001652
Validation Loss: 0.00151279
Epoch [103/300], Train Loss: 0.001594
Validation Loss: 0.00149555
Epoch [104/300], Train Loss: 0.001542
Validation Loss: 0.00147554
Epoch [105/300], Train Loss: 0.001522
Validation Loss: 0.00148250
Epoch [106/300], Train Loss: 0.001504
Validation Loss: 0.00153549
Epoch [107/300], Train Loss: 0.001522
Validation Loss: 0.00165965
Epoch [108/300], Train Loss: 0.001751
Validation Loss: 0.00163110
Epoch [109/300], Train Loss: 0.001691
Validation Loss: 0.00161596
Epoch [110/300], Train Loss: 0.001621
Validation Loss: 0.00156080
Epoch [111/300], Train Loss: 0.001605
Validation Loss: 0.00154873
Epoch [112/300], Train Loss: 0.001586
Validation Loss: 0.00155306
Epoch [113/300], Train Loss: 0.001600
Validation Loss: 0.00153569
Epoch [114/300], Train Loss: 0.001590
Validation Loss: 0.00152675
Early stopping triggered

Evaluating model for: Freezer
Run 44/72 completed in 1002.85 seconds with: {'MAE': np.float32(33.633595), 'MSE': np.float32(2384.4868), 'RMSE': np.float32(48.831207), 'SAE': np.float32(0.00094917655), 'NDE': np.float32(0.36476427)}

Run 45/72: hidden=256, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Freezer
Dataset length: 1146 windows

Epoch [1/300], Train Loss: 0.012424
Validation Loss: 0.01054578
Epoch [2/300], Train Loss: 0.008946
Validation Loss: 0.00757803
Epoch [3/300], Train Loss: 0.006893
Validation Loss: 0.00602679
Epoch [4/300], Train Loss: 0.006181
Validation Loss: 0.00605419
Epoch [5/300], Train Loss: 0.006174
Validation Loss: 0.00590802
Epoch [6/300], Train Loss: 0.006050
Validation Loss: 0.00594034
Epoch [7/300], Train Loss: 0.005829
Validation Loss: 0.00591146
Epoch [8/300], Train Loss: 0.005816
Validation Loss: 0.00584311
Epoch [9/300], Train Loss: 0.005927
Validation Loss: 0.00581149
Epoch [10/300], Train Loss: 0.005825
Validation Loss: 0.00577326
Epoch [11/300], Train Loss: 0.005757
Validation Loss: 0.00574012
Epoch [12/300], Train Loss: 0.005592
Validation Loss: 0.00569495
Epoch [13/300], Train Loss: 0.005808
Validation Loss: 0.00569492
Epoch [14/300], Train Loss: 0.005546
Validation Loss: 0.00555417
Epoch [15/300], Train Loss: 0.005463
Validation Loss: 0.00549858
Epoch [16/300], Train Loss: 0.005354
Validation Loss: 0.00533152
Epoch [17/300], Train Loss: 0.005109
Validation Loss: 0.00515835
Epoch [18/300], Train Loss: 0.004873
Validation Loss: 0.00493648
Epoch [19/300], Train Loss: 0.004645
Validation Loss: 0.00477928
Epoch [20/300], Train Loss: 0.004557
Validation Loss: 0.00469013
Epoch [21/300], Train Loss: 0.004344
Validation Loss: 0.00467918
Epoch [22/300], Train Loss: 0.004380
Validation Loss: 0.00440717
Epoch [23/300], Train Loss: 0.004321
Validation Loss: 0.00425479
Epoch [24/300], Train Loss: 0.004051
Validation Loss: 0.00432099
Epoch [25/300], Train Loss: 0.004092
Validation Loss: 0.00389803
Epoch [26/300], Train Loss: 0.003702
Validation Loss: 0.00358602
Epoch [27/300], Train Loss: 0.003605
Validation Loss: 0.00331170
Epoch [28/300], Train Loss: 0.003375
Validation Loss: 0.00307899
Epoch [29/300], Train Loss: 0.003126
Validation Loss: 0.00277265
Epoch [30/300], Train Loss: 0.002818
Validation Loss: 0.00260331
Epoch [31/300], Train Loss: 0.002701
Validation Loss: 0.00254929
Epoch [32/300], Train Loss: 0.002617
Validation Loss: 0.00249044
Epoch [33/300], Train Loss: 0.002500
Validation Loss: 0.00236297
Epoch [34/300], Train Loss: 0.002399
Validation Loss: 0.00227048
Epoch [35/300], Train Loss: 0.002270
Validation Loss: 0.00226197
Epoch [36/300], Train Loss: 0.002159
Validation Loss: 0.00227555
Epoch [37/300], Train Loss: 0.002210
Validation Loss: 0.00221368
Epoch [38/300], Train Loss: 0.002208
Validation Loss: 0.00222051
Epoch [39/300], Train Loss: 0.002139
Validation Loss: 0.00217021
Epoch [40/300], Train Loss: 0.001999
Validation Loss: 0.00218157
Epoch [41/300], Train Loss: 0.002158
Validation Loss: 0.00211982
Epoch [42/300], Train Loss: 0.001991
Validation Loss: 0.00210466
Epoch [43/300], Train Loss: 0.002017
Validation Loss: 0.00216347
Epoch [44/300], Train Loss: 0.001954
Validation Loss: 0.00222601
Epoch [45/300], Train Loss: 0.002096
Validation Loss: 0.00206964
Epoch [46/300], Train Loss: 0.002031
Validation Loss: 0.00204633
Epoch [47/300], Train Loss: 0.001994
Validation Loss: 0.00204351
Epoch [48/300], Train Loss: 0.002029
Validation Loss: 0.00204851
Epoch [49/300], Train Loss: 0.001914
Validation Loss: 0.00203334
Epoch [50/300], Train Loss: 0.001987
Validation Loss: 0.00203453
Epoch [51/300], Train Loss: 0.001971
Validation Loss: 0.00203406
Epoch [52/300], Train Loss: 0.001891
Validation Loss: 0.00205730
Epoch [53/300], Train Loss: 0.001925
Validation Loss: 0.00201375
Epoch [54/300], Train Loss: 0.001852
Validation Loss: 0.00200850
Epoch [55/300], Train Loss: 0.001891
Validation Loss: 0.00201844
Epoch [56/300], Train Loss: 0.001900
Validation Loss: 0.00200050
Epoch [57/300], Train Loss: 0.001885
Validation Loss: 0.00200869
Epoch [58/300], Train Loss: 0.001905
Validation Loss: 0.00201360
Epoch [59/300], Train Loss: 0.001894
Validation Loss: 0.00205993
Epoch [60/300], Train Loss: 0.001898
Validation Loss: 0.00209419
Epoch [61/300], Train Loss: 0.001911
Validation Loss: 0.00202194
Epoch [62/300], Train Loss: 0.001839
Validation Loss: 0.00198286
Epoch [63/300], Train Loss: 0.001847
Validation Loss: 0.00198435
Epoch [64/300], Train Loss: 0.001824
Validation Loss: 0.00197060
Epoch [65/300], Train Loss: 0.001868
Validation Loss: 0.00197825
Epoch [66/300], Train Loss: 0.001854
Validation Loss: 0.00197164
Epoch [67/300], Train Loss: 0.001782
Validation Loss: 0.00197832
Epoch [68/300], Train Loss: 0.001869
Validation Loss: 0.00195667
Epoch [69/300], Train Loss: 0.001769
Validation Loss: 0.00196761
Epoch [70/300], Train Loss: 0.001839
Validation Loss: 0.00195783
Epoch [71/300], Train Loss: 0.001936
Validation Loss: 0.00197508
Epoch [72/300], Train Loss: 0.001713
Validation Loss: 0.00196027
Epoch [73/300], Train Loss: 0.001837
Validation Loss: 0.00197128
Epoch [74/300], Train Loss: 0.001799
Validation Loss: 0.00194366
Epoch [75/300], Train Loss: 0.001881
Validation Loss: 0.00195115
Epoch [76/300], Train Loss: 0.001731
Validation Loss: 0.00196397
Epoch [77/300], Train Loss: 0.001924
Validation Loss: 0.00195279
Epoch [78/300], Train Loss: 0.001797
Validation Loss: 0.00194336
Epoch [79/300], Train Loss: 0.001799
Validation Loss: 0.00195896
Epoch [80/300], Train Loss: 0.001807
Validation Loss: 0.00194185
Epoch [81/300], Train Loss: 0.001777
Validation Loss: 0.00193578
Epoch [82/300], Train Loss: 0.001744
Validation Loss: 0.00193068
Epoch [83/300], Train Loss: 0.001667
Validation Loss: 0.00192114
Epoch [84/300], Train Loss: 0.001709
Validation Loss: 0.00193239
Epoch [85/300], Train Loss: 0.001760
Validation Loss: 0.00192470
Epoch [86/300], Train Loss: 0.001823
Validation Loss: 0.00192320
Epoch [87/300], Train Loss: 0.001797
Validation Loss: 0.00192579
Epoch [88/300], Train Loss: 0.001796
Validation Loss: 0.00190958
Epoch [89/300], Train Loss: 0.001646
Validation Loss: 0.00190688
Epoch [90/300], Train Loss: 0.001725
Validation Loss: 0.00190309
Epoch [91/300], Train Loss: 0.001781
Validation Loss: 0.00191908
Epoch [92/300], Train Loss: 0.001803
Validation Loss: 0.00193278
Epoch [93/300], Train Loss: 0.001786
Validation Loss: 0.00189765
Epoch [94/300], Train Loss: 0.001751
Validation Loss: 0.00189285
Epoch [95/300], Train Loss: 0.001749
Validation Loss: 0.00189544
Epoch [96/300], Train Loss: 0.001755
Validation Loss: 0.00190274
Epoch [97/300], Train Loss: 0.001777
Validation Loss: 0.00188671
Epoch [98/300], Train Loss: 0.001718
Validation Loss: 0.00189489
Epoch [99/300], Train Loss: 0.001746
Validation Loss: 0.00189454
Epoch [100/300], Train Loss: 0.001709
Validation Loss: 0.00188777
Epoch [101/300], Train Loss: 0.001704
Validation Loss: 0.00189205
Epoch [102/300], Train Loss: 0.001765
Validation Loss: 0.00188506
Epoch [103/300], Train Loss: 0.001728
Validation Loss: 0.00187328
Epoch [104/300], Train Loss: 0.001656
Validation Loss: 0.00187133
Epoch [105/300], Train Loss: 0.001717
Validation Loss: 0.00190613
Epoch [106/300], Train Loss: 0.001713
Validation Loss: 0.00188125
Epoch [107/300], Train Loss: 0.001820
Validation Loss: 0.00188384
Epoch [108/300], Train Loss: 0.001771
Validation Loss: 0.00186368
Epoch [109/300], Train Loss: 0.001729
Validation Loss: 0.00186199
Epoch [110/300], Train Loss: 0.001696
Validation Loss: 0.00187092
Epoch [111/300], Train Loss: 0.001658
Validation Loss: 0.00186468
Epoch [112/300], Train Loss: 0.001638
Validation Loss: 0.00188841
Epoch [113/300], Train Loss: 0.001665
Validation Loss: 0.00186202
Epoch [114/300], Train Loss: 0.001644
Validation Loss: 0.00185851
Epoch [115/300], Train Loss: 0.001583
Validation Loss: 0.00185670
Epoch [116/300], Train Loss: 0.001653
Validation Loss: 0.00186271
Epoch [117/300], Train Loss: 0.001665
Validation Loss: 0.00187503
Epoch [118/300], Train Loss: 0.001620
Validation Loss: 0.00186405
Epoch [119/300], Train Loss: 0.001609
Validation Loss: 0.00185859
Epoch [120/300], Train Loss: 0.001707
Validation Loss: 0.00185507
Epoch [121/300], Train Loss: 0.001647
Validation Loss: 0.00185445
Epoch [122/300], Train Loss: 0.001709
Validation Loss: 0.00185475
Epoch [123/300], Train Loss: 0.001633
Validation Loss: 0.00185008
Epoch [124/300], Train Loss: 0.001707
Validation Loss: 0.00184840
Epoch [125/300], Train Loss: 0.001603
Validation Loss: 0.00185372
Epoch [126/300], Train Loss: 0.001696
Validation Loss: 0.00186497
Epoch [127/300], Train Loss: 0.001721
Validation Loss: 0.00185787
Epoch [128/300], Train Loss: 0.001589
Validation Loss: 0.00184567
Epoch [129/300], Train Loss: 0.001652
Validation Loss: 0.00185654
Epoch [130/300], Train Loss: 0.001737
Validation Loss: 0.00186253
Epoch [131/300], Train Loss: 0.001606
Validation Loss: 0.00184364
Epoch [132/300], Train Loss: 0.001671
Validation Loss: 0.00184351
Epoch [133/300], Train Loss: 0.001611
Validation Loss: 0.00184889
Epoch [134/300], Train Loss: 0.001653
Validation Loss: 0.00186609
Epoch [135/300], Train Loss: 0.001673
Validation Loss: 0.00184831
Epoch [136/300], Train Loss: 0.001613
Validation Loss: 0.00184261
Epoch [137/300], Train Loss: 0.001636
Validation Loss: 0.00185603
Epoch [138/300], Train Loss: 0.001616
Validation Loss: 0.00183984
Epoch [139/300], Train Loss: 0.001676
Validation Loss: 0.00183567
Epoch [140/300], Train Loss: 0.001658
Validation Loss: 0.00183919
Epoch [141/300], Train Loss: 0.001613
Validation Loss: 0.00183661
Epoch [142/300], Train Loss: 0.001697
Validation Loss: 0.00183550
Epoch [143/300], Train Loss: 0.001659
Validation Loss: 0.00183279
Epoch [144/300], Train Loss: 0.001640
Validation Loss: 0.00184392
Epoch [145/300], Train Loss: 0.001637
Validation Loss: 0.00183200
Epoch [146/300], Train Loss: 0.001649
Validation Loss: 0.00183551
Epoch [147/300], Train Loss: 0.001733
Validation Loss: 0.00184560
Epoch [148/300], Train Loss: 0.001645
Validation Loss: 0.00183904
Epoch [149/300], Train Loss: 0.001699
Validation Loss: 0.00183455
Epoch [150/300], Train Loss: 0.001593
Validation Loss: 0.00184261
Epoch [151/300], Train Loss: 0.001601
Validation Loss: 0.00187674
Epoch [152/300], Train Loss: 0.001662
Validation Loss: 0.00183496
Epoch [153/300], Train Loss: 0.001597
Validation Loss: 0.00182819
Epoch [154/300], Train Loss: 0.001652
Validation Loss: 0.00183987
Epoch [155/300], Train Loss: 0.001712
Validation Loss: 0.00183070
Epoch [156/300], Train Loss: 0.001616
Validation Loss: 0.00182680
Epoch [157/300], Train Loss: 0.001671
Validation Loss: 0.00183661
Epoch [158/300], Train Loss: 0.001724
Validation Loss: 0.00183010
Epoch [159/300], Train Loss: 0.001668
Validation Loss: 0.00183400
Epoch [160/300], Train Loss: 0.001588
Validation Loss: 0.00183628
Epoch [161/300], Train Loss: 0.001774
Validation Loss: 0.00182648
Epoch [162/300], Train Loss: 0.001704
Validation Loss: 0.00182209
Epoch [163/300], Train Loss: 0.001656
Validation Loss: 0.00181876
Epoch [164/300], Train Loss: 0.001591
Validation Loss: 0.00183352
Epoch [165/300], Train Loss: 0.001644
Validation Loss: 0.00182026
Epoch [166/300], Train Loss: 0.001672
Validation Loss: 0.00182296
Epoch [167/300], Train Loss: 0.001662
Validation Loss: 0.00182499
Epoch [168/300], Train Loss: 0.001655
Validation Loss: 0.00181700
Epoch [169/300], Train Loss: 0.001660
Validation Loss: 0.00182955
Epoch [170/300], Train Loss: 0.001620
Validation Loss: 0.00182907
Epoch [171/300], Train Loss: 0.001597
Validation Loss: 0.00182901
Epoch [172/300], Train Loss: 0.001561
Validation Loss: 0.00182431
Epoch [173/300], Train Loss: 0.001663
Validation Loss: 0.00181993
Epoch [174/300], Train Loss: 0.001611
Validation Loss: 0.00182235
Epoch [175/300], Train Loss: 0.001558
Validation Loss: 0.00181798
Epoch [176/300], Train Loss: 0.001634
Validation Loss: 0.00182057
Epoch [177/300], Train Loss: 0.001564
Validation Loss: 0.00181725
Epoch [178/300], Train Loss: 0.001571
Validation Loss: 0.00181818
Early stopping triggered

Evaluating model for: Freezer
Run 45/72 completed in 376.06 seconds with: {'MAE': np.float32(31.623276), 'MSE': np.float32(2171.4805), 'RMSE': np.float32(46.599148), 'SAE': np.float32(0.01371624), 'NDE': np.float32(0.36630785)}

Run 46/72: hidden=256, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Freezer
Dataset length: 1146 windows

Epoch [1/300], Train Loss: 0.011684
Validation Loss: 0.00963822
Epoch [2/300], Train Loss: 0.008078
Validation Loss: 0.00679094
Epoch [3/300], Train Loss: 0.006331
Validation Loss: 0.00591865
Epoch [4/300], Train Loss: 0.006242
Validation Loss: 0.00599623
Epoch [5/300], Train Loss: 0.006017
Validation Loss: 0.00588869
Epoch [6/300], Train Loss: 0.006026
Validation Loss: 0.00595294
Epoch [7/300], Train Loss: 0.005824
Validation Loss: 0.00590273
Epoch [8/300], Train Loss: 0.005846
Validation Loss: 0.00587546
Epoch [9/300], Train Loss: 0.005983
Validation Loss: 0.00587832
Epoch [10/300], Train Loss: 0.005902
Validation Loss: 0.00585982
Epoch [11/300], Train Loss: 0.005871
Validation Loss: 0.00584772
Epoch [12/300], Train Loss: 0.005731
Validation Loss: 0.00583552
Epoch [13/300], Train Loss: 0.006005
Validation Loss: 0.00587786
Epoch [14/300], Train Loss: 0.005784
Validation Loss: 0.00578428
Epoch [15/300], Train Loss: 0.005770
Validation Loss: 0.00576450
Epoch [16/300], Train Loss: 0.005728
Validation Loss: 0.00570747
Epoch [17/300], Train Loss: 0.005607
Validation Loss: 0.00560333
Epoch [18/300], Train Loss: 0.005474
Validation Loss: 0.00544957
Epoch [19/300], Train Loss: 0.005228
Validation Loss: 0.00525703
Epoch [20/300], Train Loss: 0.005098
Validation Loss: 0.00517580
Epoch [21/300], Train Loss: 0.004818
Validation Loss: 0.00502971
Epoch [22/300], Train Loss: 0.004742
Validation Loss: 0.00472457
Epoch [23/300], Train Loss: 0.004589
Validation Loss: 0.00448109
Epoch [24/300], Train Loss: 0.004247
Validation Loss: 0.00460486
Epoch [25/300], Train Loss: 0.004283
Validation Loss: 0.00417482
Epoch [26/300], Train Loss: 0.003883
Validation Loss: 0.00379089
Epoch [27/300], Train Loss: 0.003779
Validation Loss: 0.00359219
Epoch [28/300], Train Loss: 0.003424
Validation Loss: 0.00310999
Epoch [29/300], Train Loss: 0.003001
Validation Loss: 0.00274658
Epoch [30/300], Train Loss: 0.002656
Validation Loss: 0.00260323
Epoch [31/300], Train Loss: 0.002574
Validation Loss: 0.00253598
Epoch [32/300], Train Loss: 0.002443
Validation Loss: 0.00253048
Epoch [33/300], Train Loss: 0.002459
Validation Loss: 0.00232134
Epoch [34/300], Train Loss: 0.002405
Validation Loss: 0.00227438
Epoch [35/300], Train Loss: 0.002280
Validation Loss: 0.00224312
Epoch [36/300], Train Loss: 0.002178
Validation Loss: 0.00223146
Epoch [37/300], Train Loss: 0.002198
Validation Loss: 0.00221864
Epoch [38/300], Train Loss: 0.002269
Validation Loss: 0.00223129
Epoch [39/300], Train Loss: 0.002252
Validation Loss: 0.00218150
Epoch [40/300], Train Loss: 0.002015
Validation Loss: 0.00211223
Epoch [41/300], Train Loss: 0.002186
Validation Loss: 0.00236094
Epoch [42/300], Train Loss: 0.002018
Validation Loss: 0.00237008
Epoch [43/300], Train Loss: 0.002024
Validation Loss: 0.00240963
Epoch [44/300], Train Loss: 0.001989
Validation Loss: 0.00246681
Epoch [45/300], Train Loss: 0.002141
Validation Loss: 0.00236731
Epoch [46/300], Train Loss: 0.002086
Validation Loss: 0.00233921
Epoch [47/300], Train Loss: 0.001958
Validation Loss: 0.00235876
Epoch [48/300], Train Loss: 0.002024
Validation Loss: 0.00233279
Epoch [49/300], Train Loss: 0.001914
Validation Loss: 0.00233323
Epoch [50/300], Train Loss: 0.002105
Validation Loss: 0.00236891
Early stopping triggered

Evaluating model for: Freezer
Run 46/72 completed in 135.29 seconds with: {'MAE': np.float32(34.526108), 'MSE': np.float32(2925.4202), 'RMSE': np.float32(54.087154), 'SAE': np.float32(0.036564086), 'NDE': np.float32(0.42516977)}

Run 47/72: hidden=256, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Freezer
Dataset length: 1146 windows

Epoch [1/300], Train Loss: 0.012851
Validation Loss: 0.01067827
Epoch [2/300], Train Loss: 0.008861
Validation Loss: 0.00729681
Epoch [3/300], Train Loss: 0.006567
Validation Loss: 0.00589035
Epoch [4/300], Train Loss: 0.006184
Validation Loss: 0.00600948
Epoch [5/300], Train Loss: 0.006024
Validation Loss: 0.00588302
Epoch [6/300], Train Loss: 0.006029
Validation Loss: 0.00595843
Epoch [7/300], Train Loss: 0.005828
Validation Loss: 0.00589423
Epoch [8/300], Train Loss: 0.005852
Validation Loss: 0.00587076
Epoch [9/300], Train Loss: 0.005986
Validation Loss: 0.00587861
Epoch [10/300], Train Loss: 0.005910
Validation Loss: 0.00586048
Epoch [11/300], Train Loss: 0.005881
Validation Loss: 0.00584695
Epoch [12/300], Train Loss: 0.005746
Validation Loss: 0.00583300
Epoch [13/300], Train Loss: 0.006022
Validation Loss: 0.00587464
Epoch [14/300], Train Loss: 0.005811
Validation Loss: 0.00576775
Epoch [15/300], Train Loss: 0.005776
Validation Loss: 0.00572478
Epoch [16/300], Train Loss: 0.005693
Validation Loss: 0.00558530
Epoch [17/300], Train Loss: 0.005444
Validation Loss: 0.00516506
Epoch [18/300], Train Loss: 0.005096
Validation Loss: 0.00493344
Epoch [19/300], Train Loss: 0.004571
Validation Loss: 0.00415632
Epoch [20/300], Train Loss: 0.003625
Validation Loss: 0.00334010
Epoch [21/300], Train Loss: 0.003122
Validation Loss: 0.00336673
Epoch [22/300], Train Loss: 0.003122
Validation Loss: 0.00307401
Epoch [23/300], Train Loss: 0.002972
Validation Loss: 0.00292700
Epoch [24/300], Train Loss: 0.002809
Validation Loss: 0.00295659
Epoch [25/300], Train Loss: 0.002900
Validation Loss: 0.00282252
Epoch [26/300], Train Loss: 0.002644
Validation Loss: 0.00278128
Epoch [27/300], Train Loss: 0.002690
Validation Loss: 0.00270772
Epoch [28/300], Train Loss: 0.002642
Validation Loss: 0.00267312
Epoch [29/300], Train Loss: 0.002562
Validation Loss: 0.00262381
Epoch [30/300], Train Loss: 0.002489
Validation Loss: 0.00251389
Epoch [31/300], Train Loss: 0.002388
Validation Loss: 0.00248942
Epoch [32/300], Train Loss: 0.002204
Validation Loss: 0.00247610
Epoch [33/300], Train Loss: 0.002274
Validation Loss: 0.00246729
Epoch [34/300], Train Loss: 0.002301
Validation Loss: 0.00236562
Epoch [35/300], Train Loss: 0.002161
Validation Loss: 0.00234053
Epoch [36/300], Train Loss: 0.002139
Validation Loss: 0.00240915
Epoch [37/300], Train Loss: 0.002233
Validation Loss: 0.00226564
Epoch [38/300], Train Loss: 0.002303
Validation Loss: 0.00224649
Epoch [39/300], Train Loss: 0.002275
Validation Loss: 0.00224226
Epoch [40/300], Train Loss: 0.002050
Validation Loss: 0.00224554
Epoch [41/300], Train Loss: 0.002243
Validation Loss: 0.00223345
Epoch [42/300], Train Loss: 0.002094
Validation Loss: 0.00221060
Epoch [43/300], Train Loss: 0.002120
Validation Loss: 0.00223089
Epoch [44/300], Train Loss: 0.002038
Validation Loss: 0.00225964
Epoch [45/300], Train Loss: 0.002180
Validation Loss: 0.00247748
Epoch [46/300], Train Loss: 0.002250
Validation Loss: 0.00225906
Epoch [47/300], Train Loss: 0.002101
Validation Loss: 0.00232749
Epoch [48/300], Train Loss: 0.002121
Validation Loss: 0.00227985
Epoch [49/300], Train Loss: 0.002024
Validation Loss: 0.00228448
Epoch [50/300], Train Loss: 0.002136
Validation Loss: 0.00238296
Epoch [51/300], Train Loss: 0.002100
Validation Loss: 0.00226442
Epoch [52/300], Train Loss: 0.002104
Validation Loss: 0.00251286
Early stopping triggered

Evaluating model for: Freezer
Run 47/72 completed in 170.28 seconds with: {'MAE': np.float32(35.07589), 'MSE': np.float32(3255.2107), 'RMSE': np.float32(57.054455), 'SAE': np.float32(0.08571546), 'NDE': np.float32(0.44849518)}

Run 48/72: hidden=256, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Freezer
Dataset length: 1146 windows

Epoch [1/300], Train Loss: 0.008531
Validation Loss: 0.00717134
Epoch [2/300], Train Loss: 0.006381
Validation Loss: 0.00589198
Epoch [3/300], Train Loss: 0.006113
Validation Loss: 0.00598094
Epoch [4/300], Train Loss: 0.006205
Validation Loss: 0.00587648
Epoch [5/300], Train Loss: 0.005903
Validation Loss: 0.00589480
Epoch [6/300], Train Loss: 0.005974
Validation Loss: 0.00589465
Epoch [7/300], Train Loss: 0.005798
Validation Loss: 0.00587359
Epoch [8/300], Train Loss: 0.005834
Validation Loss: 0.00587557
Epoch [9/300], Train Loss: 0.005980
Validation Loss: 0.00589181
Epoch [10/300], Train Loss: 0.005899
Validation Loss: 0.00585736
Epoch [11/300], Train Loss: 0.005862
Validation Loss: 0.00583393
Epoch [12/300], Train Loss: 0.005714
Validation Loss: 0.00579349
Epoch [13/300], Train Loss: 0.005940
Validation Loss: 0.00575254
Epoch [14/300], Train Loss: 0.005506
Validation Loss: 0.00508288
Epoch [15/300], Train Loss: 0.004461
Validation Loss: 0.00431116
Epoch [16/300], Train Loss: 0.003893
Validation Loss: 0.00380079
Epoch [17/300], Train Loss: 0.003480
Validation Loss: 0.00335445
Epoch [18/300], Train Loss: 0.003118
Validation Loss: 0.00306079
Epoch [19/300], Train Loss: 0.002908
Validation Loss: 0.00281648
Epoch [20/300], Train Loss: 0.002773
Validation Loss: 0.00269173
Epoch [21/300], Train Loss: 0.002560
Validation Loss: 0.00258070
Epoch [22/300], Train Loss: 0.002611
Validation Loss: 0.00249172
Epoch [23/300], Train Loss: 0.002543
Validation Loss: 0.00242247
Epoch [24/300], Train Loss: 0.002413
Validation Loss: 0.00248821
Epoch [25/300], Train Loss: 0.002535
Validation Loss: 0.00298940
Epoch [26/300], Train Loss: 0.002430
Validation Loss: 0.00297303
Epoch [27/300], Train Loss: 0.002495
Validation Loss: 0.00314020
Epoch [28/300], Train Loss: 0.004723
Validation Loss: 0.00539350
Epoch [29/300], Train Loss: 0.005581
Validation Loss: 0.00548810
Epoch [30/300], Train Loss: 0.005377
Validation Loss: 0.00527845
Epoch [31/300], Train Loss: 0.005400
Validation Loss: 0.00517738
Epoch [32/300], Train Loss: 0.005112
Validation Loss: 0.00497550
Epoch [33/300], Train Loss: 0.004952
Validation Loss: 0.00461704
Early stopping triggered

Evaluating model for: Freezer
Run 48/72 completed in 149.22 seconds with: {'MAE': np.float32(78.5683), 'MSE': np.float32(7744.151), 'RMSE': np.float32(88.000854), 'SAE': np.float32(0.17393237), 'NDE': np.float32(0.69175947)}

Run 49/72: hidden=512, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Freezer
Dataset length: 14022 windows

Epoch [1/300], Train Loss: 0.005444
Validation Loss: 0.00384454
Epoch [2/300], Train Loss: 0.002710
Validation Loss: 0.00235870
Epoch [3/300], Train Loss: 0.002102
Validation Loss: 0.00202355
Epoch [4/300], Train Loss: 0.001915
Validation Loss: 0.00191624
Epoch [5/300], Train Loss: 0.001856
Validation Loss: 0.00186677
Epoch [6/300], Train Loss: 0.001789
Validation Loss: 0.00182661
Epoch [7/300], Train Loss: 0.001761
Validation Loss: 0.00188581
Epoch [8/300], Train Loss: 0.001720
Validation Loss: 0.00174347
Epoch [9/300], Train Loss: 0.001680
Validation Loss: 0.00173161
Epoch [10/300], Train Loss: 0.001667
Validation Loss: 0.00172690
Epoch [11/300], Train Loss: 0.001660
Validation Loss: 0.00167148
Epoch [12/300], Train Loss: 0.001633
Validation Loss: 0.00168697
Epoch [13/300], Train Loss: 0.001602
Validation Loss: 0.00162913
Epoch [14/300], Train Loss: 0.001587
Validation Loss: 0.00169145
Epoch [15/300], Train Loss: 0.001613
Validation Loss: 0.00161475
Epoch [16/300], Train Loss: 0.001541
Validation Loss: 0.00157559
Epoch [17/300], Train Loss: 0.001529
Validation Loss: 0.00156631
Epoch [18/300], Train Loss: 0.001508
Validation Loss: 0.00155156
Epoch [19/300], Train Loss: 0.001501
Validation Loss: 0.00150837
Epoch [20/300], Train Loss: 0.001461
Validation Loss: 0.00147159
Epoch [21/300], Train Loss: 0.001467
Validation Loss: 0.00149281
Epoch [22/300], Train Loss: 0.001420
Validation Loss: 0.00142941
Epoch [23/300], Train Loss: 0.001384
Validation Loss: 0.00143011
Epoch [24/300], Train Loss: 0.001333
Validation Loss: 0.00129296
Epoch [25/300], Train Loss: 0.001241
Validation Loss: 0.00118735
Epoch [26/300], Train Loss: 0.001125
Validation Loss: 0.00105777
Epoch [27/300], Train Loss: 0.001023
Validation Loss: 0.00109025
Epoch [28/300], Train Loss: 0.000984
Validation Loss: 0.00101095
Epoch [29/300], Train Loss: 0.000932
Validation Loss: 0.00097031
Epoch [30/300], Train Loss: 0.000930
Validation Loss: 0.00089790
Epoch [31/300], Train Loss: 0.000890
Validation Loss: 0.00089469
Epoch [32/300], Train Loss: 0.000890
Validation Loss: 0.00090492
Epoch [33/300], Train Loss: 0.000885
Validation Loss: 0.00085654
Epoch [34/300], Train Loss: 0.000850
Validation Loss: 0.00083955
Epoch [35/300], Train Loss: 0.000862
Validation Loss: 0.00087231
Epoch [36/300], Train Loss: 0.000845
Validation Loss: 0.00080505
Epoch [37/300], Train Loss: 0.000833
Validation Loss: 0.00092563
Epoch [38/300], Train Loss: 0.000828
Validation Loss: 0.00083004
Epoch [39/300], Train Loss: 0.000815
Validation Loss: 0.00081231
Epoch [40/300], Train Loss: 0.000809
Validation Loss: 0.00080263
Epoch [41/300], Train Loss: 0.000800
Validation Loss: 0.00077589
Epoch [42/300], Train Loss: 0.000797
Validation Loss: 0.00078536
Epoch [43/300], Train Loss: 0.000807
Validation Loss: 0.00076256
Epoch [44/300], Train Loss: 0.000785
Validation Loss: 0.00075435
Epoch [45/300], Train Loss: 0.000779
Validation Loss: 0.00078081
Epoch [46/300], Train Loss: 0.000761
Validation Loss: 0.00074247
Epoch [47/300], Train Loss: 0.000760
Validation Loss: 0.00078374
Epoch [48/300], Train Loss: 0.000760
Validation Loss: 0.00071798
Epoch [49/300], Train Loss: 0.000750
Validation Loss: 0.00074105
Epoch [50/300], Train Loss: 0.000741
Validation Loss: 0.00072993
Epoch [51/300], Train Loss: 0.000749
Validation Loss: 0.00076008
Epoch [52/300], Train Loss: 0.000735
Validation Loss: 0.00071968
Epoch [53/300], Train Loss: 0.000729
Validation Loss: 0.00069180
Epoch [54/300], Train Loss: 0.000737
Validation Loss: 0.00068559
Epoch [55/300], Train Loss: 0.000735
Validation Loss: 0.00074751
Epoch [56/300], Train Loss: 0.000720
Validation Loss: 0.00071882
Epoch [57/300], Train Loss: 0.000707
Validation Loss: 0.00074003
Epoch [58/300], Train Loss: 0.000717
Validation Loss: 0.00069433
Epoch [59/300], Train Loss: 0.000724
Validation Loss: 0.00077859
Epoch [60/300], Train Loss: 0.000706
Validation Loss: 0.00071136
Epoch [61/300], Train Loss: 0.000723
Validation Loss: 0.00065855
Epoch [62/300], Train Loss: 0.000680
Validation Loss: 0.00066598
Epoch [63/300], Train Loss: 0.000689
Validation Loss: 0.00070141
Epoch [64/300], Train Loss: 0.000695
Validation Loss: 0.00067811
Epoch [65/300], Train Loss: 0.000694
Validation Loss: 0.00069690
Epoch [66/300], Train Loss: 0.000681
Validation Loss: 0.00067225
Epoch [67/300], Train Loss: 0.000666
Validation Loss: 0.00064071
Epoch [68/300], Train Loss: 0.000671
Validation Loss: 0.00064465
Epoch [69/300], Train Loss: 0.000684
Validation Loss: 0.00062575
Epoch [70/300], Train Loss: 0.000661
Validation Loss: 0.00064754
Epoch [71/300], Train Loss: 0.000663
Validation Loss: 0.00061822
Epoch [72/300], Train Loss: 0.000652
Validation Loss: 0.00063341
Epoch [73/300], Train Loss: 0.000656
Validation Loss: 0.00065238
Epoch [74/300], Train Loss: 0.000653
Validation Loss: 0.00065355
Epoch [75/300], Train Loss: 0.000663
Validation Loss: 0.00065202
Epoch [76/300], Train Loss: 0.000645
Validation Loss: 0.00063222
Epoch [77/300], Train Loss: 0.000637
Validation Loss: 0.00061675
Epoch [78/300], Train Loss: 0.000648
Validation Loss: 0.00060028
Epoch [79/300], Train Loss: 0.000637
Validation Loss: 0.00061538
Epoch [80/300], Train Loss: 0.000648
Validation Loss: 0.00060881
Epoch [81/300], Train Loss: 0.000640
Validation Loss: 0.00060700
Epoch [82/300], Train Loss: 0.000629
Validation Loss: 0.00061652
Epoch [83/300], Train Loss: 0.000645
Validation Loss: 0.00061148
Epoch [84/300], Train Loss: 0.000621
Validation Loss: 0.00059425
Epoch [85/300], Train Loss: 0.000608
Validation Loss: 0.00062189
Epoch [86/300], Train Loss: 0.000629
Validation Loss: 0.00059147
Epoch [87/300], Train Loss: 0.000622
Validation Loss: 0.00058376
Epoch [88/300], Train Loss: 0.000603
Validation Loss: 0.00060629
Epoch [89/300], Train Loss: 0.000622
Validation Loss: 0.00063534
Epoch [90/300], Train Loss: 0.000604
Validation Loss: 0.00058567
Epoch [91/300], Train Loss: 0.000613
Validation Loss: 0.00060027
Epoch [92/300], Train Loss: 0.000603
Validation Loss: 0.00057397
Epoch [93/300], Train Loss: 0.000597
Validation Loss: 0.00058087
Epoch [94/300], Train Loss: 0.000613
Validation Loss: 0.00057990
Epoch [95/300], Train Loss: 0.000592
Validation Loss: 0.00057163
Epoch [96/300], Train Loss: 0.000606
Validation Loss: 0.00060447
Epoch [97/300], Train Loss: 0.000601
Validation Loss: 0.00057641
Epoch [98/300], Train Loss: 0.000601
Validation Loss: 0.00055787
Epoch [99/300], Train Loss: 0.000576
Validation Loss: 0.00059603
Epoch [100/300], Train Loss: 0.000610
Validation Loss: 0.00057961
Epoch [101/300], Train Loss: 0.000579
Validation Loss: 0.00054727
Epoch [102/300], Train Loss: 0.000578
Validation Loss: 0.00054718
Epoch [103/300], Train Loss: 0.000576
Validation Loss: 0.00055234
Epoch [104/300], Train Loss: 0.000734
Validation Loss: 0.00079695
Epoch [105/300], Train Loss: 0.000722
Validation Loss: 0.00069593
Epoch [106/300], Train Loss: 0.000674
Validation Loss: 0.00064997
Epoch [107/300], Train Loss: 0.000638
Validation Loss: 0.00063911
Epoch [108/300], Train Loss: 0.000631
Validation Loss: 0.00062678
Epoch [109/300], Train Loss: 0.000604
Validation Loss: 0.00059902
Epoch [110/300], Train Loss: 0.000595
Validation Loss: 0.00056410
Epoch [111/300], Train Loss: 0.000589
Validation Loss: 0.00056034
Epoch [112/300], Train Loss: 0.000595
Validation Loss: 0.00059933
Early stopping triggered

Evaluating model for: Freezer
Run 49/72 completed in 1835.22 seconds with: {'MAE': np.float32(21.122078), 'MSE': np.float32(992.85236), 'RMSE': np.float32(31.50956), 'SAE': np.float32(0.05029284), 'NDE': np.float32(0.23893766)}

Run 50/72: hidden=512, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Freezer
Dataset length: 14022 windows

Epoch [1/300], Train Loss: 0.005680
Validation Loss: 0.00393266
Epoch [2/300], Train Loss: 0.002843
Validation Loss: 0.00247778
Epoch [3/300], Train Loss: 0.002241
Validation Loss: 0.00210508
Epoch [4/300], Train Loss: 0.001992
Validation Loss: 0.00196511
Epoch [5/300], Train Loss: 0.001903
Validation Loss: 0.00191758
Epoch [6/300], Train Loss: 0.001843
Validation Loss: 0.00190593
Epoch [7/300], Train Loss: 0.001808
Validation Loss: 0.00196432
Epoch [8/300], Train Loss: 0.001779
Validation Loss: 0.00185159
Epoch [9/300], Train Loss: 0.001748
Validation Loss: 0.00179936
Epoch [10/300], Train Loss: 0.001735
Validation Loss: 0.00177893
Epoch [11/300], Train Loss: 0.001719
Validation Loss: 0.00174561
Epoch [12/300], Train Loss: 0.001714
Validation Loss: 0.00174601
Epoch [13/300], Train Loss: 0.001670
Validation Loss: 0.00176162
Epoch [14/300], Train Loss: 0.001649
Validation Loss: 0.00166328
Epoch [15/300], Train Loss: 0.001643
Validation Loss: 0.00173873
Epoch [16/300], Train Loss: 0.001612
Validation Loss: 0.00166164
Epoch [17/300], Train Loss: 0.001582
Validation Loss: 0.00162532
Epoch [18/300], Train Loss: 0.001571
Validation Loss: 0.00162016
Epoch [19/300], Train Loss: 0.001585
Validation Loss: 0.00161400
Epoch [20/300], Train Loss: 0.001543
Validation Loss: 0.00156165
Epoch [21/300], Train Loss: 0.001568
Validation Loss: 0.00161551
Epoch [22/300], Train Loss: 0.001569
Validation Loss: 0.00162114
Epoch [23/300], Train Loss: 0.001544
Validation Loss: 0.00162387
Epoch [24/300], Train Loss: 0.001537
Validation Loss: 0.00155017
Epoch [25/300], Train Loss: 0.001543
Validation Loss: 0.00163106
Epoch [26/300], Train Loss: 0.001547
Validation Loss: 0.00158466
Epoch [27/300], Train Loss: 0.001520
Validation Loss: 0.00162063
Epoch [28/300], Train Loss: 0.001506
Validation Loss: 0.00160467
Epoch [29/300], Train Loss: 0.001476
Validation Loss: 0.00159602
Epoch [30/300], Train Loss: 0.001496
Validation Loss: 0.00149565
Epoch [31/300], Train Loss: 0.001469
Validation Loss: 0.00148848
Epoch [32/300], Train Loss: 0.001467
Validation Loss: 0.00151671
Epoch [33/300], Train Loss: 0.001436
Validation Loss: 0.00148721
Epoch [34/300], Train Loss: 0.001487
Validation Loss: 0.00147839
Epoch [35/300], Train Loss: 0.001420
Validation Loss: 0.00146408
Epoch [36/300], Train Loss: 0.001390
Validation Loss: 0.00138867
Epoch [37/300], Train Loss: 0.001304
Validation Loss: 0.00125675
Epoch [38/300], Train Loss: 0.001144
Validation Loss: 0.00112362
Epoch [39/300], Train Loss: 0.001048
Validation Loss: 0.00118768
Epoch [40/300], Train Loss: 0.001002
Validation Loss: 0.00097029
Epoch [41/300], Train Loss: 0.000950
Validation Loss: 0.00093209
Epoch [42/300], Train Loss: 0.000924
Validation Loss: 0.00105631
Epoch [43/300], Train Loss: 0.000975
Validation Loss: 0.00091529
Epoch [44/300], Train Loss: 0.000900
Validation Loss: 0.00088406
Epoch [45/300], Train Loss: 0.000879
Validation Loss: 0.00087158
Epoch [46/300], Train Loss: 0.000858
Validation Loss: 0.00083073
Epoch [47/300], Train Loss: 0.000845
Validation Loss: 0.00087534
Epoch [48/300], Train Loss: 0.000830
Validation Loss: 0.00082897
Epoch [49/300], Train Loss: 0.000821
Validation Loss: 0.00083389
Epoch [50/300], Train Loss: 0.000800
Validation Loss: 0.00077888
Epoch [51/300], Train Loss: 0.000785
Validation Loss: 0.00083139
Epoch [52/300], Train Loss: 0.000776
Validation Loss: 0.00079388
Epoch [53/300], Train Loss: 0.000766
Validation Loss: 0.00078182
Epoch [54/300], Train Loss: 0.000776
Validation Loss: 0.00079820
Epoch [55/300], Train Loss: 0.000928
Validation Loss: 0.00092177
Epoch [56/300], Train Loss: 0.000863
Validation Loss: 0.00090282
Epoch [57/300], Train Loss: 0.000810
Validation Loss: 0.00080139
Epoch [58/300], Train Loss: 0.000800
Validation Loss: 0.00078372
Epoch [59/300], Train Loss: 0.000775
Validation Loss: 0.00078838
Epoch [60/300], Train Loss: 0.000804
Validation Loss: 0.00077501
Epoch [61/300], Train Loss: 0.000752
Validation Loss: 0.00077842
Epoch [62/300], Train Loss: 0.000744
Validation Loss: 0.00074245
Epoch [63/300], Train Loss: 0.000776
Validation Loss: 0.00073214
Epoch [64/300], Train Loss: 0.000799
Validation Loss: 0.00081301
Epoch [65/300], Train Loss: 0.000738
Validation Loss: 0.00073291
Epoch [66/300], Train Loss: 0.000723
Validation Loss: 0.00071252
Epoch [67/300], Train Loss: 0.000721
Validation Loss: 0.00083541
Epoch [68/300], Train Loss: 0.000739
Validation Loss: 0.00070043
Epoch [69/300], Train Loss: 0.000734
Validation Loss: 0.00069841
Epoch [70/300], Train Loss: 0.000708
Validation Loss: 0.00068541
Epoch [71/300], Train Loss: 0.000701
Validation Loss: 0.00068230
Epoch [72/300], Train Loss: 0.000700
Validation Loss: 0.00069090
Epoch [73/300], Train Loss: 0.000709
Validation Loss: 0.00077153
Epoch [74/300], Train Loss: 0.000803
Validation Loss: 0.00079104
Epoch [75/300], Train Loss: 0.000730
Validation Loss: 0.00072633
Epoch [76/300], Train Loss: 0.000709
Validation Loss: 0.00068720
Epoch [77/300], Train Loss: 0.000693
Validation Loss: 0.00069485
Epoch [78/300], Train Loss: 0.000686
Validation Loss: 0.00068888
Epoch [79/300], Train Loss: 0.000680
Validation Loss: 0.00066448
Epoch [80/300], Train Loss: 0.000676
Validation Loss: 0.00065710
Epoch [81/300], Train Loss: 0.000670
Validation Loss: 0.00066968
Epoch [82/300], Train Loss: 0.000668
Validation Loss: 0.00067346
Epoch [83/300], Train Loss: 0.000666
Validation Loss: 0.00065717
Epoch [84/300], Train Loss: 0.000669
Validation Loss: 0.00067213
Epoch [85/300], Train Loss: 0.000676
Validation Loss: 0.00067644
Epoch [86/300], Train Loss: 0.000663
Validation Loss: 0.00063419
Epoch [87/300], Train Loss: 0.000658
Validation Loss: 0.00062917
Epoch [88/300], Train Loss: 0.000649
Validation Loss: 0.00064381
Epoch [89/300], Train Loss: 0.000646
Validation Loss: 0.00064802
Epoch [90/300], Train Loss: 0.000653
Validation Loss: 0.00062693
Epoch [91/300], Train Loss: 0.000653
Validation Loss: 0.00064276
Epoch [92/300], Train Loss: 0.000680
Validation Loss: 0.00065049
Epoch [93/300], Train Loss: 0.000640
Validation Loss: 0.00062258
Epoch [94/300], Train Loss: 0.000629
Validation Loss: 0.00062748
Epoch [95/300], Train Loss: 0.000630
Validation Loss: 0.00061675
Epoch [96/300], Train Loss: 0.000635
Validation Loss: 0.00062593
Epoch [97/300], Train Loss: 0.000666
Validation Loss: 0.00061113
Epoch [98/300], Train Loss: 0.000623
Validation Loss: 0.00061215
Epoch [99/300], Train Loss: 0.000654
Validation Loss: 0.00062047
Epoch [100/300], Train Loss: 0.000636
Validation Loss: 0.00067577
Epoch [101/300], Train Loss: 0.000650
Validation Loss: 0.00063850
Epoch [102/300], Train Loss: 0.000680
Validation Loss: 0.00067360
Epoch [103/300], Train Loss: 0.000681
Validation Loss: 0.00092681
Epoch [104/300], Train Loss: 0.000746
Validation Loss: 0.00072835
Epoch [105/300], Train Loss: 0.000682
Validation Loss: 0.00066310
Epoch [106/300], Train Loss: 0.000676
Validation Loss: 0.00063973
Epoch [107/300], Train Loss: 0.000631
Validation Loss: 0.00061430
Early stopping triggered

Evaluating model for: Freezer
Run 50/72 completed in 1972.19 seconds with: {'MAE': np.float32(23.057497), 'MSE': np.float32(1011.5535), 'RMSE': np.float32(31.80493), 'SAE': np.float32(0.0063209804), 'NDE': np.float32(0.24117744)}

Run 51/72: hidden=512, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Freezer
Dataset length: 14022 windows

Epoch [1/300], Train Loss: 0.006157
Validation Loss: 0.00516456
Epoch [2/300], Train Loss: 0.003807
Validation Loss: 0.00257882
Epoch [3/300], Train Loss: 0.002317
Validation Loss: 0.00233379
Epoch [4/300], Train Loss: 0.001987
Validation Loss: 0.00193167
Epoch [5/300], Train Loss: 0.001921
Validation Loss: 0.00189739
Epoch [6/300], Train Loss: 0.001838
Validation Loss: 0.00186976
Epoch [7/300], Train Loss: 0.001826
Validation Loss: 0.00194272
Epoch [8/300], Train Loss: 0.001771
Validation Loss: 0.00184138
Epoch [9/300], Train Loss: 0.001751
Validation Loss: 0.00176553
Epoch [10/300], Train Loss: 0.001741
Validation Loss: 0.00174750
Epoch [11/300], Train Loss: 0.001729
Validation Loss: 0.00173075
Epoch [12/300], Train Loss: 0.001713
Validation Loss: 0.00170302
Epoch [13/300], Train Loss: 0.001674
Validation Loss: 0.00169698
Epoch [14/300], Train Loss: 0.001661
Validation Loss: 0.00166019
Epoch [15/300], Train Loss: 0.001697
Validation Loss: 0.00167876
Epoch [16/300], Train Loss: 0.001616
Validation Loss: 0.00163670
Epoch [17/300], Train Loss: 0.001589
Validation Loss: 0.00160103
Epoch [18/300], Train Loss: 0.001565
Validation Loss: 0.00159574
Epoch [19/300], Train Loss: 0.001575
Validation Loss: 0.00159508
Epoch [20/300], Train Loss: 0.001530
Validation Loss: 0.00154280
Epoch [21/300], Train Loss: 0.001537
Validation Loss: 0.00154259
Epoch [22/300], Train Loss: 0.001486
Validation Loss: 0.00147042
Epoch [23/300], Train Loss: 0.001487
Validation Loss: 0.00148543
Epoch [24/300], Train Loss: 0.001384
Validation Loss: 0.00128754
Epoch [25/300], Train Loss: 0.001147
Validation Loss: 0.00109825
Epoch [26/300], Train Loss: 0.001029
Validation Loss: 0.00103700
Epoch [27/300], Train Loss: 0.001027
Validation Loss: 0.00106229
Epoch [28/300], Train Loss: 0.000953
Validation Loss: 0.00103915
Epoch [29/300], Train Loss: 0.000912
Validation Loss: 0.00103451
Epoch [30/300], Train Loss: 0.000938
Validation Loss: 0.00085220
Epoch [31/300], Train Loss: 0.000860
Validation Loss: 0.00083168
Epoch [32/300], Train Loss: 0.000866
Validation Loss: 0.00084225
Epoch [33/300], Train Loss: 0.000827
Validation Loss: 0.00082072
Epoch [34/300], Train Loss: 0.000834
Validation Loss: 0.00080517
Epoch [35/300], Train Loss: 0.000823
Validation Loss: 0.00080019
Epoch [36/300], Train Loss: 0.000811
Validation Loss: 0.00080797
Epoch [37/300], Train Loss: 0.000805
Validation Loss: 0.00078316
Epoch [38/300], Train Loss: 0.000794
Validation Loss: 0.00080207
Epoch [39/300], Train Loss: 0.000822
Validation Loss: 0.00076445
Epoch [40/300], Train Loss: 0.000800
Validation Loss: 0.00082927
Epoch [41/300], Train Loss: 0.000778
Validation Loss: 0.00076922
Epoch [42/300], Train Loss: 0.000792
Validation Loss: 0.00076561
Epoch [43/300], Train Loss: 0.000772
Validation Loss: 0.00076027
Epoch [44/300], Train Loss: 0.000756
Validation Loss: 0.00074550
Epoch [45/300], Train Loss: 0.000805
Validation Loss: 0.00082828
Epoch [46/300], Train Loss: 0.000779
Validation Loss: 0.00076817
Epoch [47/300], Train Loss: 0.000766
Validation Loss: 0.00087919
Epoch [48/300], Train Loss: 0.000764
Validation Loss: 0.00075704
Epoch [49/300], Train Loss: 0.000779
Validation Loss: 0.00085275
Epoch [50/300], Train Loss: 0.000749
Validation Loss: 0.00070917
Epoch [51/300], Train Loss: 0.000721
Validation Loss: 0.00073118
Epoch [52/300], Train Loss: 0.000755
Validation Loss: 0.00075760
Epoch [53/300], Train Loss: 0.000743
Validation Loss: 0.00083451
Epoch [54/300], Train Loss: 0.000737
Validation Loss: 0.00072620
Epoch [55/300], Train Loss: 0.000859
Validation Loss: 0.00075132
Epoch [56/300], Train Loss: 0.000748
Validation Loss: 0.00074236
Epoch [57/300], Train Loss: 0.000721
Validation Loss: 0.00075918
Epoch [58/300], Train Loss: 0.000732
Validation Loss: 0.00071334
Epoch [59/300], Train Loss: 0.000719
Validation Loss: 0.00076157
Epoch [60/300], Train Loss: 0.000722
Validation Loss: 0.00072387
Early stopping triggered

Evaluating model for: Freezer
Run 51/72 completed in 1223.55 seconds with: {'MAE': np.float32(24.006836), 'MSE': np.float32(1123.0308), 'RMSE': np.float32(33.51165), 'SAE': np.float32(0.031210884), 'NDE': np.float32(0.25411958)}

Run 52/72: hidden=512, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Freezer
Dataset length: 14022 windows

Epoch [1/300], Train Loss: 0.005990
Validation Loss: 0.00570155
Epoch [2/300], Train Loss: 0.003822
Validation Loss: 0.00274710
Epoch [3/300], Train Loss: 0.002479
Validation Loss: 0.00234255
Epoch [4/300], Train Loss: 0.002097
Validation Loss: 0.00215551
Epoch [5/300], Train Loss: 0.002003
Validation Loss: 0.00202186
Epoch [6/300], Train Loss: 0.001895
Validation Loss: 0.00191798
Epoch [7/300], Train Loss: 0.001825
Validation Loss: 0.00194343
Epoch [8/300], Train Loss: 0.001766
Validation Loss: 0.00183085
Epoch [9/300], Train Loss: 0.001735
Validation Loss: 0.00176126
Epoch [10/300], Train Loss: 0.001725
Validation Loss: 0.00175242
Epoch [11/300], Train Loss: 0.001708
Validation Loss: 0.00171021
Epoch [12/300], Train Loss: 0.001680
Validation Loss: 0.00165660
Epoch [13/300], Train Loss: 0.001631
Validation Loss: 0.00164722
Epoch [14/300], Train Loss: 0.001608
Validation Loss: 0.00162938
Epoch [15/300], Train Loss: 0.001644
Validation Loss: 0.00162058
Epoch [16/300], Train Loss: 0.001584
Validation Loss: 0.00160275
Epoch [17/300], Train Loss: 0.001551
Validation Loss: 0.00154189
Epoch [18/300], Train Loss: 0.001531
Validation Loss: 0.00154542
Epoch [19/300], Train Loss: 0.001536
Validation Loss: 0.00153092
Epoch [20/300], Train Loss: 0.001504
Validation Loss: 0.00151863
Epoch [21/300], Train Loss: 0.001528
Validation Loss: 0.00151884
Epoch [22/300], Train Loss: 0.001492
Validation Loss: 0.00151147
Epoch [23/300], Train Loss: 0.001464
Validation Loss: 0.00150853
Epoch [24/300], Train Loss: 0.001460
Validation Loss: 0.00143505
Epoch [25/300], Train Loss: 0.001436
Validation Loss: 0.00141677
Epoch [26/300], Train Loss: 0.001379
Validation Loss: 0.00138203
Epoch [27/300], Train Loss: 0.001342
Validation Loss: 0.00131662
Epoch [28/300], Train Loss: 0.001283
Validation Loss: 0.00138164
Epoch [29/300], Train Loss: 0.001057
Validation Loss: 0.00100587
Epoch [30/300], Train Loss: 0.000932
Validation Loss: 0.00083015
Epoch [31/300], Train Loss: 0.000852
Validation Loss: 0.00083269
Epoch [32/300], Train Loss: 0.000831
Validation Loss: 0.00080411
Epoch [33/300], Train Loss: 0.000800
Validation Loss: 0.00080162
Epoch [34/300], Train Loss: 0.000803
Validation Loss: 0.00075866
Epoch [35/300], Train Loss: 0.000783
Validation Loss: 0.00075946
Epoch [36/300], Train Loss: 0.000786
Validation Loss: 0.00075784
Epoch [37/300], Train Loss: 0.000758
Validation Loss: 0.00074456
Epoch [38/300], Train Loss: 0.001030
Validation Loss: 0.00089067
Epoch [39/300], Train Loss: 0.000816
Validation Loss: 0.00085191
Epoch [40/300], Train Loss: 0.000785
Validation Loss: 0.00082308
Epoch [41/300], Train Loss: 0.000779
Validation Loss: 0.00077951
Epoch [42/300], Train Loss: 0.000794
Validation Loss: 0.00079696
Epoch [43/300], Train Loss: 0.000778
Validation Loss: 0.00081766
Epoch [44/300], Train Loss: 0.000736
Validation Loss: 0.00074623
Epoch [45/300], Train Loss: 0.000739
Validation Loss: 0.00072033
Epoch [46/300], Train Loss: 0.000737
Validation Loss: 0.00093178
Epoch [47/300], Train Loss: 0.000744
Validation Loss: 0.00078159
Epoch [48/300], Train Loss: 0.000721
Validation Loss: 0.00079565
Epoch [49/300], Train Loss: 0.000715
Validation Loss: 0.00070789
Epoch [50/300], Train Loss: 0.000710
Validation Loss: 0.00069770
Epoch [51/300], Train Loss: 0.000720
Validation Loss: 0.00073278
Epoch [52/300], Train Loss: 0.000831
Validation Loss: 0.00075571
Epoch [53/300], Train Loss: 0.000708
Validation Loss: 0.00079196
Epoch [54/300], Train Loss: 0.000712
Validation Loss: 0.00070907
Epoch [55/300], Train Loss: 0.000704
Validation Loss: 0.00070463
Epoch [56/300], Train Loss: 0.000692
Validation Loss: 0.00074433
Epoch [57/300], Train Loss: 0.000700
Validation Loss: 0.00068212
Epoch [58/300], Train Loss: 0.000720
Validation Loss: 0.00069429
Epoch [59/300], Train Loss: 0.000701
Validation Loss: 0.00068853
Epoch [60/300], Train Loss: 0.000682
Validation Loss: 0.00068319
Epoch [61/300], Train Loss: 0.000694
Validation Loss: 0.00069573
Epoch [62/300], Train Loss: 0.000714
Validation Loss: 0.00071641
Epoch [63/300], Train Loss: 0.000709
Validation Loss: 0.00069036
Epoch [64/300], Train Loss: 0.000685
Validation Loss: 0.00070408
Epoch [65/300], Train Loss: 0.000677
Validation Loss: 0.00068820
Epoch [66/300], Train Loss: 0.000673
Validation Loss: 0.00066896
Epoch [67/300], Train Loss: 0.000665
Validation Loss: 0.00068417
Epoch [68/300], Train Loss: 0.000681
Validation Loss: 0.00067062
Epoch [69/300], Train Loss: 0.000870
Validation Loss: 0.00075516
Epoch [70/300], Train Loss: 0.000710
Validation Loss: 0.00072906
Epoch [71/300], Train Loss: 0.000686
Validation Loss: 0.00070885
Epoch [72/300], Train Loss: 0.000683
Validation Loss: 0.00068814
Epoch [73/300], Train Loss: 0.000678
Validation Loss: 0.00070307
Epoch [74/300], Train Loss: 0.000666
Validation Loss: 0.00067060
Epoch [75/300], Train Loss: 0.000659
Validation Loss: 0.00067989
Epoch [76/300], Train Loss: 0.000673
Validation Loss: 0.00067928
Early stopping triggered

Evaluating model for: Freezer
Run 52/72 completed in 1754.29 seconds with: {'MAE': np.float32(24.05174), 'MSE': np.float32(1065.9617), 'RMSE': np.float32(32.649067), 'SAE': np.float32(0.056859978), 'NDE': np.float32(0.24757859)}

Run 53/72: hidden=512, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Freezer
Dataset length: 7026 windows

Epoch [1/300], Train Loss: 0.005950
Validation Loss: 0.00568659
Epoch [2/300], Train Loss: 0.005488
Validation Loss: 0.00470242
Epoch [3/300], Train Loss: 0.003653
Validation Loss: 0.00312014
Epoch [4/300], Train Loss: 0.002760
Validation Loss: 0.00268121
Epoch [5/300], Train Loss: 0.002495
Validation Loss: 0.00235298
Epoch [6/300], Train Loss: 0.002214
Validation Loss: 0.00219812
Epoch [7/300], Train Loss: 0.002130
Validation Loss: 0.00204472
Epoch [8/300], Train Loss: 0.002005
Validation Loss: 0.00199055
Epoch [9/300], Train Loss: 0.001964
Validation Loss: 0.00191102
Epoch [10/300], Train Loss: 0.001913
Validation Loss: 0.00187240
Epoch [11/300], Train Loss: 0.001885
Validation Loss: 0.00187948
Epoch [12/300], Train Loss: 0.001870
Validation Loss: 0.00186675
Epoch [13/300], Train Loss: 0.001870
Validation Loss: 0.00185274
Epoch [14/300], Train Loss: 0.001813
Validation Loss: 0.00180130
Epoch [15/300], Train Loss: 0.001807
Validation Loss: 0.00180923
Epoch [16/300], Train Loss: 0.001790
Validation Loss: 0.00175852
Epoch [17/300], Train Loss: 0.001764
Validation Loss: 0.00172773
Epoch [18/300], Train Loss: 0.001745
Validation Loss: 0.00169973
Epoch [19/300], Train Loss: 0.001733
Validation Loss: 0.00169199
Epoch [20/300], Train Loss: 0.001720
Validation Loss: 0.00170108
Epoch [21/300], Train Loss: 0.001721
Validation Loss: 0.00168257
Epoch [22/300], Train Loss: 0.001696
Validation Loss: 0.00166676
Epoch [23/300], Train Loss: 0.001710
Validation Loss: 0.00165692
Epoch [24/300], Train Loss: 0.001683
Validation Loss: 0.00163990
Epoch [25/300], Train Loss: 0.001680
Validation Loss: 0.00164326
Epoch [26/300], Train Loss: 0.001658
Validation Loss: 0.00164492
Epoch [27/300], Train Loss: 0.001655
Validation Loss: 0.00161781
Epoch [28/300], Train Loss: 0.001659
Validation Loss: 0.00169313
Epoch [29/300], Train Loss: 0.001630
Validation Loss: 0.00163381
Epoch [30/300], Train Loss: 0.001650
Validation Loss: 0.00160313
Epoch [31/300], Train Loss: 0.001632
Validation Loss: 0.00159923
Epoch [32/300], Train Loss: 0.001624
Validation Loss: 0.00160363
Epoch [33/300], Train Loss: 0.001622
Validation Loss: 0.00158176
Epoch [34/300], Train Loss: 0.001600
Validation Loss: 0.00156564
Epoch [35/300], Train Loss: 0.001583
Validation Loss: 0.00157588
Epoch [36/300], Train Loss: 0.001579
Validation Loss: 0.00155709
Epoch [37/300], Train Loss: 0.001579
Validation Loss: 0.00156510
Epoch [38/300], Train Loss: 0.001578
Validation Loss: 0.00159279
Epoch [39/300], Train Loss: 0.001557
Validation Loss: 0.00152381
Epoch [40/300], Train Loss: 0.001532
Validation Loss: 0.00150769
Epoch [41/300], Train Loss: 0.001525
Validation Loss: 0.00153850
Epoch [42/300], Train Loss: 0.001531
Validation Loss: 0.00157510
Epoch [43/300], Train Loss: 0.001533
Validation Loss: 0.00149254
Epoch [44/300], Train Loss: 0.001496
Validation Loss: 0.00146784
Epoch [45/300], Train Loss: 0.001486
Validation Loss: 0.00146504
Epoch [46/300], Train Loss: 0.001477
Validation Loss: 0.00146640
Epoch [47/300], Train Loss: 0.001455
Validation Loss: 0.00142991
Epoch [48/300], Train Loss: 0.001446
Validation Loss: 0.00141855
Epoch [49/300], Train Loss: 0.001457
Validation Loss: 0.00140767
Epoch [50/300], Train Loss: 0.001408
Validation Loss: 0.00137179
Epoch [51/300], Train Loss: 0.001388
Validation Loss: 0.00139599
Epoch [52/300], Train Loss: 0.001367
Validation Loss: 0.00133662
Epoch [53/300], Train Loss: 0.001332
Validation Loss: 0.00130919
Epoch [54/300], Train Loss: 0.001288
Validation Loss: 0.00118727
Epoch [55/300], Train Loss: 0.001222
Validation Loss: 0.00113551
Epoch [56/300], Train Loss: 0.001144
Validation Loss: 0.00101773
Epoch [57/300], Train Loss: 0.001110
Validation Loss: 0.00101067
Epoch [58/300], Train Loss: 0.001078
Validation Loss: 0.00097334
Epoch [59/300], Train Loss: 0.001051
Validation Loss: 0.00093030
Epoch [60/300], Train Loss: 0.001018
Validation Loss: 0.00091502
Epoch [61/300], Train Loss: 0.001008
Validation Loss: 0.00090272
Epoch [62/300], Train Loss: 0.001022
Validation Loss: 0.00091675
Epoch [63/300], Train Loss: 0.000988
Validation Loss: 0.00090669
Epoch [64/300], Train Loss: 0.000985
Validation Loss: 0.00088177
Epoch [65/300], Train Loss: 0.000977
Validation Loss: 0.00087738
Epoch [66/300], Train Loss: 0.000971
Validation Loss: 0.00091888
Epoch [67/300], Train Loss: 0.000996
Validation Loss: 0.00087209
Epoch [68/300], Train Loss: 0.000959
Validation Loss: 0.00087332
Epoch [69/300], Train Loss: 0.000961
Validation Loss: 0.00086523
Epoch [70/300], Train Loss: 0.000960
Validation Loss: 0.00086097
Epoch [71/300], Train Loss: 0.000960
Validation Loss: 0.00086853
Epoch [72/300], Train Loss: 0.000942
Validation Loss: 0.00086892
Epoch [73/300], Train Loss: 0.000937
Validation Loss: 0.00086667
Epoch [74/300], Train Loss: 0.000942
Validation Loss: 0.00084017
Epoch [75/300], Train Loss: 0.000926
Validation Loss: 0.00087210
Epoch [76/300], Train Loss: 0.000923
Validation Loss: 0.00084639
Epoch [77/300], Train Loss: 0.000925
Validation Loss: 0.00082785
Epoch [78/300], Train Loss: 0.000924
Validation Loss: 0.00086150
Epoch [79/300], Train Loss: 0.000914
Validation Loss: 0.00083728
Epoch [80/300], Train Loss: 0.000929
Validation Loss: 0.00083175
Epoch [81/300], Train Loss: 0.000905
Validation Loss: 0.00086365
Epoch [82/300], Train Loss: 0.000919
Validation Loss: 0.00082765
Epoch [83/300], Train Loss: 0.000903
Validation Loss: 0.00084015
Epoch [84/300], Train Loss: 0.000905
Validation Loss: 0.00087598
Epoch [85/300], Train Loss: 0.000900
Validation Loss: 0.00082384
Epoch [86/300], Train Loss: 0.000894
Validation Loss: 0.00080878
Epoch [87/300], Train Loss: 0.000892
Validation Loss: 0.00080308
Epoch [88/300], Train Loss: 0.000903
Validation Loss: 0.00080304
Epoch [89/300], Train Loss: 0.000899
Validation Loss: 0.00082040
Epoch [90/300], Train Loss: 0.000893
Validation Loss: 0.00082292
Epoch [91/300], Train Loss: 0.000879
Validation Loss: 0.00078982
Epoch [92/300], Train Loss: 0.000875
Validation Loss: 0.00080066
Epoch [93/300], Train Loss: 0.000886
Validation Loss: 0.00082242
Epoch [94/300], Train Loss: 0.000886
Validation Loss: 0.00080962
Epoch [95/300], Train Loss: 0.000884
Validation Loss: 0.00079630
Epoch [96/300], Train Loss: 0.000884
Validation Loss: 0.00080229
Epoch [97/300], Train Loss: 0.000895
Validation Loss: 0.00080561
Epoch [98/300], Train Loss: 0.000873
Validation Loss: 0.00080776
Epoch [99/300], Train Loss: 0.000864
Validation Loss: 0.00079939
Epoch [100/300], Train Loss: 0.000858
Validation Loss: 0.00078730
Epoch [101/300], Train Loss: 0.000863
Validation Loss: 0.00078390
Epoch [102/300], Train Loss: 0.000862
Validation Loss: 0.00080680
Epoch [103/300], Train Loss: 0.000875
Validation Loss: 0.00083252
Epoch [104/300], Train Loss: 0.000851
Validation Loss: 0.00078491
Epoch [105/300], Train Loss: 0.000844
Validation Loss: 0.00077850
Epoch [106/300], Train Loss: 0.000888
Validation Loss: 0.00080475
Epoch [107/300], Train Loss: 0.000850
Validation Loss: 0.00078604
Epoch [108/300], Train Loss: 0.000841
Validation Loss: 0.00078045
Epoch [109/300], Train Loss: 0.000833
Validation Loss: 0.00077324
Epoch [110/300], Train Loss: 0.000841
Validation Loss: 0.00078102
Epoch [111/300], Train Loss: 0.000838
Validation Loss: 0.00079597
Epoch [112/300], Train Loss: 0.000846
Validation Loss: 0.00077291
Epoch [113/300], Train Loss: 0.000843
Validation Loss: 0.00082895
Epoch [114/300], Train Loss: 0.000840
Validation Loss: 0.00081034
Epoch [115/300], Train Loss: 0.000844
Validation Loss: 0.00077438
Epoch [116/300], Train Loss: 0.000838
Validation Loss: 0.00077434
Epoch [117/300], Train Loss: 0.000832
Validation Loss: 0.00081295
Epoch [118/300], Train Loss: 0.000828
Validation Loss: 0.00076685
Epoch [119/300], Train Loss: 0.000826
Validation Loss: 0.00078800
Epoch [120/300], Train Loss: 0.000844
Validation Loss: 0.00077714
Epoch [121/300], Train Loss: 0.000822
Validation Loss: 0.00082226
Epoch [122/300], Train Loss: 0.000818
Validation Loss: 0.00076470
Epoch [123/300], Train Loss: 0.000816
Validation Loss: 0.00075986
Epoch [124/300], Train Loss: 0.000819
Validation Loss: 0.00078968
Epoch [125/300], Train Loss: 0.000826
Validation Loss: 0.00076211
Epoch [126/300], Train Loss: 0.000815
Validation Loss: 0.00075953
Epoch [127/300], Train Loss: 0.000810
Validation Loss: 0.00076958
Epoch [128/300], Train Loss: 0.000811
Validation Loss: 0.00075985
Epoch [129/300], Train Loss: 0.000811
Validation Loss: 0.00075755
Epoch [130/300], Train Loss: 0.000802
Validation Loss: 0.00076094
Epoch [131/300], Train Loss: 0.000807
Validation Loss: 0.00075603
Epoch [132/300], Train Loss: 0.000794
Validation Loss: 0.00075305
Epoch [133/300], Train Loss: 0.000804
Validation Loss: 0.00075423
Epoch [134/300], Train Loss: 0.000802
Validation Loss: 0.00074652
Epoch [135/300], Train Loss: 0.000795
Validation Loss: 0.00075875
Epoch [136/300], Train Loss: 0.000795
Validation Loss: 0.00074428
Epoch [137/300], Train Loss: 0.000793
Validation Loss: 0.00075445
Epoch [138/300], Train Loss: 0.000801
Validation Loss: 0.00074321
Epoch [139/300], Train Loss: 0.000797
Validation Loss: 0.00075064
Epoch [140/300], Train Loss: 0.000792
Validation Loss: 0.00074808
Epoch [141/300], Train Loss: 0.000787
Validation Loss: 0.00074723
Epoch [142/300], Train Loss: 0.000797
Validation Loss: 0.00077620
Epoch [143/300], Train Loss: 0.000789
Validation Loss: 0.00075687
Epoch [144/300], Train Loss: 0.000788
Validation Loss: 0.00073860
Epoch [145/300], Train Loss: 0.000784
Validation Loss: 0.00075496
Epoch [146/300], Train Loss: 0.000780
Validation Loss: 0.00073871
Epoch [147/300], Train Loss: 0.000776
Validation Loss: 0.00074462
Epoch [148/300], Train Loss: 0.000784
Validation Loss: 0.00073977
Epoch [149/300], Train Loss: 0.000786
Validation Loss: 0.00073539
Epoch [150/300], Train Loss: 0.000773
Validation Loss: 0.00075294
Epoch [151/300], Train Loss: 0.000790
Validation Loss: 0.00074223
Epoch [152/300], Train Loss: 0.000778
Validation Loss: 0.00074546
Epoch [153/300], Train Loss: 0.000780
Validation Loss: 0.00075691
Epoch [154/300], Train Loss: 0.000783
Validation Loss: 0.00074352
Epoch [155/300], Train Loss: 0.000772
Validation Loss: 0.00075741
Epoch [156/300], Train Loss: 0.000765
Validation Loss: 0.00073212
Epoch [157/300], Train Loss: 0.000772
Validation Loss: 0.00073905
Epoch [158/300], Train Loss: 0.000768
Validation Loss: 0.00073624
Epoch [159/300], Train Loss: 0.000776
Validation Loss: 0.00075439
Epoch [160/300], Train Loss: 0.000769
Validation Loss: 0.00072882
Epoch [161/300], Train Loss: 0.000768
Validation Loss: 0.00075803
Epoch [162/300], Train Loss: 0.000769
Validation Loss: 0.00072318
Epoch [163/300], Train Loss: 0.000767
Validation Loss: 0.00074935
Epoch [164/300], Train Loss: 0.000762
Validation Loss: 0.00073209
Epoch [165/300], Train Loss: 0.000761
Validation Loss: 0.00073991
Epoch [166/300], Train Loss: 0.000754
Validation Loss: 0.00073154
Epoch [167/300], Train Loss: 0.000762
Validation Loss: 0.00074811
Epoch [168/300], Train Loss: 0.000755
Validation Loss: 0.00074086
Epoch [169/300], Train Loss: 0.000790
Validation Loss: 0.00073099
Epoch [170/300], Train Loss: 0.000754
Validation Loss: 0.00074471
Epoch [171/300], Train Loss: 0.000750
Validation Loss: 0.00071863
Epoch [172/300], Train Loss: 0.000757
Validation Loss: 0.00073584
Epoch [173/300], Train Loss: 0.000756
Validation Loss: 0.00071479
Epoch [174/300], Train Loss: 0.000745
Validation Loss: 0.00071422
Epoch [175/300], Train Loss: 0.000748
Validation Loss: 0.00072868
Epoch [176/300], Train Loss: 0.000742
Validation Loss: 0.00072428
Epoch [177/300], Train Loss: 0.000747
Validation Loss: 0.00071965
Epoch [178/300], Train Loss: 0.000741
Validation Loss: 0.00071759
Epoch [179/300], Train Loss: 0.000748
Validation Loss: 0.00073950
Epoch [180/300], Train Loss: 0.000749
Validation Loss: 0.00071925
Epoch [181/300], Train Loss: 0.000735
Validation Loss: 0.00070866
Epoch [182/300], Train Loss: 0.000741
Validation Loss: 0.00072035
Epoch [183/300], Train Loss: 0.000736
Validation Loss: 0.00073378
Epoch [184/300], Train Loss: 0.000738
Validation Loss: 0.00071219
Epoch [185/300], Train Loss: 0.000735
Validation Loss: 0.00071107
Epoch [186/300], Train Loss: 0.000731
Validation Loss: 0.00070777
Epoch [187/300], Train Loss: 0.000735
Validation Loss: 0.00071127
Epoch [188/300], Train Loss: 0.000729
Validation Loss: 0.00072989
Epoch [189/300], Train Loss: 0.000732
Validation Loss: 0.00071857
Epoch [190/300], Train Loss: 0.000739
Validation Loss: 0.00073358
Epoch [191/300], Train Loss: 0.000737
Validation Loss: 0.00072327
Epoch [192/300], Train Loss: 0.000726
Validation Loss: 0.00070352
Epoch [193/300], Train Loss: 0.000731
Validation Loss: 0.00071138
Epoch [194/300], Train Loss: 0.000751
Validation Loss: 0.00070434
Epoch [195/300], Train Loss: 0.000727
Validation Loss: 0.00070659
Epoch [196/300], Train Loss: 0.000730
Validation Loss: 0.00073743
Epoch [197/300], Train Loss: 0.000725
Validation Loss: 0.00069940
Epoch [198/300], Train Loss: 0.000719
Validation Loss: 0.00070708
Epoch [199/300], Train Loss: 0.000722
Validation Loss: 0.00076477
Epoch [200/300], Train Loss: 0.000735
Validation Loss: 0.00070462
Epoch [201/300], Train Loss: 0.000719
Validation Loss: 0.00076002
Epoch [202/300], Train Loss: 0.000726
Validation Loss: 0.00069438
Epoch [203/300], Train Loss: 0.000720
Validation Loss: 0.00070412
Epoch [204/300], Train Loss: 0.000717
Validation Loss: 0.00070237
Epoch [205/300], Train Loss: 0.000713
Validation Loss: 0.00072073
Epoch [206/300], Train Loss: 0.000721
Validation Loss: 0.00071938
Epoch [207/300], Train Loss: 0.000723
Validation Loss: 0.00069715
Epoch [208/300], Train Loss: 0.000713
Validation Loss: 0.00071141
Epoch [209/300], Train Loss: 0.000707
Validation Loss: 0.00069546
Epoch [210/300], Train Loss: 0.000710
Validation Loss: 0.00069192
Epoch [211/300], Train Loss: 0.000709
Validation Loss: 0.00069558
Epoch [212/300], Train Loss: 0.000709
Validation Loss: 0.00069309
Epoch [213/300], Train Loss: 0.000771
Validation Loss: 0.00071885
Epoch [214/300], Train Loss: 0.000721
Validation Loss: 0.00070209
Epoch [215/300], Train Loss: 0.000707
Validation Loss: 0.00070590
Epoch [216/300], Train Loss: 0.000710
Validation Loss: 0.00072746
Epoch [217/300], Train Loss: 0.000707
Validation Loss: 0.00069593
Epoch [218/300], Train Loss: 0.000715
Validation Loss: 0.00074692
Epoch [219/300], Train Loss: 0.000705
Validation Loss: 0.00069570
Epoch [220/300], Train Loss: 0.000705
Validation Loss: 0.00070745
Early stopping triggered

Evaluating model for: Freezer
Run 53/72 completed in 1787.92 seconds with: {'MAE': np.float32(22.685629), 'MSE': np.float32(1042.2684), 'RMSE': np.float32(32.284184), 'SAE': np.float32(0.008737452), 'NDE': np.float32(0.2499707)}

Run 54/72: hidden=512, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Freezer
Dataset length: 7026 windows

Epoch [1/300], Train Loss: 0.006175
Validation Loss: 0.00576284
Epoch [2/300], Train Loss: 0.005539
Validation Loss: 0.00416960
Epoch [3/300], Train Loss: 0.003243
Validation Loss: 0.00270429
Epoch [4/300], Train Loss: 0.002508
Validation Loss: 0.00245566
Epoch [5/300], Train Loss: 0.002369
Validation Loss: 0.00238245
Epoch [6/300], Train Loss: 0.002150
Validation Loss: 0.00217686
Epoch [7/300], Train Loss: 0.002082
Validation Loss: 0.00201803
Epoch [8/300], Train Loss: 0.001967
Validation Loss: 0.00197969
Epoch [9/300], Train Loss: 0.001921
Validation Loss: 0.00188820
Epoch [10/300], Train Loss: 0.001880
Validation Loss: 0.00185179
Epoch [11/300], Train Loss: 0.001862
Validation Loss: 0.00186444
Epoch [12/300], Train Loss: 0.001860
Validation Loss: 0.00181861
Epoch [13/300], Train Loss: 0.001828
Validation Loss: 0.00180118
Epoch [14/300], Train Loss: 0.001809
Validation Loss: 0.00181285
Epoch [15/300], Train Loss: 0.001824
Validation Loss: 0.00191402
Epoch [16/300], Train Loss: 0.001803
Validation Loss: 0.00183149
Epoch [17/300], Train Loss: 0.001785
Validation Loss: 0.00177731
Epoch [18/300], Train Loss: 0.001782
Validation Loss: 0.00181757
Epoch [19/300], Train Loss: 0.001760
Validation Loss: 0.00174651
Epoch [20/300], Train Loss: 0.001755
Validation Loss: 0.00175133
Epoch [21/300], Train Loss: 0.001768
Validation Loss: 0.00175158
Epoch [22/300], Train Loss: 0.001732
Validation Loss: 0.00170996
Epoch [23/300], Train Loss: 0.001733
Validation Loss: 0.00172101
Epoch [24/300], Train Loss: 0.001727
Validation Loss: 0.00170778
Epoch [25/300], Train Loss: 0.001723
Validation Loss: 0.00171719
Epoch [26/300], Train Loss: 0.001707
Validation Loss: 0.00171415
Epoch [27/300], Train Loss: 0.001709
Validation Loss: 0.00167825
Epoch [28/300], Train Loss: 0.001716
Validation Loss: 0.00166948
Epoch [29/300], Train Loss: 0.001695
Validation Loss: 0.00168786
Epoch [30/300], Train Loss: 0.001689
Validation Loss: 0.00166801
Epoch [31/300], Train Loss: 0.001675
Validation Loss: 0.00169552
Epoch [32/300], Train Loss: 0.001673
Validation Loss: 0.00164608
Epoch [33/300], Train Loss: 0.001670
Validation Loss: 0.00162972
Epoch [34/300], Train Loss: 0.001635
Validation Loss: 0.00163532
Epoch [35/300], Train Loss: 0.001630
Validation Loss: 0.00163077
Epoch [36/300], Train Loss: 0.001620
Validation Loss: 0.00163773
Epoch [37/300], Train Loss: 0.001626
Validation Loss: 0.00163801
Epoch [38/300], Train Loss: 0.001620
Validation Loss: 0.00162182
Epoch [39/300], Train Loss: 0.001608
Validation Loss: 0.00163825
Epoch [40/300], Train Loss: 0.001588
Validation Loss: 0.00161549
Epoch [41/300], Train Loss: 0.001579
Validation Loss: 0.00159428
Epoch [42/300], Train Loss: 0.001594
Validation Loss: 0.00166130
Epoch [43/300], Train Loss: 0.001610
Validation Loss: 0.00163684
Epoch [44/300], Train Loss: 0.001578
Validation Loss: 0.00160234
Epoch [45/300], Train Loss: 0.001564
Validation Loss: 0.00159011
Epoch [46/300], Train Loss: 0.001559
Validation Loss: 0.00159886
Epoch [47/300], Train Loss: 0.001562
Validation Loss: 0.00159218
Epoch [48/300], Train Loss: 0.001554
Validation Loss: 0.00158043
Epoch [49/300], Train Loss: 0.001567
Validation Loss: 0.00162024
Epoch [50/300], Train Loss: 0.001558
Validation Loss: 0.00158260
Epoch [51/300], Train Loss: 0.001547
Validation Loss: 0.00160338
Epoch [52/300], Train Loss: 0.001546
Validation Loss: 0.00160445
Epoch [53/300], Train Loss: 0.001551
Validation Loss: 0.00156232
Epoch [54/300], Train Loss: 0.001546
Validation Loss: 0.00160887
Epoch [55/300], Train Loss: 0.001526
Validation Loss: 0.00157362
Epoch [56/300], Train Loss: 0.001516
Validation Loss: 0.00154512
Epoch [57/300], Train Loss: 0.001522
Validation Loss: 0.00156669
Epoch [58/300], Train Loss: 0.001515
Validation Loss: 0.00158197
Epoch [59/300], Train Loss: 0.001532
Validation Loss: 0.00155742
Epoch [60/300], Train Loss: 0.001516
Validation Loss: 0.00155132
Epoch [61/300], Train Loss: 0.001506
Validation Loss: 0.00156317
Epoch [62/300], Train Loss: 0.001518
Validation Loss: 0.00155944
Epoch [63/300], Train Loss: 0.001502
Validation Loss: 0.00154582
Epoch [64/300], Train Loss: 0.001508
Validation Loss: 0.00154760
Epoch [65/300], Train Loss: 0.001494
Validation Loss: 0.00153288
Epoch [66/300], Train Loss: 0.001517
Validation Loss: 0.00155093
Epoch [67/300], Train Loss: 0.001506
Validation Loss: 0.00152784
Epoch [68/300], Train Loss: 0.001480
Validation Loss: 0.00179514
Epoch [69/300], Train Loss: 0.001521
Validation Loss: 0.00153215
Epoch [70/300], Train Loss: 0.001492
Validation Loss: 0.00152717
Epoch [71/300], Train Loss: 0.001484
Validation Loss: 0.00155395
Epoch [72/300], Train Loss: 0.001481
Validation Loss: 0.00154818
Epoch [73/300], Train Loss: 0.001487
Validation Loss: 0.00154449
Epoch [74/300], Train Loss: 0.001474
Validation Loss: 0.00152500
Epoch [75/300], Train Loss: 0.001478
Validation Loss: 0.00152159
Epoch [76/300], Train Loss: 0.001469
Validation Loss: 0.00152327
Epoch [77/300], Train Loss: 0.001476
Validation Loss: 0.00151225
Epoch [78/300], Train Loss: 0.001449
Validation Loss: 0.00151621
Epoch [79/300], Train Loss: 0.001451
Validation Loss: 0.00152749
Epoch [80/300], Train Loss: 0.001452
Validation Loss: 0.00148979
Epoch [81/300], Train Loss: 0.001453
Validation Loss: 0.00149767
Epoch [82/300], Train Loss: 0.001447
Validation Loss: 0.00148094
Epoch [83/300], Train Loss: 0.001437
Validation Loss: 0.00150208
Epoch [84/300], Train Loss: 0.001449
Validation Loss: 0.00151673
Epoch [85/300], Train Loss: 0.001433
Validation Loss: 0.00149485
Epoch [86/300], Train Loss: 0.001426
Validation Loss: 0.00149054
Epoch [87/300], Train Loss: 0.001421
Validation Loss: 0.00145756
Epoch [88/300], Train Loss: 0.001459
Validation Loss: 0.00148917
Epoch [89/300], Train Loss: 0.001426
Validation Loss: 0.00145941
Epoch [90/300], Train Loss: 0.001402
Validation Loss: 0.00145151
Epoch [91/300], Train Loss: 0.001389
Validation Loss: 0.00144866
Epoch [92/300], Train Loss: 0.001402
Validation Loss: 0.00148484
Epoch [93/300], Train Loss: 0.001374
Validation Loss: 0.00139576
Epoch [94/300], Train Loss: 0.001358
Validation Loss: 0.00139441
Epoch [95/300], Train Loss: 0.001347
Validation Loss: 0.00137812
Epoch [96/300], Train Loss: 0.001320
Validation Loss: 0.00132858
Epoch [97/300], Train Loss: 0.001295
Validation Loss: 0.00130040
Epoch [98/300], Train Loss: 0.001262
Validation Loss: 0.00127179
Epoch [99/300], Train Loss: 0.001207
Validation Loss: 0.00118269
Epoch [100/300], Train Loss: 0.001145
Validation Loss: 0.00110134
Epoch [101/300], Train Loss: 0.001071
Validation Loss: 0.00101927
Epoch [102/300], Train Loss: 0.001033
Validation Loss: 0.00096191
Epoch [103/300], Train Loss: 0.000989
Validation Loss: 0.00091731
Epoch [104/300], Train Loss: 0.000945
Validation Loss: 0.00089347
Epoch [105/300], Train Loss: 0.000938
Validation Loss: 0.00085270
Epoch [106/300], Train Loss: 0.000900
Validation Loss: 0.00085738
Epoch [107/300], Train Loss: 0.000900
Validation Loss: 0.00085373
Epoch [108/300], Train Loss: 0.000882
Validation Loss: 0.00085890
Epoch [109/300], Train Loss: 0.000869
Validation Loss: 0.00083261
Epoch [110/300], Train Loss: 0.000865
Validation Loss: 0.00082220
Epoch [111/300], Train Loss: 0.000860
Validation Loss: 0.00079406
Epoch [112/300], Train Loss: 0.000857
Validation Loss: 0.00079663
Epoch [113/300], Train Loss: 0.000853
Validation Loss: 0.00082126
Epoch [114/300], Train Loss: 0.000841
Validation Loss: 0.00082612
Epoch [115/300], Train Loss: 0.000834
Validation Loss: 0.00082026
Epoch [116/300], Train Loss: 0.000827
Validation Loss: 0.00080226
Epoch [117/300], Train Loss: 0.000823
Validation Loss: 0.00081332
Epoch [118/300], Train Loss: 0.000824
Validation Loss: 0.00076659
Epoch [119/300], Train Loss: 0.000811
Validation Loss: 0.00076665
Epoch [120/300], Train Loss: 0.000810
Validation Loss: 0.00076452
Epoch [121/300], Train Loss: 0.000798
Validation Loss: 0.00078974
Epoch [122/300], Train Loss: 0.000809
Validation Loss: 0.00077732
Epoch [123/300], Train Loss: 0.000793
Validation Loss: 0.00076648
Epoch [124/300], Train Loss: 0.000792
Validation Loss: 0.00074706
Epoch [125/300], Train Loss: 0.000789
Validation Loss: 0.00075058
Epoch [126/300], Train Loss: 0.000782
Validation Loss: 0.00074665
Epoch [127/300], Train Loss: 0.000787
Validation Loss: 0.00074503
Epoch [128/300], Train Loss: 0.000790
Validation Loss: 0.00075296
Epoch [129/300], Train Loss: 0.000779
Validation Loss: 0.00072918
Epoch [130/300], Train Loss: 0.000773
Validation Loss: 0.00074666
Epoch [131/300], Train Loss: 0.000785
Validation Loss: 0.00073860
Epoch [132/300], Train Loss: 0.000775
Validation Loss: 0.00073974
Epoch [133/300], Train Loss: 0.000766
Validation Loss: 0.00073506
Epoch [134/300], Train Loss: 0.000765
Validation Loss: 0.00072973
Epoch [135/300], Train Loss: 0.000760
Validation Loss: 0.00074909
Epoch [136/300], Train Loss: 0.000757
Validation Loss: 0.00072239
Epoch [137/300], Train Loss: 0.000759
Validation Loss: 0.00073528
Epoch [138/300], Train Loss: 0.000757
Validation Loss: 0.00072269
Epoch [139/300], Train Loss: 0.000754
Validation Loss: 0.00072766
Epoch [140/300], Train Loss: 0.000754
Validation Loss: 0.00072705
Epoch [141/300], Train Loss: 0.000747
Validation Loss: 0.00075926
Epoch [142/300], Train Loss: 0.000752
Validation Loss: 0.00072960
Epoch [143/300], Train Loss: 0.000749
Validation Loss: 0.00074991
Epoch [144/300], Train Loss: 0.000762
Validation Loss: 0.00071045
Epoch [145/300], Train Loss: 0.000749
Validation Loss: 0.00073949
Epoch [146/300], Train Loss: 0.000747
Validation Loss: 0.00073098
Epoch [147/300], Train Loss: 0.000758
Validation Loss: 0.00074463
Epoch [148/300], Train Loss: 0.000741
Validation Loss: 0.00073118
Epoch [149/300], Train Loss: 0.000733
Validation Loss: 0.00072180
Epoch [150/300], Train Loss: 0.000738
Validation Loss: 0.00074311
Epoch [151/300], Train Loss: 0.000744
Validation Loss: 0.00071967
Epoch [152/300], Train Loss: 0.000736
Validation Loss: 0.00071218
Epoch [153/300], Train Loss: 0.000734
Validation Loss: 0.00071400
Epoch [154/300], Train Loss: 0.000733
Validation Loss: 0.00071949
Early stopping triggered

Evaluating model for: Freezer
Run 54/72 completed in 1380.69 seconds with: {'MAE': np.float32(23.42184), 'MSE': np.float32(1035.3864), 'RMSE': np.float32(32.17742), 'SAE': np.float32(0.0054556094), 'NDE': np.float32(0.24914406)}

Run 55/72: hidden=512, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Freezer
Dataset length: 7026 windows

Epoch [1/300], Train Loss: 0.006090
Validation Loss: 0.00579464
Epoch [2/300], Train Loss: 0.005906
Validation Loss: 0.00580972
Epoch [3/300], Train Loss: 0.004793
Validation Loss: 0.00315678
Epoch [4/300], Train Loss: 0.002843
Validation Loss: 0.00278245
Epoch [5/300], Train Loss: 0.002642
Validation Loss: 0.00283827
Epoch [6/300], Train Loss: 0.002539
Validation Loss: 0.00267809
Epoch [7/300], Train Loss: 0.002457
Validation Loss: 0.00257647
Epoch [8/300], Train Loss: 0.002281
Validation Loss: 0.00229334
Epoch [9/300], Train Loss: 0.002053
Validation Loss: 0.00191432
Epoch [10/300], Train Loss: 0.001913
Validation Loss: 0.00183635
Epoch [11/300], Train Loss: 0.001838
Validation Loss: 0.00181556
Epoch [12/300], Train Loss: 0.001835
Validation Loss: 0.00189396
Epoch [13/300], Train Loss: 0.001836
Validation Loss: 0.00183118
Epoch [14/300], Train Loss: 0.001787
Validation Loss: 0.00179800
Epoch [15/300], Train Loss: 0.001803
Validation Loss: 0.00185503
Epoch [16/300], Train Loss: 0.001780
Validation Loss: 0.00175047
Epoch [17/300], Train Loss: 0.001744
Validation Loss: 0.00175293
Epoch [18/300], Train Loss: 0.001735
Validation Loss: 0.00171642
Epoch [19/300], Train Loss: 0.001718
Validation Loss: 0.00170445
Epoch [20/300], Train Loss: 0.001714
Validation Loss: 0.00171804
Epoch [21/300], Train Loss: 0.001720
Validation Loss: 0.00170256
Epoch [22/300], Train Loss: 0.001695
Validation Loss: 0.00169004
Epoch [23/300], Train Loss: 0.001701
Validation Loss: 0.00170921
Epoch [24/300], Train Loss: 0.001686
Validation Loss: 0.00166584
Epoch [25/300], Train Loss: 0.001676
Validation Loss: 0.00165869
Epoch [26/300], Train Loss: 0.001652
Validation Loss: 0.00165297
Epoch [27/300], Train Loss: 0.001650
Validation Loss: 0.00165624
Epoch [28/300], Train Loss: 0.001630
Validation Loss: 0.00166156
Epoch [29/300], Train Loss: 0.001598
Validation Loss: 0.00165969
Epoch [30/300], Train Loss: 0.001621
Validation Loss: 0.00166356
Epoch [31/300], Train Loss: 0.001615
Validation Loss: 0.00160394
Epoch [32/300], Train Loss: 0.001599
Validation Loss: 0.00161720
Epoch [33/300], Train Loss: 0.001598
Validation Loss: 0.00161222
Epoch [34/300], Train Loss: 0.001573
Validation Loss: 0.00158991
Epoch [35/300], Train Loss: 0.001577
Validation Loss: 0.00163102
Epoch [36/300], Train Loss: 0.001559
Validation Loss: 0.00158028
Epoch [37/300], Train Loss: 0.001559
Validation Loss: 0.00164718
Epoch [38/300], Train Loss: 0.001580
Validation Loss: 0.00166617
Epoch [39/300], Train Loss: 0.001556
Validation Loss: 0.00158595
Epoch [40/300], Train Loss: 0.001533
Validation Loss: 0.00156289
Epoch [41/300], Train Loss: 0.001528
Validation Loss: 0.00158392
Epoch [42/300], Train Loss: 0.001546
Validation Loss: 0.00161064
Epoch [43/300], Train Loss: 0.001548
Validation Loss: 0.00156778
Epoch [44/300], Train Loss: 0.001529
Validation Loss: 0.00156495
Epoch [45/300], Train Loss: 0.001527
Validation Loss: 0.00154152
Epoch [46/300], Train Loss: 0.001523
Validation Loss: 0.00155418
Epoch [47/300], Train Loss: 0.001512
Validation Loss: 0.00154628
Epoch [48/300], Train Loss: 0.001506
Validation Loss: 0.00154299
Epoch [49/300], Train Loss: 0.001525
Validation Loss: 0.00155069
Epoch [50/300], Train Loss: 0.001500
Validation Loss: 0.00156460
Epoch [51/300], Train Loss: 0.001505
Validation Loss: 0.00154132
Epoch [52/300], Train Loss: 0.001501
Validation Loss: 0.00155344
Epoch [53/300], Train Loss: 0.001510
Validation Loss: 0.00154786
Epoch [54/300], Train Loss: 0.001499
Validation Loss: 0.00153035
Epoch [55/300], Train Loss: 0.001492
Validation Loss: 0.00156046
Epoch [56/300], Train Loss: 0.001491
Validation Loss: 0.00152668
Epoch [57/300], Train Loss: 0.001482
Validation Loss: 0.00154978
Epoch [58/300], Train Loss: 0.001483
Validation Loss: 0.00153781
Epoch [59/300], Train Loss: 0.001494
Validation Loss: 0.00155926
Epoch [60/300], Train Loss: 0.001480
Validation Loss: 0.00151228
Epoch [61/300], Train Loss: 0.001472
Validation Loss: 0.00154008
Epoch [62/300], Train Loss: 0.001488
Validation Loss: 0.00155308
Epoch [63/300], Train Loss: 0.001472
Validation Loss: 0.00151251
Epoch [64/300], Train Loss: 0.001490
Validation Loss: 0.00151782
Epoch [65/300], Train Loss: 0.001461
Validation Loss: 0.00151606
Epoch [66/300], Train Loss: 0.001478
Validation Loss: 0.00152629
Epoch [67/300], Train Loss: 0.001469
Validation Loss: 0.00150028
Epoch [68/300], Train Loss: 0.001462
Validation Loss: 0.00155159
Epoch [69/300], Train Loss: 0.001468
Validation Loss: 0.00148873
Epoch [70/300], Train Loss: 0.001458
Validation Loss: 0.00149876
Epoch [71/300], Train Loss: 0.001459
Validation Loss: 0.00154336
Epoch [72/300], Train Loss: 0.001451
Validation Loss: 0.00150626
Epoch [73/300], Train Loss: 0.001436
Validation Loss: 0.00152968
Epoch [74/300], Train Loss: 0.001473
Validation Loss: 0.00150026
Epoch [75/300], Train Loss: 0.001444
Validation Loss: 0.00151404
Epoch [76/300], Train Loss: 0.001435
Validation Loss: 0.00150611
Epoch [77/300], Train Loss: 0.001444
Validation Loss: 0.00148451
Epoch [78/300], Train Loss: 0.001424
Validation Loss: 0.00155628
Epoch [79/300], Train Loss: 0.001431
Validation Loss: 0.00149422
Epoch [80/300], Train Loss: 0.001428
Validation Loss: 0.00154090
Epoch [81/300], Train Loss: 0.001436
Validation Loss: 0.00149899
Epoch [82/300], Train Loss: 0.001429
Validation Loss: 0.00147988
Epoch [83/300], Train Loss: 0.001414
Validation Loss: 0.00152174
Epoch [84/300], Train Loss: 0.001426
Validation Loss: 0.00149360
Epoch [85/300], Train Loss: 0.001413
Validation Loss: 0.00146151
Epoch [86/300], Train Loss: 0.001402
Validation Loss: 0.00151134
Epoch [87/300], Train Loss: 0.001405
Validation Loss: 0.00148114
Epoch [88/300], Train Loss: 0.001437
Validation Loss: 0.00152898
Epoch [89/300], Train Loss: 0.001424
Validation Loss: 0.00149114
Epoch [90/300], Train Loss: 0.001404
Validation Loss: 0.00149463
Epoch [91/300], Train Loss: 0.001411
Validation Loss: 0.00145784
Epoch [92/300], Train Loss: 0.001407
Validation Loss: 0.00150205
Epoch [93/300], Train Loss: 0.001412
Validation Loss: 0.00147072
Epoch [94/300], Train Loss: 0.001397
Validation Loss: 0.00149415
Epoch [95/300], Train Loss: 0.001402
Validation Loss: 0.00146140
Epoch [96/300], Train Loss: 0.001396
Validation Loss: 0.00147346
Epoch [97/300], Train Loss: 0.001386
Validation Loss: 0.00146266
Epoch [98/300], Train Loss: 0.001380
Validation Loss: 0.00145520
Epoch [99/300], Train Loss: 0.001384
Validation Loss: 0.00144907
Epoch [100/300], Train Loss: 0.001379
Validation Loss: 0.00144121
Epoch [101/300], Train Loss: 0.001399
Validation Loss: 0.00148191
Epoch [102/300], Train Loss: 0.001401
Validation Loss: 0.00151014
Epoch [103/300], Train Loss: 0.001399
Validation Loss: 0.00144404
Epoch [104/300], Train Loss: 0.001375
Validation Loss: 0.00145198
Epoch [105/300], Train Loss: 0.001377
Validation Loss: 0.00143293
Epoch [106/300], Train Loss: 0.001367
Validation Loss: 0.00144768
Epoch [107/300], Train Loss: 0.001370
Validation Loss: 0.00144122
Epoch [108/300], Train Loss: 0.001360
Validation Loss: 0.00145030
Epoch [109/300], Train Loss: 0.001356
Validation Loss: 0.00143180
Epoch [110/300], Train Loss: 0.001361
Validation Loss: 0.00144116
Epoch [111/300], Train Loss: 0.001359
Validation Loss: 0.00142718
Epoch [112/300], Train Loss: 0.001356
Validation Loss: 0.00140898
Epoch [113/300], Train Loss: 0.001356
Validation Loss: 0.00143817
Epoch [114/300], Train Loss: 0.001353
Validation Loss: 0.00144721
Epoch [115/300], Train Loss: 0.001357
Validation Loss: 0.00142530
Epoch [116/300], Train Loss: 0.001343
Validation Loss: 0.00141510
Epoch [117/300], Train Loss: 0.001340
Validation Loss: 0.00147152
Epoch [118/300], Train Loss: 0.001357
Validation Loss: 0.00140213
Epoch [119/300], Train Loss: 0.001348
Validation Loss: 0.00139878
Epoch [120/300], Train Loss: 0.001341
Validation Loss: 0.00139133
Epoch [121/300], Train Loss: 0.001320
Validation Loss: 0.00151235
Epoch [122/300], Train Loss: 0.001322
Validation Loss: 0.00137111
Epoch [123/300], Train Loss: 0.001297
Validation Loss: 0.00135619
Epoch [124/300], Train Loss: 0.001316
Validation Loss: 0.00142280
Epoch [125/300], Train Loss: 0.001287
Validation Loss: 0.00131003
Epoch [126/300], Train Loss: 0.001253
Validation Loss: 0.00127915
Epoch [127/300], Train Loss: 0.001228
Validation Loss: 0.00124899
Epoch [128/300], Train Loss: 0.001224
Validation Loss: 0.00118485
Epoch [129/300], Train Loss: 0.001132
Validation Loss: 0.00108883
Epoch [130/300], Train Loss: 0.001035
Validation Loss: 0.00095104
Epoch [131/300], Train Loss: 0.000973
Validation Loss: 0.00087623
Epoch [132/300], Train Loss: 0.000922
Validation Loss: 0.00085874
Epoch [133/300], Train Loss: 0.000911
Validation Loss: 0.00083477
Epoch [134/300], Train Loss: 0.000877
Validation Loss: 0.00080251
Epoch [135/300], Train Loss: 0.000865
Validation Loss: 0.00080142
Epoch [136/300], Train Loss: 0.000848
Validation Loss: 0.00077046
Epoch [137/300], Train Loss: 0.000835
Validation Loss: 0.00077916
Epoch [138/300], Train Loss: 0.000826
Validation Loss: 0.00076024
Epoch [139/300], Train Loss: 0.000840
Validation Loss: 0.00078903
Epoch [140/300], Train Loss: 0.000812
Validation Loss: 0.00074083
Epoch [141/300], Train Loss: 0.000799
Validation Loss: 0.00074821
Epoch [142/300], Train Loss: 0.000790
Validation Loss: 0.00076232
Epoch [143/300], Train Loss: 0.000797
Validation Loss: 0.00073555
Epoch [144/300], Train Loss: 0.000789
Validation Loss: 0.00072279
Epoch [145/300], Train Loss: 0.000771
Validation Loss: 0.00072504
Epoch [146/300], Train Loss: 0.000763
Validation Loss: 0.00070807
Epoch [147/300], Train Loss: 0.000760
Validation Loss: 0.00071224
Epoch [148/300], Train Loss: 0.000774
Validation Loss: 0.00070632
Epoch [149/300], Train Loss: 0.000751
Validation Loss: 0.00069879
Epoch [150/300], Train Loss: 0.000759
Validation Loss: 0.00072444
Epoch [151/300], Train Loss: 0.000765
Validation Loss: 0.00068915
Epoch [152/300], Train Loss: 0.000737
Validation Loss: 0.00069096
Epoch [153/300], Train Loss: 0.000742
Validation Loss: 0.00070090
Epoch [154/300], Train Loss: 0.000734
Validation Loss: 0.00070084
Epoch [155/300], Train Loss: 0.000732
Validation Loss: 0.00071080
Epoch [156/300], Train Loss: 0.000731
Validation Loss: 0.00069338
Epoch [157/300], Train Loss: 0.000727
Validation Loss: 0.00068336
Epoch [158/300], Train Loss: 0.000720
Validation Loss: 0.00068045
Epoch [159/300], Train Loss: 0.000723
Validation Loss: 0.00068187
Epoch [160/300], Train Loss: 0.000720
Validation Loss: 0.00066311
Epoch [161/300], Train Loss: 0.000722
Validation Loss: 0.00067095
Epoch [162/300], Train Loss: 0.000716
Validation Loss: 0.00065827
Epoch [163/300], Train Loss: 0.000711
Validation Loss: 0.00067082
Epoch [164/300], Train Loss: 0.000709
Validation Loss: 0.00065839
Epoch [165/300], Train Loss: 0.000700
Validation Loss: 0.00066814
Epoch [166/300], Train Loss: 0.000697
Validation Loss: 0.00066985
Epoch [167/300], Train Loss: 0.000700
Validation Loss: 0.00066683
Epoch [168/300], Train Loss: 0.000694
Validation Loss: 0.00066835
Epoch [169/300], Train Loss: 0.000709
Validation Loss: 0.00065514
Epoch [170/300], Train Loss: 0.000696
Validation Loss: 0.00068401
Epoch [171/300], Train Loss: 0.000689
Validation Loss: 0.00064061
Epoch [172/300], Train Loss: 0.000686
Validation Loss: 0.00065154
Epoch [173/300], Train Loss: 0.000687
Validation Loss: 0.00064091
Epoch [174/300], Train Loss: 0.000681
Validation Loss: 0.00064976
Epoch [175/300], Train Loss: 0.000685
Validation Loss: 0.00064301
Epoch [176/300], Train Loss: 0.000683
Validation Loss: 0.00065460
Epoch [177/300], Train Loss: 0.000683
Validation Loss: 0.00065338
Epoch [178/300], Train Loss: 0.000674
Validation Loss: 0.00068177
Epoch [179/300], Train Loss: 0.000679
Validation Loss: 0.00063695
Epoch [180/300], Train Loss: 0.000679
Validation Loss: 0.00065599
Epoch [181/300], Train Loss: 0.000669
Validation Loss: 0.00062780
Epoch [182/300], Train Loss: 0.000674
Validation Loss: 0.00064396
Epoch [183/300], Train Loss: 0.000671
Validation Loss: 0.00066329
Epoch [184/300], Train Loss: 0.000666
Validation Loss: 0.00064515
Epoch [185/300], Train Loss: 0.000662
Validation Loss: 0.00064420
Epoch [186/300], Train Loss: 0.000659
Validation Loss: 0.00063166
Epoch [187/300], Train Loss: 0.000658
Validation Loss: 0.00062591
Epoch [188/300], Train Loss: 0.000658
Validation Loss: 0.00067600
Epoch [189/300], Train Loss: 0.000657
Validation Loss: 0.00062120
Epoch [190/300], Train Loss: 0.000655
Validation Loss: 0.00062863
Epoch [191/300], Train Loss: 0.000652
Validation Loss: 0.00064213
Epoch [192/300], Train Loss: 0.000653
Validation Loss: 0.00062129
Epoch [193/300], Train Loss: 0.000662
Validation Loss: 0.00065936
Epoch [194/300], Train Loss: 0.000659
Validation Loss: 0.00063081
Epoch [195/300], Train Loss: 0.000652
Validation Loss: 0.00063282
Epoch [196/300], Train Loss: 0.000653
Validation Loss: 0.00061759
Epoch [197/300], Train Loss: 0.000647
Validation Loss: 0.00062135
Epoch [198/300], Train Loss: 0.000642
Validation Loss: 0.00062164
Epoch [199/300], Train Loss: 0.000641
Validation Loss: 0.00067524
Epoch [200/300], Train Loss: 0.000660
Validation Loss: 0.00065594
Epoch [201/300], Train Loss: 0.000647
Validation Loss: 0.00062756
Epoch [202/300], Train Loss: 0.000641
Validation Loss: 0.00062992
Epoch [203/300], Train Loss: 0.000646
Validation Loss: 0.00061943
Epoch [204/300], Train Loss: 0.000643
Validation Loss: 0.00062331
Epoch [205/300], Train Loss: 0.000645
Validation Loss: 0.00061595
Epoch [206/300], Train Loss: 0.000643
Validation Loss: 0.00061522
Epoch [207/300], Train Loss: 0.000632
Validation Loss: 0.00060685
Epoch [208/300], Train Loss: 0.000635
Validation Loss: 0.00065896
Epoch [209/300], Train Loss: 0.000637
Validation Loss: 0.00063762
Epoch [210/300], Train Loss: 0.000681
Validation Loss: 0.00062632
Epoch [211/300], Train Loss: 0.000638
Validation Loss: 0.00061252
Epoch [212/300], Train Loss: 0.000628
Validation Loss: 0.00061767
Epoch [213/300], Train Loss: 0.000625
Validation Loss: 0.00060588
Epoch [214/300], Train Loss: 0.000623
Validation Loss: 0.00060808
Epoch [215/300], Train Loss: 0.000624
Validation Loss: 0.00061702
Epoch [216/300], Train Loss: 0.000629
Validation Loss: 0.00061859
Epoch [217/300], Train Loss: 0.000625
Validation Loss: 0.00060208
Epoch [218/300], Train Loss: 0.000623
Validation Loss: 0.00060720
Epoch [219/300], Train Loss: 0.000621
Validation Loss: 0.00060674
Epoch [220/300], Train Loss: 0.000623
Validation Loss: 0.00060967
Epoch [221/300], Train Loss: 0.000623
Validation Loss: 0.00061633
Epoch [222/300], Train Loss: 0.000624
Validation Loss: 0.00061434
Epoch [223/300], Train Loss: 0.000659
Validation Loss: 0.00060985
Epoch [224/300], Train Loss: 0.000627
Validation Loss: 0.00060433
Epoch [225/300], Train Loss: 0.000619
Validation Loss: 0.00060713
Epoch [226/300], Train Loss: 0.000619
Validation Loss: 0.00060571
Epoch [227/300], Train Loss: 0.000617
Validation Loss: 0.00062726
Early stopping triggered

Evaluating model for: Freezer
Run 55/72 completed in 2236.45 seconds with: {'MAE': np.float32(21.913557), 'MSE': np.float32(886.0469), 'RMSE': np.float32(29.766539), 'SAE': np.float32(0.0027034034), 'NDE': np.float32(0.23047705)}

Run 56/72: hidden=512, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Freezer
Dataset length: 7026 windows

Epoch [1/300], Train Loss: 0.006686
Validation Loss: 0.00585918
Epoch [2/300], Train Loss: 0.005976
Validation Loss: 0.00589096
Epoch [3/300], Train Loss: 0.005544
Validation Loss: 0.00447878
Epoch [4/300], Train Loss: 0.003584
Validation Loss: 0.00329547
Epoch [5/300], Train Loss: 0.003153
Validation Loss: 0.00328192
Epoch [6/300], Train Loss: 0.002895
Validation Loss: 0.00292352
Epoch [7/300], Train Loss: 0.002673
Validation Loss: 0.00264487
Epoch [8/300], Train Loss: 0.002463
Validation Loss: 0.00266759
Epoch [9/300], Train Loss: 0.002403
Validation Loss: 0.00243329
Epoch [10/300], Train Loss: 0.002385
Validation Loss: 0.00245189
Epoch [11/300], Train Loss: 0.002336
Validation Loss: 0.00244439
Epoch [12/300], Train Loss: 0.002330
Validation Loss: 0.00235040
Epoch [13/300], Train Loss: 0.002304
Validation Loss: 0.00228615
Epoch [14/300], Train Loss: 0.002282
Validation Loss: 0.00232046
Epoch [15/300], Train Loss: 0.002280
Validation Loss: 0.00236899
Epoch [16/300], Train Loss: 0.002206
Validation Loss: 0.00225822
Epoch [17/300], Train Loss: 0.002127
Validation Loss: 0.00214403
Epoch [18/300], Train Loss: 0.002096
Validation Loss: 0.00223871
Epoch [19/300], Train Loss: 0.002048
Validation Loss: 0.00213993
Epoch [20/300], Train Loss: 0.002028
Validation Loss: 0.00213008
Epoch [21/300], Train Loss: 0.001990
Validation Loss: 0.00226673
Epoch [22/300], Train Loss: 0.002024
Validation Loss: 0.00199891
Epoch [23/300], Train Loss: 0.001948
Validation Loss: 0.00202089
Epoch [24/300], Train Loss: 0.001876
Validation Loss: 0.00189524
Epoch [25/300], Train Loss: 0.001842
Validation Loss: 0.00205926
Epoch [26/300], Train Loss: 0.001942
Validation Loss: 0.00200891
Epoch [27/300], Train Loss: 0.001879
Validation Loss: 0.00190150
Epoch [28/300], Train Loss: 0.001856
Validation Loss: 0.00197389
Epoch [29/300], Train Loss: 0.001792
Validation Loss: 0.00182843
Epoch [30/300], Train Loss: 0.001776
Validation Loss: 0.00186584
Epoch [31/300], Train Loss: 0.001760
Validation Loss: 0.00178409
Epoch [32/300], Train Loss: 0.001724
Validation Loss: 0.00179897
Epoch [33/300], Train Loss: 0.001720
Validation Loss: 0.00171340
Epoch [34/300], Train Loss: 0.001728
Validation Loss: 0.00173031
Epoch [35/300], Train Loss: 0.001650
Validation Loss: 0.00173545
Epoch [36/300], Train Loss: 0.001623
Validation Loss: 0.00169914
Epoch [37/300], Train Loss: 0.001627
Validation Loss: 0.00175132
Epoch [38/300], Train Loss: 0.001640
Validation Loss: 0.00165751
Epoch [39/300], Train Loss: 0.001603
Validation Loss: 0.00171778
Epoch [40/300], Train Loss: 0.001597
Validation Loss: 0.00162295
Epoch [41/300], Train Loss: 0.001582
Validation Loss: 0.00162177
Epoch [42/300], Train Loss: 0.001588
Validation Loss: 0.00167615
Epoch [43/300], Train Loss: 0.001586
Validation Loss: 0.00170731
Epoch [44/300], Train Loss: 0.001594
Validation Loss: 0.00164304
Epoch [45/300], Train Loss: 0.001585
Validation Loss: 0.00160506
Epoch [46/300], Train Loss: 0.001563
Validation Loss: 0.00159460
Epoch [47/300], Train Loss: 0.001546
Validation Loss: 0.00158529
Epoch [48/300], Train Loss: 0.001535
Validation Loss: 0.00159721
Epoch [49/300], Train Loss: 0.001562
Validation Loss: 0.00169112
Epoch [50/300], Train Loss: 0.001569
Validation Loss: 0.00161008
Epoch [51/300], Train Loss: 0.001547
Validation Loss: 0.00169276
Epoch [52/300], Train Loss: 0.001520
Validation Loss: 0.00161037
Epoch [53/300], Train Loss: 0.001798
Validation Loss: 0.00169925
Epoch [54/300], Train Loss: 0.001688
Validation Loss: 0.00172113
Epoch [55/300], Train Loss: 0.001634
Validation Loss: 0.00165458
Epoch [56/300], Train Loss: 0.001603
Validation Loss: 0.00162897
Epoch [57/300], Train Loss: 0.001596
Validation Loss: 0.00163244
Early stopping triggered

Evaluating model for: Freezer
Run 56/72 completed in 650.11 seconds with: {'MAE': np.float32(33.867607), 'MSE': np.float32(2461.5947), 'RMSE': np.float32(49.61446), 'SAE': np.float32(0.011910617), 'NDE': np.float32(0.384156)}

Run 57/72: hidden=512, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Freezer
Dataset length: 4614 windows

Epoch [1/300], Train Loss: 0.006226
Validation Loss: 0.00556820
Epoch [2/300], Train Loss: 0.005788
Validation Loss: 0.00539598
Epoch [3/300], Train Loss: 0.005143
Validation Loss: 0.00400645
Epoch [4/300], Train Loss: 0.003482
Validation Loss: 0.00299564
Epoch [5/300], Train Loss: 0.002594
Validation Loss: 0.00241263
Epoch [6/300], Train Loss: 0.002350
Validation Loss: 0.00234199
Epoch [7/300], Train Loss: 0.002292
Validation Loss: 0.00225057
Epoch [8/300], Train Loss: 0.002184
Validation Loss: 0.00213817
Epoch [9/300], Train Loss: 0.002121
Validation Loss: 0.00207764
Epoch [10/300], Train Loss: 0.002044
Validation Loss: 0.00202242
Epoch [11/300], Train Loss: 0.002002
Validation Loss: 0.00199613
Epoch [12/300], Train Loss: 0.001954
Validation Loss: 0.00190697
Epoch [13/300], Train Loss: 0.001910
Validation Loss: 0.00186142
Epoch [14/300], Train Loss: 0.001896
Validation Loss: 0.00182157
Epoch [15/300], Train Loss: 0.001857
Validation Loss: 0.00180377
Epoch [16/300], Train Loss: 0.001859
Validation Loss: 0.00180120
Epoch [17/300], Train Loss: 0.001809
Validation Loss: 0.00172041
Epoch [18/300], Train Loss: 0.001766
Validation Loss: 0.00169613
Epoch [19/300], Train Loss: 0.001751
Validation Loss: 0.00170403
Epoch [20/300], Train Loss: 0.001746
Validation Loss: 0.00166980
Epoch [21/300], Train Loss: 0.001727
Validation Loss: 0.00170094
Epoch [22/300], Train Loss: 0.001714
Validation Loss: 0.00164922
Epoch [23/300], Train Loss: 0.001725
Validation Loss: 0.00166589
Epoch [24/300], Train Loss: 0.001717
Validation Loss: 0.00162644
Epoch [25/300], Train Loss: 0.001686
Validation Loss: 0.00161333
Epoch [26/300], Train Loss: 0.001673
Validation Loss: 0.00161025
Epoch [27/300], Train Loss: 0.001675
Validation Loss: 0.00160955
Epoch [28/300], Train Loss: 0.001674
Validation Loss: 0.00159431
Epoch [29/300], Train Loss: 0.001673
Validation Loss: 0.00166076
Epoch [30/300], Train Loss: 0.001663
Validation Loss: 0.00165591
Epoch [31/300], Train Loss: 0.001676
Validation Loss: 0.00158070
Epoch [32/300], Train Loss: 0.001650
Validation Loss: 0.00157429
Epoch [33/300], Train Loss: 0.001639
Validation Loss: 0.00158965
Epoch [34/300], Train Loss: 0.001628
Validation Loss: 0.00155355
Epoch [35/300], Train Loss: 0.001625
Validation Loss: 0.00155171
Epoch [36/300], Train Loss: 0.001617
Validation Loss: 0.00155072
Epoch [37/300], Train Loss: 0.001604
Validation Loss: 0.00153628
Epoch [38/300], Train Loss: 0.001620
Validation Loss: 0.00156218
Epoch [39/300], Train Loss: 0.001601
Validation Loss: 0.00151976
Epoch [40/300], Train Loss: 0.001598
Validation Loss: 0.00152000
Epoch [41/300], Train Loss: 0.001592
Validation Loss: 0.00151551
Epoch [42/300], Train Loss: 0.001596
Validation Loss: 0.00152765
Epoch [43/300], Train Loss: 0.001573
Validation Loss: 0.00150860
Epoch [44/300], Train Loss: 0.001565
Validation Loss: 0.00149666
Epoch [45/300], Train Loss: 0.001561
Validation Loss: 0.00147854
Epoch [46/300], Train Loss: 0.001547
Validation Loss: 0.00149801
Epoch [47/300], Train Loss: 0.001541
Validation Loss: 0.00146744
Epoch [48/300], Train Loss: 0.001545
Validation Loss: 0.00145724
Epoch [49/300], Train Loss: 0.001543
Validation Loss: 0.00144738
Epoch [50/300], Train Loss: 0.001534
Validation Loss: 0.00145845
Epoch [51/300], Train Loss: 0.001544
Validation Loss: 0.00146151
Epoch [52/300], Train Loss: 0.001560
Validation Loss: 0.00148785
Epoch [53/300], Train Loss: 0.001543
Validation Loss: 0.00146045
Epoch [54/300], Train Loss: 0.001524
Validation Loss: 0.00144966
Epoch [55/300], Train Loss: 0.001507
Validation Loss: 0.00142787
Epoch [56/300], Train Loss: 0.001568
Validation Loss: 0.00162405
Epoch [57/300], Train Loss: 0.001588
Validation Loss: 0.00149479
Epoch [58/300], Train Loss: 0.001537
Validation Loss: 0.00148831
Epoch [59/300], Train Loss: 0.001524
Validation Loss: 0.00148852
Epoch [60/300], Train Loss: 0.001521
Validation Loss: 0.00144494
Epoch [61/300], Train Loss: 0.001483
Validation Loss: 0.00144234
Epoch [62/300], Train Loss: 0.001475
Validation Loss: 0.00141110
Epoch [63/300], Train Loss: 0.001474
Validation Loss: 0.00145082
Epoch [64/300], Train Loss: 0.001493
Validation Loss: 0.00144703
Epoch [65/300], Train Loss: 0.001493
Validation Loss: 0.00142717
Epoch [66/300], Train Loss: 0.001465
Validation Loss: 0.00141503
Epoch [67/300], Train Loss: 0.001456
Validation Loss: 0.00142192
Epoch [68/300], Train Loss: 0.001486
Validation Loss: 0.00141063
Epoch [69/300], Train Loss: 0.001462
Validation Loss: 0.00142657
Epoch [70/300], Train Loss: 0.001493
Validation Loss: 0.00141773
Epoch [71/300], Train Loss: 0.001460
Validation Loss: 0.00141281
Epoch [72/300], Train Loss: 0.001453
Validation Loss: 0.00140076
Epoch [73/300], Train Loss: 0.001459
Validation Loss: 0.00138908
Epoch [74/300], Train Loss: 0.001454
Validation Loss: 0.00140977
Epoch [75/300], Train Loss: 0.001443
Validation Loss: 0.00139436
Epoch [76/300], Train Loss: 0.001446
Validation Loss: 0.00139968
Epoch [77/300], Train Loss: 0.001449
Validation Loss: 0.00139279
Epoch [78/300], Train Loss: 0.001439
Validation Loss: 0.00139002
Epoch [79/300], Train Loss: 0.001439
Validation Loss: 0.00138571
Epoch [80/300], Train Loss: 0.001445
Validation Loss: 0.00140865
Epoch [81/300], Train Loss: 0.001466
Validation Loss: 0.00137921
Epoch [82/300], Train Loss: 0.001446
Validation Loss: 0.00137766
Epoch [83/300], Train Loss: 0.001443
Validation Loss: 0.00139548
Epoch [84/300], Train Loss: 0.001432
Validation Loss: 0.00136163
Epoch [85/300], Train Loss: 0.001432
Validation Loss: 0.00140783
Epoch [86/300], Train Loss: 0.001440
Validation Loss: 0.00140852
Epoch [87/300], Train Loss: 0.001436
Validation Loss: 0.00136696
Epoch [88/300], Train Loss: 0.001445
Validation Loss: 0.00139817
Epoch [89/300], Train Loss: 0.001426
Validation Loss: 0.00140737
Epoch [90/300], Train Loss: 0.001422
Validation Loss: 0.00137681
Epoch [91/300], Train Loss: 0.001431
Validation Loss: 0.00138131
Epoch [92/300], Train Loss: 0.001430
Validation Loss: 0.00137976
Epoch [93/300], Train Loss: 0.001426
Validation Loss: 0.00136987
Epoch [94/300], Train Loss: 0.001418
Validation Loss: 0.00136430
Early stopping triggered

Evaluating model for: Freezer
Run 57/72 completed in 756.33 seconds with: {'MAE': np.float32(33.57895), 'MSE': np.float32(2399.9246), 'RMSE': np.float32(48.989025), 'SAE': np.float32(0.0036333152), 'NDE': np.float32(0.36557817)}

Run 58/72: hidden=512, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Freezer
Dataset length: 4614 windows

Epoch [1/300], Train Loss: 0.006682
Validation Loss: 0.00560532
Epoch [2/300], Train Loss: 0.005859
Validation Loss: 0.00548997
Epoch [3/300], Train Loss: 0.005394
Validation Loss: 0.00440930
Epoch [4/300], Train Loss: 0.004373
Validation Loss: 0.00378941
Epoch [5/300], Train Loss: 0.003235
Validation Loss: 0.00260247
Epoch [6/300], Train Loss: 0.002435
Validation Loss: 0.00225464
Epoch [7/300], Train Loss: 0.002321
Validation Loss: 0.00226541
Epoch [8/300], Train Loss: 0.002206
Validation Loss: 0.00214058
Epoch [9/300], Train Loss: 0.002136
Validation Loss: 0.00211214
Epoch [10/300], Train Loss: 0.002046
Validation Loss: 0.00193020
Epoch [11/300], Train Loss: 0.001959
Validation Loss: 0.00191555
Epoch [12/300], Train Loss: 0.001899
Validation Loss: 0.00183614
Epoch [13/300], Train Loss: 0.001860
Validation Loss: 0.00180081
Epoch [14/300], Train Loss: 0.001894
Validation Loss: 0.00180036
Epoch [15/300], Train Loss: 0.001835
Validation Loss: 0.00175608
Epoch [16/300], Train Loss: 0.001822
Validation Loss: 0.00176930
Epoch [17/300], Train Loss: 0.001790
Validation Loss: 0.00171382
Epoch [18/300], Train Loss: 0.001754
Validation Loss: 0.00170283
Epoch [19/300], Train Loss: 0.001740
Validation Loss: 0.00170793
Epoch [20/300], Train Loss: 0.001738
Validation Loss: 0.00167957
Epoch [21/300], Train Loss: 0.001714
Validation Loss: 0.00168646
Epoch [22/300], Train Loss: 0.001704
Validation Loss: 0.00164946
Epoch [23/300], Train Loss: 0.001729
Validation Loss: 0.00166824
Epoch [24/300], Train Loss: 0.001704
Validation Loss: 0.00162051
Epoch [25/300], Train Loss: 0.001668
Validation Loss: 0.00159715
Epoch [26/300], Train Loss: 0.001655
Validation Loss: 0.00158935
Epoch [27/300], Train Loss: 0.001658
Validation Loss: 0.00160376
Epoch [28/300], Train Loss: 0.001646
Validation Loss: 0.00155688
Epoch [29/300], Train Loss: 0.001634
Validation Loss: 0.00158410
Epoch [30/300], Train Loss: 0.001621
Validation Loss: 0.00161387
Epoch [31/300], Train Loss: 0.001622
Validation Loss: 0.00156175
Epoch [32/300], Train Loss: 0.001620
Validation Loss: 0.00152586
Epoch [33/300], Train Loss: 0.001590
Validation Loss: 0.00152260
Epoch [34/300], Train Loss: 0.001581
Validation Loss: 0.00151405
Epoch [35/300], Train Loss: 0.001615
Validation Loss: 0.00152355
Epoch [36/300], Train Loss: 0.001569
Validation Loss: 0.00150123
Epoch [37/300], Train Loss: 0.001580
Validation Loss: 0.00169405
Epoch [38/300], Train Loss: 0.001659
Validation Loss: 0.00158101
Epoch [39/300], Train Loss: 0.001601
Validation Loss: 0.00153264
Epoch [40/300], Train Loss: 0.001581
Validation Loss: 0.00150614
Epoch [41/300], Train Loss: 0.001563
Validation Loss: 0.00149937
Epoch [42/300], Train Loss: 0.001558
Validation Loss: 0.00149562
Epoch [43/300], Train Loss: 0.001544
Validation Loss: 0.00149537
Epoch [44/300], Train Loss: 0.001540
Validation Loss: 0.00147523
Epoch [45/300], Train Loss: 0.001544
Validation Loss: 0.00146886
Epoch [46/300], Train Loss: 0.001527
Validation Loss: 0.00146115
Epoch [47/300], Train Loss: 0.001530
Validation Loss: 0.00144723
Epoch [48/300], Train Loss: 0.001530
Validation Loss: 0.00144566
Epoch [49/300], Train Loss: 0.001532
Validation Loss: 0.00144319
Epoch [50/300], Train Loss: 0.001514
Validation Loss: 0.00143287
Epoch [51/300], Train Loss: 0.001510
Validation Loss: 0.00144598
Epoch [52/300], Train Loss: 0.001526
Validation Loss: 0.00143873
Epoch [53/300], Train Loss: 0.001505
Validation Loss: 0.00143825
Epoch [54/300], Train Loss: 0.001495
Validation Loss: 0.00141289
Epoch [55/300], Train Loss: 0.001478
Validation Loss: 0.00140166
Epoch [56/300], Train Loss: 0.001477
Validation Loss: 0.00139264
Epoch [57/300], Train Loss: 0.001483
Validation Loss: 0.00142061
Epoch [58/300], Train Loss: 0.001474
Validation Loss: 0.00141423
Epoch [59/300], Train Loss: 0.001459
Validation Loss: 0.00141625
Epoch [60/300], Train Loss: 0.001467
Validation Loss: 0.00138593
Epoch [61/300], Train Loss: 0.001449
Validation Loss: 0.00138078
Epoch [62/300], Train Loss: 0.001468
Validation Loss: 0.00139698
Epoch [63/300], Train Loss: 0.001468
Validation Loss: 0.00141901
Epoch [64/300], Train Loss: 0.001456
Validation Loss: 0.00141815
Epoch [65/300], Train Loss: 0.001461
Validation Loss: 0.00141068
Epoch [66/300], Train Loss: 0.001431
Validation Loss: 0.00141906
Epoch [67/300], Train Loss: 0.001435
Validation Loss: 0.00136712
Epoch [68/300], Train Loss: 0.001441
Validation Loss: 0.00136017
Epoch [69/300], Train Loss: 0.001428
Validation Loss: 0.00135970
Epoch [70/300], Train Loss: 0.001463
Validation Loss: 0.00136948
Epoch [71/300], Train Loss: 0.001422
Validation Loss: 0.00149523
Epoch [72/300], Train Loss: 0.001450
Validation Loss: 0.00138547
Epoch [73/300], Train Loss: 0.001418
Validation Loss: 0.00137027
Epoch [74/300], Train Loss: 0.001421
Validation Loss: 0.00140757
Epoch [75/300], Train Loss: 0.001443
Validation Loss: 0.00138698
Epoch [76/300], Train Loss: 0.001416
Validation Loss: 0.00138374
Epoch [77/300], Train Loss: 0.001423
Validation Loss: 0.00138500
Epoch [78/300], Train Loss: 0.001511
Validation Loss: 0.00144765
Epoch [79/300], Train Loss: 0.001494
Validation Loss: 0.00144037
Early stopping triggered

Evaluating model for: Freezer
Run 58/72 completed in 808.45 seconds with: {'MAE': np.float32(34.05545), 'MSE': np.float32(2482.5632), 'RMSE': np.float32(49.82533), 'SAE': np.float32(0.0051999264), 'NDE': np.float32(0.37181908)}

Run 59/72: hidden=512, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Freezer
Dataset length: 4614 windows

Epoch [1/300], Train Loss: 0.006668
Validation Loss: 0.00562387
Epoch [2/300], Train Loss: 0.005910
Validation Loss: 0.00559301
Epoch [3/300], Train Loss: 0.005698
Validation Loss: 0.00471409
Epoch [4/300], Train Loss: 0.003927
Validation Loss: 0.00312319
Epoch [5/300], Train Loss: 0.002918
Validation Loss: 0.00262242
Epoch [6/300], Train Loss: 0.002579
Validation Loss: 0.00240106
Epoch [7/300], Train Loss: 0.002438
Validation Loss: 0.00234929
Epoch [8/300], Train Loss: 0.002339
Validation Loss: 0.00219448
Epoch [9/300], Train Loss: 0.002232
Validation Loss: 0.00210982
Epoch [10/300], Train Loss: 0.002142
Validation Loss: 0.00202209
Epoch [11/300], Train Loss: 0.002100
Validation Loss: 0.00196144
Epoch [12/300], Train Loss: 0.001981
Validation Loss: 0.00181047
Epoch [13/300], Train Loss: 0.001844
Validation Loss: 0.00176997
Epoch [14/300], Train Loss: 0.001849
Validation Loss: 0.00178116
Epoch [15/300], Train Loss: 0.001797
Validation Loss: 0.00174127
Epoch [16/300], Train Loss: 0.001801
Validation Loss: 0.00169205
Epoch [17/300], Train Loss: 0.001762
Validation Loss: 0.00170287
Epoch [18/300], Train Loss: 0.001755
Validation Loss: 0.00167336
Epoch [19/300], Train Loss: 0.001753
Validation Loss: 0.00166872
Epoch [20/300], Train Loss: 0.001745
Validation Loss: 0.00166427
Epoch [21/300], Train Loss: 0.001746
Validation Loss: 0.00170664
Epoch [22/300], Train Loss: 0.001723
Validation Loss: 0.00165541
Epoch [23/300], Train Loss: 0.001734
Validation Loss: 0.00165024
Epoch [24/300], Train Loss: 0.001722
Validation Loss: 0.00162139
Epoch [25/300], Train Loss: 0.001676
Validation Loss: 0.00157767
Epoch [26/300], Train Loss: 0.001647
Validation Loss: 0.00156377
Epoch [27/300], Train Loss: 0.001645
Validation Loss: 0.00155620
Epoch [28/300], Train Loss: 0.001641
Validation Loss: 0.00156396
Epoch [29/300], Train Loss: 0.001641
Validation Loss: 0.00165044
Epoch [30/300], Train Loss: 0.001630
Validation Loss: 0.00160567
Epoch [31/300], Train Loss: 0.001619
Validation Loss: 0.00151401
Epoch [32/300], Train Loss: 0.001617
Validation Loss: 0.00150027
Epoch [33/300], Train Loss: 0.001616
Validation Loss: 0.00152202
Epoch [34/300], Train Loss: 0.001599
Validation Loss: 0.00151846
Epoch [35/300], Train Loss: 0.001581
Validation Loss: 0.00148953
Epoch [36/300], Train Loss: 0.001567
Validation Loss: 0.00151741
Epoch [37/300], Train Loss: 0.001571
Validation Loss: 0.00150432
Epoch [38/300], Train Loss: 0.001558
Validation Loss: 0.00147673
Epoch [39/300], Train Loss: 0.001560
Validation Loss: 0.00146617
Epoch [40/300], Train Loss: 0.001558
Validation Loss: 0.00153083
Epoch [41/300], Train Loss: 0.001581
Validation Loss: 0.00150403
Epoch [42/300], Train Loss: 0.001556
Validation Loss: 0.00147199
Epoch [43/300], Train Loss: 0.001558
Validation Loss: 0.00151263
Epoch [44/300], Train Loss: 0.001544
Validation Loss: 0.00147061
Epoch [45/300], Train Loss: 0.001605
Validation Loss: 0.00149547
Epoch [46/300], Train Loss: 0.001559
Validation Loss: 0.00152431
Epoch [47/300], Train Loss: 0.001605
Validation Loss: 0.00158066
Epoch [48/300], Train Loss: 0.001675
Validation Loss: 0.00161828
Epoch [49/300], Train Loss: 0.001622
Validation Loss: 0.00152652
Early stopping triggered

Evaluating model for: Freezer
Run 59/72 completed in 586.69 seconds with: {'MAE': np.float32(34.47371), 'MSE': np.float32(2658.0422), 'RMSE': np.float32(51.556206), 'SAE': np.float32(0.046574075), 'NDE': np.float32(0.38473564)}

Run 60/72: hidden=512, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Freezer
Dataset length: 4614 windows

Epoch [1/300], Train Loss: 0.006459
Validation Loss: 0.00562352
Epoch [2/300], Train Loss: 0.005928
Validation Loss: 0.00563589
Epoch [3/300], Train Loss: 0.005918
Validation Loss: 0.00561988
Epoch [4/300], Train Loss: 0.005885
Validation Loss: 0.00548710
Epoch [5/300], Train Loss: 0.005156
Validation Loss: 0.00436469
Epoch [6/300], Train Loss: 0.004032
Validation Loss: 0.00294162
Epoch [7/300], Train Loss: 0.003847
Validation Loss: 0.00647006
Epoch [8/300], Train Loss: 0.005989
Validation Loss: 0.00562300
Epoch [9/300], Train Loss: 0.005925
Validation Loss: 0.00561406
Epoch [10/300], Train Loss: 0.005926
Validation Loss: 0.00562300
Epoch [11/300], Train Loss: 0.005942
Validation Loss: 0.00568615
Epoch [12/300], Train Loss: 0.005913
Validation Loss: 0.00562488
Epoch [13/300], Train Loss: 0.005906
Validation Loss: 0.00564180
Epoch [14/300], Train Loss: 0.005910
Validation Loss: 0.00564928
Epoch [15/300], Train Loss: 0.005922
Validation Loss: 0.00565016
Epoch [16/300], Train Loss: 0.005912
Validation Loss: 0.00561870
Early stopping triggered

Evaluating model for: Freezer
Run 60/72 completed in 245.10 seconds with: {'MAE': np.float32(86.96469), 'MSE': np.float32(10074.735), 'RMSE': np.float32(100.37298), 'SAE': np.float32(0.099137075), 'NDE': np.float32(0.74902844)}

Run 61/72: hidden=512, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Freezer
Dataset length: 2322 windows

Epoch [1/300], Train Loss: 0.006658
Validation Loss: 0.00593559
Epoch [2/300], Train Loss: 0.005864
Validation Loss: 0.00528037
Epoch [3/300], Train Loss: 0.005671
Validation Loss: 0.00526878
Epoch [4/300], Train Loss: 0.005353
Validation Loss: 0.00471618
Epoch [5/300], Train Loss: 0.004467
Validation Loss: 0.00402868
Epoch [6/300], Train Loss: 0.003708
Validation Loss: 0.00327556
Epoch [7/300], Train Loss: 0.002971
Validation Loss: 0.00263382
Epoch [8/300], Train Loss: 0.002517
Validation Loss: 0.00243820
Epoch [9/300], Train Loss: 0.002287
Validation Loss: 0.00219187
Epoch [10/300], Train Loss: 0.002158
Validation Loss: 0.00208891
Epoch [11/300], Train Loss: 0.002045
Validation Loss: 0.00208251
Epoch [12/300], Train Loss: 0.001982
Validation Loss: 0.00205245
Epoch [13/300], Train Loss: 0.001954
Validation Loss: 0.00200348
Epoch [14/300], Train Loss: 0.001943
Validation Loss: 0.00197992
Epoch [15/300], Train Loss: 0.001895
Validation Loss: 0.00194871
Epoch [16/300], Train Loss: 0.001875
Validation Loss: 0.00195081
Epoch [17/300], Train Loss: 0.001822
Validation Loss: 0.00194734
Epoch [18/300], Train Loss: 0.001823
Validation Loss: 0.00190006
Epoch [19/300], Train Loss: 0.001825
Validation Loss: 0.00188745
Epoch [20/300], Train Loss: 0.001775
Validation Loss: 0.00189212
Epoch [21/300], Train Loss: 0.001766
Validation Loss: 0.00186071
Epoch [22/300], Train Loss: 0.001763
Validation Loss: 0.00183777
Epoch [23/300], Train Loss: 0.001779
Validation Loss: 0.00183658
Epoch [24/300], Train Loss: 0.001726
Validation Loss: 0.00181561
Epoch [25/300], Train Loss: 0.001728
Validation Loss: 0.00180819
Epoch [26/300], Train Loss: 0.001735
Validation Loss: 0.00180535
Epoch [27/300], Train Loss: 0.001737
Validation Loss: 0.00180012
Epoch [28/300], Train Loss: 0.001672
Validation Loss: 0.00177835
Epoch [29/300], Train Loss: 0.001674
Validation Loss: 0.00176302
Epoch [30/300], Train Loss: 0.001661
Validation Loss: 0.00176814
Epoch [31/300], Train Loss: 0.001647
Validation Loss: 0.00174961
Epoch [32/300], Train Loss: 0.001627
Validation Loss: 0.00176311
Epoch [33/300], Train Loss: 0.001649
Validation Loss: 0.00176775
Epoch [34/300], Train Loss: 0.001649
Validation Loss: 0.00175965
Epoch [35/300], Train Loss: 0.001629
Validation Loss: 0.00174692
Epoch [36/300], Train Loss: 0.001633
Validation Loss: 0.00173670
Epoch [37/300], Train Loss: 0.001642
Validation Loss: 0.00174416
Epoch [38/300], Train Loss: 0.001609
Validation Loss: 0.00171687
Epoch [39/300], Train Loss: 0.001606
Validation Loss: 0.00175268
Epoch [40/300], Train Loss: 0.001604
Validation Loss: 0.00171127
Epoch [41/300], Train Loss: 0.001580
Validation Loss: 0.00171056
Epoch [42/300], Train Loss: 0.001590
Validation Loss: 0.00174411
Epoch [43/300], Train Loss: 0.001588
Validation Loss: 0.00172145
Epoch [44/300], Train Loss: 0.001603
Validation Loss: 0.00170034
Epoch [45/300], Train Loss: 0.001584
Validation Loss: 0.00170664
Epoch [46/300], Train Loss: 0.001575
Validation Loss: 0.00169689
Epoch [47/300], Train Loss: 0.001574
Validation Loss: 0.00171136
Epoch [48/300], Train Loss: 0.001561
Validation Loss: 0.00170318
Epoch [49/300], Train Loss: 0.001567
Validation Loss: 0.00170759
Epoch [50/300], Train Loss: 0.001576
Validation Loss: 0.00171575
Epoch [51/300], Train Loss: 0.001565
Validation Loss: 0.00168723
Epoch [52/300], Train Loss: 0.001544
Validation Loss: 0.00172308
Epoch [53/300], Train Loss: 0.001588
Validation Loss: 0.00169015
Epoch [54/300], Train Loss: 0.001540
Validation Loss: 0.00170020
Epoch [55/300], Train Loss: 0.001558
Validation Loss: 0.00168443
Epoch [56/300], Train Loss: 0.001568
Validation Loss: 0.00168504
Epoch [57/300], Train Loss: 0.001589
Validation Loss: 0.00168641
Epoch [58/300], Train Loss: 0.001551
Validation Loss: 0.00169114
Epoch [59/300], Train Loss: 0.001547
Validation Loss: 0.00167236
Epoch [60/300], Train Loss: 0.001583
Validation Loss: 0.00167699
Epoch [61/300], Train Loss: 0.001569
Validation Loss: 0.00168016
Epoch [62/300], Train Loss: 0.001542
Validation Loss: 0.00166707
Epoch [63/300], Train Loss: 0.001551
Validation Loss: 0.00168686
Epoch [64/300], Train Loss: 0.001565
Validation Loss: 0.00167265
Epoch [65/300], Train Loss: 0.001524
Validation Loss: 0.00168591
Epoch [66/300], Train Loss: 0.001547
Validation Loss: 0.00170810
Epoch [67/300], Train Loss: 0.001553
Validation Loss: 0.00170668
Epoch [68/300], Train Loss: 0.001543
Validation Loss: 0.00167598
Epoch [69/300], Train Loss: 0.001536
Validation Loss: 0.00166798
Epoch [70/300], Train Loss: 0.001516
Validation Loss: 0.00168794
Epoch [71/300], Train Loss: 0.001515
Validation Loss: 0.00167013
Epoch [72/300], Train Loss: 0.001521
Validation Loss: 0.00165670
Epoch [73/300], Train Loss: 0.001536
Validation Loss: 0.00166572
Epoch [74/300], Train Loss: 0.001537
Validation Loss: 0.00166000
Epoch [75/300], Train Loss: 0.001516
Validation Loss: 0.00165251
Epoch [76/300], Train Loss: 0.001524
Validation Loss: 0.00165048
Epoch [77/300], Train Loss: 0.001516
Validation Loss: 0.00166470
Epoch [78/300], Train Loss: 0.001512
Validation Loss: 0.00165997
Epoch [79/300], Train Loss: 0.001516
Validation Loss: 0.00166175
Epoch [80/300], Train Loss: 0.001497
Validation Loss: 0.00164589
Epoch [81/300], Train Loss: 0.001505
Validation Loss: 0.00164272
Epoch [82/300], Train Loss: 0.001505
Validation Loss: 0.00164536
Epoch [83/300], Train Loss: 0.001498
Validation Loss: 0.00164063
Epoch [84/300], Train Loss: 0.001489
Validation Loss: 0.00163181
Epoch [85/300], Train Loss: 0.001500
Validation Loss: 0.00162992
Epoch [86/300], Train Loss: 0.001488
Validation Loss: 0.00163662
Epoch [87/300], Train Loss: 0.001480
Validation Loss: 0.00163671
Epoch [88/300], Train Loss: 0.001527
Validation Loss: 0.00162483
Epoch [89/300], Train Loss: 0.001478
Validation Loss: 0.00162496
Epoch [90/300], Train Loss: 0.001469
Validation Loss: 0.00162458
Epoch [91/300], Train Loss: 0.001477
Validation Loss: 0.00163355
Epoch [92/300], Train Loss: 0.001511
Validation Loss: 0.00163545
Epoch [93/300], Train Loss: 0.001477
Validation Loss: 0.00168520
Epoch [94/300], Train Loss: 0.001484
Validation Loss: 0.00164320
Epoch [95/300], Train Loss: 0.001477
Validation Loss: 0.00161002
Epoch [96/300], Train Loss: 0.001463
Validation Loss: 0.00165303
Epoch [97/300], Train Loss: 0.001488
Validation Loss: 0.00163445
Epoch [98/300], Train Loss: 0.001468
Validation Loss: 0.00161114
Epoch [99/300], Train Loss: 0.001453
Validation Loss: 0.00159699
Epoch [100/300], Train Loss: 0.001472
Validation Loss: 0.00162589
Epoch [101/300], Train Loss: 0.001463
Validation Loss: 0.00160133
Epoch [102/300], Train Loss: 0.001468
Validation Loss: 0.00161855
Epoch [103/300], Train Loss: 0.001446
Validation Loss: 0.00162402
Epoch [104/300], Train Loss: 0.001465
Validation Loss: 0.00160393
Epoch [105/300], Train Loss: 0.001436
Validation Loss: 0.00159092
Epoch [106/300], Train Loss: 0.001445
Validation Loss: 0.00158035
Epoch [107/300], Train Loss: 0.001441
Validation Loss: 0.00159896
Epoch [108/300], Train Loss: 0.001442
Validation Loss: 0.00160266
Epoch [109/300], Train Loss: 0.001445
Validation Loss: 0.00157678
Epoch [110/300], Train Loss: 0.001422
Validation Loss: 0.00157275
Epoch [111/300], Train Loss: 0.001420
Validation Loss: 0.00157684
Epoch [112/300], Train Loss: 0.001419
Validation Loss: 0.00158629
Epoch [113/300], Train Loss: 0.001431
Validation Loss: 0.00160627
Epoch [114/300], Train Loss: 0.001448
Validation Loss: 0.00157256
Epoch [115/300], Train Loss: 0.001432
Validation Loss: 0.00158490
Epoch [116/300], Train Loss: 0.001433
Validation Loss: 0.00156126
Epoch [117/300], Train Loss: 0.001422
Validation Loss: 0.00155598
Epoch [118/300], Train Loss: 0.001415
Validation Loss: 0.00155781
Epoch [119/300], Train Loss: 0.001407
Validation Loss: 0.00155596
Epoch [120/300], Train Loss: 0.001430
Validation Loss: 0.00155230
Epoch [121/300], Train Loss: 0.001431
Validation Loss: 0.00155435
Epoch [122/300], Train Loss: 0.001423
Validation Loss: 0.00155403
Epoch [123/300], Train Loss: 0.001405
Validation Loss: 0.00156220
Epoch [124/300], Train Loss: 0.001403
Validation Loss: 0.00153493
Epoch [125/300], Train Loss: 0.001388
Validation Loss: 0.00153827
Epoch [126/300], Train Loss: 0.001394
Validation Loss: 0.00152610
Epoch [127/300], Train Loss: 0.001404
Validation Loss: 0.00152356
Epoch [128/300], Train Loss: 0.001389
Validation Loss: 0.00153236
Epoch [129/300], Train Loss: 0.001394
Validation Loss: 0.00152541
Epoch [130/300], Train Loss: 0.001382
Validation Loss: 0.00154485
Epoch [131/300], Train Loss: 0.001373
Validation Loss: 0.00151709
Epoch [132/300], Train Loss: 0.001383
Validation Loss: 0.00150388
Epoch [133/300], Train Loss: 0.001357
Validation Loss: 0.00151465
Epoch [134/300], Train Loss: 0.001378
Validation Loss: 0.00150754
Epoch [135/300], Train Loss: 0.001364
Validation Loss: 0.00152678
Epoch [136/300], Train Loss: 0.001384
Validation Loss: 0.00150907
Epoch [137/300], Train Loss: 0.001366
Validation Loss: 0.00152393
Epoch [138/300], Train Loss: 0.001371
Validation Loss: 0.00160511
Epoch [139/300], Train Loss: 0.001367
Validation Loss: 0.00159131
Epoch [140/300], Train Loss: 0.001418
Validation Loss: 0.00152266
Epoch [141/300], Train Loss: 0.001402
Validation Loss: 0.00150425
Epoch [142/300], Train Loss: 0.001376
Validation Loss: 0.00152249
Early stopping triggered

Evaluating model for: Freezer
Run 61/72 completed in 576.57 seconds with: {'MAE': np.float32(36.204002), 'MSE': np.float32(2741.7563), 'RMSE': np.float32(52.361782), 'SAE': np.float32(0.07243848), 'NDE': np.float32(0.36703694)}

Run 62/72: hidden=512, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Freezer
Dataset length: 2322 windows

Epoch [1/300], Train Loss: 0.006763
Validation Loss: 0.00606601
Epoch [2/300], Train Loss: 0.005945
Validation Loss: 0.00538589
Epoch [3/300], Train Loss: 0.005861
Validation Loss: 0.00551109
Epoch [4/300], Train Loss: 0.005812
Validation Loss: 0.00536546
Epoch [5/300], Train Loss: 0.005735
Validation Loss: 0.00533523
Epoch [6/300], Train Loss: 0.005289
Validation Loss: 0.00440938
Epoch [7/300], Train Loss: 0.004256
Validation Loss: 0.00393754
Epoch [8/300], Train Loss: 0.003698
Validation Loss: 0.00327919
Epoch [9/300], Train Loss: 0.003113
Validation Loss: 0.00286416
Epoch [10/300], Train Loss: 0.002673
Validation Loss: 0.00255191
Epoch [11/300], Train Loss: 0.002494
Validation Loss: 0.00240716
Epoch [12/300], Train Loss: 0.002521
Validation Loss: 0.00261480
Epoch [13/300], Train Loss: 0.002442
Validation Loss: 0.00224078
Epoch [14/300], Train Loss: 0.002263
Validation Loss: 0.00226705
Epoch [15/300], Train Loss: 0.002294
Validation Loss: 0.00242225
Epoch [16/300], Train Loss: 0.002290
Validation Loss: 0.00224410
Epoch [17/300], Train Loss: 0.002162
Validation Loss: 0.00224606
Epoch [18/300], Train Loss: 0.002115
Validation Loss: 0.00215993
Epoch [19/300], Train Loss: 0.002108
Validation Loss: 0.00213756
Epoch [20/300], Train Loss: 0.002082
Validation Loss: 0.00217937
Epoch [21/300], Train Loss: 0.002073
Validation Loss: 0.00212232
Epoch [22/300], Train Loss: 0.002047
Validation Loss: 0.00212083
Epoch [23/300], Train Loss: 0.002098
Validation Loss: 0.00216028
Epoch [24/300], Train Loss: 0.002090
Validation Loss: 0.00211339
Epoch [25/300], Train Loss: 0.002078
Validation Loss: 0.00211213
Epoch [26/300], Train Loss: 0.002104
Validation Loss: 0.00213142
Epoch [27/300], Train Loss: 0.002078
Validation Loss: 0.00217707
Epoch [28/300], Train Loss: 0.002010
Validation Loss: 0.00206012
Epoch [29/300], Train Loss: 0.002012
Validation Loss: 0.00202977
Epoch [30/300], Train Loss: 0.001972
Validation Loss: 0.00201168
Epoch [31/300], Train Loss: 0.001938
Validation Loss: 0.00196312
Epoch [32/300], Train Loss: 0.001892
Validation Loss: 0.00196540
Epoch [33/300], Train Loss: 0.001875
Validation Loss: 0.00196549
Epoch [34/300], Train Loss: 0.001869
Validation Loss: 0.00191226
Epoch [35/300], Train Loss: 0.001807
Validation Loss: 0.00189903
Epoch [36/300], Train Loss: 0.001805
Validation Loss: 0.00189249
Epoch [37/300], Train Loss: 0.001836
Validation Loss: 0.00187245
Epoch [38/300], Train Loss: 0.001766
Validation Loss: 0.00191384
Epoch [39/300], Train Loss: 0.001751
Validation Loss: 0.00187415
Epoch [40/300], Train Loss: 0.001730
Validation Loss: 0.00182154
Epoch [41/300], Train Loss: 0.001721
Validation Loss: 0.00185444
Epoch [42/300], Train Loss: 0.001711
Validation Loss: 0.00184084
Epoch [43/300], Train Loss: 0.001687
Validation Loss: 0.00180067
Epoch [44/300], Train Loss: 0.001682
Validation Loss: 0.00181340
Epoch [45/300], Train Loss: 0.001674
Validation Loss: 0.00179257
Epoch [46/300], Train Loss: 0.001659
Validation Loss: 0.00179080
Epoch [47/300], Train Loss: 0.001661
Validation Loss: 0.00181080
Epoch [48/300], Train Loss: 0.001659
Validation Loss: 0.00182214
Epoch [49/300], Train Loss: 0.001658
Validation Loss: 0.00179472
Epoch [50/300], Train Loss: 0.001661
Validation Loss: 0.00178443
Epoch [51/300], Train Loss: 0.001660
Validation Loss: 0.00177730
Epoch [52/300], Train Loss: 0.001620
Validation Loss: 0.00180089
Epoch [53/300], Train Loss: 0.001672
Validation Loss: 0.00177444
Epoch [54/300], Train Loss: 0.001616
Validation Loss: 0.00178259
Epoch [55/300], Train Loss: 0.001635
Validation Loss: 0.00176496
Epoch [56/300], Train Loss: 0.001632
Validation Loss: 0.00176924
Epoch [57/300], Train Loss: 0.001655
Validation Loss: 0.00183311
Epoch [58/300], Train Loss: 0.001654
Validation Loss: 0.00181578
Epoch [59/300], Train Loss: 0.001616
Validation Loss: 0.00176989
Epoch [60/300], Train Loss: 0.001644
Validation Loss: 0.00177480
Epoch [61/300], Train Loss: 0.001647
Validation Loss: 0.00175920
Epoch [62/300], Train Loss: 0.001616
Validation Loss: 0.00176743
Epoch [63/300], Train Loss: 0.001613
Validation Loss: 0.00177437
Epoch [64/300], Train Loss: 0.001639
Validation Loss: 0.00176009
Epoch [65/300], Train Loss: 0.001602
Validation Loss: 0.00178394
Epoch [66/300], Train Loss: 0.001626
Validation Loss: 0.00182421
Epoch [67/300], Train Loss: 0.001666
Validation Loss: 0.00184523
Epoch [68/300], Train Loss: 0.001652
Validation Loss: 0.00180492
Epoch [69/300], Train Loss: 0.001627
Validation Loss: 0.00179921
Epoch [70/300], Train Loss: 0.001604
Validation Loss: 0.00175155
Epoch [71/300], Train Loss: 0.001585
Validation Loss: 0.00175303
Epoch [72/300], Train Loss: 0.001593
Validation Loss: 0.00175442
Epoch [73/300], Train Loss: 0.001608
Validation Loss: 0.00175855
Epoch [74/300], Train Loss: 0.001615
Validation Loss: 0.00175528
Epoch [75/300], Train Loss: 0.001593
Validation Loss: 0.00174457
Epoch [76/300], Train Loss: 0.001604
Validation Loss: 0.00174418
Epoch [77/300], Train Loss: 0.001601
Validation Loss: 0.00175999
Epoch [78/300], Train Loss: 0.001597
Validation Loss: 0.00176866
Epoch [79/300], Train Loss: 0.001597
Validation Loss: 0.00173723
Epoch [80/300], Train Loss: 0.001570
Validation Loss: 0.00175041
Epoch [81/300], Train Loss: 0.001590
Validation Loss: 0.00173296
Epoch [82/300], Train Loss: 0.001587
Validation Loss: 0.00173952
Epoch [83/300], Train Loss: 0.001588
Validation Loss: 0.00175924
Epoch [84/300], Train Loss: 0.001575
Validation Loss: 0.00173775
Epoch [85/300], Train Loss: 0.001586
Validation Loss: 0.00173352
Epoch [86/300], Train Loss: 0.001575
Validation Loss: 0.00173571
Epoch [87/300], Train Loss: 0.001572
Validation Loss: 0.00173787
Epoch [88/300], Train Loss: 0.001614
Validation Loss: 0.00172750
Epoch [89/300], Train Loss: 0.001568
Validation Loss: 0.00173570
Epoch [90/300], Train Loss: 0.001570
Validation Loss: 0.00173204
Epoch [91/300], Train Loss: 0.001577
Validation Loss: 0.00176533
Epoch [92/300], Train Loss: 0.001603
Validation Loss: 0.00176238
Epoch [93/300], Train Loss: 0.001571
Validation Loss: 0.00176780
Epoch [94/300], Train Loss: 0.001563
Validation Loss: 0.00172463
Epoch [95/300], Train Loss: 0.001555
Validation Loss: 0.00173095
Epoch [96/300], Train Loss: 0.001552
Validation Loss: 0.00172376
Epoch [97/300], Train Loss: 0.001581
Validation Loss: 0.00172829
Epoch [98/300], Train Loss: 0.001571
Validation Loss: 0.00173082
Epoch [99/300], Train Loss: 0.001557
Validation Loss: 0.00172428
Epoch [100/300], Train Loss: 0.001571
Validation Loss: 0.00175123
Epoch [101/300], Train Loss: 0.001573
Validation Loss: 0.00172757
Epoch [102/300], Train Loss: 0.001567
Validation Loss: 0.00175571
Epoch [103/300], Train Loss: 0.001529
Validation Loss: 0.00171360
Epoch [104/300], Train Loss: 0.001544
Validation Loss: 0.00171750
Epoch [105/300], Train Loss: 0.001512
Validation Loss: 0.00169690
Epoch [106/300], Train Loss: 0.001530
Validation Loss: 0.00168806
Epoch [107/300], Train Loss: 0.001529
Validation Loss: 0.00170678
Epoch [108/300], Train Loss: 0.001529
Validation Loss: 0.00172288
Epoch [109/300], Train Loss: 0.001523
Validation Loss: 0.00167787
Epoch [110/300], Train Loss: 0.001504
Validation Loss: 0.00168067
Epoch [111/300], Train Loss: 0.001503
Validation Loss: 0.00170753
Epoch [112/300], Train Loss: 0.001516
Validation Loss: 0.00170548
Epoch [113/300], Train Loss: 0.001536
Validation Loss: 0.00172727
Epoch [114/300], Train Loss: 0.001562
Validation Loss: 0.00168591
Epoch [115/300], Train Loss: 0.001534
Validation Loss: 0.00170992
Epoch [116/300], Train Loss: 0.001521
Validation Loss: 0.00167201
Epoch [117/300], Train Loss: 0.001503
Validation Loss: 0.00167840
Epoch [118/300], Train Loss: 0.001491
Validation Loss: 0.00167826
Epoch [119/300], Train Loss: 0.001495
Validation Loss: 0.00167192
Epoch [120/300], Train Loss: 0.001518
Validation Loss: 0.00165885
Epoch [121/300], Train Loss: 0.001502
Validation Loss: 0.00166719
Epoch [122/300], Train Loss: 0.001500
Validation Loss: 0.00165477
Epoch [123/300], Train Loss: 0.001489
Validation Loss: 0.00164819
Epoch [124/300], Train Loss: 0.001475
Validation Loss: 0.00164768
Epoch [125/300], Train Loss: 0.001468
Validation Loss: 0.00165443
Epoch [126/300], Train Loss: 0.001475
Validation Loss: 0.00164202
Epoch [127/300], Train Loss: 0.001483
Validation Loss: 0.00165117
Epoch [128/300], Train Loss: 0.001474
Validation Loss: 0.00165124
Epoch [129/300], Train Loss: 0.001474
Validation Loss: 0.00162984
Epoch [130/300], Train Loss: 0.001466
Validation Loss: 0.00163443
Epoch [131/300], Train Loss: 0.001455
Validation Loss: 0.00162096
Epoch [132/300], Train Loss: 0.001472
Validation Loss: 0.00161728
Epoch [133/300], Train Loss: 0.001441
Validation Loss: 0.00162466
Epoch [134/300], Train Loss: 0.001456
Validation Loss: 0.00162552
Epoch [135/300], Train Loss: 0.001444
Validation Loss: 0.00164614
Epoch [136/300], Train Loss: 0.001464
Validation Loss: 0.00160816
Epoch [137/300], Train Loss: 0.001456
Validation Loss: 0.00166073
Epoch [138/300], Train Loss: 0.001448
Validation Loss: 0.00170186
Epoch [139/300], Train Loss: 0.001453
Validation Loss: 0.00161455
Epoch [140/300], Train Loss: 0.001430
Validation Loss: 0.00161023
Epoch [141/300], Train Loss: 0.001459
Validation Loss: 0.00162285
Epoch [142/300], Train Loss: 0.001469
Validation Loss: 0.00161018
Epoch [143/300], Train Loss: 0.001434
Validation Loss: 0.00165665
Epoch [144/300], Train Loss: 0.001470
Validation Loss: 0.00169071
Epoch [145/300], Train Loss: 0.001459
Validation Loss: 0.00170056
Epoch [146/300], Train Loss: 0.001449
Validation Loss: 0.00162149
Early stopping triggered

Evaluating model for: Freezer
Run 62/72 completed in 760.18 seconds with: {'MAE': np.float32(37.36045), 'MSE': np.float32(2890.557), 'RMSE': np.float32(53.7639), 'SAE': np.float32(0.02868122), 'NDE': np.float32(0.37686524)}

Run 63/72: hidden=512, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Freezer
Dataset length: 2322 windows

Epoch [1/300], Train Loss: 0.008560
Validation Loss: 0.00661776
Epoch [2/300], Train Loss: 0.006087
Validation Loss: 0.00541574
Epoch [3/300], Train Loss: 0.005923
Validation Loss: 0.00558700
Epoch [4/300], Train Loss: 0.005876
Validation Loss: 0.00542893
Epoch [5/300], Train Loss: 0.005862
Validation Loss: 0.00549485
Epoch [6/300], Train Loss: 0.005828
Validation Loss: 0.00542382
Epoch [7/300], Train Loss: 0.005577
Validation Loss: 0.00471795
Epoch [8/300], Train Loss: 0.004740
Validation Loss: 0.00432210
Epoch [9/300], Train Loss: 0.004073
Validation Loss: 0.00375598
Epoch [10/300], Train Loss: 0.003049
Validation Loss: 0.00321301
Epoch [11/300], Train Loss: 0.002723
Validation Loss: 0.00254148
Epoch [12/300], Train Loss: 0.002618
Validation Loss: 0.00246125
Epoch [13/300], Train Loss: 0.002403
Validation Loss: 0.00250820
Epoch [14/300], Train Loss: 0.002389
Validation Loss: 0.00237783
Epoch [15/300], Train Loss: 0.002265
Validation Loss: 0.00229411
Epoch [16/300], Train Loss: 0.002158
Validation Loss: 0.00220994
Epoch [17/300], Train Loss: 0.002109
Validation Loss: 0.00223582
Epoch [18/300], Train Loss: 0.002273
Validation Loss: 0.00255153
Epoch [19/300], Train Loss: 0.002181
Validation Loss: 0.00222745
Epoch [20/300], Train Loss: 0.002049
Validation Loss: 0.00225899
Epoch [21/300], Train Loss: 0.002098
Validation Loss: 0.00208788
Epoch [22/300], Train Loss: 0.002149
Validation Loss: 0.00211010
Epoch [23/300], Train Loss: 0.002046
Validation Loss: 0.00215155
Epoch [24/300], Train Loss: 0.002031
Validation Loss: 0.00214702
Epoch [25/300], Train Loss: 0.002073
Validation Loss: 0.00211065
Epoch [26/300], Train Loss: 0.001988
Validation Loss: 0.00235249
Epoch [27/300], Train Loss: 0.002247
Validation Loss: 0.00222791
Epoch [28/300], Train Loss: 0.001996
Validation Loss: 0.00208550
Epoch [29/300], Train Loss: 0.001969
Validation Loss: 0.00208607
Epoch [30/300], Train Loss: 0.001942
Validation Loss: 0.00223075
Epoch [31/300], Train Loss: 0.005090
Validation Loss: 0.00556047
Epoch [32/300], Train Loss: 0.004902
Validation Loss: 0.00344576
Epoch [33/300], Train Loss: 0.003271
Validation Loss: 0.00275434
Epoch [34/300], Train Loss: 0.002557
Validation Loss: 0.00236813
Epoch [35/300], Train Loss: 0.002319
Validation Loss: 0.00228270
Epoch [36/300], Train Loss: 0.002275
Validation Loss: 0.00228289
Epoch [37/300], Train Loss: 0.002247
Validation Loss: 0.00224083
Epoch [38/300], Train Loss: 0.002191
Validation Loss: 0.00220829
Early stopping triggered

Evaluating model for: Freezer
Run 63/72 completed in 230.34 seconds with: {'MAE': np.float32(43.361107), 'MSE': np.float32(3936.042), 'RMSE': np.float32(62.737885), 'SAE': np.float32(0.03352448), 'NDE': np.float32(0.43976957)}

Run 64/72: hidden=512, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Freezer
Dataset length: 2322 windows

Epoch [1/300], Train Loss: 0.007057
Validation Loss: 0.00613597
Epoch [2/300], Train Loss: 0.005958
Validation Loss: 0.00539646
Epoch [3/300], Train Loss: 0.005883
Validation Loss: 0.00553959
Epoch [4/300], Train Loss: 0.005863
Validation Loss: 0.00543495
Epoch [5/300], Train Loss: 0.005862
Validation Loss: 0.00548549
Epoch [6/300], Train Loss: 0.005863
Validation Loss: 0.00545863
Epoch [7/300], Train Loss: 0.005843
Validation Loss: 0.00533055
Epoch [8/300], Train Loss: 0.005140
Validation Loss: 0.00393727
Epoch [9/300], Train Loss: 0.003815
Validation Loss: 0.00327026
Epoch [10/300], Train Loss: 0.002912
Validation Loss: 0.00277929
Epoch [11/300], Train Loss: 0.002942
Validation Loss: 0.00344407
Epoch [12/300], Train Loss: 0.003388
Validation Loss: 0.00294933
Epoch [13/300], Train Loss: 0.002676
Validation Loss: 0.00262968
Epoch [14/300], Train Loss: 0.002441
Validation Loss: 0.00251995
Epoch [15/300], Train Loss: 0.002391
Validation Loss: 0.00245599
Epoch [16/300], Train Loss: 0.002451
Validation Loss: 0.00261285
Epoch [17/300], Train Loss: 0.004117
Validation Loss: 0.00520634
Epoch [18/300], Train Loss: 0.005836
Validation Loss: 0.00508041
Epoch [19/300], Train Loss: 0.005272
Validation Loss: 0.00446174
Epoch [20/300], Train Loss: 0.003749
Validation Loss: 0.00291252
Epoch [21/300], Train Loss: 0.002848
Validation Loss: 0.00273163
Epoch [22/300], Train Loss: 0.002727
Validation Loss: 0.00267002
Epoch [23/300], Train Loss: 0.002664
Validation Loss: 0.00258736
Epoch [24/300], Train Loss: 0.002589
Validation Loss: 0.00254471
Epoch [25/300], Train Loss: 0.002598
Validation Loss: 0.00254097
Early stopping triggered

Evaluating model for: Freezer
Run 64/72 completed in 193.59 seconds with: {'MAE': np.float32(48.009186), 'MSE': np.float32(4889.22), 'RMSE': np.float32(69.92296), 'SAE': np.float32(0.12654167), 'NDE': np.float32(0.49013433)}

Run 65/72: hidden=512, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Freezer
Dataset length: 2262 windows

Epoch [1/300], Train Loss: 0.009579
Validation Loss: 0.00597544
Epoch [2/300], Train Loss: 0.005914
Validation Loss: 0.00597197
Epoch [3/300], Train Loss: 0.005841
Validation Loss: 0.00583165
Epoch [4/300], Train Loss: 0.005711
Validation Loss: 0.00574158
Epoch [5/300], Train Loss: 0.005595
Validation Loss: 0.00556733
Epoch [6/300], Train Loss: 0.005328
Validation Loss: 0.00519511
Epoch [7/300], Train Loss: 0.004872
Validation Loss: 0.00463965
Epoch [8/300], Train Loss: 0.004453
Validation Loss: 0.00442635
Epoch [9/300], Train Loss: 0.004239
Validation Loss: 0.00422971
Epoch [10/300], Train Loss: 0.004026
Validation Loss: 0.00389908
Epoch [11/300], Train Loss: 0.003739
Validation Loss: 0.00369191
Epoch [12/300], Train Loss: 0.003405
Validation Loss: 0.00304012
Epoch [13/300], Train Loss: 0.002917
Validation Loss: 0.00263847
Epoch [14/300], Train Loss: 0.002671
Validation Loss: 0.00248484
Epoch [15/300], Train Loss: 0.002447
Validation Loss: 0.00237309
Epoch [16/300], Train Loss: 0.002368
Validation Loss: 0.00226889
Epoch [17/300], Train Loss: 0.002341
Validation Loss: 0.00217788
Epoch [18/300], Train Loss: 0.002279
Validation Loss: 0.00216270
Epoch [19/300], Train Loss: 0.002119
Validation Loss: 0.00205003
Epoch [20/300], Train Loss: 0.002111
Validation Loss: 0.00197707
Epoch [21/300], Train Loss: 0.002033
Validation Loss: 0.00209224
Epoch [22/300], Train Loss: 0.002008
Validation Loss: 0.00188417
Epoch [23/300], Train Loss: 0.001872
Validation Loss: 0.00184579
Epoch [24/300], Train Loss: 0.001878
Validation Loss: 0.00182681
Epoch [25/300], Train Loss: 0.001815
Validation Loss: 0.00192649
Epoch [26/300], Train Loss: 0.001845
Validation Loss: 0.00182266
Epoch [27/300], Train Loss: 0.001811
Validation Loss: 0.00188978
Epoch [28/300], Train Loss: 0.001812
Validation Loss: 0.00235330
Epoch [29/300], Train Loss: 0.002015
Validation Loss: 0.00173214
Epoch [30/300], Train Loss: 0.001894
Validation Loss: 0.00181681
Epoch [31/300], Train Loss: 0.001796
Validation Loss: 0.00172933
Epoch [32/300], Train Loss: 0.001802
Validation Loss: 0.00170927
Epoch [33/300], Train Loss: 0.001832
Validation Loss: 0.00173395
Epoch [34/300], Train Loss: 0.001783
Validation Loss: 0.00175729
Epoch [35/300], Train Loss: 0.001883
Validation Loss: 0.00168037
Epoch [36/300], Train Loss: 0.001779
Validation Loss: 0.00168504
Epoch [37/300], Train Loss: 0.001769
Validation Loss: 0.00166934
Epoch [38/300], Train Loss: 0.001737
Validation Loss: 0.00167830
Epoch [39/300], Train Loss: 0.001759
Validation Loss: 0.00170785
Epoch [40/300], Train Loss: 0.001730
Validation Loss: 0.00174055
Epoch [41/300], Train Loss: 0.001699
Validation Loss: 0.00166222
Epoch [42/300], Train Loss: 0.001727
Validation Loss: 0.00165577
Epoch [43/300], Train Loss: 0.001705
Validation Loss: 0.00164153
Epoch [44/300], Train Loss: 0.001716
Validation Loss: 0.00165968
Epoch [45/300], Train Loss: 0.001665
Validation Loss: 0.00165362
Epoch [46/300], Train Loss: 0.001739
Validation Loss: 0.00168476
Epoch [47/300], Train Loss: 0.001707
Validation Loss: 0.00163284
Epoch [48/300], Train Loss: 0.001723
Validation Loss: 0.00166493
Epoch [49/300], Train Loss: 0.001756
Validation Loss: 0.00163281
Epoch [50/300], Train Loss: 0.001705
Validation Loss: 0.00171203
Epoch [51/300], Train Loss: 0.001691
Validation Loss: 0.00175678
Epoch [52/300], Train Loss: 0.001704
Validation Loss: 0.00168955
Epoch [53/300], Train Loss: 0.001672
Validation Loss: 0.00168140
Epoch [54/300], Train Loss: 0.001720
Validation Loss: 0.00165661
Epoch [55/300], Train Loss: 0.001733
Validation Loss: 0.00165583
Epoch [56/300], Train Loss: 0.001660
Validation Loss: 0.00165574
Epoch [57/300], Train Loss: 0.001705
Validation Loss: 0.00160667
Epoch [58/300], Train Loss: 0.001696
Validation Loss: 0.00167393
Epoch [59/300], Train Loss: 0.001666
Validation Loss: 0.00160090
Epoch [60/300], Train Loss: 0.001682
Validation Loss: 0.00161249
Epoch [61/300], Train Loss: 0.001674
Validation Loss: 0.00161174
Epoch [62/300], Train Loss: 0.001670
Validation Loss: 0.00158878
Epoch [63/300], Train Loss: 0.001668
Validation Loss: 0.00159089
Epoch [64/300], Train Loss: 0.001634
Validation Loss: 0.00158219
Epoch [65/300], Train Loss: 0.001656
Validation Loss: 0.00158621
Epoch [66/300], Train Loss: 0.001669
Validation Loss: 0.00162259
Epoch [67/300], Train Loss: 0.001667
Validation Loss: 0.00157538
Epoch [68/300], Train Loss: 0.001708
Validation Loss: 0.00155605
Epoch [69/300], Train Loss: 0.001687
Validation Loss: 0.00158920
Epoch [70/300], Train Loss: 0.001621
Validation Loss: 0.00157715
Epoch [71/300], Train Loss: 0.001630
Validation Loss: 0.00154863
Epoch [72/300], Train Loss: 0.001622
Validation Loss: 0.00155572
Epoch [73/300], Train Loss: 0.001558
Validation Loss: 0.00158066
Epoch [74/300], Train Loss: 0.001740
Validation Loss: 0.00161353
Epoch [75/300], Train Loss: 0.001690
Validation Loss: 0.00153938
Epoch [76/300], Train Loss: 0.001629
Validation Loss: 0.00154051
Epoch [77/300], Train Loss: 0.001616
Validation Loss: 0.00162298
Epoch [78/300], Train Loss: 0.001635
Validation Loss: 0.00163656
Epoch [79/300], Train Loss: 0.001614
Validation Loss: 0.00162134
Epoch [80/300], Train Loss: 0.001678
Validation Loss: 0.00153071
Epoch [81/300], Train Loss: 0.001603
Validation Loss: 0.00156189
Epoch [82/300], Train Loss: 0.001605
Validation Loss: 0.00157003
Epoch [83/300], Train Loss: 0.001653
Validation Loss: 0.00157494
Epoch [84/300], Train Loss: 0.001549
Validation Loss: 0.00152868
Epoch [85/300], Train Loss: 0.001591
Validation Loss: 0.00151741
Epoch [86/300], Train Loss: 0.001629
Validation Loss: 0.00151649
Epoch [87/300], Train Loss: 0.001637
Validation Loss: 0.00160813
Epoch [88/300], Train Loss: 0.001646
Validation Loss: 0.00153205
Epoch [89/300], Train Loss: 0.001600
Validation Loss: 0.00152552
Epoch [90/300], Train Loss: 0.001637
Validation Loss: 0.00153752
Epoch [91/300], Train Loss: 0.001570
Validation Loss: 0.00154886
Epoch [92/300], Train Loss: 0.001565
Validation Loss: 0.00151121
Epoch [93/300], Train Loss: 0.001637
Validation Loss: 0.00150854
Epoch [94/300], Train Loss: 0.001586
Validation Loss: 0.00150479
Epoch [95/300], Train Loss: 0.001623
Validation Loss: 0.00150868
Epoch [96/300], Train Loss: 0.001684
Validation Loss: 0.00154225
Epoch [97/300], Train Loss: 0.001548
Validation Loss: 0.00150973
Epoch [98/300], Train Loss: 0.001632
Validation Loss: 0.00150589
Epoch [99/300], Train Loss: 0.001613
Validation Loss: 0.00150825
Epoch [100/300], Train Loss: 0.001566
Validation Loss: 0.00149352
Epoch [101/300], Train Loss: 0.001544
Validation Loss: 0.00149942
Epoch [102/300], Train Loss: 0.001607
Validation Loss: 0.00151424
Epoch [103/300], Train Loss: 0.001572
Validation Loss: 0.00152962
Epoch [104/300], Train Loss: 0.001550
Validation Loss: 0.00148790
Epoch [105/300], Train Loss: 0.001535
Validation Loss: 0.00148927
Epoch [106/300], Train Loss: 0.001516
Validation Loss: 0.00148603
Epoch [107/300], Train Loss: 0.001511
Validation Loss: 0.00152685
Epoch [108/300], Train Loss: 0.001574
Validation Loss: 0.00147825
Epoch [109/300], Train Loss: 0.001582
Validation Loss: 0.00150144
Epoch [110/300], Train Loss: 0.001533
Validation Loss: 0.00151612
Epoch [111/300], Train Loss: 0.001553
Validation Loss: 0.00153793
Epoch [112/300], Train Loss: 0.001537
Validation Loss: 0.00148886
Epoch [113/300], Train Loss: 0.001548
Validation Loss: 0.00148958
Epoch [114/300], Train Loss: 0.001548
Validation Loss: 0.00147163
Epoch [115/300], Train Loss: 0.001586
Validation Loss: 0.00146920
Epoch [116/300], Train Loss: 0.001568
Validation Loss: 0.00146853
Epoch [117/300], Train Loss: 0.001568
Validation Loss: 0.00148059
Epoch [118/300], Train Loss: 0.001517
Validation Loss: 0.00154785
Epoch [119/300], Train Loss: 0.001609
Validation Loss: 0.00149598
Epoch [120/300], Train Loss: 0.001522
Validation Loss: 0.00147690
Epoch [121/300], Train Loss: 0.001546
Validation Loss: 0.00147270
Epoch [122/300], Train Loss: 0.001562
Validation Loss: 0.00148592
Epoch [123/300], Train Loss: 0.001524
Validation Loss: 0.00146975
Epoch [124/300], Train Loss: 0.001549
Validation Loss: 0.00149732
Epoch [125/300], Train Loss: 0.001565
Validation Loss: 0.00146869
Epoch [126/300], Train Loss: 0.001615
Validation Loss: 0.00155934
Early stopping triggered

Evaluating model for: Freezer
Run 65/72 completed in 716.86 seconds with: {'MAE': np.float32(34.09608), 'MSE': np.float32(2427.0112), 'RMSE': np.float32(49.264706), 'SAE': np.float32(0.011850049), 'NDE': np.float32(0.3680024)}

Run 66/72: hidden=512, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Freezer
Dataset length: 2262 windows

Epoch [1/300], Train Loss: 0.006999
Validation Loss: 0.00610479
Epoch [2/300], Train Loss: 0.005718
Validation Loss: 0.00597831
Epoch [3/300], Train Loss: 0.005783
Validation Loss: 0.00584522
Epoch [4/300], Train Loss: 0.005738
Validation Loss: 0.00580095
Epoch [5/300], Train Loss: 0.005641
Validation Loss: 0.00558113
Epoch [6/300], Train Loss: 0.005096
Validation Loss: 0.00504174
Epoch [7/300], Train Loss: 0.004510
Validation Loss: 0.00379252
Epoch [8/300], Train Loss: 0.003558
Validation Loss: 0.00330869
Epoch [9/300], Train Loss: 0.003137
Validation Loss: 0.00290618
Epoch [10/300], Train Loss: 0.002669
Validation Loss: 0.00259778
Epoch [11/300], Train Loss: 0.002526
Validation Loss: 0.00253950
Epoch [12/300], Train Loss: 0.002493
Validation Loss: 0.00263726
Epoch [13/300], Train Loss: 0.003090
Validation Loss: 0.00260446
Epoch [14/300], Train Loss: 0.002617
Validation Loss: 0.00214866
Epoch [15/300], Train Loss: 0.003143
Validation Loss: 0.00472277
Epoch [16/300], Train Loss: 0.004787
Validation Loss: 0.00443801
Epoch [17/300], Train Loss: 0.003897
Validation Loss: 0.00317853
Epoch [18/300], Train Loss: 0.002948
Validation Loss: 0.00264223
Epoch [19/300], Train Loss: 0.002602
Validation Loss: 0.00261531
Epoch [20/300], Train Loss: 0.002641
Validation Loss: 0.00254409
Epoch [21/300], Train Loss: 0.002592
Validation Loss: 0.00251519
Epoch [22/300], Train Loss: 0.002621
Validation Loss: 0.00248395
Epoch [23/300], Train Loss: 0.002427
Validation Loss: 0.00249680
Epoch [24/300], Train Loss: 0.002477
Validation Loss: 0.00245434
Early stopping triggered

Evaluating model for: Freezer
Run 66/72 completed in 183.13 seconds with: {'MAE': np.float32(41.543747), 'MSE': np.float32(3800.1013), 'RMSE': np.float32(61.644962), 'SAE': np.float32(0.103616364), 'NDE': np.float32(0.46048176)}

Run 67/72: hidden=512, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Freezer
Dataset length: 2262 windows

Epoch [1/300], Train Loss: 0.009677
Validation Loss: 0.00599090
Epoch [2/300], Train Loss: 0.005837
Validation Loss: 0.00610971
Epoch [3/300], Train Loss: 0.005889
Validation Loss: 0.00590194
Epoch [4/300], Train Loss: 0.005815
Validation Loss: 0.00591373
Epoch [5/300], Train Loss: 0.005814
Validation Loss: 0.00586896
Epoch [6/300], Train Loss: 0.005770
Validation Loss: 0.00580727
Epoch [7/300], Train Loss: 0.005704
Validation Loss: 0.00556554
Epoch [8/300], Train Loss: 0.004609
Validation Loss: 0.00360431
Epoch [9/300], Train Loss: 0.003302
Validation Loss: 0.00301865
Epoch [10/300], Train Loss: 0.002866
Validation Loss: 0.00290298
Epoch [11/300], Train Loss: 0.002689
Validation Loss: 0.00266835
Epoch [12/300], Train Loss: 0.002613
Validation Loss: 0.00250358
Epoch [13/300], Train Loss: 0.002612
Validation Loss: 0.00225219
Epoch [14/300], Train Loss: 0.002556
Validation Loss: 0.00229237
Epoch [15/300], Train Loss: 0.002497
Validation Loss: 0.00238906
Epoch [16/300], Train Loss: 0.002368
Validation Loss: 0.00220548
Epoch [17/300], Train Loss: 0.002299
Validation Loss: 0.00216125
Epoch [18/300], Train Loss: 0.002258
Validation Loss: 0.00196676
Epoch [19/300], Train Loss: 0.002062
Validation Loss: 0.00193280
Epoch [20/300], Train Loss: 0.002158
Validation Loss: 0.00194559
Epoch [21/300], Train Loss: 0.002143
Validation Loss: 0.00198218
Epoch [22/300], Train Loss: 0.002111
Validation Loss: 0.00191891
Epoch [23/300], Train Loss: 0.001975
Validation Loss: 0.00195076
Epoch [24/300], Train Loss: 0.002044
Validation Loss: 0.00209392
Epoch [25/300], Train Loss: 0.002028
Validation Loss: 0.00199069
Epoch [26/300], Train Loss: 0.002081
Validation Loss: 0.00193642
Epoch [27/300], Train Loss: 0.001986
Validation Loss: 0.00191103
Epoch [28/300], Train Loss: 0.001907
Validation Loss: 0.00191514
Epoch [29/300], Train Loss: 0.002058
Validation Loss: 0.00214061
Epoch [30/300], Train Loss: 0.002057
Validation Loss: 0.00194383
Epoch [31/300], Train Loss: 0.001973
Validation Loss: 0.00188129
Epoch [32/300], Train Loss: 0.002024
Validation Loss: 0.00186787
Epoch [33/300], Train Loss: 0.001972
Validation Loss: 0.00181788
Epoch [34/300], Train Loss: 0.001900
Validation Loss: 0.00189412
Epoch [35/300], Train Loss: 0.002064
Validation Loss: 0.00180915
Epoch [36/300], Train Loss: 0.002031
Validation Loss: 0.00197068
Epoch [37/300], Train Loss: 0.005034
Validation Loss: 0.00515009
Epoch [38/300], Train Loss: 0.003429
Validation Loss: 0.00231679
Epoch [39/300], Train Loss: 0.002609
Validation Loss: 0.00271720
Epoch [40/300], Train Loss: 0.002731
Validation Loss: 0.00233957
Epoch [41/300], Train Loss: 0.002147
Validation Loss: 0.00187847
Epoch [42/300], Train Loss: 0.002025
Validation Loss: 0.00201146
Epoch [43/300], Train Loss: 0.002028
Validation Loss: 0.00190636
Epoch [44/300], Train Loss: 0.001992
Validation Loss: 0.00186092
Epoch [45/300], Train Loss: 0.001883
Validation Loss: 0.00185703
Early stopping triggered

Evaluating model for: Freezer
Run 67/72 completed in 444.88 seconds with: {'MAE': np.float32(36.439575), 'MSE': np.float32(2893.5396), 'RMSE': np.float32(53.79163), 'SAE': np.float32(0.08202622), 'NDE': np.float32(0.4018179)}

Run 68/72: hidden=512, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Freezer
Dataset length: 2262 windows

Epoch [1/300], Train Loss: 0.006104
Validation Loss: 0.00590110
Epoch [2/300], Train Loss: 0.005729
Validation Loss: 0.00591516
Epoch [3/300], Train Loss: 0.005759
Validation Loss: 0.00589777
Epoch [4/300], Train Loss: 0.005809
Validation Loss: 0.00590130
Epoch [5/300], Train Loss: 0.005802
Validation Loss: 0.00585341
Epoch [6/300], Train Loss: 0.005388
Validation Loss: 0.00464367
Epoch [7/300], Train Loss: 0.003591
Validation Loss: 0.00304129
Epoch [8/300], Train Loss: 0.002968
Validation Loss: 0.00258433
Epoch [9/300], Train Loss: 0.002700
Validation Loss: 0.00225001
Epoch [10/300], Train Loss: 0.002400
Validation Loss: 0.00300459
Epoch [11/300], Train Loss: 0.002753
Validation Loss: 0.00217778
Epoch [12/300], Train Loss: 0.002309
Validation Loss: 0.00195721
Epoch [13/300], Train Loss: 0.002159
Validation Loss: 0.00190146
Epoch [14/300], Train Loss: 0.002125
Validation Loss: 0.00192870
Epoch [15/300], Train Loss: 0.002104
Validation Loss: 0.00191521
Epoch [16/300], Train Loss: 0.002049
Validation Loss: 0.00195186
Epoch [17/300], Train Loss: 0.002127
Validation Loss: 0.00187894
Epoch [18/300], Train Loss: 0.002094
Validation Loss: 0.00188430
Epoch [19/300], Train Loss: 0.001958
Validation Loss: 0.00185928
Epoch [20/300], Train Loss: 0.002033
Validation Loss: 0.00188406
Epoch [21/300], Train Loss: 0.002074
Validation Loss: 0.00189345
Epoch [22/300], Train Loss: 0.002080
Validation Loss: 0.00180262
Epoch [23/300], Train Loss: 0.001945
Validation Loss: 0.00189397
Epoch [24/300], Train Loss: 0.001970
Validation Loss: 0.00200641
Epoch [25/300], Train Loss: 0.002069
Validation Loss: 0.00345958
Epoch [26/300], Train Loss: 0.006030
Validation Loss: 0.00591204
Epoch [27/300], Train Loss: 0.005767
Validation Loss: 0.00582025
Epoch [28/300], Train Loss: 0.005610
Validation Loss: 0.00576104
Epoch [29/300], Train Loss: 0.005727
Validation Loss: 0.00564755
Epoch [30/300], Train Loss: 0.005774
Validation Loss: 0.00566719
Epoch [31/300], Train Loss: 0.005599
Validation Loss: 0.00566403
Epoch [32/300], Train Loss: 0.005796
Validation Loss: 0.00563602
Early stopping triggered

Evaluating model for: Freezer
Run 68/72 completed in 411.40 seconds with: {'MAE': np.float32(85.25113), 'MSE': np.float32(9665.697), 'RMSE': np.float32(98.31428), 'SAE': np.float32(0.03907662), 'NDE': np.float32(0.73439705)}

Run 69/72: hidden=512, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Freezer
Dataset length: 1146 windows

Epoch [1/300], Train Loss: 0.006389
Validation Loss: 0.00587193
Epoch [2/300], Train Loss: 0.005991
Validation Loss: 0.00585843
Epoch [3/300], Train Loss: 0.006001
Validation Loss: 0.00587225
Epoch [4/300], Train Loss: 0.006023
Validation Loss: 0.00580788
Epoch [5/300], Train Loss: 0.005804
Validation Loss: 0.00577110
Epoch [6/300], Train Loss: 0.005791
Validation Loss: 0.00575606
Epoch [7/300], Train Loss: 0.005525
Validation Loss: 0.00563063
Epoch [8/300], Train Loss: 0.005412
Validation Loss: 0.00554443
Epoch [9/300], Train Loss: 0.005366
Validation Loss: 0.00525765
Epoch [10/300], Train Loss: 0.004879
Validation Loss: 0.00484270
Epoch [11/300], Train Loss: 0.004454
Validation Loss: 0.00462760
Epoch [12/300], Train Loss: 0.004179
Validation Loss: 0.00453620
Epoch [13/300], Train Loss: 0.004059
Validation Loss: 0.00380720
Epoch [14/300], Train Loss: 0.003386
Validation Loss: 0.00341964
Epoch [15/300], Train Loss: 0.003134
Validation Loss: 0.00297907
Epoch [16/300], Train Loss: 0.002770
Validation Loss: 0.00269204
Epoch [17/300], Train Loss: 0.002513
Validation Loss: 0.00256174
Epoch [18/300], Train Loss: 0.002413
Validation Loss: 0.00290696
Epoch [19/300], Train Loss: 0.002389
Validation Loss: 0.00241964
Epoch [20/300], Train Loss: 0.002270
Validation Loss: 0.00234437
Epoch [21/300], Train Loss: 0.002165
Validation Loss: 0.00231009
Epoch [22/300], Train Loss: 0.002198
Validation Loss: 0.00227594
Epoch [23/300], Train Loss: 0.002174
Validation Loss: 0.00222481
Epoch [24/300], Train Loss: 0.001983
Validation Loss: 0.00218389
Epoch [25/300], Train Loss: 0.002128
Validation Loss: 0.00221947
Epoch [26/300], Train Loss: 0.001974
Validation Loss: 0.00218088
Epoch [27/300], Train Loss: 0.002010
Validation Loss: 0.00213133
Epoch [28/300], Train Loss: 0.002016
Validation Loss: 0.00215522
Epoch [29/300], Train Loss: 0.002007
Validation Loss: 0.00212755
Epoch [30/300], Train Loss: 0.001992
Validation Loss: 0.00216230
Epoch [31/300], Train Loss: 0.001952
Validation Loss: 0.00220718
Epoch [32/300], Train Loss: 0.001941
Validation Loss: 0.00214869
Epoch [33/300], Train Loss: 0.001959
Validation Loss: 0.00208028
Epoch [34/300], Train Loss: 0.001967
Validation Loss: 0.00206660
Epoch [35/300], Train Loss: 0.001870
Validation Loss: 0.00208511
Epoch [36/300], Train Loss: 0.001823
Validation Loss: 0.00206326
Epoch [37/300], Train Loss: 0.001874
Validation Loss: 0.00204843
Epoch [38/300], Train Loss: 0.001953
Validation Loss: 0.00208975
Epoch [39/300], Train Loss: 0.001926
Validation Loss: 0.00203028
Epoch [40/300], Train Loss: 0.001815
Validation Loss: 0.00208067
Epoch [41/300], Train Loss: 0.001938
Validation Loss: 0.00202560
Epoch [42/300], Train Loss: 0.001814
Validation Loss: 0.00201997
Epoch [43/300], Train Loss: 0.001839
Validation Loss: 0.00201568
Epoch [44/300], Train Loss: 0.001741
Validation Loss: 0.00201498
Epoch [45/300], Train Loss: 0.001902
Validation Loss: 0.00201356
Epoch [46/300], Train Loss: 0.001857
Validation Loss: 0.00200828
Epoch [47/300], Train Loss: 0.001813
Validation Loss: 0.00203033
Epoch [48/300], Train Loss: 0.001875
Validation Loss: 0.00198206
Epoch [49/300], Train Loss: 0.001766
Validation Loss: 0.00195845
Epoch [50/300], Train Loss: 0.001829
Validation Loss: 0.00200302
Epoch [51/300], Train Loss: 0.001795
Validation Loss: 0.00194980
Epoch [52/300], Train Loss: 0.001724
Validation Loss: 0.00203559
Epoch [53/300], Train Loss: 0.001801
Validation Loss: 0.00194794
Epoch [54/300], Train Loss: 0.001707
Validation Loss: 0.00194632
Epoch [55/300], Train Loss: 0.001743
Validation Loss: 0.00193950
Epoch [56/300], Train Loss: 0.001754
Validation Loss: 0.00192923
Epoch [57/300], Train Loss: 0.001754
Validation Loss: 0.00201678
Epoch [58/300], Train Loss: 0.001762
Validation Loss: 0.00193472
Epoch [59/300], Train Loss: 0.001735
Validation Loss: 0.00195027
Epoch [60/300], Train Loss: 0.001713
Validation Loss: 0.00192038
Epoch [61/300], Train Loss: 0.001710
Validation Loss: 0.00192421
Epoch [62/300], Train Loss: 0.001675
Validation Loss: 0.00194187
Epoch [63/300], Train Loss: 0.001730
Validation Loss: 0.00191890
Epoch [64/300], Train Loss: 0.001680
Validation Loss: 0.00192490
Epoch [65/300], Train Loss: 0.001726
Validation Loss: 0.00198756
Epoch [66/300], Train Loss: 0.001746
Validation Loss: 0.00199498
Epoch [67/300], Train Loss: 0.001699
Validation Loss: 0.00208009
Epoch [68/300], Train Loss: 0.001775
Validation Loss: 0.00188142
Epoch [69/300], Train Loss: 0.001655
Validation Loss: 0.00195668
Epoch [70/300], Train Loss: 0.001706
Validation Loss: 0.00190132
Epoch [71/300], Train Loss: 0.001819
Validation Loss: 0.00191093
Epoch [72/300], Train Loss: 0.001585
Validation Loss: 0.00191858
Epoch [73/300], Train Loss: 0.001767
Validation Loss: 0.00194541
Epoch [74/300], Train Loss: 0.001690
Validation Loss: 0.00185964
Epoch [75/300], Train Loss: 0.001744
Validation Loss: 0.00188700
Epoch [76/300], Train Loss: 0.001604
Validation Loss: 0.00191375
Epoch [77/300], Train Loss: 0.001803
Validation Loss: 0.00187405
Epoch [78/300], Train Loss: 0.001670
Validation Loss: 0.00185139
Epoch [79/300], Train Loss: 0.001671
Validation Loss: 0.00186516
Epoch [80/300], Train Loss: 0.001666
Validation Loss: 0.00184182
Epoch [81/300], Train Loss: 0.001625
Validation Loss: 0.00187093
Epoch [82/300], Train Loss: 0.001618
Validation Loss: 0.00185018
Epoch [83/300], Train Loss: 0.001540
Validation Loss: 0.00189916
Epoch [84/300], Train Loss: 0.001590
Validation Loss: 0.00192539
Epoch [85/300], Train Loss: 0.001632
Validation Loss: 0.00186814
Epoch [86/300], Train Loss: 0.001661
Validation Loss: 0.00184815
Epoch [87/300], Train Loss: 0.001668
Validation Loss: 0.00185326
Epoch [88/300], Train Loss: 0.001682
Validation Loss: 0.00183472
Epoch [89/300], Train Loss: 0.001534
Validation Loss: 0.00187462
Epoch [90/300], Train Loss: 0.001605
Validation Loss: 0.00183592
Epoch [91/300], Train Loss: 0.001667
Validation Loss: 0.00183496
Epoch [92/300], Train Loss: 0.001679
Validation Loss: 0.00194249
Epoch [93/300], Train Loss: 0.001692
Validation Loss: 0.00185053
Epoch [94/300], Train Loss: 0.001646
Validation Loss: 0.00182292
Epoch [95/300], Train Loss: 0.001623
Validation Loss: 0.00182613
Epoch [96/300], Train Loss: 0.001626
Validation Loss: 0.00182703
Epoch [97/300], Train Loss: 0.001636
Validation Loss: 0.00184415
Epoch [98/300], Train Loss: 0.001603
Validation Loss: 0.00182414
Epoch [99/300], Train Loss: 0.001639
Validation Loss: 0.00181613
Epoch [100/300], Train Loss: 0.001596
Validation Loss: 0.00180254
Epoch [101/300], Train Loss: 0.001589
Validation Loss: 0.00181868
Epoch [102/300], Train Loss: 0.001660
Validation Loss: 0.00182450
Epoch [103/300], Train Loss: 0.001621
Validation Loss: 0.00181025
Epoch [104/300], Train Loss: 0.001584
Validation Loss: 0.00187061
Epoch [105/300], Train Loss: 0.001633
Validation Loss: 0.00184993
Epoch [106/300], Train Loss: 0.001592
Validation Loss: 0.00183296
Epoch [107/300], Train Loss: 0.001701
Validation Loss: 0.00180417
Epoch [108/300], Train Loss: 0.001649
Validation Loss: 0.00179540
Epoch [109/300], Train Loss: 0.001616
Validation Loss: 0.00180499
Epoch [110/300], Train Loss: 0.001576
Validation Loss: 0.00180782
Epoch [111/300], Train Loss: 0.001561
Validation Loss: 0.00179509
Epoch [112/300], Train Loss: 0.001527
Validation Loss: 0.00178031
Epoch [113/300], Train Loss: 0.001553
Validation Loss: 0.00178406
Epoch [114/300], Train Loss: 0.001534
Validation Loss: 0.00178693
Epoch [115/300], Train Loss: 0.001487
Validation Loss: 0.00178411
Epoch [116/300], Train Loss: 0.001544
Validation Loss: 0.00177286
Epoch [117/300], Train Loss: 0.001557
Validation Loss: 0.00177802
Epoch [118/300], Train Loss: 0.001525
Validation Loss: 0.00176862
Epoch [119/300], Train Loss: 0.001511
Validation Loss: 0.00178034
Epoch [120/300], Train Loss: 0.001596
Validation Loss: 0.00177239
Epoch [121/300], Train Loss: 0.001549
Validation Loss: 0.00178821
Epoch [122/300], Train Loss: 0.001613
Validation Loss: 0.00176667
Epoch [123/300], Train Loss: 0.001530
Validation Loss: 0.00177432
Epoch [124/300], Train Loss: 0.001601
Validation Loss: 0.00176828
Epoch [125/300], Train Loss: 0.001506
Validation Loss: 0.00176417
Epoch [126/300], Train Loss: 0.001596
Validation Loss: 0.00177415
Epoch [127/300], Train Loss: 0.001617
Validation Loss: 0.00177461
Epoch [128/300], Train Loss: 0.001487
Validation Loss: 0.00176304
Epoch [129/300], Train Loss: 0.001537
Validation Loss: 0.00178728
Epoch [130/300], Train Loss: 0.001629
Validation Loss: 0.00177583
Epoch [131/300], Train Loss: 0.001501
Validation Loss: 0.00175080
Epoch [132/300], Train Loss: 0.001569
Validation Loss: 0.00175730
Epoch [133/300], Train Loss: 0.001506
Validation Loss: 0.00176173
Epoch [134/300], Train Loss: 0.001544
Validation Loss: 0.00178405
Epoch [135/300], Train Loss: 0.001572
Validation Loss: 0.00175509
Epoch [136/300], Train Loss: 0.001518
Validation Loss: 0.00175145
Epoch [137/300], Train Loss: 0.001537
Validation Loss: 0.00175531
Epoch [138/300], Train Loss: 0.001504
Validation Loss: 0.00174226
Epoch [139/300], Train Loss: 0.001565
Validation Loss: 0.00176386
Epoch [140/300], Train Loss: 0.001553
Validation Loss: 0.00175588
Epoch [141/300], Train Loss: 0.001522
Validation Loss: 0.00175339
Epoch [142/300], Train Loss: 0.001584
Validation Loss: 0.00174063
Epoch [143/300], Train Loss: 0.001555
Validation Loss: 0.00175567
Epoch [144/300], Train Loss: 0.001522
Validation Loss: 0.00174230
Epoch [145/300], Train Loss: 0.001528
Validation Loss: 0.00174142
Epoch [146/300], Train Loss: 0.001535
Validation Loss: 0.00174097
Epoch [147/300], Train Loss: 0.001626
Validation Loss: 0.00174076
Epoch [148/300], Train Loss: 0.001538
Validation Loss: 0.00173852
Epoch [149/300], Train Loss: 0.001571
Validation Loss: 0.00174527
Epoch [150/300], Train Loss: 0.001486
Validation Loss: 0.00174589
Epoch [151/300], Train Loss: 0.001489
Validation Loss: 0.00173897
Epoch [152/300], Train Loss: 0.001529
Validation Loss: 0.00175871
Epoch [153/300], Train Loss: 0.001498
Validation Loss: 0.00174462
Epoch [154/300], Train Loss: 0.001545
Validation Loss: 0.00173153
Epoch [155/300], Train Loss: 0.001601
Validation Loss: 0.00173373
Epoch [156/300], Train Loss: 0.001497
Validation Loss: 0.00173014
Epoch [157/300], Train Loss: 0.001556
Validation Loss: 0.00173697
Epoch [158/300], Train Loss: 0.001614
Validation Loss: 0.00172864
Epoch [159/300], Train Loss: 0.001564
Validation Loss: 0.00173376
Epoch [160/300], Train Loss: 0.001471
Validation Loss: 0.00175975
Epoch [161/300], Train Loss: 0.001683
Validation Loss: 0.00173931
Epoch [162/300], Train Loss: 0.001592
Validation Loss: 0.00174884
Epoch [163/300], Train Loss: 0.001516
Validation Loss: 0.00173751
Epoch [164/300], Train Loss: 0.001482
Validation Loss: 0.00172314
Epoch [165/300], Train Loss: 0.001518
Validation Loss: 0.00172382
Epoch [166/300], Train Loss: 0.001557
Validation Loss: 0.00172456
Epoch [167/300], Train Loss: 0.001528
Validation Loss: 0.00172631
Epoch [168/300], Train Loss: 0.001547
Validation Loss: 0.00172352
Epoch [169/300], Train Loss: 0.001551
Validation Loss: 0.00173505
Epoch [170/300], Train Loss: 0.001508
Validation Loss: 0.00173347
Epoch [171/300], Train Loss: 0.001486
Validation Loss: 0.00174248
Epoch [172/300], Train Loss: 0.001450
Validation Loss: 0.00172089
Epoch [173/300], Train Loss: 0.001543
Validation Loss: 0.00172393
Epoch [174/300], Train Loss: 0.001491
Validation Loss: 0.00172038
Epoch [175/300], Train Loss: 0.001446
Validation Loss: 0.00172388
Epoch [176/300], Train Loss: 0.001523
Validation Loss: 0.00172242
Epoch [177/300], Train Loss: 0.001452
Validation Loss: 0.00172477
Epoch [178/300], Train Loss: 0.001455
Validation Loss: 0.00172816
Epoch [179/300], Train Loss: 0.001468
Validation Loss: 0.00172242
Epoch [180/300], Train Loss: 0.001542
Validation Loss: 0.00171771
Epoch [181/300], Train Loss: 0.001533
Validation Loss: 0.00171650
Epoch [182/300], Train Loss: 0.001498
Validation Loss: 0.00171514
Epoch [183/300], Train Loss: 0.001551
Validation Loss: 0.00176873
Epoch [184/300], Train Loss: 0.001542
Validation Loss: 0.00171499
Epoch [185/300], Train Loss: 0.001539
Validation Loss: 0.00172955
Epoch [186/300], Train Loss: 0.001594
Validation Loss: 0.00172221
Epoch [187/300], Train Loss: 0.001582
Validation Loss: 0.00171287
Epoch [188/300], Train Loss: 0.001574
Validation Loss: 0.00171211
Epoch [189/300], Train Loss: 0.001488
Validation Loss: 0.00171593
Epoch [190/300], Train Loss: 0.001512
Validation Loss: 0.00171748
Epoch [191/300], Train Loss: 0.001484
Validation Loss: 0.00172533
Epoch [192/300], Train Loss: 0.001555
Validation Loss: 0.00171358
Epoch [193/300], Train Loss: 0.001573
Validation Loss: 0.00172642
Epoch [194/300], Train Loss: 0.001501
Validation Loss: 0.00171323
Epoch [195/300], Train Loss: 0.001476
Validation Loss: 0.00172100
Epoch [196/300], Train Loss: 0.001604
Validation Loss: 0.00171070
Epoch [197/300], Train Loss: 0.001540
Validation Loss: 0.00170675
Epoch [198/300], Train Loss: 0.001437
Validation Loss: 0.00170630
Epoch [199/300], Train Loss: 0.001401
Validation Loss: 0.00172005
Epoch [200/300], Train Loss: 0.001534
Validation Loss: 0.00171757
Epoch [201/300], Train Loss: 0.001600
Validation Loss: 0.00171156
Epoch [202/300], Train Loss: 0.001545
Validation Loss: 0.00172238
Epoch [203/300], Train Loss: 0.001431
Validation Loss: 0.00171000
Epoch [204/300], Train Loss: 0.001548
Validation Loss: 0.00171121
Epoch [205/300], Train Loss: 0.001449
Validation Loss: 0.00175911
Epoch [206/300], Train Loss: 0.001647
Validation Loss: 0.00174185
Epoch [207/300], Train Loss: 0.001532
Validation Loss: 0.00173521
Epoch [208/300], Train Loss: 0.001484
Validation Loss: 0.00173523
Early stopping triggered

Evaluating model for: Freezer
Run 69/72 completed in 607.23 seconds with: {'MAE': np.float32(30.047144), 'MSE': np.float32(1984.1881), 'RMSE': np.float32(44.544228), 'SAE': np.float32(0.06105614), 'NDE': np.float32(0.35015455)}

Run 70/72: hidden=512, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Freezer
Dataset length: 1146 windows

Epoch [1/300], Train Loss: 0.006694
Validation Loss: 0.00587193
Epoch [2/300], Train Loss: 0.006059
Validation Loss: 0.00586778
Epoch [3/300], Train Loss: 0.006034
Validation Loss: 0.00589830
Epoch [4/300], Train Loss: 0.006069
Validation Loss: 0.00583366
Epoch [5/300], Train Loss: 0.005862
Validation Loss: 0.00580550
Epoch [6/300], Train Loss: 0.005876
Validation Loss: 0.00578659
Epoch [7/300], Train Loss: 0.005635
Validation Loss: 0.00567449
Epoch [8/300], Train Loss: 0.005524
Validation Loss: 0.00546490
Epoch [9/300], Train Loss: 0.005228
Validation Loss: 0.00458741
Epoch [10/300], Train Loss: 0.004321
Validation Loss: 0.00381281
Epoch [11/300], Train Loss: 0.003572
Validation Loss: 0.00326356
Epoch [12/300], Train Loss: 0.003109
Validation Loss: 0.00308264
Epoch [13/300], Train Loss: 0.002825
Validation Loss: 0.00238440
Epoch [14/300], Train Loss: 0.002389
Validation Loss: 0.00239444
Epoch [15/300], Train Loss: 0.002402
Validation Loss: 0.00227697
Epoch [16/300], Train Loss: 0.002258
Validation Loss: 0.00227069
Epoch [17/300], Train Loss: 0.002234
Validation Loss: 0.00222472
Epoch [18/300], Train Loss: 0.002142
Validation Loss: 0.00228875
Epoch [19/300], Train Loss: 0.002100
Validation Loss: 0.00222372
Epoch [20/300], Train Loss: 0.002137
Validation Loss: 0.00218202
Epoch [21/300], Train Loss: 0.002083
Validation Loss: 0.00217934
Epoch [22/300], Train Loss: 0.002152
Validation Loss: 0.00217841
Epoch [23/300], Train Loss: 0.002130
Validation Loss: 0.00219833
Epoch [24/300], Train Loss: 0.001993
Validation Loss: 0.00215719
Epoch [25/300], Train Loss: 0.002115
Validation Loss: 0.00214959
Epoch [26/300], Train Loss: 0.001943
Validation Loss: 0.00215337
Epoch [27/300], Train Loss: 0.001995
Validation Loss: 0.00215510
Epoch [28/300], Train Loss: 0.002047
Validation Loss: 0.00210556
Epoch [29/300], Train Loss: 0.002029
Validation Loss: 0.00229817
Epoch [30/300], Train Loss: 0.002001
Validation Loss: 0.00206565
Epoch [31/300], Train Loss: 0.001921
Validation Loss: 0.00210384
Epoch [32/300], Train Loss: 0.001845
Validation Loss: 0.00206477
Epoch [33/300], Train Loss: 0.001872
Validation Loss: 0.00203931
Epoch [34/300], Train Loss: 0.001915
Validation Loss: 0.00199788
Epoch [35/300], Train Loss: 0.001813
Validation Loss: 0.00201876
Epoch [36/300], Train Loss: 0.001748
Validation Loss: 0.00197496
Epoch [37/300], Train Loss: 0.001809
Validation Loss: 0.00200504
Epoch [38/300], Train Loss: 0.001877
Validation Loss: 0.00200818
Epoch [39/300], Train Loss: 0.001857
Validation Loss: 0.00197169
Epoch [40/300], Train Loss: 0.001740
Validation Loss: 0.00197287
Epoch [41/300], Train Loss: 0.001874
Validation Loss: 0.00196547
Epoch [42/300], Train Loss: 0.001750
Validation Loss: 0.00195873
Epoch [43/300], Train Loss: 0.001799
Validation Loss: 0.00197034
Epoch [44/300], Train Loss: 0.001716
Validation Loss: 0.00194665
Epoch [45/300], Train Loss: 0.001871
Validation Loss: 0.00194612
Epoch [46/300], Train Loss: 0.001825
Validation Loss: 0.00195667
Epoch [47/300], Train Loss: 0.001778
Validation Loss: 0.00198856
Epoch [48/300], Train Loss: 0.001842
Validation Loss: 0.00195051
Epoch [49/300], Train Loss: 0.001733
Validation Loss: 0.00195021
Epoch [50/300], Train Loss: 0.001800
Validation Loss: 0.00195338
Epoch [51/300], Train Loss: 0.001770
Validation Loss: 0.00191521
Epoch [52/300], Train Loss: 0.001698
Validation Loss: 0.00196954
Epoch [53/300], Train Loss: 0.001766
Validation Loss: 0.00191137
Epoch [54/300], Train Loss: 0.001677
Validation Loss: 0.00191735
Epoch [55/300], Train Loss: 0.001720
Validation Loss: 0.00190645
Epoch [56/300], Train Loss: 0.001729
Validation Loss: 0.00190282
Epoch [57/300], Train Loss: 0.001722
Validation Loss: 0.00195165
Epoch [58/300], Train Loss: 0.001736
Validation Loss: 0.00195593
Epoch [59/300], Train Loss: 0.001716
Validation Loss: 0.00191310
Epoch [60/300], Train Loss: 0.001688
Validation Loss: 0.00192195
Epoch [61/300], Train Loss: 0.001696
Validation Loss: 0.00188202
Epoch [62/300], Train Loss: 0.001658
Validation Loss: 0.00196952
Epoch [63/300], Train Loss: 0.001717
Validation Loss: 0.00189788
Epoch [64/300], Train Loss: 0.001683
Validation Loss: 0.00188602
Epoch [65/300], Train Loss: 0.001732
Validation Loss: 0.00194330
Epoch [66/300], Train Loss: 0.001722
Validation Loss: 0.00190746
Epoch [67/300], Train Loss: 0.001660
Validation Loss: 0.00187377
Epoch [68/300], Train Loss: 0.001732
Validation Loss: 0.00187128
Epoch [69/300], Train Loss: 0.001633
Validation Loss: 0.00187782
Epoch [70/300], Train Loss: 0.001680
Validation Loss: 0.00189541
Epoch [71/300], Train Loss: 0.001802
Validation Loss: 0.00188443
Epoch [72/300], Train Loss: 0.001573
Validation Loss: 0.00188088
Epoch [73/300], Train Loss: 0.001713
Validation Loss: 0.00189849
Epoch [74/300], Train Loss: 0.001690
Validation Loss: 0.00187782
Epoch [75/300], Train Loss: 0.001762
Validation Loss: 0.00186539
Epoch [76/300], Train Loss: 0.001606
Validation Loss: 0.00188161
Epoch [77/300], Train Loss: 0.001791
Validation Loss: 0.00186088
Epoch [78/300], Train Loss: 0.001666
Validation Loss: 0.00188386
Epoch [79/300], Train Loss: 0.001694
Validation Loss: 0.00188345
Epoch [80/300], Train Loss: 0.001689
Validation Loss: 0.00187552
Epoch [81/300], Train Loss: 0.001639
Validation Loss: 0.00187519
Epoch [82/300], Train Loss: 0.001619
Validation Loss: 0.00184993
Epoch [83/300], Train Loss: 0.001541
Validation Loss: 0.00187331
Epoch [84/300], Train Loss: 0.001589
Validation Loss: 0.00189849
Epoch [85/300], Train Loss: 0.001644
Validation Loss: 0.00190432
Epoch [86/300], Train Loss: 0.001704
Validation Loss: 0.00187694
Epoch [87/300], Train Loss: 0.001689
Validation Loss: 0.00185145
Epoch [88/300], Train Loss: 0.001687
Validation Loss: 0.00187646
Epoch [89/300], Train Loss: 0.001552
Validation Loss: 0.00186226
Epoch [90/300], Train Loss: 0.001620
Validation Loss: 0.00185600
Epoch [91/300], Train Loss: 0.001692
Validation Loss: 0.00184762
Epoch [92/300], Train Loss: 0.001691
Validation Loss: 0.00186588
Epoch [93/300], Train Loss: 0.001687
Validation Loss: 0.00183815
Epoch [94/300], Train Loss: 0.001662
Validation Loss: 0.00184204
Epoch [95/300], Train Loss: 0.001650
Validation Loss: 0.00184766
Epoch [96/300], Train Loss: 0.001664
Validation Loss: 0.00184684
Epoch [97/300], Train Loss: 0.001687
Validation Loss: 0.00184365
Epoch [98/300], Train Loss: 0.001624
Validation Loss: 0.00185671
Epoch [99/300], Train Loss: 0.001667
Validation Loss: 0.00183922
Epoch [100/300], Train Loss: 0.001611
Validation Loss: 0.00184210
Epoch [101/300], Train Loss: 0.001622
Validation Loss: 0.00184632
Epoch [102/300], Train Loss: 0.001683
Validation Loss: 0.00184456
Epoch [103/300], Train Loss: 0.001648
Validation Loss: 0.00182380
Epoch [104/300], Train Loss: 0.001586
Validation Loss: 0.00185177
Epoch [105/300], Train Loss: 0.001651
Validation Loss: 0.00187737
Epoch [106/300], Train Loss: 0.001642
Validation Loss: 0.00183254
Epoch [107/300], Train Loss: 0.001753
Validation Loss: 0.00184162
Epoch [108/300], Train Loss: 0.001698
Validation Loss: 0.00181284
Epoch [109/300], Train Loss: 0.001650
Validation Loss: 0.00182668
Epoch [110/300], Train Loss: 0.001617
Validation Loss: 0.00180611
Epoch [111/300], Train Loss: 0.001585
Validation Loss: 0.00181217
Epoch [112/300], Train Loss: 0.001553
Validation Loss: 0.00185301
Epoch [113/300], Train Loss: 0.001580
Validation Loss: 0.00180912
Epoch [114/300], Train Loss: 0.001550
Validation Loss: 0.00179060
Epoch [115/300], Train Loss: 0.001490
Validation Loss: 0.00179785
Epoch [116/300], Train Loss: 0.001562
Validation Loss: 0.00179059
Epoch [117/300], Train Loss: 0.001588
Validation Loss: 0.00181625
Epoch [118/300], Train Loss: 0.001537
Validation Loss: 0.00179342
Epoch [119/300], Train Loss: 0.001519
Validation Loss: 0.00180649
Epoch [120/300], Train Loss: 0.001614
Validation Loss: 0.00179591
Epoch [121/300], Train Loss: 0.001568
Validation Loss: 0.00179542
Epoch [122/300], Train Loss: 0.001630
Validation Loss: 0.00179671
Epoch [123/300], Train Loss: 0.001544
Validation Loss: 0.00178764
Epoch [124/300], Train Loss: 0.001608
Validation Loss: 0.00178676
Epoch [125/300], Train Loss: 0.001509
Validation Loss: 0.00179590
Epoch [126/300], Train Loss: 0.001615
Validation Loss: 0.00179373
Epoch [127/300], Train Loss: 0.001640
Validation Loss: 0.00181627
Epoch [128/300], Train Loss: 0.001505
Validation Loss: 0.00179341
Epoch [129/300], Train Loss: 0.001566
Validation Loss: 0.00178706
Epoch [130/300], Train Loss: 0.001646
Validation Loss: 0.00180960
Epoch [131/300], Train Loss: 0.001521
Validation Loss: 0.00179233
Epoch [132/300], Train Loss: 0.001589
Validation Loss: 0.00178817
Epoch [133/300], Train Loss: 0.001523
Validation Loss: 0.00180382
Epoch [134/300], Train Loss: 0.001557
Validation Loss: 0.00179807
Early stopping triggered

Evaluating model for: Freezer
Run 70/72 completed in 521.79 seconds with: {'MAE': np.float32(30.500977), 'MSE': np.float32(2021.4153), 'RMSE': np.float32(44.96015), 'SAE': np.float32(0.019056398), 'NDE': np.float32(0.353424)}

Run 71/72: hidden=512, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Freezer
Dataset length: 1146 windows

Epoch [1/300], Train Loss: 0.006454
Validation Loss: 0.00594214
Epoch [2/300], Train Loss: 0.006065
Validation Loss: 0.00587663
Epoch [3/300], Train Loss: 0.006066
Validation Loss: 0.00592549
Epoch [4/300], Train Loss: 0.006078
Validation Loss: 0.00586580
Epoch [5/300], Train Loss: 0.005922
Validation Loss: 0.00586348
Epoch [6/300], Train Loss: 0.005958
Validation Loss: 0.00588055
Epoch [7/300], Train Loss: 0.005756
Validation Loss: 0.00582962
Epoch [8/300], Train Loss: 0.005739
Validation Loss: 0.00575643
Epoch [9/300], Train Loss: 0.005708
Validation Loss: 0.00524443
Epoch [10/300], Train Loss: 0.004321
Validation Loss: 0.00333201
Epoch [11/300], Train Loss: 0.003209
Validation Loss: 0.00292865
Epoch [12/300], Train Loss: 0.002763
Validation Loss: 0.00312829
Epoch [13/300], Train Loss: 0.002841
Validation Loss: 0.00241419
Epoch [14/300], Train Loss: 0.002342
Validation Loss: 0.00253886
Epoch [15/300], Train Loss: 0.002323
Validation Loss: 0.00233108
Epoch [16/300], Train Loss: 0.002170
Validation Loss: 0.00226381
Epoch [17/300], Train Loss: 0.002077
Validation Loss: 0.00220126
Epoch [18/300], Train Loss: 0.002039
Validation Loss: 0.00217474
Epoch [19/300], Train Loss: 0.001940
Validation Loss: 0.00216758
Epoch [20/300], Train Loss: 0.002019
Validation Loss: 0.00213399
Epoch [21/300], Train Loss: 0.001977
Validation Loss: 0.00216736
Epoch [22/300], Train Loss: 0.002024
Validation Loss: 0.00210346
Epoch [23/300], Train Loss: 0.002001
Validation Loss: 0.00219027
Epoch [24/300], Train Loss: 0.001873
Validation Loss: 0.00206548
Epoch [25/300], Train Loss: 0.001990
Validation Loss: 0.00206926
Epoch [26/300], Train Loss: 0.001833
Validation Loss: 0.00204331
Epoch [27/300], Train Loss: 0.001880
Validation Loss: 0.00203712
Epoch [28/300], Train Loss: 0.001904
Validation Loss: 0.00202563
Epoch [29/300], Train Loss: 0.001906
Validation Loss: 0.00212950
Epoch [30/300], Train Loss: 0.001904
Validation Loss: 0.00200541
Epoch [31/300], Train Loss: 0.001854
Validation Loss: 0.00202699
Epoch [32/300], Train Loss: 0.001799
Validation Loss: 0.00203068
Epoch [33/300], Train Loss: 0.001840
Validation Loss: 0.00201256
Epoch [34/300], Train Loss: 0.001909
Validation Loss: 0.00199345
Epoch [35/300], Train Loss: 0.001809
Validation Loss: 0.00201198
Epoch [36/300], Train Loss: 0.001750
Validation Loss: 0.00198362
Epoch [37/300], Train Loss: 0.001816
Validation Loss: 0.00204902
Epoch [38/300], Train Loss: 0.001887
Validation Loss: 0.00197452
Epoch [39/300], Train Loss: 0.001858
Validation Loss: 0.00197703
Epoch [40/300], Train Loss: 0.001753
Validation Loss: 0.00197759
Epoch [41/300], Train Loss: 0.001895
Validation Loss: 0.00196600
Epoch [42/300], Train Loss: 0.001753
Validation Loss: 0.00197520
Epoch [43/300], Train Loss: 0.001796
Validation Loss: 0.00200087
Epoch [44/300], Train Loss: 0.001729
Validation Loss: 0.00199276
Epoch [45/300], Train Loss: 0.001890
Validation Loss: 0.00194852
Epoch [46/300], Train Loss: 0.001819
Validation Loss: 0.00197225
Epoch [47/300], Train Loss: 0.001789
Validation Loss: 0.00197357
Epoch [48/300], Train Loss: 0.001833
Validation Loss: 0.00192930
Epoch [49/300], Train Loss: 0.001720
Validation Loss: 0.00195198
Epoch [50/300], Train Loss: 0.001799
Validation Loss: 0.00194830
Epoch [51/300], Train Loss: 0.001767
Validation Loss: 0.00191108
Epoch [52/300], Train Loss: 0.001686
Validation Loss: 0.00191936
Epoch [53/300], Train Loss: 0.001736
Validation Loss: 0.00190013
Epoch [54/300], Train Loss: 0.001670
Validation Loss: 0.00190342
Epoch [55/300], Train Loss: 0.001714
Validation Loss: 0.00189855
Epoch [56/300], Train Loss: 0.001720
Validation Loss: 0.00190459
Epoch [57/300], Train Loss: 0.001717
Validation Loss: 0.00189252
Epoch [58/300], Train Loss: 0.001717
Validation Loss: 0.00193410
Epoch [59/300], Train Loss: 0.001708
Validation Loss: 0.00194407
Epoch [60/300], Train Loss: 0.001706
Validation Loss: 0.00195831
Epoch [61/300], Train Loss: 0.001725
Validation Loss: 0.00186906
Epoch [62/300], Train Loss: 0.001663
Validation Loss: 0.00192291
Epoch [63/300], Train Loss: 0.001695
Validation Loss: 0.00188185
Epoch [64/300], Train Loss: 0.001679
Validation Loss: 0.00191680
Epoch [65/300], Train Loss: 0.001715
Validation Loss: 0.00185902
Epoch [66/300], Train Loss: 0.001662
Validation Loss: 0.00188984
Epoch [67/300], Train Loss: 0.001641
Validation Loss: 0.00187430
Epoch [68/300], Train Loss: 0.001732
Validation Loss: 0.00187397
Epoch [69/300], Train Loss: 0.001634
Validation Loss: 0.00186600
Epoch [70/300], Train Loss: 0.001670
Validation Loss: 0.00189504
Epoch [71/300], Train Loss: 0.001794
Validation Loss: 0.00185511
Epoch [72/300], Train Loss: 0.001556
Validation Loss: 0.00188573
Epoch [73/300], Train Loss: 0.001702
Validation Loss: 0.00186507
Epoch [74/300], Train Loss: 0.001670
Validation Loss: 0.00187204
Epoch [75/300], Train Loss: 0.001751
Validation Loss: 0.00185324
Epoch [76/300], Train Loss: 0.001598
Validation Loss: 0.00187747
Epoch [77/300], Train Loss: 0.001774
Validation Loss: 0.00185526
Epoch [78/300], Train Loss: 0.001660
Validation Loss: 0.00189288
Epoch [79/300], Train Loss: 0.001676
Validation Loss: 0.00186500
Epoch [80/300], Train Loss: 0.001688
Validation Loss: 0.00188876
Epoch [81/300], Train Loss: 0.001649
Validation Loss: 0.00185246
Epoch [82/300], Train Loss: 0.001621
Validation Loss: 0.00183360
Epoch [83/300], Train Loss: 0.001532
Validation Loss: 0.00184697
Epoch [84/300], Train Loss: 0.001581
Validation Loss: 0.00186062
Epoch [85/300], Train Loss: 0.001636
Validation Loss: 0.00189715
Epoch [86/300], Train Loss: 0.001718
Validation Loss: 0.00181866
Epoch [87/300], Train Loss: 0.001667
Validation Loss: 0.00182497
Epoch [88/300], Train Loss: 0.001673
Validation Loss: 0.00182404
Epoch [89/300], Train Loss: 0.001533
Validation Loss: 0.00180613
Epoch [90/300], Train Loss: 0.001591
Validation Loss: 0.00180496
Epoch [91/300], Train Loss: 0.001656
Validation Loss: 0.00181068
Epoch [92/300], Train Loss: 0.001669
Validation Loss: 0.00183892
Epoch [93/300], Train Loss: 0.001643
Validation Loss: 0.00178814
Epoch [94/300], Train Loss: 0.001621
Validation Loss: 0.00179832
Epoch [95/300], Train Loss: 0.001611
Validation Loss: 0.00180003
Epoch [96/300], Train Loss: 0.001622
Validation Loss: 0.00179913
Epoch [97/300], Train Loss: 0.001649
Validation Loss: 0.00179523
Epoch [98/300], Train Loss: 0.001572
Validation Loss: 0.00179865
Epoch [99/300], Train Loss: 0.001620
Validation Loss: 0.00179607
Epoch [100/300], Train Loss: 0.001562
Validation Loss: 0.00179156
Epoch [101/300], Train Loss: 0.001577
Validation Loss: 0.00179313
Epoch [102/300], Train Loss: 0.001640
Validation Loss: 0.00179246
Epoch [103/300], Train Loss: 0.001596
Validation Loss: 0.00178287
Epoch [104/300], Train Loss: 0.001540
Validation Loss: 0.00179652
Epoch [105/300], Train Loss: 0.001617
Validation Loss: 0.00183413
Epoch [106/300], Train Loss: 0.001609
Validation Loss: 0.00178817
Epoch [107/300], Train Loss: 0.001724
Validation Loss: 0.00179745
Epoch [108/300], Train Loss: 0.001672
Validation Loss: 0.00179539
Epoch [109/300], Train Loss: 0.001625
Validation Loss: 0.00178116
Epoch [110/300], Train Loss: 0.001584
Validation Loss: 0.00178513
Epoch [111/300], Train Loss: 0.001544
Validation Loss: 0.00177604
Epoch [112/300], Train Loss: 0.001528
Validation Loss: 0.00181913
Epoch [113/300], Train Loss: 0.001562
Validation Loss: 0.00177841
Epoch [114/300], Train Loss: 0.001525
Validation Loss: 0.00178289
Epoch [115/300], Train Loss: 0.001474
Validation Loss: 0.00177343
Epoch [116/300], Train Loss: 0.001533
Validation Loss: 0.00177828
Epoch [117/300], Train Loss: 0.001554
Validation Loss: 0.00178584
Epoch [118/300], Train Loss: 0.001518
Validation Loss: 0.00177991
Epoch [119/300], Train Loss: 0.001497
Validation Loss: 0.00177472
Epoch [120/300], Train Loss: 0.001599
Validation Loss: 0.00176960
Epoch [121/300], Train Loss: 0.001549
Validation Loss: 0.00177541
Epoch [122/300], Train Loss: 0.001618
Validation Loss: 0.00177495
Epoch [123/300], Train Loss: 0.001529
Validation Loss: 0.00176681
Epoch [124/300], Train Loss: 0.001588
Validation Loss: 0.00176919
Epoch [125/300], Train Loss: 0.001487
Validation Loss: 0.00177182
Epoch [126/300], Train Loss: 0.001582
Validation Loss: 0.00177387
Epoch [127/300], Train Loss: 0.001611
Validation Loss: 0.00176989
Epoch [128/300], Train Loss: 0.001489
Validation Loss: 0.00177095
Epoch [129/300], Train Loss: 0.001533
Validation Loss: 0.00175487
Epoch [130/300], Train Loss: 0.001618
Validation Loss: 0.00176291
Epoch [131/300], Train Loss: 0.001483
Validation Loss: 0.00176458
Epoch [132/300], Train Loss: 0.001562
Validation Loss: 0.00176250
Epoch [133/300], Train Loss: 0.001492
Validation Loss: 0.00177566
Epoch [134/300], Train Loss: 0.001524
Validation Loss: 0.00176417
Epoch [135/300], Train Loss: 0.001562
Validation Loss: 0.00176246
Epoch [136/300], Train Loss: 0.001500
Validation Loss: 0.00175152
Epoch [137/300], Train Loss: 0.001521
Validation Loss: 0.00177283
Epoch [138/300], Train Loss: 0.001504
Validation Loss: 0.00175896
Epoch [139/300], Train Loss: 0.001561
Validation Loss: 0.00174569
Epoch [140/300], Train Loss: 0.001548
Validation Loss: 0.00175703
Epoch [141/300], Train Loss: 0.001500
Validation Loss: 0.00174607
Epoch [142/300], Train Loss: 0.001595
Validation Loss: 0.00176675
Epoch [143/300], Train Loss: 0.001574
Validation Loss: 0.00177017
Epoch [144/300], Train Loss: 0.001536
Validation Loss: 0.00178288
Epoch [145/300], Train Loss: 0.001538
Validation Loss: 0.00175264
Epoch [146/300], Train Loss: 0.001545
Validation Loss: 0.00176170
Epoch [147/300], Train Loss: 0.001629
Validation Loss: 0.00176742
Epoch [148/300], Train Loss: 0.001535
Validation Loss: 0.00175714
Epoch [149/300], Train Loss: 0.001591
Validation Loss: 0.00175344
Early stopping triggered

Evaluating model for: Freezer
Run 71/72 completed in 750.06 seconds with: {'MAE': np.float32(30.029526), 'MSE': np.float32(1946.5758), 'RMSE': np.float32(44.120014), 'SAE': np.float32(0.012022774), 'NDE': np.float32(0.34681988)}

Run 72/72: hidden=512, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Freezer
Dataset length: 1146 windows

Epoch [1/300], Train Loss: 0.011790
Validation Loss: 0.00788469
Epoch [2/300], Train Loss: 0.006471
Validation Loss: 0.00637342
Epoch [3/300], Train Loss: 0.006335
Validation Loss: 0.00594444
Epoch [4/300], Train Loss: 0.006255
Validation Loss: 0.00599550
Epoch [5/300], Train Loss: 0.005936
Validation Loss: 0.00589089
Epoch [6/300], Train Loss: 0.005985
Validation Loss: 0.00587881
Epoch [7/300], Train Loss: 0.005804
Validation Loss: 0.00588874
Epoch [8/300], Train Loss: 0.005818
Validation Loss: 0.00587855
Epoch [9/300], Train Loss: 0.005960
Validation Loss: 0.00584335
Epoch [10/300], Train Loss: 0.005819
Validation Loss: 0.00572794
Epoch [11/300], Train Loss: 0.005554
Validation Loss: 0.00501300
Epoch [12/300], Train Loss: 0.004140
Validation Loss: 0.00416344
Epoch [13/300], Train Loss: 0.003900
Validation Loss: 0.00311091
Epoch [14/300], Train Loss: 0.003173
Validation Loss: 0.00325213
Epoch [15/300], Train Loss: 0.003260
Validation Loss: 0.00318091
Epoch [16/300], Train Loss: 0.002993
Validation Loss: 0.00276406
Epoch [17/300], Train Loss: 0.002825
Validation Loss: 0.00270838
Epoch [18/300], Train Loss: 0.002694
Validation Loss: 0.00270660
Epoch [19/300], Train Loss: 0.002656
Validation Loss: 0.00259097
Epoch [20/300], Train Loss: 0.002644
Validation Loss: 0.00251633
Epoch [21/300], Train Loss: 0.002567
Validation Loss: 0.00255727
Epoch [22/300], Train Loss: 0.002427
Validation Loss: 0.00256355
Epoch [23/300], Train Loss: 0.003428
Validation Loss: 0.00425843
Epoch [24/300], Train Loss: 0.004355
Validation Loss: 0.00427834
Epoch [25/300], Train Loss: 0.003535
Validation Loss: 0.00270241
Epoch [26/300], Train Loss: 0.002826
Validation Loss: 0.00260973
Epoch [27/300], Train Loss: 0.002698
Validation Loss: 0.00264251
Epoch [28/300], Train Loss: 0.002659
Validation Loss: 0.00249347
Epoch [29/300], Train Loss: 0.002561
Validation Loss: 0.00247666
Epoch [30/300], Train Loss: 0.002493
Validation Loss: 0.00244446
Epoch [31/300], Train Loss: 0.002523
Validation Loss: 0.00242425
Epoch [32/300], Train Loss: 0.002420
Validation Loss: 0.00245021
Epoch [33/300], Train Loss: 0.002448
Validation Loss: 0.00240863
Epoch [34/300], Train Loss: 0.002462
Validation Loss: 0.00238981
Epoch [35/300], Train Loss: 0.002378
Validation Loss: 0.00238307
Epoch [36/300], Train Loss: 0.002312
Validation Loss: 0.00245150
Epoch [37/300], Train Loss: 0.002458
Validation Loss: 0.00240223
Epoch [38/300], Train Loss: 0.002424
Validation Loss: 0.00233446
Epoch [39/300], Train Loss: 0.002374
Validation Loss: 0.00228811
Epoch [40/300], Train Loss: 0.002253
Validation Loss: 0.00234564
Epoch [41/300], Train Loss: 0.002371
Validation Loss: 0.00228223
Epoch [42/300], Train Loss: 0.002188
Validation Loss: 0.00229251
Epoch [43/300], Train Loss: 0.002315
Validation Loss: 0.00238066
Epoch [44/300], Train Loss: 0.002275
Validation Loss: 0.00225656
Epoch [45/300], Train Loss: 0.002329
Validation Loss: 0.00222038
Epoch [46/300], Train Loss: 0.002226
Validation Loss: 0.00218560
Epoch [47/300], Train Loss: 0.002165
Validation Loss: 0.00218529
Epoch [48/300], Train Loss: 0.002176
Validation Loss: 0.00217443
Epoch [49/300], Train Loss: 0.002060
Validation Loss: 0.00214917
Epoch [50/300], Train Loss: 0.002118
Validation Loss: 0.00221535
Epoch [51/300], Train Loss: 0.002145
Validation Loss: 0.00211895
Epoch [52/300], Train Loss: 0.002013
Validation Loss: 0.00211816
Epoch [53/300], Train Loss: 0.002080
Validation Loss: 0.00210971
Epoch [54/300], Train Loss: 0.001995
Validation Loss: 0.00209130
Epoch [55/300], Train Loss: 0.001961
Validation Loss: 0.00208144
Epoch [56/300], Train Loss: 0.001998
Validation Loss: 0.00207055
Epoch [57/300], Train Loss: 0.001961
Validation Loss: 0.00205356
Epoch [58/300], Train Loss: 0.001991
Validation Loss: 0.00205285
Epoch [59/300], Train Loss: 0.002018
Validation Loss: 0.00209748
Epoch [60/300], Train Loss: 0.002000
Validation Loss: 0.00204282
Epoch [61/300], Train Loss: 0.001942
Validation Loss: 0.00205714
Epoch [62/300], Train Loss: 0.001860
Validation Loss: 0.00205045
Epoch [63/300], Train Loss: 0.001887
Validation Loss: 0.00202684
Epoch [64/300], Train Loss: 0.001917
Validation Loss: 0.00234501
Epoch [65/300], Train Loss: 0.002103
Validation Loss: 0.00213668
Epoch [66/300], Train Loss: 0.002040
Validation Loss: 0.00205800
Epoch [67/300], Train Loss: 0.001922
Validation Loss: 0.00209922
Epoch [68/300], Train Loss: 0.001974
Validation Loss: 0.00206190
Epoch [69/300], Train Loss: 0.001861
Validation Loss: 0.00209665
Epoch [70/300], Train Loss: 0.001946
Validation Loss: 0.00208892
Epoch [71/300], Train Loss: 0.002073
Validation Loss: 0.00210087
Epoch [72/300], Train Loss: 0.001821
Validation Loss: 0.00199567
Epoch [73/300], Train Loss: 0.001909
Validation Loss: 0.00211705
Epoch [74/300], Train Loss: 0.001873
Validation Loss: 0.00208072
Epoch [75/300], Train Loss: 0.001965
Validation Loss: 0.00203739
Epoch [76/300], Train Loss: 0.001840
Validation Loss: 0.00223767
Epoch [77/300], Train Loss: 0.002223
Validation Loss: 0.00203404
Epoch [78/300], Train Loss: 0.001960
Validation Loss: 0.00199744
Epoch [79/300], Train Loss: 0.001914
Validation Loss: 0.00204941
Epoch [80/300], Train Loss: 0.001962
Validation Loss: 0.00200503
Epoch [81/300], Train Loss: 0.001856
Validation Loss: 0.00210130
Epoch [82/300], Train Loss: 0.001862
Validation Loss: 0.00204097
Early stopping triggered

Evaluating model for: Freezer
Run 72/72 completed in 542.93 seconds with: {'MAE': np.float32(34.533005), 'MSE': np.float32(2558.5913), 'RMSE': np.float32(50.58252), 'SAE': np.float32(0.053309437), 'NDE': np.float32(0.39762047)}
    hidden_size  seq_length  stride  num_layers  eval_result
0           128         120    0.25           2    20.542892
48          512         120    0.25           2    21.122078
1           128         120    0.25           3    21.439991
24          256         120    0.25           2    21.909859
54          512         120    0.50           4    21.913557
..          ...         ...     ...         ...          ...
62          512         360    0.50           4    43.361107
63          512         360    0.50           5    48.009186
47          256         720    0.50           5    78.568298
67          512         720    0.25           5    85.251129
59          512         360    0.25           5    86.964691

[72 rows x 5 columns]
