Using device: cuda

Run 1/72: hidden=128, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Laptop
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.005586
Validation Loss: 0.00362761
Epoch [2/300], Train Loss: 0.003385
Validation Loss: 0.00357461
Epoch [3/300], Train Loss: 0.003328
Validation Loss: 0.00355674
Epoch [4/300], Train Loss: 0.003327
Validation Loss: 0.00354263
Epoch [5/300], Train Loss: 0.003532
Validation Loss: 0.00353214
Epoch [6/300], Train Loss: 0.003285
Validation Loss: 0.00351292
Epoch [7/300], Train Loss: 0.003270
Validation Loss: 0.00350453
Epoch [8/300], Train Loss: 0.003252
Validation Loss: 0.00348378
Epoch [9/300], Train Loss: 0.003308
Validation Loss: 0.00345950
Epoch [10/300], Train Loss: 0.003302
Validation Loss: 0.00344539
Epoch [11/300], Train Loss: 0.003210
Validation Loss: 0.00343532
Epoch [12/300], Train Loss: 0.003193
Validation Loss: 0.00343089
Epoch [13/300], Train Loss: 0.003203
Validation Loss: 0.00343430
Epoch [14/300], Train Loss: 0.003261
Validation Loss: 0.00343496
Epoch [15/300], Train Loss: 0.003229
Validation Loss: 0.00341613
Epoch [16/300], Train Loss: 0.003221
Validation Loss: 0.00341045
Epoch [17/300], Train Loss: 0.003221
Validation Loss: 0.00341163
Epoch [18/300], Train Loss: 0.003226
Validation Loss: 0.00340354
Epoch [19/300], Train Loss: 0.003264
Validation Loss: 0.00340270
Epoch [20/300], Train Loss: 0.003238
Validation Loss: 0.00341983
Epoch [21/300], Train Loss: 0.003259
Validation Loss: 0.00339544
Epoch [22/300], Train Loss: 0.003317
Validation Loss: 0.00339977
Epoch [23/300], Train Loss: 0.003304
Validation Loss: 0.00341582
Epoch [24/300], Train Loss: 0.003344
Validation Loss: 0.00338876
Epoch [25/300], Train Loss: 0.003190
Validation Loss: 0.00338774
Epoch [26/300], Train Loss: 0.003163
Validation Loss: 0.00338388
Epoch [27/300], Train Loss: 0.003159
Validation Loss: 0.00338321
Epoch [28/300], Train Loss: 0.003172
Validation Loss: 0.00337971
Epoch [29/300], Train Loss: 0.003156
Validation Loss: 0.00337975
Epoch [30/300], Train Loss: 0.003258
Validation Loss: 0.00337678
Epoch [31/300], Train Loss: 0.003154
Validation Loss: 0.00337453
Epoch [32/300], Train Loss: 0.003182
Validation Loss: 0.00337365
Epoch [33/300], Train Loss: 0.003259
Validation Loss: 0.00337260
Epoch [34/300], Train Loss: 0.003235
Validation Loss: 0.00336421
Epoch [35/300], Train Loss: 0.003174
Validation Loss: 0.00336478
Epoch [36/300], Train Loss: 0.003175
Validation Loss: 0.00336164
Epoch [37/300], Train Loss: 0.003190
Validation Loss: 0.00334996
Epoch [38/300], Train Loss: 0.003215
Validation Loss: 0.00334139
Epoch [39/300], Train Loss: 0.003126
Validation Loss: 0.00333020
Epoch [40/300], Train Loss: 0.003189
Validation Loss: 0.00331056
Epoch [41/300], Train Loss: 0.003117
Validation Loss: 0.00329050
Epoch [42/300], Train Loss: 0.003146
Validation Loss: 0.00326519
Epoch [43/300], Train Loss: 0.003097
Validation Loss: 0.00320184
Epoch [44/300], Train Loss: 0.003081
Validation Loss: 0.00321463
Epoch [45/300], Train Loss: 0.002987
Validation Loss: 0.00301221
Epoch [46/300], Train Loss: 0.002986
Validation Loss: 0.00293244
Epoch [47/300], Train Loss: 0.002812
Validation Loss: 0.00279721
Epoch [48/300], Train Loss: 0.002687
Validation Loss: 0.00269195
Epoch [49/300], Train Loss: 0.002645
Validation Loss: 0.00269205
Epoch [50/300], Train Loss: 0.002535
Validation Loss: 0.00272542
Epoch [51/300], Train Loss: 0.002882
Validation Loss: 0.00268115
Epoch [52/300], Train Loss: 0.002493
Validation Loss: 0.00281926
Epoch [53/300], Train Loss: 0.002431
Validation Loss: 0.00256491
Epoch [54/300], Train Loss: 0.002344
Validation Loss: 0.00249157
Epoch [55/300], Train Loss: 0.002354
Validation Loss: 0.00248996
Epoch [56/300], Train Loss: 0.002230
Validation Loss: 0.00230744
Epoch [57/300], Train Loss: 0.002097
Validation Loss: 0.00218839
Epoch [58/300], Train Loss: 0.001950
Validation Loss: 0.00203657
Epoch [59/300], Train Loss: 0.001777
Validation Loss: 0.00187675
Epoch [60/300], Train Loss: 0.001549
Validation Loss: 0.00181086
Epoch [61/300], Train Loss: 0.001519
Validation Loss: 0.00175563
Epoch [62/300], Train Loss: 0.001537
Validation Loss: 0.00170539
Epoch [63/300], Train Loss: 0.001446
Validation Loss: 0.00172905
Epoch [64/300], Train Loss: 0.001538
Validation Loss: 0.00176906
Epoch [65/300], Train Loss: 0.001330
Validation Loss: 0.00152641
Epoch [66/300], Train Loss: 0.001276
Validation Loss: 0.00150254
Epoch [67/300], Train Loss: 0.001249
Validation Loss: 0.00154537
Epoch [68/300], Train Loss: 0.001224
Validation Loss: 0.00148871
Epoch [69/300], Train Loss: 0.001207
Validation Loss: 0.00152938
Epoch [70/300], Train Loss: 0.001198
Validation Loss: 0.00140951
Epoch [71/300], Train Loss: 0.001193
Validation Loss: 0.00140801
Epoch [72/300], Train Loss: 0.001158
Validation Loss: 0.00134001
Epoch [73/300], Train Loss: 0.001141
Validation Loss: 0.00131103
Epoch [74/300], Train Loss: 0.001124
Validation Loss: 0.00133865
Epoch [75/300], Train Loss: 0.001097
Validation Loss: 0.00131266
Epoch [76/300], Train Loss: 0.001099
Validation Loss: 0.00129504
Epoch [77/300], Train Loss: 0.001076
Validation Loss: 0.00129111
Epoch [78/300], Train Loss: 0.001055
Validation Loss: 0.00126722
Epoch [79/300], Train Loss: 0.001045
Validation Loss: 0.00125486
Epoch [80/300], Train Loss: 0.001035
Validation Loss: 0.00128917
Epoch [81/300], Train Loss: 0.001075
Validation Loss: 0.00126923
Epoch [82/300], Train Loss: 0.001007
Validation Loss: 0.00122991
Epoch [83/300], Train Loss: 0.001017
Validation Loss: 0.00119200
Epoch [84/300], Train Loss: 0.000991
Validation Loss: 0.00121019
Epoch [85/300], Train Loss: 0.001005
Validation Loss: 0.00121889
Epoch [86/300], Train Loss: 0.001024
Validation Loss: 0.00120412
Epoch [87/300], Train Loss: 0.000974
Validation Loss: 0.00109902
Epoch [88/300], Train Loss: 0.000962
Validation Loss: 0.00110571
Epoch [89/300], Train Loss: 0.000960
Validation Loss: 0.00110182
Epoch [90/300], Train Loss: 0.000941
Validation Loss: 0.00106908
Epoch [91/300], Train Loss: 0.000931
Validation Loss: 0.00105521
Epoch [92/300], Train Loss: 0.000938
Validation Loss: 0.00106301
Epoch [93/300], Train Loss: 0.000905
Validation Loss: 0.00104141
Epoch [94/300], Train Loss: 0.000915
Validation Loss: 0.00105496
Epoch [95/300], Train Loss: 0.000899
Validation Loss: 0.00102414
Epoch [96/300], Train Loss: 0.000883
Validation Loss: 0.00102016
Epoch [97/300], Train Loss: 0.000914
Validation Loss: 0.00108568
Epoch [98/300], Train Loss: 0.000895
Validation Loss: 0.00100368
Epoch [99/300], Train Loss: 0.000878
Validation Loss: 0.00100351
Epoch [100/300], Train Loss: 0.000880
Validation Loss: 0.00101476
Epoch [101/300], Train Loss: 0.000862
Validation Loss: 0.00098607
Epoch [102/300], Train Loss: 0.000858
Validation Loss: 0.00095875
Epoch [103/300], Train Loss: 0.000867
Validation Loss: 0.00095310
Epoch [104/300], Train Loss: 0.000854
Validation Loss: 0.00093055
Epoch [105/300], Train Loss: 0.000852
Validation Loss: 0.00092850
Epoch [106/300], Train Loss: 0.000828
Validation Loss: 0.00092140
Epoch [107/300], Train Loss: 0.000836
Validation Loss: 0.00090857
Epoch [108/300], Train Loss: 0.000821
Validation Loss: 0.00087985
Epoch [109/300], Train Loss: 0.000809
Validation Loss: 0.00086251
Epoch [110/300], Train Loss: 0.000796
Validation Loss: 0.00083367
Epoch [111/300], Train Loss: 0.000800
Validation Loss: 0.00082495
Epoch [112/300], Train Loss: 0.000788
Validation Loss: 0.00079289
Epoch [113/300], Train Loss: 0.000772
Validation Loss: 0.00077263
Epoch [114/300], Train Loss: 0.000772
Validation Loss: 0.00073285
Epoch [115/300], Train Loss: 0.000773
Validation Loss: 0.00073798
Epoch [116/300], Train Loss: 0.000753
Validation Loss: 0.00068582
Epoch [117/300], Train Loss: 0.000760
Validation Loss: 0.00067086
Epoch [118/300], Train Loss: 0.000778
Validation Loss: 0.00072935
Epoch [119/300], Train Loss: 0.000755
Validation Loss: 0.00064329
Epoch [120/300], Train Loss: 0.000734
Validation Loss: 0.00063895
Epoch [121/300], Train Loss: 0.000741
Validation Loss: 0.00065060
Epoch [122/300], Train Loss: 0.000731
Validation Loss: 0.00061533
Epoch [123/300], Train Loss: 0.000728
Validation Loss: 0.00062154
Epoch [124/300], Train Loss: 0.000737
Validation Loss: 0.00065250
Epoch [125/300], Train Loss: 0.000711
Validation Loss: 0.00059650
Epoch [126/300], Train Loss: 0.000708
Validation Loss: 0.00059100
Epoch [127/300], Train Loss: 0.000694
Validation Loss: 0.00059268
Epoch [128/300], Train Loss: 0.000695
Validation Loss: 0.00058228
Epoch [129/300], Train Loss: 0.000682
Validation Loss: 0.00057429
Epoch [130/300], Train Loss: 0.000674
Validation Loss: 0.00056723
Epoch [131/300], Train Loss: 0.000675
Validation Loss: 0.00059533
Epoch [132/300], Train Loss: 0.000680
Validation Loss: 0.00056646
Epoch [133/300], Train Loss: 0.000668
Validation Loss: 0.00058076
Epoch [134/300], Train Loss: 0.000682
Validation Loss: 0.00055688
Epoch [135/300], Train Loss: 0.000677
Validation Loss: 0.00055150
Epoch [136/300], Train Loss: 0.000660
Validation Loss: 0.00056044
Epoch [137/300], Train Loss: 0.000674
Validation Loss: 0.00054693
Epoch [138/300], Train Loss: 0.000661
Validation Loss: 0.00054457
Epoch [139/300], Train Loss: 0.000669
Validation Loss: 0.00056002
Epoch [140/300], Train Loss: 0.000658
Validation Loss: 0.00054260
Epoch [141/300], Train Loss: 0.000658
Validation Loss: 0.00054008
Epoch [142/300], Train Loss: 0.000654
Validation Loss: 0.00053457
Epoch [143/300], Train Loss: 0.000646
Validation Loss: 0.00055190
Epoch [144/300], Train Loss: 0.000646
Validation Loss: 0.00053411
Epoch [145/300], Train Loss: 0.000655
Validation Loss: 0.00057985
Epoch [146/300], Train Loss: 0.000651
Validation Loss: 0.00053288
Epoch [147/300], Train Loss: 0.000634
Validation Loss: 0.00053213
Epoch [148/300], Train Loss: 0.000632
Validation Loss: 0.00053674
Epoch [149/300], Train Loss: 0.000630
Validation Loss: 0.00052198
Epoch [150/300], Train Loss: 0.000629
Validation Loss: 0.00051597
Epoch [151/300], Train Loss: 0.000637
Validation Loss: 0.00051798
Epoch [152/300], Train Loss: 0.000623
Validation Loss: 0.00051598
Epoch [153/300], Train Loss: 0.000625
Validation Loss: 0.00051264
Epoch [154/300], Train Loss: 0.000623
Validation Loss: 0.00051627
Epoch [155/300], Train Loss: 0.000627
Validation Loss: 0.00051076
Epoch [156/300], Train Loss: 0.000631
Validation Loss: 0.00050685
Epoch [157/300], Train Loss: 0.000623
Validation Loss: 0.00050294
Epoch [158/300], Train Loss: 0.000632
Validation Loss: 0.00051232
Epoch [159/300], Train Loss: 0.000614
Validation Loss: 0.00052173
Epoch [160/300], Train Loss: 0.000609
Validation Loss: 0.00051266
Epoch [161/300], Train Loss: 0.000630
Validation Loss: 0.00050197
Epoch [162/300], Train Loss: 0.000603
Validation Loss: 0.00050325
Epoch [163/300], Train Loss: 0.000666
Validation Loss: 0.00060552
Epoch [164/300], Train Loss: 0.000637
Validation Loss: 0.00050066
Epoch [165/300], Train Loss: 0.000606
Validation Loss: 0.00049361
Epoch [166/300], Train Loss: 0.000607
Validation Loss: 0.00049779
Epoch [167/300], Train Loss: 0.000602
Validation Loss: 0.00049332
Epoch [168/300], Train Loss: 0.000612
Validation Loss: 0.00048809
Epoch [169/300], Train Loss: 0.000595
Validation Loss: 0.00048489
Epoch [170/300], Train Loss: 0.000596
Validation Loss: 0.00048619
Epoch [171/300], Train Loss: 0.000595
Validation Loss: 0.00048207
Epoch [172/300], Train Loss: 0.000602
Validation Loss: 0.00048412
Epoch [173/300], Train Loss: 0.000606
Validation Loss: 0.00048467
Epoch [174/300], Train Loss: 0.000603
Validation Loss: 0.00050137
Epoch [175/300], Train Loss: 0.000613
Validation Loss: 0.00047466
Epoch [176/300], Train Loss: 0.000598
Validation Loss: 0.00047424
Epoch [177/300], Train Loss: 0.000592
Validation Loss: 0.00047830
Epoch [178/300], Train Loss: 0.000582
Validation Loss: 0.00047100
Epoch [179/300], Train Loss: 0.000577
Validation Loss: 0.00047371
Epoch [180/300], Train Loss: 0.000583
Validation Loss: 0.00048761
Epoch [181/300], Train Loss: 0.000577
Validation Loss: 0.00046694
Epoch [182/300], Train Loss: 0.000577
Validation Loss: 0.00046274
Epoch [183/300], Train Loss: 0.000578
Validation Loss: 0.00050295
Epoch [184/300], Train Loss: 0.000638
Validation Loss: 0.00052317
Epoch [185/300], Train Loss: 0.000586
Validation Loss: 0.00046982
Epoch [186/300], Train Loss: 0.000567
Validation Loss: 0.00045796
Epoch [187/300], Train Loss: 0.000573
Validation Loss: 0.00045644
Epoch [188/300], Train Loss: 0.000575
Validation Loss: 0.00047131
Epoch [189/300], Train Loss: 0.000565
Validation Loss: 0.00047004
Epoch [190/300], Train Loss: 0.000572
Validation Loss: 0.00045243
Epoch [191/300], Train Loss: 0.000565
Validation Loss: 0.00045194
Epoch [192/300], Train Loss: 0.000561
Validation Loss: 0.00044853
Epoch [193/300], Train Loss: 0.000564
Validation Loss: 0.00044361
Epoch [194/300], Train Loss: 0.000564
Validation Loss: 0.00045183
Epoch [195/300], Train Loss: 0.000578
Validation Loss: 0.00044964
Epoch [196/300], Train Loss: 0.000559
Validation Loss: 0.00044219
Epoch [197/300], Train Loss: 0.000560
Validation Loss: 0.00043783
Epoch [198/300], Train Loss: 0.000557
Validation Loss: 0.00043611
Epoch [199/300], Train Loss: 0.000552
Validation Loss: 0.00043779
Epoch [200/300], Train Loss: 0.000546
Validation Loss: 0.00043744
Epoch [201/300], Train Loss: 0.000557
Validation Loss: 0.00043312
Epoch [202/300], Train Loss: 0.000549
Validation Loss: 0.00043338
Epoch [203/300], Train Loss: 0.000547
Validation Loss: 0.00045012
Epoch [204/300], Train Loss: 0.000552
Validation Loss: 0.00042851
Epoch [205/300], Train Loss: 0.000541
Validation Loss: 0.00042846
Epoch [206/300], Train Loss: 0.000549
Validation Loss: 0.00042713
Epoch [207/300], Train Loss: 0.000550
Validation Loss: 0.00042442
Epoch [208/300], Train Loss: 0.000549
Validation Loss: 0.00045133
Epoch [209/300], Train Loss: 0.000566
Validation Loss: 0.00044019
Epoch [210/300], Train Loss: 0.000547
Validation Loss: 0.00041919
Epoch [211/300], Train Loss: 0.000536
Validation Loss: 0.00041736
Epoch [212/300], Train Loss: 0.000538
Validation Loss: 0.00041740
Epoch [213/300], Train Loss: 0.000534
Validation Loss: 0.00041783
Epoch [214/300], Train Loss: 0.000539
Validation Loss: 0.00041124
Epoch [215/300], Train Loss: 0.000536
Validation Loss: 0.00041556
Epoch [216/300], Train Loss: 0.000528
Validation Loss: 0.00041195
Epoch [217/300], Train Loss: 0.000539
Validation Loss: 0.00040968
Epoch [218/300], Train Loss: 0.000524
Validation Loss: 0.00040710
Epoch [219/300], Train Loss: 0.000533
Validation Loss: 0.00040735
Epoch [220/300], Train Loss: 0.000521
Validation Loss: 0.00041951
Epoch [221/300], Train Loss: 0.000523
Validation Loss: 0.00042013
Epoch [222/300], Train Loss: 0.000522
Validation Loss: 0.00040604
Epoch [223/300], Train Loss: 0.000558
Validation Loss: 0.00040073
Epoch [224/300], Train Loss: 0.000523
Validation Loss: 0.00040809
Epoch [225/300], Train Loss: 0.000557
Validation Loss: 0.00039707
Epoch [226/300], Train Loss: 0.000517
Validation Loss: 0.00039868
Epoch [227/300], Train Loss: 0.000520
Validation Loss: 0.00039998
Epoch [228/300], Train Loss: 0.000517
Validation Loss: 0.00039860
Epoch [229/300], Train Loss: 0.000512
Validation Loss: 0.00039403
Epoch [230/300], Train Loss: 0.000515
Validation Loss: 0.00039250
Epoch [231/300], Train Loss: 0.000512
Validation Loss: 0.00041391
Epoch [232/300], Train Loss: 0.000511
Validation Loss: 0.00039458
Epoch [233/300], Train Loss: 0.000507
Validation Loss: 0.00038896
Epoch [234/300], Train Loss: 0.000506
Validation Loss: 0.00039006
Epoch [235/300], Train Loss: 0.000507
Validation Loss: 0.00039093
Epoch [236/300], Train Loss: 0.000517
Validation Loss: 0.00038490
Epoch [237/300], Train Loss: 0.000503
Validation Loss: 0.00039279
Epoch [238/300], Train Loss: 0.000512
Validation Loss: 0.00038485
Epoch [239/300], Train Loss: 0.000512
Validation Loss: 0.00038439
Epoch [240/300], Train Loss: 0.000501
Validation Loss: 0.00040073
Epoch [241/300], Train Loss: 0.000502
Validation Loss: 0.00038208
Epoch [242/300], Train Loss: 0.000497
Validation Loss: 0.00038189
Epoch [243/300], Train Loss: 0.000501
Validation Loss: 0.00038980
Epoch [244/300], Train Loss: 0.000499
Validation Loss: 0.00038612
Epoch [245/300], Train Loss: 0.000504
Validation Loss: 0.00037869
Epoch [246/300], Train Loss: 0.000492
Validation Loss: 0.00037582
Epoch [247/300], Train Loss: 0.000501
Validation Loss: 0.00037594
Epoch [248/300], Train Loss: 0.000500
Validation Loss: 0.00038895
Epoch [249/300], Train Loss: 0.000492
Validation Loss: 0.00037710
Epoch [250/300], Train Loss: 0.000494
Validation Loss: 0.00038277
Epoch [251/300], Train Loss: 0.000488
Validation Loss: 0.00037477
Epoch [252/300], Train Loss: 0.000552
Validation Loss: 0.00037868
Epoch [253/300], Train Loss: 0.000488
Validation Loss: 0.00037300
Epoch [254/300], Train Loss: 0.000499
Validation Loss: 0.00036973
Epoch [255/300], Train Loss: 0.000504
Validation Loss: 0.00037252
Epoch [256/300], Train Loss: 0.000484
Validation Loss: 0.00038175
Epoch [257/300], Train Loss: 0.000486
Validation Loss: 0.00036908
Epoch [258/300], Train Loss: 0.000488
Validation Loss: 0.00036836
Epoch [259/300], Train Loss: 0.000549
Validation Loss: 0.00040045
Epoch [260/300], Train Loss: 0.000492
Validation Loss: 0.00036925
Epoch [261/300], Train Loss: 0.000489
Validation Loss: 0.00036666
Epoch [262/300], Train Loss: 0.000485
Validation Loss: 0.00038152
Epoch [263/300], Train Loss: 0.000485
Validation Loss: 0.00036676
Epoch [264/300], Train Loss: 0.000487
Validation Loss: 0.00036954
Epoch [265/300], Train Loss: 0.000481
Validation Loss: 0.00036977
Epoch [266/300], Train Loss: 0.000477
Validation Loss: 0.00036545
Epoch [267/300], Train Loss: 0.000486
Validation Loss: 0.00036468
Epoch [268/300], Train Loss: 0.000479
Validation Loss: 0.00036678
Epoch [269/300], Train Loss: 0.000480
Validation Loss: 0.00036397
Epoch [270/300], Train Loss: 0.000470
Validation Loss: 0.00036580
Epoch [271/300], Train Loss: 0.000473
Validation Loss: 0.00036205
Epoch [272/300], Train Loss: 0.000475
Validation Loss: 0.00036254
Epoch [273/300], Train Loss: 0.000474
Validation Loss: 0.00036112
Epoch [274/300], Train Loss: 0.000474
Validation Loss: 0.00036380
Epoch [275/300], Train Loss: 0.000479
Validation Loss: 0.00036223
Epoch [276/300], Train Loss: 0.000475
Validation Loss: 0.00036238
Epoch [277/300], Train Loss: 0.000471
Validation Loss: 0.00035890
Epoch [278/300], Train Loss: 0.000473
Validation Loss: 0.00036761
Epoch [279/300], Train Loss: 0.000468
Validation Loss: 0.00035834
Epoch [280/300], Train Loss: 0.000469
Validation Loss: 0.00035824
Epoch [281/300], Train Loss: 0.000471
Validation Loss: 0.00035757
Epoch [282/300], Train Loss: 0.000468
Validation Loss: 0.00035796
Epoch [283/300], Train Loss: 0.000467
Validation Loss: 0.00035716
Epoch [284/300], Train Loss: 0.000489
Validation Loss: 0.00037493
Epoch [285/300], Train Loss: 0.000508
Validation Loss: 0.00036326
Epoch [286/300], Train Loss: 0.000462
Validation Loss: 0.00035674
Epoch [287/300], Train Loss: 0.000467
Validation Loss: 0.00035754
Epoch [288/300], Train Loss: 0.000474
Validation Loss: 0.00036290
Epoch [289/300], Train Loss: 0.000463
Validation Loss: 0.00035610
Epoch [290/300], Train Loss: 0.000470
Validation Loss: 0.00035582
Epoch [291/300], Train Loss: 0.000469
Validation Loss: 0.00036475
Epoch [292/300], Train Loss: 0.000469
Validation Loss: 0.00035315
Epoch [293/300], Train Loss: 0.000463
Validation Loss: 0.00035681
Epoch [294/300], Train Loss: 0.000457
Validation Loss: 0.00035350
Epoch [295/300], Train Loss: 0.000465
Validation Loss: 0.00035790
Epoch [296/300], Train Loss: 0.000463
Validation Loss: 0.00035431
Epoch [297/300], Train Loss: 0.000460
Validation Loss: 0.00035114
Epoch [298/300], Train Loss: 0.000464
Validation Loss: 0.00035181
Epoch [299/300], Train Loss: 0.000461
Validation Loss: 0.00035033
Epoch [300/300], Train Loss: 0.000455
Validation Loss: 0.00035501

Evaluating model for: Laptop
Run 1/72 completed in 1618.82 seconds with: {'MAE': np.float32(0.6891071), 'MSE': np.float32(3.202099), 'RMSE': np.float32(1.789441), 'SAE': np.float32(0.016267883), 'NDE': np.float32(0.22920096)}

Run 2/72: hidden=128, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Laptop
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.006497
Validation Loss: 0.00368161
Epoch [2/300], Train Loss: 0.003435
Validation Loss: 0.00360447
Epoch [3/300], Train Loss: 0.003367
Validation Loss: 0.00359229
Epoch [4/300], Train Loss: 0.003370
Validation Loss: 0.00357802
Epoch [5/300], Train Loss: 0.003575
Validation Loss: 0.00356723
Epoch [6/300], Train Loss: 0.003329
Validation Loss: 0.00354627
Epoch [7/300], Train Loss: 0.003313
Validation Loss: 0.00353607
Epoch [8/300], Train Loss: 0.003286
Validation Loss: 0.00351561
Epoch [9/300], Train Loss: 0.003336
Validation Loss: 0.00348054
Epoch [10/300], Train Loss: 0.003332
Validation Loss: 0.00346022
Epoch [11/300], Train Loss: 0.003234
Validation Loss: 0.00344882
Epoch [12/300], Train Loss: 0.003217
Validation Loss: 0.00345112
Epoch [13/300], Train Loss: 0.003222
Validation Loss: 0.00344281
Epoch [14/300], Train Loss: 0.003280
Validation Loss: 0.00346172
Epoch [15/300], Train Loss: 0.003248
Validation Loss: 0.00343001
Epoch [16/300], Train Loss: 0.003241
Validation Loss: 0.00342703
Epoch [17/300], Train Loss: 0.003245
Validation Loss: 0.00343561
Epoch [18/300], Train Loss: 0.003248
Validation Loss: 0.00342338
Epoch [19/300], Train Loss: 0.003285
Validation Loss: 0.00341933
Epoch [20/300], Train Loss: 0.003258
Validation Loss: 0.00343429
Epoch [21/300], Train Loss: 0.003275
Validation Loss: 0.00341823
Epoch [22/300], Train Loss: 0.003338
Validation Loss: 0.00342080
Epoch [23/300], Train Loss: 0.003324
Validation Loss: 0.00343988
Epoch [24/300], Train Loss: 0.003362
Validation Loss: 0.00341266
Epoch [25/300], Train Loss: 0.003212
Validation Loss: 0.00340317
Epoch [26/300], Train Loss: 0.003180
Validation Loss: 0.00340407
Epoch [27/300], Train Loss: 0.003176
Validation Loss: 0.00339985
Epoch [28/300], Train Loss: 0.003188
Validation Loss: 0.00339730
Epoch [29/300], Train Loss: 0.003172
Validation Loss: 0.00339500
Epoch [30/300], Train Loss: 0.003272
Validation Loss: 0.00339148
Epoch [31/300], Train Loss: 0.003167
Validation Loss: 0.00338968
Epoch [32/300], Train Loss: 0.003198
Validation Loss: 0.00338666
Epoch [33/300], Train Loss: 0.003272
Validation Loss: 0.00339336
Epoch [34/300], Train Loss: 0.003250
Validation Loss: 0.00338468
Epoch [35/300], Train Loss: 0.003191
Validation Loss: 0.00338372
Epoch [36/300], Train Loss: 0.003186
Validation Loss: 0.00337617
Epoch [37/300], Train Loss: 0.003206
Validation Loss: 0.00337340
Epoch [38/300], Train Loss: 0.003232
Validation Loss: 0.00336980
Epoch [39/300], Train Loss: 0.003149
Validation Loss: 0.00336294
Epoch [40/300], Train Loss: 0.003224
Validation Loss: 0.00336998
Epoch [41/300], Train Loss: 0.003159
Validation Loss: 0.00335755
Epoch [42/300], Train Loss: 0.003197
Validation Loss: 0.00334618
Epoch [43/300], Train Loss: 0.003174
Validation Loss: 0.00333482
Epoch [44/300], Train Loss: 0.003195
Validation Loss: 0.00332339
Epoch [45/300], Train Loss: 0.003157
Validation Loss: 0.00331547
Epoch [46/300], Train Loss: 0.003243
Validation Loss: 0.00335649
Epoch [47/300], Train Loss: 0.003182
Validation Loss: 0.00330255
Epoch [48/300], Train Loss: 0.003151
Validation Loss: 0.00330758
Epoch [49/300], Train Loss: 0.003171
Validation Loss: 0.00329925
Epoch [50/300], Train Loss: 0.003175
Validation Loss: 0.00328554
Epoch [51/300], Train Loss: 0.003192
Validation Loss: 0.00331164
Epoch [52/300], Train Loss: 0.003194
Validation Loss: 0.00332079
Epoch [53/300], Train Loss: 0.003105
Validation Loss: 0.00329707
Epoch [54/300], Train Loss: 0.003086
Validation Loss: 0.00329377
Epoch [55/300], Train Loss: 0.003123
Validation Loss: 0.00328319
Epoch [56/300], Train Loss: 0.003080
Validation Loss: 0.00326729
Epoch [57/300], Train Loss: 0.003086
Validation Loss: 0.00329694
Epoch [58/300], Train Loss: 0.003084
Validation Loss: 0.00327911
Epoch [59/300], Train Loss: 0.003144
Validation Loss: 0.00330809
Epoch [60/300], Train Loss: 0.003074
Validation Loss: 0.00329487
Epoch [61/300], Train Loss: 0.003167
Validation Loss: 0.00327268
Epoch [62/300], Train Loss: 0.003132
Validation Loss: 0.00328106
Epoch [63/300], Train Loss: 0.003303
Validation Loss: 0.00326835
Epoch [64/300], Train Loss: 0.003439
Validation Loss: 0.00326825
Epoch [65/300], Train Loss: 0.003090
Validation Loss: 0.00327373
Epoch [66/300], Train Loss: 0.003123
Validation Loss: 0.00325624
Epoch [67/300], Train Loss: 0.003159
Validation Loss: 0.00328721
Epoch [68/300], Train Loss: 0.003118
Validation Loss: 0.00324647
Epoch [69/300], Train Loss: 0.003123
Validation Loss: 0.00325087
Epoch [70/300], Train Loss: 0.003076
Validation Loss: 0.00324849
Epoch [71/300], Train Loss: 0.003036
Validation Loss: 0.00325053
Epoch [72/300], Train Loss: 0.003088
Validation Loss: 0.00325739
Epoch [73/300], Train Loss: 0.003051
Validation Loss: 0.00325052
Epoch [74/300], Train Loss: 0.003093
Validation Loss: 0.00323427
Epoch [75/300], Train Loss: 0.003037
Validation Loss: 0.00326368
Epoch [76/300], Train Loss: 0.003136
Validation Loss: 0.00324075
Epoch [77/300], Train Loss: 0.003082
Validation Loss: 0.00323885
Epoch [78/300], Train Loss: 0.003069
Validation Loss: 0.00324167
Epoch [79/300], Train Loss: 0.003078
Validation Loss: 0.00322907
Epoch [80/300], Train Loss: 0.003088
Validation Loss: 0.00324807
Epoch [81/300], Train Loss: 0.003201
Validation Loss: 0.00323088
Epoch [82/300], Train Loss: 0.003069
Validation Loss: 0.00332784
Epoch [83/300], Train Loss: 0.003049
Validation Loss: 0.00325121
Epoch [84/300], Train Loss: 0.003132
Validation Loss: 0.00325464
Epoch [85/300], Train Loss: 0.003037
Validation Loss: 0.00322940
Epoch [86/300], Train Loss: 0.003142
Validation Loss: 0.00323467
Epoch [87/300], Train Loss: 0.003032
Validation Loss: 0.00322929
Epoch [88/300], Train Loss: 0.003045
Validation Loss: 0.00323040
Epoch [89/300], Train Loss: 0.003104
Validation Loss: 0.00323345
Early stopping triggered

Evaluating model for: Laptop
Run 2/72 completed in 506.54 seconds with: {'MAE': np.float32(2.776152), 'MSE': np.float32(27.430975), 'RMSE': np.float32(5.2374587), 'SAE': np.float32(0.031426784), 'NDE': np.float32(0.6708411)}

Run 3/72: hidden=128, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Laptop
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.003580
Validation Loss: 0.00352111
Epoch [2/300], Train Loss: 0.003274
Validation Loss: 0.00349614
Epoch [3/300], Train Loss: 0.003240
Validation Loss: 0.00349289
Epoch [4/300], Train Loss: 0.003255
Validation Loss: 0.00348920
Epoch [5/300], Train Loss: 0.003467
Validation Loss: 0.00348984
Epoch [6/300], Train Loss: 0.003230
Validation Loss: 0.00348095
Epoch [7/300], Train Loss: 0.003225
Validation Loss: 0.00348129
Epoch [8/300], Train Loss: 0.003209
Validation Loss: 0.00346389
Epoch [9/300], Train Loss: 0.003264
Validation Loss: 0.00342793
Epoch [10/300], Train Loss: 0.003256
Validation Loss: 0.00341763
Epoch [11/300], Train Loss: 0.003165
Validation Loss: 0.00339563
Epoch [12/300], Train Loss: 0.003145
Validation Loss: 0.00339284
Epoch [13/300], Train Loss: 0.003157
Validation Loss: 0.00339709
Epoch [14/300], Train Loss: 0.003217
Validation Loss: 0.00339972
Epoch [15/300], Train Loss: 0.003185
Validation Loss: 0.00337862
Epoch [16/300], Train Loss: 0.003178
Validation Loss: 0.00337839
Epoch [17/300], Train Loss: 0.003183
Validation Loss: 0.00338364
Epoch [18/300], Train Loss: 0.003187
Validation Loss: 0.00337280
Epoch [19/300], Train Loss: 0.003222
Validation Loss: 0.00336995
Epoch [20/300], Train Loss: 0.003196
Validation Loss: 0.00339666
Epoch [21/300], Train Loss: 0.003218
Validation Loss: 0.00336852
Epoch [22/300], Train Loss: 0.003277
Validation Loss: 0.00338549
Epoch [23/300], Train Loss: 0.003272
Validation Loss: 0.00338809
Epoch [24/300], Train Loss: 0.003305
Validation Loss: 0.00336328
Epoch [25/300], Train Loss: 0.003152
Validation Loss: 0.00336277
Epoch [26/300], Train Loss: 0.003125
Validation Loss: 0.00336415
Epoch [27/300], Train Loss: 0.003120
Validation Loss: 0.00336099
Epoch [28/300], Train Loss: 0.003133
Validation Loss: 0.00335748
Epoch [29/300], Train Loss: 0.003117
Validation Loss: 0.00335268
Epoch [30/300], Train Loss: 0.003215
Validation Loss: 0.00335157
Epoch [31/300], Train Loss: 0.003117
Validation Loss: 0.00335079
Epoch [32/300], Train Loss: 0.003142
Validation Loss: 0.00334847
Epoch [33/300], Train Loss: 0.003219
Validation Loss: 0.00334850
Epoch [34/300], Train Loss: 0.003192
Validation Loss: 0.00334007
Epoch [35/300], Train Loss: 0.003130
Validation Loss: 0.00335219
Epoch [36/300], Train Loss: 0.003132
Validation Loss: 0.00333712
Epoch [37/300], Train Loss: 0.003144
Validation Loss: 0.00333858
Epoch [38/300], Train Loss: 0.003170
Validation Loss: 0.00334843
Epoch [39/300], Train Loss: 0.003089
Validation Loss: 0.00333066
Epoch [40/300], Train Loss: 0.003152
Validation Loss: 0.00335910
Epoch [41/300], Train Loss: 0.003092
Validation Loss: 0.00331899
Epoch [42/300], Train Loss: 0.003133
Validation Loss: 0.00332043
Epoch [43/300], Train Loss: 0.003103
Validation Loss: 0.00331953
Epoch [44/300], Train Loss: 0.003106
Validation Loss: 0.00330471
Epoch [45/300], Train Loss: 0.003097
Validation Loss: 0.00330796
Epoch [46/300], Train Loss: 0.003154
Validation Loss: 0.00332727
Epoch [47/300], Train Loss: 0.003110
Validation Loss: 0.00330443
Epoch [48/300], Train Loss: 0.003082
Validation Loss: 0.00329351
Epoch [49/300], Train Loss: 0.003089
Validation Loss: 0.00329751
Epoch [50/300], Train Loss: 0.003108
Validation Loss: 0.00329770
Epoch [51/300], Train Loss: 0.003103
Validation Loss: 0.00329834
Epoch [52/300], Train Loss: 0.003128
Validation Loss: 0.00332843
Epoch [53/300], Train Loss: 0.003041
Validation Loss: 0.00327002
Epoch [54/300], Train Loss: 0.003028
Validation Loss: 0.00329828
Epoch [55/300], Train Loss: 0.003074
Validation Loss: 0.00329810
Epoch [56/300], Train Loss: 0.003025
Validation Loss: 0.00327423
Epoch [57/300], Train Loss: 0.003017
Validation Loss: 0.00329798
Epoch [58/300], Train Loss: 0.003025
Validation Loss: 0.00331603
Epoch [59/300], Train Loss: 0.003096
Validation Loss: 0.00328874
Epoch [60/300], Train Loss: 0.003021
Validation Loss: 0.00329063
Epoch [61/300], Train Loss: 0.003115
Validation Loss: 0.00328795
Epoch [62/300], Train Loss: 0.003086
Validation Loss: 0.00328650
Epoch [63/300], Train Loss: 0.003227
Validation Loss: 0.00329615
Early stopping triggered

Evaluating model for: Laptop
Run 3/72 completed in 366.83 seconds with: {'MAE': np.float32(2.7567234), 'MSE': np.float32(28.292463), 'RMSE': np.float32(5.319066), 'SAE': np.float32(0.007962463), 'NDE': np.float32(0.68129385)}

Run 4/72: hidden=128, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Laptop
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.006035
Validation Loss: 0.00373716
Epoch [2/300], Train Loss: 0.003423
Validation Loss: 0.00359037
Epoch [3/300], Train Loss: 0.003362
Validation Loss: 0.00358437
Epoch [4/300], Train Loss: 0.003373
Validation Loss: 0.00357620
Epoch [5/300], Train Loss: 0.003583
Validation Loss: 0.00357168
Epoch [6/300], Train Loss: 0.003342
Validation Loss: 0.00355908
Epoch [7/300], Train Loss: 0.003330
Validation Loss: 0.00355070
Epoch [8/300], Train Loss: 0.003300
Validation Loss: 0.00351496
Epoch [9/300], Train Loss: 0.003340
Validation Loss: 0.00347360
Epoch [10/300], Train Loss: 0.003339
Validation Loss: 0.00345850
Epoch [11/300], Train Loss: 0.003242
Validation Loss: 0.00344859
Epoch [12/300], Train Loss: 0.003225
Validation Loss: 0.00344368
Epoch [13/300], Train Loss: 0.003236
Validation Loss: 0.00345217
Epoch [14/300], Train Loss: 0.003293
Validation Loss: 0.00344069
Epoch [15/300], Train Loss: 0.003257
Validation Loss: 0.00342419
Epoch [16/300], Train Loss: 0.003246
Validation Loss: 0.00341794
Epoch [17/300], Train Loss: 0.003245
Validation Loss: 0.00344334
Epoch [18/300], Train Loss: 0.003257
Validation Loss: 0.00340762
Epoch [19/300], Train Loss: 0.003284
Validation Loss: 0.00339879
Epoch [20/300], Train Loss: 0.003263
Validation Loss: 0.00342962
Epoch [21/300], Train Loss: 0.003275
Validation Loss: 0.00339726
Epoch [22/300], Train Loss: 0.003333
Validation Loss: 0.00339506
Epoch [23/300], Train Loss: 0.003310
Validation Loss: 0.00340209
Epoch [24/300], Train Loss: 0.003348
Validation Loss: 0.00338432
Epoch [25/300], Train Loss: 0.003197
Validation Loss: 0.00336590
Epoch [26/300], Train Loss: 0.003169
Validation Loss: 0.00336760
Epoch [27/300], Train Loss: 0.003161
Validation Loss: 0.00336122
Epoch [28/300], Train Loss: 0.003173
Validation Loss: 0.00336749
Epoch [29/300], Train Loss: 0.003152
Validation Loss: 0.00336358
Epoch [30/300], Train Loss: 0.003254
Validation Loss: 0.00335409
Epoch [31/300], Train Loss: 0.003154
Validation Loss: 0.00334629
Epoch [32/300], Train Loss: 0.003181
Validation Loss: 0.00335068
Epoch [33/300], Train Loss: 0.003252
Validation Loss: 0.00333633
Epoch [34/300], Train Loss: 0.003225
Validation Loss: 0.00335074
Epoch [35/300], Train Loss: 0.003175
Validation Loss: 0.00332324
Epoch [36/300], Train Loss: 0.003168
Validation Loss: 0.00332381
Epoch [37/300], Train Loss: 0.003185
Validation Loss: 0.00331364
Epoch [38/300], Train Loss: 0.003203
Validation Loss: 0.00331713
Epoch [39/300], Train Loss: 0.003130
Validation Loss: 0.00333348
Epoch [40/300], Train Loss: 0.003206
Validation Loss: 0.00330685
Epoch [41/300], Train Loss: 0.003143
Validation Loss: 0.00332851
Epoch [42/300], Train Loss: 0.003185
Validation Loss: 0.00331054
Epoch [43/300], Train Loss: 0.003173
Validation Loss: 0.00330601
Epoch [44/300], Train Loss: 0.003194
Validation Loss: 0.00330027
Epoch [45/300], Train Loss: 0.003151
Validation Loss: 0.00331725
Epoch [46/300], Train Loss: 0.003236
Validation Loss: 0.00330872
Epoch [47/300], Train Loss: 0.003188
Validation Loss: 0.00328926
Epoch [48/300], Train Loss: 0.003149
Validation Loss: 0.00329291
Epoch [49/300], Train Loss: 0.003182
Validation Loss: 0.00329170
Epoch [50/300], Train Loss: 0.003197
Validation Loss: 0.00329203
Epoch [51/300], Train Loss: 0.003204
Validation Loss: 0.00329091
Epoch [52/300], Train Loss: 0.003189
Validation Loss: 0.00330534
Epoch [53/300], Train Loss: 0.003112
Validation Loss: 0.00329423
Epoch [54/300], Train Loss: 0.003101
Validation Loss: 0.00329517
Epoch [55/300], Train Loss: 0.003140
Validation Loss: 0.00331162
Epoch [56/300], Train Loss: 0.003105
Validation Loss: 0.00327869
Epoch [57/300], Train Loss: 0.003093
Validation Loss: 0.00331886
Epoch [58/300], Train Loss: 0.003107
Validation Loss: 0.00328394
Epoch [59/300], Train Loss: 0.003174
Validation Loss: 0.00331837
Epoch [60/300], Train Loss: 0.003101
Validation Loss: 0.00329159
Epoch [61/300], Train Loss: 0.003191
Validation Loss: 0.00329142
Epoch [62/300], Train Loss: 0.003153
Validation Loss: 0.00327608
Epoch [63/300], Train Loss: 0.003331
Validation Loss: 0.00329061
Epoch [64/300], Train Loss: 0.003466
Validation Loss: 0.00327623
Epoch [65/300], Train Loss: 0.003119
Validation Loss: 0.00328609
Epoch [66/300], Train Loss: 0.003156
Validation Loss: 0.00328553
Epoch [67/300], Train Loss: 0.003197
Validation Loss: 0.00329330
Epoch [68/300], Train Loss: 0.003160
Validation Loss: 0.00327326
Epoch [69/300], Train Loss: 0.003166
Validation Loss: 0.00325870
Epoch [70/300], Train Loss: 0.003114
Validation Loss: 0.00327886
Epoch [71/300], Train Loss: 0.003082
Validation Loss: 0.00327535
Epoch [72/300], Train Loss: 0.003127
Validation Loss: 0.00328087
Epoch [73/300], Train Loss: 0.003094
Validation Loss: 0.00326261
Epoch [74/300], Train Loss: 0.003152
Validation Loss: 0.00326002
Epoch [75/300], Train Loss: 0.003086
Validation Loss: 0.00326967
Epoch [76/300], Train Loss: 0.003180
Validation Loss: 0.00326891
Epoch [77/300], Train Loss: 0.003125
Validation Loss: 0.00325455
Epoch [78/300], Train Loss: 0.003113
Validation Loss: 0.00325690
Epoch [79/300], Train Loss: 0.003129
Validation Loss: 0.00325131
Epoch [80/300], Train Loss: 0.003141
Validation Loss: 0.00327474
Epoch [81/300], Train Loss: 0.003246
Validation Loss: 0.00327003
Epoch [82/300], Train Loss: 0.003125
Validation Loss: 0.00326436
Epoch [83/300], Train Loss: 0.003105
Validation Loss: 0.00328715
Epoch [84/300], Train Loss: 0.003190
Validation Loss: 0.00327983
Epoch [85/300], Train Loss: 0.003094
Validation Loss: 0.00326667
Epoch [86/300], Train Loss: 0.003201
Validation Loss: 0.00324561
Epoch [87/300], Train Loss: 0.003095
Validation Loss: 0.00325288
Epoch [88/300], Train Loss: 0.003089
Validation Loss: 0.00323143
Epoch [89/300], Train Loss: 0.003166
Validation Loss: 0.00322715
Epoch [90/300], Train Loss: 0.003148
Validation Loss: 0.00325222
Epoch [91/300], Train Loss: 0.003115
Validation Loss: 0.00324630
Epoch [92/300], Train Loss: 0.003140
Validation Loss: 0.00323249
Epoch [93/300], Train Loss: 0.003058
Validation Loss: 0.00322356
Epoch [94/300], Train Loss: 0.003139
Validation Loss: 0.00321873
Epoch [95/300], Train Loss: 0.003204
Validation Loss: 0.00321302
Epoch [96/300], Train Loss: 0.003084
Validation Loss: 0.00321513
Epoch [97/300], Train Loss: 0.003159
Validation Loss: 0.00320081
Epoch [98/300], Train Loss: 0.003068
Validation Loss: 0.00322551
Epoch [99/300], Train Loss: 0.003084
Validation Loss: 0.00321382
Epoch [100/300], Train Loss: 0.003085
Validation Loss: 0.00320613
Epoch [101/300], Train Loss: 0.003107
Validation Loss: 0.00321663
Epoch [102/300], Train Loss: 0.003139
Validation Loss: 0.00319882
Epoch [103/300], Train Loss: 0.003065
Validation Loss: 0.00320014
Epoch [104/300], Train Loss: 0.003185
Validation Loss: 0.00319100
Epoch [105/300], Train Loss: 0.003171
Validation Loss: 0.00321721
Epoch [106/300], Train Loss: 0.003029
Validation Loss: 0.00318891
Epoch [107/300], Train Loss: 0.003072
Validation Loss: 0.00320009
Epoch [108/300], Train Loss: 0.003070
Validation Loss: 0.00317033
Epoch [109/300], Train Loss: 0.003060
Validation Loss: 0.00317051
Epoch [110/300], Train Loss: 0.003033
Validation Loss: 0.00316240
Epoch [111/300], Train Loss: 0.003111
Validation Loss: 0.00315969
Epoch [112/300], Train Loss: 0.003157
Validation Loss: 0.00318892
Epoch [113/300], Train Loss: 0.003031
Validation Loss: 0.00316462
Epoch [114/300], Train Loss: 0.003145
Validation Loss: 0.00315471
Epoch [115/300], Train Loss: 0.003071
Validation Loss: 0.00314266
Epoch [116/300], Train Loss: 0.003061
Validation Loss: 0.00315887
Epoch [117/300], Train Loss: 0.003148
Validation Loss: 0.00313537
Epoch [118/300], Train Loss: 0.003081
Validation Loss: 0.00314973
Epoch [119/300], Train Loss: 0.003083
Validation Loss: 0.00312338
Epoch [120/300], Train Loss: 0.002999
Validation Loss: 0.00308128
Epoch [121/300], Train Loss: 0.003089
Validation Loss: 0.00309106
Epoch [122/300], Train Loss: 0.002949
Validation Loss: 0.00307306
Epoch [123/300], Train Loss: 0.003019
Validation Loss: 0.00302276
Epoch [124/300], Train Loss: 0.002917
Validation Loss: 0.00294949
Epoch [125/300], Train Loss: 0.002932
Validation Loss: 0.00292115
Epoch [126/300], Train Loss: 0.002951
Validation Loss: 0.00282204
Epoch [127/300], Train Loss: 0.002843
Validation Loss: 0.00274047
Epoch [128/300], Train Loss: 0.002791
Validation Loss: 0.00265427
Epoch [129/300], Train Loss: 0.002693
Validation Loss: 0.00259533
Epoch [130/300], Train Loss: 0.002673
Validation Loss: 0.00259382
Epoch [131/300], Train Loss: 0.002605
Validation Loss: 0.00252016
Epoch [132/300], Train Loss: 0.002657
Validation Loss: 0.00250281
Epoch [133/300], Train Loss: 0.002531
Validation Loss: 0.00243022
Epoch [134/300], Train Loss: 0.002545
Validation Loss: 0.00240278
Epoch [135/300], Train Loss: 0.002541
Validation Loss: 0.00233096
Epoch [136/300], Train Loss: 0.002406
Validation Loss: 0.00230771
Epoch [137/300], Train Loss: 0.002380
Validation Loss: 0.00233489
Epoch [138/300], Train Loss: 0.002276
Validation Loss: 0.00230509
Epoch [139/300], Train Loss: 0.002116
Validation Loss: 0.00238982
Epoch [140/300], Train Loss: 0.001854
Validation Loss: 0.00228895
Epoch [141/300], Train Loss: 0.001639
Validation Loss: 0.00202969
Epoch [142/300], Train Loss: 0.001454
Validation Loss: 0.00175058
Epoch [143/300], Train Loss: 0.001408
Validation Loss: 0.00165939
Epoch [144/300], Train Loss: 0.001351
Validation Loss: 0.00175187
Epoch [145/300], Train Loss: 0.001323
Validation Loss: 0.00164798
Epoch [146/300], Train Loss: 0.001326
Validation Loss: 0.00168092
Epoch [147/300], Train Loss: 0.001279
Validation Loss: 0.00161665
Epoch [148/300], Train Loss: 0.001257
Validation Loss: 0.00153057
Epoch [149/300], Train Loss: 0.001246
Validation Loss: 0.00152180
Epoch [150/300], Train Loss: 0.001220
Validation Loss: 0.00151768
Epoch [151/300], Train Loss: 0.001221
Validation Loss: 0.00138450
Epoch [152/300], Train Loss: 0.001171
Validation Loss: 0.00128890
Epoch [153/300], Train Loss: 0.001128
Validation Loss: 0.00121080
Epoch [154/300], Train Loss: 0.001175
Validation Loss: 0.00128482
Epoch [155/300], Train Loss: 0.001105
Validation Loss: 0.00113521
Epoch [156/300], Train Loss: 0.001092
Validation Loss: 0.00111306
Epoch [157/300], Train Loss: 0.001068
Validation Loss: 0.00107557
Epoch [158/300], Train Loss: 0.001094
Validation Loss: 0.00107761
Epoch [159/300], Train Loss: 0.001029
Validation Loss: 0.00105699
Epoch [160/300], Train Loss: 0.001026
Validation Loss: 0.00116154
Epoch [161/300], Train Loss: 0.001044
Validation Loss: 0.00107312
Epoch [162/300], Train Loss: 0.001016
Validation Loss: 0.00103097
Epoch [163/300], Train Loss: 0.001030
Validation Loss: 0.00102013
Epoch [164/300], Train Loss: 0.001008
Validation Loss: 0.00099989
Epoch [165/300], Train Loss: 0.000969
Validation Loss: 0.00100881
Epoch [166/300], Train Loss: 0.000977
Validation Loss: 0.00098723
Epoch [167/300], Train Loss: 0.000957
Validation Loss: 0.00098480
Epoch [168/300], Train Loss: 0.000964
Validation Loss: 0.00096291
Epoch [169/300], Train Loss: 0.000942
Validation Loss: 0.00095719
Epoch [170/300], Train Loss: 0.000925
Validation Loss: 0.00093958
Epoch [171/300], Train Loss: 0.000930
Validation Loss: 0.00092953
Epoch [172/300], Train Loss: 0.000923
Validation Loss: 0.00092284
Epoch [173/300], Train Loss: 0.000920
Validation Loss: 0.00090658
Epoch [174/300], Train Loss: 0.000898
Validation Loss: 0.00089599
Epoch [175/300], Train Loss: 0.000919
Validation Loss: 0.00090227
Epoch [176/300], Train Loss: 0.000892
Validation Loss: 0.00087848
Epoch [177/300], Train Loss: 0.000889
Validation Loss: 0.00086330
Epoch [178/300], Train Loss: 0.000865
Validation Loss: 0.00086367
Epoch [179/300], Train Loss: 0.000852
Validation Loss: 0.00083396
Epoch [180/300], Train Loss: 0.000860
Validation Loss: 0.00082895
Epoch [181/300], Train Loss: 0.000841
Validation Loss: 0.00081623
Epoch [182/300], Train Loss: 0.000832
Validation Loss: 0.00081623
Epoch [183/300], Train Loss: 0.000834
Validation Loss: 0.00081574
Epoch [184/300], Train Loss: 0.000903
Validation Loss: 0.00085740
Epoch [185/300], Train Loss: 0.000832
Validation Loss: 0.00079479
Epoch [186/300], Train Loss: 0.000810
Validation Loss: 0.00078817
Epoch [187/300], Train Loss: 0.000810
Validation Loss: 0.00079898
Epoch [188/300], Train Loss: 0.000810
Validation Loss: 0.00077070
Epoch [189/300], Train Loss: 0.000796
Validation Loss: 0.00075700
Epoch [190/300], Train Loss: 0.000797
Validation Loss: 0.00075156
Epoch [191/300], Train Loss: 0.000791
Validation Loss: 0.00075354
Epoch [192/300], Train Loss: 0.000788
Validation Loss: 0.00073935
Epoch [193/300], Train Loss: 0.000782
Validation Loss: 0.00072925
Epoch [194/300], Train Loss: 0.000784
Validation Loss: 0.00072787
Epoch [195/300], Train Loss: 0.000800
Validation Loss: 0.00073142
Epoch [196/300], Train Loss: 0.000770
Validation Loss: 0.00071663
Epoch [197/300], Train Loss: 0.000766
Validation Loss: 0.00070772
Epoch [198/300], Train Loss: 0.000753
Validation Loss: 0.00070419
Epoch [199/300], Train Loss: 0.000757
Validation Loss: 0.00071412
Epoch [200/300], Train Loss: 0.000748
Validation Loss: 0.00070424
Epoch [201/300], Train Loss: 0.000759
Validation Loss: 0.00068853
Epoch [202/300], Train Loss: 0.000739
Validation Loss: 0.00068637
Epoch [203/300], Train Loss: 0.000738
Validation Loss: 0.00071207
Epoch [204/300], Train Loss: 0.000741
Validation Loss: 0.00067320
Epoch [205/300], Train Loss: 0.000724
Validation Loss: 0.00067490
Epoch [206/300], Train Loss: 0.000731
Validation Loss: 0.00066313
Epoch [207/300], Train Loss: 0.000733
Validation Loss: 0.00065822
Epoch [208/300], Train Loss: 0.000721
Validation Loss: 0.00065720
Epoch [209/300], Train Loss: 0.000732
Validation Loss: 0.00065500
Epoch [210/300], Train Loss: 0.000721
Validation Loss: 0.00064369
Epoch [211/300], Train Loss: 0.000702
Validation Loss: 0.00064174
Epoch [212/300], Train Loss: 0.000701
Validation Loss: 0.00063792
Epoch [213/300], Train Loss: 0.000699
Validation Loss: 0.00064543
Epoch [214/300], Train Loss: 0.000698
Validation Loss: 0.00064027
Epoch [215/300], Train Loss: 0.000691
Validation Loss: 0.00063200
Epoch [216/300], Train Loss: 0.000679
Validation Loss: 0.00063432
Epoch [217/300], Train Loss: 0.000688
Validation Loss: 0.00063287
Epoch [218/300], Train Loss: 0.000676
Validation Loss: 0.00063174
Epoch [219/300], Train Loss: 0.000681
Validation Loss: 0.00061229
Epoch [220/300], Train Loss: 0.000663
Validation Loss: 0.00062015
Epoch [221/300], Train Loss: 0.000665
Validation Loss: 0.00060794
Epoch [222/300], Train Loss: 0.000661
Validation Loss: 0.00060140
Epoch [223/300], Train Loss: 0.000701
Validation Loss: 0.00061931
Epoch [224/300], Train Loss: 0.000675
Validation Loss: 0.00061529
Epoch [225/300], Train Loss: 0.000696
Validation Loss: 0.00058763
Epoch [226/300], Train Loss: 0.000647
Validation Loss: 0.00059079
Epoch [227/300], Train Loss: 0.000646
Validation Loss: 0.00059371
Epoch [228/300], Train Loss: 0.000641
Validation Loss: 0.00057993
Epoch [229/300], Train Loss: 0.000641
Validation Loss: 0.00059491
Epoch [230/300], Train Loss: 0.000641
Validation Loss: 0.00057951
Epoch [231/300], Train Loss: 0.000634
Validation Loss: 0.00057604
Epoch [232/300], Train Loss: 0.000630
Validation Loss: 0.00058112
Epoch [233/300], Train Loss: 0.000627
Validation Loss: 0.00057761
Epoch [234/300], Train Loss: 0.000627
Validation Loss: 0.00056144
Epoch [235/300], Train Loss: 0.000621
Validation Loss: 0.00055794
Epoch [236/300], Train Loss: 0.000627
Validation Loss: 0.00055184
Epoch [237/300], Train Loss: 0.000609
Validation Loss: 0.00056742
Epoch [238/300], Train Loss: 0.000626
Validation Loss: 0.00055667
Epoch [239/300], Train Loss: 0.000617
Validation Loss: 0.00053950
Epoch [240/300], Train Loss: 0.000603
Validation Loss: 0.00053967
Epoch [241/300], Train Loss: 0.000598
Validation Loss: 0.00053662
Epoch [242/300], Train Loss: 0.000599
Validation Loss: 0.00053030
Epoch [243/300], Train Loss: 0.000603
Validation Loss: 0.00053356
Epoch [244/300], Train Loss: 0.000598
Validation Loss: 0.00052393
Epoch [245/300], Train Loss: 0.000601
Validation Loss: 0.00053564
Epoch [246/300], Train Loss: 0.000587
Validation Loss: 0.00052309
Epoch [247/300], Train Loss: 0.000590
Validation Loss: 0.00051528
Epoch [248/300], Train Loss: 0.000586
Validation Loss: 0.00051302
Epoch [249/300], Train Loss: 0.000583
Validation Loss: 0.00051129
Epoch [250/300], Train Loss: 0.000571
Validation Loss: 0.00051418
Epoch [251/300], Train Loss: 0.000575
Validation Loss: 0.00050519
Epoch [252/300], Train Loss: 0.000669
Validation Loss: 0.00053297
Epoch [253/300], Train Loss: 0.000594
Validation Loss: 0.00050700
Epoch [254/300], Train Loss: 0.000574
Validation Loss: 0.00050862
Epoch [255/300], Train Loss: 0.000578
Validation Loss: 0.00050043
Epoch [256/300], Train Loss: 0.000565
Validation Loss: 0.00050113
Epoch [257/300], Train Loss: 0.000559
Validation Loss: 0.00049532
Epoch [258/300], Train Loss: 0.000561
Validation Loss: 0.00048779
Epoch [259/300], Train Loss: 0.000563
Validation Loss: 0.00048841
Epoch [260/300], Train Loss: 0.000551
Validation Loss: 0.00049321
Epoch [261/300], Train Loss: 0.000555
Validation Loss: 0.00048610
Epoch [262/300], Train Loss: 0.000554
Validation Loss: 0.00048210
Epoch [263/300], Train Loss: 0.000542
Validation Loss: 0.00048102
Epoch [264/300], Train Loss: 0.000547
Validation Loss: 0.00048570
Epoch [265/300], Train Loss: 0.000536
Validation Loss: 0.00048831
Epoch [266/300], Train Loss: 0.000532
Validation Loss: 0.00047369
Epoch [267/300], Train Loss: 0.000534
Validation Loss: 0.00047727
Epoch [268/300], Train Loss: 0.000545
Validation Loss: 0.00047011
Epoch [269/300], Train Loss: 0.000540
Validation Loss: 0.00047737
Epoch [270/300], Train Loss: 0.000522
Validation Loss: 0.00046716
Epoch [271/300], Train Loss: 0.000517
Validation Loss: 0.00046729
Epoch [272/300], Train Loss: 0.000523
Validation Loss: 0.00046572
Epoch [273/300], Train Loss: 0.000526
Validation Loss: 0.00047322
Epoch [274/300], Train Loss: 0.000515
Validation Loss: 0.00046057
Epoch [275/300], Train Loss: 0.000530
Validation Loss: 0.00046712
Epoch [276/300], Train Loss: 0.000518
Validation Loss: 0.00046342
Epoch [277/300], Train Loss: 0.000510
Validation Loss: 0.00045818
Epoch [278/300], Train Loss: 0.000509
Validation Loss: 0.00045847
Epoch [279/300], Train Loss: 0.000506
Validation Loss: 0.00045552
Epoch [280/300], Train Loss: 0.000507
Validation Loss: 0.00045733
Epoch [281/300], Train Loss: 0.000517
Validation Loss: 0.00045086
Epoch [282/300], Train Loss: 0.000506
Validation Loss: 0.00045389
Epoch [283/300], Train Loss: 0.000505
Validation Loss: 0.00044883
Epoch [284/300], Train Loss: 0.000527
Validation Loss: 0.00046443
Epoch [285/300], Train Loss: 0.000551
Validation Loss: 0.00044669
Epoch [286/300], Train Loss: 0.000506
Validation Loss: 0.00044828
Epoch [287/300], Train Loss: 0.000506
Validation Loss: 0.00044393
Epoch [288/300], Train Loss: 0.000506
Validation Loss: 0.00045615
Epoch [289/300], Train Loss: 0.000494
Validation Loss: 0.00044496
Epoch [290/300], Train Loss: 0.000499
Validation Loss: 0.00044299
Epoch [291/300], Train Loss: 0.000498
Validation Loss: 0.00043692
Epoch [292/300], Train Loss: 0.000496
Validation Loss: 0.00043777
Epoch [293/300], Train Loss: 0.000490
Validation Loss: 0.00043757
Epoch [294/300], Train Loss: 0.000484
Validation Loss: 0.00043412
Epoch [295/300], Train Loss: 0.000492
Validation Loss: 0.00043979
Epoch [296/300], Train Loss: 0.000491
Validation Loss: 0.00043190
Epoch [297/300], Train Loss: 0.000486
Validation Loss: 0.00043544
Epoch [298/300], Train Loss: 0.000542
Validation Loss: 0.00044148
Epoch [299/300], Train Loss: 0.000498
Validation Loss: 0.00043268
Epoch [300/300], Train Loss: 0.000488
Validation Loss: 0.00043247

Evaluating model for: Laptop
Run 4/72 completed in 1755.50 seconds with: {'MAE': np.float32(0.8370062), 'MSE': np.float32(3.7838664), 'RMSE': np.float32(1.9452163), 'SAE': np.float32(0.016897518), 'NDE': np.float32(0.24915347)}

Run 5/72: hidden=128, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Laptop
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.004148
Validation Loss: 0.00215205
Epoch [2/300], Train Loss: 0.003344
Validation Loss: 0.00224244
Epoch [3/300], Train Loss: 0.003336
Validation Loss: 0.00216498
Epoch [4/300], Train Loss: 0.003275
Validation Loss: 0.00218514
Epoch [5/300], Train Loss: 0.003327
Validation Loss: 0.00216458
Epoch [6/300], Train Loss: 0.003324
Validation Loss: 0.00217728
Epoch [7/300], Train Loss: 0.003330
Validation Loss: 0.00215179
Epoch [8/300], Train Loss: 0.003310
Validation Loss: 0.00215095
Epoch [9/300], Train Loss: 0.003269
Validation Loss: 0.00218299
Epoch [10/300], Train Loss: 0.003227
Validation Loss: 0.00213123
Epoch [11/300], Train Loss: 0.003213
Validation Loss: 0.00213389
Epoch [12/300], Train Loss: 0.003230
Validation Loss: 0.00212964
Epoch [13/300], Train Loss: 0.003243
Validation Loss: 0.00213657
Epoch [14/300], Train Loss: 0.003246
Validation Loss: 0.00211423
Epoch [15/300], Train Loss: 0.003217
Validation Loss: 0.00211071
Epoch [16/300], Train Loss: 0.003243
Validation Loss: 0.00215273
Epoch [17/300], Train Loss: 0.003206
Validation Loss: 0.00216989
Epoch [18/300], Train Loss: 0.003247
Validation Loss: 0.00219205
Epoch [19/300], Train Loss: 0.003212
Validation Loss: 0.00210565
Epoch [20/300], Train Loss: 0.003205
Validation Loss: 0.00212419
Epoch [21/300], Train Loss: 0.003218
Validation Loss: 0.00210631
Epoch [22/300], Train Loss: 0.003247
Validation Loss: 0.00211181
Epoch [23/300], Train Loss: 0.003204
Validation Loss: 0.00216629
Epoch [24/300], Train Loss: 0.003196
Validation Loss: 0.00216567
Epoch [25/300], Train Loss: 0.003226
Validation Loss: 0.00212824
Epoch [26/300], Train Loss: 0.003206
Validation Loss: 0.00213929
Epoch [27/300], Train Loss: 0.003243
Validation Loss: 0.00215065
Epoch [28/300], Train Loss: 0.003216
Validation Loss: 0.00212728
Epoch [29/300], Train Loss: 0.003194
Validation Loss: 0.00212071
Early stopping triggered

Evaluating model for: Laptop
Run 5/72 completed in 78.84 seconds with: {'MAE': np.float32(3.00743), 'MSE': np.float32(39.36693), 'RMSE': np.float32(6.274307), 'SAE': np.float32(0.033013146), 'NDE': np.float32(0.73362976)}

Run 6/72: hidden=128, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Laptop
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.011350
Validation Loss: 0.00596686
Epoch [2/300], Train Loss: 0.005818
Validation Loss: 0.00252446
Epoch [3/300], Train Loss: 0.003623
Validation Loss: 0.00250304
Epoch [4/300], Train Loss: 0.003509
Validation Loss: 0.00230243
Epoch [5/300], Train Loss: 0.003550
Validation Loss: 0.00232946
Epoch [6/300], Train Loss: 0.003549
Validation Loss: 0.00231791
Epoch [7/300], Train Loss: 0.003550
Validation Loss: 0.00231475
Epoch [8/300], Train Loss: 0.003529
Validation Loss: 0.00230421
Epoch [9/300], Train Loss: 0.003496
Validation Loss: 0.00231819
Epoch [10/300], Train Loss: 0.003456
Validation Loss: 0.00229468
Epoch [11/300], Train Loss: 0.003436
Validation Loss: 0.00229035
Epoch [12/300], Train Loss: 0.003453
Validation Loss: 0.00228101
Epoch [13/300], Train Loss: 0.003472
Validation Loss: 0.00228416
Epoch [14/300], Train Loss: 0.003472
Validation Loss: 0.00226664
Epoch [15/300], Train Loss: 0.003443
Validation Loss: 0.00226794
Epoch [16/300], Train Loss: 0.003464
Validation Loss: 0.00227371
Epoch [17/300], Train Loss: 0.003423
Validation Loss: 0.00227639
Epoch [18/300], Train Loss: 0.003459
Validation Loss: 0.00228069
Epoch [19/300], Train Loss: 0.003417
Validation Loss: 0.00222773
Epoch [20/300], Train Loss: 0.003404
Validation Loss: 0.00226046
Epoch [21/300], Train Loss: 0.003409
Validation Loss: 0.00221308
Epoch [22/300], Train Loss: 0.003431
Validation Loss: 0.00222426
Epoch [23/300], Train Loss: 0.003376
Validation Loss: 0.00225080
Epoch [24/300], Train Loss: 0.003357
Validation Loss: 0.00224478
Epoch [25/300], Train Loss: 0.003384
Validation Loss: 0.00221271
Epoch [26/300], Train Loss: 0.003356
Validation Loss: 0.00222047
Epoch [27/300], Train Loss: 0.003384
Validation Loss: 0.00223419
Epoch [28/300], Train Loss: 0.003353
Validation Loss: 0.00221398
Epoch [29/300], Train Loss: 0.003328
Validation Loss: 0.00219525
Epoch [30/300], Train Loss: 0.003326
Validation Loss: 0.00219514
Epoch [31/300], Train Loss: 0.003294
Validation Loss: 0.00223578
Epoch [32/300], Train Loss: 0.003325
Validation Loss: 0.00218965
Epoch [33/300], Train Loss: 0.003321
Validation Loss: 0.00223997
Epoch [34/300], Train Loss: 0.003309
Validation Loss: 0.00227840
Epoch [35/300], Train Loss: 0.003322
Validation Loss: 0.00219697
Epoch [36/300], Train Loss: 0.003301
Validation Loss: 0.00219667
Epoch [37/300], Train Loss: 0.003303
Validation Loss: 0.00218018
Epoch [38/300], Train Loss: 0.003272
Validation Loss: 0.00223670
Epoch [39/300], Train Loss: 0.003292
Validation Loss: 0.00218797
Epoch [40/300], Train Loss: 0.003316
Validation Loss: 0.00218869
Epoch [41/300], Train Loss: 0.003305
Validation Loss: 0.00220310
Epoch [42/300], Train Loss: 0.003263
Validation Loss: 0.00219474
Epoch [43/300], Train Loss: 0.003262
Validation Loss: 0.00222246
Epoch [44/300], Train Loss: 0.003300
Validation Loss: 0.00221001
Epoch [45/300], Train Loss: 0.003305
Validation Loss: 0.00223645
Epoch [46/300], Train Loss: 0.003297
Validation Loss: 0.00217505
Epoch [47/300], Train Loss: 0.003249
Validation Loss: 0.00216772
Epoch [48/300], Train Loss: 0.003268
Validation Loss: 0.00221686
Epoch [49/300], Train Loss: 0.003275
Validation Loss: 0.00219406
Epoch [50/300], Train Loss: 0.003266
Validation Loss: 0.00221971
Epoch [51/300], Train Loss: 0.003302
Validation Loss: 0.00216939
Epoch [52/300], Train Loss: 0.003318
Validation Loss: 0.00219396
Epoch [53/300], Train Loss: 0.003258
Validation Loss: 0.00220059
Epoch [54/300], Train Loss: 0.003278
Validation Loss: 0.00224351
Epoch [55/300], Train Loss: 0.003249
Validation Loss: 0.00218049
Epoch [56/300], Train Loss: 0.003250
Validation Loss: 0.00221626
Epoch [57/300], Train Loss: 0.003236
Validation Loss: 0.00219529
Early stopping triggered

Evaluating model for: Laptop
Run 6/72 completed in 158.95 seconds with: {'MAE': np.float32(3.1090288), 'MSE': np.float32(39.60006), 'RMSE': np.float32(6.2928576), 'SAE': np.float32(0.023004444), 'NDE': np.float32(0.73579884)}

Run 7/72: hidden=128, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Laptop
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.003416
Validation Loss: 0.00225687
Epoch [2/300], Train Loss: 0.003295
Validation Loss: 0.00215689
Epoch [3/300], Train Loss: 0.003300
Validation Loss: 0.00217977
Epoch [4/300], Train Loss: 0.003251
Validation Loss: 0.00216948
Epoch [5/300], Train Loss: 0.003312
Validation Loss: 0.00216450
Epoch [6/300], Train Loss: 0.003315
Validation Loss: 0.00217484
Epoch [7/300], Train Loss: 0.003325
Validation Loss: 0.00215874
Epoch [8/300], Train Loss: 0.003308
Validation Loss: 0.00215941
Epoch [9/300], Train Loss: 0.003275
Validation Loss: 0.00219062
Epoch [10/300], Train Loss: 0.003233
Validation Loss: 0.00213400
Epoch [11/300], Train Loss: 0.003216
Validation Loss: 0.00213269
Epoch [12/300], Train Loss: 0.003223
Validation Loss: 0.00211293
Epoch [13/300], Train Loss: 0.003219
Validation Loss: 0.00213284
Epoch [14/300], Train Loss: 0.003216
Validation Loss: 0.00211681
Epoch [15/300], Train Loss: 0.003171
Validation Loss: 0.00210089
Epoch [16/300], Train Loss: 0.003203
Validation Loss: 0.00211597
Epoch [17/300], Train Loss: 0.003156
Validation Loss: 0.00217865
Epoch [18/300], Train Loss: 0.003200
Validation Loss: 0.00224780
Epoch [19/300], Train Loss: 0.003159
Validation Loss: 0.00212120
Epoch [20/300], Train Loss: 0.003144
Validation Loss: 0.00213179
Epoch [21/300], Train Loss: 0.003180
Validation Loss: 0.00211922
Epoch [22/300], Train Loss: 0.003199
Validation Loss: 0.00213407
Epoch [23/300], Train Loss: 0.003155
Validation Loss: 0.00221306
Epoch [24/300], Train Loss: 0.003148
Validation Loss: 0.00220049
Epoch [25/300], Train Loss: 0.003177
Validation Loss: 0.00217705
Early stopping triggered

Evaluating model for: Laptop
Run 7/72 completed in 74.24 seconds with: {'MAE': np.float32(2.987657), 'MSE': np.float32(39.233173), 'RMSE': np.float32(6.263639), 'SAE': np.float32(0.0012168131), 'NDE': np.float32(0.7323824)}

Run 8/72: hidden=128, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Laptop
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.005632
Validation Loss: 0.00231232
Epoch [2/300], Train Loss: 0.003450
Validation Loss: 0.00236199
Epoch [3/300], Train Loss: 0.003399
Validation Loss: 0.00219439
Epoch [4/300], Train Loss: 0.003328
Validation Loss: 0.00223351
Epoch [5/300], Train Loss: 0.003388
Validation Loss: 0.00220695
Epoch [6/300], Train Loss: 0.003390
Validation Loss: 0.00222274
Epoch [7/300], Train Loss: 0.003401
Validation Loss: 0.00220503
Epoch [8/300], Train Loss: 0.003384
Validation Loss: 0.00220501
Epoch [9/300], Train Loss: 0.003351
Validation Loss: 0.00222580
Epoch [10/300], Train Loss: 0.003312
Validation Loss: 0.00219472
Epoch [11/300], Train Loss: 0.003300
Validation Loss: 0.00219995
Epoch [12/300], Train Loss: 0.003321
Validation Loss: 0.00218836
Epoch [13/300], Train Loss: 0.003342
Validation Loss: 0.00219832
Epoch [14/300], Train Loss: 0.003346
Validation Loss: 0.00217915
Epoch [15/300], Train Loss: 0.003319
Validation Loss: 0.00218415
Epoch [16/300], Train Loss: 0.003344
Validation Loss: 0.00219383
Epoch [17/300], Train Loss: 0.003303
Validation Loss: 0.00219520
Epoch [18/300], Train Loss: 0.003334
Validation Loss: 0.00220525
Epoch [19/300], Train Loss: 0.003282
Validation Loss: 0.00211895
Epoch [20/300], Train Loss: 0.003255
Validation Loss: 0.00211791
Epoch [21/300], Train Loss: 0.003267
Validation Loss: 0.00212130
Epoch [22/300], Train Loss: 0.003291
Validation Loss: 0.00211510
Epoch [23/300], Train Loss: 0.003232
Validation Loss: 0.00217000
Epoch [24/300], Train Loss: 0.003223
Validation Loss: 0.00220097
Epoch [25/300], Train Loss: 0.003243
Validation Loss: 0.00216596
Epoch [26/300], Train Loss: 0.003223
Validation Loss: 0.00217371
Epoch [27/300], Train Loss: 0.003257
Validation Loss: 0.00217670
Epoch [28/300], Train Loss: 0.003225
Validation Loss: 0.00217010
Epoch [29/300], Train Loss: 0.003208
Validation Loss: 0.00218044
Epoch [30/300], Train Loss: 0.003202
Validation Loss: 0.00215588
Epoch [31/300], Train Loss: 0.003171
Validation Loss: 0.00220666
Epoch [32/300], Train Loss: 0.003204
Validation Loss: 0.00217157
Early stopping triggered

Evaluating model for: Laptop
Run 8/72 completed in 92.97 seconds with: {'MAE': np.float32(3.0292568), 'MSE': np.float32(39.597004), 'RMSE': np.float32(6.292615), 'SAE': np.float32(0.05335998), 'NDE': np.float32(0.7357704)}

Run 9/72: hidden=128, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Laptop
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.004182
Validation Loss: 0.00383800
Epoch [2/300], Train Loss: 0.003376
Validation Loss: 0.00364368
Epoch [3/300], Train Loss: 0.003294
Validation Loss: 0.00364638
Epoch [4/300], Train Loss: 0.003298
Validation Loss: 0.00362004
Epoch [5/300], Train Loss: 0.003284
Validation Loss: 0.00361909
Epoch [6/300], Train Loss: 0.003361
Validation Loss: 0.00361610
Epoch [7/300], Train Loss: 0.003319
Validation Loss: 0.00361590
Epoch [8/300], Train Loss: 0.003416
Validation Loss: 0.00361157
Epoch [9/300], Train Loss: 0.003290
Validation Loss: 0.00361186
Epoch [10/300], Train Loss: 0.003295
Validation Loss: 0.00360414
Epoch [11/300], Train Loss: 0.003338
Validation Loss: 0.00360157
Epoch [12/300], Train Loss: 0.003276
Validation Loss: 0.00360239
Epoch [13/300], Train Loss: 0.003297
Validation Loss: 0.00359412
Epoch [14/300], Train Loss: 0.003294
Validation Loss: 0.00360258
Epoch [15/300], Train Loss: 0.003298
Validation Loss: 0.00358760
Epoch [16/300], Train Loss: 0.003228
Validation Loss: 0.00359104
Epoch [17/300], Train Loss: 0.003304
Validation Loss: 0.00358190
Epoch [18/300], Train Loss: 0.003258
Validation Loss: 0.00358491
Epoch [19/300], Train Loss: 0.003242
Validation Loss: 0.00357935
Epoch [20/300], Train Loss: 0.003249
Validation Loss: 0.00357243
Epoch [21/300], Train Loss: 0.003229
Validation Loss: 0.00357151
Epoch [22/300], Train Loss: 0.003208
Validation Loss: 0.00356961
Epoch [23/300], Train Loss: 0.003278
Validation Loss: 0.00356371
Epoch [24/300], Train Loss: 0.003236
Validation Loss: 0.00356472
Epoch [25/300], Train Loss: 0.003244
Validation Loss: 0.00356132
Epoch [26/300], Train Loss: 0.003224
Validation Loss: 0.00355868
Epoch [27/300], Train Loss: 0.003254
Validation Loss: 0.00355538
Epoch [28/300], Train Loss: 0.003200
Validation Loss: 0.00355431
Epoch [29/300], Train Loss: 0.003232
Validation Loss: 0.00355637
Epoch [30/300], Train Loss: 0.003331
Validation Loss: 0.00355196
Epoch [31/300], Train Loss: 0.003241
Validation Loss: 0.00355421
Epoch [32/300], Train Loss: 0.003221
Validation Loss: 0.00354980
Epoch [33/300], Train Loss: 0.003329
Validation Loss: 0.00354802
Epoch [34/300], Train Loss: 0.003238
Validation Loss: 0.00355036
Epoch [35/300], Train Loss: 0.003284
Validation Loss: 0.00354527
Epoch [36/300], Train Loss: 0.003184
Validation Loss: 0.00355325
Epoch [37/300], Train Loss: 0.003240
Validation Loss: 0.00354385
Epoch [38/300], Train Loss: 0.003237
Validation Loss: 0.00355098
Epoch [39/300], Train Loss: 0.003166
Validation Loss: 0.00354311
Epoch [40/300], Train Loss: 0.003173
Validation Loss: 0.00354321
Epoch [41/300], Train Loss: 0.003176
Validation Loss: 0.00354215
Epoch [42/300], Train Loss: 0.003209
Validation Loss: 0.00353753
Epoch [43/300], Train Loss: 0.003198
Validation Loss: 0.00353701
Epoch [44/300], Train Loss: 0.003340
Validation Loss: 0.00353360
Epoch [45/300], Train Loss: 0.003218
Validation Loss: 0.00353893
Epoch [46/300], Train Loss: 0.003220
Validation Loss: 0.00353002
Epoch [47/300], Train Loss: 0.003220
Validation Loss: 0.00352751
Epoch [48/300], Train Loss: 0.003249
Validation Loss: 0.00352686
Epoch [49/300], Train Loss: 0.003160
Validation Loss: 0.00352230
Epoch [50/300], Train Loss: 0.003156
Validation Loss: 0.00351573
Epoch [51/300], Train Loss: 0.003180
Validation Loss: 0.00350949
Epoch [52/300], Train Loss: 0.003204
Validation Loss: 0.00350556
Epoch [53/300], Train Loss: 0.003125
Validation Loss: 0.00349430
Epoch [54/300], Train Loss: 0.003125
Validation Loss: 0.00348423
Epoch [55/300], Train Loss: 0.003115
Validation Loss: 0.00346539
Epoch [56/300], Train Loss: 0.003120
Validation Loss: 0.00344693
Epoch [57/300], Train Loss: 0.003081
Validation Loss: 0.00342311
Epoch [58/300], Train Loss: 0.003040
Validation Loss: 0.00338784
Epoch [59/300], Train Loss: 0.002990
Validation Loss: 0.00335193
Epoch [60/300], Train Loss: 0.003075
Validation Loss: 0.00327634
Epoch [61/300], Train Loss: 0.003005
Validation Loss: 0.00323073
Epoch [62/300], Train Loss: 0.002897
Validation Loss: 0.00313873
Epoch [63/300], Train Loss: 0.002920
Validation Loss: 0.00332972
Epoch [64/300], Train Loss: 0.002832
Validation Loss: 0.00310476
Epoch [65/300], Train Loss: 0.002732
Validation Loss: 0.00298671
Epoch [66/300], Train Loss: 0.002764
Validation Loss: 0.00300661
Epoch [67/300], Train Loss: 0.002700
Validation Loss: 0.00273021
Epoch [68/300], Train Loss: 0.002644
Validation Loss: 0.00265363
Epoch [69/300], Train Loss: 0.002504
Validation Loss: 0.00257593
Epoch [70/300], Train Loss: 0.002401
Validation Loss: 0.00250571
Epoch [71/300], Train Loss: 0.002304
Validation Loss: 0.00234162
Epoch [72/300], Train Loss: 0.002245
Validation Loss: 0.00227634
Epoch [73/300], Train Loss: 0.002202
Validation Loss: 0.00234986
Epoch [74/300], Train Loss: 0.002131
Validation Loss: 0.00221866
Epoch [75/300], Train Loss: 0.002132
Validation Loss: 0.00217757
Epoch [76/300], Train Loss: 0.001967
Validation Loss: 0.00199355
Epoch [77/300], Train Loss: 0.001897
Validation Loss: 0.00189615
Epoch [78/300], Train Loss: 0.001830
Validation Loss: 0.00190720
Epoch [79/300], Train Loss: 0.001754
Validation Loss: 0.00180245
Epoch [80/300], Train Loss: 0.001859
Validation Loss: 0.00204611
Epoch [81/300], Train Loss: 0.001879
Validation Loss: 0.00181913
Epoch [82/300], Train Loss: 0.001704
Validation Loss: 0.00179136
Epoch [83/300], Train Loss: 0.001701
Validation Loss: 0.00165038
Epoch [84/300], Train Loss: 0.001584
Validation Loss: 0.00163235
Epoch [85/300], Train Loss: 0.001610
Validation Loss: 0.00158829
Epoch [86/300], Train Loss: 0.001602
Validation Loss: 0.00161139
Epoch [87/300], Train Loss: 0.001505
Validation Loss: 0.00149036
Epoch [88/300], Train Loss: 0.001523
Validation Loss: 0.00146084
Epoch [89/300], Train Loss: 0.001536
Validation Loss: 0.00150673
Epoch [90/300], Train Loss: 0.001367
Validation Loss: 0.00139472
Epoch [91/300], Train Loss: 0.001347
Validation Loss: 0.00136572
Epoch [92/300], Train Loss: 0.001307
Validation Loss: 0.00135024
Epoch [93/300], Train Loss: 0.001299
Validation Loss: 0.00131531
Epoch [94/300], Train Loss: 0.001304
Validation Loss: 0.00129782
Epoch [95/300], Train Loss: 0.001289
Validation Loss: 0.00128225
Epoch [96/300], Train Loss: 0.001254
Validation Loss: 0.00127126
Epoch [97/300], Train Loss: 0.001236
Validation Loss: 0.00126809
Epoch [98/300], Train Loss: 0.001227
Validation Loss: 0.00126195
Epoch [99/300], Train Loss: 0.001232
Validation Loss: 0.00127275
Epoch [100/300], Train Loss: 0.001227
Validation Loss: 0.00123732
Epoch [101/300], Train Loss: 0.001207
Validation Loss: 0.00123737
Epoch [102/300], Train Loss: 0.001201
Validation Loss: 0.00124789
Epoch [103/300], Train Loss: 0.001215
Validation Loss: 0.00122805
Epoch [104/300], Train Loss: 0.001231
Validation Loss: 0.00123007
Epoch [105/300], Train Loss: 0.001189
Validation Loss: 0.00122949
Epoch [106/300], Train Loss: 0.001192
Validation Loss: 0.00119023
Epoch [107/300], Train Loss: 0.001173
Validation Loss: 0.00119441
Epoch [108/300], Train Loss: 0.001160
Validation Loss: 0.00117991
Epoch [109/300], Train Loss: 0.001163
Validation Loss: 0.00116100
Epoch [110/300], Train Loss: 0.001152
Validation Loss: 0.00116977
Epoch [111/300], Train Loss: 0.001162
Validation Loss: 0.00115231
Epoch [112/300], Train Loss: 0.001151
Validation Loss: 0.00115135
Epoch [113/300], Train Loss: 0.001167
Validation Loss: 0.00114475
Epoch [114/300], Train Loss: 0.001145
Validation Loss: 0.00113254
Epoch [115/300], Train Loss: 0.001124
Validation Loss: 0.00112701
Epoch [116/300], Train Loss: 0.001142
Validation Loss: 0.00115079
Epoch [117/300], Train Loss: 0.001128
Validation Loss: 0.00111831
Epoch [118/300], Train Loss: 0.001146
Validation Loss: 0.00113920
Epoch [119/300], Train Loss: 0.001108
Validation Loss: 0.00111862
Epoch [120/300], Train Loss: 0.001105
Validation Loss: 0.00111242
Epoch [121/300], Train Loss: 0.001122
Validation Loss: 0.00111079
Epoch [122/300], Train Loss: 0.001090
Validation Loss: 0.00112963
Epoch [123/300], Train Loss: 0.001117
Validation Loss: 0.00110062
Epoch [124/300], Train Loss: 0.001081
Validation Loss: 0.00111431
Epoch [125/300], Train Loss: 0.001076
Validation Loss: 0.00110292
Epoch [126/300], Train Loss: 0.001104
Validation Loss: 0.00109674
Epoch [127/300], Train Loss: 0.001069
Validation Loss: 0.00110372
Epoch [128/300], Train Loss: 0.001084
Validation Loss: 0.00109321
Epoch [129/300], Train Loss: 0.001079
Validation Loss: 0.00111125
Epoch [130/300], Train Loss: 0.001096
Validation Loss: 0.00109520
Epoch [131/300], Train Loss: 0.001080
Validation Loss: 0.00109011
Epoch [132/300], Train Loss: 0.001063
Validation Loss: 0.00108102
Epoch [133/300], Train Loss: 0.001051
Validation Loss: 0.00108524
Epoch [134/300], Train Loss: 0.001048
Validation Loss: 0.00107855
Epoch [135/300], Train Loss: 0.001043
Validation Loss: 0.00110175
Epoch [136/300], Train Loss: 0.001031
Validation Loss: 0.00108091
Epoch [137/300], Train Loss: 0.001039
Validation Loss: 0.00106525
Epoch [138/300], Train Loss: 0.001012
Validation Loss: 0.00107691
Epoch [139/300], Train Loss: 0.001033
Validation Loss: 0.00106781
Epoch [140/300], Train Loss: 0.001040
Validation Loss: 0.00107070
Epoch [141/300], Train Loss: 0.001012
Validation Loss: 0.00106138
Epoch [142/300], Train Loss: 0.001017
Validation Loss: 0.00106732
Epoch [143/300], Train Loss: 0.001016
Validation Loss: 0.00105889
Epoch [144/300], Train Loss: 0.001006
Validation Loss: 0.00105039
Epoch [145/300], Train Loss: 0.000999
Validation Loss: 0.00107987
Epoch [146/300], Train Loss: 0.001026
Validation Loss: 0.00106059
Epoch [147/300], Train Loss: 0.001014
Validation Loss: 0.00105871
Epoch [148/300], Train Loss: 0.000988
Validation Loss: 0.00104256
Epoch [149/300], Train Loss: 0.001018
Validation Loss: 0.00104520
Epoch [150/300], Train Loss: 0.000979
Validation Loss: 0.00102129
Epoch [151/300], Train Loss: 0.000989
Validation Loss: 0.00102821
Epoch [152/300], Train Loss: 0.000979
Validation Loss: 0.00103824
Epoch [153/300], Train Loss: 0.000982
Validation Loss: 0.00103847
Epoch [154/300], Train Loss: 0.000990
Validation Loss: 0.00102560
Epoch [155/300], Train Loss: 0.000958
Validation Loss: 0.00101512
Epoch [156/300], Train Loss: 0.000972
Validation Loss: 0.00101373
Epoch [157/300], Train Loss: 0.000968
Validation Loss: 0.00104923
Epoch [158/300], Train Loss: 0.000971
Validation Loss: 0.00101488
Epoch [159/300], Train Loss: 0.000995
Validation Loss: 0.00099819
Epoch [160/300], Train Loss: 0.000955
Validation Loss: 0.00102128
Epoch [161/300], Train Loss: 0.000960
Validation Loss: 0.00100549
Epoch [162/300], Train Loss: 0.000940
Validation Loss: 0.00099996
Epoch [163/300], Train Loss: 0.000961
Validation Loss: 0.00098913
Epoch [164/300], Train Loss: 0.000967
Validation Loss: 0.00101424
Epoch [165/300], Train Loss: 0.000979
Validation Loss: 0.00100457
Epoch [166/300], Train Loss: 0.000958
Validation Loss: 0.00099567
Epoch [167/300], Train Loss: 0.000928
Validation Loss: 0.00099684
Epoch [168/300], Train Loss: 0.000952
Validation Loss: 0.00099043
Epoch [169/300], Train Loss: 0.000924
Validation Loss: 0.00098527
Epoch [170/300], Train Loss: 0.000918
Validation Loss: 0.00098875
Epoch [171/300], Train Loss: 0.000929
Validation Loss: 0.00097761
Epoch [172/300], Train Loss: 0.000919
Validation Loss: 0.00097557
Epoch [173/300], Train Loss: 0.000910
Validation Loss: 0.00100715
Epoch [174/300], Train Loss: 0.000941
Validation Loss: 0.00097821
Epoch [175/300], Train Loss: 0.000904
Validation Loss: 0.00097071
Epoch [176/300], Train Loss: 0.000917
Validation Loss: 0.00097498
Epoch [177/300], Train Loss: 0.000899
Validation Loss: 0.00097339
Epoch [178/300], Train Loss: 0.000902
Validation Loss: 0.00097428
Epoch [179/300], Train Loss: 0.000911
Validation Loss: 0.00096141
Epoch [180/300], Train Loss: 0.000895
Validation Loss: 0.00097360
Epoch [181/300], Train Loss: 0.000887
Validation Loss: 0.00096291
Epoch [182/300], Train Loss: 0.000872
Validation Loss: 0.00096952
Epoch [183/300], Train Loss: 0.000881
Validation Loss: 0.00095509
Epoch [184/300], Train Loss: 0.000880
Validation Loss: 0.00096015
Epoch [185/300], Train Loss: 0.000883
Validation Loss: 0.00096518
Epoch [186/300], Train Loss: 0.000868
Validation Loss: 0.00097369
Epoch [187/300], Train Loss: 0.000868
Validation Loss: 0.00096692
Epoch [188/300], Train Loss: 0.000861
Validation Loss: 0.00094817
Epoch [189/300], Train Loss: 0.000869
Validation Loss: 0.00098144
Epoch [190/300], Train Loss: 0.000861
Validation Loss: 0.00096025
Epoch [191/300], Train Loss: 0.000861
Validation Loss: 0.00096646
Epoch [192/300], Train Loss: 0.000855
Validation Loss: 0.00095705
Epoch [193/300], Train Loss: 0.000849
Validation Loss: 0.00094923
Epoch [194/300], Train Loss: 0.000830
Validation Loss: 0.00095806
Epoch [195/300], Train Loss: 0.000844
Validation Loss: 0.00095283
Epoch [196/300], Train Loss: 0.000822
Validation Loss: 0.00095122
Epoch [197/300], Train Loss: 0.000824
Validation Loss: 0.00095299
Epoch [198/300], Train Loss: 0.000830
Validation Loss: 0.00094716
Epoch [199/300], Train Loss: 0.000826
Validation Loss: 0.00095294
Epoch [200/300], Train Loss: 0.000820
Validation Loss: 0.00094619
Epoch [201/300], Train Loss: 0.000817
Validation Loss: 0.00094079
Epoch [202/300], Train Loss: 0.000821
Validation Loss: 0.00092948
Epoch [203/300], Train Loss: 0.000960
Validation Loss: 0.00121563
Epoch [204/300], Train Loss: 0.001175
Validation Loss: 0.00101298
Epoch [205/300], Train Loss: 0.001015
Validation Loss: 0.00092457
Epoch [206/300], Train Loss: 0.000948
Validation Loss: 0.00093810
Epoch [207/300], Train Loss: 0.000976
Validation Loss: 0.00094032
Epoch [208/300], Train Loss: 0.000934
Validation Loss: 0.00093364
Epoch [209/300], Train Loss: 0.000954
Validation Loss: 0.00093543
Epoch [210/300], Train Loss: 0.000912
Validation Loss: 0.00093778
Epoch [211/300], Train Loss: 0.000905
Validation Loss: 0.00093534
Epoch [212/300], Train Loss: 0.000906
Validation Loss: 0.00093597
Epoch [213/300], Train Loss: 0.000895
Validation Loss: 0.00093050
Epoch [214/300], Train Loss: 0.000895
Validation Loss: 0.00092986
Epoch [215/300], Train Loss: 0.000912
Validation Loss: 0.00093810
Early stopping triggered

Evaluating model for: Laptop
Run 9/72 completed in 414.66 seconds with: {'MAE': np.float32(1.4014161), 'MSE': np.float32(5.107258), 'RMSE': np.float32(2.2599244), 'SAE': np.float32(0.024448168), 'NDE': np.float32(0.30484495)}

Run 10/72: hidden=128, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Laptop
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.006627
Validation Loss: 0.00535827
Epoch [2/300], Train Loss: 0.004293
Validation Loss: 0.00379979
Epoch [3/300], Train Loss: 0.003392
Validation Loss: 0.00376800
Epoch [4/300], Train Loss: 0.003381
Validation Loss: 0.00365767
Epoch [5/300], Train Loss: 0.003342
Validation Loss: 0.00365447
Epoch [6/300], Train Loss: 0.003416
Validation Loss: 0.00365413
Epoch [7/300], Train Loss: 0.003376
Validation Loss: 0.00365354
Epoch [8/300], Train Loss: 0.003470
Validation Loss: 0.00364859
Epoch [9/300], Train Loss: 0.003344
Validation Loss: 0.00365092
Epoch [10/300], Train Loss: 0.003350
Validation Loss: 0.00364271
Epoch [11/300], Train Loss: 0.003393
Validation Loss: 0.00364123
Epoch [12/300], Train Loss: 0.003334
Validation Loss: 0.00364039
Epoch [13/300], Train Loss: 0.003355
Validation Loss: 0.00363410
Epoch [14/300], Train Loss: 0.003352
Validation Loss: 0.00364543
Epoch [15/300], Train Loss: 0.003353
Validation Loss: 0.00362820
Epoch [16/300], Train Loss: 0.003286
Validation Loss: 0.00363334
Epoch [17/300], Train Loss: 0.003361
Validation Loss: 0.00362214
Epoch [18/300], Train Loss: 0.003311
Validation Loss: 0.00362702
Epoch [19/300], Train Loss: 0.003293
Validation Loss: 0.00361511
Epoch [20/300], Train Loss: 0.003302
Validation Loss: 0.00360819
Epoch [21/300], Train Loss: 0.003278
Validation Loss: 0.00360436
Epoch [22/300], Train Loss: 0.003253
Validation Loss: 0.00359929
Epoch [23/300], Train Loss: 0.003323
Validation Loss: 0.00359061
Epoch [24/300], Train Loss: 0.003280
Validation Loss: 0.00358690
Epoch [25/300], Train Loss: 0.003285
Validation Loss: 0.00358663
Epoch [26/300], Train Loss: 0.003261
Validation Loss: 0.00357933
Epoch [27/300], Train Loss: 0.003294
Validation Loss: 0.00357517
Epoch [28/300], Train Loss: 0.003235
Validation Loss: 0.00357540
Epoch [29/300], Train Loss: 0.003268
Validation Loss: 0.00357876
Epoch [30/300], Train Loss: 0.003368
Validation Loss: 0.00357321
Epoch [31/300], Train Loss: 0.003280
Validation Loss: 0.00357281
Epoch [32/300], Train Loss: 0.003257
Validation Loss: 0.00357048
Epoch [33/300], Train Loss: 0.003363
Validation Loss: 0.00356862
Epoch [34/300], Train Loss: 0.003276
Validation Loss: 0.00356729
Epoch [35/300], Train Loss: 0.003323
Validation Loss: 0.00357195
Epoch [36/300], Train Loss: 0.003225
Validation Loss: 0.00356677
Epoch [37/300], Train Loss: 0.003281
Validation Loss: 0.00357104
Epoch [38/300], Train Loss: 0.003279
Validation Loss: 0.00357055
Epoch [39/300], Train Loss: 0.003203
Validation Loss: 0.00356598
Epoch [40/300], Train Loss: 0.003212
Validation Loss: 0.00357018
Epoch [41/300], Train Loss: 0.003216
Validation Loss: 0.00356528
Epoch [42/300], Train Loss: 0.003251
Validation Loss: 0.00356116
Epoch [43/300], Train Loss: 0.003239
Validation Loss: 0.00356510
Epoch [44/300], Train Loss: 0.003389
Validation Loss: 0.00355974
Epoch [45/300], Train Loss: 0.003263
Validation Loss: 0.00356815
Epoch [46/300], Train Loss: 0.003267
Validation Loss: 0.00355863
Epoch [47/300], Train Loss: 0.003267
Validation Loss: 0.00356081
Epoch [48/300], Train Loss: 0.003299
Validation Loss: 0.00355921
Epoch [49/300], Train Loss: 0.003212
Validation Loss: 0.00355831
Epoch [50/300], Train Loss: 0.003212
Validation Loss: 0.00355749
Epoch [51/300], Train Loss: 0.003243
Validation Loss: 0.00355604
Epoch [52/300], Train Loss: 0.003274
Validation Loss: 0.00355948
Epoch [53/300], Train Loss: 0.003201
Validation Loss: 0.00355484
Epoch [54/300], Train Loss: 0.003210
Validation Loss: 0.00355760
Epoch [55/300], Train Loss: 0.003215
Validation Loss: 0.00355412
Epoch [56/300], Train Loss: 0.003235
Validation Loss: 0.00355656
Epoch [57/300], Train Loss: 0.003221
Validation Loss: 0.00355421
Epoch [58/300], Train Loss: 0.003206
Validation Loss: 0.00355596
Epoch [59/300], Train Loss: 0.003191
Validation Loss: 0.00355259
Epoch [60/300], Train Loss: 0.003320
Validation Loss: 0.00355299
Epoch [61/300], Train Loss: 0.003292
Validation Loss: 0.00355131
Epoch [62/300], Train Loss: 0.003207
Validation Loss: 0.00355170
Epoch [63/300], Train Loss: 0.003271
Validation Loss: 0.00355450
Epoch [64/300], Train Loss: 0.003237
Validation Loss: 0.00355212
Epoch [65/300], Train Loss: 0.003182
Validation Loss: 0.00355310
Epoch [66/300], Train Loss: 0.003258
Validation Loss: 0.00355084
Epoch [67/300], Train Loss: 0.003287
Validation Loss: 0.00354846
Epoch [68/300], Train Loss: 0.003275
Validation Loss: 0.00355039
Epoch [69/300], Train Loss: 0.003199
Validation Loss: 0.00355389
Epoch [70/300], Train Loss: 0.003169
Validation Loss: 0.00355399
Epoch [71/300], Train Loss: 0.003215
Validation Loss: 0.00354490
Epoch [72/300], Train Loss: 0.003224
Validation Loss: 0.00355031
Epoch [73/300], Train Loss: 0.003254
Validation Loss: 0.00354475
Epoch [74/300], Train Loss: 0.003197
Validation Loss: 0.00354371
Epoch [75/300], Train Loss: 0.003284
Validation Loss: 0.00354768
Epoch [76/300], Train Loss: 0.003283
Validation Loss: 0.00354434
Epoch [77/300], Train Loss: 0.003215
Validation Loss: 0.00354594
Epoch [78/300], Train Loss: 0.003240
Validation Loss: 0.00354041
Epoch [79/300], Train Loss: 0.003257
Validation Loss: 0.00354297
Epoch [80/300], Train Loss: 0.003215
Validation Loss: 0.00354009
Epoch [81/300], Train Loss: 0.003225
Validation Loss: 0.00354090
Epoch [82/300], Train Loss: 0.003213
Validation Loss: 0.00354409
Epoch [83/300], Train Loss: 0.003224
Validation Loss: 0.00353627
Epoch [84/300], Train Loss: 0.003236
Validation Loss: 0.00353788
Epoch [85/300], Train Loss: 0.003211
Validation Loss: 0.00353804
Epoch [86/300], Train Loss: 0.003333
Validation Loss: 0.00353839
Epoch [87/300], Train Loss: 0.003243
Validation Loss: 0.00354953
Epoch [88/300], Train Loss: 0.003230
Validation Loss: 0.00353437
Epoch [89/300], Train Loss: 0.003177
Validation Loss: 0.00353586
Epoch [90/300], Train Loss: 0.003165
Validation Loss: 0.00353377
Epoch [91/300], Train Loss: 0.003221
Validation Loss: 0.00353201
Epoch [92/300], Train Loss: 0.003159
Validation Loss: 0.00352946
Epoch [93/300], Train Loss: 0.003136
Validation Loss: 0.00353112
Epoch [94/300], Train Loss: 0.003238
Validation Loss: 0.00352820
Epoch [95/300], Train Loss: 0.003325
Validation Loss: 0.00353424
Epoch [96/300], Train Loss: 0.003148
Validation Loss: 0.00353513
Epoch [97/300], Train Loss: 0.003169
Validation Loss: 0.00353283
Epoch [98/300], Train Loss: 0.003269
Validation Loss: 0.00353119
Epoch [99/300], Train Loss: 0.003327
Validation Loss: 0.00352700
Epoch [100/300], Train Loss: 0.003211
Validation Loss: 0.00353791
Epoch [101/300], Train Loss: 0.003177
Validation Loss: 0.00353808
Epoch [102/300], Train Loss: 0.003151
Validation Loss: 0.00352710
Epoch [103/300], Train Loss: 0.003156
Validation Loss: 0.00352537
Epoch [104/300], Train Loss: 0.003226
Validation Loss: 0.00352561
Epoch [105/300], Train Loss: 0.003167
Validation Loss: 0.00352795
Epoch [106/300], Train Loss: 0.003142
Validation Loss: 0.00352338
Epoch [107/300], Train Loss: 0.003295
Validation Loss: 0.00352445
Epoch [108/300], Train Loss: 0.003208
Validation Loss: 0.00353267
Epoch [109/300], Train Loss: 0.003159
Validation Loss: 0.00351757
Epoch [110/300], Train Loss: 0.003176
Validation Loss: 0.00351516
Epoch [111/300], Train Loss: 0.003236
Validation Loss: 0.00351005
Epoch [112/300], Train Loss: 0.003170
Validation Loss: 0.00351370
Epoch [113/300], Train Loss: 0.003239
Validation Loss: 0.00350306
Epoch [114/300], Train Loss: 0.003233
Validation Loss: 0.00349975
Epoch [115/300], Train Loss: 0.003171
Validation Loss: 0.00351584
Epoch [116/300], Train Loss: 0.003221
Validation Loss: 0.00352668
Epoch [117/300], Train Loss: 0.003202
Validation Loss: 0.00352910
Epoch [118/300], Train Loss: 0.003258
Validation Loss: 0.00352543
Epoch [119/300], Train Loss: 0.003188
Validation Loss: 0.00352609
Epoch [120/300], Train Loss: 0.003158
Validation Loss: 0.00352529
Epoch [121/300], Train Loss: 0.003215
Validation Loss: 0.00352135
Epoch [122/300], Train Loss: 0.003154
Validation Loss: 0.00352219
Epoch [123/300], Train Loss: 0.003247
Validation Loss: 0.00352041
Epoch [124/300], Train Loss: 0.003092
Validation Loss: 0.00351895
Early stopping triggered

Evaluating model for: Laptop
Run 10/72 completed in 255.59 seconds with: {'MAE': np.float32(2.6629949), 'MSE': np.float32(23.582829), 'RMSE': np.float32(4.8562155), 'SAE': np.float32(0.09503159), 'NDE': np.float32(0.655063)}

Run 11/72: hidden=128, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Laptop
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.005901
Validation Loss: 0.00498602
Epoch [2/300], Train Loss: 0.004051
Validation Loss: 0.00372842
Epoch [3/300], Train Loss: 0.003340
Validation Loss: 0.00371828
Epoch [4/300], Train Loss: 0.003347
Validation Loss: 0.00364402
Epoch [5/300], Train Loss: 0.003316
Validation Loss: 0.00364160
Epoch [6/300], Train Loss: 0.003395
Validation Loss: 0.00364217
Epoch [7/300], Train Loss: 0.003355
Validation Loss: 0.00364455
Epoch [8/300], Train Loss: 0.003455
Validation Loss: 0.00364136
Epoch [9/300], Train Loss: 0.003330
Validation Loss: 0.00364402
Epoch [10/300], Train Loss: 0.003334
Validation Loss: 0.00363929
Epoch [11/300], Train Loss: 0.003383
Validation Loss: 0.00363901
Epoch [12/300], Train Loss: 0.003322
Validation Loss: 0.00364187
Epoch [13/300], Train Loss: 0.003345
Validation Loss: 0.00363707
Epoch [14/300], Train Loss: 0.003345
Validation Loss: 0.00364674
Epoch [15/300], Train Loss: 0.003350
Validation Loss: 0.00363488
Epoch [16/300], Train Loss: 0.003280
Validation Loss: 0.00363996
Epoch [17/300], Train Loss: 0.003363
Validation Loss: 0.00363364
Epoch [18/300], Train Loss: 0.003316
Validation Loss: 0.00363655
Epoch [19/300], Train Loss: 0.003301
Validation Loss: 0.00363639
Epoch [20/300], Train Loss: 0.003312
Validation Loss: 0.00363008
Epoch [21/300], Train Loss: 0.003294
Validation Loss: 0.00362965
Epoch [22/300], Train Loss: 0.003271
Validation Loss: 0.00363016
Epoch [23/300], Train Loss: 0.003344
Validation Loss: 0.00362387
Epoch [24/300], Train Loss: 0.003298
Validation Loss: 0.00362369
Epoch [25/300], Train Loss: 0.003307
Validation Loss: 0.00361855
Epoch [26/300], Train Loss: 0.003281
Validation Loss: 0.00361196
Epoch [27/300], Train Loss: 0.003308
Validation Loss: 0.00360126
Epoch [28/300], Train Loss: 0.003246
Validation Loss: 0.00359022
Epoch [29/300], Train Loss: 0.003270
Validation Loss: 0.00358236
Epoch [30/300], Train Loss: 0.003360
Validation Loss: 0.00357251
Epoch [31/300], Train Loss: 0.003276
Validation Loss: 0.00355669
Epoch [32/300], Train Loss: 0.003236
Validation Loss: 0.00355561
Epoch [33/300], Train Loss: 0.003343
Validation Loss: 0.00355213
Epoch [34/300], Train Loss: 0.003255
Validation Loss: 0.00355434
Epoch [35/300], Train Loss: 0.003297
Validation Loss: 0.00357482
Epoch [36/300], Train Loss: 0.003205
Validation Loss: 0.00355065
Epoch [37/300], Train Loss: 0.003259
Validation Loss: 0.00356230
Epoch [38/300], Train Loss: 0.003260
Validation Loss: 0.00354893
Epoch [39/300], Train Loss: 0.003179
Validation Loss: 0.00354772
Epoch [40/300], Train Loss: 0.003191
Validation Loss: 0.00355210
Epoch [41/300], Train Loss: 0.003194
Validation Loss: 0.00354661
Epoch [42/300], Train Loss: 0.003226
Validation Loss: 0.00354416
Epoch [43/300], Train Loss: 0.003213
Validation Loss: 0.00354552
Epoch [44/300], Train Loss: 0.003364
Validation Loss: 0.00354239
Epoch [45/300], Train Loss: 0.003235
Validation Loss: 0.00354822
Epoch [46/300], Train Loss: 0.003241
Validation Loss: 0.00353880
Epoch [47/300], Train Loss: 0.003240
Validation Loss: 0.00354036
Epoch [48/300], Train Loss: 0.003272
Validation Loss: 0.00353724
Epoch [49/300], Train Loss: 0.003185
Validation Loss: 0.00353567
Epoch [50/300], Train Loss: 0.003186
Validation Loss: 0.00353352
Epoch [51/300], Train Loss: 0.003212
Validation Loss: 0.00353322
Epoch [52/300], Train Loss: 0.003240
Validation Loss: 0.00353385
Epoch [53/300], Train Loss: 0.003173
Validation Loss: 0.00352803
Epoch [54/300], Train Loss: 0.003177
Validation Loss: 0.00352949
Epoch [55/300], Train Loss: 0.003181
Validation Loss: 0.00352633
Epoch [56/300], Train Loss: 0.003205
Validation Loss: 0.00352451
Epoch [57/300], Train Loss: 0.003189
Validation Loss: 0.00352253
Epoch [58/300], Train Loss: 0.003167
Validation Loss: 0.00351959
Epoch [59/300], Train Loss: 0.003149
Validation Loss: 0.00351478
Epoch [60/300], Train Loss: 0.003281
Validation Loss: 0.00351194
Epoch [61/300], Train Loss: 0.003248
Validation Loss: 0.00351792
Epoch [62/300], Train Loss: 0.003170
Validation Loss: 0.00351124
Epoch [63/300], Train Loss: 0.003233
Validation Loss: 0.00351562
Epoch [64/300], Train Loss: 0.003190
Validation Loss: 0.00350772
Epoch [65/300], Train Loss: 0.003134
Validation Loss: 0.00350394
Epoch [66/300], Train Loss: 0.003206
Validation Loss: 0.00350264
Epoch [67/300], Train Loss: 0.003238
Validation Loss: 0.00352110
Epoch [68/300], Train Loss: 0.003249
Validation Loss: 0.00352971
Epoch [69/300], Train Loss: 0.003159
Validation Loss: 0.00350793
Epoch [70/300], Train Loss: 0.003121
Validation Loss: 0.00350091
Epoch [71/300], Train Loss: 0.003165
Validation Loss: 0.00349768
Epoch [72/300], Train Loss: 0.003173
Validation Loss: 0.00349763
Epoch [73/300], Train Loss: 0.003199
Validation Loss: 0.00349424
Epoch [74/300], Train Loss: 0.003139
Validation Loss: 0.00349196
Epoch [75/300], Train Loss: 0.003229
Validation Loss: 0.00349719
Epoch [76/300], Train Loss: 0.003231
Validation Loss: 0.00349536
Epoch [77/300], Train Loss: 0.003166
Validation Loss: 0.00349696
Epoch [78/300], Train Loss: 0.003186
Validation Loss: 0.00348924
Epoch [79/300], Train Loss: 0.003209
Validation Loss: 0.00349020
Epoch [80/300], Train Loss: 0.003166
Validation Loss: 0.00349431
Epoch [81/300], Train Loss: 0.003168
Validation Loss: 0.00348350
Epoch [82/300], Train Loss: 0.003159
Validation Loss: 0.00348260
Epoch [83/300], Train Loss: 0.003164
Validation Loss: 0.00348124
Epoch [84/300], Train Loss: 0.003180
Validation Loss: 0.00348099
Epoch [85/300], Train Loss: 0.003152
Validation Loss: 0.00349730
Epoch [86/300], Train Loss: 0.003269
Validation Loss: 0.00347607
Epoch [87/300], Train Loss: 0.003176
Validation Loss: 0.00348224
Epoch [88/300], Train Loss: 0.003175
Validation Loss: 0.00347401
Epoch [89/300], Train Loss: 0.003121
Validation Loss: 0.00348883
Epoch [90/300], Train Loss: 0.003116
Validation Loss: 0.00347769
Epoch [91/300], Train Loss: 0.003164
Validation Loss: 0.00346852
Epoch [92/300], Train Loss: 0.003114
Validation Loss: 0.00347641
Epoch [93/300], Train Loss: 0.003101
Validation Loss: 0.00347412
Epoch [94/300], Train Loss: 0.003215
Validation Loss: 0.00346421
Epoch [95/300], Train Loss: 0.003279
Validation Loss: 0.00348084
Epoch [96/300], Train Loss: 0.003117
Validation Loss: 0.00346310
Epoch [97/300], Train Loss: 0.003111
Validation Loss: 0.00345961
Epoch [98/300], Train Loss: 0.003215
Validation Loss: 0.00346681
Epoch [99/300], Train Loss: 0.003219
Validation Loss: 0.00346750
Epoch [100/300], Train Loss: 0.003160
Validation Loss: 0.00348502
Epoch [101/300], Train Loss: 0.003126
Validation Loss: 0.00345805
Epoch [102/300], Train Loss: 0.003117
Validation Loss: 0.00345546
Epoch [103/300], Train Loss: 0.003120
Validation Loss: 0.00345151
Epoch [104/300], Train Loss: 0.003206
Validation Loss: 0.00345866
Epoch [105/300], Train Loss: 0.003147
Validation Loss: 0.00345598
Epoch [106/300], Train Loss: 0.003113
Validation Loss: 0.00345573
Epoch [107/300], Train Loss: 0.003118
Validation Loss: 0.00344520
Epoch [108/300], Train Loss: 0.003091
Validation Loss: 0.00347052
Epoch [109/300], Train Loss: 0.003085
Validation Loss: 0.00344254
Epoch [110/300], Train Loss: 0.003105
Validation Loss: 0.00344542
Epoch [111/300], Train Loss: 0.003161
Validation Loss: 0.00344057
Epoch [112/300], Train Loss: 0.003104
Validation Loss: 0.00343879
Epoch [113/300], Train Loss: 0.003179
Validation Loss: 0.00346087
Epoch [114/300], Train Loss: 0.003176
Validation Loss: 0.00345093
Epoch [115/300], Train Loss: 0.003119
Validation Loss: 0.00345856
Epoch [116/300], Train Loss: 0.003151
Validation Loss: 0.00343159
Epoch [117/300], Train Loss: 0.003156
Validation Loss: 0.00347881
Epoch [118/300], Train Loss: 0.003211
Validation Loss: 0.00344096
Epoch [119/300], Train Loss: 0.003149
Validation Loss: 0.00345066
Epoch [120/300], Train Loss: 0.003123
Validation Loss: 0.00343857
Epoch [121/300], Train Loss: 0.003180
Validation Loss: 0.00343105
Epoch [122/300], Train Loss: 0.003117
Validation Loss: 0.00346327
Epoch [123/300], Train Loss: 0.003211
Validation Loss: 0.00342575
Epoch [124/300], Train Loss: 0.003064
Validation Loss: 0.00343614
Epoch [125/300], Train Loss: 0.003086
Validation Loss: 0.00342589
Epoch [126/300], Train Loss: 0.003116
Validation Loss: 0.00341633
Epoch [127/300], Train Loss: 0.003108
Validation Loss: 0.00343570
Epoch [128/300], Train Loss: 0.003132
Validation Loss: 0.00347083
Epoch [129/300], Train Loss: 0.003221
Validation Loss: 0.00341646
Epoch [130/300], Train Loss: 0.003257
Validation Loss: 0.00342621
Epoch [131/300], Train Loss: 0.003211
Validation Loss: 0.00343367
Epoch [132/300], Train Loss: 0.003080
Validation Loss: 0.00341389
Epoch [133/300], Train Loss: 0.003109
Validation Loss: 0.00341446
Epoch [134/300], Train Loss: 0.003086
Validation Loss: 0.00344211
Epoch [135/300], Train Loss: 0.003166
Validation Loss: 0.00347083
Epoch [136/300], Train Loss: 0.003161
Validation Loss: 0.00344508
Epoch [137/300], Train Loss: 0.003121
Validation Loss: 0.00340698
Epoch [138/300], Train Loss: 0.003054
Validation Loss: 0.00339505
Epoch [139/300], Train Loss: 0.003107
Validation Loss: 0.00339564
Epoch [140/300], Train Loss: 0.003148
Validation Loss: 0.00341162
Epoch [141/300], Train Loss: 0.003054
Validation Loss: 0.00341929
Epoch [142/300], Train Loss: 0.003119
Validation Loss: 0.00343209
Epoch [143/300], Train Loss: 0.003076
Validation Loss: 0.00341008
Epoch [144/300], Train Loss: 0.003100
Validation Loss: 0.00341664
Epoch [145/300], Train Loss: 0.003049
Validation Loss: 0.00338535
Epoch [146/300], Train Loss: 0.003074
Validation Loss: 0.00338673
Epoch [147/300], Train Loss: 0.003105
Validation Loss: 0.00340314
Epoch [148/300], Train Loss: 0.003058
Validation Loss: 0.00338399
Epoch [149/300], Train Loss: 0.003157
Validation Loss: 0.00341092
Epoch [150/300], Train Loss: 0.003053
Validation Loss: 0.00338258
Epoch [151/300], Train Loss: 0.003093
Validation Loss: 0.00337628
Epoch [152/300], Train Loss: 0.003031
Validation Loss: 0.00337826
Epoch [153/300], Train Loss: 0.003102
Validation Loss: 0.00340056
Epoch [154/300], Train Loss: 0.003111
Validation Loss: 0.00335461
Epoch [155/300], Train Loss: 0.003041
Validation Loss: 0.00338140
Epoch [156/300], Train Loss: 0.003113
Validation Loss: 0.00336386
Epoch [157/300], Train Loss: 0.003056
Validation Loss: 0.00336676
Epoch [158/300], Train Loss: 0.003091
Validation Loss: 0.00334715
Epoch [159/300], Train Loss: 0.003113
Validation Loss: 0.00335429
Epoch [160/300], Train Loss: 0.003094
Validation Loss: 0.00334572
Epoch [161/300], Train Loss: 0.003089
Validation Loss: 0.00336054
Epoch [162/300], Train Loss: 0.003047
Validation Loss: 0.00333629
Epoch [163/300], Train Loss: 0.003052
Validation Loss: 0.00333056
Epoch [164/300], Train Loss: 0.003092
Validation Loss: 0.00332726
Epoch [165/300], Train Loss: 0.003128
Validation Loss: 0.00334251
Epoch [166/300], Train Loss: 0.003041
Validation Loss: 0.00332756
Epoch [167/300], Train Loss: 0.003070
Validation Loss: 0.00334391
Epoch [168/300], Train Loss: 0.003075
Validation Loss: 0.00331564
Epoch [169/300], Train Loss: 0.003041
Validation Loss: 0.00335594
Epoch [170/300], Train Loss: 0.003024
Validation Loss: 0.00330468
Epoch [171/300], Train Loss: 0.003066
Validation Loss: 0.00334931
Epoch [172/300], Train Loss: 0.003084
Validation Loss: 0.00334951
Epoch [173/300], Train Loss: 0.002993
Validation Loss: 0.00330664
Epoch [174/300], Train Loss: 0.003064
Validation Loss: 0.00333751
Epoch [175/300], Train Loss: 0.003017
Validation Loss: 0.00332405
Epoch [176/300], Train Loss: 0.003049
Validation Loss: 0.00330484
Epoch [177/300], Train Loss: 0.003104
Validation Loss: 0.00334218
Epoch [178/300], Train Loss: 0.003038
Validation Loss: 0.00330906
Epoch [179/300], Train Loss: 0.003057
Validation Loss: 0.00330176
Epoch [180/300], Train Loss: 0.002993
Validation Loss: 0.00333064
Epoch [181/300], Train Loss: 0.003056
Validation Loss: 0.00333393
Epoch [182/300], Train Loss: 0.002991
Validation Loss: 0.00329166
Epoch [183/300], Train Loss: 0.002986
Validation Loss: 0.00330009
Epoch [184/300], Train Loss: 0.003030
Validation Loss: 0.00330578
Epoch [185/300], Train Loss: 0.003041
Validation Loss: 0.00330591
Epoch [186/300], Train Loss: 0.002997
Validation Loss: 0.00330972
Epoch [187/300], Train Loss: 0.003053
Validation Loss: 0.00328370
Epoch [188/300], Train Loss: 0.002966
Validation Loss: 0.00329570
Epoch [189/300], Train Loss: 0.003060
Validation Loss: 0.00330003
Epoch [190/300], Train Loss: 0.002986
Validation Loss: 0.00329185
Epoch [191/300], Train Loss: 0.003108
Validation Loss: 0.00329707
Epoch [192/300], Train Loss: 0.003005
Validation Loss: 0.00329033
Epoch [193/300], Train Loss: 0.003074
Validation Loss: 0.00328189
Epoch [194/300], Train Loss: 0.002980
Validation Loss: 0.00328575
Epoch [195/300], Train Loss: 0.003037
Validation Loss: 0.00327967
Epoch [196/300], Train Loss: 0.003014
Validation Loss: 0.00328231
Epoch [197/300], Train Loss: 0.002992
Validation Loss: 0.00327829
Epoch [198/300], Train Loss: 0.002953
Validation Loss: 0.00328590
Epoch [199/300], Train Loss: 0.002980
Validation Loss: 0.00328971
Epoch [200/300], Train Loss: 0.003028
Validation Loss: 0.00327155
Epoch [201/300], Train Loss: 0.003008
Validation Loss: 0.00328424
Epoch [202/300], Train Loss: 0.002985
Validation Loss: 0.00326934
Epoch [203/300], Train Loss: 0.002964
Validation Loss: 0.00326076
Epoch [204/300], Train Loss: 0.003014
Validation Loss: 0.00326131
Epoch [205/300], Train Loss: 0.002970
Validation Loss: 0.00325072
Epoch [206/300], Train Loss: 0.003019
Validation Loss: 0.00325685
Epoch [207/300], Train Loss: 0.003092
Validation Loss: 0.00325916
Epoch [208/300], Train Loss: 0.002958
Validation Loss: 0.00325758
Epoch [209/300], Train Loss: 0.003052
Validation Loss: 0.00325916
Epoch [210/300], Train Loss: 0.002956
Validation Loss: 0.00325062
Epoch [211/300], Train Loss: 0.002980
Validation Loss: 0.00325939
Epoch [212/300], Train Loss: 0.003033
Validation Loss: 0.00323163
Epoch [213/300], Train Loss: 0.003024
Validation Loss: 0.00324930
Epoch [214/300], Train Loss: 0.003057
Validation Loss: 0.00325431
Epoch [215/300], Train Loss: 0.003000
Validation Loss: 0.00323596
Epoch [216/300], Train Loss: 0.002947
Validation Loss: 0.00323849
Epoch [217/300], Train Loss: 0.002974
Validation Loss: 0.00324798
Epoch [218/300], Train Loss: 0.002989
Validation Loss: 0.00322402
Epoch [219/300], Train Loss: 0.002986
Validation Loss: 0.00322332
Epoch [220/300], Train Loss: 0.002946
Validation Loss: 0.00321858
Epoch [221/300], Train Loss: 0.002967
Validation Loss: 0.00322754
Epoch [222/300], Train Loss: 0.002964
Validation Loss: 0.00320663
Epoch [223/300], Train Loss: 0.003020
Validation Loss: 0.00322986
Epoch [224/300], Train Loss: 0.002990
Validation Loss: 0.00317995
Epoch [225/300], Train Loss: 0.002965
Validation Loss: 0.00322382
Epoch [226/300], Train Loss: 0.003008
Validation Loss: 0.00319950
Epoch [227/300], Train Loss: 0.003055
Validation Loss: 0.00320875
Epoch [228/300], Train Loss: 0.002946
Validation Loss: 0.00320956
Epoch [229/300], Train Loss: 0.002969
Validation Loss: 0.00319491
Epoch [230/300], Train Loss: 0.002942
Validation Loss: 0.00320013
Epoch [231/300], Train Loss: 0.002965
Validation Loss: 0.00317645
Epoch [232/300], Train Loss: 0.003052
Validation Loss: 0.00319651
Epoch [233/300], Train Loss: 0.002968
Validation Loss: 0.00318568
Epoch [234/300], Train Loss: 0.002914
Validation Loss: 0.00318388
Epoch [235/300], Train Loss: 0.002997
Validation Loss: 0.00318991
Epoch [236/300], Train Loss: 0.002930
Validation Loss: 0.00316940
Epoch [237/300], Train Loss: 0.002944
Validation Loss: 0.00317207
Epoch [238/300], Train Loss: 0.002970
Validation Loss: 0.00319032
Epoch [239/300], Train Loss: 0.002974
Validation Loss: 0.00314817
Epoch [240/300], Train Loss: 0.002978
Validation Loss: 0.00317012
Epoch [241/300], Train Loss: 0.003042
Validation Loss: 0.00314932
Epoch [242/300], Train Loss: 0.002917
Validation Loss: 0.00313951
Epoch [243/300], Train Loss: 0.002966
Validation Loss: 0.00318643
Epoch [244/300], Train Loss: 0.002935
Validation Loss: 0.00314534
Epoch [245/300], Train Loss: 0.002928
Validation Loss: 0.00313104
Epoch [246/300], Train Loss: 0.002996
Validation Loss: 0.00316544
Epoch [247/300], Train Loss: 0.002979
Validation Loss: 0.00314004
Epoch [248/300], Train Loss: 0.002942
Validation Loss: 0.00316860
Epoch [249/300], Train Loss: 0.002934
Validation Loss: 0.00311949
Epoch [250/300], Train Loss: 0.002927
Validation Loss: 0.00314379
Epoch [251/300], Train Loss: 0.002982
Validation Loss: 0.00313917
Epoch [252/300], Train Loss: 0.002943
Validation Loss: 0.00314412
Epoch [253/300], Train Loss: 0.002909
Validation Loss: 0.00310953
Epoch [254/300], Train Loss: 0.002970
Validation Loss: 0.00319754
Epoch [255/300], Train Loss: 0.002930
Validation Loss: 0.00311498
Epoch [256/300], Train Loss: 0.002961
Validation Loss: 0.00312043
Epoch [257/300], Train Loss: 0.002886
Validation Loss: 0.00310859
Epoch [258/300], Train Loss: 0.002917
Validation Loss: 0.00312842
Epoch [259/300], Train Loss: 0.002906
Validation Loss: 0.00308154
Epoch [260/300], Train Loss: 0.002973
Validation Loss: 0.00314062
Epoch [261/300], Train Loss: 0.002898
Validation Loss: 0.00309335
Epoch [262/300], Train Loss: 0.002902
Validation Loss: 0.00308574
Epoch [263/300], Train Loss: 0.002903
Validation Loss: 0.00310425
Epoch [264/300], Train Loss: 0.002858
Validation Loss: 0.00309641
Epoch [265/300], Train Loss: 0.002939
Validation Loss: 0.00307943
Epoch [266/300], Train Loss: 0.002882
Validation Loss: 0.00308303
Epoch [267/300], Train Loss: 0.002895
Validation Loss: 0.00310918
Epoch [268/300], Train Loss: 0.002873
Validation Loss: 0.00308560
Epoch [269/300], Train Loss: 0.002888
Validation Loss: 0.00308290
Epoch [270/300], Train Loss: 0.002960
Validation Loss: 0.00310252
Epoch [271/300], Train Loss: 0.002891
Validation Loss: 0.00306115
Epoch [272/300], Train Loss: 0.002920
Validation Loss: 0.00306476
Epoch [273/300], Train Loss: 0.002820
Validation Loss: 0.00307340
Epoch [274/300], Train Loss: 0.002900
Validation Loss: 0.00305441
Epoch [275/300], Train Loss: 0.002872
Validation Loss: 0.00307236
Epoch [276/300], Train Loss: 0.002885
Validation Loss: 0.00306812
Epoch [277/300], Train Loss: 0.002868
Validation Loss: 0.00304252
Epoch [278/300], Train Loss: 0.002849
Validation Loss: 0.00313663
Epoch [279/300], Train Loss: 0.002848
Validation Loss: 0.00304290
Epoch [280/300], Train Loss: 0.002890
Validation Loss: 0.00304034
Epoch [281/300], Train Loss: 0.002885
Validation Loss: 0.00304693
Epoch [282/300], Train Loss: 0.002853
Validation Loss: 0.00304141
Epoch [283/300], Train Loss: 0.002871
Validation Loss: 0.00305220
Epoch [284/300], Train Loss: 0.002869
Validation Loss: 0.00303288
Epoch [285/300], Train Loss: 0.002852
Validation Loss: 0.00302509
Epoch [286/300], Train Loss: 0.002912
Validation Loss: 0.00303642
Epoch [287/300], Train Loss: 0.002886
Validation Loss: 0.00304018
Epoch [288/300], Train Loss: 0.002879
Validation Loss: 0.00301109
Epoch [289/300], Train Loss: 0.002872
Validation Loss: 0.00301319
Epoch [290/300], Train Loss: 0.002828
Validation Loss: 0.00301330
Epoch [291/300], Train Loss: 0.002800
Validation Loss: 0.00300916
Epoch [292/300], Train Loss: 0.002827
Validation Loss: 0.00302811
Epoch [293/300], Train Loss: 0.002887
Validation Loss: 0.00301869
Epoch [294/300], Train Loss: 0.002824
Validation Loss: 0.00300330
Epoch [295/300], Train Loss: 0.002793
Validation Loss: 0.00301286
Epoch [296/300], Train Loss: 0.002800
Validation Loss: 0.00299660
Epoch [297/300], Train Loss: 0.002789
Validation Loss: 0.00298530
Epoch [298/300], Train Loss: 0.002831
Validation Loss: 0.00301332
Epoch [299/300], Train Loss: 0.002800
Validation Loss: 0.00297404
Epoch [300/300], Train Loss: 0.002831
Validation Loss: 0.00296838

Evaluating model for: Laptop
Run 11/72 completed in 636.61 seconds with: {'MAE': np.float32(2.8606117), 'MSE': np.float32(21.816525), 'RMSE': np.float32(4.6708164), 'SAE': np.float32(0.07901376), 'NDE': np.float32(0.6300542)}

Run 12/72: hidden=128, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Laptop
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.012119
Validation Loss: 0.00934370
Epoch [2/300], Train Loss: 0.007187
Validation Loss: 0.00518854
Epoch [3/300], Train Loss: 0.003941
Validation Loss: 0.00376057
Epoch [4/300], Train Loss: 0.003500
Validation Loss: 0.00370483
Epoch [5/300], Train Loss: 0.003405
Validation Loss: 0.00368824
Epoch [6/300], Train Loss: 0.003481
Validation Loss: 0.00368533
Epoch [7/300], Train Loss: 0.003436
Validation Loss: 0.00368787
Epoch [8/300], Train Loss: 0.003534
Validation Loss: 0.00368193
Epoch [9/300], Train Loss: 0.003408
Validation Loss: 0.00368603
Epoch [10/300], Train Loss: 0.003416
Validation Loss: 0.00367945
Epoch [11/300], Train Loss: 0.003461
Validation Loss: 0.00367895
Epoch [12/300], Train Loss: 0.003401
Validation Loss: 0.00367894
Epoch [13/300], Train Loss: 0.003425
Validation Loss: 0.00367508
Epoch [14/300], Train Loss: 0.003419
Validation Loss: 0.00368625
Epoch [15/300], Train Loss: 0.003424
Validation Loss: 0.00367165
Epoch [16/300], Train Loss: 0.003358
Validation Loss: 0.00367739
Epoch [17/300], Train Loss: 0.003433
Validation Loss: 0.00366882
Epoch [18/300], Train Loss: 0.003385
Validation Loss: 0.00367353
Epoch [19/300], Train Loss: 0.003369
Validation Loss: 0.00366409
Epoch [20/300], Train Loss: 0.003375
Validation Loss: 0.00365785
Epoch [21/300], Train Loss: 0.003354
Validation Loss: 0.00365340
Epoch [22/300], Train Loss: 0.003328
Validation Loss: 0.00364541
Epoch [23/300], Train Loss: 0.003393
Validation Loss: 0.00363134
Epoch [24/300], Train Loss: 0.003339
Validation Loss: 0.00361568
Epoch [25/300], Train Loss: 0.003335
Validation Loss: 0.00360758
Epoch [26/300], Train Loss: 0.003309
Validation Loss: 0.00359710
Epoch [27/300], Train Loss: 0.003338
Validation Loss: 0.00359464
Epoch [28/300], Train Loss: 0.003283
Validation Loss: 0.00359420
Epoch [29/300], Train Loss: 0.003310
Validation Loss: 0.00359510
Epoch [30/300], Train Loss: 0.003406
Validation Loss: 0.00358980
Epoch [31/300], Train Loss: 0.003322
Validation Loss: 0.00358804
Epoch [32/300], Train Loss: 0.003297
Validation Loss: 0.00358553
Epoch [33/300], Train Loss: 0.003402
Validation Loss: 0.00358587
Epoch [34/300], Train Loss: 0.003312
Validation Loss: 0.00358403
Epoch [35/300], Train Loss: 0.003355
Validation Loss: 0.00358464
Epoch [36/300], Train Loss: 0.003259
Validation Loss: 0.00358370
Epoch [37/300], Train Loss: 0.003317
Validation Loss: 0.00358893
Epoch [38/300], Train Loss: 0.003306
Validation Loss: 0.00358544
Epoch [39/300], Train Loss: 0.003234
Validation Loss: 0.00358010
Epoch [40/300], Train Loss: 0.003248
Validation Loss: 0.00357851
Epoch [41/300], Train Loss: 0.003256
Validation Loss: 0.00359151
Epoch [42/300], Train Loss: 0.003292
Validation Loss: 0.00358307
Epoch [43/300], Train Loss: 0.003274
Validation Loss: 0.00357809
Epoch [44/300], Train Loss: 0.003420
Validation Loss: 0.00357437
Epoch [45/300], Train Loss: 0.003294
Validation Loss: 0.00357858
Epoch [46/300], Train Loss: 0.003295
Validation Loss: 0.00357424
Epoch [47/300], Train Loss: 0.003295
Validation Loss: 0.00357390
Epoch [48/300], Train Loss: 0.003324
Validation Loss: 0.00357396
Epoch [49/300], Train Loss: 0.003231
Validation Loss: 0.00357091
Epoch [50/300], Train Loss: 0.003244
Validation Loss: 0.00357030
Epoch [51/300], Train Loss: 0.003277
Validation Loss: 0.00357803
Epoch [52/300], Train Loss: 0.003295
Validation Loss: 0.00357499
Epoch [53/300], Train Loss: 0.003228
Validation Loss: 0.00356782
Epoch [54/300], Train Loss: 0.003231
Validation Loss: 0.00357010
Epoch [55/300], Train Loss: 0.003233
Validation Loss: 0.00356850
Epoch [56/300], Train Loss: 0.003266
Validation Loss: 0.00356711
Epoch [57/300], Train Loss: 0.003256
Validation Loss: 0.00357651
Epoch [58/300], Train Loss: 0.003233
Validation Loss: 0.00357060
Epoch [59/300], Train Loss: 0.003204
Validation Loss: 0.00356305
Epoch [60/300], Train Loss: 0.003337
Validation Loss: 0.00356285
Epoch [61/300], Train Loss: 0.003308
Validation Loss: 0.00356493
Epoch [62/300], Train Loss: 0.003228
Validation Loss: 0.00356175
Epoch [63/300], Train Loss: 0.003290
Validation Loss: 0.00356650
Epoch [64/300], Train Loss: 0.003253
Validation Loss: 0.00356205
Epoch [65/300], Train Loss: 0.003192
Validation Loss: 0.00356134
Epoch [66/300], Train Loss: 0.003265
Validation Loss: 0.00355917
Epoch [67/300], Train Loss: 0.003289
Validation Loss: 0.00356315
Epoch [68/300], Train Loss: 0.003282
Validation Loss: 0.00356661
Epoch [69/300], Train Loss: 0.003209
Validation Loss: 0.00355577
Epoch [70/300], Train Loss: 0.003176
Validation Loss: 0.00356135
Epoch [71/300], Train Loss: 0.003224
Validation Loss: 0.00355253
Epoch [72/300], Train Loss: 0.003235
Validation Loss: 0.00355831
Epoch [73/300], Train Loss: 0.003255
Validation Loss: 0.00354627
Epoch [74/300], Train Loss: 0.003195
Validation Loss: 0.00353949
Epoch [75/300], Train Loss: 0.003281
Validation Loss: 0.00355832
Epoch [76/300], Train Loss: 0.003280
Validation Loss: 0.00354568
Epoch [77/300], Train Loss: 0.003219
Validation Loss: 0.00355469
Epoch [78/300], Train Loss: 0.003239
Validation Loss: 0.00353803
Epoch [79/300], Train Loss: 0.003254
Validation Loss: 0.00354713
Epoch [80/300], Train Loss: 0.003208
Validation Loss: 0.00353772
Epoch [81/300], Train Loss: 0.003215
Validation Loss: 0.00352787
Epoch [82/300], Train Loss: 0.003206
Validation Loss: 0.00354722
Epoch [83/300], Train Loss: 0.003212
Validation Loss: 0.00354375
Epoch [84/300], Train Loss: 0.003227
Validation Loss: 0.00354534
Epoch [85/300], Train Loss: 0.003206
Validation Loss: 0.00354401
Epoch [86/300], Train Loss: 0.003321
Validation Loss: 0.00351472
Epoch [87/300], Train Loss: 0.003224
Validation Loss: 0.00355221
Epoch [88/300], Train Loss: 0.003214
Validation Loss: 0.00351334
Epoch [89/300], Train Loss: 0.003167
Validation Loss: 0.00356555
Epoch [90/300], Train Loss: 0.003204
Validation Loss: 0.00357104
Epoch [91/300], Train Loss: 0.003261
Validation Loss: 0.00355553
Epoch [92/300], Train Loss: 0.003175
Validation Loss: 0.00354368
Epoch [93/300], Train Loss: 0.003148
Validation Loss: 0.00353644
Epoch [94/300], Train Loss: 0.003281
Validation Loss: 0.00352982
Epoch [95/300], Train Loss: 0.003332
Validation Loss: 0.00354421
Epoch [96/300], Train Loss: 0.003160
Validation Loss: 0.00353542
Epoch [97/300], Train Loss: 0.003149
Validation Loss: 0.00351403
Epoch [98/300], Train Loss: 0.003250
Validation Loss: 0.00350544
Epoch [99/300], Train Loss: 0.003249
Validation Loss: 0.00354259
Epoch [100/300], Train Loss: 0.003189
Validation Loss: 0.00353229
Epoch [101/300], Train Loss: 0.003171
Validation Loss: 0.00351659
Epoch [102/300], Train Loss: 0.003161
Validation Loss: 0.00353452
Epoch [103/300], Train Loss: 0.003177
Validation Loss: 0.00353474
Epoch [104/300], Train Loss: 0.003236
Validation Loss: 0.00353625
Epoch [105/300], Train Loss: 0.003213
Validation Loss: 0.00355074
Epoch [106/300], Train Loss: 0.003164
Validation Loss: 0.00354150
Epoch [107/300], Train Loss: 0.003175
Validation Loss: 0.00351191
Epoch [108/300], Train Loss: 0.003158
Validation Loss: 0.00355466
Early stopping triggered

Evaluating model for: Laptop
Run 12/72 completed in 240.18 seconds with: {'MAE': np.float32(2.5916924), 'MSE': np.float32(24.0326), 'RMSE': np.float32(4.9023056), 'SAE': np.float32(0.07575141), 'NDE': np.float32(0.66128016)}

Run 13/72: hidden=128, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Laptop
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.003550
Validation Loss: 0.00488749
Epoch [2/300], Train Loss: 0.003170
Validation Loss: 0.00446894
Epoch [3/300], Train Loss: 0.003203
Validation Loss: 0.00436243
Epoch [4/300], Train Loss: 0.003207
Validation Loss: 0.00438648
Epoch [5/300], Train Loss: 0.003158
Validation Loss: 0.00444782
Epoch [6/300], Train Loss: 0.003195
Validation Loss: 0.00448742
Epoch [7/300], Train Loss: 0.003085
Validation Loss: 0.00445853
Epoch [8/300], Train Loss: 0.003108
Validation Loss: 0.00444029
Epoch [9/300], Train Loss: 0.003106
Validation Loss: 0.00444296
Epoch [10/300], Train Loss: 0.003095
Validation Loss: 0.00444514
Epoch [11/300], Train Loss: 0.003093
Validation Loss: 0.00444371
Epoch [12/300], Train Loss: 0.003150
Validation Loss: 0.00445611
Epoch [13/300], Train Loss: 0.003118
Validation Loss: 0.00447672
Early stopping triggered

Evaluating model for: Laptop
Run 13/72 completed in 13.06 seconds with: {'MAE': np.float32(2.4734902), 'MSE': np.float32(30.453308), 'RMSE': np.float32(5.5184517), 'SAE': np.float32(0.09677064), 'NDE': np.float32(0.67691743)}

Run 14/72: hidden=128, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Laptop
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.003839
Validation Loss: 0.00519602
Epoch [2/300], Train Loss: 0.003260
Validation Loss: 0.00458853
Epoch [3/300], Train Loss: 0.003194
Validation Loss: 0.00436972
Epoch [4/300], Train Loss: 0.003206
Validation Loss: 0.00435918
Epoch [5/300], Train Loss: 0.003163
Validation Loss: 0.00441229
Epoch [6/300], Train Loss: 0.003192
Validation Loss: 0.00447344
Epoch [7/300], Train Loss: 0.003082
Validation Loss: 0.00446843
Epoch [8/300], Train Loss: 0.003103
Validation Loss: 0.00445181
Epoch [9/300], Train Loss: 0.003101
Validation Loss: 0.00444351
Epoch [10/300], Train Loss: 0.003090
Validation Loss: 0.00443685
Epoch [11/300], Train Loss: 0.003087
Validation Loss: 0.00443382
Epoch [12/300], Train Loss: 0.003145
Validation Loss: 0.00444893
Epoch [13/300], Train Loss: 0.003113
Validation Loss: 0.00447158
Epoch [14/300], Train Loss: 0.003091
Validation Loss: 0.00443820
Early stopping triggered

Evaluating model for: Laptop
Run 14/72 completed in 15.24 seconds with: {'MAE': np.float32(2.4955454), 'MSE': np.float32(30.293612), 'RMSE': np.float32(5.5039635), 'SAE': np.float32(0.07838566), 'NDE': np.float32(0.6751402)}

Run 15/72: hidden=128, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Laptop
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.011903
Validation Loss: 0.01370204
Epoch [2/300], Train Loss: 0.009339
Validation Loss: 0.01104192
Epoch [3/300], Train Loss: 0.007293
Validation Loss: 0.00875419
Epoch [4/300], Train Loss: 0.005486
Validation Loss: 0.00672424
Epoch [5/300], Train Loss: 0.003998
Validation Loss: 0.00508337
Epoch [6/300], Train Loss: 0.003331
Validation Loss: 0.00441232
Epoch [7/300], Train Loss: 0.003347
Validation Loss: 0.00439332
Epoch [8/300], Train Loss: 0.003287
Validation Loss: 0.00447981
Epoch [9/300], Train Loss: 0.003217
Validation Loss: 0.00464805
Epoch [10/300], Train Loss: 0.003226
Validation Loss: 0.00465743
Epoch [11/300], Train Loss: 0.003214
Validation Loss: 0.00457001
Epoch [12/300], Train Loss: 0.003265
Validation Loss: 0.00451587
Epoch [13/300], Train Loss: 0.003231
Validation Loss: 0.00452495
Epoch [14/300], Train Loss: 0.003216
Validation Loss: 0.00453091
Epoch [15/300], Train Loss: 0.003194
Validation Loss: 0.00451331
Epoch [16/300], Train Loss: 0.003199
Validation Loss: 0.00453588
Epoch [17/300], Train Loss: 0.003192
Validation Loss: 0.00453053
Early stopping triggered

Evaluating model for: Laptop
Run 15/72 completed in 18.74 seconds with: {'MAE': np.float32(2.5103006), 'MSE': np.float32(31.136942), 'RMSE': np.float32(5.5800486), 'SAE': np.float32(0.085731715), 'NDE': np.float32(0.684473)}

Run 16/72: hidden=128, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Laptop
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.005674
Validation Loss: 0.00737794
Epoch [2/300], Train Loss: 0.004583
Validation Loss: 0.00617740
Epoch [3/300], Train Loss: 0.003860
Validation Loss: 0.00521543
Epoch [4/300], Train Loss: 0.003328
Validation Loss: 0.00458646
Epoch [5/300], Train Loss: 0.003139
Validation Loss: 0.00436175
Epoch [6/300], Train Loss: 0.003238
Validation Loss: 0.00435135
Epoch [7/300], Train Loss: 0.003115
Validation Loss: 0.00439934
Epoch [8/300], Train Loss: 0.003113
Validation Loss: 0.00447457
Epoch [9/300], Train Loss: 0.003115
Validation Loss: 0.00451372
Epoch [10/300], Train Loss: 0.003109
Validation Loss: 0.00449742
Epoch [11/300], Train Loss: 0.003106
Validation Loss: 0.00446410
Epoch [12/300], Train Loss: 0.003166
Validation Loss: 0.00445416
Epoch [13/300], Train Loss: 0.003135
Validation Loss: 0.00447136
Epoch [14/300], Train Loss: 0.003119
Validation Loss: 0.00446737
Epoch [15/300], Train Loss: 0.003099
Validation Loss: 0.00444114
Epoch [16/300], Train Loss: 0.003100
Validation Loss: 0.00445520
Early stopping triggered

Evaluating model for: Laptop
Run 16/72 completed in 19.10 seconds with: {'MAE': np.float32(2.468299), 'MSE': np.float32(30.502077), 'RMSE': np.float32(5.5228686), 'SAE': np.float32(0.069548585), 'NDE': np.float32(0.6774588)}

Run 17/72: hidden=128, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Laptop
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.010537
Validation Loss: 0.01089054
Epoch [2/300], Train Loss: 0.008368
Validation Loss: 0.00898296
Epoch [3/300], Train Loss: 0.006830
Validation Loss: 0.00744467
Epoch [4/300], Train Loss: 0.005482
Validation Loss: 0.00614250
Epoch [5/300], Train Loss: 0.004450
Validation Loss: 0.00516154
Epoch [6/300], Train Loss: 0.003696
Validation Loss: 0.00452038
Epoch [7/300], Train Loss: 0.003270
Validation Loss: 0.00423840
Epoch [8/300], Train Loss: 0.003244
Validation Loss: 0.00419477
Epoch [9/300], Train Loss: 0.003265
Validation Loss: 0.00419684
Epoch [10/300], Train Loss: 0.003295
Validation Loss: 0.00418876
Epoch [11/300], Train Loss: 0.003218
Validation Loss: 0.00419871
Epoch [12/300], Train Loss: 0.003188
Validation Loss: 0.00420921
Epoch [13/300], Train Loss: 0.003108
Validation Loss: 0.00420232
Epoch [14/300], Train Loss: 0.003155
Validation Loss: 0.00420231
Epoch [15/300], Train Loss: 0.003117
Validation Loss: 0.00420040
Epoch [16/300], Train Loss: 0.003207
Validation Loss: 0.00419756
Epoch [17/300], Train Loss: 0.003102
Validation Loss: 0.00419192
Epoch [18/300], Train Loss: 0.003169
Validation Loss: 0.00418803
Epoch [19/300], Train Loss: 0.003191
Validation Loss: 0.00418906
Epoch [20/300], Train Loss: 0.003101
Validation Loss: 0.00418453
Epoch [21/300], Train Loss: 0.003243
Validation Loss: 0.00418448
Epoch [22/300], Train Loss: 0.003157
Validation Loss: 0.00417910
Epoch [23/300], Train Loss: 0.003254
Validation Loss: 0.00418007
Epoch [24/300], Train Loss: 0.003246
Validation Loss: 0.00417980
Epoch [25/300], Train Loss: 0.003195
Validation Loss: 0.00417248
Epoch [26/300], Train Loss: 0.003104
Validation Loss: 0.00417058
Epoch [27/300], Train Loss: 0.003139
Validation Loss: 0.00417415
Epoch [28/300], Train Loss: 0.003097
Validation Loss: 0.00417440
Epoch [29/300], Train Loss: 0.003197
Validation Loss: 0.00417611
Epoch [30/300], Train Loss: 0.003164
Validation Loss: 0.00416602
Epoch [31/300], Train Loss: 0.003147
Validation Loss: 0.00416642
Epoch [32/300], Train Loss: 0.003178
Validation Loss: 0.00416722
Epoch [33/300], Train Loss: 0.003159
Validation Loss: 0.00416909
Epoch [34/300], Train Loss: 0.003142
Validation Loss: 0.00416314
Epoch [35/300], Train Loss: 0.003115
Validation Loss: 0.00416147
Epoch [36/300], Train Loss: 0.003182
Validation Loss: 0.00416223
Epoch [37/300], Train Loss: 0.003099
Validation Loss: 0.00415568
Epoch [38/300], Train Loss: 0.003098
Validation Loss: 0.00415681
Epoch [39/300], Train Loss: 0.003070
Validation Loss: 0.00415718
Epoch [40/300], Train Loss: 0.003220
Validation Loss: 0.00416358
Epoch [41/300], Train Loss: 0.003146
Validation Loss: 0.00415453
Epoch [42/300], Train Loss: 0.003170
Validation Loss: 0.00414890
Epoch [43/300], Train Loss: 0.003258
Validation Loss: 0.00414848
Epoch [44/300], Train Loss: 0.003210
Validation Loss: 0.00414487
Epoch [45/300], Train Loss: 0.003065
Validation Loss: 0.00414686
Epoch [46/300], Train Loss: 0.003153
Validation Loss: 0.00414521
Epoch [47/300], Train Loss: 0.003034
Validation Loss: 0.00414010
Epoch [48/300], Train Loss: 0.003139
Validation Loss: 0.00414297
Epoch [49/300], Train Loss: 0.003071
Validation Loss: 0.00414246
Epoch [50/300], Train Loss: 0.003101
Validation Loss: 0.00414193
Epoch [51/300], Train Loss: 0.003181
Validation Loss: 0.00414822
Epoch [52/300], Train Loss: 0.003168
Validation Loss: 0.00413615
Epoch [53/300], Train Loss: 0.003179
Validation Loss: 0.00413265
Epoch [54/300], Train Loss: 0.003094
Validation Loss: 0.00412420
Epoch [55/300], Train Loss: 0.003108
Validation Loss: 0.00412289
Epoch [56/300], Train Loss: 0.003125
Validation Loss: 0.00412920
Epoch [57/300], Train Loss: 0.003146
Validation Loss: 0.00413003
Epoch [58/300], Train Loss: 0.003163
Validation Loss: 0.00412532
Epoch [59/300], Train Loss: 0.003113
Validation Loss: 0.00411681
Epoch [60/300], Train Loss: 0.003176
Validation Loss: 0.00411820
Epoch [61/300], Train Loss: 0.003166
Validation Loss: 0.00411538
Epoch [62/300], Train Loss: 0.003087
Validation Loss: 0.00411079
Epoch [63/300], Train Loss: 0.003093
Validation Loss: 0.00410982
Epoch [64/300], Train Loss: 0.003126
Validation Loss: 0.00411300
Epoch [65/300], Train Loss: 0.003152
Validation Loss: 0.00411151
Epoch [66/300], Train Loss: 0.003170
Validation Loss: 0.00410758
Epoch [67/300], Train Loss: 0.003106
Validation Loss: 0.00409693
Epoch [68/300], Train Loss: 0.003016
Validation Loss: 0.00409327
Epoch [69/300], Train Loss: 0.003112
Validation Loss: 0.00409904
Epoch [70/300], Train Loss: 0.003028
Validation Loss: 0.00410132
Epoch [71/300], Train Loss: 0.003102
Validation Loss: 0.00409623
Epoch [72/300], Train Loss: 0.003096
Validation Loss: 0.00408469
Epoch [73/300], Train Loss: 0.003153
Validation Loss: 0.00408270
Epoch [74/300], Train Loss: 0.003096
Validation Loss: 0.00408456
Epoch [75/300], Train Loss: 0.003087
Validation Loss: 0.00408317
Epoch [76/300], Train Loss: 0.003073
Validation Loss: 0.00407707
Epoch [77/300], Train Loss: 0.003049
Validation Loss: 0.00407575
Epoch [78/300], Train Loss: 0.003090
Validation Loss: 0.00407221
Epoch [79/300], Train Loss: 0.003064
Validation Loss: 0.00406902
Epoch [80/300], Train Loss: 0.003077
Validation Loss: 0.00407039
Epoch [81/300], Train Loss: 0.003092
Validation Loss: 0.00406769
Epoch [82/300], Train Loss: 0.003118
Validation Loss: 0.00405954
Epoch [83/300], Train Loss: 0.003008
Validation Loss: 0.00406210
Epoch [84/300], Train Loss: 0.003103
Validation Loss: 0.00405964
Epoch [85/300], Train Loss: 0.003129
Validation Loss: 0.00405663
Epoch [86/300], Train Loss: 0.003030
Validation Loss: 0.00405140
Epoch [87/300], Train Loss: 0.003041
Validation Loss: 0.00405102
Epoch [88/300], Train Loss: 0.003072
Validation Loss: 0.00405304
Epoch [89/300], Train Loss: 0.003199
Validation Loss: 0.00405026
Epoch [90/300], Train Loss: 0.003142
Validation Loss: 0.00404047
Epoch [91/300], Train Loss: 0.003081
Validation Loss: 0.00404139
Epoch [92/300], Train Loss: 0.003075
Validation Loss: 0.00404229
Epoch [93/300], Train Loss: 0.003135
Validation Loss: 0.00404390
Epoch [94/300], Train Loss: 0.003069
Validation Loss: 0.00403497
Epoch [95/300], Train Loss: 0.003041
Validation Loss: 0.00403322
Epoch [96/300], Train Loss: 0.003065
Validation Loss: 0.00404573
Epoch [97/300], Train Loss: 0.003075
Validation Loss: 0.00403942
Epoch [98/300], Train Loss: 0.003033
Validation Loss: 0.00403422
Epoch [99/300], Train Loss: 0.003132
Validation Loss: 0.00403128
Epoch [100/300], Train Loss: 0.003084
Validation Loss: 0.00402887
Epoch [101/300], Train Loss: 0.003066
Validation Loss: 0.00403265
Epoch [102/300], Train Loss: 0.003159
Validation Loss: 0.00403356
Epoch [103/300], Train Loss: 0.003145
Validation Loss: 0.00403093
Epoch [104/300], Train Loss: 0.003050
Validation Loss: 0.00402626
Epoch [105/300], Train Loss: 0.003147
Validation Loss: 0.00403139
Epoch [106/300], Train Loss: 0.003070
Validation Loss: 0.00403002
Epoch [107/300], Train Loss: 0.003049
Validation Loss: 0.00402298
Epoch [108/300], Train Loss: 0.003065
Validation Loss: 0.00402735
Epoch [109/300], Train Loss: 0.003079
Validation Loss: 0.00402800
Epoch [110/300], Train Loss: 0.003175
Validation Loss: 0.00402711
Epoch [111/300], Train Loss: 0.002979
Validation Loss: 0.00402187
Epoch [112/300], Train Loss: 0.003126
Validation Loss: 0.00403370
Epoch [113/300], Train Loss: 0.003158
Validation Loss: 0.00402754
Epoch [114/300], Train Loss: 0.003048
Validation Loss: 0.00402032
Epoch [115/300], Train Loss: 0.003124
Validation Loss: 0.00402157
Epoch [116/300], Train Loss: 0.003092
Validation Loss: 0.00402256
Epoch [117/300], Train Loss: 0.003044
Validation Loss: 0.00402449
Epoch [118/300], Train Loss: 0.003022
Validation Loss: 0.00402002
Epoch [119/300], Train Loss: 0.003121
Validation Loss: 0.00402316
Epoch [120/300], Train Loss: 0.003061
Validation Loss: 0.00402534
Epoch [121/300], Train Loss: 0.003116
Validation Loss: 0.00402232
Epoch [122/300], Train Loss: 0.003056
Validation Loss: 0.00401726
Epoch [123/300], Train Loss: 0.003113
Validation Loss: 0.00402334
Epoch [124/300], Train Loss: 0.003036
Validation Loss: 0.00401804
Epoch [125/300], Train Loss: 0.003100
Validation Loss: 0.00402149
Epoch [126/300], Train Loss: 0.003124
Validation Loss: 0.00402026
Epoch [127/300], Train Loss: 0.003023
Validation Loss: 0.00401609
Epoch [128/300], Train Loss: 0.003023
Validation Loss: 0.00401871
Epoch [129/300], Train Loss: 0.003034
Validation Loss: 0.00402362
Epoch [130/300], Train Loss: 0.003059
Validation Loss: 0.00402314
Epoch [131/300], Train Loss: 0.003058
Validation Loss: 0.00401967
Epoch [132/300], Train Loss: 0.003038
Validation Loss: 0.00401559
Epoch [133/300], Train Loss: 0.003019
Validation Loss: 0.00401909
Epoch [134/300], Train Loss: 0.003083
Validation Loss: 0.00402072
Epoch [135/300], Train Loss: 0.003065
Validation Loss: 0.00401712
Epoch [136/300], Train Loss: 0.003098
Validation Loss: 0.00401598
Epoch [137/300], Train Loss: 0.003031
Validation Loss: 0.00401686
Epoch [138/300], Train Loss: 0.003063
Validation Loss: 0.00401754
Epoch [139/300], Train Loss: 0.003137
Validation Loss: 0.00402028
Epoch [140/300], Train Loss: 0.003059
Validation Loss: 0.00401087
Epoch [141/300], Train Loss: 0.003064
Validation Loss: 0.00401881
Epoch [142/300], Train Loss: 0.003142
Validation Loss: 0.00403148
Epoch [143/300], Train Loss: 0.003118
Validation Loss: 0.00401450
Epoch [144/300], Train Loss: 0.003014
Validation Loss: 0.00401314
Epoch [145/300], Train Loss: 0.003106
Validation Loss: 0.00401768
Epoch [146/300], Train Loss: 0.003126
Validation Loss: 0.00401689
Epoch [147/300], Train Loss: 0.003022
Validation Loss: 0.00401157
Epoch [148/300], Train Loss: 0.003029
Validation Loss: 0.00401380
Epoch [149/300], Train Loss: 0.003082
Validation Loss: 0.00402032
Epoch [150/300], Train Loss: 0.003022
Validation Loss: 0.00402101
Early stopping triggered

Evaluating model for: Laptop
Run 17/72 completed in 156.83 seconds with: {'MAE': np.float32(2.7478437), 'MSE': np.float32(28.49443), 'RMSE': np.float32(5.3380175), 'SAE': np.float32(0.0037288708), 'NDE': np.float32(0.6846968)}

Run 18/72: hidden=128, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Laptop
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.004475
Validation Loss: 0.00502290
Epoch [2/300], Train Loss: 0.003452
Validation Loss: 0.00433032
Epoch [3/300], Train Loss: 0.003201
Validation Loss: 0.00415537
Epoch [4/300], Train Loss: 0.003168
Validation Loss: 0.00416343
Epoch [5/300], Train Loss: 0.003232
Validation Loss: 0.00415037
Epoch [6/300], Train Loss: 0.003164
Validation Loss: 0.00416093
Epoch [7/300], Train Loss: 0.003126
Validation Loss: 0.00418108
Epoch [8/300], Train Loss: 0.003210
Validation Loss: 0.00418049
Epoch [9/300], Train Loss: 0.003187
Validation Loss: 0.00415521
Epoch [10/300], Train Loss: 0.003220
Validation Loss: 0.00415290
Epoch [11/300], Train Loss: 0.003170
Validation Loss: 0.00414590
Epoch [12/300], Train Loss: 0.003144
Validation Loss: 0.00414648
Epoch [13/300], Train Loss: 0.003068
Validation Loss: 0.00414278
Epoch [14/300], Train Loss: 0.003107
Validation Loss: 0.00415476
Epoch [15/300], Train Loss: 0.003074
Validation Loss: 0.00415738
Epoch [16/300], Train Loss: 0.003164
Validation Loss: 0.00414963
Epoch [17/300], Train Loss: 0.003057
Validation Loss: 0.00413677
Epoch [18/300], Train Loss: 0.003121
Validation Loss: 0.00413146
Epoch [19/300], Train Loss: 0.003142
Validation Loss: 0.00413624
Epoch [20/300], Train Loss: 0.003050
Validation Loss: 0.00412821
Epoch [21/300], Train Loss: 0.003191
Validation Loss: 0.00412678
Epoch [22/300], Train Loss: 0.003102
Validation Loss: 0.00411621
Epoch [23/300], Train Loss: 0.003199
Validation Loss: 0.00411737
Epoch [24/300], Train Loss: 0.003189
Validation Loss: 0.00411484
Epoch [25/300], Train Loss: 0.003132
Validation Loss: 0.00409868
Epoch [26/300], Train Loss: 0.003040
Validation Loss: 0.00409674
Epoch [27/300], Train Loss: 0.003071
Validation Loss: 0.00410387
Epoch [28/300], Train Loss: 0.003033
Validation Loss: 0.00409216
Epoch [29/300], Train Loss: 0.003124
Validation Loss: 0.00408559
Epoch [30/300], Train Loss: 0.003097
Validation Loss: 0.00407041
Epoch [31/300], Train Loss: 0.003074
Validation Loss: 0.00408023
Epoch [32/300], Train Loss: 0.003099
Validation Loss: 0.00407715
Epoch [33/300], Train Loss: 0.003076
Validation Loss: 0.00406684
Epoch [34/300], Train Loss: 0.003063
Validation Loss: 0.00405482
Epoch [35/300], Train Loss: 0.003046
Validation Loss: 0.00406105
Epoch [36/300], Train Loss: 0.003099
Validation Loss: 0.00406439
Epoch [37/300], Train Loss: 0.003028
Validation Loss: 0.00404659
Epoch [38/300], Train Loss: 0.003020
Validation Loss: 0.00405483
Epoch [39/300], Train Loss: 0.002995
Validation Loss: 0.00405444
Epoch [40/300], Train Loss: 0.003139
Validation Loss: 0.00405983
Epoch [41/300], Train Loss: 0.003074
Validation Loss: 0.00404072
Epoch [42/300], Train Loss: 0.003089
Validation Loss: 0.00404482
Epoch [43/300], Train Loss: 0.003174
Validation Loss: 0.00405321
Epoch [44/300], Train Loss: 0.003140
Validation Loss: 0.00404047
Epoch [45/300], Train Loss: 0.002995
Validation Loss: 0.00404170
Epoch [46/300], Train Loss: 0.003079
Validation Loss: 0.00404045
Epoch [47/300], Train Loss: 0.002967
Validation Loss: 0.00403668
Epoch [48/300], Train Loss: 0.003069
Validation Loss: 0.00404745
Epoch [49/300], Train Loss: 0.002996
Validation Loss: 0.00404322
Epoch [50/300], Train Loss: 0.003035
Validation Loss: 0.00403902
Epoch [51/300], Train Loss: 0.003114
Validation Loss: 0.00405009
Epoch [52/300], Train Loss: 0.003099
Validation Loss: 0.00403225
Epoch [53/300], Train Loss: 0.003114
Validation Loss: 0.00403537
Epoch [54/300], Train Loss: 0.003025
Validation Loss: 0.00402996
Epoch [55/300], Train Loss: 0.003042
Validation Loss: 0.00403188
Epoch [56/300], Train Loss: 0.003060
Validation Loss: 0.00404253
Epoch [57/300], Train Loss: 0.003085
Validation Loss: 0.00403518
Epoch [58/300], Train Loss: 0.003089
Validation Loss: 0.00402933
Epoch [59/300], Train Loss: 0.003050
Validation Loss: 0.00402710
Epoch [60/300], Train Loss: 0.003109
Validation Loss: 0.00403580
Epoch [61/300], Train Loss: 0.003096
Validation Loss: 0.00402782
Epoch [62/300], Train Loss: 0.003026
Validation Loss: 0.00402171
Epoch [63/300], Train Loss: 0.003029
Validation Loss: 0.00402525
Epoch [64/300], Train Loss: 0.003068
Validation Loss: 0.00403134
Epoch [65/300], Train Loss: 0.003095
Validation Loss: 0.00402381
Epoch [66/300], Train Loss: 0.003109
Validation Loss: 0.00402141
Epoch [67/300], Train Loss: 0.003054
Validation Loss: 0.00401508
Epoch [68/300], Train Loss: 0.002963
Validation Loss: 0.00401718
Epoch [69/300], Train Loss: 0.003059
Validation Loss: 0.00402878
Epoch [70/300], Train Loss: 0.002977
Validation Loss: 0.00402425
Epoch [71/300], Train Loss: 0.003053
Validation Loss: 0.00401669
Epoch [72/300], Train Loss: 0.003051
Validation Loss: 0.00401171
Epoch [73/300], Train Loss: 0.003104
Validation Loss: 0.00401773
Epoch [74/300], Train Loss: 0.003048
Validation Loss: 0.00402006
Epoch [75/300], Train Loss: 0.003038
Validation Loss: 0.00401492
Epoch [76/300], Train Loss: 0.003026
Validation Loss: 0.00400919
Epoch [77/300], Train Loss: 0.003006
Validation Loss: 0.00401390
Epoch [78/300], Train Loss: 0.003043
Validation Loss: 0.00401263
Epoch [79/300], Train Loss: 0.003020
Validation Loss: 0.00400895
Epoch [80/300], Train Loss: 0.003035
Validation Loss: 0.00401056
Epoch [81/300], Train Loss: 0.003048
Validation Loss: 0.00400941
Epoch [82/300], Train Loss: 0.003075
Validation Loss: 0.00400315
Epoch [83/300], Train Loss: 0.002969
Validation Loss: 0.00400902
Epoch [84/300], Train Loss: 0.003059
Validation Loss: 0.00400675
Epoch [85/300], Train Loss: 0.003093
Validation Loss: 0.00400311
Epoch [86/300], Train Loss: 0.002991
Validation Loss: 0.00400039
Epoch [87/300], Train Loss: 0.003005
Validation Loss: 0.00400145
Epoch [88/300], Train Loss: 0.003036
Validation Loss: 0.00400620
Epoch [89/300], Train Loss: 0.003162
Validation Loss: 0.00400283
Epoch [90/300], Train Loss: 0.003110
Validation Loss: 0.00399385
Epoch [91/300], Train Loss: 0.003046
Validation Loss: 0.00399655
Epoch [92/300], Train Loss: 0.003040
Validation Loss: 0.00399926
Epoch [93/300], Train Loss: 0.003102
Validation Loss: 0.00399958
Epoch [94/300], Train Loss: 0.003033
Validation Loss: 0.00399197
Epoch [95/300], Train Loss: 0.003008
Validation Loss: 0.00399078
Epoch [96/300], Train Loss: 0.003032
Validation Loss: 0.00400495
Epoch [97/300], Train Loss: 0.003045
Validation Loss: 0.00399773
Epoch [98/300], Train Loss: 0.002999
Validation Loss: 0.00399304
Epoch [99/300], Train Loss: 0.003096
Validation Loss: 0.00399063
Epoch [100/300], Train Loss: 0.003050
Validation Loss: 0.00398769
Epoch [101/300], Train Loss: 0.003034
Validation Loss: 0.00399189
Epoch [102/300], Train Loss: 0.003125
Validation Loss: 0.00399171
Epoch [103/300], Train Loss: 0.003110
Validation Loss: 0.00398849
Epoch [104/300], Train Loss: 0.003015
Validation Loss: 0.00398383
Epoch [105/300], Train Loss: 0.003115
Validation Loss: 0.00398900
Epoch [106/300], Train Loss: 0.003036
Validation Loss: 0.00398665
Epoch [107/300], Train Loss: 0.003013
Validation Loss: 0.00398071
Epoch [108/300], Train Loss: 0.003027
Validation Loss: 0.00398550
Epoch [109/300], Train Loss: 0.003045
Validation Loss: 0.00398392
Epoch [110/300], Train Loss: 0.003139
Validation Loss: 0.00398307
Epoch [111/300], Train Loss: 0.002946
Validation Loss: 0.00397769
Epoch [112/300], Train Loss: 0.003094
Validation Loss: 0.00399209
Epoch [113/300], Train Loss: 0.003125
Validation Loss: 0.00398435
Epoch [114/300], Train Loss: 0.003010
Validation Loss: 0.00397527
Epoch [115/300], Train Loss: 0.003091
Validation Loss: 0.00397584
Epoch [116/300], Train Loss: 0.003055
Validation Loss: 0.00397697
Epoch [117/300], Train Loss: 0.003011
Validation Loss: 0.00397835
Epoch [118/300], Train Loss: 0.002984
Validation Loss: 0.00397224
Epoch [119/300], Train Loss: 0.003082
Validation Loss: 0.00397620
Epoch [120/300], Train Loss: 0.003026
Validation Loss: 0.00397772
Epoch [121/300], Train Loss: 0.003081
Validation Loss: 0.00397273
Epoch [122/300], Train Loss: 0.003017
Validation Loss: 0.00396721
Epoch [123/300], Train Loss: 0.003075
Validation Loss: 0.00397267
Epoch [124/300], Train Loss: 0.003004
Validation Loss: 0.00396690
Epoch [125/300], Train Loss: 0.003063
Validation Loss: 0.00397176
Epoch [126/300], Train Loss: 0.003089
Validation Loss: 0.00396766
Epoch [127/300], Train Loss: 0.002989
Validation Loss: 0.00396362
Epoch [128/300], Train Loss: 0.002987
Validation Loss: 0.00396675
Epoch [129/300], Train Loss: 0.002997
Validation Loss: 0.00397094
Epoch [130/300], Train Loss: 0.003024
Validation Loss: 0.00396811
Epoch [131/300], Train Loss: 0.003017
Validation Loss: 0.00396591
Epoch [132/300], Train Loss: 0.002998
Validation Loss: 0.00395987
Epoch [133/300], Train Loss: 0.002982
Validation Loss: 0.00396236
Epoch [134/300], Train Loss: 0.003047
Validation Loss: 0.00396345
Epoch [135/300], Train Loss: 0.003023
Validation Loss: 0.00395921
Epoch [136/300], Train Loss: 0.003062
Validation Loss: 0.00395631
Epoch [137/300], Train Loss: 0.002994
Validation Loss: 0.00395852
Epoch [138/300], Train Loss: 0.003022
Validation Loss: 0.00395822
Epoch [139/300], Train Loss: 0.003095
Validation Loss: 0.00396153
Epoch [140/300], Train Loss: 0.003026
Validation Loss: 0.00394855
Epoch [141/300], Train Loss: 0.003021
Validation Loss: 0.00395731
Epoch [142/300], Train Loss: 0.003103
Validation Loss: 0.00397343
Epoch [143/300], Train Loss: 0.003084
Validation Loss: 0.00394880
Epoch [144/300], Train Loss: 0.002974
Validation Loss: 0.00394765
Epoch [145/300], Train Loss: 0.003063
Validation Loss: 0.00395339
Epoch [146/300], Train Loss: 0.003088
Validation Loss: 0.00394922
Epoch [147/300], Train Loss: 0.002983
Validation Loss: 0.00394223
Epoch [148/300], Train Loss: 0.002988
Validation Loss: 0.00394267
Epoch [149/300], Train Loss: 0.003044
Validation Loss: 0.00395126
Epoch [150/300], Train Loss: 0.002980
Validation Loss: 0.00395113
Epoch [151/300], Train Loss: 0.003061
Validation Loss: 0.00394465
Epoch [152/300], Train Loss: 0.003072
Validation Loss: 0.00393205
Epoch [153/300], Train Loss: 0.003063
Validation Loss: 0.00393475
Epoch [154/300], Train Loss: 0.003012
Validation Loss: 0.00393591
Epoch [155/300], Train Loss: 0.003060
Validation Loss: 0.00393474
Epoch [156/300], Train Loss: 0.003048
Validation Loss: 0.00393200
Epoch [157/300], Train Loss: 0.002997
Validation Loss: 0.00392676
Epoch [158/300], Train Loss: 0.002964
Validation Loss: 0.00392431
Epoch [159/300], Train Loss: 0.002991
Validation Loss: 0.00392776
Epoch [160/300], Train Loss: 0.003019
Validation Loss: 0.00393064
Epoch [161/300], Train Loss: 0.002998
Validation Loss: 0.00391477
Epoch [162/300], Train Loss: 0.003088
Validation Loss: 0.00391924
Epoch [163/300], Train Loss: 0.002978
Validation Loss: 0.00391169
Epoch [164/300], Train Loss: 0.003019
Validation Loss: 0.00390708
Epoch [165/300], Train Loss: 0.003053
Validation Loss: 0.00388345
Epoch [166/300], Train Loss: 0.003099
Validation Loss: 0.00382838
Epoch [167/300], Train Loss: 0.003039
Validation Loss: 0.00381064
Epoch [168/300], Train Loss: 0.002980
Validation Loss: 0.00379114
Epoch [169/300], Train Loss: 0.002971
Validation Loss: 0.00380832
Epoch [170/300], Train Loss: 0.002984
Validation Loss: 0.00391482
Epoch [171/300], Train Loss: 0.003002
Validation Loss: 0.00392150
Epoch [172/300], Train Loss: 0.002930
Validation Loss: 0.00389628
Epoch [173/300], Train Loss: 0.003030
Validation Loss: 0.00387180
Epoch [174/300], Train Loss: 0.003058
Validation Loss: 0.00380503
Epoch [175/300], Train Loss: 0.003028
Validation Loss: 0.00378203
Epoch [176/300], Train Loss: 0.003232
Validation Loss: 0.00471832
Epoch [177/300], Train Loss: 0.003005
Validation Loss: 0.00389197
Epoch [178/300], Train Loss: 0.002977
Validation Loss: 0.00400867
Epoch [179/300], Train Loss: 0.003004
Validation Loss: 0.00399164
Epoch [180/300], Train Loss: 0.002997
Validation Loss: 0.00397621
Epoch [181/300], Train Loss: 0.003005
Validation Loss: 0.00396645
Epoch [182/300], Train Loss: 0.002997
Validation Loss: 0.00396424
Epoch [183/300], Train Loss: 0.003078
Validation Loss: 0.00395936
Epoch [184/300], Train Loss: 0.003000
Validation Loss: 0.00395180
Epoch [185/300], Train Loss: 0.003009
Validation Loss: 0.00394410
Early stopping triggered

Evaluating model for: Laptop
Run 18/72 completed in 206.39 seconds with: {'MAE': np.float32(2.685589), 'MSE': np.float32(28.20318), 'RMSE': np.float32(5.3106666), 'SAE': np.float32(0.021798069), 'NDE': np.float32(0.6811886)}

Run 19/72: hidden=128, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Laptop
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.003949
Validation Loss: 0.00467446
Epoch [2/300], Train Loss: 0.003268
Validation Loss: 0.00425229
Epoch [3/300], Train Loss: 0.003168
Validation Loss: 0.00414625
Epoch [4/300], Train Loss: 0.003133
Validation Loss: 0.00414525
Epoch [5/300], Train Loss: 0.003198
Validation Loss: 0.00414362
Epoch [6/300], Train Loss: 0.003150
Validation Loss: 0.00415249
Epoch [7/300], Train Loss: 0.003114
Validation Loss: 0.00416814
Epoch [8/300], Train Loss: 0.003196
Validation Loss: 0.00417323
Epoch [9/300], Train Loss: 0.003177
Validation Loss: 0.00415677
Epoch [10/300], Train Loss: 0.003210
Validation Loss: 0.00415694
Epoch [11/300], Train Loss: 0.003163
Validation Loss: 0.00415086
Epoch [12/300], Train Loss: 0.003138
Validation Loss: 0.00415162
Epoch [13/300], Train Loss: 0.003064
Validation Loss: 0.00414959
Epoch [14/300], Train Loss: 0.003107
Validation Loss: 0.00416124
Epoch [15/300], Train Loss: 0.003072
Validation Loss: 0.00416793
Early stopping triggered

Evaluating model for: Laptop
Run 19/72 completed in 18.34 seconds with: {'MAE': np.float32(2.3843107), 'MSE': np.float32(29.258282), 'RMSE': np.float32(5.4090924), 'SAE': np.float32(1.6111022e-05), 'NDE': np.float32(0.6938133)}

Run 20/72: hidden=128, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Laptop
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.004271
Validation Loss: 0.00496886
Epoch [2/300], Train Loss: 0.003450
Validation Loss: 0.00436341
Epoch [3/300], Train Loss: 0.003210
Validation Loss: 0.00415239
Epoch [4/300], Train Loss: 0.003157
Validation Loss: 0.00415406
Epoch [5/300], Train Loss: 0.003228
Validation Loss: 0.00414646
Epoch [6/300], Train Loss: 0.003166
Validation Loss: 0.00415881
Epoch [7/300], Train Loss: 0.003131
Validation Loss: 0.00418052
Epoch [8/300], Train Loss: 0.003214
Validation Loss: 0.00418267
Epoch [9/300], Train Loss: 0.003193
Validation Loss: 0.00416000
Epoch [10/300], Train Loss: 0.003226
Validation Loss: 0.00415965
Epoch [11/300], Train Loss: 0.003178
Validation Loss: 0.00415395
Epoch [12/300], Train Loss: 0.003155
Validation Loss: 0.00415631
Epoch [13/300], Train Loss: 0.003078
Validation Loss: 0.00415453
Epoch [14/300], Train Loss: 0.003122
Validation Loss: 0.00416845
Epoch [15/300], Train Loss: 0.003086
Validation Loss: 0.00417407
Early stopping triggered

Evaluating model for: Laptop
Run 20/72 completed in 19.46 seconds with: {'MAE': np.float32(2.3892725), 'MSE': np.float32(29.28901), 'RMSE': np.float32(5.411932), 'SAE': np.float32(0.0052147694), 'NDE': np.float32(0.694177)}

Run 21/72: hidden=128, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Laptop
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.003016
Validation Loss: 0.00331090
Epoch [2/300], Train Loss: 0.003225
Validation Loss: 0.00327557
Epoch [3/300], Train Loss: 0.003402
Validation Loss: 0.00327535
Epoch [4/300], Train Loss: 0.003244
Validation Loss: 0.00328245
Epoch [5/300], Train Loss: 0.003181
Validation Loss: 0.00328076
Epoch [6/300], Train Loss: 0.003337
Validation Loss: 0.00327779
Epoch [7/300], Train Loss: 0.002882
Validation Loss: 0.00327630
Epoch [8/300], Train Loss: 0.002980
Validation Loss: 0.00327693
Epoch [9/300], Train Loss: 0.003061
Validation Loss: 0.00328089
Epoch [10/300], Train Loss: 0.003178
Validation Loss: 0.00328237
Epoch [11/300], Train Loss: 0.003168
Validation Loss: 0.00328294
Epoch [12/300], Train Loss: 0.003210
Validation Loss: 0.00328004
Epoch [13/300], Train Loss: 0.003054
Validation Loss: 0.00327772
Early stopping triggered

Evaluating model for: Laptop
Run 21/72 completed in 7.01 seconds with: {'MAE': np.float32(2.4946232), 'MSE': np.float32(30.96484), 'RMSE': np.float32(5.564606), 'SAE': np.float32(0.13661231), 'NDE': np.float32(0.73776495)}

Run 22/72: hidden=128, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Laptop
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.010650
Validation Loss: 0.01043957
Epoch [2/300], Train Loss: 0.009818
Validation Loss: 0.00920290
Epoch [3/300], Train Loss: 0.009039
Validation Loss: 0.00809384
Epoch [4/300], Train Loss: 0.007764
Validation Loss: 0.00708472
Epoch [5/300], Train Loss: 0.006658
Validation Loss: 0.00616173
Epoch [6/300], Train Loss: 0.006079
Validation Loss: 0.00535347
Epoch [7/300], Train Loss: 0.004534
Validation Loss: 0.00462859
Epoch [8/300], Train Loss: 0.004076
Validation Loss: 0.00402416
Epoch [9/300], Train Loss: 0.003662
Validation Loss: 0.00358468
Epoch [10/300], Train Loss: 0.003442
Validation Loss: 0.00334431
Epoch [11/300], Train Loss: 0.003276
Validation Loss: 0.00330440
Epoch [12/300], Train Loss: 0.003328
Validation Loss: 0.00335877
Epoch [13/300], Train Loss: 0.003262
Validation Loss: 0.00337427
Epoch [14/300], Train Loss: 0.003555
Validation Loss: 0.00332892
Epoch [15/300], Train Loss: 0.003247
Validation Loss: 0.00330416
Epoch [16/300], Train Loss: 0.003533
Validation Loss: 0.00329725
Epoch [17/300], Train Loss: 0.003032
Validation Loss: 0.00329850
Epoch [18/300], Train Loss: 0.003604
Validation Loss: 0.00330218
Epoch [19/300], Train Loss: 0.003252
Validation Loss: 0.00330136
Epoch [20/300], Train Loss: 0.003235
Validation Loss: 0.00329876
Epoch [21/300], Train Loss: 0.003774
Validation Loss: 0.00329649
Epoch [22/300], Train Loss: 0.003697
Validation Loss: 0.00329630
Epoch [23/300], Train Loss: 0.003319
Validation Loss: 0.00329903
Epoch [24/300], Train Loss: 0.003118
Validation Loss: 0.00330051
Epoch [25/300], Train Loss: 0.003389
Validation Loss: 0.00329688
Epoch [26/300], Train Loss: 0.003382
Validation Loss: 0.00329522
Epoch [27/300], Train Loss: 0.003323
Validation Loss: 0.00329569
Epoch [28/300], Train Loss: 0.003319
Validation Loss: 0.00329604
Epoch [29/300], Train Loss: 0.003118
Validation Loss: 0.00329533
Epoch [30/300], Train Loss: 0.003292
Validation Loss: 0.00329502
Epoch [31/300], Train Loss: 0.003633
Validation Loss: 0.00329481
Epoch [32/300], Train Loss: 0.003228
Validation Loss: 0.00329456
Epoch [33/300], Train Loss: 0.002876
Validation Loss: 0.00329548
Epoch [34/300], Train Loss: 0.003433
Validation Loss: 0.00329783
Epoch [35/300], Train Loss: 0.003053
Validation Loss: 0.00329803
Epoch [36/300], Train Loss: 0.003285
Validation Loss: 0.00329737
Epoch [37/300], Train Loss: 0.003275
Validation Loss: 0.00329575
Epoch [38/300], Train Loss: 0.003542
Validation Loss: 0.00329496
Epoch [39/300], Train Loss: 0.003717
Validation Loss: 0.00329383
Epoch [40/300], Train Loss: 0.002981
Validation Loss: 0.00329453
Epoch [41/300], Train Loss: 0.003336
Validation Loss: 0.00329437
Epoch [42/300], Train Loss: 0.003249
Validation Loss: 0.00329384
Epoch [43/300], Train Loss: 0.003830
Validation Loss: 0.00329368
Epoch [44/300], Train Loss: 0.003119
Validation Loss: 0.00329430
Epoch [45/300], Train Loss: 0.003550
Validation Loss: 0.00329362
Epoch [46/300], Train Loss: 0.003366
Validation Loss: 0.00329352
Epoch [47/300], Train Loss: 0.003701
Validation Loss: 0.00329347
Epoch [48/300], Train Loss: 0.003237
Validation Loss: 0.00329348
Epoch [49/300], Train Loss: 0.003275
Validation Loss: 0.00329341
Epoch [50/300], Train Loss: 0.003767
Validation Loss: 0.00329372
Epoch [51/300], Train Loss: 0.003239
Validation Loss: 0.00329349
Epoch [52/300], Train Loss: 0.003037
Validation Loss: 0.00329331
Epoch [53/300], Train Loss: 0.003250
Validation Loss: 0.00329327
Epoch [54/300], Train Loss: 0.003268
Validation Loss: 0.00329337
Epoch [55/300], Train Loss: 0.003016
Validation Loss: 0.00329361
Epoch [56/300], Train Loss: 0.003197
Validation Loss: 0.00329631
Epoch [57/300], Train Loss: 0.003232
Validation Loss: 0.00329694
Epoch [58/300], Train Loss: 0.003702
Validation Loss: 0.00329612
Epoch [59/300], Train Loss: 0.003533
Validation Loss: 0.00329381
Epoch [60/300], Train Loss: 0.003451
Validation Loss: 0.00329478
Epoch [61/300], Train Loss: 0.003178
Validation Loss: 0.00329738
Epoch [62/300], Train Loss: 0.002988
Validation Loss: 0.00329642
Epoch [63/300], Train Loss: 0.003089
Validation Loss: 0.00329450
Early stopping triggered

Evaluating model for: Laptop
Run 22/72 completed in 36.57 seconds with: {'MAE': np.float32(2.600949), 'MSE': np.float32(31.127193), 'RMSE': np.float32(5.579175), 'SAE': np.float32(0.15094537), 'NDE': np.float32(0.73969656)}

Run 23/72: hidden=128, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Laptop
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.008826
Validation Loss: 0.00867124
Epoch [2/300], Train Loss: 0.008138
Validation Loss: 0.00762450
Epoch [3/300], Train Loss: 0.007484
Validation Loss: 0.00665410
Epoch [4/300], Train Loss: 0.006366
Validation Loss: 0.00579319
Epoch [5/300], Train Loss: 0.005407
Validation Loss: 0.00502037
Epoch [6/300], Train Loss: 0.004930
Validation Loss: 0.00432843
Epoch [7/300], Train Loss: 0.003635
Validation Loss: 0.00378512
Epoch [8/300], Train Loss: 0.003345
Validation Loss: 0.00343055
Epoch [9/300], Train Loss: 0.003191
Validation Loss: 0.00329113
Epoch [10/300], Train Loss: 0.003272
Validation Loss: 0.00332565
Epoch [11/300], Train Loss: 0.003271
Validation Loss: 0.00335873
Epoch [12/300], Train Loss: 0.003325
Validation Loss: 0.00333181
Epoch [13/300], Train Loss: 0.003150
Validation Loss: 0.00329851
Epoch [14/300], Train Loss: 0.003478
Validation Loss: 0.00328837
Epoch [15/300], Train Loss: 0.003187
Validation Loss: 0.00329222
Epoch [16/300], Train Loss: 0.003501
Validation Loss: 0.00329286
Epoch [17/300], Train Loss: 0.003001
Validation Loss: 0.00329072
Epoch [18/300], Train Loss: 0.003560
Validation Loss: 0.00328969
Epoch [19/300], Train Loss: 0.003206
Validation Loss: 0.00328851
Epoch [20/300], Train Loss: 0.003187
Validation Loss: 0.00328881
Epoch [21/300], Train Loss: 0.003724
Validation Loss: 0.00328977
Epoch [22/300], Train Loss: 0.003651
Validation Loss: 0.00329163
Epoch [23/300], Train Loss: 0.003287
Validation Loss: 0.00329404
Epoch [24/300], Train Loss: 0.003085
Validation Loss: 0.00329358
Early stopping triggered

Evaluating model for: Laptop
Run 23/72 completed in 15.09 seconds with: {'MAE': np.float32(2.7201138), 'MSE': np.float32(31.619804), 'RMSE': np.float32(5.623149), 'SAE': np.float32(0.1781212), 'NDE': np.float32(0.7455268)}

Run 24/72: hidden=128, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Laptop
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.002951
Validation Loss: 0.00327006
Epoch [2/300], Train Loss: 0.003206
Validation Loss: 0.00327060
Epoch [3/300], Train Loss: 0.003408
Validation Loss: 0.00327021
Epoch [4/300], Train Loss: 0.003245
Validation Loss: 0.00326999
Epoch [5/300], Train Loss: 0.003178
Validation Loss: 0.00326991
Epoch [6/300], Train Loss: 0.003339
Validation Loss: 0.00327042
Epoch [7/300], Train Loss: 0.002895
Validation Loss: 0.00327199
Epoch [8/300], Train Loss: 0.002992
Validation Loss: 0.00326991
Epoch [9/300], Train Loss: 0.003069
Validation Loss: 0.00327232
Epoch [10/300], Train Loss: 0.003186
Validation Loss: 0.00327411
Epoch [11/300], Train Loss: 0.003178
Validation Loss: 0.00327538
Epoch [12/300], Train Loss: 0.003219
Validation Loss: 0.00327193
Epoch [13/300], Train Loss: 0.003068
Validation Loss: 0.00326993
Epoch [14/300], Train Loss: 0.003422
Validation Loss: 0.00326995
Epoch [15/300], Train Loss: 0.003143
Validation Loss: 0.00327218
Epoch [16/300], Train Loss: 0.003444
Validation Loss: 0.00327379
Epoch [17/300], Train Loss: 0.002973
Validation Loss: 0.00327259
Epoch [18/300], Train Loss: 0.003505
Validation Loss: 0.00326997
Early stopping triggered

Evaluating model for: Laptop
Run 24/72 completed in 12.10 seconds with: {'MAE': np.float32(2.5251386), 'MSE': np.float32(31.153397), 'RMSE': np.float32(5.581523), 'SAE': np.float32(0.14506963), 'NDE': np.float32(0.7400079)}

Run 25/72: hidden=256, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Laptop
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.005822
Validation Loss: 0.00374724
Epoch [2/300], Train Loss: 0.003450
Validation Loss: 0.00362840
Epoch [3/300], Train Loss: 0.003367
Validation Loss: 0.00358166
Epoch [4/300], Train Loss: 0.003347
Validation Loss: 0.00354258
Epoch [5/300], Train Loss: 0.003520
Validation Loss: 0.00351867
Epoch [6/300], Train Loss: 0.003273
Validation Loss: 0.00350355
Epoch [7/300], Train Loss: 0.003271
Validation Loss: 0.00352248
Epoch [8/300], Train Loss: 0.003253
Validation Loss: 0.00348992
Epoch [9/300], Train Loss: 0.003314
Validation Loss: 0.00347187
Epoch [10/300], Train Loss: 0.003318
Validation Loss: 0.00346767
Epoch [11/300], Train Loss: 0.003226
Validation Loss: 0.00344760
Epoch [12/300], Train Loss: 0.003206
Validation Loss: 0.00344937
Epoch [13/300], Train Loss: 0.003213
Validation Loss: 0.00343622
Epoch [14/300], Train Loss: 0.003266
Validation Loss: 0.00345980
Epoch [15/300], Train Loss: 0.003236
Validation Loss: 0.00341569
Epoch [16/300], Train Loss: 0.003226
Validation Loss: 0.00340644
Epoch [17/300], Train Loss: 0.003227
Validation Loss: 0.00342847
Epoch [18/300], Train Loss: 0.003223
Validation Loss: 0.00338390
Epoch [19/300], Train Loss: 0.003248
Validation Loss: 0.00336251
Epoch [20/300], Train Loss: 0.003202
Validation Loss: 0.00332348
Epoch [21/300], Train Loss: 0.003178
Validation Loss: 0.00324932
Epoch [22/300], Train Loss: 0.003196
Validation Loss: 0.00320287
Epoch [23/300], Train Loss: 0.003122
Validation Loss: 0.00312174
Epoch [24/300], Train Loss: 0.003097
Validation Loss: 0.00302038
Epoch [25/300], Train Loss: 0.002867
Validation Loss: 0.00290457
Epoch [26/300], Train Loss: 0.002759
Validation Loss: 0.00289081
Epoch [27/300], Train Loss: 0.002600
Validation Loss: 0.00270513
Epoch [28/300], Train Loss: 0.002480
Validation Loss: 0.00243688
Epoch [29/300], Train Loss: 0.002313
Validation Loss: 0.00239893
Epoch [30/300], Train Loss: 0.002352
Validation Loss: 0.00308033
Epoch [31/300], Train Loss: 0.002184
Validation Loss: 0.00215127
Epoch [32/300], Train Loss: 0.001927
Validation Loss: 0.00206589
Epoch [33/300], Train Loss: 0.001915
Validation Loss: 0.00196500
Epoch [34/300], Train Loss: 0.001885
Validation Loss: 0.00209446
Epoch [35/300], Train Loss: 0.001762
Validation Loss: 0.00201403
Epoch [36/300], Train Loss: 0.001692
Validation Loss: 0.00186757
Epoch [37/300], Train Loss: 0.001637
Validation Loss: 0.00173055
Epoch [38/300], Train Loss: 0.001595
Validation Loss: 0.00164522
Epoch [39/300], Train Loss: 0.001541
Validation Loss: 0.00165889
Epoch [40/300], Train Loss: 0.001359
Validation Loss: 0.00153432
Epoch [41/300], Train Loss: 0.001286
Validation Loss: 0.00150068
Epoch [42/300], Train Loss: 0.001233
Validation Loss: 0.00145148
Epoch [43/300], Train Loss: 0.001237
Validation Loss: 0.00136375
Epoch [44/300], Train Loss: 0.001262
Validation Loss: 0.00132039
Epoch [45/300], Train Loss: 0.001145
Validation Loss: 0.00125922
Epoch [46/300], Train Loss: 0.001112
Validation Loss: 0.00119574
Epoch [47/300], Train Loss: 0.001092
Validation Loss: 0.00125794
Epoch [48/300], Train Loss: 0.001073
Validation Loss: 0.00132950
Epoch [49/300], Train Loss: 0.000983
Validation Loss: 0.00088957
Epoch [50/300], Train Loss: 0.000960
Validation Loss: 0.00089020
Epoch [51/300], Train Loss: 0.000897
Validation Loss: 0.00081836
Epoch [52/300], Train Loss: 0.000878
Validation Loss: 0.00081708
Epoch [53/300], Train Loss: 0.000839
Validation Loss: 0.00083290
Epoch [54/300], Train Loss: 0.000819
Validation Loss: 0.00078932
Epoch [55/300], Train Loss: 0.000791
Validation Loss: 0.00072517
Epoch [56/300], Train Loss: 0.000775
Validation Loss: 0.00069464
Epoch [57/300], Train Loss: 0.000767
Validation Loss: 0.00068537
Epoch [58/300], Train Loss: 0.000739
Validation Loss: 0.00067092
Epoch [59/300], Train Loss: 0.000743
Validation Loss: 0.00067174
Epoch [60/300], Train Loss: 0.000744
Validation Loss: 0.00064306
Epoch [61/300], Train Loss: 0.000747
Validation Loss: 0.00064825
Epoch [62/300], Train Loss: 0.000706
Validation Loss: 0.00062418
Epoch [63/300], Train Loss: 0.000703
Validation Loss: 0.00060723
Epoch [64/300], Train Loss: 0.000771
Validation Loss: 0.00082982
Epoch [65/300], Train Loss: 0.000735
Validation Loss: 0.00090860
Epoch [66/300], Train Loss: 0.000731
Validation Loss: 0.00060628
Epoch [67/300], Train Loss: 0.000668
Validation Loss: 0.00057672
Epoch [68/300], Train Loss: 0.000654
Validation Loss: 0.00056868
Epoch [69/300], Train Loss: 0.000650
Validation Loss: 0.00057229
Epoch [70/300], Train Loss: 0.000632
Validation Loss: 0.00054955
Epoch [71/300], Train Loss: 0.000627
Validation Loss: 0.00055277
Epoch [72/300], Train Loss: 0.000642
Validation Loss: 0.00053536
Epoch [73/300], Train Loss: 0.000615
Validation Loss: 0.00053138
Epoch [74/300], Train Loss: 0.000622
Validation Loss: 0.00059555
Epoch [75/300], Train Loss: 0.000622
Validation Loss: 0.00053098
Epoch [76/300], Train Loss: 0.000630
Validation Loss: 0.00052469
Epoch [77/300], Train Loss: 0.000615
Validation Loss: 0.00052762
Epoch [78/300], Train Loss: 0.000596
Validation Loss: 0.00051996
Epoch [79/300], Train Loss: 0.000602
Validation Loss: 0.00049925
Epoch [80/300], Train Loss: 0.000589
Validation Loss: 0.00053201
Epoch [81/300], Train Loss: 0.000619
Validation Loss: 0.00049717
Epoch [82/300], Train Loss: 0.000600
Validation Loss: 0.00053964
Epoch [83/300], Train Loss: 0.000601
Validation Loss: 0.00049481
Epoch [84/300], Train Loss: 0.000587
Validation Loss: 0.00052395
Epoch [85/300], Train Loss: 0.000604
Validation Loss: 0.00057831
Epoch [86/300], Train Loss: 0.000610
Validation Loss: 0.00049153
Epoch [87/300], Train Loss: 0.000574
Validation Loss: 0.00046851
Epoch [88/300], Train Loss: 0.000559
Validation Loss: 0.00046348
Epoch [89/300], Train Loss: 0.000565
Validation Loss: 0.00046770
Epoch [90/300], Train Loss: 0.000556
Validation Loss: 0.00045906
Epoch [91/300], Train Loss: 0.000562
Validation Loss: 0.00046940
Epoch [92/300], Train Loss: 0.000566
Validation Loss: 0.00045170
Epoch [93/300], Train Loss: 0.000551
Validation Loss: 0.00044826
Epoch [94/300], Train Loss: 0.000554
Validation Loss: 0.00044003
Epoch [95/300], Train Loss: 0.000546
Validation Loss: 0.00048358
Epoch [96/300], Train Loss: 0.000549
Validation Loss: 0.00043147
Epoch [97/300], Train Loss: 0.000540
Validation Loss: 0.00042782
Epoch [98/300], Train Loss: 0.000535
Validation Loss: 0.00043292
Epoch [99/300], Train Loss: 0.000538
Validation Loss: 0.00043727
Epoch [100/300], Train Loss: 0.000541
Validation Loss: 0.00043102
Epoch [101/300], Train Loss: 0.000534
Validation Loss: 0.00043036
Epoch [102/300], Train Loss: 0.000526
Validation Loss: 0.00041621
Epoch [103/300], Train Loss: 0.000527
Validation Loss: 0.00042109
Epoch [104/300], Train Loss: 0.000539
Validation Loss: 0.00040616
Epoch [105/300], Train Loss: 0.000528
Validation Loss: 0.00049170
Epoch [106/300], Train Loss: 0.000513
Validation Loss: 0.00041598
Epoch [107/300], Train Loss: 0.000514
Validation Loss: 0.00039802
Epoch [108/300], Train Loss: 0.000509
Validation Loss: 0.00039691
Epoch [109/300], Train Loss: 0.000506
Validation Loss: 0.00040591
Epoch [110/300], Train Loss: 0.000497
Validation Loss: 0.00038863
Epoch [111/300], Train Loss: 0.000500
Validation Loss: 0.00038704
Epoch [112/300], Train Loss: 0.000501
Validation Loss: 0.00039553
Epoch [113/300], Train Loss: 0.000499
Validation Loss: 0.00038802
Epoch [114/300], Train Loss: 0.000500
Validation Loss: 0.00039562
Epoch [115/300], Train Loss: 0.000496
Validation Loss: 0.00038941
Epoch [116/300], Train Loss: 0.000484
Validation Loss: 0.00037557
Epoch [117/300], Train Loss: 0.000495
Validation Loss: 0.00037967
Epoch [118/300], Train Loss: 0.000516
Validation Loss: 0.00052620
Epoch [119/300], Train Loss: 0.000515
Validation Loss: 0.00039177
Epoch [120/300], Train Loss: 0.000487
Validation Loss: 0.00037287
Epoch [121/300], Train Loss: 0.000503
Validation Loss: 0.00036912
Epoch [122/300], Train Loss: 0.000514
Validation Loss: 0.00049988
Epoch [123/300], Train Loss: 0.000564
Validation Loss: 0.00038738
Epoch [124/300], Train Loss: 0.000501
Validation Loss: 0.00036901
Epoch [125/300], Train Loss: 0.000492
Validation Loss: 0.00040068
Epoch [126/300], Train Loss: 0.000476
Validation Loss: 0.00036651
Epoch [127/300], Train Loss: 0.000465
Validation Loss: 0.00035689
Epoch [128/300], Train Loss: 0.000466
Validation Loss: 0.00038938
Epoch [129/300], Train Loss: 0.000451
Validation Loss: 0.00035693
Epoch [130/300], Train Loss: 0.000458
Validation Loss: 0.00037211
Epoch [131/300], Train Loss: 0.000465
Validation Loss: 0.00036301
Epoch [132/300], Train Loss: 0.000460
Validation Loss: 0.00035136
Epoch [133/300], Train Loss: 0.000465
Validation Loss: 0.00037491
Epoch [134/300], Train Loss: 0.000465
Validation Loss: 0.00036049
Epoch [135/300], Train Loss: 0.000455
Validation Loss: 0.00034819
Epoch [136/300], Train Loss: 0.000447
Validation Loss: 0.00037585
Epoch [137/300], Train Loss: 0.000455
Validation Loss: 0.00034782
Epoch [138/300], Train Loss: 0.000447
Validation Loss: 0.00034743
Epoch [139/300], Train Loss: 0.000451
Validation Loss: 0.00035684
Epoch [140/300], Train Loss: 0.000451
Validation Loss: 0.00034983
Epoch [141/300], Train Loss: 0.000461
Validation Loss: 0.00033666
Epoch [142/300], Train Loss: 0.000435
Validation Loss: 0.00034990
Epoch [143/300], Train Loss: 0.000432
Validation Loss: 0.00034614
Epoch [144/300], Train Loss: 0.000439
Validation Loss: 0.00036460
Epoch [145/300], Train Loss: 0.000465
Validation Loss: 0.00034325
Epoch [146/300], Train Loss: 0.000441
Validation Loss: 0.00034913
Epoch [147/300], Train Loss: 0.000440
Validation Loss: 0.00033812
Epoch [148/300], Train Loss: 0.000429
Validation Loss: 0.00033337
Epoch [149/300], Train Loss: 0.000431
Validation Loss: 0.00034373
Epoch [150/300], Train Loss: 0.000429
Validation Loss: 0.00033127
Epoch [151/300], Train Loss: 0.000432
Validation Loss: 0.00033504
Epoch [152/300], Train Loss: 0.000417
Validation Loss: 0.00033369
Epoch [153/300], Train Loss: 0.000426
Validation Loss: 0.00033059
Epoch [154/300], Train Loss: 0.000435
Validation Loss: 0.00032720
Epoch [155/300], Train Loss: 0.000421
Validation Loss: 0.00032696
Epoch [156/300], Train Loss: 0.000435
Validation Loss: 0.00033407
Epoch [157/300], Train Loss: 0.000438
Validation Loss: 0.00033052
Epoch [158/300], Train Loss: 0.000413
Validation Loss: 0.00032608
Epoch [159/300], Train Loss: 0.000413
Validation Loss: 0.00032300
Epoch [160/300], Train Loss: 0.000416
Validation Loss: 0.00035431
Epoch [161/300], Train Loss: 0.000430
Validation Loss: 0.00032816
Epoch [162/300], Train Loss: 0.000404
Validation Loss: 0.00032875
Epoch [163/300], Train Loss: 0.000471
Validation Loss: 0.00039049
Epoch [164/300], Train Loss: 0.000502
Validation Loss: 0.00034423
Epoch [165/300], Train Loss: 0.000419
Validation Loss: 0.00033047
Epoch [166/300], Train Loss: 0.000408
Validation Loss: 0.00032340
Epoch [167/300], Train Loss: 0.000409
Validation Loss: 0.00031874
Epoch [168/300], Train Loss: 0.000411
Validation Loss: 0.00033913
Epoch [169/300], Train Loss: 0.000393
Validation Loss: 0.00031717
Epoch [170/300], Train Loss: 0.000406
Validation Loss: 0.00033716
Epoch [171/300], Train Loss: 0.000408
Validation Loss: 0.00035749
Epoch [172/300], Train Loss: 0.000417
Validation Loss: 0.00032307
Epoch [173/300], Train Loss: 0.000408
Validation Loss: 0.00035188
Epoch [174/300], Train Loss: 0.000406
Validation Loss: 0.00032673
Epoch [175/300], Train Loss: 0.000409
Validation Loss: 0.00032794
Epoch [176/300], Train Loss: 0.000635
Validation Loss: 0.00069002
Epoch [177/300], Train Loss: 0.000469
Validation Loss: 0.00034994
Epoch [178/300], Train Loss: 0.000400
Validation Loss: 0.00032077
Epoch [179/300], Train Loss: 0.000388
Validation Loss: 0.00031851
Early stopping triggered

Evaluating model for: Laptop
Run 25/72 completed in 1124.35 seconds with: {'MAE': np.float32(0.64566976), 'MSE': np.float32(2.662522), 'RMSE': np.float32(1.6317236), 'SAE': np.float32(0.01403821), 'NDE': np.float32(0.20899971)}

Run 26/72: hidden=256, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Laptop
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.003259
Validation Loss: 0.00348649
Epoch [2/300], Train Loss: 0.003234
Validation Loss: 0.00345728
Epoch [3/300], Train Loss: 0.003188
Validation Loss: 0.00341671
Epoch [4/300], Train Loss: 0.003189
Validation Loss: 0.00341236
Epoch [5/300], Train Loss: 0.003377
Validation Loss: 0.00340431
Epoch [6/300], Train Loss: 0.003155
Validation Loss: 0.00339895
Epoch [7/300], Train Loss: 0.003163
Validation Loss: 0.00342671
Epoch [8/300], Train Loss: 0.003147
Validation Loss: 0.00340220
Epoch [9/300], Train Loss: 0.003214
Validation Loss: 0.00338684
Epoch [10/300], Train Loss: 0.003224
Validation Loss: 0.00337589
Epoch [11/300], Train Loss: 0.003133
Validation Loss: 0.00336744
Epoch [12/300], Train Loss: 0.003123
Validation Loss: 0.00337205
Epoch [13/300], Train Loss: 0.003135
Validation Loss: 0.00337406
Epoch [14/300], Train Loss: 0.003191
Validation Loss: 0.00338759
Epoch [15/300], Train Loss: 0.003160
Validation Loss: 0.00335716
Epoch [16/300], Train Loss: 0.003156
Validation Loss: 0.00335175
Epoch [17/300], Train Loss: 0.003160
Validation Loss: 0.00339158
Epoch [18/300], Train Loss: 0.003168
Validation Loss: 0.00334227
Epoch [19/300], Train Loss: 0.003192
Validation Loss: 0.00332305
Epoch [20/300], Train Loss: 0.003199
Validation Loss: 0.00340011
Epoch [21/300], Train Loss: 0.003201
Validation Loss: 0.00335229
Epoch [22/300], Train Loss: 0.003258
Validation Loss: 0.00335835
Epoch [23/300], Train Loss: 0.003240
Validation Loss: 0.00335700
Epoch [24/300], Train Loss: 0.003274
Validation Loss: 0.00332284
Epoch [25/300], Train Loss: 0.003124
Validation Loss: 0.00330558
Epoch [26/300], Train Loss: 0.003099
Validation Loss: 0.00329856
Epoch [27/300], Train Loss: 0.003094
Validation Loss: 0.00330103
Epoch [28/300], Train Loss: 0.003098
Validation Loss: 0.00329985
Epoch [29/300], Train Loss: 0.003080
Validation Loss: 0.00329552
Epoch [30/300], Train Loss: 0.003175
Validation Loss: 0.00332086
Epoch [31/300], Train Loss: 0.003086
Validation Loss: 0.00329822
Epoch [32/300], Train Loss: 0.003109
Validation Loss: 0.00328266
Epoch [33/300], Train Loss: 0.003197
Validation Loss: 0.00329492
Epoch [34/300], Train Loss: 0.003159
Validation Loss: 0.00328795
Epoch [35/300], Train Loss: 0.003102
Validation Loss: 0.00329247
Epoch [36/300], Train Loss: 0.003119
Validation Loss: 0.00328364
Epoch [37/300], Train Loss: 0.003120
Validation Loss: 0.00326556
Epoch [38/300], Train Loss: 0.003137
Validation Loss: 0.00326835
Epoch [39/300], Train Loss: 0.003073
Validation Loss: 0.00327700
Epoch [40/300], Train Loss: 0.003143
Validation Loss: 0.00326489
Epoch [41/300], Train Loss: 0.003077
Validation Loss: 0.00329416
Epoch [42/300], Train Loss: 0.003121
Validation Loss: 0.00326163
Epoch [43/300], Train Loss: 0.003108
Validation Loss: 0.00325355
Epoch [44/300], Train Loss: 0.003128
Validation Loss: 0.00325177
Epoch [45/300], Train Loss: 0.003091
Validation Loss: 0.00325125
Epoch [46/300], Train Loss: 0.003173
Validation Loss: 0.00329981
Epoch [47/300], Train Loss: 0.003114
Validation Loss: 0.00324051
Epoch [48/300], Train Loss: 0.003088
Validation Loss: 0.00323436
Epoch [49/300], Train Loss: 0.003109
Validation Loss: 0.00324497
Epoch [50/300], Train Loss: 0.003114
Validation Loss: 0.00322371
Epoch [51/300], Train Loss: 0.003123
Validation Loss: 0.00322420
Epoch [52/300], Train Loss: 0.003122
Validation Loss: 0.00323037
Epoch [53/300], Train Loss: 0.003034
Validation Loss: 0.00323132
Epoch [54/300], Train Loss: 0.003010
Validation Loss: 0.00322107
Epoch [55/300], Train Loss: 0.003035
Validation Loss: 0.00322158
Epoch [56/300], Train Loss: 0.003005
Validation Loss: 0.00318437
Epoch [57/300], Train Loss: 0.003013
Validation Loss: 0.00325796
Epoch [58/300], Train Loss: 0.003007
Validation Loss: 0.00320111
Epoch [59/300], Train Loss: 0.003059
Validation Loss: 0.00321004
Epoch [60/300], Train Loss: 0.002988
Validation Loss: 0.00318263
Epoch [61/300], Train Loss: 0.003076
Validation Loss: 0.00318524
Epoch [62/300], Train Loss: 0.003029
Validation Loss: 0.00316131
Epoch [63/300], Train Loss: 0.003173
Validation Loss: 0.00314932
Epoch [64/300], Train Loss: 0.003318
Validation Loss: 0.00316753
Epoch [65/300], Train Loss: 0.002982
Validation Loss: 0.00310530
Epoch [66/300], Train Loss: 0.002983
Validation Loss: 0.00307408
Epoch [67/300], Train Loss: 0.003039
Validation Loss: 0.00308960
Epoch [68/300], Train Loss: 0.002958
Validation Loss: 0.00305341
Epoch [69/300], Train Loss: 0.002967
Validation Loss: 0.00304063
Epoch [70/300], Train Loss: 0.002893
Validation Loss: 0.00304822
Epoch [71/300], Train Loss: 0.002847
Validation Loss: 0.00298498
Epoch [72/300], Train Loss: 0.002857
Validation Loss: 0.00294386
Epoch [73/300], Train Loss: 0.002797
Validation Loss: 0.00290812
Epoch [74/300], Train Loss: 0.002841
Validation Loss: 0.00287056
Epoch [75/300], Train Loss: 0.002884
Validation Loss: 0.00302136
Epoch [76/300], Train Loss: 0.002870
Validation Loss: 0.00295052
Epoch [77/300], Train Loss: 0.002792
Validation Loss: 0.00289957
Epoch [78/300], Train Loss: 0.002729
Validation Loss: 0.00284015
Epoch [79/300], Train Loss: 0.002714
Validation Loss: 0.00280304
Epoch [80/300], Train Loss: 0.002679
Validation Loss: 0.00273843
Epoch [81/300], Train Loss: 0.002740
Validation Loss: 0.00277556
Epoch [82/300], Train Loss: 0.002664
Validation Loss: 0.00273167
Epoch [83/300], Train Loss: 0.002606
Validation Loss: 0.00272522
Epoch [84/300], Train Loss: 0.002606
Validation Loss: 0.00271797
Epoch [85/300], Train Loss: 0.002536
Validation Loss: 0.00267095
Epoch [86/300], Train Loss: 0.002572
Validation Loss: 0.00263724
Epoch [87/300], Train Loss: 0.002487
Validation Loss: 0.00257170
Epoch [88/300], Train Loss: 0.002424
Validation Loss: 0.00251528
Epoch [89/300], Train Loss: 0.002351
Validation Loss: 0.00243410
Epoch [90/300], Train Loss: 0.002309
Validation Loss: 0.00237403
Epoch [91/300], Train Loss: 0.002262
Validation Loss: 0.00233740
Epoch [92/300], Train Loss: 0.002202
Validation Loss: 0.00229359
Epoch [93/300], Train Loss: 0.002080
Validation Loss: 0.00224795
Epoch [94/300], Train Loss: 0.002082
Validation Loss: 0.00227832
Epoch [95/300], Train Loss: 0.002097
Validation Loss: 0.00212481
Epoch [96/300], Train Loss: 0.001904
Validation Loss: 0.00220251
Epoch [97/300], Train Loss: 0.001821
Validation Loss: 0.00208345
Epoch [98/300], Train Loss: 0.001631
Validation Loss: 0.00178519
Epoch [99/300], Train Loss: 0.001421
Validation Loss: 0.00143928
Epoch [100/300], Train Loss: 0.001301
Validation Loss: 0.00162241
Epoch [101/300], Train Loss: 0.001227
Validation Loss: 0.00133670
Epoch [102/300], Train Loss: 0.001170
Validation Loss: 0.00129434
Epoch [103/300], Train Loss: 0.001202
Validation Loss: 0.00111703
Epoch [104/300], Train Loss: 0.001120
Validation Loss: 0.00104661
Epoch [105/300], Train Loss: 0.001044
Validation Loss: 0.00099647
Epoch [106/300], Train Loss: 0.000975
Validation Loss: 0.00102306
Epoch [107/300], Train Loss: 0.000955
Validation Loss: 0.00094139
Epoch [108/300], Train Loss: 0.000913
Validation Loss: 0.00088294
Epoch [109/300], Train Loss: 0.000880
Validation Loss: 0.00086450
Epoch [110/300], Train Loss: 0.000850
Validation Loss: 0.00085995
Epoch [111/300], Train Loss: 0.000864
Validation Loss: 0.00080952
Epoch [112/300], Train Loss: 0.000845
Validation Loss: 0.00079277
Epoch [113/300], Train Loss: 0.000840
Validation Loss: 0.00079874
Epoch [114/300], Train Loss: 0.000806
Validation Loss: 0.00078387
Epoch [115/300], Train Loss: 0.000780
Validation Loss: 0.00078812
Epoch [116/300], Train Loss: 0.000751
Validation Loss: 0.00076657
Epoch [117/300], Train Loss: 0.000750
Validation Loss: 0.00071335
Epoch [118/300], Train Loss: 0.000773
Validation Loss: 0.00099960
Epoch [119/300], Train Loss: 0.000770
Validation Loss: 0.00068686
Epoch [120/300], Train Loss: 0.000703
Validation Loss: 0.00067772
Epoch [121/300], Train Loss: 0.000731
Validation Loss: 0.00076640
Epoch [122/300], Train Loss: 0.000729
Validation Loss: 0.00067716
Epoch [123/300], Train Loss: 0.000684
Validation Loss: 0.00064813
Epoch [124/300], Train Loss: 0.000685
Validation Loss: 0.00064277
Epoch [125/300], Train Loss: 0.000669
Validation Loss: 0.00063799
Epoch [126/300], Train Loss: 0.000676
Validation Loss: 0.00065307
Epoch [127/300], Train Loss: 0.000663
Validation Loss: 0.00064874
Epoch [128/300], Train Loss: 0.000661
Validation Loss: 0.00063107
Epoch [129/300], Train Loss: 0.000640
Validation Loss: 0.00061734
Epoch [130/300], Train Loss: 0.000629
Validation Loss: 0.00059591
Epoch [131/300], Train Loss: 0.000637
Validation Loss: 0.00059314
Epoch [132/300], Train Loss: 0.000634
Validation Loss: 0.00059779
Epoch [133/300], Train Loss: 0.000637
Validation Loss: 0.00059057
Epoch [134/300], Train Loss: 0.000626
Validation Loss: 0.00066671
Epoch [135/300], Train Loss: 0.000630
Validation Loss: 0.00057966
Epoch [136/300], Train Loss: 0.000612
Validation Loss: 0.00057639
Epoch [137/300], Train Loss: 0.000604
Validation Loss: 0.00056518
Epoch [138/300], Train Loss: 0.000601
Validation Loss: 0.00064623
Epoch [139/300], Train Loss: 0.000627
Validation Loss: 0.00059139
Epoch [140/300], Train Loss: 0.000592
Validation Loss: 0.00056206
Epoch [141/300], Train Loss: 0.000607
Validation Loss: 0.00055659
Epoch [142/300], Train Loss: 0.000578
Validation Loss: 0.00055565
Epoch [143/300], Train Loss: 0.000578
Validation Loss: 0.00055618
Epoch [144/300], Train Loss: 0.000581
Validation Loss: 0.00053450
Epoch [145/300], Train Loss: 0.000683
Validation Loss: 0.00069423
Epoch [146/300], Train Loss: 0.000628
Validation Loss: 0.00054101
Epoch [147/300], Train Loss: 0.000573
Validation Loss: 0.00052941
Epoch [148/300], Train Loss: 0.000560
Validation Loss: 0.00052497
Epoch [149/300], Train Loss: 0.000553
Validation Loss: 0.00051283
Epoch [150/300], Train Loss: 0.000549
Validation Loss: 0.00052930
Epoch [151/300], Train Loss: 0.000562
Validation Loss: 0.00051314
Epoch [152/300], Train Loss: 0.000542
Validation Loss: 0.00052477
Epoch [153/300], Train Loss: 0.000554
Validation Loss: 0.00050111
Epoch [154/300], Train Loss: 0.000543
Validation Loss: 0.00050025
Epoch [155/300], Train Loss: 0.000535
Validation Loss: 0.00049838
Epoch [156/300], Train Loss: 0.000546
Validation Loss: 0.00050870
Epoch [157/300], Train Loss: 0.000537
Validation Loss: 0.00049092
Epoch [158/300], Train Loss: 0.000532
Validation Loss: 0.00048979
Epoch [159/300], Train Loss: 0.000537
Validation Loss: 0.00048620
Epoch [160/300], Train Loss: 0.000518
Validation Loss: 0.00053296
Epoch [161/300], Train Loss: 0.000547
Validation Loss: 0.00047854
Epoch [162/300], Train Loss: 0.000508
Validation Loss: 0.00048184
Epoch [163/300], Train Loss: 0.000523
Validation Loss: 0.00047510
Epoch [164/300], Train Loss: 0.000518
Validation Loss: 0.00050133
Epoch [165/300], Train Loss: 0.000506
Validation Loss: 0.00047366
Epoch [166/300], Train Loss: 0.000508
Validation Loss: 0.00046805
Epoch [167/300], Train Loss: 0.000505
Validation Loss: 0.00047646
Epoch [168/300], Train Loss: 0.000512
Validation Loss: 0.00049350
Epoch [169/300], Train Loss: 0.000507
Validation Loss: 0.00045891
Epoch [170/300], Train Loss: 0.000489
Validation Loss: 0.00046588
Epoch [171/300], Train Loss: 0.000496
Validation Loss: 0.00047233
Epoch [172/300], Train Loss: 0.000495
Validation Loss: 0.00045766
Epoch [173/300], Train Loss: 0.000502
Validation Loss: 0.00049439
Epoch [174/300], Train Loss: 0.000504
Validation Loss: 0.00046768
Epoch [175/300], Train Loss: 0.000521
Validation Loss: 0.00049588
Epoch [176/300], Train Loss: 0.000493
Validation Loss: 0.00045244
Epoch [177/300], Train Loss: 0.000486
Validation Loss: 0.00045236
Epoch [178/300], Train Loss: 0.000469
Validation Loss: 0.00043948
Epoch [179/300], Train Loss: 0.000469
Validation Loss: 0.00044692
Epoch [180/300], Train Loss: 0.000473
Validation Loss: 0.00044271
Epoch [181/300], Train Loss: 0.000471
Validation Loss: 0.00045962
Epoch [182/300], Train Loss: 0.000466
Validation Loss: 0.00044170
Epoch [183/300], Train Loss: 0.000460
Validation Loss: 0.00048602
Epoch [184/300], Train Loss: 0.000498
Validation Loss: 0.00047839
Epoch [185/300], Train Loss: 0.000490
Validation Loss: 0.00044152
Epoch [186/300], Train Loss: 0.000453
Validation Loss: 0.00042857
Epoch [187/300], Train Loss: 0.000454
Validation Loss: 0.00042816
Epoch [188/300], Train Loss: 0.000454
Validation Loss: 0.00042480
Epoch [189/300], Train Loss: 0.000447
Validation Loss: 0.00042744
Epoch [190/300], Train Loss: 0.000450
Validation Loss: 0.00042334
Epoch [191/300], Train Loss: 0.000446
Validation Loss: 0.00042402
Epoch [192/300], Train Loss: 0.000443
Validation Loss: 0.00041753
Epoch [193/300], Train Loss: 0.000435
Validation Loss: 0.00040991
Epoch [194/300], Train Loss: 0.000449
Validation Loss: 0.00042227
Epoch [195/300], Train Loss: 0.000451
Validation Loss: 0.00041790
Epoch [196/300], Train Loss: 0.000452
Validation Loss: 0.00042552
Epoch [197/300], Train Loss: 0.000447
Validation Loss: 0.00042184
Epoch [198/300], Train Loss: 0.000436
Validation Loss: 0.00040919
Epoch [199/300], Train Loss: 0.000439
Validation Loss: 0.00044768
Epoch [200/300], Train Loss: 0.000432
Validation Loss: 0.00040559
Epoch [201/300], Train Loss: 0.000431
Validation Loss: 0.00045447
Epoch [202/300], Train Loss: 0.000425
Validation Loss: 0.00043669
Epoch [203/300], Train Loss: 0.000421
Validation Loss: 0.00041102
Epoch [204/300], Train Loss: 0.000425
Validation Loss: 0.00040624
Epoch [205/300], Train Loss: 0.000428
Validation Loss: 0.00039777
Epoch [206/300], Train Loss: 0.000416
Validation Loss: 0.00039465
Epoch [207/300], Train Loss: 0.000417
Validation Loss: 0.00040948
Epoch [208/300], Train Loss: 0.000423
Validation Loss: 0.00041339
Epoch [209/300], Train Loss: 0.000433
Validation Loss: 0.00039049
Epoch [210/300], Train Loss: 0.000418
Validation Loss: 0.00040806
Epoch [211/300], Train Loss: 0.000432
Validation Loss: 0.00061169
Epoch [212/300], Train Loss: 0.000490
Validation Loss: 0.00039507
Epoch [213/300], Train Loss: 0.000405
Validation Loss: 0.00038624
Epoch [214/300], Train Loss: 0.000401
Validation Loss: 0.00038715
Epoch [215/300], Train Loss: 0.000404
Validation Loss: 0.00039058
Epoch [216/300], Train Loss: 0.000402
Validation Loss: 0.00040964
Epoch [217/300], Train Loss: 0.000411
Validation Loss: 0.00038686
Epoch [218/300], Train Loss: 0.000420
Validation Loss: 0.00041146
Epoch [219/300], Train Loss: 0.000404
Validation Loss: 0.00039984
Epoch [220/300], Train Loss: 0.000443
Validation Loss: 0.00039863
Epoch [221/300], Train Loss: 0.000404
Validation Loss: 0.00042727
Epoch [222/300], Train Loss: 0.000398
Validation Loss: 0.00037991
Epoch [223/300], Train Loss: 0.000428
Validation Loss: 0.00043850
Epoch [224/300], Train Loss: 0.000418
Validation Loss: 0.00044359
Epoch [225/300], Train Loss: 0.000445
Validation Loss: 0.00040603
Epoch [226/300], Train Loss: 0.000396
Validation Loss: 0.00039180
Epoch [227/300], Train Loss: 0.000390
Validation Loss: 0.00042108
Epoch [228/300], Train Loss: 0.000386
Validation Loss: 0.00036937
Epoch [229/300], Train Loss: 0.000382
Validation Loss: 0.00037597
Epoch [230/300], Train Loss: 0.000387
Validation Loss: 0.00037896
Epoch [231/300], Train Loss: 0.000392
Validation Loss: 0.00036660
Epoch [232/300], Train Loss: 0.000378
Validation Loss: 0.00036944
Epoch [233/300], Train Loss: 0.000378
Validation Loss: 0.00036715
Epoch [234/300], Train Loss: 0.000382
Validation Loss: 0.00037190
Epoch [235/300], Train Loss: 0.000376
Validation Loss: 0.00036372
Epoch [236/300], Train Loss: 0.000380
Validation Loss: 0.00036262
Epoch [237/300], Train Loss: 0.000383
Validation Loss: 0.00036801
Epoch [238/300], Train Loss: 0.000390
Validation Loss: 0.00046209
Epoch [239/300], Train Loss: 0.000457
Validation Loss: 0.00045127
Epoch [240/300], Train Loss: 0.000465
Validation Loss: 0.00043212
Epoch [241/300], Train Loss: 0.000403
Validation Loss: 0.00040097
Epoch [242/300], Train Loss: 0.000392
Validation Loss: 0.00037863
Epoch [243/300], Train Loss: 0.000390
Validation Loss: 0.00041341
Epoch [244/300], Train Loss: 0.000395
Validation Loss: 0.00037295
Epoch [245/300], Train Loss: 0.000385
Validation Loss: 0.00036996
Epoch [246/300], Train Loss: 0.000374
Validation Loss: 0.00036393
Early stopping triggered

Evaluating model for: Laptop
Run 26/72 completed in 1778.56 seconds with: {'MAE': np.float32(0.67155564), 'MSE': np.float32(2.972876), 'RMSE': np.float32(1.724203), 'SAE': np.float32(0.0009996011), 'NDE': np.float32(0.22084494)}

Run 27/72: hidden=256, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Laptop
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.003336
Validation Loss: 0.00348945
Epoch [2/300], Train Loss: 0.003255
Validation Loss: 0.00348545
Epoch [3/300], Train Loss: 0.003223
Validation Loss: 0.00347739
Epoch [4/300], Train Loss: 0.003233
Validation Loss: 0.00346364
Epoch [5/300], Train Loss: 0.003412
Validation Loss: 0.00342239
Epoch [6/300], Train Loss: 0.003162
Validation Loss: 0.00340910
Epoch [7/300], Train Loss: 0.003159
Validation Loss: 0.00342024
Epoch [8/300], Train Loss: 0.003139
Validation Loss: 0.00337058
Epoch [9/300], Train Loss: 0.003193
Validation Loss: 0.00334649
Epoch [10/300], Train Loss: 0.003191
Validation Loss: 0.00338025
Epoch [11/300], Train Loss: 0.003111
Validation Loss: 0.00331579
Epoch [12/300], Train Loss: 0.003104
Validation Loss: 0.00333110
Epoch [13/300], Train Loss: 0.003116
Validation Loss: 0.00334125
Epoch [14/300], Train Loss: 0.003162
Validation Loss: 0.00334642
Epoch [15/300], Train Loss: 0.003130
Validation Loss: 0.00334061
Epoch [16/300], Train Loss: 0.003138
Validation Loss: 0.00329860
Epoch [17/300], Train Loss: 0.003134
Validation Loss: 0.00332393
Epoch [18/300], Train Loss: 0.003130
Validation Loss: 0.00331093
Epoch [19/300], Train Loss: 0.003162
Validation Loss: 0.00327379
Epoch [20/300], Train Loss: 0.003131
Validation Loss: 0.00334135
Epoch [21/300], Train Loss: 0.003179
Validation Loss: 0.00328286
Epoch [22/300], Train Loss: 0.003221
Validation Loss: 0.00331198
Epoch [23/300], Train Loss: 0.003213
Validation Loss: 0.00329575
Epoch [24/300], Train Loss: 0.003240
Validation Loss: 0.00330096
Epoch [25/300], Train Loss: 0.003105
Validation Loss: 0.00327888
Epoch [26/300], Train Loss: 0.003077
Validation Loss: 0.00325802
Epoch [27/300], Train Loss: 0.003074
Validation Loss: 0.00326945
Epoch [28/300], Train Loss: 0.003084
Validation Loss: 0.00327450
Epoch [29/300], Train Loss: 0.003060
Validation Loss: 0.00331563
Epoch [30/300], Train Loss: 0.003171
Validation Loss: 0.00326286
Epoch [31/300], Train Loss: 0.003078
Validation Loss: 0.00329893
Epoch [32/300], Train Loss: 0.003102
Validation Loss: 0.00326703
Epoch [33/300], Train Loss: 0.003174
Validation Loss: 0.00325614
Epoch [34/300], Train Loss: 0.003152
Validation Loss: 0.00327026
Epoch [35/300], Train Loss: 0.003098
Validation Loss: 0.00324729
Epoch [36/300], Train Loss: 0.003099
Validation Loss: 0.00326465
Epoch [37/300], Train Loss: 0.003118
Validation Loss: 0.00324986
Epoch [38/300], Train Loss: 0.003133
Validation Loss: 0.00326049
Epoch [39/300], Train Loss: 0.003066
Validation Loss: 0.00326300
Epoch [40/300], Train Loss: 0.003135
Validation Loss: 0.00325255
Epoch [41/300], Train Loss: 0.003074
Validation Loss: 0.00327503
Epoch [42/300], Train Loss: 0.003103
Validation Loss: 0.00325060
Epoch [43/300], Train Loss: 0.003105
Validation Loss: 0.00324735
Epoch [44/300], Train Loss: 0.003125
Validation Loss: 0.00323742
Epoch [45/300], Train Loss: 0.003088
Validation Loss: 0.00326357
Epoch [46/300], Train Loss: 0.003177
Validation Loss: 0.00325651
Epoch [47/300], Train Loss: 0.003109
Validation Loss: 0.00322447
Epoch [48/300], Train Loss: 0.003084
Validation Loss: 0.00321520
Epoch [49/300], Train Loss: 0.003087
Validation Loss: 0.00316888
Epoch [50/300], Train Loss: 0.003000
Validation Loss: 0.00296642
Epoch [51/300], Train Loss: 0.002759
Validation Loss: 0.00266121
Epoch [52/300], Train Loss: 0.002374
Validation Loss: 0.00274081
Epoch [53/300], Train Loss: 0.002114
Validation Loss: 0.00248843
Epoch [54/300], Train Loss: 0.001804
Validation Loss: 0.00199379
Epoch [55/300], Train Loss: 0.001574
Validation Loss: 0.00178307
Epoch [56/300], Train Loss: 0.001347
Validation Loss: 0.00156165
Epoch [57/300], Train Loss: 0.001206
Validation Loss: 0.00149704
Epoch [58/300], Train Loss: 0.001065
Validation Loss: 0.00138529
Epoch [59/300], Train Loss: 0.001019
Validation Loss: 0.00137249
Epoch [60/300], Train Loss: 0.000920
Validation Loss: 0.00119699
Epoch [61/300], Train Loss: 0.000893
Validation Loss: 0.00086454
Epoch [62/300], Train Loss: 0.000879
Validation Loss: 0.00095872
Epoch [63/300], Train Loss: 0.000763
Validation Loss: 0.00068871
Epoch [64/300], Train Loss: 0.000782
Validation Loss: 0.00079925
Epoch [65/300], Train Loss: 0.000714
Validation Loss: 0.00085182
Epoch [66/300], Train Loss: 0.000743
Validation Loss: 0.00063369
Epoch [67/300], Train Loss: 0.000699
Validation Loss: 0.00062400
Epoch [68/300], Train Loss: 0.000630
Validation Loss: 0.00059031
Epoch [69/300], Train Loss: 0.000610
Validation Loss: 0.00058709
Epoch [70/300], Train Loss: 0.000602
Validation Loss: 0.00057970
Epoch [71/300], Train Loss: 0.000586
Validation Loss: 0.00056070
Epoch [72/300], Train Loss: 0.000598
Validation Loss: 0.00059514
Epoch [73/300], Train Loss: 0.000561
Validation Loss: 0.00052446
Epoch [74/300], Train Loss: 0.000568
Validation Loss: 0.00053790
Epoch [75/300], Train Loss: 0.000538
Validation Loss: 0.00050414
Epoch [76/300], Train Loss: 0.000540
Validation Loss: 0.00054070
Epoch [77/300], Train Loss: 0.000524
Validation Loss: 0.00050236
Epoch [78/300], Train Loss: 0.000508
Validation Loss: 0.00046204
Epoch [79/300], Train Loss: 0.000497
Validation Loss: 0.00044795
Epoch [80/300], Train Loss: 0.000480
Validation Loss: 0.00045068
Epoch [81/300], Train Loss: 0.000559
Validation Loss: 0.00050963
Epoch [82/300], Train Loss: 0.000535
Validation Loss: 0.00050111
Epoch [83/300], Train Loss: 0.000479
Validation Loss: 0.00042978
Epoch [84/300], Train Loss: 0.000461
Validation Loss: 0.00043796
Epoch [85/300], Train Loss: 0.000480
Validation Loss: 0.00054863
Epoch [86/300], Train Loss: 0.000484
Validation Loss: 0.00041668
Epoch [87/300], Train Loss: 0.000441
Validation Loss: 0.00040707
Epoch [88/300], Train Loss: 0.000430
Validation Loss: 0.00039774
Epoch [89/300], Train Loss: 0.000694
Validation Loss: 0.00124292
Epoch [90/300], Train Loss: 0.000575
Validation Loss: 0.00043174
Epoch [91/300], Train Loss: 0.000441
Validation Loss: 0.00040883
Epoch [92/300], Train Loss: 0.000425
Validation Loss: 0.00039191
Epoch [93/300], Train Loss: 0.000413
Validation Loss: 0.00038490
Epoch [94/300], Train Loss: 0.000416
Validation Loss: 0.00038494
Epoch [95/300], Train Loss: 0.000411
Validation Loss: 0.00038329
Epoch [96/300], Train Loss: 0.000399
Validation Loss: 0.00036628
Epoch [97/300], Train Loss: 0.000400
Validation Loss: 0.00038021
Epoch [98/300], Train Loss: 0.000397
Validation Loss: 0.00037205
Epoch [99/300], Train Loss: 0.000397
Validation Loss: 0.00035859
Epoch [100/300], Train Loss: 0.000401
Validation Loss: 0.00035809
Epoch [101/300], Train Loss: 0.000391
Validation Loss: 0.00036852
Epoch [102/300], Train Loss: 0.000390
Validation Loss: 0.00035236
Epoch [103/300], Train Loss: 0.000392
Validation Loss: 0.00037277
Epoch [104/300], Train Loss: 0.000385
Validation Loss: 0.00035094
Epoch [105/300], Train Loss: 0.000390
Validation Loss: 0.00036424
Epoch [106/300], Train Loss: 0.000372
Validation Loss: 0.00036782
Epoch [107/300], Train Loss: 0.000376
Validation Loss: 0.00033828
Epoch [108/300], Train Loss: 0.000369
Validation Loss: 0.00033914
Epoch [109/300], Train Loss: 0.000368
Validation Loss: 0.00034597
Epoch [110/300], Train Loss: 0.000360
Validation Loss: 0.00033370
Epoch [111/300], Train Loss: 0.000484
Validation Loss: 0.00037316
Epoch [112/300], Train Loss: 0.000431
Validation Loss: 0.00033856
Epoch [113/300], Train Loss: 0.000410
Validation Loss: 0.00034141
Epoch [114/300], Train Loss: 0.000392
Validation Loss: 0.00034148
Epoch [115/300], Train Loss: 0.000376
Validation Loss: 0.00032810
Epoch [116/300], Train Loss: 0.000360
Validation Loss: 0.00032244
Epoch [117/300], Train Loss: 0.000361
Validation Loss: 0.00037224
Epoch [118/300], Train Loss: 0.000385
Validation Loss: 0.00035338
Epoch [119/300], Train Loss: 0.000468
Validation Loss: 0.00034272
Epoch [120/300], Train Loss: 0.000361
Validation Loss: 0.00032732
Epoch [121/300], Train Loss: 0.000366
Validation Loss: 0.00033809
Epoch [122/300], Train Loss: 0.000351
Validation Loss: 0.00031929
Epoch [123/300], Train Loss: 0.000349
Validation Loss: 0.00031392
Epoch [124/300], Train Loss: 0.000342
Validation Loss: 0.00031404
Epoch [125/300], Train Loss: 0.000340
Validation Loss: 0.00031591
Epoch [126/300], Train Loss: 0.000341
Validation Loss: 0.00031645
Epoch [127/300], Train Loss: 0.000336
Validation Loss: 0.00031150
Epoch [128/300], Train Loss: 0.000340
Validation Loss: 0.00031301
Epoch [129/300], Train Loss: 0.000332
Validation Loss: 0.00031110
Epoch [130/300], Train Loss: 0.000333
Validation Loss: 0.00030673
Epoch [131/300], Train Loss: 0.000329
Validation Loss: 0.00031645
Epoch [132/300], Train Loss: 0.000334
Validation Loss: 0.00030187
Epoch [133/300], Train Loss: 0.000324
Validation Loss: 0.00029905
Epoch [134/300], Train Loss: 0.000333
Validation Loss: 0.00031756
Epoch [135/300], Train Loss: 0.000333
Validation Loss: 0.00033146
Epoch [136/300], Train Loss: 0.000325
Validation Loss: 0.00029813
Epoch [137/300], Train Loss: 0.000328
Validation Loss: 0.00029646
Epoch [138/300], Train Loss: 0.000322
Validation Loss: 0.00029609
Epoch [139/300], Train Loss: 0.000323
Validation Loss: 0.00029368
Epoch [140/300], Train Loss: 0.000320
Validation Loss: 0.00030330
Epoch [141/300], Train Loss: 0.000322
Validation Loss: 0.00029117
Epoch [142/300], Train Loss: 0.000317
Validation Loss: 0.00029655
Epoch [143/300], Train Loss: 0.000311
Validation Loss: 0.00028660
Epoch [144/300], Train Loss: 0.000312
Validation Loss: 0.00029474
Epoch [145/300], Train Loss: 0.000323
Validation Loss: 0.00032007
Epoch [146/300], Train Loss: 0.000318
Validation Loss: 0.00028758
Epoch [147/300], Train Loss: 0.000309
Validation Loss: 0.00028733
Epoch [148/300], Train Loss: 0.000303
Validation Loss: 0.00027958
Epoch [149/300], Train Loss: 0.000306
Validation Loss: 0.00028107
Epoch [150/300], Train Loss: 0.000304
Validation Loss: 0.00027628
Epoch [151/300], Train Loss: 0.000303
Validation Loss: 0.00029635
Epoch [152/300], Train Loss: 0.000301
Validation Loss: 0.00027446
Epoch [153/300], Train Loss: 0.000299
Validation Loss: 0.00027468
Epoch [154/300], Train Loss: 0.000304
Validation Loss: 0.00027379
Epoch [155/300], Train Loss: 0.000309
Validation Loss: 0.00027658
Epoch [156/300], Train Loss: 0.000305
Validation Loss: 0.00027048
Epoch [157/300], Train Loss: 0.000308
Validation Loss: 0.00030387
Epoch [158/300], Train Loss: 0.000392
Validation Loss: 0.00028705
Epoch [159/300], Train Loss: 0.000307
Validation Loss: 0.00027409
Epoch [160/300], Train Loss: 0.000296
Validation Loss: 0.00027059
Epoch [161/300], Train Loss: 0.000304
Validation Loss: 0.00027119
Epoch [162/300], Train Loss: 0.000290
Validation Loss: 0.00026385
Epoch [163/300], Train Loss: 0.000287
Validation Loss: 0.00028223
Epoch [164/300], Train Loss: 0.000294
Validation Loss: 0.00026618
Epoch [165/300], Train Loss: 0.000283
Validation Loss: 0.00026243
Epoch [166/300], Train Loss: 0.000287
Validation Loss: 0.00026047
Epoch [167/300], Train Loss: 0.000283
Validation Loss: 0.00025983
Epoch [168/300], Train Loss: 0.000288
Validation Loss: 0.00026789
Epoch [169/300], Train Loss: 0.000278
Validation Loss: 0.00025447
Epoch [170/300], Train Loss: 0.000275
Validation Loss: 0.00025418
Epoch [171/300], Train Loss: 0.000277
Validation Loss: 0.00025509
Epoch [172/300], Train Loss: 0.000282
Validation Loss: 0.00027562
Epoch [173/300], Train Loss: 0.000288
Validation Loss: 0.00025217
Epoch [174/300], Train Loss: 0.000292
Validation Loss: 0.00026337
Epoch [175/300], Train Loss: 0.000290
Validation Loss: 0.00025383
Epoch [176/300], Train Loss: 0.000276
Validation Loss: 0.00025033
Epoch [177/300], Train Loss: 0.000272
Validation Loss: 0.00024813
Epoch [178/300], Train Loss: 0.000271
Validation Loss: 0.00024879
Epoch [179/300], Train Loss: 0.000267
Validation Loss: 0.00025254
Epoch [180/300], Train Loss: 0.000269
Validation Loss: 0.00024750
Epoch [181/300], Train Loss: 0.000266
Validation Loss: 0.00024501
Epoch [182/300], Train Loss: 0.000262
Validation Loss: 0.00024304
Epoch [183/300], Train Loss: 0.000264
Validation Loss: 0.00024469
Epoch [184/300], Train Loss: 0.000291
Validation Loss: 0.00024351
Epoch [185/300], Train Loss: 0.000264
Validation Loss: 0.00024158
Epoch [186/300], Train Loss: 0.000258
Validation Loss: 0.00024481
Epoch [187/300], Train Loss: 0.000257
Validation Loss: 0.00024251
Epoch [188/300], Train Loss: 0.000258
Validation Loss: 0.00024658
Epoch [189/300], Train Loss: 0.000257
Validation Loss: 0.00023807
Epoch [190/300], Train Loss: 0.000257
Validation Loss: 0.00023829
Epoch [191/300], Train Loss: 0.000283
Validation Loss: 0.00024117
Epoch [192/300], Train Loss: 0.000283
Validation Loss: 0.00025779
Epoch [193/300], Train Loss: 0.000403
Validation Loss: 0.00032378
Epoch [194/300], Train Loss: 0.000359
Validation Loss: 0.00025868
Epoch [195/300], Train Loss: 0.000351
Validation Loss: 0.00025239
Epoch [196/300], Train Loss: 0.000324
Validation Loss: 0.00025043
Epoch [197/300], Train Loss: 0.000298
Validation Loss: 0.00025202
Epoch [198/300], Train Loss: 0.000266
Validation Loss: 0.00023611
Epoch [199/300], Train Loss: 0.000269
Validation Loss: 0.00023622
Epoch [200/300], Train Loss: 0.000261
Validation Loss: 0.00023738
Epoch [201/300], Train Loss: 0.000263
Validation Loss: 0.00023314
Epoch [202/300], Train Loss: 0.000265
Validation Loss: 0.00025757
Epoch [203/300], Train Loss: 0.000259
Validation Loss: 0.00023109
Epoch [204/300], Train Loss: 0.000253
Validation Loss: 0.00023167
Epoch [205/300], Train Loss: 0.000253
Validation Loss: 0.00023015
Epoch [206/300], Train Loss: 0.000253
Validation Loss: 0.00022890
Epoch [207/300], Train Loss: 0.000261
Validation Loss: 0.00023547
Epoch [208/300], Train Loss: 0.000250
Validation Loss: 0.00022757
Epoch [209/300], Train Loss: 0.000265
Validation Loss: 0.00023037
Epoch [210/300], Train Loss: 0.000255
Validation Loss: 0.00022941
Epoch [211/300], Train Loss: 0.000249
Validation Loss: 0.00022612
Epoch [212/300], Train Loss: 0.000249
Validation Loss: 0.00022558
Epoch [213/300], Train Loss: 0.000246
Validation Loss: 0.00023733
Epoch [214/300], Train Loss: 0.000249
Validation Loss: 0.00022474
Epoch [215/300], Train Loss: 0.000246
Validation Loss: 0.00022419
Epoch [216/300], Train Loss: 0.000244
Validation Loss: 0.00022585
Epoch [217/300], Train Loss: 0.000247
Validation Loss: 0.00023088
Epoch [218/300], Train Loss: 0.000245
Validation Loss: 0.00024220
Epoch [219/300], Train Loss: 0.000245
Validation Loss: 0.00022683
Epoch [220/300], Train Loss: 0.000240
Validation Loss: 0.00022269
Epoch [221/300], Train Loss: 0.000239
Validation Loss: 0.00022582
Epoch [222/300], Train Loss: 0.000240
Validation Loss: 0.00022686
Epoch [223/300], Train Loss: 0.000265
Validation Loss: 0.00022010
Epoch [224/300], Train Loss: 0.000247
Validation Loss: 0.00022175
Epoch [225/300], Train Loss: 0.000257
Validation Loss: 0.00022387
Epoch [226/300], Train Loss: 0.000239
Validation Loss: 0.00022348
Epoch [227/300], Train Loss: 0.000241
Validation Loss: 0.00022156
Epoch [228/300], Train Loss: 0.000240
Validation Loss: 0.00022988
Epoch [229/300], Train Loss: 0.000240
Validation Loss: 0.00023022
Epoch [230/300], Train Loss: 0.000241
Validation Loss: 0.00021841
Epoch [231/300], Train Loss: 0.000244
Validation Loss: 0.00022076
Epoch [232/300], Train Loss: 0.000235
Validation Loss: 0.00021673
Epoch [233/300], Train Loss: 0.000235
Validation Loss: 0.00021770
Epoch [234/300], Train Loss: 0.000235
Validation Loss: 0.00021898
Epoch [235/300], Train Loss: 0.000236
Validation Loss: 0.00021745
Epoch [236/300], Train Loss: 0.000246
Validation Loss: 0.00021582
Epoch [237/300], Train Loss: 0.000234
Validation Loss: 0.00022743
Epoch [238/300], Train Loss: 0.000241
Validation Loss: 0.00021862
Epoch [239/300], Train Loss: 0.000237
Validation Loss: 0.00021902
Epoch [240/300], Train Loss: 0.000231
Validation Loss: 0.00021291
Epoch [241/300], Train Loss: 0.000231
Validation Loss: 0.00021383
Epoch [242/300], Train Loss: 0.000231
Validation Loss: 0.00021451
Epoch [243/300], Train Loss: 0.000235
Validation Loss: 0.00021598
Epoch [244/300], Train Loss: 0.000232
Validation Loss: 0.00021313
Epoch [245/300], Train Loss: 0.000233
Validation Loss: 0.00022067
Epoch [246/300], Train Loss: 0.000231
Validation Loss: 0.00021118
Epoch [247/300], Train Loss: 0.000236
Validation Loss: 0.00021123
Epoch [248/300], Train Loss: 0.000235
Validation Loss: 0.00021077
Epoch [249/300], Train Loss: 0.000231
Validation Loss: 0.00021067
Epoch [250/300], Train Loss: 0.000231
Validation Loss: 0.00021235
Epoch [251/300], Train Loss: 0.000225
Validation Loss: 0.00020983
Epoch [252/300], Train Loss: 0.000242
Validation Loss: 0.00021076
Epoch [253/300], Train Loss: 0.000228
Validation Loss: 0.00021129
Epoch [254/300], Train Loss: 0.000229
Validation Loss: 0.00020953
Epoch [255/300], Train Loss: 0.000232
Validation Loss: 0.00021264
Epoch [256/300], Train Loss: 0.000224
Validation Loss: 0.00021207
Epoch [257/300], Train Loss: 0.000226
Validation Loss: 0.00020634
Epoch [258/300], Train Loss: 0.000224
Validation Loss: 0.00020754
Epoch [259/300], Train Loss: 0.000224
Validation Loss: 0.00021279
Epoch [260/300], Train Loss: 0.000222
Validation Loss: 0.00021412
Epoch [261/300], Train Loss: 0.000253
Validation Loss: 0.00021186
Epoch [262/300], Train Loss: 0.000224
Validation Loss: 0.00020725
Epoch [263/300], Train Loss: 0.000221
Validation Loss: 0.00020569
Epoch [264/300], Train Loss: 0.000222
Validation Loss: 0.00020726
Epoch [265/300], Train Loss: 0.000224
Validation Loss: 0.00020968
Epoch [266/300], Train Loss: 0.000220
Validation Loss: 0.00020429
Epoch [267/300], Train Loss: 0.000223
Validation Loss: 0.00021829
Epoch [268/300], Train Loss: 0.000222
Validation Loss: 0.00020596
Epoch [269/300], Train Loss: 0.000219
Validation Loss: 0.00020207
Epoch [270/300], Train Loss: 0.000215
Validation Loss: 0.00020582
Epoch [271/300], Train Loss: 0.000217
Validation Loss: 0.00020323
Epoch [272/300], Train Loss: 0.000218
Validation Loss: 0.00020313
Epoch [273/300], Train Loss: 0.000218
Validation Loss: 0.00020357
Epoch [274/300], Train Loss: 0.000217
Validation Loss: 0.00020151
Epoch [275/300], Train Loss: 0.000219
Validation Loss: 0.00019952
Epoch [276/300], Train Loss: 0.000218
Validation Loss: 0.00020560
Epoch [277/300], Train Loss: 0.000215
Validation Loss: 0.00019906
Epoch [278/300], Train Loss: 0.000219
Validation Loss: 0.00019890
Epoch [279/300], Train Loss: 0.000213
Validation Loss: 0.00020421
Epoch [280/300], Train Loss: 0.000212
Validation Loss: 0.00020105
Epoch [281/300], Train Loss: 0.000215
Validation Loss: 0.00019737
Epoch [282/300], Train Loss: 0.000218
Validation Loss: 0.00026728
Epoch [283/300], Train Loss: 0.000221
Validation Loss: 0.00019867
Epoch [284/300], Train Loss: 0.000226
Validation Loss: 0.00019585
Epoch [285/300], Train Loss: 0.000229
Validation Loss: 0.00019362
Epoch [286/300], Train Loss: 0.000207
Validation Loss: 0.00019695
Epoch [287/300], Train Loss: 0.000210
Validation Loss: 0.00019363
Epoch [288/300], Train Loss: 0.000216
Validation Loss: 0.00019686
Epoch [289/300], Train Loss: 0.000225
Validation Loss: 0.00024040
Epoch [290/300], Train Loss: 0.000223
Validation Loss: 0.00019676
Epoch [291/300], Train Loss: 0.000222
Validation Loss: 0.00022908
Epoch [292/300], Train Loss: 0.000210
Validation Loss: 0.00019091
Epoch [293/300], Train Loss: 0.000231
Validation Loss: 0.00020288
Epoch [294/300], Train Loss: 0.000206
Validation Loss: 0.00019390
Epoch [295/300], Train Loss: 0.000206
Validation Loss: 0.00019564
Epoch [296/300], Train Loss: 0.000205
Validation Loss: 0.00018974
Epoch [297/300], Train Loss: 0.000201
Validation Loss: 0.00018885
Epoch [298/300], Train Loss: 0.000206
Validation Loss: 0.00018967
Epoch [299/300], Train Loss: 0.000203
Validation Loss: 0.00018851
Epoch [300/300], Train Loss: 0.000201
Validation Loss: 0.00018737

Evaluating model for: Laptop
Run 27/72 completed in 2158.22 seconds with: {'MAE': np.float32(0.43143204), 'MSE': np.float32(1.4443058), 'RMSE': np.float32(1.2017927), 'SAE': np.float32(0.0065393685), 'NDE': np.float32(0.15393189)}

Run 28/72: hidden=256, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Laptop
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.004570
Validation Loss: 0.00357548
Epoch [2/300], Train Loss: 0.003345
Validation Loss: 0.00355416
Epoch [3/300], Train Loss: 0.003297
Validation Loss: 0.00354534
Epoch [4/300], Train Loss: 0.003307
Validation Loss: 0.00353701
Epoch [5/300], Train Loss: 0.003513
Validation Loss: 0.00353657
Epoch [6/300], Train Loss: 0.003267
Validation Loss: 0.00350017
Epoch [7/300], Train Loss: 0.003249
Validation Loss: 0.00349023
Epoch [8/300], Train Loss: 0.003217
Validation Loss: 0.00344783
Epoch [9/300], Train Loss: 0.003263
Validation Loss: 0.00341427
Epoch [10/300], Train Loss: 0.003264
Validation Loss: 0.00340731
Epoch [11/300], Train Loss: 0.003173
Validation Loss: 0.00338865
Epoch [12/300], Train Loss: 0.003157
Validation Loss: 0.00340977
Epoch [13/300], Train Loss: 0.003173
Validation Loss: 0.00338712
Epoch [14/300], Train Loss: 0.003221
Validation Loss: 0.00342150
Epoch [15/300], Train Loss: 0.003196
Validation Loss: 0.00338796
Epoch [16/300], Train Loss: 0.003189
Validation Loss: 0.00336931
Epoch [17/300], Train Loss: 0.003187
Validation Loss: 0.00342577
Epoch [18/300], Train Loss: 0.003205
Validation Loss: 0.00337006
Epoch [19/300], Train Loss: 0.003227
Validation Loss: 0.00336001
Epoch [20/300], Train Loss: 0.003220
Validation Loss: 0.00341786
Epoch [21/300], Train Loss: 0.003231
Validation Loss: 0.00336568
Epoch [22/300], Train Loss: 0.003287
Validation Loss: 0.00336614
Epoch [23/300], Train Loss: 0.003267
Validation Loss: 0.00337367
Epoch [24/300], Train Loss: 0.003301
Validation Loss: 0.00336106
Epoch [25/300], Train Loss: 0.003155
Validation Loss: 0.00333447
Epoch [26/300], Train Loss: 0.003129
Validation Loss: 0.00332881
Epoch [27/300], Train Loss: 0.003124
Validation Loss: 0.00333132
Epoch [28/300], Train Loss: 0.003132
Validation Loss: 0.00333973
Epoch [29/300], Train Loss: 0.003110
Validation Loss: 0.00336335
Epoch [30/300], Train Loss: 0.003219
Validation Loss: 0.00332672
Epoch [31/300], Train Loss: 0.003116
Validation Loss: 0.00333580
Epoch [32/300], Train Loss: 0.003137
Validation Loss: 0.00330835
Epoch [33/300], Train Loss: 0.003215
Validation Loss: 0.00331449
Epoch [34/300], Train Loss: 0.003183
Validation Loss: 0.00330936
Epoch [35/300], Train Loss: 0.003125
Validation Loss: 0.00331343
Epoch [36/300], Train Loss: 0.003147
Validation Loss: 0.00330216
Epoch [37/300], Train Loss: 0.003144
Validation Loss: 0.00328684
Epoch [38/300], Train Loss: 0.003160
Validation Loss: 0.00328027
Epoch [39/300], Train Loss: 0.003094
Validation Loss: 0.00329538
Epoch [40/300], Train Loss: 0.003167
Validation Loss: 0.00328786
Epoch [41/300], Train Loss: 0.003099
Validation Loss: 0.00332128
Epoch [42/300], Train Loss: 0.003141
Validation Loss: 0.00327513
Epoch [43/300], Train Loss: 0.003134
Validation Loss: 0.00327540
Epoch [44/300], Train Loss: 0.003155
Validation Loss: 0.00327386
Epoch [45/300], Train Loss: 0.003116
Validation Loss: 0.00328919
Epoch [46/300], Train Loss: 0.003204
Validation Loss: 0.00330660
Epoch [47/300], Train Loss: 0.003146
Validation Loss: 0.00326256
Epoch [48/300], Train Loss: 0.003117
Validation Loss: 0.00326303
Epoch [49/300], Train Loss: 0.003144
Validation Loss: 0.00327190
Epoch [50/300], Train Loss: 0.003147
Validation Loss: 0.00326026
Epoch [51/300], Train Loss: 0.003168
Validation Loss: 0.00327049
Epoch [52/300], Train Loss: 0.003160
Validation Loss: 0.00327293
Epoch [53/300], Train Loss: 0.003079
Validation Loss: 0.00326965
Epoch [54/300], Train Loss: 0.003068
Validation Loss: 0.00328304
Epoch [55/300], Train Loss: 0.003111
Validation Loss: 0.00326158
Epoch [56/300], Train Loss: 0.003067
Validation Loss: 0.00325316
Epoch [57/300], Train Loss: 0.003073
Validation Loss: 0.00331665
Epoch [58/300], Train Loss: 0.003083
Validation Loss: 0.00326219
Epoch [59/300], Train Loss: 0.003142
Validation Loss: 0.00328866
Epoch [60/300], Train Loss: 0.003069
Validation Loss: 0.00330051
Epoch [61/300], Train Loss: 0.003169
Validation Loss: 0.00326642
Epoch [62/300], Train Loss: 0.003132
Validation Loss: 0.00326950
Epoch [63/300], Train Loss: 0.003304
Validation Loss: 0.00326301
Epoch [64/300], Train Loss: 0.003438
Validation Loss: 0.00325851
Epoch [65/300], Train Loss: 0.003085
Validation Loss: 0.00325905
Epoch [66/300], Train Loss: 0.003122
Validation Loss: 0.00325065
Epoch [67/300], Train Loss: 0.003143
Validation Loss: 0.00325733
Epoch [68/300], Train Loss: 0.003105
Validation Loss: 0.00320465
Epoch [69/300], Train Loss: 0.003109
Validation Loss: 0.00320573
Epoch [70/300], Train Loss: 0.003059
Validation Loss: 0.00320397
Epoch [71/300], Train Loss: 0.003014
Validation Loss: 0.00318059
Epoch [72/300], Train Loss: 0.003054
Validation Loss: 0.00315706
Epoch [73/300], Train Loss: 0.002988
Validation Loss: 0.00314874
Epoch [74/300], Train Loss: 0.002820
Validation Loss: 0.00290486
Epoch [75/300], Train Loss: 0.002495
Validation Loss: 0.00264440
Epoch [76/300], Train Loss: 0.001920
Validation Loss: 0.00198407
Epoch [77/300], Train Loss: 0.001714
Validation Loss: 0.00195031
Epoch [78/300], Train Loss: 0.001556
Validation Loss: 0.00173225
Epoch [79/300], Train Loss: 0.001487
Validation Loss: 0.00190092
Epoch [80/300], Train Loss: 0.002632
Validation Loss: 0.00321524
Epoch [81/300], Train Loss: 0.003129
Validation Loss: 0.00306530
Epoch [82/300], Train Loss: 0.003006
Validation Loss: 0.00315262
Epoch [83/300], Train Loss: 0.002986
Validation Loss: 0.00303098
Epoch [84/300], Train Loss: 0.003031
Validation Loss: 0.00300338
Epoch [85/300], Train Loss: 0.002931
Validation Loss: 0.00299660
Epoch [86/300], Train Loss: 0.003046
Validation Loss: 0.00299641
Epoch [87/300], Train Loss: 0.002921
Validation Loss: 0.00301823
Epoch [88/300], Train Loss: 0.002941
Validation Loss: 0.00298248
Early stopping triggered

Evaluating model for: Laptop
Run 28/72 completed in 731.51 seconds with: {'MAE': np.float32(2.3174038), 'MSE': np.float32(27.027645), 'RMSE': np.float32(5.198812), 'SAE': np.float32(0.03788385), 'NDE': np.float32(0.6658907)}

Run 29/72: hidden=256, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Laptop
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.003783
Validation Loss: 0.00241424
Epoch [2/300], Train Loss: 0.003345
Validation Loss: 0.00216508
Epoch [3/300], Train Loss: 0.003314
Validation Loss: 0.00220902
Epoch [4/300], Train Loss: 0.003257
Validation Loss: 0.00217448
Epoch [5/300], Train Loss: 0.003296
Validation Loss: 0.00215316
Epoch [6/300], Train Loss: 0.003282
Validation Loss: 0.00221150
Epoch [7/300], Train Loss: 0.003290
Validation Loss: 0.00215532
Epoch [8/300], Train Loss: 0.003266
Validation Loss: 0.00214115
Epoch [9/300], Train Loss: 0.003225
Validation Loss: 0.00220994
Epoch [10/300], Train Loss: 0.003201
Validation Loss: 0.00215245
Epoch [11/300], Train Loss: 0.003174
Validation Loss: 0.00211445
Epoch [12/300], Train Loss: 0.003203
Validation Loss: 0.00211891
Epoch [13/300], Train Loss: 0.003214
Validation Loss: 0.00213365
Epoch [14/300], Train Loss: 0.003224
Validation Loss: 0.00211445
Epoch [15/300], Train Loss: 0.003191
Validation Loss: 0.00211009
Epoch [16/300], Train Loss: 0.003225
Validation Loss: 0.00213786
Epoch [17/300], Train Loss: 0.003179
Validation Loss: 0.00219058
Epoch [18/300], Train Loss: 0.003227
Validation Loss: 0.00223171
Epoch [19/300], Train Loss: 0.003187
Validation Loss: 0.00211090
Epoch [20/300], Train Loss: 0.003179
Validation Loss: 0.00211838
Epoch [21/300], Train Loss: 0.003206
Validation Loss: 0.00211087
Epoch [22/300], Train Loss: 0.003232
Validation Loss: 0.00211912
Epoch [23/300], Train Loss: 0.003183
Validation Loss: 0.00218451
Epoch [24/300], Train Loss: 0.003178
Validation Loss: 0.00218860
Epoch [25/300], Train Loss: 0.003204
Validation Loss: 0.00215490
Early stopping triggered

Evaluating model for: Laptop
Run 29/72 completed in 78.63 seconds with: {'MAE': np.float32(2.9887187), 'MSE': np.float32(39.408463), 'RMSE': np.float32(6.277616), 'SAE': np.float32(0.00015641352), 'NDE': np.float32(0.7340167)}

Run 30/72: hidden=256, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Laptop
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.007515
Validation Loss: 0.00249465
Epoch [2/300], Train Loss: 0.003560
Validation Loss: 0.00224974
Epoch [3/300], Train Loss: 0.003451
Validation Loss: 0.00231674
Epoch [4/300], Train Loss: 0.003380
Validation Loss: 0.00225209
Epoch [5/300], Train Loss: 0.003426
Validation Loss: 0.00225954
Epoch [6/300], Train Loss: 0.003427
Validation Loss: 0.00227558
Epoch [7/300], Train Loss: 0.003435
Validation Loss: 0.00223038
Epoch [8/300], Train Loss: 0.003411
Validation Loss: 0.00223176
Epoch [9/300], Train Loss: 0.003371
Validation Loss: 0.00228464
Epoch [10/300], Train Loss: 0.003328
Validation Loss: 0.00220548
Epoch [11/300], Train Loss: 0.003309
Validation Loss: 0.00219264
Epoch [12/300], Train Loss: 0.003322
Validation Loss: 0.00218077
Epoch [13/300], Train Loss: 0.003322
Validation Loss: 0.00218050
Epoch [14/300], Train Loss: 0.003317
Validation Loss: 0.00215814
Epoch [15/300], Train Loss: 0.003267
Validation Loss: 0.00214583
Epoch [16/300], Train Loss: 0.003294
Validation Loss: 0.00216181
Epoch [17/300], Train Loss: 0.003249
Validation Loss: 0.00222420
Epoch [18/300], Train Loss: 0.003296
Validation Loss: 0.00226359
Epoch [19/300], Train Loss: 0.003244
Validation Loss: 0.00215862
Epoch [20/300], Train Loss: 0.003231
Validation Loss: 0.00214592
Epoch [21/300], Train Loss: 0.003278
Validation Loss: 0.00214176
Epoch [22/300], Train Loss: 0.003303
Validation Loss: 0.00213970
Epoch [23/300], Train Loss: 0.003243
Validation Loss: 0.00215435
Epoch [24/300], Train Loss: 0.003234
Validation Loss: 0.00218768
Epoch [25/300], Train Loss: 0.003250
Validation Loss: 0.00222097
Epoch [26/300], Train Loss: 0.003245
Validation Loss: 0.00219889
Epoch [27/300], Train Loss: 0.003271
Validation Loss: 0.00219803
Epoch [28/300], Train Loss: 0.003237
Validation Loss: 0.00220207
Epoch [29/300], Train Loss: 0.003217
Validation Loss: 0.00218318
Epoch [30/300], Train Loss: 0.003215
Validation Loss: 0.00215401
Epoch [31/300], Train Loss: 0.003191
Validation Loss: 0.00219935
Epoch [32/300], Train Loss: 0.003222
Validation Loss: 0.00215199
Early stopping triggered

Evaluating model for: Laptop
Run 30/72 completed in 110.59 seconds with: {'MAE': np.float32(3.0725017), 'MSE': np.float32(39.64455), 'RMSE': np.float32(6.296392), 'SAE': np.float32(0.0462881), 'NDE': np.float32(0.7362121)}

Run 31/72: hidden=256, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Laptop
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.004593
Validation Loss: 0.00240940
Epoch [2/300], Train Loss: 0.003365
Validation Loss: 0.00216271
Epoch [3/300], Train Loss: 0.003323
Validation Loss: 0.00222111
Epoch [4/300], Train Loss: 0.003277
Validation Loss: 0.00218678
Epoch [5/300], Train Loss: 0.003333
Validation Loss: 0.00218858
Epoch [6/300], Train Loss: 0.003336
Validation Loss: 0.00220334
Epoch [7/300], Train Loss: 0.003348
Validation Loss: 0.00217156
Epoch [8/300], Train Loss: 0.003327
Validation Loss: 0.00217578
Epoch [9/300], Train Loss: 0.003289
Validation Loss: 0.00222322
Epoch [10/300], Train Loss: 0.003244
Validation Loss: 0.00214503
Epoch [11/300], Train Loss: 0.003215
Validation Loss: 0.00211714
Epoch [12/300], Train Loss: 0.003224
Validation Loss: 0.00213253
Epoch [13/300], Train Loss: 0.003219
Validation Loss: 0.00216028
Epoch [14/300], Train Loss: 0.003227
Validation Loss: 0.00213591
Epoch [15/300], Train Loss: 0.003185
Validation Loss: 0.00212590
Epoch [16/300], Train Loss: 0.003220
Validation Loss: 0.00213497
Epoch [17/300], Train Loss: 0.003171
Validation Loss: 0.00221280
Epoch [18/300], Train Loss: 0.003222
Validation Loss: 0.00226791
Epoch [19/300], Train Loss: 0.003177
Validation Loss: 0.00214305
Epoch [20/300], Train Loss: 0.003160
Validation Loss: 0.00213443
Epoch [21/300], Train Loss: 0.003206
Validation Loss: 0.00211068
Epoch [22/300], Train Loss: 0.003236
Validation Loss: 0.00212829
Epoch [23/300], Train Loss: 0.003171
Validation Loss: 0.00220834
Epoch [24/300], Train Loss: 0.003165
Validation Loss: 0.00221786
Epoch [25/300], Train Loss: 0.003189
Validation Loss: 0.00226199
Epoch [26/300], Train Loss: 0.003190
Validation Loss: 0.00216528
Epoch [27/300], Train Loss: 0.003221
Validation Loss: 0.00216664
Epoch [28/300], Train Loss: 0.003186
Validation Loss: 0.00216705
Epoch [29/300], Train Loss: 0.003162
Validation Loss: 0.00219473
Epoch [30/300], Train Loss: 0.003162
Validation Loss: 0.00215473
Epoch [31/300], Train Loss: 0.003132
Validation Loss: 0.00220181
Early stopping triggered

Evaluating model for: Laptop
Run 31/72 completed in 113.97 seconds with: {'MAE': np.float32(2.9955354), 'MSE': np.float32(39.336296), 'RMSE': np.float32(6.2718654), 'SAE': np.float32(0.015321612), 'NDE': np.float32(0.73334426)}

Run 32/72: hidden=256, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Laptop
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.007812
Validation Loss: 0.00233109
Epoch [2/300], Train Loss: 0.003530
Validation Loss: 0.00223495
Epoch [3/300], Train Loss: 0.003441
Validation Loss: 0.00233343
Epoch [4/300], Train Loss: 0.003383
Validation Loss: 0.00225607
Epoch [5/300], Train Loss: 0.003431
Validation Loss: 0.00225444
Epoch [6/300], Train Loss: 0.003432
Validation Loss: 0.00228770
Epoch [7/300], Train Loss: 0.003441
Validation Loss: 0.00223395
Epoch [8/300], Train Loss: 0.003419
Validation Loss: 0.00223452
Epoch [9/300], Train Loss: 0.003381
Validation Loss: 0.00229528
Epoch [10/300], Train Loss: 0.003339
Validation Loss: 0.00221406
Epoch [11/300], Train Loss: 0.003320
Validation Loss: 0.00219613
Epoch [12/300], Train Loss: 0.003330
Validation Loss: 0.00217044
Epoch [13/300], Train Loss: 0.003318
Validation Loss: 0.00222822
Epoch [14/300], Train Loss: 0.003310
Validation Loss: 0.00218957
Epoch [15/300], Train Loss: 0.003266
Validation Loss: 0.00215447
Epoch [16/300], Train Loss: 0.003298
Validation Loss: 0.00217283
Epoch [17/300], Train Loss: 0.003256
Validation Loss: 0.00222711
Epoch [18/300], Train Loss: 0.003299
Validation Loss: 0.00226111
Epoch [19/300], Train Loss: 0.003248
Validation Loss: 0.00216137
Epoch [20/300], Train Loss: 0.003235
Validation Loss: 0.00215810
Epoch [21/300], Train Loss: 0.003282
Validation Loss: 0.00214955
Epoch [22/300], Train Loss: 0.003308
Validation Loss: 0.00215706
Epoch [23/300], Train Loss: 0.003245
Validation Loss: 0.00219812
Epoch [24/300], Train Loss: 0.003238
Validation Loss: 0.00223342
Epoch [25/300], Train Loss: 0.003260
Validation Loss: 0.00224136
Epoch [26/300], Train Loss: 0.003251
Validation Loss: 0.00220509
Epoch [27/300], Train Loss: 0.003277
Validation Loss: 0.00220383
Epoch [28/300], Train Loss: 0.003247
Validation Loss: 0.00220074
Epoch [29/300], Train Loss: 0.003232
Validation Loss: 0.00218624
Epoch [30/300], Train Loss: 0.003225
Validation Loss: 0.00216235
Epoch [31/300], Train Loss: 0.003195
Validation Loss: 0.00221488
Early stopping triggered

Evaluating model for: Laptop
Run 32/72 completed in 128.81 seconds with: {'MAE': np.float32(3.04451), 'MSE': np.float32(39.682533), 'RMSE': np.float32(6.2994075), 'SAE': np.float32(0.01504511), 'NDE': np.float32(0.73656464)}

Run 33/72: hidden=256, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Laptop
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.007206
Validation Loss: 0.00470534
Epoch [2/300], Train Loss: 0.003680
Validation Loss: 0.00388447
Epoch [3/300], Train Loss: 0.003402
Validation Loss: 0.00366958
Epoch [4/300], Train Loss: 0.003357
Validation Loss: 0.00365905
Epoch [5/300], Train Loss: 0.003323
Validation Loss: 0.00366360
Epoch [6/300], Train Loss: 0.003393
Validation Loss: 0.00363891
Epoch [7/300], Train Loss: 0.003341
Validation Loss: 0.00363413
Epoch [8/300], Train Loss: 0.003433
Validation Loss: 0.00362048
Epoch [9/300], Train Loss: 0.003299
Validation Loss: 0.00361835
Epoch [10/300], Train Loss: 0.003301
Validation Loss: 0.00360507
Epoch [11/300], Train Loss: 0.003337
Validation Loss: 0.00359938
Epoch [12/300], Train Loss: 0.003275
Validation Loss: 0.00359349
Epoch [13/300], Train Loss: 0.003308
Validation Loss: 0.00361007
Epoch [14/300], Train Loss: 0.003297
Validation Loss: 0.00358464
Epoch [15/300], Train Loss: 0.003292
Validation Loss: 0.00358469
Epoch [16/300], Train Loss: 0.003224
Validation Loss: 0.00357891
Epoch [17/300], Train Loss: 0.003311
Validation Loss: 0.00357801
Epoch [18/300], Train Loss: 0.003252
Validation Loss: 0.00358601
Epoch [19/300], Train Loss: 0.003233
Validation Loss: 0.00357265
Epoch [20/300], Train Loss: 0.003249
Validation Loss: 0.00357388
Epoch [21/300], Train Loss: 0.003227
Validation Loss: 0.00356931
Epoch [22/300], Train Loss: 0.003211
Validation Loss: 0.00356851
Epoch [23/300], Train Loss: 0.003277
Validation Loss: 0.00356719
Epoch [24/300], Train Loss: 0.003248
Validation Loss: 0.00356409
Epoch [25/300], Train Loss: 0.003249
Validation Loss: 0.00357540
Epoch [26/300], Train Loss: 0.003231
Validation Loss: 0.00356111
Epoch [27/300], Train Loss: 0.003260
Validation Loss: 0.00355955
Epoch [28/300], Train Loss: 0.003206
Validation Loss: 0.00355988
Epoch [29/300], Train Loss: 0.003235
Validation Loss: 0.00356365
Epoch [30/300], Train Loss: 0.003336
Validation Loss: 0.00356021
Epoch [31/300], Train Loss: 0.003254
Validation Loss: 0.00355353
Epoch [32/300], Train Loss: 0.003224
Validation Loss: 0.00355390
Epoch [33/300], Train Loss: 0.003328
Validation Loss: 0.00355072
Epoch [34/300], Train Loss: 0.003242
Validation Loss: 0.00355301
Epoch [35/300], Train Loss: 0.003282
Validation Loss: 0.00358529
Epoch [36/300], Train Loss: 0.003194
Validation Loss: 0.00355151
Epoch [37/300], Train Loss: 0.003242
Validation Loss: 0.00357563
Epoch [38/300], Train Loss: 0.003250
Validation Loss: 0.00354680
Epoch [39/300], Train Loss: 0.003165
Validation Loss: 0.00354709
Epoch [40/300], Train Loss: 0.003177
Validation Loss: 0.00355647
Epoch [41/300], Train Loss: 0.003180
Validation Loss: 0.00354507
Epoch [42/300], Train Loss: 0.003212
Validation Loss: 0.00354191
Epoch [43/300], Train Loss: 0.003197
Validation Loss: 0.00354944
Epoch [44/300], Train Loss: 0.003355
Validation Loss: 0.00353685
Epoch [45/300], Train Loss: 0.003223
Validation Loss: 0.00353953
Epoch [46/300], Train Loss: 0.003222
Validation Loss: 0.00353429
Epoch [47/300], Train Loss: 0.003220
Validation Loss: 0.00353664
Epoch [48/300], Train Loss: 0.003251
Validation Loss: 0.00353088
Epoch [49/300], Train Loss: 0.003164
Validation Loss: 0.00353004
Epoch [50/300], Train Loss: 0.003169
Validation Loss: 0.00352776
Epoch [51/300], Train Loss: 0.003191
Validation Loss: 0.00352875
Epoch [52/300], Train Loss: 0.003215
Validation Loss: 0.00352931
Epoch [53/300], Train Loss: 0.003154
Validation Loss: 0.00352232
Epoch [54/300], Train Loss: 0.003157
Validation Loss: 0.00352229
Epoch [55/300], Train Loss: 0.003160
Validation Loss: 0.00352388
Epoch [56/300], Train Loss: 0.003186
Validation Loss: 0.00351687
Epoch [57/300], Train Loss: 0.003169
Validation Loss: 0.00351779
Epoch [58/300], Train Loss: 0.003142
Validation Loss: 0.00351608
Epoch [59/300], Train Loss: 0.003125
Validation Loss: 0.00351084
Epoch [60/300], Train Loss: 0.003494
Validation Loss: 0.00352532
Epoch [61/300], Train Loss: 0.003258
Validation Loss: 0.00354896
Epoch [62/300], Train Loss: 0.003165
Validation Loss: 0.00351756
Epoch [63/300], Train Loss: 0.003217
Validation Loss: 0.00352098
Epoch [64/300], Train Loss: 0.003186
Validation Loss: 0.00352128
Epoch [65/300], Train Loss: 0.003124
Validation Loss: 0.00351201
Epoch [66/300], Train Loss: 0.003193
Validation Loss: 0.00351994
Epoch [67/300], Train Loss: 0.003226
Validation Loss: 0.00351338
Epoch [68/300], Train Loss: 0.003204
Validation Loss: 0.00353050
Epoch [69/300], Train Loss: 0.003149
Validation Loss: 0.00351811
Early stopping triggered

Evaluating model for: Laptop
Run 33/72 completed in 185.05 seconds with: {'MAE': np.float32(2.841078), 'MSE': np.float32(26.977068), 'RMSE': np.float32(5.1939454), 'SAE': np.float32(0.14900658), 'NDE': np.float32(0.70061994)}

Run 34/72: hidden=256, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Laptop
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.005717
Validation Loss: 0.00387206
Epoch [2/300], Train Loss: 0.003453
Validation Loss: 0.00381552
Epoch [3/300], Train Loss: 0.003318
Validation Loss: 0.00365590
Epoch [4/300], Train Loss: 0.003329
Validation Loss: 0.00364453
Epoch [5/300], Train Loss: 0.003305
Validation Loss: 0.00364907
Epoch [6/300], Train Loss: 0.003385
Validation Loss: 0.00363768
Epoch [7/300], Train Loss: 0.003341
Validation Loss: 0.00364277
Epoch [8/300], Train Loss: 0.003439
Validation Loss: 0.00363526
Epoch [9/300], Train Loss: 0.003314
Validation Loss: 0.00363937
Epoch [10/300], Train Loss: 0.003320
Validation Loss: 0.00363133
Epoch [11/300], Train Loss: 0.003364
Validation Loss: 0.00363051
Epoch [12/300], Train Loss: 0.003304
Validation Loss: 0.00362491
Epoch [13/300], Train Loss: 0.003336
Validation Loss: 0.00362675
Epoch [14/300], Train Loss: 0.003327
Validation Loss: 0.00362436
Epoch [15/300], Train Loss: 0.003325
Validation Loss: 0.00361668
Epoch [16/300], Train Loss: 0.003265
Validation Loss: 0.00361906
Epoch [17/300], Train Loss: 0.003337
Validation Loss: 0.00360949
Epoch [18/300], Train Loss: 0.003278
Validation Loss: 0.00362371
Epoch [19/300], Train Loss: 0.003260
Validation Loss: 0.00359538
Epoch [20/300], Train Loss: 0.003271
Validation Loss: 0.00359156
Epoch [21/300], Train Loss: 0.003241
Validation Loss: 0.00357901
Epoch [22/300], Train Loss: 0.003221
Validation Loss: 0.00356971
Epoch [23/300], Train Loss: 0.003283
Validation Loss: 0.00358448
Epoch [24/300], Train Loss: 0.003260
Validation Loss: 0.00356796
Epoch [25/300], Train Loss: 0.003254
Validation Loss: 0.00357197
Epoch [26/300], Train Loss: 0.003237
Validation Loss: 0.00357288
Epoch [27/300], Train Loss: 0.003265
Validation Loss: 0.00356950
Epoch [28/300], Train Loss: 0.003220
Validation Loss: 0.00356455
Epoch [29/300], Train Loss: 0.003250
Validation Loss: 0.00357831
Epoch [30/300], Train Loss: 0.003351
Validation Loss: 0.00356894
Epoch [31/300], Train Loss: 0.003272
Validation Loss: 0.00355955
Epoch [32/300], Train Loss: 0.003234
Validation Loss: 0.00356064
Epoch [33/300], Train Loss: 0.003343
Validation Loss: 0.00355810
Epoch [34/300], Train Loss: 0.003255
Validation Loss: 0.00356156
Epoch [35/300], Train Loss: 0.003293
Validation Loss: 0.00360490
Epoch [36/300], Train Loss: 0.003208
Validation Loss: 0.00355995
Epoch [37/300], Train Loss: 0.003258
Validation Loss: 0.00358790
Epoch [38/300], Train Loss: 0.003268
Validation Loss: 0.00355864
Epoch [39/300], Train Loss: 0.003183
Validation Loss: 0.00355825
Epoch [40/300], Train Loss: 0.003197
Validation Loss: 0.00357308
Epoch [41/300], Train Loss: 0.003199
Validation Loss: 0.00355752
Epoch [42/300], Train Loss: 0.003232
Validation Loss: 0.00355472
Epoch [43/300], Train Loss: 0.003219
Validation Loss: 0.00356479
Epoch [44/300], Train Loss: 0.003378
Validation Loss: 0.00355254
Epoch [45/300], Train Loss: 0.003246
Validation Loss: 0.00355735
Epoch [46/300], Train Loss: 0.003247
Validation Loss: 0.00355168
Epoch [47/300], Train Loss: 0.003245
Validation Loss: 0.00355576
Epoch [48/300], Train Loss: 0.003280
Validation Loss: 0.00355005
Epoch [49/300], Train Loss: 0.003194
Validation Loss: 0.00355052
Epoch [50/300], Train Loss: 0.003196
Validation Loss: 0.00354986
Epoch [51/300], Train Loss: 0.003226
Validation Loss: 0.00355221
Epoch [52/300], Train Loss: 0.003256
Validation Loss: 0.00355373
Epoch [53/300], Train Loss: 0.003185
Validation Loss: 0.00354772
Epoch [54/300], Train Loss: 0.003192
Validation Loss: 0.00354814
Epoch [55/300], Train Loss: 0.003197
Validation Loss: 0.00355248
Epoch [56/300], Train Loss: 0.003220
Validation Loss: 0.00354878
Epoch [57/300], Train Loss: 0.003203
Validation Loss: 0.00354825
Epoch [58/300], Train Loss: 0.003192
Validation Loss: 0.00355492
Epoch [59/300], Train Loss: 0.003172
Validation Loss: 0.00354573
Epoch [60/300], Train Loss: 0.003303
Validation Loss: 0.00355456
Epoch [61/300], Train Loss: 0.003277
Validation Loss: 0.00354553
Epoch [62/300], Train Loss: 0.003190
Validation Loss: 0.00354665
Epoch [63/300], Train Loss: 0.003257
Validation Loss: 0.00355292
Epoch [64/300], Train Loss: 0.003225
Validation Loss: 0.00355209
Epoch [65/300], Train Loss: 0.003166
Validation Loss: 0.00354490
Epoch [66/300], Train Loss: 0.003241
Validation Loss: 0.00355633
Epoch [67/300], Train Loss: 0.003273
Validation Loss: 0.00354498
Epoch [68/300], Train Loss: 0.003260
Validation Loss: 0.00356220
Epoch [69/300], Train Loss: 0.003199
Validation Loss: 0.00354782
Epoch [70/300], Train Loss: 0.003153
Validation Loss: 0.00355126
Epoch [71/300], Train Loss: 0.003197
Validation Loss: 0.00354116
Epoch [72/300], Train Loss: 0.003208
Validation Loss: 0.00355915
Epoch [73/300], Train Loss: 0.003234
Validation Loss: 0.00354341
Epoch [74/300], Train Loss: 0.003185
Validation Loss: 0.00354527
Epoch [75/300], Train Loss: 0.003268
Validation Loss: 0.00354066
Epoch [76/300], Train Loss: 0.003263
Validation Loss: 0.00354400
Epoch [77/300], Train Loss: 0.003197
Validation Loss: 0.00353773
Epoch [78/300], Train Loss: 0.003224
Validation Loss: 0.00353894
Epoch [79/300], Train Loss: 0.003242
Validation Loss: 0.00353906
Epoch [80/300], Train Loss: 0.003200
Validation Loss: 0.00353597
Epoch [81/300], Train Loss: 0.003207
Validation Loss: 0.00354691
Epoch [82/300], Train Loss: 0.003200
Validation Loss: 0.00353497
Epoch [83/300], Train Loss: 0.003210
Validation Loss: 0.00353363
Epoch [84/300], Train Loss: 0.003220
Validation Loss: 0.00353973
Epoch [85/300], Train Loss: 0.003195
Validation Loss: 0.00353956
Epoch [86/300], Train Loss: 0.003316
Validation Loss: 0.00354541
Epoch [87/300], Train Loss: 0.003222
Validation Loss: 0.00353158
Epoch [88/300], Train Loss: 0.003221
Validation Loss: 0.00353112
Epoch [89/300], Train Loss: 0.003165
Validation Loss: 0.00352765
Epoch [90/300], Train Loss: 0.003151
Validation Loss: 0.00353258
Epoch [91/300], Train Loss: 0.003206
Validation Loss: 0.00352476
Epoch [92/300], Train Loss: 0.003151
Validation Loss: 0.00352710
Epoch [93/300], Train Loss: 0.003143
Validation Loss: 0.00352554
Epoch [94/300], Train Loss: 0.003266
Validation Loss: 0.00352668
Epoch [95/300], Train Loss: 0.003321
Validation Loss: 0.00352261
Epoch [96/300], Train Loss: 0.003159
Validation Loss: 0.00353478
Epoch [97/300], Train Loss: 0.003160
Validation Loss: 0.00353050
Epoch [98/300], Train Loss: 0.003264
Validation Loss: 0.00352413
Epoch [99/300], Train Loss: 0.003266
Validation Loss: 0.00352230
Epoch [100/300], Train Loss: 0.003192
Validation Loss: 0.00352356
Epoch [101/300], Train Loss: 0.003171
Validation Loss: 0.00351985
Epoch [102/300], Train Loss: 0.003160
Validation Loss: 0.00351511
Epoch [103/300], Train Loss: 0.003158
Validation Loss: 0.00351741
Epoch [104/300], Train Loss: 0.003245
Validation Loss: 0.00352279
Epoch [105/300], Train Loss: 0.003187
Validation Loss: 0.00351991
Epoch [106/300], Train Loss: 0.003173
Validation Loss: 0.00352431
Epoch [107/300], Train Loss: 0.003171
Validation Loss: 0.00352182
Epoch [108/300], Train Loss: 0.003138
Validation Loss: 0.00351489
Epoch [109/300], Train Loss: 0.003130
Validation Loss: 0.00351330
Epoch [110/300], Train Loss: 0.003146
Validation Loss: 0.00350915
Epoch [111/300], Train Loss: 0.003194
Validation Loss: 0.00350598
Epoch [112/300], Train Loss: 0.003178
Validation Loss: 0.00353106
Epoch [113/300], Train Loss: 0.003229
Validation Loss: 0.00351835
Epoch [114/300], Train Loss: 0.003224
Validation Loss: 0.00351582
Epoch [115/300], Train Loss: 0.003162
Validation Loss: 0.00352125
Epoch [116/300], Train Loss: 0.003213
Validation Loss: 0.00351143
Epoch [117/300], Train Loss: 0.003190
Validation Loss: 0.00350745
Epoch [118/300], Train Loss: 0.003251
Validation Loss: 0.00350297
Epoch [119/300], Train Loss: 0.003185
Validation Loss: 0.00353120
Epoch [120/300], Train Loss: 0.003187
Validation Loss: 0.00352053
Epoch [121/300], Train Loss: 0.003237
Validation Loss: 0.00350987
Epoch [122/300], Train Loss: 0.003172
Validation Loss: 0.00350833
Epoch [123/300], Train Loss: 0.003263
Validation Loss: 0.00350157
Epoch [124/300], Train Loss: 0.003102
Validation Loss: 0.00350543
Epoch [125/300], Train Loss: 0.003133
Validation Loss: 0.00350151
Epoch [126/300], Train Loss: 0.003158
Validation Loss: 0.00349763
Epoch [127/300], Train Loss: 0.003141
Validation Loss: 0.00351242
Epoch [128/300], Train Loss: 0.003165
Validation Loss: 0.00350530
Epoch [129/300], Train Loss: 0.003246
Validation Loss: 0.00349389
Epoch [130/300], Train Loss: 0.003298
Validation Loss: 0.00351251
Epoch [131/300], Train Loss: 0.003303
Validation Loss: 0.00353599
Epoch [132/300], Train Loss: 0.003188
Validation Loss: 0.00353994
Epoch [133/300], Train Loss: 0.003215
Validation Loss: 0.00352054
Epoch [134/300], Train Loss: 0.003166
Validation Loss: 0.00351934
Epoch [135/300], Train Loss: 0.003206
Validation Loss: 0.00351219
Epoch [136/300], Train Loss: 0.003204
Validation Loss: 0.00351257
Epoch [137/300], Train Loss: 0.003185
Validation Loss: 0.00350799
Epoch [138/300], Train Loss: 0.003126
Validation Loss: 0.00350658
Epoch [139/300], Train Loss: 0.003184
Validation Loss: 0.00350363
Early stopping triggered

Evaluating model for: Laptop
Run 34/72 completed in 459.43 seconds with: {'MAE': np.float32(2.7187095), 'MSE': np.float32(23.467333), 'RMSE': np.float32(4.8443093), 'SAE': np.float32(0.10119433), 'NDE': np.float32(0.6534569)}

Run 35/72: hidden=256, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Laptop
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.006620
Validation Loss: 0.00404032
Epoch [2/300], Train Loss: 0.003528
Validation Loss: 0.00381492
Epoch [3/300], Train Loss: 0.003334
Validation Loss: 0.00367631
Epoch [4/300], Train Loss: 0.003339
Validation Loss: 0.00366049
Epoch [5/300], Train Loss: 0.003316
Validation Loss: 0.00365281
Epoch [6/300], Train Loss: 0.003397
Validation Loss: 0.00364643
Epoch [7/300], Train Loss: 0.003352
Validation Loss: 0.00365180
Epoch [8/300], Train Loss: 0.003451
Validation Loss: 0.00364447
Epoch [9/300], Train Loss: 0.003327
Validation Loss: 0.00364945
Epoch [10/300], Train Loss: 0.003335
Validation Loss: 0.00364110
Epoch [11/300], Train Loss: 0.003376
Validation Loss: 0.00364041
Epoch [12/300], Train Loss: 0.003317
Validation Loss: 0.00363498
Epoch [13/300], Train Loss: 0.003352
Validation Loss: 0.00364007
Epoch [14/300], Train Loss: 0.003339
Validation Loss: 0.00362896
Epoch [15/300], Train Loss: 0.003334
Validation Loss: 0.00362342
Epoch [16/300], Train Loss: 0.003268
Validation Loss: 0.00361561
Epoch [17/300], Train Loss: 0.003346
Validation Loss: 0.00360909
Epoch [18/300], Train Loss: 0.003280
Validation Loss: 0.00360858
Epoch [19/300], Train Loss: 0.003250
Validation Loss: 0.00358398
Epoch [20/300], Train Loss: 0.003265
Validation Loss: 0.00357942
Epoch [21/300], Train Loss: 0.003248
Validation Loss: 0.00358355
Epoch [22/300], Train Loss: 0.003228
Validation Loss: 0.00357781
Epoch [23/300], Train Loss: 0.003288
Validation Loss: 0.00359084
Epoch [24/300], Train Loss: 0.003271
Validation Loss: 0.00357923
Epoch [25/300], Train Loss: 0.003265
Validation Loss: 0.00358361
Epoch [26/300], Train Loss: 0.003247
Validation Loss: 0.00358215
Epoch [27/300], Train Loss: 0.003273
Validation Loss: 0.00358239
Epoch [28/300], Train Loss: 0.003231
Validation Loss: 0.00357410
Epoch [29/300], Train Loss: 0.003260
Validation Loss: 0.00359078
Epoch [30/300], Train Loss: 0.003363
Validation Loss: 0.00357989
Epoch [31/300], Train Loss: 0.003282
Validation Loss: 0.00357084
Epoch [32/300], Train Loss: 0.003245
Validation Loss: 0.00357203
Epoch [33/300], Train Loss: 0.003353
Validation Loss: 0.00356975
Epoch [34/300], Train Loss: 0.003265
Validation Loss: 0.00357585
Epoch [35/300], Train Loss: 0.003306
Validation Loss: 0.00361661
Epoch [36/300], Train Loss: 0.003219
Validation Loss: 0.00357273
Epoch [37/300], Train Loss: 0.003268
Validation Loss: 0.00359883
Epoch [38/300], Train Loss: 0.003279
Validation Loss: 0.00356984
Epoch [39/300], Train Loss: 0.003193
Validation Loss: 0.00356996
Epoch [40/300], Train Loss: 0.003209
Validation Loss: 0.00358699
Epoch [41/300], Train Loss: 0.003213
Validation Loss: 0.00356968
Epoch [42/300], Train Loss: 0.003244
Validation Loss: 0.00356713
Epoch [43/300], Train Loss: 0.003231
Validation Loss: 0.00357595
Epoch [44/300], Train Loss: 0.003387
Validation Loss: 0.00356497
Epoch [45/300], Train Loss: 0.003256
Validation Loss: 0.00357001
Epoch [46/300], Train Loss: 0.003260
Validation Loss: 0.00356399
Epoch [47/300], Train Loss: 0.003257
Validation Loss: 0.00356780
Epoch [48/300], Train Loss: 0.003292
Validation Loss: 0.00356269
Epoch [49/300], Train Loss: 0.003207
Validation Loss: 0.00356314
Epoch [50/300], Train Loss: 0.003209
Validation Loss: 0.00356265
Epoch [51/300], Train Loss: 0.003238
Validation Loss: 0.00356381
Epoch [52/300], Train Loss: 0.003267
Validation Loss: 0.00356602
Epoch [53/300], Train Loss: 0.003197
Validation Loss: 0.00356082
Epoch [54/300], Train Loss: 0.003205
Validation Loss: 0.00356077
Epoch [55/300], Train Loss: 0.003208
Validation Loss: 0.00356311
Epoch [56/300], Train Loss: 0.003233
Validation Loss: 0.00356081
Epoch [57/300], Train Loss: 0.003217
Validation Loss: 0.00356033
Epoch [58/300], Train Loss: 0.003202
Validation Loss: 0.00356518
Epoch [59/300], Train Loss: 0.003183
Validation Loss: 0.00355675
Epoch [60/300], Train Loss: 0.003314
Validation Loss: 0.00356480
Epoch [61/300], Train Loss: 0.003290
Validation Loss: 0.00355654
Epoch [62/300], Train Loss: 0.003203
Validation Loss: 0.00355675
Epoch [63/300], Train Loss: 0.003268
Validation Loss: 0.00356193
Epoch [64/300], Train Loss: 0.003236
Validation Loss: 0.00356057
Epoch [65/300], Train Loss: 0.003175
Validation Loss: 0.00355407
Epoch [66/300], Train Loss: 0.003243
Validation Loss: 0.00356254
Epoch [67/300], Train Loss: 0.003285
Validation Loss: 0.00355273
Epoch [68/300], Train Loss: 0.003270
Validation Loss: 0.00356512
Epoch [69/300], Train Loss: 0.003208
Validation Loss: 0.00355927
Epoch [70/300], Train Loss: 0.003165
Validation Loss: 0.00355897
Epoch [71/300], Train Loss: 0.003205
Validation Loss: 0.00354885
Epoch [72/300], Train Loss: 0.003216
Validation Loss: 0.00356303
Epoch [73/300], Train Loss: 0.003243
Validation Loss: 0.00354828
Epoch [74/300], Train Loss: 0.003186
Validation Loss: 0.00355496
Epoch [75/300], Train Loss: 0.003301
Validation Loss: 0.00356372
Epoch [76/300], Train Loss: 0.003289
Validation Loss: 0.00356079
Epoch [77/300], Train Loss: 0.003218
Validation Loss: 0.00355328
Epoch [78/300], Train Loss: 0.003241
Validation Loss: 0.00355000
Epoch [79/300], Train Loss: 0.003257
Validation Loss: 0.00355238
Epoch [80/300], Train Loss: 0.003216
Validation Loss: 0.00354875
Epoch [81/300], Train Loss: 0.003222
Validation Loss: 0.00355683
Epoch [82/300], Train Loss: 0.003217
Validation Loss: 0.00354928
Epoch [83/300], Train Loss: 0.003227
Validation Loss: 0.00354713
Epoch [84/300], Train Loss: 0.003237
Validation Loss: 0.00355072
Epoch [85/300], Train Loss: 0.003214
Validation Loss: 0.00354695
Epoch [86/300], Train Loss: 0.003332
Validation Loss: 0.00355135
Epoch [87/300], Train Loss: 0.003243
Validation Loss: 0.00354562
Epoch [88/300], Train Loss: 0.003233
Validation Loss: 0.00354192
Epoch [89/300], Train Loss: 0.003181
Validation Loss: 0.00354705
Epoch [90/300], Train Loss: 0.003177
Validation Loss: 0.00355319
Epoch [91/300], Train Loss: 0.003232
Validation Loss: 0.00354320
Epoch [92/300], Train Loss: 0.003167
Validation Loss: 0.00354387
Epoch [93/300], Train Loss: 0.003152
Validation Loss: 0.00354061
Epoch [94/300], Train Loss: 0.003283
Validation Loss: 0.00354151
Epoch [95/300], Train Loss: 0.003335
Validation Loss: 0.00353862
Epoch [96/300], Train Loss: 0.003178
Validation Loss: 0.00354710
Epoch [97/300], Train Loss: 0.003176
Validation Loss: 0.00354596
Epoch [98/300], Train Loss: 0.003280
Validation Loss: 0.00353914
Epoch [99/300], Train Loss: 0.003282
Validation Loss: 0.00353676
Epoch [100/300], Train Loss: 0.003213
Validation Loss: 0.00354219
Epoch [101/300], Train Loss: 0.003187
Validation Loss: 0.00353630
Epoch [102/300], Train Loss: 0.003182
Validation Loss: 0.00353400
Epoch [103/300], Train Loss: 0.003177
Validation Loss: 0.00353595
Epoch [104/300], Train Loss: 0.003267
Validation Loss: 0.00353654
Epoch [105/300], Train Loss: 0.003211
Validation Loss: 0.00353857
Epoch [106/300], Train Loss: 0.003182
Validation Loss: 0.00353755
Epoch [107/300], Train Loss: 0.003179
Validation Loss: 0.00353336
Epoch [108/300], Train Loss: 0.003153
Validation Loss: 0.00353494
Epoch [109/300], Train Loss: 0.003141
Validation Loss: 0.00353046
Epoch [110/300], Train Loss: 0.003179
Validation Loss: 0.00353689
Epoch [111/300], Train Loss: 0.003217
Validation Loss: 0.00353595
Epoch [112/300], Train Loss: 0.003188
Validation Loss: 0.00353880
Epoch [113/300], Train Loss: 0.003235
Validation Loss: 0.00352887
Epoch [114/300], Train Loss: 0.003238
Validation Loss: 0.00353783
Epoch [115/300], Train Loss: 0.003190
Validation Loss: 0.00355485
Epoch [116/300], Train Loss: 0.003243
Validation Loss: 0.00353803
Epoch [117/300], Train Loss: 0.003217
Validation Loss: 0.00353035
Epoch [118/300], Train Loss: 0.003281
Validation Loss: 0.00352853
Epoch [119/300], Train Loss: 0.003216
Validation Loss: 0.00353611
Epoch [120/300], Train Loss: 0.003197
Validation Loss: 0.00353447
Epoch [121/300], Train Loss: 0.003257
Validation Loss: 0.00352380
Epoch [122/300], Train Loss: 0.003181
Validation Loss: 0.00353379
Epoch [123/300], Train Loss: 0.003278
Validation Loss: 0.00352231
Epoch [124/300], Train Loss: 0.003129
Validation Loss: 0.00353487
Epoch [125/300], Train Loss: 0.003174
Validation Loss: 0.00353182
Epoch [126/300], Train Loss: 0.003193
Validation Loss: 0.00352511
Epoch [127/300], Train Loss: 0.003178
Validation Loss: 0.00352398
Epoch [128/300], Train Loss: 0.003190
Validation Loss: 0.00353308
Epoch [129/300], Train Loss: 0.003284
Validation Loss: 0.00352156
Epoch [130/300], Train Loss: 0.003327
Validation Loss: 0.00352687
Epoch [131/300], Train Loss: 0.003296
Validation Loss: 0.00353437
Epoch [132/300], Train Loss: 0.003162
Validation Loss: 0.00352528
Epoch [133/300], Train Loss: 0.003224
Validation Loss: 0.00352843
Epoch [134/300], Train Loss: 0.003166
Validation Loss: 0.00353156
Epoch [135/300], Train Loss: 0.003238
Validation Loss: 0.00354805
Epoch [136/300], Train Loss: 0.003236
Validation Loss: 0.00354189
Epoch [137/300], Train Loss: 0.003211
Validation Loss: 0.00352775
Epoch [138/300], Train Loss: 0.003136
Validation Loss: 0.00352134
Epoch [139/300], Train Loss: 0.003187
Validation Loss: 0.00351702
Epoch [140/300], Train Loss: 0.003232
Validation Loss: 0.00351773
Epoch [141/300], Train Loss: 0.003133
Validation Loss: 0.00352231
Epoch [142/300], Train Loss: 0.003194
Validation Loss: 0.00352515
Epoch [143/300], Train Loss: 0.003152
Validation Loss: 0.00352427
Epoch [144/300], Train Loss: 0.003186
Validation Loss: 0.00352473
Epoch [145/300], Train Loss: 0.003129
Validation Loss: 0.00350897
Epoch [146/300], Train Loss: 0.003151
Validation Loss: 0.00351448
Epoch [147/300], Train Loss: 0.003178
Validation Loss: 0.00352312
Epoch [148/300], Train Loss: 0.003137
Validation Loss: 0.00351184
Epoch [149/300], Train Loss: 0.003251
Validation Loss: 0.00353251
Epoch [150/300], Train Loss: 0.003154
Validation Loss: 0.00353170
Epoch [151/300], Train Loss: 0.003188
Validation Loss: 0.00349979
Epoch [152/300], Train Loss: 0.003109
Validation Loss: 0.00351754
Epoch [153/300], Train Loss: 0.003176
Validation Loss: 0.00351611
Epoch [154/300], Train Loss: 0.003183
Validation Loss: 0.00350287
Epoch [155/300], Train Loss: 0.003111
Validation Loss: 0.00351654
Epoch [156/300], Train Loss: 0.003199
Validation Loss: 0.00350594
Epoch [157/300], Train Loss: 0.003153
Validation Loss: 0.00351973
Epoch [158/300], Train Loss: 0.003184
Validation Loss: 0.00350313
Epoch [159/300], Train Loss: 0.003193
Validation Loss: 0.00350716
Epoch [160/300], Train Loss: 0.003182
Validation Loss: 0.00350210
Epoch [161/300], Train Loss: 0.003175
Validation Loss: 0.00352191
Early stopping triggered

Evaluating model for: Laptop
Run 35/72 completed in 609.06 seconds with: {'MAE': np.float32(2.6275437), 'MSE': np.float32(23.996258), 'RMSE': np.float32(4.8985977), 'SAE': np.float32(0.06519198), 'NDE': np.float32(0.66077995)}

Run 36/72: hidden=256, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Laptop
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.003297
Validation Loss: 0.00363288
Epoch [2/300], Train Loss: 0.003277
Validation Loss: 0.00361848
Epoch [3/300], Train Loss: 0.003253
Validation Loss: 0.00362403
Epoch [4/300], Train Loss: 0.003275
Validation Loss: 0.00362120
Epoch [5/300], Train Loss: 0.003266
Validation Loss: 0.00362356
Epoch [6/300], Train Loss: 0.003349
Validation Loss: 0.00361832
Epoch [7/300], Train Loss: 0.003309
Validation Loss: 0.00362240
Epoch [8/300], Train Loss: 0.003406
Validation Loss: 0.00361856
Epoch [9/300], Train Loss: 0.003283
Validation Loss: 0.00362475
Epoch [10/300], Train Loss: 0.003291
Validation Loss: 0.00361814
Epoch [11/300], Train Loss: 0.003336
Validation Loss: 0.00361859
Epoch [12/300], Train Loss: 0.003278
Validation Loss: 0.00361456
Epoch [13/300], Train Loss: 0.003312
Validation Loss: 0.00362057
Epoch [14/300], Train Loss: 0.003305
Validation Loss: 0.00362051
Epoch [15/300], Train Loss: 0.003304
Validation Loss: 0.00361136
Epoch [16/300], Train Loss: 0.003244
Validation Loss: 0.00361460
Epoch [17/300], Train Loss: 0.003310
Validation Loss: 0.00359733
Epoch [18/300], Train Loss: 0.003240
Validation Loss: 0.00358645
Epoch [19/300], Train Loss: 0.003206
Validation Loss: 0.00356583
Epoch [20/300], Train Loss: 0.003216
Validation Loss: 0.00356017
Epoch [21/300], Train Loss: 0.003201
Validation Loss: 0.00356041
Epoch [22/300], Train Loss: 0.003186
Validation Loss: 0.00355517
Epoch [23/300], Train Loss: 0.003241
Validation Loss: 0.00355691
Epoch [24/300], Train Loss: 0.003215
Validation Loss: 0.00355029
Epoch [25/300], Train Loss: 0.003218
Validation Loss: 0.00356049
Epoch [26/300], Train Loss: 0.003198
Validation Loss: 0.00354996
Epoch [27/300], Train Loss: 0.003224
Validation Loss: 0.00354630
Epoch [28/300], Train Loss: 0.003172
Validation Loss: 0.00354650
Epoch [29/300], Train Loss: 0.003205
Validation Loss: 0.00354989
Epoch [30/300], Train Loss: 0.003306
Validation Loss: 0.00354598
Epoch [31/300], Train Loss: 0.003218
Validation Loss: 0.00354567
Epoch [32/300], Train Loss: 0.003198
Validation Loss: 0.00354031
Epoch [33/300], Train Loss: 0.003306
Validation Loss: 0.00354013
Epoch [34/300], Train Loss: 0.003213
Validation Loss: 0.00353663
Epoch [35/300], Train Loss: 0.003262
Validation Loss: 0.00355254
Epoch [36/300], Train Loss: 0.003172
Validation Loss: 0.00354005
Epoch [37/300], Train Loss: 0.003226
Validation Loss: 0.00354287
Epoch [38/300], Train Loss: 0.003214
Validation Loss: 0.00354909
Epoch [39/300], Train Loss: 0.003144
Validation Loss: 0.00353438
Epoch [40/300], Train Loss: 0.003164
Validation Loss: 0.00353929
Epoch [41/300], Train Loss: 0.003173
Validation Loss: 0.00354593
Epoch [42/300], Train Loss: 0.003198
Validation Loss: 0.00353289
Epoch [43/300], Train Loss: 0.003185
Validation Loss: 0.00353584
Epoch [44/300], Train Loss: 0.003330
Validation Loss: 0.00353606
Epoch [45/300], Train Loss: 0.003211
Validation Loss: 0.00353768
Epoch [46/300], Train Loss: 0.003212
Validation Loss: 0.00353291
Epoch [47/300], Train Loss: 0.003213
Validation Loss: 0.00353091
Epoch [48/300], Train Loss: 0.003249
Validation Loss: 0.00353161
Epoch [49/300], Train Loss: 0.003157
Validation Loss: 0.00352715
Epoch [50/300], Train Loss: 0.003157
Validation Loss: 0.00352736
Epoch [51/300], Train Loss: 0.003184
Validation Loss: 0.00352303
Epoch [52/300], Train Loss: 0.003219
Validation Loss: 0.00352267
Epoch [53/300], Train Loss: 0.003147
Validation Loss: 0.00352190
Epoch [54/300], Train Loss: 0.003156
Validation Loss: 0.00352821
Epoch [55/300], Train Loss: 0.003159
Validation Loss: 0.00351515
Epoch [56/300], Train Loss: 0.003184
Validation Loss: 0.00352012
Epoch [57/300], Train Loss: 0.003171
Validation Loss: 0.00351840
Epoch [58/300], Train Loss: 0.003156
Validation Loss: 0.00351380
Epoch [59/300], Train Loss: 0.003139
Validation Loss: 0.00351207
Epoch [60/300], Train Loss: 0.003268
Validation Loss: 0.00350772
Epoch [61/300], Train Loss: 0.003243
Validation Loss: 0.00351993
Epoch [62/300], Train Loss: 0.003153
Validation Loss: 0.00351290
Epoch [63/300], Train Loss: 0.003221
Validation Loss: 0.00351799
Epoch [64/300], Train Loss: 0.003188
Validation Loss: 0.00351415
Epoch [65/300], Train Loss: 0.003129
Validation Loss: 0.00351374
Epoch [66/300], Train Loss: 0.003205
Validation Loss: 0.00350872
Epoch [67/300], Train Loss: 0.003236
Validation Loss: 0.00351075
Epoch [68/300], Train Loss: 0.003238
Validation Loss: 0.00353124
Epoch [69/300], Train Loss: 0.003155
Validation Loss: 0.00353089
Epoch [70/300], Train Loss: 0.003121
Validation Loss: 0.00352242
Early stopping triggered

Evaluating model for: Laptop
Run 36/72 completed in 334.84 seconds with: {'MAE': np.float32(2.6777186), 'MSE': np.float32(24.543837), 'RMSE': np.float32(4.9541736), 'SAE': np.float32(0.110349536), 'NDE': np.float32(0.66827667)}

Run 37/72: hidden=256, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Laptop
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.006589
Validation Loss: 0.00758322
Epoch [2/300], Train Loss: 0.004406
Validation Loss: 0.00547923
Epoch [3/300], Train Loss: 0.003389
Validation Loss: 0.00446233
Epoch [4/300], Train Loss: 0.003243
Validation Loss: 0.00434241
Epoch [5/300], Train Loss: 0.003270
Validation Loss: 0.00437504
Epoch [6/300], Train Loss: 0.003230
Validation Loss: 0.00451627
Epoch [7/300], Train Loss: 0.003107
Validation Loss: 0.00455011
Epoch [8/300], Train Loss: 0.003131
Validation Loss: 0.00450190
Epoch [9/300], Train Loss: 0.003122
Validation Loss: 0.00445749
Epoch [10/300], Train Loss: 0.003113
Validation Loss: 0.00444298
Epoch [11/300], Train Loss: 0.003108
Validation Loss: 0.00445344
Epoch [12/300], Train Loss: 0.003165
Validation Loss: 0.00448168
Epoch [13/300], Train Loss: 0.003134
Validation Loss: 0.00450194
Epoch [14/300], Train Loss: 0.003113
Validation Loss: 0.00445638
Early stopping triggered

Evaluating model for: Laptop
Run 37/72 completed in 20.22 seconds with: {'MAE': np.float32(2.475364), 'MSE': np.float32(30.445028), 'RMSE': np.float32(5.517701), 'SAE': np.float32(0.07461482), 'NDE': np.float32(0.6768254)}

Run 38/72: hidden=256, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Laptop
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.009705
Validation Loss: 0.01044386
Epoch [2/300], Train Loss: 0.006249
Validation Loss: 0.00704858
Epoch [3/300], Train Loss: 0.004037
Validation Loss: 0.00481538
Epoch [4/300], Train Loss: 0.003245
Validation Loss: 0.00437459
Epoch [5/300], Train Loss: 0.003379
Validation Loss: 0.00437917
Epoch [6/300], Train Loss: 0.003270
Validation Loss: 0.00459699
Epoch [7/300], Train Loss: 0.003147
Validation Loss: 0.00461966
Epoch [8/300], Train Loss: 0.003161
Validation Loss: 0.00451170
Epoch [9/300], Train Loss: 0.003150
Validation Loss: 0.00445749
Epoch [10/300], Train Loss: 0.003141
Validation Loss: 0.00446813
Epoch [11/300], Train Loss: 0.003136
Validation Loss: 0.00449819
Epoch [12/300], Train Loss: 0.003196
Validation Loss: 0.00452140
Epoch [13/300], Train Loss: 0.003166
Validation Loss: 0.00452707
Epoch [14/300], Train Loss: 0.003144
Validation Loss: 0.00447601
Early stopping triggered

Evaluating model for: Laptop
Run 38/72 completed in 23.21 seconds with: {'MAE': np.float32(2.5066912), 'MSE': np.float32(30.730476), 'RMSE': np.float32(5.5435076), 'SAE': np.float32(0.06902915), 'NDE': np.float32(0.6799909)}

Run 39/72: hidden=256, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Laptop
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.003216
Validation Loss: 0.00435328
Epoch [2/300], Train Loss: 0.003131
Validation Loss: 0.00438187
Epoch [3/300], Train Loss: 0.003174
Validation Loss: 0.00450284
Epoch [4/300], Train Loss: 0.003162
Validation Loss: 0.00447790
Epoch [5/300], Train Loss: 0.003117
Validation Loss: 0.00440302
Epoch [6/300], Train Loss: 0.003176
Validation Loss: 0.00441749
Epoch [7/300], Train Loss: 0.003064
Validation Loss: 0.00441845
Epoch [8/300], Train Loss: 0.003084
Validation Loss: 0.00444809
Epoch [9/300], Train Loss: 0.003086
Validation Loss: 0.00444845
Epoch [10/300], Train Loss: 0.003075
Validation Loss: 0.00441389
Epoch [11/300], Train Loss: 0.003072
Validation Loss: 0.00441953
Early stopping triggered

Evaluating model for: Laptop
Run 39/72 completed in 20.73 seconds with: {'MAE': np.float32(2.4842064), 'MSE': np.float32(30.230885), 'RMSE': np.float32(5.498262), 'SAE': np.float32(0.06586235), 'NDE': np.float32(0.67444086)}

Run 40/72: hidden=256, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Laptop
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.006832
Validation Loss: 0.00772907
Epoch [2/300], Train Loss: 0.004443
Validation Loss: 0.00544159
Epoch [3/300], Train Loss: 0.003338
Validation Loss: 0.00437878
Epoch [4/300], Train Loss: 0.003278
Validation Loss: 0.00433599
Epoch [5/300], Train Loss: 0.003209
Validation Loss: 0.00447117
Epoch [6/300], Train Loss: 0.003213
Validation Loss: 0.00459049
Epoch [7/300], Train Loss: 0.003105
Validation Loss: 0.00450012
Epoch [8/300], Train Loss: 0.003119
Validation Loss: 0.00443506
Epoch [9/300], Train Loss: 0.003117
Validation Loss: 0.00444318
Epoch [10/300], Train Loss: 0.003106
Validation Loss: 0.00446927
Epoch [11/300], Train Loss: 0.003105
Validation Loss: 0.00447525
Epoch [12/300], Train Loss: 0.003166
Validation Loss: 0.00448265
Epoch [13/300], Train Loss: 0.003138
Validation Loss: 0.00449775
Epoch [14/300], Train Loss: 0.003119
Validation Loss: 0.00446094
Early stopping triggered

Evaluating model for: Laptop
Run 40/72 completed in 33.73 seconds with: {'MAE': np.float32(2.4736795), 'MSE': np.float32(30.554817), 'RMSE': np.float32(5.5276413), 'SAE': np.float32(0.070281506), 'NDE': np.float32(0.6780444)}

Run 41/72: hidden=256, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Laptop
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.005100
Validation Loss: 0.00513122
Epoch [2/300], Train Loss: 0.003399
Validation Loss: 0.00421907
Epoch [3/300], Train Loss: 0.003256
Validation Loss: 0.00424449
Epoch [4/300], Train Loss: 0.003244
Validation Loss: 0.00418101
Epoch [5/300], Train Loss: 0.003217
Validation Loss: 0.00420716
Epoch [6/300], Train Loss: 0.003176
Validation Loss: 0.00421695
Epoch [7/300], Train Loss: 0.003141
Validation Loss: 0.00418737
Epoch [8/300], Train Loss: 0.003205
Validation Loss: 0.00416588
Epoch [9/300], Train Loss: 0.003190
Validation Loss: 0.00415147
Epoch [10/300], Train Loss: 0.003227
Validation Loss: 0.00416381
Epoch [11/300], Train Loss: 0.003164
Validation Loss: 0.00415041
Epoch [12/300], Train Loss: 0.003136
Validation Loss: 0.00414247
Epoch [13/300], Train Loss: 0.003064
Validation Loss: 0.00413269
Epoch [14/300], Train Loss: 0.003095
Validation Loss: 0.00415368
Epoch [15/300], Train Loss: 0.003065
Validation Loss: 0.00414308
Epoch [16/300], Train Loss: 0.003147
Validation Loss: 0.00412364
Epoch [17/300], Train Loss: 0.003041
Validation Loss: 0.00411194
Epoch [18/300], Train Loss: 0.003103
Validation Loss: 0.00411151
Epoch [19/300], Train Loss: 0.003125
Validation Loss: 0.00411843
Epoch [20/300], Train Loss: 0.003034
Validation Loss: 0.00409340
Epoch [21/300], Train Loss: 0.003172
Validation Loss: 0.00409560
Epoch [22/300], Train Loss: 0.003082
Validation Loss: 0.00408512
Epoch [23/300], Train Loss: 0.003177
Validation Loss: 0.00408698
Epoch [24/300], Train Loss: 0.003171
Validation Loss: 0.00407838
Epoch [25/300], Train Loss: 0.003115
Validation Loss: 0.00406482
Epoch [26/300], Train Loss: 0.003025
Validation Loss: 0.00407637
Epoch [27/300], Train Loss: 0.003055
Validation Loss: 0.00407270
Epoch [28/300], Train Loss: 0.003022
Validation Loss: 0.00405546
Epoch [29/300], Train Loss: 0.003115
Validation Loss: 0.00406509
Epoch [30/300], Train Loss: 0.003094
Validation Loss: 0.00405031
Epoch [31/300], Train Loss: 0.003066
Validation Loss: 0.00406852
Epoch [32/300], Train Loss: 0.003095
Validation Loss: 0.00405347
Epoch [33/300], Train Loss: 0.003071
Validation Loss: 0.00405052
Epoch [34/300], Train Loss: 0.003058
Validation Loss: 0.00404408
Epoch [35/300], Train Loss: 0.003042
Validation Loss: 0.00405727
Epoch [36/300], Train Loss: 0.003094
Validation Loss: 0.00404980
Epoch [37/300], Train Loss: 0.003032
Validation Loss: 0.00403851
Epoch [38/300], Train Loss: 0.003018
Validation Loss: 0.00406011
Epoch [39/300], Train Loss: 0.002999
Validation Loss: 0.00404366
Epoch [40/300], Train Loss: 0.003137
Validation Loss: 0.00405067
Epoch [41/300], Train Loss: 0.003074
Validation Loss: 0.00403562
Epoch [42/300], Train Loss: 0.003085
Validation Loss: 0.00404635
Epoch [43/300], Train Loss: 0.003175
Validation Loss: 0.00404534
Epoch [44/300], Train Loss: 0.003138
Validation Loss: 0.00403330
Epoch [45/300], Train Loss: 0.002997
Validation Loss: 0.00404220
Epoch [46/300], Train Loss: 0.003078
Validation Loss: 0.00403451
Epoch [47/300], Train Loss: 0.002969
Validation Loss: 0.00403137
Epoch [48/300], Train Loss: 0.003068
Validation Loss: 0.00405055
Epoch [49/300], Train Loss: 0.002998
Validation Loss: 0.00403643
Epoch [50/300], Train Loss: 0.003034
Validation Loss: 0.00403383
Epoch [51/300], Train Loss: 0.003116
Validation Loss: 0.00405234
Epoch [52/300], Train Loss: 0.003099
Validation Loss: 0.00402664
Epoch [53/300], Train Loss: 0.003116
Validation Loss: 0.00403443
Epoch [54/300], Train Loss: 0.003023
Validation Loss: 0.00402768
Epoch [55/300], Train Loss: 0.003041
Validation Loss: 0.00403014
Epoch [56/300], Train Loss: 0.003059
Validation Loss: 0.00404172
Epoch [57/300], Train Loss: 0.003084
Validation Loss: 0.00402810
Epoch [58/300], Train Loss: 0.003086
Validation Loss: 0.00402531
Epoch [59/300], Train Loss: 0.003047
Validation Loss: 0.00402639
Epoch [60/300], Train Loss: 0.003110
Validation Loss: 0.00403435
Epoch [61/300], Train Loss: 0.003093
Validation Loss: 0.00402105
Epoch [62/300], Train Loss: 0.003026
Validation Loss: 0.00402068
Epoch [63/300], Train Loss: 0.003025
Validation Loss: 0.00403099
Epoch [64/300], Train Loss: 0.003068
Validation Loss: 0.00402828
Epoch [65/300], Train Loss: 0.003092
Validation Loss: 0.00401873
Epoch [66/300], Train Loss: 0.003112
Validation Loss: 0.00402206
Epoch [67/300], Train Loss: 0.003052
Validation Loss: 0.00401510
Epoch [68/300], Train Loss: 0.002961
Validation Loss: 0.00401824
Epoch [69/300], Train Loss: 0.003058
Validation Loss: 0.00403038
Epoch [70/300], Train Loss: 0.002976
Validation Loss: 0.00401816
Epoch [71/300], Train Loss: 0.003050
Validation Loss: 0.00401479
Epoch [72/300], Train Loss: 0.003048
Validation Loss: 0.00401407
Epoch [73/300], Train Loss: 0.003104
Validation Loss: 0.00402026
Epoch [74/300], Train Loss: 0.003046
Validation Loss: 0.00401596
Epoch [75/300], Train Loss: 0.003037
Validation Loss: 0.00401183
Epoch [76/300], Train Loss: 0.003025
Validation Loss: 0.00401065
Epoch [77/300], Train Loss: 0.003005
Validation Loss: 0.00401828
Epoch [78/300], Train Loss: 0.003042
Validation Loss: 0.00401080
Epoch [79/300], Train Loss: 0.003018
Validation Loss: 0.00400803
Epoch [80/300], Train Loss: 0.003035
Validation Loss: 0.00401439
Epoch [81/300], Train Loss: 0.003046
Validation Loss: 0.00401060
Epoch [82/300], Train Loss: 0.003076
Validation Loss: 0.00400481
Epoch [83/300], Train Loss: 0.002968
Validation Loss: 0.00401599
Epoch [84/300], Train Loss: 0.003060
Validation Loss: 0.00400668
Epoch [85/300], Train Loss: 0.003091
Validation Loss: 0.00400408
Epoch [86/300], Train Loss: 0.002989
Validation Loss: 0.00400339
Epoch [87/300], Train Loss: 0.003004
Validation Loss: 0.00400725
Epoch [88/300], Train Loss: 0.003035
Validation Loss: 0.00400767
Epoch [89/300], Train Loss: 0.003161
Validation Loss: 0.00400219
Epoch [90/300], Train Loss: 0.003109
Validation Loss: 0.00399747
Epoch [91/300], Train Loss: 0.003045
Validation Loss: 0.00400407
Epoch [92/300], Train Loss: 0.003038
Validation Loss: 0.00400163
Epoch [93/300], Train Loss: 0.003099
Validation Loss: 0.00399975
Epoch [94/300], Train Loss: 0.003030
Validation Loss: 0.00399445
Epoch [95/300], Train Loss: 0.003002
Validation Loss: 0.00399808
Epoch [96/300], Train Loss: 0.003031
Validation Loss: 0.00401523
Epoch [97/300], Train Loss: 0.003042
Validation Loss: 0.00399429
Epoch [98/300], Train Loss: 0.002995
Validation Loss: 0.00399430
Epoch [99/300], Train Loss: 0.003094
Validation Loss: 0.00399686
Epoch [100/300], Train Loss: 0.003046
Validation Loss: 0.00399244
Epoch [101/300], Train Loss: 0.003028
Validation Loss: 0.00399601
Epoch [102/300], Train Loss: 0.003120
Validation Loss: 0.00399557
Epoch [103/300], Train Loss: 0.003107
Validation Loss: 0.00399202
Epoch [104/300], Train Loss: 0.003012
Validation Loss: 0.00398886
Epoch [105/300], Train Loss: 0.003110
Validation Loss: 0.00399830
Epoch [106/300], Train Loss: 0.003030
Validation Loss: 0.00398975
Epoch [107/300], Train Loss: 0.003011
Validation Loss: 0.00398364
Epoch [108/300], Train Loss: 0.003022
Validation Loss: 0.00399328
Epoch [109/300], Train Loss: 0.003040
Validation Loss: 0.00399073
Epoch [110/300], Train Loss: 0.003133
Validation Loss: 0.00398620
Epoch [111/300], Train Loss: 0.002941
Validation Loss: 0.00398207
Epoch [112/300], Train Loss: 0.003088
Validation Loss: 0.00400369
Epoch [113/300], Train Loss: 0.003119
Validation Loss: 0.00398493
Epoch [114/300], Train Loss: 0.003005
Validation Loss: 0.00397788
Epoch [115/300], Train Loss: 0.003086
Validation Loss: 0.00398322
Epoch [116/300], Train Loss: 0.003046
Validation Loss: 0.00398423
Epoch [117/300], Train Loss: 0.003003
Validation Loss: 0.00398062
Epoch [118/300], Train Loss: 0.002976
Validation Loss: 0.00397511
Epoch [119/300], Train Loss: 0.003074
Validation Loss: 0.00398354
Epoch [120/300], Train Loss: 0.003017
Validation Loss: 0.00398255
Epoch [121/300], Train Loss: 0.003070
Validation Loss: 0.00397442
Epoch [122/300], Train Loss: 0.003010
Validation Loss: 0.00397006
Epoch [123/300], Train Loss: 0.003068
Validation Loss: 0.00398193
Epoch [124/300], Train Loss: 0.002993
Validation Loss: 0.00396913
Epoch [125/300], Train Loss: 0.003052
Validation Loss: 0.00397323
Epoch [126/300], Train Loss: 0.003078
Validation Loss: 0.00397012
Epoch [127/300], Train Loss: 0.002978
Validation Loss: 0.00396517
Epoch [128/300], Train Loss: 0.002972
Validation Loss: 0.00397061
Epoch [129/300], Train Loss: 0.002985
Validation Loss: 0.00397464
Epoch [130/300], Train Loss: 0.003010
Validation Loss: 0.00396871
Epoch [131/300], Train Loss: 0.003004
Validation Loss: 0.00396414
Epoch [132/300], Train Loss: 0.002985
Validation Loss: 0.00396044
Epoch [133/300], Train Loss: 0.002966
Validation Loss: 0.00396666
Epoch [134/300], Train Loss: 0.003030
Validation Loss: 0.00396322
Epoch [135/300], Train Loss: 0.003006
Validation Loss: 0.00395631
Epoch [136/300], Train Loss: 0.003043
Validation Loss: 0.00395632
Epoch [137/300], Train Loss: 0.002974
Validation Loss: 0.00395790
Epoch [138/300], Train Loss: 0.003005
Validation Loss: 0.00395659
Epoch [139/300], Train Loss: 0.003077
Validation Loss: 0.00395731
Epoch [140/300], Train Loss: 0.003013
Validation Loss: 0.00394567
Epoch [141/300], Train Loss: 0.002998
Validation Loss: 0.00396295
Epoch [142/300], Train Loss: 0.003090
Validation Loss: 0.00397290
Epoch [143/300], Train Loss: 0.003064
Validation Loss: 0.00394087
Epoch [144/300], Train Loss: 0.002954
Validation Loss: 0.00394154
Epoch [145/300], Train Loss: 0.003041
Validation Loss: 0.00395529
Epoch [146/300], Train Loss: 0.003065
Validation Loss: 0.00394289
Epoch [147/300], Train Loss: 0.002962
Validation Loss: 0.00393388
Epoch [148/300], Train Loss: 0.002960
Validation Loss: 0.00393558
Epoch [149/300], Train Loss: 0.003017
Validation Loss: 0.00394618
Epoch [150/300], Train Loss: 0.002952
Validation Loss: 0.00393470
Epoch [151/300], Train Loss: 0.003029
Validation Loss: 0.00392858
Epoch [152/300], Train Loss: 0.003041
Validation Loss: 0.00392196
Epoch [153/300], Train Loss: 0.003032
Validation Loss: 0.00392426
Epoch [154/300], Train Loss: 0.002977
Validation Loss: 0.00392177
Epoch [155/300], Train Loss: 0.003025
Validation Loss: 0.00391704
Epoch [156/300], Train Loss: 0.003011
Validation Loss: 0.00391402
Epoch [157/300], Train Loss: 0.002962
Validation Loss: 0.00390738
Epoch [158/300], Train Loss: 0.002925
Validation Loss: 0.00390740
Epoch [159/300], Train Loss: 0.002949
Validation Loss: 0.00391027
Epoch [160/300], Train Loss: 0.002975
Validation Loss: 0.00390266
Epoch [161/300], Train Loss: 0.002954
Validation Loss: 0.00389360
Epoch [162/300], Train Loss: 0.003048
Validation Loss: 0.00390116
Epoch [163/300], Train Loss: 0.002931
Validation Loss: 0.00388581
Epoch [164/300], Train Loss: 0.002972
Validation Loss: 0.00388543
Epoch [165/300], Train Loss: 0.003003
Validation Loss: 0.00387924
Epoch [166/300], Train Loss: 0.003049
Validation Loss: 0.00387913
Epoch [167/300], Train Loss: 0.002995
Validation Loss: 0.00386581
Epoch [168/300], Train Loss: 0.002938
Validation Loss: 0.00387038
Epoch [169/300], Train Loss: 0.002908
Validation Loss: 0.00386369
Epoch [170/300], Train Loss: 0.002936
Validation Loss: 0.00385324
Epoch [171/300], Train Loss: 0.002928
Validation Loss: 0.00386099
Epoch [172/300], Train Loss: 0.002863
Validation Loss: 0.00384595
Epoch [173/300], Train Loss: 0.002956
Validation Loss: 0.00384433
Epoch [174/300], Train Loss: 0.002991
Validation Loss: 0.00383594
Epoch [175/300], Train Loss: 0.002963
Validation Loss: 0.00382726
Epoch [176/300], Train Loss: 0.002936
Validation Loss: 0.00381608
Epoch [177/300], Train Loss: 0.002891
Validation Loss: 0.00381279
Epoch [178/300], Train Loss: 0.002857
Validation Loss: 0.00380302
Epoch [179/300], Train Loss: 0.002884
Validation Loss: 0.00379430
Epoch [180/300], Train Loss: 0.002874
Validation Loss: 0.00380532
Epoch [181/300], Train Loss: 0.002899
Validation Loss: 0.00379115
Epoch [182/300], Train Loss: 0.002885
Validation Loss: 0.00378666
Epoch [183/300], Train Loss: 0.002948
Validation Loss: 0.00377198
Epoch [184/300], Train Loss: 0.002875
Validation Loss: 0.00375075
Epoch [185/300], Train Loss: 0.002874
Validation Loss: 0.00374390
Epoch [186/300], Train Loss: 0.002889
Validation Loss: 0.00373031
Epoch [187/300], Train Loss: 0.002841
Validation Loss: 0.00372135
Epoch [188/300], Train Loss: 0.002843
Validation Loss: 0.00371117
Epoch [189/300], Train Loss: 0.002903
Validation Loss: 0.00370958
Epoch [190/300], Train Loss: 0.002859
Validation Loss: 0.00367577
Epoch [191/300], Train Loss: 0.002796
Validation Loss: 0.00365179
Epoch [192/300], Train Loss: 0.002894
Validation Loss: 0.00365645
Epoch [193/300], Train Loss: 0.002822
Validation Loss: 0.00366775
Epoch [194/300], Train Loss: 0.002919
Validation Loss: 0.00369470
Epoch [195/300], Train Loss: 0.002833
Validation Loss: 0.00364556
Epoch [196/300], Train Loss: 0.002817
Validation Loss: 0.00362170
Epoch [197/300], Train Loss: 0.002813
Validation Loss: 0.00361585
Epoch [198/300], Train Loss: 0.002789
Validation Loss: 0.00360548
Epoch [199/300], Train Loss: 0.002802
Validation Loss: 0.00358445
Epoch [200/300], Train Loss: 0.002755
Validation Loss: 0.00356957
Epoch [201/300], Train Loss: 0.002736
Validation Loss: 0.00353962
Epoch [202/300], Train Loss: 0.002761
Validation Loss: 0.00353137
Epoch [203/300], Train Loss: 0.002739
Validation Loss: 0.00350806
Epoch [204/300], Train Loss: 0.002649
Validation Loss: 0.00348562
Epoch [205/300], Train Loss: 0.002694
Validation Loss: 0.00349468
Epoch [206/300], Train Loss: 0.002806
Validation Loss: 0.00345905
Epoch [207/300], Train Loss: 0.002731
Validation Loss: 0.00342523
Epoch [208/300], Train Loss: 0.002626
Validation Loss: 0.00339296
Epoch [209/300], Train Loss: 0.002776
Validation Loss: 0.00337994
Epoch [210/300], Train Loss: 0.002690
Validation Loss: 0.00335810
Epoch [211/300], Train Loss: 0.002616
Validation Loss: 0.00332797
Epoch [212/300], Train Loss: 0.002713
Validation Loss: 0.00332921
Epoch [213/300], Train Loss: 0.002612
Validation Loss: 0.00328782
Epoch [214/300], Train Loss: 0.002597
Validation Loss: 0.00324882
Epoch [215/300], Train Loss: 0.002729
Validation Loss: 0.00321243
Epoch [216/300], Train Loss: 0.002577
Validation Loss: 0.00323652
Epoch [217/300], Train Loss: 0.002534
Validation Loss: 0.00314535
Epoch [218/300], Train Loss: 0.002576
Validation Loss: 0.00314719
Epoch [219/300], Train Loss: 0.002569
Validation Loss: 0.00330862
Epoch [220/300], Train Loss: 0.002611
Validation Loss: 0.00311085
Epoch [221/300], Train Loss: 0.002497
Validation Loss: 0.00304373
Epoch [222/300], Train Loss: 0.002470
Validation Loss: 0.00304497
Epoch [223/300], Train Loss: 0.002480
Validation Loss: 0.00294997
Epoch [224/300], Train Loss: 0.002408
Validation Loss: 0.00289633
Epoch [225/300], Train Loss: 0.002367
Validation Loss: 0.00283864
Epoch [226/300], Train Loss: 0.002287
Validation Loss: 0.00282799
Epoch [227/300], Train Loss: 0.002226
Validation Loss: 0.00269239
Epoch [228/300], Train Loss: 0.002175
Validation Loss: 0.00264828
Epoch [229/300], Train Loss: 0.002358
Validation Loss: 0.00294755
Epoch [230/300], Train Loss: 0.002309
Validation Loss: 0.00276354
Epoch [231/300], Train Loss: 0.002196
Validation Loss: 0.00282158
Epoch [232/300], Train Loss: 0.002194
Validation Loss: 0.00261553
Epoch [233/300], Train Loss: 0.002245
Validation Loss: 0.00241753
Epoch [234/300], Train Loss: 0.002219
Validation Loss: 0.00247413
Epoch [235/300], Train Loss: 0.002007
Validation Loss: 0.00240171
Epoch [236/300], Train Loss: 0.001959
Validation Loss: 0.00236433
Epoch [237/300], Train Loss: 0.001837
Validation Loss: 0.00223517
Epoch [238/300], Train Loss: 0.001775
Validation Loss: 0.00214941
Epoch [239/300], Train Loss: 0.001692
Validation Loss: 0.00205962
Epoch [240/300], Train Loss: 0.001699
Validation Loss: 0.00210173
Epoch [241/300], Train Loss: 0.001609
Validation Loss: 0.00197845
Epoch [242/300], Train Loss: 0.001550
Validation Loss: 0.00210889
Epoch [243/300], Train Loss: 0.001574
Validation Loss: 0.00221450
Epoch [244/300], Train Loss: 0.001714
Validation Loss: 0.00191949
Epoch [245/300], Train Loss: 0.001529
Validation Loss: 0.00186224
Epoch [246/300], Train Loss: 0.001498
Validation Loss: 0.00191575
Epoch [247/300], Train Loss: 0.001398
Validation Loss: 0.00196360
Epoch [248/300], Train Loss: 0.001403
Validation Loss: 0.00185406
Epoch [249/300], Train Loss: 0.001369
Validation Loss: 0.00180203
Epoch [250/300], Train Loss: 0.001338
Validation Loss: 0.00184663
Epoch [251/300], Train Loss: 0.001292
Validation Loss: 0.00179694
Epoch [252/300], Train Loss: 0.001284
Validation Loss: 0.00176242
Epoch [253/300], Train Loss: 0.001319
Validation Loss: 0.00183533
Epoch [254/300], Train Loss: 0.002224
Validation Loss: 0.00272398
Epoch [255/300], Train Loss: 0.002230
Validation Loss: 0.00231360
Epoch [256/300], Train Loss: 0.001694
Validation Loss: 0.00211767
Epoch [257/300], Train Loss: 0.001548
Validation Loss: 0.00226234
Epoch [258/300], Train Loss: 0.001637
Validation Loss: 0.00225867
Epoch [259/300], Train Loss: 0.001537
Validation Loss: 0.00205926
Epoch [260/300], Train Loss: 0.001471
Validation Loss: 0.00209276
Epoch [261/300], Train Loss: 0.001461
Validation Loss: 0.00197484
Epoch [262/300], Train Loss: 0.001489
Validation Loss: 0.00195087
Early stopping triggered

Evaluating model for: Laptop
Run 41/72 completed in 467.97 seconds with: {'MAE': np.float32(2.446679), 'MSE': np.float32(17.522505), 'RMSE': np.float32(4.185989), 'SAE': np.float32(0.07419747), 'NDE': np.float32(0.5369284)}

Run 42/72: hidden=256, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Laptop
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.010149
Validation Loss: 0.00926752
Epoch [2/300], Train Loss: 0.006235
Validation Loss: 0.00599506
Epoch [3/300], Train Loss: 0.003904
Validation Loss: 0.00427826
Epoch [4/300], Train Loss: 0.003277
Validation Loss: 0.00435938
Epoch [5/300], Train Loss: 0.003416
Validation Loss: 0.00419043
Epoch [6/300], Train Loss: 0.003190
Validation Loss: 0.00425616
Epoch [7/300], Train Loss: 0.003187
Validation Loss: 0.00426502
Epoch [8/300], Train Loss: 0.003246
Validation Loss: 0.00420221
Epoch [9/300], Train Loss: 0.003223
Validation Loss: 0.00417312
Epoch [10/300], Train Loss: 0.003258
Validation Loss: 0.00418067
Epoch [11/300], Train Loss: 0.003194
Validation Loss: 0.00418159
Epoch [12/300], Train Loss: 0.003168
Validation Loss: 0.00418046
Epoch [13/300], Train Loss: 0.003097
Validation Loss: 0.00416814
Epoch [14/300], Train Loss: 0.003131
Validation Loss: 0.00418431
Epoch [15/300], Train Loss: 0.003098
Validation Loss: 0.00418350
Epoch [16/300], Train Loss: 0.003185
Validation Loss: 0.00416991
Epoch [17/300], Train Loss: 0.003079
Validation Loss: 0.00415665
Epoch [18/300], Train Loss: 0.003144
Validation Loss: 0.00415509
Epoch [19/300], Train Loss: 0.003165
Validation Loss: 0.00416433
Epoch [20/300], Train Loss: 0.003072
Validation Loss: 0.00414635
Epoch [21/300], Train Loss: 0.003212
Validation Loss: 0.00414509
Epoch [22/300], Train Loss: 0.003123
Validation Loss: 0.00413466
Epoch [23/300], Train Loss: 0.003219
Validation Loss: 0.00413986
Epoch [24/300], Train Loss: 0.003211
Validation Loss: 0.00413275
Epoch [25/300], Train Loss: 0.003153
Validation Loss: 0.00411291
Epoch [26/300], Train Loss: 0.003060
Validation Loss: 0.00411755
Epoch [27/300], Train Loss: 0.003088
Validation Loss: 0.00412549
Epoch [28/300], Train Loss: 0.003050
Validation Loss: 0.00410022
Epoch [29/300], Train Loss: 0.003140
Validation Loss: 0.00409836
Epoch [30/300], Train Loss: 0.003115
Validation Loss: 0.00408449
Epoch [31/300], Train Loss: 0.003088
Validation Loss: 0.00409969
Epoch [32/300], Train Loss: 0.003118
Validation Loss: 0.00408171
Epoch [33/300], Train Loss: 0.003092
Validation Loss: 0.00407428
Epoch [34/300], Train Loss: 0.003076
Validation Loss: 0.00406512
Epoch [35/300], Train Loss: 0.003059
Validation Loss: 0.00407778
Epoch [36/300], Train Loss: 0.003111
Validation Loss: 0.00406898
Epoch [37/300], Train Loss: 0.003049
Validation Loss: 0.00405623
Epoch [38/300], Train Loss: 0.003034
Validation Loss: 0.00407974
Epoch [39/300], Train Loss: 0.003017
Validation Loss: 0.00406073
Epoch [40/300], Train Loss: 0.003156
Validation Loss: 0.00406936
Epoch [41/300], Train Loss: 0.003094
Validation Loss: 0.00405288
Epoch [42/300], Train Loss: 0.003102
Validation Loss: 0.00406539
Epoch [43/300], Train Loss: 0.003193
Validation Loss: 0.00406312
Epoch [44/300], Train Loss: 0.003159
Validation Loss: 0.00405071
Epoch [45/300], Train Loss: 0.003013
Validation Loss: 0.00406164
Epoch [46/300], Train Loss: 0.003096
Validation Loss: 0.00405243
Epoch [47/300], Train Loss: 0.002986
Validation Loss: 0.00404919
Epoch [48/300], Train Loss: 0.003085
Validation Loss: 0.00407116
Epoch [49/300], Train Loss: 0.003016
Validation Loss: 0.00405508
Epoch [50/300], Train Loss: 0.003051
Validation Loss: 0.00405211
Epoch [51/300], Train Loss: 0.003135
Validation Loss: 0.00407262
Epoch [52/300], Train Loss: 0.003116
Validation Loss: 0.00404450
Epoch [53/300], Train Loss: 0.003136
Validation Loss: 0.00405395
Epoch [54/300], Train Loss: 0.003043
Validation Loss: 0.00404589
Epoch [55/300], Train Loss: 0.003058
Validation Loss: 0.00404895
Epoch [56/300], Train Loss: 0.003078
Validation Loss: 0.00406242
Epoch [57/300], Train Loss: 0.003102
Validation Loss: 0.00404659
Epoch [58/300], Train Loss: 0.003106
Validation Loss: 0.00404422
Epoch [59/300], Train Loss: 0.003066
Validation Loss: 0.00404597
Epoch [60/300], Train Loss: 0.003130
Validation Loss: 0.00405453
Epoch [61/300], Train Loss: 0.003111
Validation Loss: 0.00403950
Epoch [62/300], Train Loss: 0.003045
Validation Loss: 0.00403953
Epoch [63/300], Train Loss: 0.003044
Validation Loss: 0.00405120
Epoch [64/300], Train Loss: 0.003087
Validation Loss: 0.00404659
Epoch [65/300], Train Loss: 0.003113
Validation Loss: 0.00403691
Epoch [66/300], Train Loss: 0.003131
Validation Loss: 0.00404151
Epoch [67/300], Train Loss: 0.003072
Validation Loss: 0.00403284
Epoch [68/300], Train Loss: 0.002980
Validation Loss: 0.00403751
Epoch [69/300], Train Loss: 0.003078
Validation Loss: 0.00405078
Epoch [70/300], Train Loss: 0.002995
Validation Loss: 0.00403632
Epoch [71/300], Train Loss: 0.003071
Validation Loss: 0.00403380
Epoch [72/300], Train Loss: 0.003067
Validation Loss: 0.00403334
Epoch [73/300], Train Loss: 0.003122
Validation Loss: 0.00404033
Epoch [74/300], Train Loss: 0.003065
Validation Loss: 0.00403468
Epoch [75/300], Train Loss: 0.003056
Validation Loss: 0.00403034
Epoch [76/300], Train Loss: 0.003044
Validation Loss: 0.00402949
Epoch [77/300], Train Loss: 0.003023
Validation Loss: 0.00403842
Epoch [78/300], Train Loss: 0.003061
Validation Loss: 0.00402875
Epoch [79/300], Train Loss: 0.003038
Validation Loss: 0.00402618
Epoch [80/300], Train Loss: 0.003054
Validation Loss: 0.00403402
Epoch [81/300], Train Loss: 0.003065
Validation Loss: 0.00402863
Epoch [82/300], Train Loss: 0.003097
Validation Loss: 0.00402229
Epoch [83/300], Train Loss: 0.002989
Validation Loss: 0.00403581
Epoch [84/300], Train Loss: 0.003078
Validation Loss: 0.00402284
Epoch [85/300], Train Loss: 0.003109
Validation Loss: 0.00402051
Epoch [86/300], Train Loss: 0.003008
Validation Loss: 0.00402106
Epoch [87/300], Train Loss: 0.003023
Validation Loss: 0.00402410
Epoch [88/300], Train Loss: 0.003054
Validation Loss: 0.00402380
Epoch [89/300], Train Loss: 0.003179
Validation Loss: 0.00401730
Epoch [90/300], Train Loss: 0.003127
Validation Loss: 0.00401232
Epoch [91/300], Train Loss: 0.003064
Validation Loss: 0.00402084
Epoch [92/300], Train Loss: 0.003056
Validation Loss: 0.00401551
Epoch [93/300], Train Loss: 0.003118
Validation Loss: 0.00401349
Epoch [94/300], Train Loss: 0.003049
Validation Loss: 0.00400781
Epoch [95/300], Train Loss: 0.003022
Validation Loss: 0.00401261
Epoch [96/300], Train Loss: 0.003053
Validation Loss: 0.00403023
Epoch [97/300], Train Loss: 0.003061
Validation Loss: 0.00400467
Epoch [98/300], Train Loss: 0.003015
Validation Loss: 0.00400663
Epoch [99/300], Train Loss: 0.003114
Validation Loss: 0.00400969
Epoch [100/300], Train Loss: 0.003065
Validation Loss: 0.00400170
Epoch [101/300], Train Loss: 0.003049
Validation Loss: 0.00400682
Epoch [102/300], Train Loss: 0.003140
Validation Loss: 0.00400595
Epoch [103/300], Train Loss: 0.003123
Validation Loss: 0.00399963
Epoch [104/300], Train Loss: 0.003031
Validation Loss: 0.00399472
Epoch [105/300], Train Loss: 0.003130
Validation Loss: 0.00400602
Epoch [106/300], Train Loss: 0.003050
Validation Loss: 0.00399256
Epoch [107/300], Train Loss: 0.003031
Validation Loss: 0.00398574
Epoch [108/300], Train Loss: 0.003039
Validation Loss: 0.00400161
Epoch [109/300], Train Loss: 0.003060
Validation Loss: 0.00399042
Epoch [110/300], Train Loss: 0.003152
Validation Loss: 0.00398434
Epoch [111/300], Train Loss: 0.002960
Validation Loss: 0.00397898
Epoch [112/300], Train Loss: 0.003109
Validation Loss: 0.00400955
Epoch [113/300], Train Loss: 0.003134
Validation Loss: 0.00397635
Epoch [114/300], Train Loss: 0.003023
Validation Loss: 0.00396912
Epoch [115/300], Train Loss: 0.003105
Validation Loss: 0.00397895
Epoch [116/300], Train Loss: 0.003061
Validation Loss: 0.00397069
Epoch [117/300], Train Loss: 0.003018
Validation Loss: 0.00396000
Epoch [118/300], Train Loss: 0.002995
Validation Loss: 0.00395092
Epoch [119/300], Train Loss: 0.003087
Validation Loss: 0.00396934
Epoch [120/300], Train Loss: 0.003030
Validation Loss: 0.00395055
Epoch [121/300], Train Loss: 0.003083
Validation Loss: 0.00392562
Epoch [122/300], Train Loss: 0.003020
Validation Loss: 0.00387686
Epoch [123/300], Train Loss: 0.003193
Validation Loss: 0.00398429
Epoch [124/300], Train Loss: 0.003017
Validation Loss: 0.00397788
Epoch [125/300], Train Loss: 0.003070
Validation Loss: 0.00397658
Epoch [126/300], Train Loss: 0.003100
Validation Loss: 0.00397264
Epoch [127/300], Train Loss: 0.002996
Validation Loss: 0.00397043
Epoch [128/300], Train Loss: 0.002990
Validation Loss: 0.00397352
Epoch [129/300], Train Loss: 0.003003
Validation Loss: 0.00396821
Epoch [130/300], Train Loss: 0.003027
Validation Loss: 0.00395302
Epoch [131/300], Train Loss: 0.003019
Validation Loss: 0.00394733
Epoch [132/300], Train Loss: 0.003001
Validation Loss: 0.00393208
Early stopping triggered

Evaluating model for: Laptop
Run 42/72 completed in 311.38 seconds with: {'MAE': np.float32(2.7840505), 'MSE': np.float32(28.256134), 'RMSE': np.float32(5.31565), 'SAE': np.float32(0.024659906), 'NDE': np.float32(0.6818278)}

Run 43/72: hidden=256, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Laptop
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.005835
Validation Loss: 0.00574972
Epoch [2/300], Train Loss: 0.003727
Validation Loss: 0.00427611
Epoch [3/300], Train Loss: 0.003240
Validation Loss: 0.00424529
Epoch [4/300], Train Loss: 0.003252
Validation Loss: 0.00415367
Epoch [5/300], Train Loss: 0.003204
Validation Loss: 0.00421751
Epoch [6/300], Train Loss: 0.003180
Validation Loss: 0.00420388
Epoch [7/300], Train Loss: 0.003133
Validation Loss: 0.00416673
Epoch [8/300], Train Loss: 0.003203
Validation Loss: 0.00415736
Epoch [9/300], Train Loss: 0.003194
Validation Loss: 0.00415310
Epoch [10/300], Train Loss: 0.003234
Validation Loss: 0.00417562
Epoch [11/300], Train Loss: 0.003176
Validation Loss: 0.00416213
Epoch [12/300], Train Loss: 0.003150
Validation Loss: 0.00415637
Epoch [13/300], Train Loss: 0.003082
Validation Loss: 0.00415192
Epoch [14/300], Train Loss: 0.003116
Validation Loss: 0.00417838
Epoch [15/300], Train Loss: 0.003087
Validation Loss: 0.00417665
Epoch [16/300], Train Loss: 0.003176
Validation Loss: 0.00416048
Epoch [17/300], Train Loss: 0.003069
Validation Loss: 0.00414951
Epoch [18/300], Train Loss: 0.003137
Validation Loss: 0.00415178
Epoch [19/300], Train Loss: 0.003159
Validation Loss: 0.00416419
Epoch [20/300], Train Loss: 0.003067
Validation Loss: 0.00414681
Epoch [21/300], Train Loss: 0.003208
Validation Loss: 0.00414695
Epoch [22/300], Train Loss: 0.003121
Validation Loss: 0.00413827
Epoch [23/300], Train Loss: 0.003217
Validation Loss: 0.00414537
Epoch [24/300], Train Loss: 0.003210
Validation Loss: 0.00413844
Epoch [25/300], Train Loss: 0.003154
Validation Loss: 0.00411723
Epoch [26/300], Train Loss: 0.003059
Validation Loss: 0.00411865
Epoch [27/300], Train Loss: 0.003088
Validation Loss: 0.00412417
Epoch [28/300], Train Loss: 0.003047
Validation Loss: 0.00409042
Epoch [29/300], Train Loss: 0.003134
Validation Loss: 0.00408180
Epoch [30/300], Train Loss: 0.003110
Validation Loss: 0.00405934
Epoch [31/300], Train Loss: 0.003080
Validation Loss: 0.00407266
Epoch [32/300], Train Loss: 0.003107
Validation Loss: 0.00404972
Epoch [33/300], Train Loss: 0.003082
Validation Loss: 0.00405126
Epoch [34/300], Train Loss: 0.003069
Validation Loss: 0.00404125
Epoch [35/300], Train Loss: 0.003051
Validation Loss: 0.00405311
Epoch [36/300], Train Loss: 0.003105
Validation Loss: 0.00404744
Epoch [37/300], Train Loss: 0.003042
Validation Loss: 0.00403451
Epoch [38/300], Train Loss: 0.003027
Validation Loss: 0.00405801
Epoch [39/300], Train Loss: 0.003008
Validation Loss: 0.00404063
Epoch [40/300], Train Loss: 0.003145
Validation Loss: 0.00404707
Epoch [41/300], Train Loss: 0.003084
Validation Loss: 0.00402759
Epoch [42/300], Train Loss: 0.003092
Validation Loss: 0.00403775
Epoch [43/300], Train Loss: 0.003183
Validation Loss: 0.00403796
Epoch [44/300], Train Loss: 0.003147
Validation Loss: 0.00401844
Epoch [45/300], Train Loss: 0.003004
Validation Loss: 0.00402770
Epoch [46/300], Train Loss: 0.003086
Validation Loss: 0.00402355
Epoch [47/300], Train Loss: 0.002976
Validation Loss: 0.00401709
Epoch [48/300], Train Loss: 0.003074
Validation Loss: 0.00403635
Epoch [49/300], Train Loss: 0.003004
Validation Loss: 0.00402294
Epoch [50/300], Train Loss: 0.003041
Validation Loss: 0.00401568
Epoch [51/300], Train Loss: 0.003121
Validation Loss: 0.00403269
Epoch [52/300], Train Loss: 0.003105
Validation Loss: 0.00400642
Epoch [53/300], Train Loss: 0.003122
Validation Loss: 0.00401683
Epoch [54/300], Train Loss: 0.003033
Validation Loss: 0.00400312
Epoch [55/300], Train Loss: 0.003047
Validation Loss: 0.00400513
Epoch [56/300], Train Loss: 0.003064
Validation Loss: 0.00402416
Epoch [57/300], Train Loss: 0.003088
Validation Loss: 0.00400744
Epoch [58/300], Train Loss: 0.003091
Validation Loss: 0.00400353
Epoch [59/300], Train Loss: 0.003051
Validation Loss: 0.00399312
Epoch [60/300], Train Loss: 0.003115
Validation Loss: 0.00399644
Epoch [61/300], Train Loss: 0.003095
Validation Loss: 0.00397817
Epoch [62/300], Train Loss: 0.003030
Validation Loss: 0.00397322
Epoch [63/300], Train Loss: 0.003028
Validation Loss: 0.00398310
Epoch [64/300], Train Loss: 0.003074
Validation Loss: 0.00397631
Epoch [65/300], Train Loss: 0.003091
Validation Loss: 0.00398219
Epoch [66/300], Train Loss: 0.003113
Validation Loss: 0.00398450
Epoch [67/300], Train Loss: 0.003055
Validation Loss: 0.00393430
Epoch [68/300], Train Loss: 0.002959
Validation Loss: 0.00396809
Epoch [69/300], Train Loss: 0.003057
Validation Loss: 0.00394375
Epoch [70/300], Train Loss: 0.003001
Validation Loss: 0.00393128
Epoch [71/300], Train Loss: 0.003066
Validation Loss: 0.00404257
Epoch [72/300], Train Loss: 0.003062
Validation Loss: 0.00403346
Epoch [73/300], Train Loss: 0.003118
Validation Loss: 0.00403300
Epoch [74/300], Train Loss: 0.003058
Validation Loss: 0.00402970
Epoch [75/300], Train Loss: 0.003045
Validation Loss: 0.00401522
Epoch [76/300], Train Loss: 0.003033
Validation Loss: 0.00399929
Epoch [77/300], Train Loss: 0.003010
Validation Loss: 0.00400286
Epoch [78/300], Train Loss: 0.003045
Validation Loss: 0.00399581
Epoch [79/300], Train Loss: 0.003022
Validation Loss: 0.00398849
Epoch [80/300], Train Loss: 0.003038
Validation Loss: 0.00399014
Early stopping triggered

Evaluating model for: Laptop
Run 43/72 completed in 227.11 seconds with: {'MAE': np.float32(2.781449), 'MSE': np.float32(28.564152), 'RMSE': np.float32(5.344544), 'SAE': np.float32(0.0020629333), 'NDE': np.float32(0.68553394)}

Run 44/72: hidden=256, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Laptop
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.003160
Validation Loss: 0.00414530
Epoch [2/300], Train Loss: 0.003070
Validation Loss: 0.00416012
Epoch [3/300], Train Loss: 0.003146
Validation Loss: 0.00415947
Epoch [4/300], Train Loss: 0.003111
Validation Loss: 0.00415391
Epoch [5/300], Train Loss: 0.003169
Validation Loss: 0.00415236
Epoch [6/300], Train Loss: 0.003143
Validation Loss: 0.00414916
Epoch [7/300], Train Loss: 0.003107
Validation Loss: 0.00416661
Epoch [8/300], Train Loss: 0.003188
Validation Loss: 0.00416054
Epoch [9/300], Train Loss: 0.003179
Validation Loss: 0.00414116
Epoch [10/300], Train Loss: 0.003221
Validation Loss: 0.00417096
Epoch [11/300], Train Loss: 0.003156
Validation Loss: 0.00414783
Epoch [12/300], Train Loss: 0.003131
Validation Loss: 0.00414706
Epoch [13/300], Train Loss: 0.003062
Validation Loss: 0.00414678
Epoch [14/300], Train Loss: 0.003097
Validation Loss: 0.00417999
Epoch [15/300], Train Loss: 0.003071
Validation Loss: 0.00416502
Epoch [16/300], Train Loss: 0.003157
Validation Loss: 0.00415071
Epoch [17/300], Train Loss: 0.003052
Validation Loss: 0.00414627
Epoch [18/300], Train Loss: 0.003120
Validation Loss: 0.00415148
Epoch [19/300], Train Loss: 0.003144
Validation Loss: 0.00416164
Early stopping triggered

Evaluating model for: Laptop
Run 44/72 completed in 75.04 seconds with: {'MAE': np.float32(2.3894722), 'MSE': np.float32(29.213324), 'RMSE': np.float32(5.404935), 'SAE': np.float32(0.0020682074), 'NDE': np.float32(0.69328004)}

Run 45/72: hidden=256, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Laptop
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.008866
Validation Loss: 0.00824972
Epoch [2/300], Train Loss: 0.007499
Validation Loss: 0.00662890
Epoch [3/300], Train Loss: 0.006323
Validation Loss: 0.00529211
Epoch [4/300], Train Loss: 0.004901
Validation Loss: 0.00422766
Epoch [5/300], Train Loss: 0.003868
Validation Loss: 0.00354215
Epoch [6/300], Train Loss: 0.003553
Validation Loss: 0.00329068
Epoch [7/300], Train Loss: 0.003046
Validation Loss: 0.00339934
Epoch [8/300], Train Loss: 0.003242
Validation Loss: 0.00343391
Epoch [9/300], Train Loss: 0.003273
Validation Loss: 0.00334051
Epoch [10/300], Train Loss: 0.003271
Validation Loss: 0.00328744
Epoch [11/300], Train Loss: 0.003229
Validation Loss: 0.00330004
Epoch [12/300], Train Loss: 0.003288
Validation Loss: 0.00332114
Epoch [13/300], Train Loss: 0.003126
Validation Loss: 0.00331579
Epoch [14/300], Train Loss: 0.003512
Validation Loss: 0.00330258
Epoch [15/300], Train Loss: 0.003186
Validation Loss: 0.00328686
Epoch [16/300], Train Loss: 0.003483
Validation Loss: 0.00328764
Epoch [17/300], Train Loss: 0.003004
Validation Loss: 0.00329244
Epoch [18/300], Train Loss: 0.003531
Validation Loss: 0.00328983
Epoch [19/300], Train Loss: 0.003193
Validation Loss: 0.00328830
Epoch [20/300], Train Loss: 0.003169
Validation Loss: 0.00328776
Epoch [21/300], Train Loss: 0.003706
Validation Loss: 0.00328855
Epoch [22/300], Train Loss: 0.003620
Validation Loss: 0.00328914
Epoch [23/300], Train Loss: 0.003253
Validation Loss: 0.00329130
Epoch [24/300], Train Loss: 0.003046
Validation Loss: 0.00329331
Epoch [25/300], Train Loss: 0.003308
Validation Loss: 0.00329209
Early stopping triggered

Evaluating model for: Laptop
Run 45/72 completed in 24.05 seconds with: {'MAE': np.float32(2.555132), 'MSE': np.float32(31.081884), 'RMSE': np.float32(5.575113), 'SAE': np.float32(0.14207362), 'NDE': np.float32(0.739158)}

Run 46/72: hidden=256, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Laptop
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.008296
Validation Loss: 0.00754371
Epoch [2/300], Train Loss: 0.006776
Validation Loss: 0.00586425
Epoch [3/300], Train Loss: 0.005543
Validation Loss: 0.00456626
Epoch [4/300], Train Loss: 0.004201
Validation Loss: 0.00368005
Epoch [5/300], Train Loss: 0.003380
Validation Loss: 0.00329859
Epoch [6/300], Train Loss: 0.003377
Validation Loss: 0.00339367
Epoch [7/300], Train Loss: 0.003172
Validation Loss: 0.00350546
Epoch [8/300], Train Loss: 0.003219
Validation Loss: 0.00336859
Epoch [9/300], Train Loss: 0.003145
Validation Loss: 0.00328900
Epoch [10/300], Train Loss: 0.003197
Validation Loss: 0.00330025
Epoch [11/300], Train Loss: 0.003225
Validation Loss: 0.00332902
Epoch [12/300], Train Loss: 0.003286
Validation Loss: 0.00332809
Epoch [13/300], Train Loss: 0.003112
Validation Loss: 0.00330543
Epoch [14/300], Train Loss: 0.003472
Validation Loss: 0.00329118
Epoch [15/300], Train Loss: 0.003171
Validation Loss: 0.00328722
Epoch [16/300], Train Loss: 0.003475
Validation Loss: 0.00329411
Epoch [17/300], Train Loss: 0.003009
Validation Loss: 0.00329656
Epoch [18/300], Train Loss: 0.003533
Validation Loss: 0.00328969
Epoch [19/300], Train Loss: 0.003194
Validation Loss: 0.00328699
Epoch [20/300], Train Loss: 0.003174
Validation Loss: 0.00328648
Epoch [21/300], Train Loss: 0.003715
Validation Loss: 0.00328669
Epoch [22/300], Train Loss: 0.003639
Validation Loss: 0.00328660
Epoch [23/300], Train Loss: 0.003267
Validation Loss: 0.00328865
Epoch [24/300], Train Loss: 0.003064
Validation Loss: 0.00329044
Epoch [25/300], Train Loss: 0.003334
Validation Loss: 0.00328738
Epoch [26/300], Train Loss: 0.003330
Validation Loss: 0.00328693
Epoch [27/300], Train Loss: 0.003274
Validation Loss: 0.00328779
Epoch [28/300], Train Loss: 0.003270
Validation Loss: 0.00328764
Epoch [29/300], Train Loss: 0.003075
Validation Loss: 0.00328697
Epoch [30/300], Train Loss: 0.003244
Validation Loss: 0.00328701
Early stopping triggered

Evaluating model for: Laptop
Run 46/72 completed in 38.29 seconds with: {'MAE': np.float32(2.5362482), 'MSE': np.float32(31.174067), 'RMSE': np.float32(5.583374), 'SAE': np.float32(0.13872766), 'NDE': np.float32(0.7402533)}

Run 47/72: hidden=256, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Laptop
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.009388
Validation Loss: 0.00861354
Epoch [2/300], Train Loss: 0.007764
Validation Loss: 0.00674389
Epoch [3/300], Train Loss: 0.006345
Validation Loss: 0.00520746
Epoch [4/300], Train Loss: 0.004746
Validation Loss: 0.00403640
Epoch [5/300], Train Loss: 0.003637
Validation Loss: 0.00339156
Epoch [6/300], Train Loss: 0.003398
Validation Loss: 0.00334120
Epoch [7/300], Train Loss: 0.003135
Validation Loss: 0.00352108
Epoch [8/300], Train Loss: 0.003232
Validation Loss: 0.00338820
Epoch [9/300], Train Loss: 0.003154
Validation Loss: 0.00329272
Epoch [10/300], Train Loss: 0.003197
Validation Loss: 0.00329883
Epoch [11/300], Train Loss: 0.003223
Validation Loss: 0.00332835
Epoch [12/300], Train Loss: 0.003287
Validation Loss: 0.00332794
Epoch [13/300], Train Loss: 0.003109
Validation Loss: 0.00330479
Epoch [14/300], Train Loss: 0.003472
Validation Loss: 0.00329057
Epoch [15/300], Train Loss: 0.003169
Validation Loss: 0.00328833
Epoch [16/300], Train Loss: 0.003472
Validation Loss: 0.00329605
Epoch [17/300], Train Loss: 0.003009
Validation Loss: 0.00329777
Epoch [18/300], Train Loss: 0.003533
Validation Loss: 0.00328987
Epoch [19/300], Train Loss: 0.003195
Validation Loss: 0.00328707
Epoch [20/300], Train Loss: 0.003175
Validation Loss: 0.00328664
Epoch [21/300], Train Loss: 0.003716
Validation Loss: 0.00328676
Epoch [22/300], Train Loss: 0.003640
Validation Loss: 0.00328670
Epoch [23/300], Train Loss: 0.003268
Validation Loss: 0.00328914
Epoch [24/300], Train Loss: 0.003068
Validation Loss: 0.00329101
Epoch [25/300], Train Loss: 0.003335
Validation Loss: 0.00328735
Epoch [26/300], Train Loss: 0.003333
Validation Loss: 0.00328672
Epoch [27/300], Train Loss: 0.003275
Validation Loss: 0.00328751
Epoch [28/300], Train Loss: 0.003272
Validation Loss: 0.00328725
Epoch [29/300], Train Loss: 0.003076
Validation Loss: 0.00328650
Epoch [30/300], Train Loss: 0.003247
Validation Loss: 0.00328650
Epoch [31/300], Train Loss: 0.003588
Validation Loss: 0.00328651
Epoch [32/300], Train Loss: 0.003189
Validation Loss: 0.00328648
Epoch [33/300], Train Loss: 0.002840
Validation Loss: 0.00328763
Epoch [34/300], Train Loss: 0.003394
Validation Loss: 0.00329163
Epoch [35/300], Train Loss: 0.003012
Validation Loss: 0.00329141
Epoch [36/300], Train Loss: 0.003249
Validation Loss: 0.00328949
Epoch [37/300], Train Loss: 0.003241
Validation Loss: 0.00328716
Epoch [38/300], Train Loss: 0.003501
Validation Loss: 0.00328658
Epoch [39/300], Train Loss: 0.003678
Validation Loss: 0.00328681
Epoch [40/300], Train Loss: 0.002950
Validation Loss: 0.00328956
Epoch [41/300], Train Loss: 0.003301
Validation Loss: 0.00328780
Epoch [42/300], Train Loss: 0.003218
Validation Loss: 0.00328649
Early stopping triggered

Evaluating model for: Laptop
Run 47/72 completed in 65.05 seconds with: {'MAE': np.float32(2.5537038), 'MSE': np.float32(31.24827), 'RMSE': np.float32(5.5900154), 'SAE': np.float32(0.14272378), 'NDE': np.float32(0.7411338)}

Run 48/72: hidden=256, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Laptop
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.005241
Validation Loss: 0.00490732
Epoch [2/300], Train Loss: 0.004424
Validation Loss: 0.00393422
Epoch [3/300], Train Loss: 0.003833
Validation Loss: 0.00338239
Epoch [4/300], Train Loss: 0.003286
Validation Loss: 0.00330110
Epoch [5/300], Train Loss: 0.003233
Validation Loss: 0.00342145
Epoch [6/300], Train Loss: 0.003460
Validation Loss: 0.00337885
Epoch [7/300], Train Loss: 0.002977
Validation Loss: 0.00329728
Epoch [8/300], Train Loss: 0.002995
Validation Loss: 0.00327925
Epoch [9/300], Train Loss: 0.003074
Validation Loss: 0.00330209
Epoch [10/300], Train Loss: 0.003205
Validation Loss: 0.00330778
Epoch [11/300], Train Loss: 0.003205
Validation Loss: 0.00329749
Epoch [12/300], Train Loss: 0.003233
Validation Loss: 0.00328101
Epoch [13/300], Train Loss: 0.003075
Validation Loss: 0.00327659
Epoch [14/300], Train Loss: 0.003421
Validation Loss: 0.00327808
Epoch [15/300], Train Loss: 0.003150
Validation Loss: 0.00328256
Epoch [16/300], Train Loss: 0.003452
Validation Loss: 0.00328248
Epoch [17/300], Train Loss: 0.002977
Validation Loss: 0.00327909
Epoch [18/300], Train Loss: 0.003511
Validation Loss: 0.00327616
Epoch [19/300], Train Loss: 0.003172
Validation Loss: 0.00327643
Epoch [20/300], Train Loss: 0.003152
Validation Loss: 0.00327641
Epoch [21/300], Train Loss: 0.003691
Validation Loss: 0.00327611
Epoch [22/300], Train Loss: 0.003614
Validation Loss: 0.00327768
Epoch [23/300], Train Loss: 0.003248
Validation Loss: 0.00328262
Epoch [24/300], Train Loss: 0.003055
Validation Loss: 0.00328311
Epoch [25/300], Train Loss: 0.003315
Validation Loss: 0.00327669
Epoch [26/300], Train Loss: 0.003313
Validation Loss: 0.00327693
Epoch [27/300], Train Loss: 0.003257
Validation Loss: 0.00327832
Epoch [28/300], Train Loss: 0.003254
Validation Loss: 0.00327724
Epoch [29/300], Train Loss: 0.003057
Validation Loss: 0.00327600
Epoch [30/300], Train Loss: 0.003226
Validation Loss: 0.00327616
Epoch [31/300], Train Loss: 0.003567
Validation Loss: 0.00327620
Epoch [32/300], Train Loss: 0.003169
Validation Loss: 0.00327606
Epoch [33/300], Train Loss: 0.002820
Validation Loss: 0.00327726
Epoch [34/300], Train Loss: 0.003376
Validation Loss: 0.00328209
Epoch [35/300], Train Loss: 0.002995
Validation Loss: 0.00328144
Epoch [36/300], Train Loss: 0.003228
Validation Loss: 0.00327881
Epoch [37/300], Train Loss: 0.003220
Validation Loss: 0.00327632
Epoch [38/300], Train Loss: 0.003480
Validation Loss: 0.00327594
Epoch [39/300], Train Loss: 0.003657
Validation Loss: 0.00327667
Epoch [40/300], Train Loss: 0.002932
Validation Loss: 0.00327979
Epoch [41/300], Train Loss: 0.003282
Validation Loss: 0.00327728
Epoch [42/300], Train Loss: 0.003200
Validation Loss: 0.00327592
Epoch [43/300], Train Loss: 0.003776
Validation Loss: 0.00327592
Epoch [44/300], Train Loss: 0.003066
Validation Loss: 0.00327684
Epoch [45/300], Train Loss: 0.003495
Validation Loss: 0.00327616
Epoch [46/300], Train Loss: 0.003315
Validation Loss: 0.00327630
Epoch [47/300], Train Loss: 0.003645
Validation Loss: 0.00327639
Epoch [48/300], Train Loss: 0.003186
Validation Loss: 0.00327647
Epoch [49/300], Train Loss: 0.003222
Validation Loss: 0.00327627
Epoch [50/300], Train Loss: 0.003714
Validation Loss: 0.00327707
Epoch [51/300], Train Loss: 0.003188
Validation Loss: 0.00327640
Epoch [52/300], Train Loss: 0.002985
Validation Loss: 0.00327684
Early stopping triggered

Evaluating model for: Laptop
Run 48/72 completed in 112.07 seconds with: {'MAE': np.float32(2.5760262), 'MSE': np.float32(31.114813), 'RMSE': np.float32(5.5780654), 'SAE': np.float32(0.15254115), 'NDE': np.float32(0.7395494)}

Run 49/72: hidden=512, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Laptop
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.003350
Validation Loss: 0.00350465
Epoch [2/300], Train Loss: 0.003239
Validation Loss: 0.00346441
Epoch [3/300], Train Loss: 0.003189
Validation Loss: 0.00342003
Epoch [4/300], Train Loss: 0.003197
Validation Loss: 0.00342245
Epoch [5/300], Train Loss: 0.003384
Validation Loss: 0.00341055
Epoch [6/300], Train Loss: 0.003156
Validation Loss: 0.00341084
Epoch [7/300], Train Loss: 0.003163
Validation Loss: 0.00341879
Epoch [8/300], Train Loss: 0.003142
Validation Loss: 0.00338471
Epoch [9/300], Train Loss: 0.003182
Validation Loss: 0.00328416
Epoch [10/300], Train Loss: 0.003005
Validation Loss: 0.00327222
Epoch [11/300], Train Loss: 0.002786
Validation Loss: 0.00279550
Epoch [12/300], Train Loss: 0.002516
Validation Loss: 0.00264187
Epoch [13/300], Train Loss: 0.002396
Validation Loss: 0.00243442
Epoch [14/300], Train Loss: 0.002162
Validation Loss: 0.00267128
Epoch [15/300], Train Loss: 0.002251
Validation Loss: 0.00218840
Epoch [16/300], Train Loss: 0.001846
Validation Loss: 0.00181397
Epoch [17/300], Train Loss: 0.001641
Validation Loss: 0.00180109
Epoch [18/300], Train Loss: 0.001364
Validation Loss: 0.00139866
Epoch [19/300], Train Loss: 0.001401
Validation Loss: 0.00136014
Epoch [20/300], Train Loss: 0.001288
Validation Loss: 0.00142284
Epoch [21/300], Train Loss: 0.001287
Validation Loss: 0.00146420
Epoch [22/300], Train Loss: 0.001283
Validation Loss: 0.00127301
Epoch [23/300], Train Loss: 0.001090
Validation Loss: 0.00123963
Epoch [24/300], Train Loss: 0.001062
Validation Loss: 0.00106540
Epoch [25/300], Train Loss: 0.000945
Validation Loss: 0.00100098
Epoch [26/300], Train Loss: 0.000971
Validation Loss: 0.00105841
Epoch [27/300], Train Loss: 0.000882
Validation Loss: 0.00097025
Epoch [28/300], Train Loss: 0.000870
Validation Loss: 0.00086820
Epoch [29/300], Train Loss: 0.000784
Validation Loss: 0.00095428
Epoch [30/300], Train Loss: 0.000801
Validation Loss: 0.00101276
Epoch [31/300], Train Loss: 0.000992
Validation Loss: 0.00093283
Epoch [32/300], Train Loss: 0.000773
Validation Loss: 0.00092175
Epoch [33/300], Train Loss: 0.000747
Validation Loss: 0.00083740
Epoch [34/300], Train Loss: 0.000715
Validation Loss: 0.00078442
Epoch [35/300], Train Loss: 0.000692
Validation Loss: 0.00073016
Epoch [36/300], Train Loss: 0.000648
Validation Loss: 0.00059780
Epoch [37/300], Train Loss: 0.000627
Validation Loss: 0.00054939
Epoch [38/300], Train Loss: 0.000629
Validation Loss: 0.00052719
Epoch [39/300], Train Loss: 0.000584
Validation Loss: 0.00062053
Epoch [40/300], Train Loss: 0.000585
Validation Loss: 0.00050926
Epoch [41/300], Train Loss: 0.000614
Validation Loss: 0.00053311
Epoch [42/300], Train Loss: 0.000575
Validation Loss: 0.00048981
Epoch [43/300], Train Loss: 0.000558
Validation Loss: 0.00047712
Epoch [44/300], Train Loss: 0.000564
Validation Loss: 0.00048640
Epoch [45/300], Train Loss: 0.000555
Validation Loss: 0.00049187
Epoch [46/300], Train Loss: 0.000564
Validation Loss: 0.00046284
Epoch [47/300], Train Loss: 0.000546
Validation Loss: 0.00055969
Epoch [48/300], Train Loss: 0.000555
Validation Loss: 0.00058425
Epoch [49/300], Train Loss: 0.000586
Validation Loss: 0.00047737
Epoch [50/300], Train Loss: 0.000552
Validation Loss: 0.00058268
Epoch [51/300], Train Loss: 0.000520
Validation Loss: 0.00048314
Epoch [52/300], Train Loss: 0.000520
Validation Loss: 0.00044688
Epoch [53/300], Train Loss: 0.000499
Validation Loss: 0.00064810
Epoch [54/300], Train Loss: 0.000522
Validation Loss: 0.00042470
Epoch [55/300], Train Loss: 0.000495
Validation Loss: 0.00042416
Epoch [56/300], Train Loss: 0.000491
Validation Loss: 0.00049107
Epoch [57/300], Train Loss: 0.000486
Validation Loss: 0.00042653
Epoch [58/300], Train Loss: 0.000470
Validation Loss: 0.00040093
Epoch [59/300], Train Loss: 0.000469
Validation Loss: 0.00047314
Epoch [60/300], Train Loss: 0.000489
Validation Loss: 0.00051739
Epoch [61/300], Train Loss: 0.000514
Validation Loss: 0.00042353
Epoch [62/300], Train Loss: 0.000539
Validation Loss: 0.00040916
Epoch [63/300], Train Loss: 0.000476
Validation Loss: 0.00039185
Epoch [64/300], Train Loss: 0.000522
Validation Loss: 0.00054370
Epoch [65/300], Train Loss: 0.000495
Validation Loss: 0.00061501
Epoch [66/300], Train Loss: 0.000460
Validation Loss: 0.00036974
Epoch [67/300], Train Loss: 0.000436
Validation Loss: 0.00035932
Epoch [68/300], Train Loss: 0.000435
Validation Loss: 0.00036692
Epoch [69/300], Train Loss: 0.000434
Validation Loss: 0.00038342
Epoch [70/300], Train Loss: 0.000428
Validation Loss: 0.00037709
Epoch [71/300], Train Loss: 0.000430
Validation Loss: 0.00036709
Epoch [72/300], Train Loss: 0.000425
Validation Loss: 0.00034216
Epoch [73/300], Train Loss: 0.000411
Validation Loss: 0.00035317
Epoch [74/300], Train Loss: 0.000426
Validation Loss: 0.00036065
Epoch [75/300], Train Loss: 0.000425
Validation Loss: 0.00043797
Epoch [76/300], Train Loss: 0.000433
Validation Loss: 0.00032668
Epoch [77/300], Train Loss: 0.000411
Validation Loss: 0.00042611
Epoch [78/300], Train Loss: 0.000400
Validation Loss: 0.00034713
Epoch [79/300], Train Loss: 0.000405
Validation Loss: 0.00032197
Epoch [80/300], Train Loss: 0.000393
Validation Loss: 0.00038916
Epoch [81/300], Train Loss: 0.000415
Validation Loss: 0.00032946
Epoch [82/300], Train Loss: 0.000412
Validation Loss: 0.00043211
Epoch [83/300], Train Loss: 0.000450
Validation Loss: 0.00033603
Epoch [84/300], Train Loss: 0.000401
Validation Loss: 0.00032608
Epoch [85/300], Train Loss: 0.000405
Validation Loss: 0.00040629
Epoch [86/300], Train Loss: 0.000401
Validation Loss: 0.00033449
Epoch [87/300], Train Loss: 0.000404
Validation Loss: 0.00030457
Epoch [88/300], Train Loss: 0.000373
Validation Loss: 0.00031386
Epoch [89/300], Train Loss: 0.000379
Validation Loss: 0.00032256
Epoch [90/300], Train Loss: 0.000378
Validation Loss: 0.00030549
Epoch [91/300], Train Loss: 0.000375
Validation Loss: 0.00029932
Epoch [92/300], Train Loss: 0.000370
Validation Loss: 0.00029895
Epoch [93/300], Train Loss: 0.000372
Validation Loss: 0.00032610
Epoch [94/300], Train Loss: 0.000377
Validation Loss: 0.00028981
Epoch [95/300], Train Loss: 0.000367
Validation Loss: 0.00028670
Epoch [96/300], Train Loss: 0.000355
Validation Loss: 0.00028649
Epoch [97/300], Train Loss: 0.000362
Validation Loss: 0.00028971
Epoch [98/300], Train Loss: 0.000354
Validation Loss: 0.00031513
Epoch [99/300], Train Loss: 0.000364
Validation Loss: 0.00029583
Epoch [100/300], Train Loss: 0.000363
Validation Loss: 0.00029500
Epoch [101/300], Train Loss: 0.000378
Validation Loss: 0.00028017
Epoch [102/300], Train Loss: 0.000351
Validation Loss: 0.00027732
Epoch [103/300], Train Loss: 0.000348
Validation Loss: 0.00027997
Epoch [104/300], Train Loss: 0.000361
Validation Loss: 0.00029789
Epoch [105/300], Train Loss: 0.000363
Validation Loss: 0.00028723
Epoch [106/300], Train Loss: 0.000337
Validation Loss: 0.00029291
Epoch [107/300], Train Loss: 0.000344
Validation Loss: 0.00027470
Epoch [108/300], Train Loss: 0.000345
Validation Loss: 0.00026731
Epoch [109/300], Train Loss: 0.000340
Validation Loss: 0.00026512
Epoch [110/300], Train Loss: 0.000330
Validation Loss: 0.00026637
Epoch [111/300], Train Loss: 0.000334
Validation Loss: 0.00026492
Epoch [112/300], Train Loss: 0.000340
Validation Loss: 0.00029125
Epoch [113/300], Train Loss: 0.000368
Validation Loss: 0.00029236
Epoch [114/300], Train Loss: 0.000341
Validation Loss: 0.00027325
Epoch [115/300], Train Loss: 0.000329
Validation Loss: 0.00027427
Epoch [116/300], Train Loss: 0.000323
Validation Loss: 0.00026320
Epoch [117/300], Train Loss: 0.000312
Validation Loss: 0.00026620
Epoch [118/300], Train Loss: 0.000406
Validation Loss: 0.00029996
Epoch [119/300], Train Loss: 0.000475
Validation Loss: 0.00036326
Epoch [120/300], Train Loss: 0.000423
Validation Loss: 0.00036653
Epoch [121/300], Train Loss: 0.000376
Validation Loss: 0.00031350
Epoch [122/300], Train Loss: 0.000351
Validation Loss: 0.00027931
Epoch [123/300], Train Loss: 0.000319
Validation Loss: 0.00026361
Epoch [124/300], Train Loss: 0.000334
Validation Loss: 0.00025769
Epoch [125/300], Train Loss: 0.000337
Validation Loss: 0.00030590
Epoch [126/300], Train Loss: 0.000338
Validation Loss: 0.00029404
Epoch [127/300], Train Loss: 0.000380
Validation Loss: 0.00030600
Epoch [128/300], Train Loss: 0.000323
Validation Loss: 0.00031384
Epoch [129/300], Train Loss: 0.000300
Validation Loss: 0.00025851
Epoch [130/300], Train Loss: 0.000298
Validation Loss: 0.00028370
Epoch [131/300], Train Loss: 0.000297
Validation Loss: 0.00025823
Epoch [132/300], Train Loss: 0.000281
Validation Loss: 0.00030875
Epoch [133/300], Train Loss: 0.000269
Validation Loss: 0.00024942
Epoch [134/300], Train Loss: 0.000272
Validation Loss: 0.00024897
Epoch [135/300], Train Loss: 0.000270
Validation Loss: 0.00025246
Epoch [136/300], Train Loss: 0.000266
Validation Loss: 0.00025124
Epoch [137/300], Train Loss: 0.000266
Validation Loss: 0.00025124
Epoch [138/300], Train Loss: 0.000265
Validation Loss: 0.00024756
Epoch [139/300], Train Loss: 0.000280
Validation Loss: 0.00027685
Epoch [140/300], Train Loss: 0.000304
Validation Loss: 0.00032172
Epoch [141/300], Train Loss: 0.000277
Validation Loss: 0.00024177
Epoch [142/300], Train Loss: 0.000261
Validation Loss: 0.00023963
Epoch [143/300], Train Loss: 0.000256
Validation Loss: 0.00025005
Epoch [144/300], Train Loss: 0.000273
Validation Loss: 0.00024050
Epoch [145/300], Train Loss: 0.000270
Validation Loss: 0.00025678
Epoch [146/300], Train Loss: 0.000262
Validation Loss: 0.00023525
Epoch [147/300], Train Loss: 0.000251
Validation Loss: 0.00024253
Epoch [148/300], Train Loss: 0.000251
Validation Loss: 0.00023526
Epoch [149/300], Train Loss: 0.000249
Validation Loss: 0.00024033
Epoch [150/300], Train Loss: 0.000253
Validation Loss: 0.00023727
Epoch [151/300], Train Loss: 0.000252
Validation Loss: 0.00024117
Epoch [152/300], Train Loss: 0.000246
Validation Loss: 0.00023104
Epoch [153/300], Train Loss: 0.000247
Validation Loss: 0.00023591
Epoch [154/300], Train Loss: 0.000255
Validation Loss: 0.00023275
Epoch [155/300], Train Loss: 0.000257
Validation Loss: 0.00025471
Epoch [156/300], Train Loss: 0.000254
Validation Loss: 0.00023115
Epoch [157/300], Train Loss: 0.000254
Validation Loss: 0.00022836
Epoch [158/300], Train Loss: 0.000254
Validation Loss: 0.00023171
Epoch [159/300], Train Loss: 0.000241
Validation Loss: 0.00023147
Epoch [160/300], Train Loss: 0.000240
Validation Loss: 0.00022942
Epoch [161/300], Train Loss: 0.000246
Validation Loss: 0.00022680
Epoch [162/300], Train Loss: 0.000243
Validation Loss: 0.00022371
Epoch [163/300], Train Loss: 0.000243
Validation Loss: 0.00022966
Epoch [164/300], Train Loss: 0.000253
Validation Loss: 0.00022857
Epoch [165/300], Train Loss: 0.000239
Validation Loss: 0.00022875
Epoch [166/300], Train Loss: 0.000240
Validation Loss: 0.00022697
Epoch [167/300], Train Loss: 0.000247
Validation Loss: 0.00022496
Epoch [168/300], Train Loss: 0.000241
Validation Loss: 0.00022421
Epoch [169/300], Train Loss: 0.000238
Validation Loss: 0.00022388
Epoch [170/300], Train Loss: 0.000235
Validation Loss: 0.00021944
Epoch [171/300], Train Loss: 0.000235
Validation Loss: 0.00023896
Epoch [172/300], Train Loss: 0.000240
Validation Loss: 0.00022899
Epoch [173/300], Train Loss: 0.000247
Validation Loss: 0.00021985
Epoch [174/300], Train Loss: 0.000241
Validation Loss: 0.00024165
Epoch [175/300], Train Loss: 0.000249
Validation Loss: 0.00021859
Epoch [176/300], Train Loss: 0.000239
Validation Loss: 0.00021534
Epoch [177/300], Train Loss: 0.000235
Validation Loss: 0.00021486
Epoch [178/300], Train Loss: 0.000229
Validation Loss: 0.00022179
Epoch [179/300], Train Loss: 0.000234
Validation Loss: 0.00021837
Epoch [180/300], Train Loss: 0.000232
Validation Loss: 0.00021944
Epoch [181/300], Train Loss: 0.000229
Validation Loss: 0.00021212
Epoch [182/300], Train Loss: 0.000227
Validation Loss: 0.00021582
Epoch [183/300], Train Loss: 0.000234
Validation Loss: 0.00021826
Epoch [184/300], Train Loss: 0.000243
Validation Loss: 0.00024530
Epoch [185/300], Train Loss: 0.000266
Validation Loss: 0.00085419
Epoch [186/300], Train Loss: 0.000583
Validation Loss: 0.00057012
Epoch [187/300], Train Loss: 0.000331
Validation Loss: 0.00024485
Epoch [188/300], Train Loss: 0.000241
Validation Loss: 0.00021429
Epoch [189/300], Train Loss: 0.000229
Validation Loss: 0.00021419
Epoch [190/300], Train Loss: 0.000226
Validation Loss: 0.00021205
Epoch [191/300], Train Loss: 0.000224
Validation Loss: 0.00021464
Epoch [192/300], Train Loss: 0.000225
Validation Loss: 0.00021276
Epoch [193/300], Train Loss: 0.000224
Validation Loss: 0.00020666
Epoch [194/300], Train Loss: 0.000223
Validation Loss: 0.00021272
Epoch [195/300], Train Loss: 0.000230
Validation Loss: 0.00021293
Epoch [196/300], Train Loss: 0.000222
Validation Loss: 0.00020791
Epoch [197/300], Train Loss: 0.000224
Validation Loss: 0.00020964
Epoch [198/300], Train Loss: 0.000220
Validation Loss: 0.00020420
Epoch [199/300], Train Loss: 0.000219
Validation Loss: 0.00020965
Epoch [200/300], Train Loss: 0.000218
Validation Loss: 0.00020427
Epoch [201/300], Train Loss: 0.000222
Validation Loss: 0.00020784
Epoch [202/300], Train Loss: 0.000219
Validation Loss: 0.00021538
Epoch [203/300], Train Loss: 0.000220
Validation Loss: 0.00021195
Epoch [204/300], Train Loss: 0.000220
Validation Loss: 0.00021534
Epoch [205/300], Train Loss: 0.000219
Validation Loss: 0.00020272
Epoch [206/300], Train Loss: 0.000219
Validation Loss: 0.00020692
Epoch [207/300], Train Loss: 0.000229
Validation Loss: 0.00020162
Epoch [208/300], Train Loss: 0.000217
Validation Loss: 0.00020448
Epoch [209/300], Train Loss: 0.000232
Validation Loss: 0.00020921
Epoch [210/300], Train Loss: 0.000225
Validation Loss: 0.00020400
Epoch [211/300], Train Loss: 0.000214
Validation Loss: 0.00020419
Epoch [212/300], Train Loss: 0.000216
Validation Loss: 0.00020347
Epoch [213/300], Train Loss: 0.000216
Validation Loss: 0.00020536
Epoch [214/300], Train Loss: 0.000217
Validation Loss: 0.00021038
Epoch [215/300], Train Loss: 0.000219
Validation Loss: 0.00020237
Epoch [216/300], Train Loss: 0.000213
Validation Loss: 0.00019842
Epoch [217/300], Train Loss: 0.000217
Validation Loss: 0.00019946
Epoch [218/300], Train Loss: 0.000215
Validation Loss: 0.00020387
Epoch [219/300], Train Loss: 0.000212
Validation Loss: 0.00020029
Epoch [220/300], Train Loss: 0.000214
Validation Loss: 0.00021200
Epoch [221/300], Train Loss: 0.000214
Validation Loss: 0.00020025
Epoch [222/300], Train Loss: 0.000212
Validation Loss: 0.00019768
Epoch [223/300], Train Loss: 0.000296
Validation Loss: 0.00176214
Epoch [224/300], Train Loss: 0.002720
Validation Loss: 0.00131928
Epoch [225/300], Train Loss: 0.000921
Validation Loss: 0.00074481
Epoch [226/300], Train Loss: 0.000686
Validation Loss: 0.00060842
Epoch [227/300], Train Loss: 0.000623
Validation Loss: 0.00056026
Epoch [228/300], Train Loss: 0.000578
Validation Loss: 0.00053726
Epoch [229/300], Train Loss: 0.000545
Validation Loss: 0.00047717
Epoch [230/300], Train Loss: 0.000529
Validation Loss: 0.00045314
Epoch [231/300], Train Loss: 0.000509
Validation Loss: 0.00043383
Epoch [232/300], Train Loss: 0.000485
Validation Loss: 0.00040927
Early stopping triggered

Evaluating model for: Laptop
Run 49/72 completed in 1655.64 seconds with: {'MAE': np.float32(1.045834), 'MSE': np.float32(3.625803), 'RMSE': np.float32(1.9041542), 'SAE': np.float32(0.007295522), 'NDE': np.float32(0.24389403)}

Run 50/72: hidden=512, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Laptop
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.003344
Validation Loss: 0.00350851
Epoch [2/300], Train Loss: 0.003260
Validation Loss: 0.00349626
Epoch [3/300], Train Loss: 0.003225
Validation Loss: 0.00347816
Epoch [4/300], Train Loss: 0.003236
Validation Loss: 0.00347534
Epoch [5/300], Train Loss: 0.003425
Validation Loss: 0.00344262
Epoch [6/300], Train Loss: 0.003184
Validation Loss: 0.00346520
Epoch [7/300], Train Loss: 0.003185
Validation Loss: 0.00342530
Epoch [8/300], Train Loss: 0.003167
Validation Loss: 0.00342208
Epoch [9/300], Train Loss: 0.003222
Validation Loss: 0.00337021
Epoch [10/300], Train Loss: 0.003217
Validation Loss: 0.00340133
Epoch [11/300], Train Loss: 0.003127
Validation Loss: 0.00333827
Epoch [12/300], Train Loss: 0.003122
Validation Loss: 0.00339554
Epoch [13/300], Train Loss: 0.003131
Validation Loss: 0.00334407
Epoch [14/300], Train Loss: 0.003170
Validation Loss: 0.00336008
Epoch [15/300], Train Loss: 0.003142
Validation Loss: 0.00335420
Epoch [16/300], Train Loss: 0.003155
Validation Loss: 0.00331358
Epoch [17/300], Train Loss: 0.003153
Validation Loss: 0.00340873
Epoch [18/300], Train Loss: 0.003156
Validation Loss: 0.00335887
Epoch [19/300], Train Loss: 0.003183
Validation Loss: 0.00335778
Epoch [20/300], Train Loss: 0.003171
Validation Loss: 0.00337670
Epoch [21/300], Train Loss: 0.003185
Validation Loss: 0.00332874
Epoch [22/300], Train Loss: 0.003246
Validation Loss: 0.00336430
Epoch [23/300], Train Loss: 0.003238
Validation Loss: 0.00336560
Epoch [24/300], Train Loss: 0.003272
Validation Loss: 0.00332041
Epoch [25/300], Train Loss: 0.003127
Validation Loss: 0.00330774
Epoch [26/300], Train Loss: 0.003101
Validation Loss: 0.00329859
Epoch [27/300], Train Loss: 0.003099
Validation Loss: 0.00330870
Epoch [28/300], Train Loss: 0.003105
Validation Loss: 0.00330813
Epoch [29/300], Train Loss: 0.003085
Validation Loss: 0.00330072
Epoch [30/300], Train Loss: 0.003183
Validation Loss: 0.00333230
Epoch [31/300], Train Loss: 0.003097
Validation Loss: 0.00330479
Epoch [32/300], Train Loss: 0.003117
Validation Loss: 0.00328778
Epoch [33/300], Train Loss: 0.003207
Validation Loss: 0.00330805
Epoch [34/300], Train Loss: 0.003169
Validation Loss: 0.00329870
Epoch [35/300], Train Loss: 0.003108
Validation Loss: 0.00329681
Epoch [36/300], Train Loss: 0.003108
Validation Loss: 0.00326553
Epoch [37/300], Train Loss: 0.003124
Validation Loss: 0.00326946
Epoch [38/300], Train Loss: 0.003134
Validation Loss: 0.00324519
Epoch [39/300], Train Loss: 0.003038
Validation Loss: 0.00318050
Epoch [40/300], Train Loss: 0.003032
Validation Loss: 0.00313773
Epoch [41/300], Train Loss: 0.002923
Validation Loss: 0.00301262
Epoch [42/300], Train Loss: 0.002746
Validation Loss: 0.00269143
Epoch [43/300], Train Loss: 0.002443
Validation Loss: 0.00244089
Epoch [44/300], Train Loss: 0.002400
Validation Loss: 0.00305788
Epoch [45/300], Train Loss: 0.002845
Validation Loss: 0.00277053
Epoch [46/300], Train Loss: 0.002525
Validation Loss: 0.00270932
Epoch [47/300], Train Loss: 0.001867
Validation Loss: 0.00175737
Epoch [48/300], Train Loss: 0.001357
Validation Loss: 0.00161508
Epoch [49/300], Train Loss: 0.001239
Validation Loss: 0.00123268
Epoch [50/300], Train Loss: 0.001101
Validation Loss: 0.00120481
Epoch [51/300], Train Loss: 0.001048
Validation Loss: 0.00125123
Epoch [52/300], Train Loss: 0.000988
Validation Loss: 0.00108643
Epoch [53/300], Train Loss: 0.000860
Validation Loss: 0.00101219
Epoch [54/300], Train Loss: 0.000802
Validation Loss: 0.00074187
Epoch [55/300], Train Loss: 0.000774
Validation Loss: 0.00078982
Epoch [56/300], Train Loss: 0.000732
Validation Loss: 0.00066990
Epoch [57/300], Train Loss: 0.000711
Validation Loss: 0.00067075
Epoch [58/300], Train Loss: 0.000685
Validation Loss: 0.00065431
Epoch [59/300], Train Loss: 0.000691
Validation Loss: 0.00068620
Epoch [60/300], Train Loss: 0.000650
Validation Loss: 0.00061809
Epoch [61/300], Train Loss: 0.000700
Validation Loss: 0.00056633
Epoch [62/300], Train Loss: 0.000697
Validation Loss: 0.00056749
Epoch [63/300], Train Loss: 0.000637
Validation Loss: 0.00055993
Epoch [64/300], Train Loss: 0.000706
Validation Loss: 0.00064529
Epoch [65/300], Train Loss: 0.000623
Validation Loss: 0.00076279
Epoch [66/300], Train Loss: 0.000594
Validation Loss: 0.00051798
Epoch [67/300], Train Loss: 0.000571
Validation Loss: 0.00048560
Epoch [68/300], Train Loss: 0.000566
Validation Loss: 0.00057580
Epoch [69/300], Train Loss: 0.000563
Validation Loss: 0.00065457
Epoch [70/300], Train Loss: 0.000566
Validation Loss: 0.00045975
Epoch [71/300], Train Loss: 0.000527
Validation Loss: 0.00044366
Epoch [72/300], Train Loss: 0.000554
Validation Loss: 0.00055548
Epoch [73/300], Train Loss: 0.000544
Validation Loss: 0.00052891
Epoch [74/300], Train Loss: 0.000560
Validation Loss: 0.00044484
Epoch [75/300], Train Loss: 0.000515
Validation Loss: 0.00043489
Epoch [76/300], Train Loss: 0.000525
Validation Loss: 0.00046635
Epoch [77/300], Train Loss: 0.000527
Validation Loss: 0.00041733
Epoch [78/300], Train Loss: 0.000497
Validation Loss: 0.00040907
Epoch [79/300], Train Loss: 0.000511
Validation Loss: 0.00052055
Epoch [80/300], Train Loss: 0.000503
Validation Loss: 0.00040318
Epoch [81/300], Train Loss: 0.000538
Validation Loss: 0.00041244
Epoch [82/300], Train Loss: 0.000498
Validation Loss: 0.00039783
Epoch [83/300], Train Loss: 0.000514
Validation Loss: 0.00040069
Epoch [84/300], Train Loss: 0.000496
Validation Loss: 0.00045014
Epoch [85/300], Train Loss: 0.000490
Validation Loss: 0.00044406
Epoch [86/300], Train Loss: 0.000483
Validation Loss: 0.00055225
Epoch [87/300], Train Loss: 0.000538
Validation Loss: 0.00038934
Epoch [88/300], Train Loss: 0.000452
Validation Loss: 0.00037281
Epoch [89/300], Train Loss: 0.000473
Validation Loss: 0.00040678
Epoch [90/300], Train Loss: 0.000459
Validation Loss: 0.00038379
Epoch [91/300], Train Loss: 0.000444
Validation Loss: 0.00037179
Epoch [92/300], Train Loss: 0.000454
Validation Loss: 0.00036596
Epoch [93/300], Train Loss: 0.000445
Validation Loss: 0.00039273
Epoch [94/300], Train Loss: 0.000449
Validation Loss: 0.00036105
Epoch [95/300], Train Loss: 0.000426
Validation Loss: 0.00035335
Epoch [96/300], Train Loss: 0.000441
Validation Loss: 0.00038838
Epoch [97/300], Train Loss: 0.000434
Validation Loss: 0.00035337
Epoch [98/300], Train Loss: 0.000457
Validation Loss: 0.00037534
Epoch [99/300], Train Loss: 0.000424
Validation Loss: 0.00035478
Epoch [100/300], Train Loss: 0.000432
Validation Loss: 0.00035823
Epoch [101/300], Train Loss: 0.000399
Validation Loss: 0.00036786
Epoch [102/300], Train Loss: 0.000429
Validation Loss: 0.00051549
Epoch [103/300], Train Loss: 0.000621
Validation Loss: 0.00038456
Epoch [104/300], Train Loss: 0.000432
Validation Loss: 0.00045051
Epoch [105/300], Train Loss: 0.000457
Validation Loss: 0.00038908
Early stopping triggered

Evaluating model for: Laptop
Run 50/72 completed in 822.33 seconds with: {'MAE': np.float32(0.8761761), 'MSE': np.float32(3.3016522), 'RMSE': np.float32(1.8170449), 'SAE': np.float32(0.053183023), 'NDE': np.float32(0.23273662)}

Run 51/72: hidden=512, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Laptop
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.003630
Validation Loss: 0.00354063
Epoch [2/300], Train Loss: 0.003275
Validation Loss: 0.00350412
Epoch [3/300], Train Loss: 0.003232
Validation Loss: 0.00345926
Epoch [4/300], Train Loss: 0.003217
Validation Loss: 0.00342455
Epoch [5/300], Train Loss: 0.003407
Validation Loss: 0.00341217
Epoch [6/300], Train Loss: 0.003173
Validation Loss: 0.00342510
Epoch [7/300], Train Loss: 0.003182
Validation Loss: 0.00344209
Epoch [8/300], Train Loss: 0.003167
Validation Loss: 0.00341428
Epoch [9/300], Train Loss: 0.003227
Validation Loss: 0.00339047
Epoch [10/300], Train Loss: 0.003237
Validation Loss: 0.00340187
Epoch [11/300], Train Loss: 0.003148
Validation Loss: 0.00337142
Epoch [12/300], Train Loss: 0.003138
Validation Loss: 0.00339996
Epoch [13/300], Train Loss: 0.003152
Validation Loss: 0.00338329
Epoch [14/300], Train Loss: 0.003203
Validation Loss: 0.00341390
Epoch [15/300], Train Loss: 0.003175
Validation Loss: 0.00338289
Epoch [16/300], Train Loss: 0.003176
Validation Loss: 0.00336967
Epoch [17/300], Train Loss: 0.003176
Validation Loss: 0.00341032
Epoch [18/300], Train Loss: 0.003185
Validation Loss: 0.00337248
Epoch [19/300], Train Loss: 0.003215
Validation Loss: 0.00336180
Epoch [20/300], Train Loss: 0.003189
Validation Loss: 0.00339263
Epoch [21/300], Train Loss: 0.003212
Validation Loss: 0.00335639
Epoch [22/300], Train Loss: 0.003274
Validation Loss: 0.00337438
Epoch [23/300], Train Loss: 0.003260
Validation Loss: 0.00337917
Epoch [24/300], Train Loss: 0.003295
Validation Loss: 0.00336452
Epoch [25/300], Train Loss: 0.003149
Validation Loss: 0.00333130
Epoch [26/300], Train Loss: 0.003126
Validation Loss: 0.00333389
Epoch [27/300], Train Loss: 0.003119
Validation Loss: 0.00332923
Epoch [28/300], Train Loss: 0.003131
Validation Loss: 0.00333925
Epoch [29/300], Train Loss: 0.003095
Validation Loss: 0.00333482
Epoch [30/300], Train Loss: 0.003192
Validation Loss: 0.00338669
Epoch [31/300], Train Loss: 0.003117
Validation Loss: 0.00332387
Epoch [32/300], Train Loss: 0.003133
Validation Loss: 0.00330413
Epoch [33/300], Train Loss: 0.003224
Validation Loss: 0.00333605
Epoch [34/300], Train Loss: 0.003188
Validation Loss: 0.00329619
Epoch [35/300], Train Loss: 0.003112
Validation Loss: 0.00332597
Epoch [36/300], Train Loss: 0.003144
Validation Loss: 0.00331708
Epoch [37/300], Train Loss: 0.003141
Validation Loss: 0.00330437
Epoch [38/300], Train Loss: 0.003159
Validation Loss: 0.00327291
Epoch [39/300], Train Loss: 0.003094
Validation Loss: 0.00330437
Epoch [40/300], Train Loss: 0.003158
Validation Loss: 0.00330453
Epoch [41/300], Train Loss: 0.003093
Validation Loss: 0.00333549
Epoch [42/300], Train Loss: 0.003147
Validation Loss: 0.00328664
Epoch [43/300], Train Loss: 0.003127
Validation Loss: 0.00328599
Epoch [44/300], Train Loss: 0.003147
Validation Loss: 0.00326447
Epoch [45/300], Train Loss: 0.003104
Validation Loss: 0.00328802
Epoch [46/300], Train Loss: 0.003198
Validation Loss: 0.00328862
Epoch [47/300], Train Loss: 0.003144
Validation Loss: 0.00325711
Epoch [48/300], Train Loss: 0.003107
Validation Loss: 0.00325245
Epoch [49/300], Train Loss: 0.003135
Validation Loss: 0.00327135
Epoch [50/300], Train Loss: 0.003134
Validation Loss: 0.00326233
Epoch [51/300], Train Loss: 0.003162
Validation Loss: 0.00327217
Epoch [52/300], Train Loss: 0.003161
Validation Loss: 0.00331325
Epoch [53/300], Train Loss: 0.003080
Validation Loss: 0.00327134
Epoch [54/300], Train Loss: 0.003065
Validation Loss: 0.00326543
Epoch [55/300], Train Loss: 0.003097
Validation Loss: 0.00325685
Epoch [56/300], Train Loss: 0.003059
Validation Loss: 0.00324595
Epoch [57/300], Train Loss: 0.003080
Validation Loss: 0.00329275
Epoch [58/300], Train Loss: 0.003074
Validation Loss: 0.00325410
Epoch [59/300], Train Loss: 0.003136
Validation Loss: 0.00328335
Epoch [60/300], Train Loss: 0.003060
Validation Loss: 0.00329626
Epoch [61/300], Train Loss: 0.003159
Validation Loss: 0.00325943
Epoch [62/300], Train Loss: 0.003122
Validation Loss: 0.00329072
Epoch [63/300], Train Loss: 0.003312
Validation Loss: 0.00326836
Epoch [64/300], Train Loss: 0.003440
Validation Loss: 0.00324874
Epoch [65/300], Train Loss: 0.003085
Validation Loss: 0.00327817
Epoch [66/300], Train Loss: 0.003127
Validation Loss: 0.00325208
Early stopping triggered

Evaluating model for: Laptop
Run 51/72 completed in 586.32 seconds with: {'MAE': np.float32(2.479356), 'MSE': np.float32(27.18108), 'RMSE': np.float32(5.2135477), 'SAE': np.float32(0.04365945), 'NDE': np.float32(0.6677785)}

Run 52/72: hidden=512, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Laptop
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.003321
Validation Loss: 0.00350173
Epoch [2/300], Train Loss: 0.003254
Validation Loss: 0.00348789
Epoch [3/300], Train Loss: 0.003220
Validation Loss: 0.00347986
Epoch [4/300], Train Loss: 0.003236
Validation Loss: 0.00347763
Epoch [5/300], Train Loss: 0.003424
Validation Loss: 0.00340818
Epoch [6/300], Train Loss: 0.003177
Validation Loss: 0.00342990
Epoch [7/300], Train Loss: 0.003171
Validation Loss: 0.00342418
Epoch [8/300], Train Loss: 0.003154
Validation Loss: 0.00340731
Epoch [9/300], Train Loss: 0.003219
Validation Loss: 0.00337439
Epoch [10/300], Train Loss: 0.003227
Validation Loss: 0.00340731
Epoch [11/300], Train Loss: 0.003143
Validation Loss: 0.00337931
Epoch [12/300], Train Loss: 0.003127
Validation Loss: 0.00338476
Epoch [13/300], Train Loss: 0.003142
Validation Loss: 0.00337374
Epoch [14/300], Train Loss: 0.003194
Validation Loss: 0.00340598
Epoch [15/300], Train Loss: 0.003170
Validation Loss: 0.00337112
Epoch [16/300], Train Loss: 0.003165
Validation Loss: 0.00335772
Epoch [17/300], Train Loss: 0.003170
Validation Loss: 0.00341757
Epoch [18/300], Train Loss: 0.003185
Validation Loss: 0.00334885
Epoch [19/300], Train Loss: 0.003208
Validation Loss: 0.00334360
Epoch [20/300], Train Loss: 0.003183
Validation Loss: 0.00335638
Epoch [21/300], Train Loss: 0.003201
Validation Loss: 0.00334568
Epoch [22/300], Train Loss: 0.003262
Validation Loss: 0.00335872
Epoch [23/300], Train Loss: 0.003254
Validation Loss: 0.00337957
Epoch [24/300], Train Loss: 0.003284
Validation Loss: 0.00333520
Epoch [25/300], Train Loss: 0.003136
Validation Loss: 0.00332991
Epoch [26/300], Train Loss: 0.003095
Validation Loss: 0.00336618
Epoch [27/300], Train Loss: 0.003099
Validation Loss: 0.00331178
Epoch [28/300], Train Loss: 0.003083
Validation Loss: 0.00332318
Epoch [29/300], Train Loss: 0.003071
Validation Loss: 0.00331118
Epoch [30/300], Train Loss: 0.003161
Validation Loss: 0.00333923
Epoch [31/300], Train Loss: 0.003062
Validation Loss: 0.00326413
Epoch [32/300], Train Loss: 0.003085
Validation Loss: 0.00330597
Epoch [33/300], Train Loss: 0.003161
Validation Loss: 0.00325771
Epoch [34/300], Train Loss: 0.003152
Validation Loss: 0.00324190
Epoch [35/300], Train Loss: 0.003075
Validation Loss: 0.00328074
Epoch [36/300], Train Loss: 0.003075
Validation Loss: 0.00332066
Epoch [37/300], Train Loss: 0.003092
Validation Loss: 0.00326538
Epoch [38/300], Train Loss: 0.003116
Validation Loss: 0.00323995
Epoch [39/300], Train Loss: 0.003056
Validation Loss: 0.00330603
Epoch [40/300], Train Loss: 0.003104
Validation Loss: 0.00325858
Epoch [41/300], Train Loss: 0.003044
Validation Loss: 0.00328605
Epoch [42/300], Train Loss: 0.003082
Validation Loss: 0.00326918
Epoch [43/300], Train Loss: 0.003066
Validation Loss: 0.00327914
Epoch [44/300], Train Loss: 0.003082
Validation Loss: 0.00325917
Epoch [45/300], Train Loss: 0.003048
Validation Loss: 0.00333402
Epoch [46/300], Train Loss: 0.003136
Validation Loss: 0.00330207
Epoch [47/300], Train Loss: 0.003097
Validation Loss: 0.00329175
Epoch [48/300], Train Loss: 0.003059
Validation Loss: 0.00326961
Early stopping triggered

Evaluating model for: Laptop
Run 52/72 completed in 498.94 seconds with: {'MAE': np.float32(2.7626412), 'MSE': np.float32(28.716702), 'RMSE': np.float32(5.3587966), 'SAE': np.float32(0.07801155), 'NDE': np.float32(0.68638265)}

Run 53/72: hidden=512, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Laptop
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.003381
Validation Loss: 0.00212969
Epoch [2/300], Train Loss: 0.003267
Validation Loss: 0.00214404
Epoch [3/300], Train Loss: 0.003253
Validation Loss: 0.00219128
Epoch [4/300], Train Loss: 0.003198
Validation Loss: 0.00218592
Epoch [5/300], Train Loss: 0.003243
Validation Loss: 0.00215827
Epoch [6/300], Train Loss: 0.003242
Validation Loss: 0.00225573
Epoch [7/300], Train Loss: 0.003262
Validation Loss: 0.00219722
Epoch [8/300], Train Loss: 0.003237
Validation Loss: 0.00216632
Epoch [9/300], Train Loss: 0.003206
Validation Loss: 0.00223043
Epoch [10/300], Train Loss: 0.003186
Validation Loss: 0.00215626
Epoch [11/300], Train Loss: 0.003164
Validation Loss: 0.00211602
Epoch [12/300], Train Loss: 0.003186
Validation Loss: 0.00211753
Epoch [13/300], Train Loss: 0.003195
Validation Loss: 0.00213215
Epoch [14/300], Train Loss: 0.003205
Validation Loss: 0.00211278
Epoch [15/300], Train Loss: 0.003165
Validation Loss: 0.00210780
Epoch [16/300], Train Loss: 0.003198
Validation Loss: 0.00211770
Epoch [17/300], Train Loss: 0.003145
Validation Loss: 0.00216752
Epoch [18/300], Train Loss: 0.003183
Validation Loss: 0.00216091
Epoch [19/300], Train Loss: 0.003104
Validation Loss: 0.00210629
Epoch [20/300], Train Loss: 0.003022
Validation Loss: 0.00203874
Epoch [21/300], Train Loss: 0.002987
Validation Loss: 0.00196276
Epoch [22/300], Train Loss: 0.002899
Validation Loss: 0.00184797
Epoch [23/300], Train Loss: 0.002598
Validation Loss: 0.00190576
Epoch [24/300], Train Loss: 0.002573
Validation Loss: 0.00188615
Epoch [25/300], Train Loss: 0.002458
Validation Loss: 0.00169628
Epoch [26/300], Train Loss: 0.002335
Validation Loss: 0.00163621
Epoch [27/300], Train Loss: 0.002273
Validation Loss: 0.00166543
Epoch [28/300], Train Loss: 0.002208
Validation Loss: 0.00166025
Epoch [29/300], Train Loss: 0.002002
Validation Loss: 0.00156262
Epoch [30/300], Train Loss: 0.001862
Validation Loss: 0.00137160
Epoch [31/300], Train Loss: 0.001728
Validation Loss: 0.00133054
Epoch [32/300], Train Loss: 0.001691
Validation Loss: 0.00133379
Epoch [33/300], Train Loss: 0.001641
Validation Loss: 0.00138740
Epoch [34/300], Train Loss: 0.001576
Validation Loss: 0.00130011
Epoch [35/300], Train Loss: 0.001544
Validation Loss: 0.00139078
Epoch [36/300], Train Loss: 0.001573
Validation Loss: 0.00116794
Epoch [37/300], Train Loss: 0.001484
Validation Loss: 0.00107259
Epoch [38/300], Train Loss: 0.001400
Validation Loss: 0.00118190
Epoch [39/300], Train Loss: 0.001396
Validation Loss: 0.00111591
Epoch [40/300], Train Loss: 0.001372
Validation Loss: 0.00101580
Epoch [41/300], Train Loss: 0.001289
Validation Loss: 0.00114927
Epoch [42/300], Train Loss: 0.001303
Validation Loss: 0.00100472
Epoch [43/300], Train Loss: 0.001218
Validation Loss: 0.00108389
Epoch [44/300], Train Loss: 0.001303
Validation Loss: 0.00097111
Epoch [45/300], Train Loss: 0.001437
Validation Loss: 0.00105908
Epoch [46/300], Train Loss: 0.001300
Validation Loss: 0.00095828
Epoch [47/300], Train Loss: 0.001235
Validation Loss: 0.00094542
Epoch [48/300], Train Loss: 0.001213
Validation Loss: 0.00089525
Epoch [49/300], Train Loss: 0.001145
Validation Loss: 0.00087445
Epoch [50/300], Train Loss: 0.001127
Validation Loss: 0.00091447
Epoch [51/300], Train Loss: 0.001108
Validation Loss: 0.00085845
Epoch [52/300], Train Loss: 0.001096
Validation Loss: 0.00084993
Epoch [53/300], Train Loss: 0.001061
Validation Loss: 0.00089029
Epoch [54/300], Train Loss: 0.001101
Validation Loss: 0.00085857
Epoch [55/300], Train Loss: 0.001042
Validation Loss: 0.00082750
Epoch [56/300], Train Loss: 0.001013
Validation Loss: 0.00082577
Epoch [57/300], Train Loss: 0.000992
Validation Loss: 0.00078602
Epoch [58/300], Train Loss: 0.000977
Validation Loss: 0.00087126
Epoch [59/300], Train Loss: 0.000998
Validation Loss: 0.00076507
Epoch [60/300], Train Loss: 0.000974
Validation Loss: 0.00074559
Epoch [61/300], Train Loss: 0.000965
Validation Loss: 0.00073860
Epoch [62/300], Train Loss: 0.000964
Validation Loss: 0.00069716
Epoch [63/300], Train Loss: 0.000919
Validation Loss: 0.00070496
Epoch [64/300], Train Loss: 0.000902
Validation Loss: 0.00068624
Epoch [65/300], Train Loss: 0.000906
Validation Loss: 0.00068228
Epoch [66/300], Train Loss: 0.000905
Validation Loss: 0.00070931
Epoch [67/300], Train Loss: 0.000913
Validation Loss: 0.00068377
Epoch [68/300], Train Loss: 0.000916
Validation Loss: 0.00068365
Epoch [69/300], Train Loss: 0.000868
Validation Loss: 0.00071204
Epoch [70/300], Train Loss: 0.000870
Validation Loss: 0.00070804
Epoch [71/300], Train Loss: 0.000856
Validation Loss: 0.00061011
Epoch [72/300], Train Loss: 0.000835
Validation Loss: 0.00063261
Epoch [73/300], Train Loss: 0.000831
Validation Loss: 0.00062501
Epoch [74/300], Train Loss: 0.000810
Validation Loss: 0.00070708
Epoch [75/300], Train Loss: 0.000836
Validation Loss: 0.00058983
Epoch [76/300], Train Loss: 0.000788
Validation Loss: 0.00062857
Epoch [77/300], Train Loss: 0.000781
Validation Loss: 0.00061726
Epoch [78/300], Train Loss: 0.000736
Validation Loss: 0.00052799
Epoch [79/300], Train Loss: 0.000713
Validation Loss: 0.00050472
Epoch [80/300], Train Loss: 0.000716
Validation Loss: 0.00066605
Epoch [81/300], Train Loss: 0.000800
Validation Loss: 0.00048856
Epoch [82/300], Train Loss: 0.000669
Validation Loss: 0.00047607
Epoch [83/300], Train Loss: 0.000640
Validation Loss: 0.00046703
Epoch [84/300], Train Loss: 0.000630
Validation Loss: 0.00046222
Epoch [85/300], Train Loss: 0.000616
Validation Loss: 0.00047568
Epoch [86/300], Train Loss: 0.000610
Validation Loss: 0.00045777
Epoch [87/300], Train Loss: 0.000621
Validation Loss: 0.00047148
Epoch [88/300], Train Loss: 0.000610
Validation Loss: 0.00049587
Epoch [89/300], Train Loss: 0.000615
Validation Loss: 0.00050012
Epoch [90/300], Train Loss: 0.000650
Validation Loss: 0.00061668
Epoch [91/300], Train Loss: 0.000631
Validation Loss: 0.00045964
Epoch [92/300], Train Loss: 0.000603
Validation Loss: 0.00046054
Epoch [93/300], Train Loss: 0.000605
Validation Loss: 0.00044902
Epoch [94/300], Train Loss: 0.000592
Validation Loss: 0.00045340
Epoch [95/300], Train Loss: 0.000583
Validation Loss: 0.00046410
Epoch [96/300], Train Loss: 0.000593
Validation Loss: 0.00042562
Epoch [97/300], Train Loss: 0.000602
Validation Loss: 0.00044327
Epoch [98/300], Train Loss: 0.000582
Validation Loss: 0.00044367
Epoch [99/300], Train Loss: 0.000563
Validation Loss: 0.00042405
Epoch [100/300], Train Loss: 0.000562
Validation Loss: 0.00042039
Epoch [101/300], Train Loss: 0.000587
Validation Loss: 0.00045800
Epoch [102/300], Train Loss: 0.000575
Validation Loss: 0.00041379
Epoch [103/300], Train Loss: 0.000571
Validation Loss: 0.00045076
Epoch [104/300], Train Loss: 0.000546
Validation Loss: 0.00041702
Epoch [105/300], Train Loss: 0.000543
Validation Loss: 0.00041095
Epoch [106/300], Train Loss: 0.000540
Validation Loss: 0.00040094
Epoch [107/300], Train Loss: 0.000544
Validation Loss: 0.00039706
Epoch [108/300], Train Loss: 0.000546
Validation Loss: 0.00041964
Epoch [109/300], Train Loss: 0.000561
Validation Loss: 0.00039642
Epoch [110/300], Train Loss: 0.000527
Validation Loss: 0.00039821
Epoch [111/300], Train Loss: 0.000553
Validation Loss: 0.00043113
Epoch [112/300], Train Loss: 0.000596
Validation Loss: 0.00049313
Epoch [113/300], Train Loss: 0.000541
Validation Loss: 0.00039654
Epoch [114/300], Train Loss: 0.000526
Validation Loss: 0.00038901
Epoch [115/300], Train Loss: 0.000517
Validation Loss: 0.00039884
Epoch [116/300], Train Loss: 0.000579
Validation Loss: 0.00042895
Epoch [117/300], Train Loss: 0.000547
Validation Loss: 0.00040721
Epoch [118/300], Train Loss: 0.000516
Validation Loss: 0.00038047
Epoch [119/300], Train Loss: 0.000552
Validation Loss: 0.00041058
Epoch [120/300], Train Loss: 0.000550
Validation Loss: 0.00043218
Epoch [121/300], Train Loss: 0.000502
Validation Loss: 0.00037735
Epoch [122/300], Train Loss: 0.000532
Validation Loss: 0.00038422
Epoch [123/300], Train Loss: 0.000502
Validation Loss: 0.00037454
Epoch [124/300], Train Loss: 0.000491
Validation Loss: 0.00038182
Epoch [125/300], Train Loss: 0.000545
Validation Loss: 0.00042234
Epoch [126/300], Train Loss: 0.000490
Validation Loss: 0.00038948
Epoch [127/300], Train Loss: 0.000488
Validation Loss: 0.00038279
Epoch [128/300], Train Loss: 0.000478
Validation Loss: 0.00035980
Epoch [129/300], Train Loss: 0.000506
Validation Loss: 0.00061353
Epoch [130/300], Train Loss: 0.000699
Validation Loss: 0.00053529
Epoch [131/300], Train Loss: 0.000513
Validation Loss: 0.00037457
Epoch [132/300], Train Loss: 0.000485
Validation Loss: 0.00035850
Epoch [133/300], Train Loss: 0.000486
Validation Loss: 0.00036062
Epoch [134/300], Train Loss: 0.000485
Validation Loss: 0.00035543
Epoch [135/300], Train Loss: 0.000469
Validation Loss: 0.00035013
Epoch [136/300], Train Loss: 0.000483
Validation Loss: 0.00036070
Epoch [137/300], Train Loss: 0.000466
Validation Loss: 0.00038442
Epoch [138/300], Train Loss: 0.000527
Validation Loss: 0.00038004
Epoch [139/300], Train Loss: 0.000496
Validation Loss: 0.00037123
Epoch [140/300], Train Loss: 0.000483
Validation Loss: 0.00034650
Epoch [141/300], Train Loss: 0.000457
Validation Loss: 0.00036653
Epoch [142/300], Train Loss: 0.000468
Validation Loss: 0.00035293
Epoch [143/300], Train Loss: 0.000469
Validation Loss: 0.00038212
Epoch [144/300], Train Loss: 0.000513
Validation Loss: 0.00037996
Epoch [145/300], Train Loss: 0.000510
Validation Loss: 0.00052125
Epoch [146/300], Train Loss: 0.000535
Validation Loss: 0.00037861
Epoch [147/300], Train Loss: 0.000487
Validation Loss: 0.00035243
Epoch [148/300], Train Loss: 0.000449
Validation Loss: 0.00034161
Epoch [149/300], Train Loss: 0.000548
Validation Loss: 0.00037635
Epoch [150/300], Train Loss: 0.000514
Validation Loss: 0.00033907
Epoch [151/300], Train Loss: 0.000466
Validation Loss: 0.00034428
Epoch [152/300], Train Loss: 0.000452
Validation Loss: 0.00034401
Epoch [153/300], Train Loss: 0.000437
Validation Loss: 0.00033751
Epoch [154/300], Train Loss: 0.000447
Validation Loss: 0.00033607
Epoch [155/300], Train Loss: 0.000436
Validation Loss: 0.00033735
Epoch [156/300], Train Loss: 0.000489
Validation Loss: 0.00034140
Epoch [157/300], Train Loss: 0.000490
Validation Loss: 0.00038688
Epoch [158/300], Train Loss: 0.000505
Validation Loss: 0.00040181
Epoch [159/300], Train Loss: 0.000489
Validation Loss: 0.00033937
Epoch [160/300], Train Loss: 0.000454
Validation Loss: 0.00034237
Epoch [161/300], Train Loss: 0.000426
Validation Loss: 0.00032857
Epoch [162/300], Train Loss: 0.000435
Validation Loss: 0.00032820
Epoch [163/300], Train Loss: 0.000432
Validation Loss: 0.00035100
Epoch [164/300], Train Loss: 0.000428
Validation Loss: 0.00036126
Epoch [165/300], Train Loss: 0.000499
Validation Loss: 0.00036397
Epoch [166/300], Train Loss: 0.000503
Validation Loss: 0.00035008
Epoch [167/300], Train Loss: 0.000453
Validation Loss: 0.00032695
Epoch [168/300], Train Loss: 0.000439
Validation Loss: 0.00032398
Epoch [169/300], Train Loss: 0.000436
Validation Loss: 0.00032821
Epoch [170/300], Train Loss: 0.000414
Validation Loss: 0.00033644
Epoch [171/300], Train Loss: 0.000434
Validation Loss: 0.00033041
Epoch [172/300], Train Loss: 0.000417
Validation Loss: 0.00032616
Epoch [173/300], Train Loss: 0.000417
Validation Loss: 0.00033379
Epoch [174/300], Train Loss: 0.000514
Validation Loss: 0.00036849
Epoch [175/300], Train Loss: 0.000516
Validation Loss: 0.00036037
Epoch [176/300], Train Loss: 0.000464
Validation Loss: 0.00032793
Epoch [177/300], Train Loss: 0.000451
Validation Loss: 0.00032447
Epoch [178/300], Train Loss: 0.000435
Validation Loss: 0.00032502
Early stopping triggered

Evaluating model for: Laptop
Run 53/72 completed in 627.84 seconds with: {'MAE': np.float32(0.9195852), 'MSE': np.float32(6.0721726), 'RMSE': np.float32(2.4641778), 'SAE': np.float32(0.0043619582), 'NDE': np.float32(0.28812653)}

Run 54/72: hidden=512, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Laptop
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.003740
Validation Loss: 0.00216609
Epoch [2/300], Train Loss: 0.003314
Validation Loss: 0.00222425
Epoch [3/300], Train Loss: 0.003303
Validation Loss: 0.00221221
Epoch [4/300], Train Loss: 0.003258
Validation Loss: 0.00218421
Epoch [5/300], Train Loss: 0.003310
Validation Loss: 0.00217121
Epoch [6/300], Train Loss: 0.003309
Validation Loss: 0.00224428
Epoch [7/300], Train Loss: 0.003323
Validation Loss: 0.00217753
Epoch [8/300], Train Loss: 0.003296
Validation Loss: 0.00216148
Epoch [9/300], Train Loss: 0.003240
Validation Loss: 0.00220889
Epoch [10/300], Train Loss: 0.003185
Validation Loss: 0.00211756
Epoch [11/300], Train Loss: 0.003232
Validation Loss: 0.00210299
Epoch [12/300], Train Loss: 0.003233
Validation Loss: 0.00210290
Epoch [13/300], Train Loss: 0.003223
Validation Loss: 0.00212221
Epoch [14/300], Train Loss: 0.003230
Validation Loss: 0.00211973
Epoch [15/300], Train Loss: 0.003184
Validation Loss: 0.00210057
Epoch [16/300], Train Loss: 0.003218
Validation Loss: 0.00211630
Epoch [17/300], Train Loss: 0.003175
Validation Loss: 0.00218130
Epoch [18/300], Train Loss: 0.003225
Validation Loss: 0.00221656
Epoch [19/300], Train Loss: 0.003177
Validation Loss: 0.00211918
Epoch [20/300], Train Loss: 0.003166
Validation Loss: 0.00211017
Epoch [21/300], Train Loss: 0.003217
Validation Loss: 0.00209957
Epoch [22/300], Train Loss: 0.003247
Validation Loss: 0.00210040
Epoch [23/300], Train Loss: 0.003183
Validation Loss: 0.00212235
Epoch [24/300], Train Loss: 0.003177
Validation Loss: 0.00213976
Epoch [25/300], Train Loss: 0.003196
Validation Loss: 0.00218504
Epoch [26/300], Train Loss: 0.003190
Validation Loss: 0.00216434
Epoch [27/300], Train Loss: 0.003220
Validation Loss: 0.00215081
Epoch [28/300], Train Loss: 0.003183
Validation Loss: 0.00217347
Epoch [29/300], Train Loss: 0.003180
Validation Loss: 0.00214219
Epoch [30/300], Train Loss: 0.003165
Validation Loss: 0.00212820
Epoch [31/300], Train Loss: 0.003132
Validation Loss: 0.00219483
Early stopping triggered

Evaluating model for: Laptop
Run 54/72 completed in 124.04 seconds with: {'MAE': np.float32(3.1135051), 'MSE': np.float32(39.445335), 'RMSE': np.float32(6.2805524), 'SAE': np.float32(0.05071932), 'NDE': np.float32(0.73436)}

Run 55/72: hidden=512, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Laptop
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.003572
Validation Loss: 0.00213883
Epoch [2/300], Train Loss: 0.003297
Validation Loss: 0.00219224
Epoch [3/300], Train Loss: 0.003292
Validation Loss: 0.00222602
Epoch [4/300], Train Loss: 0.003248
Validation Loss: 0.00218963
Epoch [5/300], Train Loss: 0.003296
Validation Loss: 0.00216354
Epoch [6/300], Train Loss: 0.003282
Validation Loss: 0.00226668
Epoch [7/300], Train Loss: 0.003281
Validation Loss: 0.00214414
Epoch [8/300], Train Loss: 0.003246
Validation Loss: 0.00213927
Epoch [9/300], Train Loss: 0.003213
Validation Loss: 0.00219344
Epoch [10/300], Train Loss: 0.003180
Validation Loss: 0.00210735
Epoch [11/300], Train Loss: 0.003208
Validation Loss: 0.00210544
Epoch [12/300], Train Loss: 0.003205
Validation Loss: 0.00211093
Epoch [13/300], Train Loss: 0.003205
Validation Loss: 0.00212897
Epoch [14/300], Train Loss: 0.003218
Validation Loss: 0.00211769
Epoch [15/300], Train Loss: 0.003175
Validation Loss: 0.00211690
Epoch [16/300], Train Loss: 0.003213
Validation Loss: 0.00211611
Epoch [17/300], Train Loss: 0.003164
Validation Loss: 0.00220605
Epoch [18/300], Train Loss: 0.003216
Validation Loss: 0.00224962
Epoch [19/300], Train Loss: 0.003168
Validation Loss: 0.00213568
Epoch [20/300], Train Loss: 0.003154
Validation Loss: 0.00211578
Epoch [21/300], Train Loss: 0.003210
Validation Loss: 0.00210744
Early stopping triggered

Evaluating model for: Laptop
Run 55/72 completed in 93.45 seconds with: {'MAE': np.float32(2.8054237), 'MSE': np.float32(39.579967), 'RMSE': np.float32(6.291261), 'SAE': np.float32(0.11252109), 'NDE': np.float32(0.7356122)}

Run 56/72: hidden=512, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Laptop
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.004595
Validation Loss: 0.00220648
Epoch [2/300], Train Loss: 0.003384
Validation Loss: 0.00228542
Epoch [3/300], Train Loss: 0.003355
Validation Loss: 0.00224241
Epoch [4/300], Train Loss: 0.003305
Validation Loss: 0.00222073
Epoch [5/300], Train Loss: 0.003357
Validation Loss: 0.00220891
Epoch [6/300], Train Loss: 0.003359
Validation Loss: 0.00227628
Epoch [7/300], Train Loss: 0.003375
Validation Loss: 0.00220647
Epoch [8/300], Train Loss: 0.003358
Validation Loss: 0.00219189
Epoch [9/300], Train Loss: 0.003312
Validation Loss: 0.00226938
Epoch [10/300], Train Loss: 0.003286
Validation Loss: 0.00217682
Epoch [11/300], Train Loss: 0.003259
Validation Loss: 0.00213143
Epoch [12/300], Train Loss: 0.003272
Validation Loss: 0.00216026
Epoch [13/300], Train Loss: 0.003251
Validation Loss: 0.00218647
Epoch [14/300], Train Loss: 0.003263
Validation Loss: 0.00218411
Epoch [15/300], Train Loss: 0.003209
Validation Loss: 0.00215291
Epoch [16/300], Train Loss: 0.003235
Validation Loss: 0.00217116
Epoch [17/300], Train Loss: 0.003196
Validation Loss: 0.00230076
Epoch [18/300], Train Loss: 0.003268
Validation Loss: 0.00223045
Epoch [19/300], Train Loss: 0.003197
Validation Loss: 0.00220113
Epoch [20/300], Train Loss: 0.003179
Validation Loss: 0.00213315
Epoch [21/300], Train Loss: 0.003244
Validation Loss: 0.00212707
Epoch [22/300], Train Loss: 0.003279
Validation Loss: 0.00214604
Epoch [23/300], Train Loss: 0.003190
Validation Loss: 0.00215101
Epoch [24/300], Train Loss: 0.003183
Validation Loss: 0.00216350
Epoch [25/300], Train Loss: 0.003213
Validation Loss: 0.00227067
Epoch [26/300], Train Loss: 0.003208
Validation Loss: 0.00220205
Epoch [27/300], Train Loss: 0.003239
Validation Loss: 0.00217701
Epoch [28/300], Train Loss: 0.003198
Validation Loss: 0.00225545
Epoch [29/300], Train Loss: 0.003218
Validation Loss: 0.00216237
Epoch [30/300], Train Loss: 0.003194
Validation Loss: 0.00215362
Epoch [31/300], Train Loss: 0.003158
Validation Loss: 0.00221432
Early stopping triggered

Evaluating model for: Laptop
Run 56/72 completed in 161.87 seconds with: {'MAE': np.float32(3.063426), 'MSE': np.float32(39.47313), 'RMSE': np.float32(6.2827644), 'SAE': np.float32(0.0317472), 'NDE': np.float32(0.7346186)}

Run 57/72: hidden=512, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Laptop
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.003741
Validation Loss: 0.00376542
Epoch [2/300], Train Loss: 0.003296
Validation Loss: 0.00362601
Epoch [3/300], Train Loss: 0.003261
Validation Loss: 0.00362520
Epoch [4/300], Train Loss: 0.003267
Validation Loss: 0.00360710
Epoch [5/300], Train Loss: 0.003251
Validation Loss: 0.00359888
Epoch [6/300], Train Loss: 0.003326
Validation Loss: 0.00358667
Epoch [7/300], Train Loss: 0.003280
Validation Loss: 0.00357553
Epoch [8/300], Train Loss: 0.003364
Validation Loss: 0.00356828
Epoch [9/300], Train Loss: 0.003236
Validation Loss: 0.00356137
Epoch [10/300], Train Loss: 0.003245
Validation Loss: 0.00358316
Epoch [11/300], Train Loss: 0.003293
Validation Loss: 0.00357025
Epoch [12/300], Train Loss: 0.003228
Validation Loss: 0.00364042
Epoch [13/300], Train Loss: 0.003273
Validation Loss: 0.00365779
Epoch [14/300], Train Loss: 0.003261
Validation Loss: 0.00356202
Epoch [15/300], Train Loss: 0.003257
Validation Loss: 0.00355821
Epoch [16/300], Train Loss: 0.003180
Validation Loss: 0.00355406
Epoch [17/300], Train Loss: 0.003271
Validation Loss: 0.00356216
Epoch [18/300], Train Loss: 0.003219
Validation Loss: 0.00355737
Epoch [19/300], Train Loss: 0.003198
Validation Loss: 0.00354905
Epoch [20/300], Train Loss: 0.003213
Validation Loss: 0.00355061
Epoch [21/300], Train Loss: 0.003193
Validation Loss: 0.00354705
Epoch [22/300], Train Loss: 0.003180
Validation Loss: 0.00354562
Epoch [23/300], Train Loss: 0.003243
Validation Loss: 0.00355361
Epoch [24/300], Train Loss: 0.003220
Validation Loss: 0.00354744
Epoch [25/300], Train Loss: 0.003217
Validation Loss: 0.00355997
Epoch [26/300], Train Loss: 0.003201
Validation Loss: 0.00354356
Epoch [27/300], Train Loss: 0.003225
Validation Loss: 0.00354436
Epoch [28/300], Train Loss: 0.003176
Validation Loss: 0.00354357
Epoch [29/300], Train Loss: 0.003203
Validation Loss: 0.00354629
Epoch [30/300], Train Loss: 0.003302
Validation Loss: 0.00354943
Epoch [31/300], Train Loss: 0.003225
Validation Loss: 0.00353692
Epoch [32/300], Train Loss: 0.003193
Validation Loss: 0.00353553
Epoch [33/300], Train Loss: 0.003298
Validation Loss: 0.00353406
Epoch [34/300], Train Loss: 0.003209
Validation Loss: 0.00354070
Epoch [35/300], Train Loss: 0.003253
Validation Loss: 0.00356839
Epoch [36/300], Train Loss: 0.003164
Validation Loss: 0.00353439
Epoch [37/300], Train Loss: 0.003219
Validation Loss: 0.00355804
Epoch [38/300], Train Loss: 0.003212
Validation Loss: 0.00353336
Epoch [39/300], Train Loss: 0.003138
Validation Loss: 0.00353379
Epoch [40/300], Train Loss: 0.003159
Validation Loss: 0.00352752
Epoch [41/300], Train Loss: 0.003178
Validation Loss: 0.00355339
Epoch [42/300], Train Loss: 0.003191
Validation Loss: 0.00352495
Epoch [43/300], Train Loss: 0.003176
Validation Loss: 0.00352989
Epoch [44/300], Train Loss: 0.003326
Validation Loss: 0.00352801
Epoch [45/300], Train Loss: 0.003202
Validation Loss: 0.00352433
Epoch [46/300], Train Loss: 0.003193
Validation Loss: 0.00352052
Epoch [47/300], Train Loss: 0.003195
Validation Loss: 0.00352091
Epoch [48/300], Train Loss: 0.003225
Validation Loss: 0.00351580
Epoch [49/300], Train Loss: 0.003129
Validation Loss: 0.00351915
Epoch [50/300], Train Loss: 0.003159
Validation Loss: 0.00351726
Epoch [51/300], Train Loss: 0.003183
Validation Loss: 0.00352381
Epoch [52/300], Train Loss: 0.003184
Validation Loss: 0.00351472
Epoch [53/300], Train Loss: 0.003128
Validation Loss: 0.00352595
Epoch [54/300], Train Loss: 0.003136
Validation Loss: 0.00350724
Epoch [55/300], Train Loss: 0.003141
Validation Loss: 0.00351352
Epoch [56/300], Train Loss: 0.003163
Validation Loss: 0.00350413
Epoch [57/300], Train Loss: 0.003150
Validation Loss: 0.00350612
Epoch [58/300], Train Loss: 0.003798
Validation Loss: 0.00360753
Epoch [59/300], Train Loss: 0.003216
Validation Loss: 0.00358406
Epoch [60/300], Train Loss: 0.003320
Validation Loss: 0.00357047
Epoch [61/300], Train Loss: 0.003280
Validation Loss: 0.00354754
Epoch [62/300], Train Loss: 0.003180
Validation Loss: 0.00354168
Epoch [63/300], Train Loss: 0.003236
Validation Loss: 0.00353966
Epoch [64/300], Train Loss: 0.003203
Validation Loss: 0.00354178
Epoch [65/300], Train Loss: 0.003145
Validation Loss: 0.00352758
Epoch [66/300], Train Loss: 0.003212
Validation Loss: 0.00354454
Early stopping triggered

Evaluating model for: Laptop
Run 57/72 completed in 238.69 seconds with: {'MAE': np.float32(2.8320475), 'MSE': np.float32(24.989462), 'RMSE': np.float32(4.998946), 'SAE': np.float32(0.14284606), 'NDE': np.float32(0.6743161)}

Run 58/72: hidden=512, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Laptop
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.004481
Validation Loss: 0.00395686
Epoch [2/300], Train Loss: 0.003356
Validation Loss: 0.00365862
Epoch [3/300], Train Loss: 0.003293
Validation Loss: 0.00365564
Epoch [4/300], Train Loss: 0.003299
Validation Loss: 0.00363155
Epoch [5/300], Train Loss: 0.003284
Validation Loss: 0.00363236
Epoch [6/300], Train Loss: 0.003365
Validation Loss: 0.00362390
Epoch [7/300], Train Loss: 0.003321
Validation Loss: 0.00361734
Epoch [8/300], Train Loss: 0.003408
Validation Loss: 0.00361124
Epoch [9/300], Train Loss: 0.003278
Validation Loss: 0.00359953
Epoch [10/300], Train Loss: 0.003279
Validation Loss: 0.00360919
Epoch [11/300], Train Loss: 0.003315
Validation Loss: 0.00359107
Epoch [12/300], Train Loss: 0.003244
Validation Loss: 0.00369047
Epoch [13/300], Train Loss: 0.003281
Validation Loss: 0.00363608
Epoch [14/300], Train Loss: 0.003273
Validation Loss: 0.00356951
Epoch [15/300], Train Loss: 0.003276
Validation Loss: 0.00356464
Epoch [16/300], Train Loss: 0.003193
Validation Loss: 0.00357736
Epoch [17/300], Train Loss: 0.003297
Validation Loss: 0.00358705
Epoch [18/300], Train Loss: 0.003240
Validation Loss: 0.00356824
Epoch [19/300], Train Loss: 0.003213
Validation Loss: 0.00355682
Epoch [20/300], Train Loss: 0.003228
Validation Loss: 0.00355670
Epoch [21/300], Train Loss: 0.003209
Validation Loss: 0.00355640
Epoch [22/300], Train Loss: 0.003192
Validation Loss: 0.00355334
Epoch [23/300], Train Loss: 0.003256
Validation Loss: 0.00356853
Epoch [24/300], Train Loss: 0.003239
Validation Loss: 0.00355765
Epoch [25/300], Train Loss: 0.003231
Validation Loss: 0.00355836
Epoch [26/300], Train Loss: 0.003216
Validation Loss: 0.00355861
Epoch [27/300], Train Loss: 0.003237
Validation Loss: 0.00356014
Epoch [28/300], Train Loss: 0.003196
Validation Loss: 0.00354947
Epoch [29/300], Train Loss: 0.003223
Validation Loss: 0.00356193
Epoch [30/300], Train Loss: 0.003322
Validation Loss: 0.00355944
Epoch [31/300], Train Loss: 0.003253
Validation Loss: 0.00354327
Epoch [32/300], Train Loss: 0.003210
Validation Loss: 0.00354237
Epoch [33/300], Train Loss: 0.003312
Validation Loss: 0.00354502
Epoch [34/300], Train Loss: 0.003223
Validation Loss: 0.00355665
Epoch [35/300], Train Loss: 0.003262
Validation Loss: 0.00360075
Epoch [36/300], Train Loss: 0.003180
Validation Loss: 0.00354536
Epoch [37/300], Train Loss: 0.003223
Validation Loss: 0.00356800
Epoch [38/300], Train Loss: 0.003230
Validation Loss: 0.00354467
Epoch [39/300], Train Loss: 0.003156
Validation Loss: 0.00354082
Epoch [40/300], Train Loss: 0.003195
Validation Loss: 0.00356984
Epoch [41/300], Train Loss: 0.003212
Validation Loss: 0.00357923
Epoch [42/300], Train Loss: 0.003236
Validation Loss: 0.00355553
Epoch [43/300], Train Loss: 0.003213
Validation Loss: 0.00355370
Epoch [44/300], Train Loss: 0.003363
Validation Loss: 0.00353688
Epoch [45/300], Train Loss: 0.003229
Validation Loss: 0.00353617
Epoch [46/300], Train Loss: 0.003224
Validation Loss: 0.00353439
Epoch [47/300], Train Loss: 0.003222
Validation Loss: 0.00353901
Epoch [48/300], Train Loss: 0.003255
Validation Loss: 0.00353344
Epoch [49/300], Train Loss: 0.003166
Validation Loss: 0.00353291
Epoch [50/300], Train Loss: 0.003170
Validation Loss: 0.00353440
Epoch [51/300], Train Loss: 0.003197
Validation Loss: 0.00353569
Epoch [52/300], Train Loss: 0.003222
Validation Loss: 0.00353684
Epoch [53/300], Train Loss: 0.003160
Validation Loss: 0.00353182
Epoch [54/300], Train Loss: 0.003163
Validation Loss: 0.00353361
Epoch [55/300], Train Loss: 0.003166
Validation Loss: 0.00353587
Epoch [56/300], Train Loss: 0.003195
Validation Loss: 0.00353088
Epoch [57/300], Train Loss: 0.003176
Validation Loss: 0.00352874
Epoch [58/300], Train Loss: 0.003158
Validation Loss: 0.00353442
Epoch [59/300], Train Loss: 0.003140
Validation Loss: 0.00352599
Epoch [60/300], Train Loss: 0.003273
Validation Loss: 0.00353275
Epoch [61/300], Train Loss: 0.003245
Validation Loss: 0.00352808
Epoch [62/300], Train Loss: 0.003161
Validation Loss: 0.00352190
Epoch [63/300], Train Loss: 0.003234
Validation Loss: 0.00353515
Epoch [64/300], Train Loss: 0.003201
Validation Loss: 0.00353189
Epoch [65/300], Train Loss: 0.003136
Validation Loss: 0.00351755
Epoch [66/300], Train Loss: 0.003203
Validation Loss: 0.00354063
Epoch [67/300], Train Loss: 0.003242
Validation Loss: 0.00353390
Epoch [68/300], Train Loss: 0.003228
Validation Loss: 0.00354394
Epoch [69/300], Train Loss: 0.003176
Validation Loss: 0.00353686
Epoch [70/300], Train Loss: 0.003135
Validation Loss: 0.00352518
Epoch [71/300], Train Loss: 0.003165
Validation Loss: 0.00351192
Epoch [72/300], Train Loss: 0.003179
Validation Loss: 0.00353412
Epoch [73/300], Train Loss: 0.003194
Validation Loss: 0.00352123
Epoch [74/300], Train Loss: 0.003152
Validation Loss: 0.00351211
Epoch [75/300], Train Loss: 0.003230
Validation Loss: 0.00350801
Epoch [76/300], Train Loss: 0.003226
Validation Loss: 0.00350910
Epoch [77/300], Train Loss: 0.003159
Validation Loss: 0.00350717
Epoch [78/300], Train Loss: 0.003186
Validation Loss: 0.00350070
Epoch [79/300], Train Loss: 0.003203
Validation Loss: 0.00349248
Epoch [80/300], Train Loss: 0.003161
Validation Loss: 0.00349776
Epoch [81/300], Train Loss: 0.003167
Validation Loss: 0.00352636
Epoch [82/300], Train Loss: 0.003175
Validation Loss: 0.00348082
Epoch [83/300], Train Loss: 0.003163
Validation Loss: 0.00347911
Epoch [84/300], Train Loss: 0.003175
Validation Loss: 0.00348808
Epoch [85/300], Train Loss: 0.003132
Validation Loss: 0.00351511
Epoch [86/300], Train Loss: 0.003245
Validation Loss: 0.00347978
Epoch [87/300], Train Loss: 0.003161
Validation Loss: 0.00346170
Epoch [88/300], Train Loss: 0.003159
Validation Loss: 0.00345387
Epoch [89/300], Train Loss: 0.003114
Validation Loss: 0.00344780
Epoch [90/300], Train Loss: 0.003105
Validation Loss: 0.00344652
Epoch [91/300], Train Loss: 0.003161
Validation Loss: 0.00344894
Epoch [92/300], Train Loss: 0.003104
Validation Loss: 0.00345053
Epoch [93/300], Train Loss: 0.003080
Validation Loss: 0.00344353
Epoch [94/300], Train Loss: 0.003213
Validation Loss: 0.00349532
Epoch [95/300], Train Loss: 0.003277
Validation Loss: 0.00343999
Epoch [96/300], Train Loss: 0.003126
Validation Loss: 0.00346993
Epoch [97/300], Train Loss: 0.003103
Validation Loss: 0.00343412
Epoch [98/300], Train Loss: 0.003197
Validation Loss: 0.00343359
Epoch [99/300], Train Loss: 0.003210
Validation Loss: 0.00348130
Epoch [100/300], Train Loss: 0.003129
Validation Loss: 0.00342882
Epoch [101/300], Train Loss: 0.003100
Validation Loss: 0.00340910
Epoch [102/300], Train Loss: 0.003092
Validation Loss: 0.00339040
Epoch [103/300], Train Loss: 0.003095
Validation Loss: 0.00341152
Epoch [104/300], Train Loss: 0.003196
Validation Loss: 0.00342691
Epoch [105/300], Train Loss: 0.003134
Validation Loss: 0.00342998
Epoch [106/300], Train Loss: 0.003124
Validation Loss: 0.00346029
Epoch [107/300], Train Loss: 0.003130
Validation Loss: 0.00340072
Epoch [108/300], Train Loss: 0.003038
Validation Loss: 0.00336538
Epoch [109/300], Train Loss: 0.003039
Validation Loss: 0.00340348
Epoch [110/300], Train Loss: 0.003086
Validation Loss: 0.00336260
Epoch [111/300], Train Loss: 0.003159
Validation Loss: 0.00338521
Epoch [112/300], Train Loss: 0.003071
Validation Loss: 0.00334116
Epoch [113/300], Train Loss: 0.003130
Validation Loss: 0.00336795
Epoch [114/300], Train Loss: 0.003099
Validation Loss: 0.00332994
Epoch [115/300], Train Loss: 0.003065
Validation Loss: 0.00325196
Epoch [116/300], Train Loss: 0.003041
Validation Loss: 0.00324611
Epoch [117/300], Train Loss: 0.002915
Validation Loss: 0.00305460
Epoch [118/300], Train Loss: 0.002852
Validation Loss: 0.00300599
Epoch [119/300], Train Loss: 0.002796
Validation Loss: 0.00300665
Epoch [120/300], Train Loss: 0.002587
Validation Loss: 0.00267188
Epoch [121/300], Train Loss: 0.002548
Validation Loss: 0.00257160
Epoch [122/300], Train Loss: 0.002397
Validation Loss: 0.00248740
Epoch [123/300], Train Loss: 0.002423
Validation Loss: 0.00240236
Epoch [124/300], Train Loss: 0.002222
Validation Loss: 0.00220935
Epoch [125/300], Train Loss: 0.002126
Validation Loss: 0.00251634
Epoch [126/300], Train Loss: 0.002023
Validation Loss: 0.00206446
Epoch [127/300], Train Loss: 0.001948
Validation Loss: 0.00191153
Epoch [128/300], Train Loss: 0.001790
Validation Loss: 0.00189997
Epoch [129/300], Train Loss: 0.001826
Validation Loss: 0.00193242
Epoch [130/300], Train Loss: 0.001893
Validation Loss: 0.00181029
Epoch [131/300], Train Loss: 0.001747
Validation Loss: 0.00165933
Epoch [132/300], Train Loss: 0.001755
Validation Loss: 0.00185029
Epoch [133/300], Train Loss: 0.001602
Validation Loss: 0.00162986
Epoch [134/300], Train Loss: 0.001480
Validation Loss: 0.00155066
Epoch [135/300], Train Loss: 0.001388
Validation Loss: 0.00140510
Epoch [136/300], Train Loss: 0.001391
Validation Loss: 0.00125641
Epoch [137/300], Train Loss: 0.001252
Validation Loss: 0.00128897
Epoch [138/300], Train Loss: 0.001159
Validation Loss: 0.00120835
Epoch [139/300], Train Loss: 0.001163
Validation Loss: 0.00119999
Epoch [140/300], Train Loss: 0.001174
Validation Loss: 0.00115337
Epoch [141/300], Train Loss: 0.001090
Validation Loss: 0.00112562
Epoch [142/300], Train Loss: 0.001067
Validation Loss: 0.00109113
Epoch [143/300], Train Loss: 0.001054
Validation Loss: 0.00107983
Epoch [144/300], Train Loss: 0.001028
Validation Loss: 0.00102392
Epoch [145/300], Train Loss: 0.001026
Validation Loss: 0.00107054
Epoch [146/300], Train Loss: 0.001016
Validation Loss: 0.00100208
Epoch [147/300], Train Loss: 0.000989
Validation Loss: 0.00099333
Epoch [148/300], Train Loss: 0.000980
Validation Loss: 0.00094198
Epoch [149/300], Train Loss: 0.000969
Validation Loss: 0.00097191
Epoch [150/300], Train Loss: 0.000950
Validation Loss: 0.00094622
Epoch [151/300], Train Loss: 0.000907
Validation Loss: 0.00090688
Epoch [152/300], Train Loss: 0.000875
Validation Loss: 0.00091681
Epoch [153/300], Train Loss: 0.000890
Validation Loss: 0.00091233
Epoch [154/300], Train Loss: 0.000855
Validation Loss: 0.00085899
Epoch [155/300], Train Loss: 0.000829
Validation Loss: 0.00087801
Epoch [156/300], Train Loss: 0.000831
Validation Loss: 0.00088164
Epoch [157/300], Train Loss: 0.000835
Validation Loss: 0.00089785
Epoch [158/300], Train Loss: 0.000838
Validation Loss: 0.00085477
Epoch [159/300], Train Loss: 0.000876
Validation Loss: 0.00083478
Epoch [160/300], Train Loss: 0.000803
Validation Loss: 0.00093614
Epoch [161/300], Train Loss: 0.000777
Validation Loss: 0.00082975
Epoch [162/300], Train Loss: 0.000750
Validation Loss: 0.00086718
Epoch [163/300], Train Loss: 0.000814
Validation Loss: 0.00082930
Epoch [164/300], Train Loss: 0.000772
Validation Loss: 0.00092125
Epoch [165/300], Train Loss: 0.000885
Validation Loss: 0.00097195
Epoch [166/300], Train Loss: 0.000735
Validation Loss: 0.00076976
Epoch [167/300], Train Loss: 0.000713
Validation Loss: 0.00098537
Epoch [168/300], Train Loss: 0.000844
Validation Loss: 0.00090672
Epoch [169/300], Train Loss: 0.000698
Validation Loss: 0.00078401
Epoch [170/300], Train Loss: 0.000708
Validation Loss: 0.00086363
Epoch [171/300], Train Loss: 0.000690
Validation Loss: 0.00077623
Epoch [172/300], Train Loss: 0.000719
Validation Loss: 0.00074408
Epoch [173/300], Train Loss: 0.000631
Validation Loss: 0.00073250
Epoch [174/300], Train Loss: 0.000635
Validation Loss: 0.00074093
Epoch [175/300], Train Loss: 0.000624
Validation Loss: 0.00070000
Epoch [176/300], Train Loss: 0.000628
Validation Loss: 0.00071570
Epoch [177/300], Train Loss: 0.000589
Validation Loss: 0.00069076
Epoch [178/300], Train Loss: 0.000585
Validation Loss: 0.00066870
Epoch [179/300], Train Loss: 0.000576
Validation Loss: 0.00066882
Epoch [180/300], Train Loss: 0.000566
Validation Loss: 0.00067651
Epoch [181/300], Train Loss: 0.000570
Validation Loss: 0.00066597
Epoch [182/300], Train Loss: 0.000555
Validation Loss: 0.00065516
Epoch [183/300], Train Loss: 0.000553
Validation Loss: 0.00062275
Epoch [184/300], Train Loss: 0.000547
Validation Loss: 0.00063406
Epoch [185/300], Train Loss: 0.000543
Validation Loss: 0.00063392
Epoch [186/300], Train Loss: 0.000536
Validation Loss: 0.00063592
Epoch [187/300], Train Loss: 0.000536
Validation Loss: 0.00065058
Epoch [188/300], Train Loss: 0.000538
Validation Loss: 0.00060352
Epoch [189/300], Train Loss: 0.000541
Validation Loss: 0.00061784
Epoch [190/300], Train Loss: 0.000531
Validation Loss: 0.00062091
Epoch [191/300], Train Loss: 0.000532
Validation Loss: 0.00061552
Epoch [192/300], Train Loss: 0.000536
Validation Loss: 0.00059820
Epoch [193/300], Train Loss: 0.000523
Validation Loss: 0.00058341
Epoch [194/300], Train Loss: 0.000507
Validation Loss: 0.00060933
Epoch [195/300], Train Loss: 0.000524
Validation Loss: 0.00057856
Epoch [196/300], Train Loss: 0.000508
Validation Loss: 0.00059235
Epoch [197/300], Train Loss: 0.000497
Validation Loss: 0.00057768
Epoch [198/300], Train Loss: 0.000500
Validation Loss: 0.00056809
Epoch [199/300], Train Loss: 0.000498
Validation Loss: 0.00056534
Epoch [200/300], Train Loss: 0.000493
Validation Loss: 0.00056574
Epoch [201/300], Train Loss: 0.000486
Validation Loss: 0.00053665
Epoch [202/300], Train Loss: 0.000496
Validation Loss: 0.00054351
Epoch [203/300], Train Loss: 0.000485
Validation Loss: 0.00055531
Epoch [204/300], Train Loss: 0.000548
Validation Loss: 0.00052582
Epoch [205/300], Train Loss: 0.000518
Validation Loss: 0.00052829
Epoch [206/300], Train Loss: 0.000495
Validation Loss: 0.00053476
Epoch [207/300], Train Loss: 0.000497
Validation Loss: 0.00056369
Epoch [208/300], Train Loss: 0.000468
Validation Loss: 0.00055835
Epoch [209/300], Train Loss: 0.000491
Validation Loss: 0.00054094
Epoch [210/300], Train Loss: 0.000469
Validation Loss: 0.00055625
Epoch [211/300], Train Loss: 0.000469
Validation Loss: 0.00054172
Epoch [212/300], Train Loss: 0.000463
Validation Loss: 0.00051447
Epoch [213/300], Train Loss: 0.000462
Validation Loss: 0.00050300
Epoch [214/300], Train Loss: 0.000460
Validation Loss: 0.00054321
Epoch [215/300], Train Loss: 0.000471
Validation Loss: 0.00055145
Epoch [216/300], Train Loss: 0.000483
Validation Loss: 0.00055424
Epoch [217/300], Train Loss: 0.000461
Validation Loss: 0.00049722
Epoch [218/300], Train Loss: 0.000452
Validation Loss: 0.00050642
Epoch [219/300], Train Loss: 0.000458
Validation Loss: 0.00048208
Epoch [220/300], Train Loss: 0.000439
Validation Loss: 0.00048800
Epoch [221/300], Train Loss: 0.000431
Validation Loss: 0.00046854
Epoch [222/300], Train Loss: 0.000430
Validation Loss: 0.00047613
Epoch [223/300], Train Loss: 0.000447
Validation Loss: 0.00046189
Epoch [224/300], Train Loss: 0.000428
Validation Loss: 0.00045931
Epoch [225/300], Train Loss: 0.000436
Validation Loss: 0.00046582
Epoch [226/300], Train Loss: 0.000429
Validation Loss: 0.00045407
Epoch [227/300], Train Loss: 0.000429
Validation Loss: 0.00045016
Epoch [228/300], Train Loss: 0.000428
Validation Loss: 0.00046729
Epoch [229/300], Train Loss: 0.000426
Validation Loss: 0.00046617
Epoch [230/300], Train Loss: 0.000424
Validation Loss: 0.00046906
Epoch [231/300], Train Loss: 0.000414
Validation Loss: 0.00045113
Epoch [232/300], Train Loss: 0.000427
Validation Loss: 0.00044871
Epoch [233/300], Train Loss: 0.000430
Validation Loss: 0.00044528
Epoch [234/300], Train Loss: 0.000410
Validation Loss: 0.00043689
Epoch [235/300], Train Loss: 0.000425
Validation Loss: 0.00046064
Epoch [236/300], Train Loss: 0.000410
Validation Loss: 0.00044283
Epoch [237/300], Train Loss: 0.000410
Validation Loss: 0.00043853
Epoch [238/300], Train Loss: 0.000410
Validation Loss: 0.00043561
Epoch [239/300], Train Loss: 0.000407
Validation Loss: 0.00043314
Epoch [240/300], Train Loss: 0.000407
Validation Loss: 0.00044693
Epoch [241/300], Train Loss: 0.000418
Validation Loss: 0.00046843
Epoch [242/300], Train Loss: 0.000410
Validation Loss: 0.00042596
Epoch [243/300], Train Loss: 0.000408
Validation Loss: 0.00042033
Epoch [244/300], Train Loss: 0.000402
Validation Loss: 0.00042911
Epoch [245/300], Train Loss: 0.000398
Validation Loss: 0.00043813
Epoch [246/300], Train Loss: 0.000401
Validation Loss: 0.00041584
Epoch [247/300], Train Loss: 0.000414
Validation Loss: 0.00042350
Epoch [248/300], Train Loss: 0.000396
Validation Loss: 0.00041864
Epoch [249/300], Train Loss: 0.000396
Validation Loss: 0.00041176
Epoch [250/300], Train Loss: 0.000391
Validation Loss: 0.00042943
Epoch [251/300], Train Loss: 0.000411
Validation Loss: 0.00041459
Epoch [252/300], Train Loss: 0.000407
Validation Loss: 0.00041836
Epoch [253/300], Train Loss: 0.000390
Validation Loss: 0.00042421
Epoch [254/300], Train Loss: 0.000396
Validation Loss: 0.00043242
Epoch [255/300], Train Loss: 0.000392
Validation Loss: 0.00041221
Epoch [256/300], Train Loss: 0.000388
Validation Loss: 0.00040669
Epoch [257/300], Train Loss: 0.000387
Validation Loss: 0.00041166
Epoch [258/300], Train Loss: 0.000393
Validation Loss: 0.00041552
Epoch [259/300], Train Loss: 0.000387
Validation Loss: 0.00040224
Epoch [260/300], Train Loss: 0.000388
Validation Loss: 0.00044375
Epoch [261/300], Train Loss: 0.000387
Validation Loss: 0.00040053
Epoch [262/300], Train Loss: 0.000385
Validation Loss: 0.00043026
Epoch [263/300], Train Loss: 0.000383
Validation Loss: 0.00040607
Epoch [264/300], Train Loss: 0.000382
Validation Loss: 0.00040275
Epoch [265/300], Train Loss: 0.000394
Validation Loss: 0.00039891
Epoch [266/300], Train Loss: 0.000385
Validation Loss: 0.00041651
Epoch [267/300], Train Loss: 0.000387
Validation Loss: 0.00042460
Epoch [268/300], Train Loss: 0.000384
Validation Loss: 0.00039706
Epoch [269/300], Train Loss: 0.000390
Validation Loss: 0.00040712
Epoch [270/300], Train Loss: 0.000385
Validation Loss: 0.00040251
Epoch [271/300], Train Loss: 0.000374
Validation Loss: 0.00039725
Epoch [272/300], Train Loss: 0.000377
Validation Loss: 0.00039599
Epoch [273/300], Train Loss: 0.000378
Validation Loss: 0.00039309
Epoch [274/300], Train Loss: 0.000377
Validation Loss: 0.00040046
Epoch [275/300], Train Loss: 0.000375
Validation Loss: 0.00040357
Epoch [276/300], Train Loss: 0.000379
Validation Loss: 0.00039082
Epoch [277/300], Train Loss: 0.000375
Validation Loss: 0.00040006
Epoch [278/300], Train Loss: 0.000372
Validation Loss: 0.00039121
Epoch [279/300], Train Loss: 0.000371
Validation Loss: 0.00038733
Epoch [280/300], Train Loss: 0.000372
Validation Loss: 0.00039001
Epoch [281/300], Train Loss: 0.000367
Validation Loss: 0.00039277
Epoch [282/300], Train Loss: 0.000371
Validation Loss: 0.00038639
Epoch [283/300], Train Loss: 0.000363
Validation Loss: 0.00038582
Epoch [284/300], Train Loss: 0.000370
Validation Loss: 0.00038164
Epoch [285/300], Train Loss: 0.000366
Validation Loss: 0.00039055
Epoch [286/300], Train Loss: 0.000368
Validation Loss: 0.00038729
Epoch [287/300], Train Loss: 0.000366
Validation Loss: 0.00037901
Epoch [288/300], Train Loss: 0.000370
Validation Loss: 0.00038657
Epoch [289/300], Train Loss: 0.000358
Validation Loss: 0.00038121
Epoch [290/300], Train Loss: 0.000367
Validation Loss: 0.00037731
Epoch [291/300], Train Loss: 0.000362
Validation Loss: 0.00038949
Epoch [292/300], Train Loss: 0.000362
Validation Loss: 0.00037868
Epoch [293/300], Train Loss: 0.000368
Validation Loss: 0.00037768
Epoch [294/300], Train Loss: 0.000363
Validation Loss: 0.00038444
Epoch [295/300], Train Loss: 0.000362
Validation Loss: 0.00038755
Epoch [296/300], Train Loss: 0.000364
Validation Loss: 0.00038266
Epoch [297/300], Train Loss: 0.000353
Validation Loss: 0.00038323
Epoch [298/300], Train Loss: 0.000357
Validation Loss: 0.00037646
Epoch [299/300], Train Loss: 0.000357
Validation Loss: 0.00038820
Epoch [300/300], Train Loss: 0.000364
Validation Loss: 0.00038233

Evaluating model for: Laptop
Run 58/72 completed in 1370.27 seconds with: {'MAE': np.float32(0.7329326), 'MSE': np.float32(2.245274), 'RMSE': np.float32(1.4984238), 'SAE': np.float32(0.0044962717), 'NDE': np.float32(0.20212488)}

Run 59/72: hidden=512, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Laptop
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.004456
Validation Loss: 0.00394043
Epoch [2/300], Train Loss: 0.003342
Validation Loss: 0.00364980
Epoch [3/300], Train Loss: 0.003283
Validation Loss: 0.00365060
Epoch [4/300], Train Loss: 0.003293
Validation Loss: 0.00363079
Epoch [5/300], Train Loss: 0.003281
Validation Loss: 0.00363414
Epoch [6/300], Train Loss: 0.003364
Validation Loss: 0.00362637
Epoch [7/300], Train Loss: 0.003322
Validation Loss: 0.00362369
Epoch [8/300], Train Loss: 0.003412
Validation Loss: 0.00361843
Epoch [9/300], Train Loss: 0.003283
Validation Loss: 0.00360699
Epoch [10/300], Train Loss: 0.003282
Validation Loss: 0.00361149
Epoch [11/300], Train Loss: 0.003309
Validation Loss: 0.00360439
Epoch [12/300], Train Loss: 0.003236
Validation Loss: 0.00364017
Epoch [13/300], Train Loss: 0.003252
Validation Loss: 0.00359957
Epoch [14/300], Train Loss: 0.003266
Validation Loss: 0.00356304
Epoch [15/300], Train Loss: 0.003267
Validation Loss: 0.00355965
Epoch [16/300], Train Loss: 0.003180
Validation Loss: 0.00358953
Epoch [17/300], Train Loss: 0.003300
Validation Loss: 0.00358622
Epoch [18/300], Train Loss: 0.003235
Validation Loss: 0.00356626
Epoch [19/300], Train Loss: 0.003206
Validation Loss: 0.00355316
Epoch [20/300], Train Loss: 0.003225
Validation Loss: 0.00355380
Epoch [21/300], Train Loss: 0.003203
Validation Loss: 0.00355625
Epoch [22/300], Train Loss: 0.003189
Validation Loss: 0.00355093
Epoch [23/300], Train Loss: 0.003249
Validation Loss: 0.00356383
Epoch [24/300], Train Loss: 0.003231
Validation Loss: 0.00355478
Epoch [25/300], Train Loss: 0.003226
Validation Loss: 0.00355996
Epoch [26/300], Train Loss: 0.003211
Validation Loss: 0.00355348
Epoch [27/300], Train Loss: 0.003235
Validation Loss: 0.00355734
Epoch [28/300], Train Loss: 0.003190
Validation Loss: 0.00355092
Epoch [29/300], Train Loss: 0.003215
Validation Loss: 0.00355897
Epoch [30/300], Train Loss: 0.003315
Validation Loss: 0.00355764
Epoch [31/300], Train Loss: 0.003237
Validation Loss: 0.00354589
Epoch [32/300], Train Loss: 0.003202
Validation Loss: 0.00354701
Epoch [33/300], Train Loss: 0.003310
Validation Loss: 0.00354063
Epoch [34/300], Train Loss: 0.003223
Validation Loss: 0.00354820
Epoch [35/300], Train Loss: 0.003265
Validation Loss: 0.00357961
Epoch [36/300], Train Loss: 0.003178
Validation Loss: 0.00355163
Epoch [37/300], Train Loss: 0.003236
Validation Loss: 0.00357266
Epoch [38/300], Train Loss: 0.003233
Validation Loss: 0.00354703
Epoch [39/300], Train Loss: 0.003154
Validation Loss: 0.00354171
Epoch [40/300], Train Loss: 0.003175
Validation Loss: 0.00356858
Epoch [41/300], Train Loss: 0.003193
Validation Loss: 0.00355247
Epoch [42/300], Train Loss: 0.003212
Validation Loss: 0.00354225
Epoch [43/300], Train Loss: 0.003192
Validation Loss: 0.00355003
Early stopping triggered

Evaluating model for: Laptop
Run 59/72 completed in 234.78 seconds with: {'MAE': np.float32(2.8086753), 'MSE': np.float32(24.44537), 'RMSE': np.float32(4.944226), 'SAE': np.float32(0.1237628), 'NDE': np.float32(0.6669347)}

Run 60/72: hidden=512, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Laptop
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.004131
Validation Loss: 0.00378519
Epoch [2/300], Train Loss: 0.003322
Validation Loss: 0.00363474
Epoch [3/300], Train Loss: 0.003274
Validation Loss: 0.00364022
Epoch [4/300], Train Loss: 0.003297
Validation Loss: 0.00363730
Epoch [5/300], Train Loss: 0.003282
Validation Loss: 0.00363290
Epoch [6/300], Train Loss: 0.003367
Validation Loss: 0.00363259
Epoch [7/300], Train Loss: 0.003329
Validation Loss: 0.00362919
Epoch [8/300], Train Loss: 0.003420
Validation Loss: 0.00363032
Epoch [9/300], Train Loss: 0.003297
Validation Loss: 0.00362813
Epoch [10/300], Train Loss: 0.003305
Validation Loss: 0.00363857
Epoch [11/300], Train Loss: 0.003353
Validation Loss: 0.00361964
Epoch [12/300], Train Loss: 0.003284
Validation Loss: 0.00368060
Epoch [13/300], Train Loss: 0.003322
Validation Loss: 0.00371003
Epoch [14/300], Train Loss: 0.003314
Validation Loss: 0.00361619
Epoch [15/300], Train Loss: 0.003306
Validation Loss: 0.00360532
Epoch [16/300], Train Loss: 0.003203
Validation Loss: 0.00364318
Epoch [17/300], Train Loss: 0.003327
Validation Loss: 0.00359739
Epoch [18/300], Train Loss: 0.003256
Validation Loss: 0.00360119
Epoch [19/300], Train Loss: 0.003223
Validation Loss: 0.00356825
Epoch [20/300], Train Loss: 0.003234
Validation Loss: 0.00356604
Epoch [21/300], Train Loss: 0.003218
Validation Loss: 0.00357107
Epoch [22/300], Train Loss: 0.003200
Validation Loss: 0.00356267
Epoch [23/300], Train Loss: 0.003265
Validation Loss: 0.00357923
Epoch [24/300], Train Loss: 0.003240
Validation Loss: 0.00356208
Epoch [25/300], Train Loss: 0.003234
Validation Loss: 0.00356276
Epoch [26/300], Train Loss: 0.003219
Validation Loss: 0.00356944
Epoch [27/300], Train Loss: 0.003243
Validation Loss: 0.00357003
Epoch [28/300], Train Loss: 0.003202
Validation Loss: 0.00356206
Epoch [29/300], Train Loss: 0.003226
Validation Loss: 0.00357472
Epoch [30/300], Train Loss: 0.003321
Validation Loss: 0.00357893
Epoch [31/300], Train Loss: 0.003260
Validation Loss: 0.00355367
Epoch [32/300], Train Loss: 0.003210
Validation Loss: 0.00355650
Epoch [33/300], Train Loss: 0.003320
Validation Loss: 0.00355324
Epoch [34/300], Train Loss: 0.003229
Validation Loss: 0.00355897
Epoch [35/300], Train Loss: 0.003268
Validation Loss: 0.00360167
Epoch [36/300], Train Loss: 0.003185
Validation Loss: 0.00356748
Epoch [37/300], Train Loss: 0.003246
Validation Loss: 0.00358271
Epoch [38/300], Train Loss: 0.003241
Validation Loss: 0.00355718
Epoch [39/300], Train Loss: 0.003161
Validation Loss: 0.00355187
Epoch [40/300], Train Loss: 0.003181
Validation Loss: 0.00357982
Epoch [41/300], Train Loss: 0.003210
Validation Loss: 0.00357638
Epoch [42/300], Train Loss: 0.003234
Validation Loss: 0.00355689
Epoch [43/300], Train Loss: 0.003208
Validation Loss: 0.00356027
Epoch [44/300], Train Loss: 0.003359
Validation Loss: 0.00354811
Epoch [45/300], Train Loss: 0.003228
Validation Loss: 0.00354911
Epoch [46/300], Train Loss: 0.003224
Validation Loss: 0.00354654
Epoch [47/300], Train Loss: 0.003223
Validation Loss: 0.00354938
Epoch [48/300], Train Loss: 0.003260
Validation Loss: 0.00354325
Epoch [49/300], Train Loss: 0.003168
Validation Loss: 0.00354195
Epoch [50/300], Train Loss: 0.003176
Validation Loss: 0.00354290
Epoch [51/300], Train Loss: 0.003203
Validation Loss: 0.00354388
Epoch [52/300], Train Loss: 0.003222
Validation Loss: 0.00354591
Epoch [53/300], Train Loss: 0.003168
Validation Loss: 0.00355543
Epoch [54/300], Train Loss: 0.003187
Validation Loss: 0.00355625
Epoch [55/300], Train Loss: 0.003181
Validation Loss: 0.00354651
Epoch [56/300], Train Loss: 0.003204
Validation Loss: 0.00354244
Epoch [57/300], Train Loss: 0.003190
Validation Loss: 0.00353926
Epoch [58/300], Train Loss: 0.003167
Validation Loss: 0.00355201
Epoch [59/300], Train Loss: 0.003147
Validation Loss: 0.00353602
Epoch [60/300], Train Loss: 0.003277
Validation Loss: 0.00354535
Epoch [61/300], Train Loss: 0.003251
Validation Loss: 0.00353817
Epoch [62/300], Train Loss: 0.003176
Validation Loss: 0.00353755
Epoch [63/300], Train Loss: 0.003244
Validation Loss: 0.00355696
Epoch [64/300], Train Loss: 0.003208
Validation Loss: 0.00354467
Epoch [65/300], Train Loss: 0.003142
Validation Loss: 0.00353214
Epoch [66/300], Train Loss: 0.003212
Validation Loss: 0.00355645
Epoch [67/300], Train Loss: 0.003251
Validation Loss: 0.00354293
Epoch [68/300], Train Loss: 0.003246
Validation Loss: 0.00356279
Epoch [69/300], Train Loss: 0.003178
Validation Loss: 0.00355621
Epoch [70/300], Train Loss: 0.003133
Validation Loss: 0.00354069
Epoch [71/300], Train Loss: 0.003167
Validation Loss: 0.00352602
Epoch [72/300], Train Loss: 0.003179
Validation Loss: 0.00354817
Epoch [73/300], Train Loss: 0.003202
Validation Loss: 0.00352340
Epoch [74/300], Train Loss: 0.003146
Validation Loss: 0.00353057
Epoch [75/300], Train Loss: 0.003230
Validation Loss: 0.00352180
Epoch [76/300], Train Loss: 0.003231
Validation Loss: 0.00353847
Epoch [77/300], Train Loss: 0.003185
Validation Loss: 0.00353290
Epoch [78/300], Train Loss: 0.003202
Validation Loss: 0.00351970
Epoch [79/300], Train Loss: 0.003210
Validation Loss: 0.00351949
Epoch [80/300], Train Loss: 0.003162
Validation Loss: 0.00351560
Epoch [81/300], Train Loss: 0.003172
Validation Loss: 0.00357857
Epoch [82/300], Train Loss: 0.003190
Validation Loss: 0.00352261
Epoch [83/300], Train Loss: 0.003168
Validation Loss: 0.00350999
Epoch [84/300], Train Loss: 0.003186
Validation Loss: 0.00353682
Epoch [85/300], Train Loss: 0.003144
Validation Loss: 0.00351508
Epoch [86/300], Train Loss: 0.003257
Validation Loss: 0.00352150
Epoch [87/300], Train Loss: 0.003185
Validation Loss: 0.00350646
Epoch [88/300], Train Loss: 0.003168
Validation Loss: 0.00350129
Epoch [89/300], Train Loss: 0.003110
Validation Loss: 0.00351458
Epoch [90/300], Train Loss: 0.003117
Validation Loss: 0.00353004
Epoch [91/300], Train Loss: 0.003235
Validation Loss: 0.00354728
Epoch [92/300], Train Loss: 0.003146
Validation Loss: 0.00352362
Epoch [93/300], Train Loss: 0.003111
Validation Loss: 0.00350974
Epoch [94/300], Train Loss: 0.003239
Validation Loss: 0.00353639
Epoch [95/300], Train Loss: 0.003302
Validation Loss: 0.00350995
Epoch [96/300], Train Loss: 0.003124
Validation Loss: 0.00350528
Epoch [97/300], Train Loss: 0.003116
Validation Loss: 0.00350765
Epoch [98/300], Train Loss: 0.003219
Validation Loss: 0.00349876
Epoch [99/300], Train Loss: 0.003221
Validation Loss: 0.00351710
Epoch [100/300], Train Loss: 0.003153
Validation Loss: 0.00350770
Epoch [101/300], Train Loss: 0.003140
Validation Loss: 0.00349257
Epoch [102/300], Train Loss: 0.003117
Validation Loss: 0.00349802
Epoch [103/300], Train Loss: 0.003133
Validation Loss: 0.00350898
Epoch [104/300], Train Loss: 0.003189
Validation Loss: 0.00356843
Epoch [105/300], Train Loss: 0.003164
Validation Loss: 0.00348961
Epoch [106/300], Train Loss: 0.003114
Validation Loss: 0.00350509
Epoch [107/300], Train Loss: 0.003137
Validation Loss: 0.00350236
Epoch [108/300], Train Loss: 0.003085
Validation Loss: 0.00349964
Epoch [109/300], Train Loss: 0.003092
Validation Loss: 0.00349182
Epoch [110/300], Train Loss: 0.003130
Validation Loss: 0.00349790
Epoch [111/300], Train Loss: 0.003176
Validation Loss: 0.00348777
Epoch [112/300], Train Loss: 0.003147
Validation Loss: 0.00352136
Epoch [113/300], Train Loss: 0.003200
Validation Loss: 0.00348972
Epoch [114/300], Train Loss: 0.003182
Validation Loss: 0.00347893
Epoch [115/300], Train Loss: 0.003129
Validation Loss: 0.00349940
Epoch [116/300], Train Loss: 0.003164
Validation Loss: 0.00347458
Epoch [117/300], Train Loss: 0.003162
Validation Loss: 0.00351960
Epoch [118/300], Train Loss: 0.003218
Validation Loss: 0.00348557
Epoch [119/300], Train Loss: 0.003157
Validation Loss: 0.00351739
Epoch [120/300], Train Loss: 0.003145
Validation Loss: 0.00347591
Epoch [121/300], Train Loss: 0.003191
Validation Loss: 0.00348953
Epoch [122/300], Train Loss: 0.003140
Validation Loss: 0.00350298
Epoch [123/300], Train Loss: 0.003216
Validation Loss: 0.00346006
Epoch [124/300], Train Loss: 0.003064
Validation Loss: 0.00348893
Epoch [125/300], Train Loss: 0.003082
Validation Loss: 0.00345919
Epoch [126/300], Train Loss: 0.003128
Validation Loss: 0.00347231
Epoch [127/300], Train Loss: 0.003113
Validation Loss: 0.00347987
Epoch [128/300], Train Loss: 0.003146
Validation Loss: 0.00350002
Epoch [129/300], Train Loss: 0.003231
Validation Loss: 0.00345503
Epoch [130/300], Train Loss: 0.003267
Validation Loss: 0.00344183
Epoch [131/300], Train Loss: 0.003231
Validation Loss: 0.00350463
Epoch [132/300], Train Loss: 0.003105
Validation Loss: 0.00346835
Epoch [133/300], Train Loss: 0.003136
Validation Loss: 0.00346198
Epoch [134/300], Train Loss: 0.003090
Validation Loss: 0.00349560
Epoch [135/300], Train Loss: 0.003164
Validation Loss: 0.00347672
Epoch [136/300], Train Loss: 0.003157
Validation Loss: 0.00348530
Epoch [137/300], Train Loss: 0.003151
Validation Loss: 0.00348880
Epoch [138/300], Train Loss: 0.003058
Validation Loss: 0.00343594
Epoch [139/300], Train Loss: 0.003128
Validation Loss: 0.00345720
Epoch [140/300], Train Loss: 0.003164
Validation Loss: 0.00345514
Epoch [141/300], Train Loss: 0.003044
Validation Loss: 0.00350621
Epoch [142/300], Train Loss: 0.003161
Validation Loss: 0.00349111
Epoch [143/300], Train Loss: 0.003099
Validation Loss: 0.00345145
Epoch [144/300], Train Loss: 0.003114
Validation Loss: 0.00343947
Epoch [145/300], Train Loss: 0.003077
Validation Loss: 0.00351100
Epoch [146/300], Train Loss: 0.003120
Validation Loss: 0.00345626
Epoch [147/300], Train Loss: 0.003114
Validation Loss: 0.00342899
Epoch [148/300], Train Loss: 0.003063
Validation Loss: 0.00340763
Epoch [149/300], Train Loss: 0.003187
Validation Loss: 0.00349706
Epoch [150/300], Train Loss: 0.003090
Validation Loss: 0.00346596
Epoch [151/300], Train Loss: 0.003114
Validation Loss: 0.00342792
Epoch [152/300], Train Loss: 0.003035
Validation Loss: 0.00344485
Epoch [153/300], Train Loss: 0.003102
Validation Loss: 0.00342514
Epoch [154/300], Train Loss: 0.003110
Validation Loss: 0.00340961
Epoch [155/300], Train Loss: 0.003032
Validation Loss: 0.00347710
Epoch [156/300], Train Loss: 0.003189
Validation Loss: 0.00345304
Epoch [157/300], Train Loss: 0.003074
Validation Loss: 0.00340774
Epoch [158/300], Train Loss: 0.003097
Validation Loss: 0.00338690
Epoch [159/300], Train Loss: 0.003110
Validation Loss: 0.00338252
Epoch [160/300], Train Loss: 0.003191
Validation Loss: 0.00353221
Epoch [161/300], Train Loss: 0.003160
Validation Loss: 0.00346257
Epoch [162/300], Train Loss: 0.003069
Validation Loss: 0.00339948
Epoch [163/300], Train Loss: 0.003107
Validation Loss: 0.00346935
Epoch [164/300], Train Loss: 0.003097
Validation Loss: 0.00336882
Epoch [165/300], Train Loss: 0.003141
Validation Loss: 0.00342433
Epoch [166/300], Train Loss: 0.003061
Validation Loss: 0.00338026
Epoch [167/300], Train Loss: 0.003059
Validation Loss: 0.00344194
Epoch [168/300], Train Loss: 0.003036
Validation Loss: 0.00341672
Epoch [169/300], Train Loss: 0.003024
Validation Loss: 0.00340888
Epoch [170/300], Train Loss: 0.003014
Validation Loss: 0.00338085
Epoch [171/300], Train Loss: 0.003053
Validation Loss: 0.00337095
Epoch [172/300], Train Loss: 0.003047
Validation Loss: 0.00344546
Epoch [173/300], Train Loss: 0.003036
Validation Loss: 0.00342707
Epoch [174/300], Train Loss: 0.003077
Validation Loss: 0.00338767
Early stopping triggered

Evaluating model for: Laptop
Run 60/72 completed in 1209.02 seconds with: {'MAE': np.float32(2.4759495), 'MSE': np.float32(23.167797), 'RMSE': np.float32(4.813294), 'SAE': np.float32(0.059917968), 'NDE': np.float32(0.64927304)}

Run 61/72: hidden=512, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Laptop
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.004152
Validation Loss: 0.00468554
Epoch [2/300], Train Loss: 0.003156
Validation Loss: 0.00432572
Epoch [3/300], Train Loss: 0.003261
Validation Loss: 0.00443178
Epoch [4/300], Train Loss: 0.003192
Validation Loss: 0.00461074
Epoch [5/300], Train Loss: 0.003132
Validation Loss: 0.00445798
Epoch [6/300], Train Loss: 0.003166
Validation Loss: 0.00438247
Epoch [7/300], Train Loss: 0.003061
Validation Loss: 0.00439398
Epoch [8/300], Train Loss: 0.003071
Validation Loss: 0.00446825
Epoch [9/300], Train Loss: 0.003071
Validation Loss: 0.00444449
Epoch [10/300], Train Loss: 0.003057
Validation Loss: 0.00438571
Epoch [11/300], Train Loss: 0.003048
Validation Loss: 0.00440419
Epoch [12/300], Train Loss: 0.003094
Validation Loss: 0.00446387
Early stopping triggered

Evaluating model for: Laptop
Run 61/72 completed in 22.14 seconds with: {'MAE': np.float32(2.663555), 'MSE': np.float32(30.238409), 'RMSE': np.float32(5.498946), 'SAE': np.float32(0.11761079), 'NDE': np.float32(0.67452484)}

Run 62/72: hidden=512, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Laptop
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.004283
Validation Loss: 0.00465713
Epoch [2/300], Train Loss: 0.003178
Validation Loss: 0.00432726
Epoch [3/300], Train Loss: 0.003250
Validation Loss: 0.00450880
Epoch [4/300], Train Loss: 0.003206
Validation Loss: 0.00462092
Epoch [5/300], Train Loss: 0.003133
Validation Loss: 0.00442414
Epoch [6/300], Train Loss: 0.003189
Validation Loss: 0.00439787
Epoch [7/300], Train Loss: 0.003077
Validation Loss: 0.00443516
Epoch [8/300], Train Loss: 0.003094
Validation Loss: 0.00448632
Epoch [9/300], Train Loss: 0.003097
Validation Loss: 0.00445829
Epoch [10/300], Train Loss: 0.003088
Validation Loss: 0.00442179
Epoch [11/300], Train Loss: 0.003083
Validation Loss: 0.00444131
Epoch [12/300], Train Loss: 0.003139
Validation Loss: 0.00449015
Early stopping triggered

Evaluating model for: Laptop
Run 62/72 completed in 28.21 seconds with: {'MAE': np.float32(2.4948616), 'MSE': np.float32(30.578688), 'RMSE': np.float32(5.5298), 'SAE': np.float32(0.10476273), 'NDE': np.float32(0.67830944)}

Run 63/72: hidden=512, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Laptop
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.007086
Validation Loss: 0.00622968
Epoch [2/300], Train Loss: 0.003390
Validation Loss: 0.00446207
Epoch [3/300], Train Loss: 0.003502
Validation Loss: 0.00448549
Epoch [4/300], Train Loss: 0.003281
Validation Loss: 0.00483604
Epoch [5/300], Train Loss: 0.003195
Validation Loss: 0.00448698
Epoch [6/300], Train Loss: 0.003212
Validation Loss: 0.00438832
Epoch [7/300], Train Loss: 0.003109
Validation Loss: 0.00444782
Epoch [8/300], Train Loss: 0.003118
Validation Loss: 0.00454215
Epoch [9/300], Train Loss: 0.003127
Validation Loss: 0.00449471
Epoch [10/300], Train Loss: 0.003115
Validation Loss: 0.00444061
Epoch [11/300], Train Loss: 0.003111
Validation Loss: 0.00446718
Epoch [12/300], Train Loss: 0.003167
Validation Loss: 0.00452379
Epoch [13/300], Train Loss: 0.003141
Validation Loss: 0.00450791
Epoch [14/300], Train Loss: 0.003115
Validation Loss: 0.00442806
Epoch [15/300], Train Loss: 0.003103
Validation Loss: 0.00443894
Epoch [16/300], Train Loss: 0.003104
Validation Loss: 0.00453764
Early stopping triggered

Evaluating model for: Laptop
Run 63/72 completed in 44.06 seconds with: {'MAE': np.float32(2.5268915), 'MSE': np.float32(30.777853), 'RMSE': np.float32(5.547779), 'SAE': np.float32(0.122480966), 'NDE': np.float32(0.68051493)}

Run 64/72: hidden=512, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Laptop
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.004746
Validation Loss: 0.00489442
Epoch [2/300], Train Loss: 0.003166
Validation Loss: 0.00432579
Epoch [3/300], Train Loss: 0.003266
Validation Loss: 0.00448885
Epoch [4/300], Train Loss: 0.003205
Validation Loss: 0.00462424
Epoch [5/300], Train Loss: 0.003134
Validation Loss: 0.00442769
Epoch [6/300], Train Loss: 0.003189
Validation Loss: 0.00439849
Epoch [7/300], Train Loss: 0.003079
Validation Loss: 0.00443383
Epoch [8/300], Train Loss: 0.003097
Validation Loss: 0.00448807
Epoch [9/300], Train Loss: 0.003103
Validation Loss: 0.00446871
Epoch [10/300], Train Loss: 0.003094
Validation Loss: 0.00443087
Epoch [11/300], Train Loss: 0.003092
Validation Loss: 0.00444387
Epoch [12/300], Train Loss: 0.003150
Validation Loss: 0.00449415
Early stopping triggered

Evaluating model for: Laptop
Run 64/72 completed in 42.18 seconds with: {'MAE': np.float32(2.464427), 'MSE': np.float32(30.633457), 'RMSE': np.float32(5.53475), 'SAE': np.float32(0.09793099), 'NDE': np.float32(0.67891663)}

Run 65/72: hidden=512, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Laptop
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.008539
Validation Loss: 0.00703683
Epoch [2/300], Train Loss: 0.004196
Validation Loss: 0.00423825
Epoch [3/300], Train Loss: 0.003421
Validation Loss: 0.00438850
Epoch [4/300], Train Loss: 0.003278
Validation Loss: 0.00422053
Epoch [5/300], Train Loss: 0.003261
Validation Loss: 0.00432960
Epoch [6/300], Train Loss: 0.003216
Validation Loss: 0.00418962
Epoch [7/300], Train Loss: 0.003145
Validation Loss: 0.00416525
Epoch [8/300], Train Loss: 0.003218
Validation Loss: 0.00417653
Epoch [9/300], Train Loss: 0.003191
Validation Loss: 0.00417037
Epoch [10/300], Train Loss: 0.003233
Validation Loss: 0.00417911
Epoch [11/300], Train Loss: 0.003170
Validation Loss: 0.00414938
Epoch [12/300], Train Loss: 0.003144
Validation Loss: 0.00415307
Epoch [13/300], Train Loss: 0.003066
Validation Loss: 0.00414970
Epoch [14/300], Train Loss: 0.003102
Validation Loss: 0.00417636
Epoch [15/300], Train Loss: 0.003073
Validation Loss: 0.00414138
Epoch [16/300], Train Loss: 0.003153
Validation Loss: 0.00413334
Epoch [17/300], Train Loss: 0.003045
Validation Loss: 0.00412848
Epoch [18/300], Train Loss: 0.003110
Validation Loss: 0.00412537
Epoch [19/300], Train Loss: 0.003128
Validation Loss: 0.00412871
Epoch [20/300], Train Loss: 0.003037
Validation Loss: 0.00410256
Epoch [21/300], Train Loss: 0.003182
Validation Loss: 0.00411899
Epoch [22/300], Train Loss: 0.003086
Validation Loss: 0.00409378
Epoch [23/300], Train Loss: 0.003183
Validation Loss: 0.00409860
Epoch [24/300], Train Loss: 0.003179
Validation Loss: 0.00408981
Epoch [25/300], Train Loss: 0.003121
Validation Loss: 0.00407482
Epoch [26/300], Train Loss: 0.003026
Validation Loss: 0.00409695
Epoch [27/300], Train Loss: 0.003054
Validation Loss: 0.00407230
Epoch [28/300], Train Loss: 0.003022
Validation Loss: 0.00406868
Epoch [29/300], Train Loss: 0.003120
Validation Loss: 0.00407576
Epoch [30/300], Train Loss: 0.003113
Validation Loss: 0.00406234
Epoch [31/300], Train Loss: 0.003077
Validation Loss: 0.00409127
Epoch [32/300], Train Loss: 0.003103
Validation Loss: 0.00405792
Epoch [33/300], Train Loss: 0.003076
Validation Loss: 0.00406980
Epoch [34/300], Train Loss: 0.003059
Validation Loss: 0.00405395
Epoch [35/300], Train Loss: 0.003043
Validation Loss: 0.00407474
Epoch [36/300], Train Loss: 0.003093
Validation Loss: 0.00405571
Epoch [37/300], Train Loss: 0.003038
Validation Loss: 0.00405079
Epoch [38/300], Train Loss: 0.003023
Validation Loss: 0.00407862
Epoch [39/300], Train Loss: 0.003010
Validation Loss: 0.00404752
Epoch [40/300], Train Loss: 0.003146
Validation Loss: 0.00407536
Epoch [41/300], Train Loss: 0.003086
Validation Loss: 0.00404489
Epoch [42/300], Train Loss: 0.003084
Validation Loss: 0.00406773
Epoch [43/300], Train Loss: 0.003177
Validation Loss: 0.00404918
Epoch [44/300], Train Loss: 0.003148
Validation Loss: 0.00404326
Epoch [45/300], Train Loss: 0.003001
Validation Loss: 0.00405705
Epoch [46/300], Train Loss: 0.003080
Validation Loss: 0.00403914
Epoch [47/300], Train Loss: 0.002966
Validation Loss: 0.00404369
Epoch [48/300], Train Loss: 0.003071
Validation Loss: 0.00406683
Epoch [49/300], Train Loss: 0.003006
Validation Loss: 0.00403831
Epoch [50/300], Train Loss: 0.003029
Validation Loss: 0.00404944
Epoch [51/300], Train Loss: 0.003123
Validation Loss: 0.00406168
Epoch [52/300], Train Loss: 0.003102
Validation Loss: 0.00403491
Epoch [53/300], Train Loss: 0.003133
Validation Loss: 0.00406095
Epoch [54/300], Train Loss: 0.003029
Validation Loss: 0.00403352
Epoch [55/300], Train Loss: 0.003042
Validation Loss: 0.00404195
Epoch [56/300], Train Loss: 0.003063
Validation Loss: 0.00405780
Epoch [57/300], Train Loss: 0.003086
Validation Loss: 0.00403230
Epoch [58/300], Train Loss: 0.003091
Validation Loss: 0.00403709
Epoch [59/300], Train Loss: 0.003047
Validation Loss: 0.00403746
Epoch [60/300], Train Loss: 0.003111
Validation Loss: 0.00403701
Epoch [61/300], Train Loss: 0.003094
Validation Loss: 0.00402769
Epoch [62/300], Train Loss: 0.003026
Validation Loss: 0.00403540
Epoch [63/300], Train Loss: 0.003028
Validation Loss: 0.00403697
Epoch [64/300], Train Loss: 0.003068
Validation Loss: 0.00403003
Epoch [65/300], Train Loss: 0.003094
Validation Loss: 0.00402850
Epoch [66/300], Train Loss: 0.003118
Validation Loss: 0.00403069
Epoch [67/300], Train Loss: 0.003056
Validation Loss: 0.00402134
Epoch [68/300], Train Loss: 0.002961
Validation Loss: 0.00403517
Epoch [69/300], Train Loss: 0.003065
Validation Loss: 0.00403566
Epoch [70/300], Train Loss: 0.002977
Validation Loss: 0.00402155
Epoch [71/300], Train Loss: 0.003055
Validation Loss: 0.00402814
Epoch [72/300], Train Loss: 0.003052
Validation Loss: 0.00402371
Epoch [73/300], Train Loss: 0.003106
Validation Loss: 0.00402718
Epoch [74/300], Train Loss: 0.003047
Validation Loss: 0.00402233
Epoch [75/300], Train Loss: 0.003042
Validation Loss: 0.00401919
Epoch [76/300], Train Loss: 0.003027
Validation Loss: 0.00402046
Epoch [77/300], Train Loss: 0.003009
Validation Loss: 0.00402782
Epoch [78/300], Train Loss: 0.003044
Validation Loss: 0.00401573
Epoch [79/300], Train Loss: 0.003021
Validation Loss: 0.00401802
Epoch [80/300], Train Loss: 0.003039
Validation Loss: 0.00402415
Epoch [81/300], Train Loss: 0.003047
Validation Loss: 0.00401519
Epoch [82/300], Train Loss: 0.003082
Validation Loss: 0.00401757
Epoch [83/300], Train Loss: 0.002977
Validation Loss: 0.00402854
Epoch [84/300], Train Loss: 0.003063
Validation Loss: 0.00400953
Epoch [85/300], Train Loss: 0.003094
Validation Loss: 0.00401840
Epoch [86/300], Train Loss: 0.002992
Validation Loss: 0.00401249
Epoch [87/300], Train Loss: 0.003006
Validation Loss: 0.00401431
Epoch [88/300], Train Loss: 0.003038
Validation Loss: 0.00401549
Epoch [89/300], Train Loss: 0.003162
Validation Loss: 0.00400822
Epoch [90/300], Train Loss: 0.003115
Validation Loss: 0.00400784
Epoch [91/300], Train Loss: 0.003049
Validation Loss: 0.00401452
Epoch [92/300], Train Loss: 0.003038
Validation Loss: 0.00400459
Epoch [93/300], Train Loss: 0.003104
Validation Loss: 0.00400898
Epoch [94/300], Train Loss: 0.003032
Validation Loss: 0.00400194
Epoch [95/300], Train Loss: 0.003004
Validation Loss: 0.00401246
Epoch [96/300], Train Loss: 0.003039
Validation Loss: 0.00401890
Epoch [97/300], Train Loss: 0.003045
Validation Loss: 0.00399861
Epoch [98/300], Train Loss: 0.003004
Validation Loss: 0.00401157
Epoch [99/300], Train Loss: 0.003097
Validation Loss: 0.00400289
Epoch [100/300], Train Loss: 0.003049
Validation Loss: 0.00399676
Epoch [101/300], Train Loss: 0.003033
Validation Loss: 0.00401092
Epoch [102/300], Train Loss: 0.003125
Validation Loss: 0.00400108
Epoch [103/300], Train Loss: 0.003106
Validation Loss: 0.00399504
Epoch [104/300], Train Loss: 0.003014
Validation Loss: 0.00399730
Epoch [105/300], Train Loss: 0.003114
Validation Loss: 0.00400584
Epoch [106/300], Train Loss: 0.003031
Validation Loss: 0.00398762
Epoch [107/300], Train Loss: 0.003013
Validation Loss: 0.00398904
Epoch [108/300], Train Loss: 0.003025
Validation Loss: 0.00400996
Epoch [109/300], Train Loss: 0.003048
Validation Loss: 0.00398606
Epoch [110/300], Train Loss: 0.003133
Validation Loss: 0.00398986
Epoch [111/300], Train Loss: 0.002941
Validation Loss: 0.00398761
Epoch [112/300], Train Loss: 0.003095
Validation Loss: 0.00401093
Epoch [113/300], Train Loss: 0.003114
Validation Loss: 0.00397896
Epoch [114/300], Train Loss: 0.003011
Validation Loss: 0.00398054
Epoch [115/300], Train Loss: 0.003089
Validation Loss: 0.00399180
Epoch [116/300], Train Loss: 0.003046
Validation Loss: 0.00397577
Epoch [117/300], Train Loss: 0.003004
Validation Loss: 0.00397565
Epoch [118/300], Train Loss: 0.002976
Validation Loss: 0.00397106
Epoch [119/300], Train Loss: 0.003072
Validation Loss: 0.00398637
Epoch [120/300], Train Loss: 0.003015
Validation Loss: 0.00396766
Epoch [121/300], Train Loss: 0.003071
Validation Loss: 0.00396279
Epoch [122/300], Train Loss: 0.003006
Validation Loss: 0.00396502
Epoch [123/300], Train Loss: 0.003072
Validation Loss: 0.00397067
Epoch [124/300], Train Loss: 0.003000
Validation Loss: 0.00395313
Epoch [125/300], Train Loss: 0.003056
Validation Loss: 0.00398132
Epoch [126/300], Train Loss: 0.003080
Validation Loss: 0.00395166
Epoch [127/300], Train Loss: 0.002977
Validation Loss: 0.00394887
Epoch [128/300], Train Loss: 0.002968
Validation Loss: 0.00396815
Epoch [129/300], Train Loss: 0.002985
Validation Loss: 0.00394939
Epoch [130/300], Train Loss: 0.003007
Validation Loss: 0.00394111
Epoch [131/300], Train Loss: 0.002999
Validation Loss: 0.00394714
Epoch [132/300], Train Loss: 0.002980
Validation Loss: 0.00393167
Epoch [133/300], Train Loss: 0.002968
Validation Loss: 0.00393523
Epoch [134/300], Train Loss: 0.003022
Validation Loss: 0.00392330
Epoch [135/300], Train Loss: 0.002996
Validation Loss: 0.00391839
Epoch [136/300], Train Loss: 0.003037
Validation Loss: 0.00390446
Epoch [137/300], Train Loss: 0.002969
Validation Loss: 0.00390476
Epoch [138/300], Train Loss: 0.002995
Validation Loss: 0.00425381
Epoch [139/300], Train Loss: 0.003090
Validation Loss: 0.00391997
Epoch [140/300], Train Loss: 0.003034
Validation Loss: 0.00395657
Epoch [141/300], Train Loss: 0.003037
Validation Loss: 0.00408674
Epoch [142/300], Train Loss: 0.003139
Validation Loss: 0.00405075
Epoch [143/300], Train Loss: 0.003114
Validation Loss: 0.00401666
Epoch [144/300], Train Loss: 0.002988
Validation Loss: 0.00400434
Epoch [145/300], Train Loss: 0.003064
Validation Loss: 0.00399246
Epoch [146/300], Train Loss: 0.003073
Validation Loss: 0.00396169
Early stopping triggered

Evaluating model for: Laptop
Run 65/72 completed in 381.63 seconds with: {'MAE': np.float32(2.797021), 'MSE': np.float32(28.170937), 'RMSE': np.float32(5.30763), 'SAE': np.float32(0.046556085), 'NDE': np.float32(0.680799)}

Run 66/72: hidden=512, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Laptop
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.004910
Validation Loss: 0.00439960
Epoch [2/300], Train Loss: 0.003192
Validation Loss: 0.00429539
Epoch [3/300], Train Loss: 0.003260
Validation Loss: 0.00417354
Epoch [4/300], Train Loss: 0.003156
Validation Loss: 0.00426156
Epoch [5/300], Train Loss: 0.003196
Validation Loss: 0.00416038
Epoch [6/300], Train Loss: 0.003167
Validation Loss: 0.00414653
Epoch [7/300], Train Loss: 0.003118
Validation Loss: 0.00416983
Epoch [8/300], Train Loss: 0.003201
Validation Loss: 0.00418577
Epoch [9/300], Train Loss: 0.003185
Validation Loss: 0.00414708
Epoch [10/300], Train Loss: 0.003219
Validation Loss: 0.00416169
Epoch [11/300], Train Loss: 0.003161
Validation Loss: 0.00414992
Epoch [12/300], Train Loss: 0.003137
Validation Loss: 0.00415270
Epoch [13/300], Train Loss: 0.003067
Validation Loss: 0.00414803
Epoch [14/300], Train Loss: 0.003100
Validation Loss: 0.00418119
Epoch [15/300], Train Loss: 0.003074
Validation Loss: 0.00415788
Epoch [16/300], Train Loss: 0.003157
Validation Loss: 0.00414516
Epoch [17/300], Train Loss: 0.003052
Validation Loss: 0.00414203
Epoch [18/300], Train Loss: 0.003118
Validation Loss: 0.00414542
Epoch [19/300], Train Loss: 0.003140
Validation Loss: 0.00415030
Epoch [20/300], Train Loss: 0.003047
Validation Loss: 0.00412468
Epoch [21/300], Train Loss: 0.003191
Validation Loss: 0.00413697
Epoch [22/300], Train Loss: 0.003098
Validation Loss: 0.00411657
Epoch [23/300], Train Loss: 0.003191
Validation Loss: 0.00411672
Epoch [24/300], Train Loss: 0.003183
Validation Loss: 0.00410222
Epoch [25/300], Train Loss: 0.003122
Validation Loss: 0.00408222
Epoch [26/300], Train Loss: 0.003026
Validation Loss: 0.00409572
Epoch [27/300], Train Loss: 0.003049
Validation Loss: 0.00406765
Epoch [28/300], Train Loss: 0.003015
Validation Loss: 0.00407219
Epoch [29/300], Train Loss: 0.003113
Validation Loss: 0.00406039
Epoch [30/300], Train Loss: 0.003108
Validation Loss: 0.00407848
Epoch [31/300], Train Loss: 0.003085
Validation Loss: 0.00408803
Epoch [32/300], Train Loss: 0.003103
Validation Loss: 0.00406580
Epoch [33/300], Train Loss: 0.003078
Validation Loss: 0.00408547
Epoch [34/300], Train Loss: 0.003057
Validation Loss: 0.00406056
Epoch [35/300], Train Loss: 0.003038
Validation Loss: 0.00407339
Epoch [36/300], Train Loss: 0.003090
Validation Loss: 0.00406009
Epoch [37/300], Train Loss: 0.003033
Validation Loss: 0.00405350
Epoch [38/300], Train Loss: 0.003017
Validation Loss: 0.00408014
Epoch [39/300], Train Loss: 0.003003
Validation Loss: 0.00405390
Epoch [40/300], Train Loss: 0.003140
Validation Loss: 0.00408043
Epoch [41/300], Train Loss: 0.003077
Validation Loss: 0.00405267
Epoch [42/300], Train Loss: 0.003079
Validation Loss: 0.00406988
Epoch [43/300], Train Loss: 0.003173
Validation Loss: 0.00405730
Epoch [44/300], Train Loss: 0.003140
Validation Loss: 0.00404808
Epoch [45/300], Train Loss: 0.002994
Validation Loss: 0.00405994
Epoch [46/300], Train Loss: 0.003073
Validation Loss: 0.00404692
Epoch [47/300], Train Loss: 0.002962
Validation Loss: 0.00404960
Epoch [48/300], Train Loss: 0.003064
Validation Loss: 0.00407251
Epoch [49/300], Train Loss: 0.003001
Validation Loss: 0.00404668
Epoch [50/300], Train Loss: 0.003023
Validation Loss: 0.00405643
Epoch [51/300], Train Loss: 0.003116
Validation Loss: 0.00406894
Epoch [52/300], Train Loss: 0.003095
Validation Loss: 0.00404521
Epoch [53/300], Train Loss: 0.003125
Validation Loss: 0.00406665
Epoch [54/300], Train Loss: 0.003020
Validation Loss: 0.00404433
Epoch [55/300], Train Loss: 0.003035
Validation Loss: 0.00404764
Epoch [56/300], Train Loss: 0.003054
Validation Loss: 0.00406462
Epoch [57/300], Train Loss: 0.003079
Validation Loss: 0.00404313
Epoch [58/300], Train Loss: 0.003084
Validation Loss: 0.00404601
Epoch [59/300], Train Loss: 0.003039
Validation Loss: 0.00404634
Epoch [60/300], Train Loss: 0.003103
Validation Loss: 0.00404409
Epoch [61/300], Train Loss: 0.003086
Validation Loss: 0.00403559
Epoch [62/300], Train Loss: 0.003018
Validation Loss: 0.00404298
Epoch [63/300], Train Loss: 0.003022
Validation Loss: 0.00404287
Epoch [64/300], Train Loss: 0.003059
Validation Loss: 0.00403879
Epoch [65/300], Train Loss: 0.003085
Validation Loss: 0.00403938
Epoch [66/300], Train Loss: 0.003107
Validation Loss: 0.00404564
Epoch [67/300], Train Loss: 0.003046
Validation Loss: 0.00403475
Epoch [68/300], Train Loss: 0.002951
Validation Loss: 0.00404315
Epoch [69/300], Train Loss: 0.003054
Validation Loss: 0.00404431
Epoch [70/300], Train Loss: 0.002966
Validation Loss: 0.00403569
Epoch [71/300], Train Loss: 0.003042
Validation Loss: 0.00404108
Epoch [72/300], Train Loss: 0.003042
Validation Loss: 0.00403419
Epoch [73/300], Train Loss: 0.003092
Validation Loss: 0.00404027
Epoch [74/300], Train Loss: 0.003033
Validation Loss: 0.00403941
Epoch [75/300], Train Loss: 0.003027
Validation Loss: 0.00403355
Epoch [76/300], Train Loss: 0.003014
Validation Loss: 0.00402846
Epoch [77/300], Train Loss: 0.002992
Validation Loss: 0.00403520
Epoch [78/300], Train Loss: 0.003026
Validation Loss: 0.00403054
Epoch [79/300], Train Loss: 0.003001
Validation Loss: 0.00403229
Epoch [80/300], Train Loss: 0.003021
Validation Loss: 0.00403034
Epoch [81/300], Train Loss: 0.003028
Validation Loss: 0.00404078
Epoch [82/300], Train Loss: 0.003057
Validation Loss: 0.00402701
Epoch [83/300], Train Loss: 0.002957
Validation Loss: 0.00401891
Epoch [84/300], Train Loss: 0.003034
Validation Loss: 0.00403245
Epoch [85/300], Train Loss: 0.003076
Validation Loss: 0.00401667
Epoch [86/300], Train Loss: 0.002976
Validation Loss: 0.00405647
Epoch [87/300], Train Loss: 0.002983
Validation Loss: 0.00404329
Epoch [88/300], Train Loss: 0.003017
Validation Loss: 0.00404445
Epoch [89/300], Train Loss: 0.003128
Validation Loss: 0.00402542
Epoch [90/300], Train Loss: 0.003087
Validation Loss: 0.00402754
Epoch [91/300], Train Loss: 0.003019
Validation Loss: 0.00402373
Epoch [92/300], Train Loss: 0.003009
Validation Loss: 0.00403182
Epoch [93/300], Train Loss: 0.003081
Validation Loss: 0.00403704
Epoch [94/300], Train Loss: 0.003005
Validation Loss: 0.00404146
Epoch [95/300], Train Loss: 0.002964
Validation Loss: 0.00400832
Epoch [96/300], Train Loss: 0.003004
Validation Loss: 0.00400469
Epoch [97/300], Train Loss: 0.003007
Validation Loss: 0.00401201
Epoch [98/300], Train Loss: 0.002981
Validation Loss: 0.00401660
Epoch [99/300], Train Loss: 0.003042
Validation Loss: 0.00404117
Epoch [100/300], Train Loss: 0.003003
Validation Loss: 0.00401139
Epoch [101/300], Train Loss: 0.002996
Validation Loss: 0.00399079
Epoch [102/300], Train Loss: 0.003092
Validation Loss: 0.00398890
Epoch [103/300], Train Loss: 0.003054
Validation Loss: 0.00404567
Epoch [104/300], Train Loss: 0.002958
Validation Loss: 0.00401080
Epoch [105/300], Train Loss: 0.003064
Validation Loss: 0.00400163
Epoch [106/300], Train Loss: 0.002994
Validation Loss: 0.00399788
Epoch [107/300], Train Loss: 0.002959
Validation Loss: 0.00401288
Epoch [108/300], Train Loss: 0.002960
Validation Loss: 0.00407599
Epoch [109/300], Train Loss: 0.002994
Validation Loss: 0.00398262
Epoch [110/300], Train Loss: 0.003076
Validation Loss: 0.00398291
Epoch [111/300], Train Loss: 0.002878
Validation Loss: 0.00398750
Epoch [112/300], Train Loss: 0.003093
Validation Loss: 0.00401745
Epoch [113/300], Train Loss: 0.003102
Validation Loss: 0.00399559
Epoch [114/300], Train Loss: 0.002976
Validation Loss: 0.00400280
Epoch [115/300], Train Loss: 0.003039
Validation Loss: 0.00401024
Epoch [116/300], Train Loss: 0.002989
Validation Loss: 0.00398969
Epoch [117/300], Train Loss: 0.002964
Validation Loss: 0.00403046
Epoch [118/300], Train Loss: 0.002921
Validation Loss: 0.00397128
Epoch [119/300], Train Loss: 0.003025
Validation Loss: 0.00398547
Epoch [120/300], Train Loss: 0.002950
Validation Loss: 0.00402660
Epoch [121/300], Train Loss: 0.003006
Validation Loss: 0.00395755
Epoch [122/300], Train Loss: 0.002949
Validation Loss: 0.00393970
Epoch [123/300], Train Loss: 0.003001
Validation Loss: 0.00403376
Epoch [124/300], Train Loss: 0.002958
Validation Loss: 0.00399765
Epoch [125/300], Train Loss: 0.003056
Validation Loss: 0.00403789
Epoch [126/300], Train Loss: 0.003063
Validation Loss: 0.00398814
Epoch [127/300], Train Loss: 0.002946
Validation Loss: 0.00399438
Epoch [128/300], Train Loss: 0.002921
Validation Loss: 0.00400890
Epoch [129/300], Train Loss: 0.002921
Validation Loss: 0.00397632
Epoch [130/300], Train Loss: 0.002942
Validation Loss: 0.00402275
Epoch [131/300], Train Loss: 0.002946
Validation Loss: 0.00395308
Epoch [132/300], Train Loss: 0.002925
Validation Loss: 0.00396757
Early stopping triggered

Evaluating model for: Laptop
Run 66/72 completed in 463.85 seconds with: {'MAE': np.float32(2.724987), 'MSE': np.float32(27.36272), 'RMSE': np.float32(5.230939), 'SAE': np.float32(0.005409113), 'NDE': np.float32(0.67096204)}

Run 67/72: hidden=512, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Laptop
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.008937
Validation Loss: 0.00694694
Epoch [2/300], Train Loss: 0.004037
Validation Loss: 0.00417735
Epoch [3/300], Train Loss: 0.003484
Validation Loss: 0.00419560
Epoch [4/300], Train Loss: 0.003181
Validation Loss: 0.00434309
Epoch [5/300], Train Loss: 0.003275
Validation Loss: 0.00424105
Epoch [6/300], Train Loss: 0.003185
Validation Loss: 0.00415690
Epoch [7/300], Train Loss: 0.003145
Validation Loss: 0.00416042
Epoch [8/300], Train Loss: 0.003216
Validation Loss: 0.00419934
Epoch [9/300], Train Loss: 0.003196
Validation Loss: 0.00416639
Epoch [10/300], Train Loss: 0.003229
Validation Loss: 0.00417193
Epoch [11/300], Train Loss: 0.003176
Validation Loss: 0.00415940
Epoch [12/300], Train Loss: 0.003152
Validation Loss: 0.00416816
Epoch [13/300], Train Loss: 0.003081
Validation Loss: 0.00416478
Epoch [14/300], Train Loss: 0.003118
Validation Loss: 0.00419524
Epoch [15/300], Train Loss: 0.003091
Validation Loss: 0.00417492
Epoch [16/300], Train Loss: 0.003176
Validation Loss: 0.00416484
Early stopping triggered

Evaluating model for: Laptop
Run 67/72 completed in 72.90 seconds with: {'MAE': np.float32(2.4981167), 'MSE': np.float32(29.391815), 'RMSE': np.float32(5.421422), 'SAE': np.float32(0.027333902), 'NDE': np.float32(0.69539493)}

Run 68/72: hidden=512, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Laptop
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.003531
Validation Loss: 0.00415908
Epoch [2/300], Train Loss: 0.003131
Validation Loss: 0.00414463
Epoch [3/300], Train Loss: 0.003152
Validation Loss: 0.00421628
Epoch [4/300], Train Loss: 0.003125
Validation Loss: 0.00415870
Epoch [5/300], Train Loss: 0.003172
Validation Loss: 0.00414496
Epoch [6/300], Train Loss: 0.003145
Validation Loss: 0.00415559
Epoch [7/300], Train Loss: 0.003109
Validation Loss: 0.00417963
Epoch [8/300], Train Loss: 0.003188
Validation Loss: 0.00415680
Epoch [9/300], Train Loss: 0.003186
Validation Loss: 0.00414331
Epoch [10/300], Train Loss: 0.003233
Validation Loss: 0.00419020
Epoch [11/300], Train Loss: 0.003160
Validation Loss: 0.00414528
Epoch [12/300], Train Loss: 0.003135
Validation Loss: 0.00414926
Epoch [13/300], Train Loss: 0.003060
Validation Loss: 0.00415553
Epoch [14/300], Train Loss: 0.003102
Validation Loss: 0.00419167
Epoch [15/300], Train Loss: 0.003076
Validation Loss: 0.00415658
Epoch [16/300], Train Loss: 0.003158
Validation Loss: 0.00415208
Epoch [17/300], Train Loss: 0.003053
Validation Loss: 0.00415435
Epoch [18/300], Train Loss: 0.003124
Validation Loss: 0.00415662
Epoch [19/300], Train Loss: 0.003147
Validation Loss: 0.00416330
Early stopping triggered

Evaluating model for: Laptop
Run 68/72 completed in 114.97 seconds with: {'MAE': np.float32(2.403317), 'MSE': np.float32(29.257454), 'RMSE': np.float32(5.409016), 'SAE': np.float32(0.0060162744), 'NDE': np.float32(0.69380337)}

Run 69/72: hidden=512, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Laptop
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.003301
Validation Loss: 0.00331916
Epoch [2/300], Train Loss: 0.003240
Validation Loss: 0.00330827
Epoch [3/300], Train Loss: 0.003429
Validation Loss: 0.00330535
Epoch [4/300], Train Loss: 0.003249
Validation Loss: 0.00327220
Epoch [5/300], Train Loss: 0.003169
Validation Loss: 0.00327884
Epoch [6/300], Train Loss: 0.003332
Validation Loss: 0.00327685
Epoch [7/300], Train Loss: 0.002869
Validation Loss: 0.00327242
Epoch [8/300], Train Loss: 0.002963
Validation Loss: 0.00327296
Epoch [9/300], Train Loss: 0.003042
Validation Loss: 0.00327650
Epoch [10/300], Train Loss: 0.003159
Validation Loss: 0.00327884
Epoch [11/300], Train Loss: 0.003139
Validation Loss: 0.00328189
Epoch [12/300], Train Loss: 0.003182
Validation Loss: 0.00327886
Epoch [13/300], Train Loss: 0.003031
Validation Loss: 0.00328180
Epoch [14/300], Train Loss: 0.003381
Validation Loss: 0.00328253
Early stopping triggered

Evaluating model for: Laptop
Run 69/72 completed in 19.56 seconds with: {'MAE': np.float32(2.498828), 'MSE': np.float32(30.589071), 'RMSE': np.float32(5.530739), 'SAE': np.float32(0.12829784), 'NDE': np.float32(0.73327476)}

Run 70/72: hidden=512, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Laptop
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.003701
Validation Loss: 0.00340388
Epoch [2/300], Train Loss: 0.003278
Validation Loss: 0.00333385
Epoch [3/300], Train Loss: 0.003465
Validation Loss: 0.00334828
Epoch [4/300], Train Loss: 0.003278
Validation Loss: 0.00327830
Epoch [5/300], Train Loss: 0.003184
Validation Loss: 0.00328610
Epoch [6/300], Train Loss: 0.003354
Validation Loss: 0.00328672
Epoch [7/300], Train Loss: 0.002880
Validation Loss: 0.00327470
Epoch [8/300], Train Loss: 0.002978
Validation Loss: 0.00327486
Epoch [9/300], Train Loss: 0.003060
Validation Loss: 0.00327540
Epoch [10/300], Train Loss: 0.003174
Validation Loss: 0.00327643
Epoch [11/300], Train Loss: 0.003159
Validation Loss: 0.00327999
Epoch [12/300], Train Loss: 0.003205
Validation Loss: 0.00327808
Epoch [13/300], Train Loss: 0.003054
Validation Loss: 0.00327766
Epoch [14/300], Train Loss: 0.003407
Validation Loss: 0.00327797
Epoch [15/300], Train Loss: 0.003127
Validation Loss: 0.00328300
Epoch [16/300], Train Loss: 0.003425
Validation Loss: 0.00328468
Epoch [17/300], Train Loss: 0.002950
Validation Loss: 0.00328150
Early stopping triggered

Evaluating model for: Laptop
Run 70/72 completed in 31.79 seconds with: {'MAE': np.float32(2.5948904), 'MSE': np.float32(31.116127), 'RMSE': np.float32(5.578183), 'SAE': np.float32(0.15818562), 'NDE': np.float32(0.73956513)}

Run 71/72: hidden=512, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Laptop
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.003421
Validation Loss: 0.00329055
Epoch [2/300], Train Loss: 0.003272
Validation Loss: 0.00337583
Epoch [3/300], Train Loss: 0.003467
Validation Loss: 0.00329494
Epoch [4/300], Train Loss: 0.003245
Validation Loss: 0.00327633
Epoch [5/300], Train Loss: 0.003191
Validation Loss: 0.00329213
Epoch [6/300], Train Loss: 0.003349
Validation Loss: 0.00327459
Epoch [7/300], Train Loss: 0.002895
Validation Loss: 0.00327861
Epoch [8/300], Train Loss: 0.002986
Validation Loss: 0.00327363
Epoch [9/300], Train Loss: 0.003059
Validation Loss: 0.00327541
Epoch [10/300], Train Loss: 0.003176
Validation Loss: 0.00327929
Epoch [11/300], Train Loss: 0.003169
Validation Loss: 0.00328025
Epoch [12/300], Train Loss: 0.003208
Validation Loss: 0.00327375
Epoch [13/300], Train Loss: 0.003062
Validation Loss: 0.00327602
Epoch [14/300], Train Loss: 0.003414
Validation Loss: 0.00327384
Epoch [15/300], Train Loss: 0.003133
Validation Loss: 0.00327678
Epoch [16/300], Train Loss: 0.003433
Validation Loss: 0.00327718
Epoch [17/300], Train Loss: 0.002954
Validation Loss: 0.00327520
Epoch [18/300], Train Loss: 0.003496
Validation Loss: 0.00327767
Early stopping triggered

Evaluating model for: Laptop
Run 71/72 completed in 42.81 seconds with: {'MAE': np.float32(2.4116402), 'MSE': np.float32(30.802422), 'RMSE': np.float32(5.549993), 'SAE': np.float32(0.10995873), 'NDE': np.float32(0.73582757)}

Run 72/72: hidden=512, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Laptop
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.009315
Validation Loss: 0.00727462
Epoch [2/300], Train Loss: 0.006040
Validation Loss: 0.00447338
Epoch [3/300], Train Loss: 0.003975
Validation Loss: 0.00329723
Epoch [4/300], Train Loss: 0.003488
Validation Loss: 0.00382153
Epoch [5/300], Train Loss: 0.003551
Validation Loss: 0.00335114
Epoch [6/300], Train Loss: 0.003383
Validation Loss: 0.00331387
Epoch [7/300], Train Loss: 0.002897
Validation Loss: 0.00336408
Epoch [8/300], Train Loss: 0.003059
Validation Loss: 0.00334810
Epoch [9/300], Train Loss: 0.003122
Validation Loss: 0.00329953
Epoch [10/300], Train Loss: 0.003218
Validation Loss: 0.00328798
Epoch [11/300], Train Loss: 0.003185
Validation Loss: 0.00329188
Epoch [12/300], Train Loss: 0.003233
Validation Loss: 0.00328897
Epoch [13/300], Train Loss: 0.003080
Validation Loss: 0.00328655
Epoch [14/300], Train Loss: 0.003451
Validation Loss: 0.00328962
Epoch [15/300], Train Loss: 0.003158
Validation Loss: 0.00328635
Epoch [16/300], Train Loss: 0.003460
Validation Loss: 0.00328813
Epoch [17/300], Train Loss: 0.002983
Validation Loss: 0.00328979
Epoch [18/300], Train Loss: 0.003522
Validation Loss: 0.00328619
Epoch [19/300], Train Loss: 0.003179
Validation Loss: 0.00328610
Epoch [20/300], Train Loss: 0.003163
Validation Loss: 0.00328607
Epoch [21/300], Train Loss: 0.003697
Validation Loss: 0.00328660
Epoch [22/300], Train Loss: 0.003619
Validation Loss: 0.00329093
Epoch [23/300], Train Loss: 0.003259
Validation Loss: 0.00329710
Epoch [24/300], Train Loss: 0.003065
Validation Loss: 0.00329034
Epoch [25/300], Train Loss: 0.003318
Validation Loss: 0.00328814
Epoch [26/300], Train Loss: 0.003331
Validation Loss: 0.00329568
Epoch [27/300], Train Loss: 0.003271
Validation Loss: 0.00328870
Epoch [28/300], Train Loss: 0.003255
Validation Loss: 0.00328622
Epoch [29/300], Train Loss: 0.003075
Validation Loss: 0.00329235
Epoch [30/300], Train Loss: 0.003237
Validation Loss: 0.00328682
Early stopping triggered

Evaluating model for: Laptop
Run 72/72 completed in 97.18 seconds with: {'MAE': np.float32(2.62865), 'MSE': np.float32(31.372387), 'RMSE': np.float32(5.6011057), 'SAE': np.float32(0.16019954), 'NDE': np.float32(0.7426042)}
    hidden_size  seq_length  stride  num_layers  eval_result
26          256         120    0.25           4     0.431432
24          256         120    0.25           2     0.645670
25          256         120    0.25           3     0.671556
0           128         120    0.25           2     0.689107
57          512         360    0.25           3     0.732933
..          ...         ...     ...         ...          ...
31          256         120    0.50           5     3.044510
55          512         120    0.50           5     3.063426
29          256         120    0.50           3     3.072502
5           128         120    0.50           3     3.109029
53          512         120    0.50           3     3.113505

[72 rows x 5 columns]
