Using device: cuda

Run 1/72: hidden=128, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Microwave
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.000666
Validation Loss: 0.00056133
Epoch [2/300], Train Loss: 0.000631
Validation Loss: 0.00055470
Epoch [3/300], Train Loss: 0.000616
Validation Loss: 0.00054448
Epoch [4/300], Train Loss: 0.000595
Validation Loss: 0.00052564
Epoch [5/300], Train Loss: 0.000555
Validation Loss: 0.00053589
Epoch [6/300], Train Loss: 0.000514
Validation Loss: 0.00050418
Epoch [7/300], Train Loss: 0.000504
Validation Loss: 0.00051156
Epoch [8/300], Train Loss: 0.000497
Validation Loss: 0.00050753
Epoch [9/300], Train Loss: 0.000492
Validation Loss: 0.00049988
Epoch [10/300], Train Loss: 0.000492
Validation Loss: 0.00051869
Epoch [11/300], Train Loss: 0.000498
Validation Loss: 0.00050228
Epoch [12/300], Train Loss: 0.000490
Validation Loss: 0.00050685
Epoch [13/300], Train Loss: 0.000482
Validation Loss: 0.00050695
Epoch [14/300], Train Loss: 0.000488
Validation Loss: 0.00051217
Epoch [15/300], Train Loss: 0.000485
Validation Loss: 0.00050743
Epoch [16/300], Train Loss: 0.000479
Validation Loss: 0.00050258
Epoch [17/300], Train Loss: 0.000476
Validation Loss: 0.00052091
Epoch [18/300], Train Loss: 0.000477
Validation Loss: 0.00049674
Epoch [19/300], Train Loss: 0.000471
Validation Loss: 0.00049710
Epoch [20/300], Train Loss: 0.000471
Validation Loss: 0.00052856
Epoch [21/300], Train Loss: 0.000468
Validation Loss: 0.00049918
Epoch [22/300], Train Loss: 0.000463
Validation Loss: 0.00051021
Epoch [23/300], Train Loss: 0.000456
Validation Loss: 0.00049080
Epoch [24/300], Train Loss: 0.000460
Validation Loss: 0.00049046
Epoch [25/300], Train Loss: 0.000452
Validation Loss: 0.00048420
Epoch [26/300], Train Loss: 0.000449
Validation Loss: 0.00048551
Epoch [27/300], Train Loss: 0.000451
Validation Loss: 0.00049426
Epoch [28/300], Train Loss: 0.000450
Validation Loss: 0.00049100
Epoch [29/300], Train Loss: 0.000440
Validation Loss: 0.00051922
Epoch [30/300], Train Loss: 0.000435
Validation Loss: 0.00050146
Epoch [31/300], Train Loss: 0.000435
Validation Loss: 0.00048764
Epoch [32/300], Train Loss: 0.000426
Validation Loss: 0.00051483
Epoch [33/300], Train Loss: 0.000416
Validation Loss: 0.00051485
Epoch [34/300], Train Loss: 0.000411
Validation Loss: 0.00054450
Epoch [35/300], Train Loss: 0.000442
Validation Loss: 0.00052840
Early stopping triggered

Evaluating model for: Microwave
Run 1/72 completed in 864.14 seconds with: {'MAE': np.float32(11.975544), 'MSE': np.float32(7140.586), 'RMSE': np.float32(84.50199), 'SAE': np.float32(0.32758912), 'NDE': np.float32(0.7339355)}

Run 2/72: hidden=128, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Microwave
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.000731
Validation Loss: 0.00057765
Epoch [2/300], Train Loss: 0.000653
Validation Loss: 0.00057204
Epoch [3/300], Train Loss: 0.000641
Validation Loss: 0.00056240
Epoch [4/300], Train Loss: 0.000619
Validation Loss: 0.00054263
Epoch [5/300], Train Loss: 0.000566
Validation Loss: 0.00054822
Epoch [6/300], Train Loss: 0.000526
Validation Loss: 0.00052908
Epoch [7/300], Train Loss: 0.000519
Validation Loss: 0.00053486
Epoch [8/300], Train Loss: 0.000511
Validation Loss: 0.00053766
Epoch [9/300], Train Loss: 0.000501
Validation Loss: 0.00054822
Epoch [10/300], Train Loss: 0.000501
Validation Loss: 0.00054217
Epoch [11/300], Train Loss: 0.000509
Validation Loss: 0.00055575
Epoch [12/300], Train Loss: 0.000500
Validation Loss: 0.00056756
Epoch [13/300], Train Loss: 0.000486
Validation Loss: 0.00056058
Epoch [14/300], Train Loss: 0.000493
Validation Loss: 0.00057452
Epoch [15/300], Train Loss: 0.000485
Validation Loss: 0.00059699
Epoch [16/300], Train Loss: 0.000485
Validation Loss: 0.00055356
Early stopping triggered

Evaluating model for: Microwave
Run 2/72 completed in 404.34 seconds with: {'MAE': np.float32(12.000519), 'MSE': np.float32(8916.609), 'RMSE': np.float32(94.4278), 'SAE': np.float32(0.33517563), 'NDE': np.float32(0.82014495)}

Run 3/72: hidden=128, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Microwave
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.000649
Validation Loss: 0.00056573
Epoch [2/300], Train Loss: 0.000636
Validation Loss: 0.00056232
Epoch [3/300], Train Loss: 0.000624
Validation Loss: 0.00054833
Epoch [4/300], Train Loss: 0.000578
Validation Loss: 0.00055008
Epoch [5/300], Train Loss: 0.000538
Validation Loss: 0.00053638
Epoch [6/300], Train Loss: 0.000506
Validation Loss: 0.00053694
Epoch [7/300], Train Loss: 0.000510
Validation Loss: 0.00053931
Epoch [8/300], Train Loss: 0.000504
Validation Loss: 0.00054373
Epoch [9/300], Train Loss: 0.000495
Validation Loss: 0.00055384
Epoch [10/300], Train Loss: 0.000497
Validation Loss: 0.00054641
Epoch [11/300], Train Loss: 0.000504
Validation Loss: 0.00056406
Epoch [12/300], Train Loss: 0.000495
Validation Loss: 0.00057123
Epoch [13/300], Train Loss: 0.000483
Validation Loss: 0.00056341
Epoch [14/300], Train Loss: 0.000490
Validation Loss: 0.00058446
Epoch [15/300], Train Loss: 0.000483
Validation Loss: 0.00060375
Early stopping triggered

Evaluating model for: Microwave
Run 3/72 completed in 388.15 seconds with: {'MAE': np.float32(11.544539), 'MSE': np.float32(8488.895), 'RMSE': np.float32(92.1352), 'SAE': np.float32(0.030384397), 'NDE': np.float32(0.80023205)}

Run 4/72: hidden=128, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Microwave
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.000711
Validation Loss: 0.00057612
Epoch [2/300], Train Loss: 0.000654
Validation Loss: 0.00057274
Epoch [3/300], Train Loss: 0.000644
Validation Loss: 0.00056453
Epoch [4/300], Train Loss: 0.000619
Validation Loss: 0.00055398
Epoch [5/300], Train Loss: 0.000581
Validation Loss: 0.00054932
Epoch [6/300], Train Loss: 0.000525
Validation Loss: 0.00055054
Epoch [7/300], Train Loss: 0.000523
Validation Loss: 0.00054783
Epoch [8/300], Train Loss: 0.000512
Validation Loss: 0.00056574
Epoch [9/300], Train Loss: 0.000502
Validation Loss: 0.00056671
Epoch [10/300], Train Loss: 0.000505
Validation Loss: 0.00055524
Epoch [11/300], Train Loss: 0.000511
Validation Loss: 0.00057700
Epoch [12/300], Train Loss: 0.000503
Validation Loss: 0.00058634
Epoch [13/300], Train Loss: 0.000489
Validation Loss: 0.00057582
Epoch [14/300], Train Loss: 0.000496
Validation Loss: 0.00058587
Epoch [15/300], Train Loss: 0.000490
Validation Loss: 0.00060988
Epoch [16/300], Train Loss: 0.000490
Validation Loss: 0.00057242
Epoch [17/300], Train Loss: 0.000484
Validation Loss: 0.00059076
Early stopping triggered

Evaluating model for: Microwave
Run 4/72 completed in 441.20 seconds with: {'MAE': np.float32(9.839746), 'MSE': np.float32(8486.453), 'RMSE': np.float32(92.12195), 'SAE': np.float32(0.23710415), 'NDE': np.float32(0.8001163)}

Run 5/72: hidden=128, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Microwave
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.000645
Validation Loss: 0.00096987
Epoch [2/300], Train Loss: 0.000630
Validation Loss: 0.00095308
Epoch [3/300], Train Loss: 0.000617
Validation Loss: 0.00093151
Epoch [4/300], Train Loss: 0.000606
Validation Loss: 0.00090528
Epoch [5/300], Train Loss: 0.000587
Validation Loss: 0.00085130
Epoch [6/300], Train Loss: 0.000551
Validation Loss: 0.00071791
Epoch [7/300], Train Loss: 0.000515
Validation Loss: 0.00063135
Epoch [8/300], Train Loss: 0.000505
Validation Loss: 0.00072234
Epoch [9/300], Train Loss: 0.000503
Validation Loss: 0.00068257
Epoch [10/300], Train Loss: 0.000501
Validation Loss: 0.00064093
Epoch [11/300], Train Loss: 0.000496
Validation Loss: 0.00066695
Epoch [12/300], Train Loss: 0.000489
Validation Loss: 0.00066692
Epoch [13/300], Train Loss: 0.000487
Validation Loss: 0.00067955
Epoch [14/300], Train Loss: 0.000485
Validation Loss: 0.00063426
Epoch [15/300], Train Loss: 0.000489
Validation Loss: 0.00068103
Epoch [16/300], Train Loss: 0.000471
Validation Loss: 0.00078783
Epoch [17/300], Train Loss: 0.000492
Validation Loss: 0.00068020
Early stopping triggered

Evaluating model for: Microwave
Run 5/72 completed in 213.11 seconds with: {'MAE': np.float32(11.32428), 'MSE': np.float32(7225.292), 'RMSE': np.float32(85.00172), 'SAE': np.float32(0.04354154), 'NDE': np.float32(0.9374251)}

Run 6/72: hidden=128, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Microwave
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.001018
Validation Loss: 0.00101265
Epoch [2/300], Train Loss: 0.000681
Validation Loss: 0.00100759
Epoch [3/300], Train Loss: 0.000673
Validation Loss: 0.00099898
Epoch [4/300], Train Loss: 0.000666
Validation Loss: 0.00099377
Epoch [5/300], Train Loss: 0.000656
Validation Loss: 0.00098193
Epoch [6/300], Train Loss: 0.000647
Validation Loss: 0.00096429
Epoch [7/300], Train Loss: 0.000634
Validation Loss: 0.00092722
Epoch [8/300], Train Loss: 0.000617
Validation Loss: 0.00083879
Epoch [9/300], Train Loss: 0.000587
Validation Loss: 0.00074942
Epoch [10/300], Train Loss: 0.000568
Validation Loss: 0.00069237
Epoch [11/300], Train Loss: 0.000568
Validation Loss: 0.00069689
Epoch [12/300], Train Loss: 0.000535
Validation Loss: 0.00068844
Epoch [13/300], Train Loss: 0.000530
Validation Loss: 0.00066585
Epoch [14/300], Train Loss: 0.000520
Validation Loss: 0.00066411
Epoch [15/300], Train Loss: 0.000525
Validation Loss: 0.00068350
Epoch [16/300], Train Loss: 0.000507
Validation Loss: 0.00079086
Epoch [17/300], Train Loss: 0.000524
Validation Loss: 0.00067128
Epoch [18/300], Train Loss: 0.000508
Validation Loss: 0.00071034
Epoch [19/300], Train Loss: 0.000510
Validation Loss: 0.00066960
Epoch [20/300], Train Loss: 0.000507
Validation Loss: 0.00066799
Epoch [21/300], Train Loss: 0.000513
Validation Loss: 0.00067643
Epoch [22/300], Train Loss: 0.000508
Validation Loss: 0.00067393
Epoch [23/300], Train Loss: 0.000501
Validation Loss: 0.00063959
Epoch [24/300], Train Loss: 0.000501
Validation Loss: 0.00070026
Epoch [25/300], Train Loss: 0.000499
Validation Loss: 0.00069726
Epoch [26/300], Train Loss: 0.000500
Validation Loss: 0.00065590
Epoch [27/300], Train Loss: 0.000498
Validation Loss: 0.00064079
Epoch [28/300], Train Loss: 0.000496
Validation Loss: 0.00071480
Epoch [29/300], Train Loss: 0.000495
Validation Loss: 0.00067283
Epoch [30/300], Train Loss: 0.000483
Validation Loss: 0.00066590
Epoch [31/300], Train Loss: 0.000485
Validation Loss: 0.00073040
Epoch [32/300], Train Loss: 0.000490
Validation Loss: 0.00065462
Epoch [33/300], Train Loss: 0.000476
Validation Loss: 0.00065740
Early stopping triggered

Evaluating model for: Microwave
Run 6/72 completed in 409.18 seconds with: {'MAE': np.float32(11.644752), 'MSE': np.float32(6957.0767), 'RMSE': np.float32(83.409096), 'SAE': np.float32(0.063027), 'NDE': np.float32(0.9198607)}

Run 7/72: hidden=128, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Microwave
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.000720
Validation Loss: 0.00098112
Epoch [2/300], Train Loss: 0.000643
Validation Loss: 0.00097973
Epoch [3/300], Train Loss: 0.000639
Validation Loss: 0.00097786
Epoch [4/300], Train Loss: 0.000638
Validation Loss: 0.00097802
Epoch [5/300], Train Loss: 0.000632
Validation Loss: 0.00097659
Epoch [6/300], Train Loss: 0.000629
Validation Loss: 0.00097003
Epoch [7/300], Train Loss: 0.000623
Validation Loss: 0.00094566
Epoch [8/300], Train Loss: 0.000615
Validation Loss: 0.00092326
Epoch [9/300], Train Loss: 0.000596
Validation Loss: 0.00088750
Epoch [10/300], Train Loss: 0.000578
Validation Loss: 0.00080382
Epoch [11/300], Train Loss: 0.000542
Validation Loss: 0.00077308
Epoch [12/300], Train Loss: 0.000532
Validation Loss: 0.00072974
Epoch [13/300], Train Loss: 0.000523
Validation Loss: 0.00069764
Epoch [14/300], Train Loss: 0.000512
Validation Loss: 0.00068762
Epoch [15/300], Train Loss: 0.000515
Validation Loss: 0.00075584
Epoch [16/300], Train Loss: 0.000498
Validation Loss: 0.00083463
Epoch [17/300], Train Loss: 0.000514
Validation Loss: 0.00072164
Epoch [18/300], Train Loss: 0.000500
Validation Loss: 0.00073796
Epoch [19/300], Train Loss: 0.000502
Validation Loss: 0.00071377
Epoch [20/300], Train Loss: 0.000498
Validation Loss: 0.00071718
Epoch [21/300], Train Loss: 0.000504
Validation Loss: 0.00073071
Epoch [22/300], Train Loss: 0.000501
Validation Loss: 0.00071616
Epoch [23/300], Train Loss: 0.000491
Validation Loss: 0.00068702
Epoch [24/300], Train Loss: 0.000493
Validation Loss: 0.00074246
Epoch [25/300], Train Loss: 0.000490
Validation Loss: 0.00074276
Epoch [26/300], Train Loss: 0.000490
Validation Loss: 0.00071146
Epoch [27/300], Train Loss: 0.000490
Validation Loss: 0.00071808
Epoch [28/300], Train Loss: 0.000487
Validation Loss: 0.00075872
Epoch [29/300], Train Loss: 0.000485
Validation Loss: 0.00073332
Epoch [30/300], Train Loss: 0.000474
Validation Loss: 0.00072268
Epoch [31/300], Train Loss: 0.000475
Validation Loss: 0.00074728
Epoch [32/300], Train Loss: 0.000482
Validation Loss: 0.00071651
Epoch [33/300], Train Loss: 0.000475
Validation Loss: 0.00072067
Early stopping triggered

Evaluating model for: Microwave
Run 7/72 completed in 412.36 seconds with: {'MAE': np.float32(9.354935), 'MSE': np.float32(7443.269), 'RMSE': np.float32(86.27438), 'SAE': np.float32(0.23826995), 'NDE': np.float32(0.95145994)}

Run 8/72: hidden=128, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Microwave
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.000654
Validation Loss: 0.00098055
Epoch [2/300], Train Loss: 0.000638
Validation Loss: 0.00097691
Epoch [3/300], Train Loss: 0.000634
Validation Loss: 0.00097545
Epoch [4/300], Train Loss: 0.000632
Validation Loss: 0.00097296
Epoch [5/300], Train Loss: 0.000627
Validation Loss: 0.00096060
Epoch [6/300], Train Loss: 0.000613
Validation Loss: 0.00090761
Epoch [7/300], Train Loss: 0.000580
Validation Loss: 0.00075113
Epoch [8/300], Train Loss: 0.000534
Validation Loss: 0.00083617
Epoch [9/300], Train Loss: 0.000529
Validation Loss: 0.00075959
Epoch [10/300], Train Loss: 0.000530
Validation Loss: 0.00068125
Epoch [11/300], Train Loss: 0.000537
Validation Loss: 0.00067282
Epoch [12/300], Train Loss: 0.000507
Validation Loss: 0.00069851
Epoch [13/300], Train Loss: 0.000501
Validation Loss: 0.00068881
Epoch [14/300], Train Loss: 0.000499
Validation Loss: 0.00066129
Epoch [15/300], Train Loss: 0.000503
Validation Loss: 0.00073024
Epoch [16/300], Train Loss: 0.000488
Validation Loss: 0.00080808
Epoch [17/300], Train Loss: 0.000504
Validation Loss: 0.00071658
Epoch [18/300], Train Loss: 0.000491
Validation Loss: 0.00072747
Epoch [19/300], Train Loss: 0.000489
Validation Loss: 0.00071506
Epoch [20/300], Train Loss: 0.000488
Validation Loss: 0.00071332
Epoch [21/300], Train Loss: 0.000495
Validation Loss: 0.00071984
Epoch [22/300], Train Loss: 0.000489
Validation Loss: 0.00070354
Epoch [23/300], Train Loss: 0.000485
Validation Loss: 0.00068375
Epoch [24/300], Train Loss: 0.000484
Validation Loss: 0.00071392
Early stopping triggered

Evaluating model for: Microwave
Run 8/72 completed in 302.86 seconds with: {'MAE': np.float32(8.663637), 'MSE': np.float32(7409.0107), 'RMSE': np.float32(86.07561), 'SAE': np.float32(0.23825385), 'NDE': np.float32(0.9492672)}

Run 9/72: hidden=128, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Microwave
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.000632
Validation Loss: 0.00090465
Epoch [2/300], Train Loss: 0.000652
Validation Loss: 0.00089894
Epoch [3/300], Train Loss: 0.000626
Validation Loss: 0.00089404
Epoch [4/300], Train Loss: 0.000612
Validation Loss: 0.00088771
Epoch [5/300], Train Loss: 0.000597
Validation Loss: 0.00088028
Epoch [6/300], Train Loss: 0.000590
Validation Loss: 0.00086837
Epoch [7/300], Train Loss: 0.000581
Validation Loss: 0.00085121
Epoch [8/300], Train Loss: 0.000577
Validation Loss: 0.00082520
Epoch [9/300], Train Loss: 0.000548
Validation Loss: 0.00079180
Epoch [10/300], Train Loss: 0.000507
Validation Loss: 0.00076882
Epoch [11/300], Train Loss: 0.000484
Validation Loss: 0.00072131
Epoch [12/300], Train Loss: 0.000478
Validation Loss: 0.00071500
Epoch [13/300], Train Loss: 0.000469
Validation Loss: 0.00074955
Epoch [14/300], Train Loss: 0.000463
Validation Loss: 0.00070778
Epoch [15/300], Train Loss: 0.000534
Validation Loss: 0.00074229
Epoch [16/300], Train Loss: 0.000473
Validation Loss: 0.00073879
Epoch [17/300], Train Loss: 0.000464
Validation Loss: 0.00070111
Epoch [18/300], Train Loss: 0.000457
Validation Loss: 0.00069857
Epoch [19/300], Train Loss: 0.000456
Validation Loss: 0.00070171
Epoch [20/300], Train Loss: 0.000455
Validation Loss: 0.00069344
Epoch [21/300], Train Loss: 0.000452
Validation Loss: 0.00070485
Epoch [22/300], Train Loss: 0.000450
Validation Loss: 0.00072486
Epoch [23/300], Train Loss: 0.000458
Validation Loss: 0.00069319
Epoch [24/300], Train Loss: 0.000453
Validation Loss: 0.00072516
Epoch [25/300], Train Loss: 0.000457
Validation Loss: 0.00070367
Epoch [26/300], Train Loss: 0.000446
Validation Loss: 0.00070156
Epoch [27/300], Train Loss: 0.000446
Validation Loss: 0.00070317
Epoch [28/300], Train Loss: 0.000445
Validation Loss: 0.00069266
Epoch [29/300], Train Loss: 0.000557
Validation Loss: 0.00068780
Epoch [30/300], Train Loss: 0.000475
Validation Loss: 0.00069336
Epoch [31/300], Train Loss: 0.000438
Validation Loss: 0.00069017
Epoch [32/300], Train Loss: 0.000434
Validation Loss: 0.00070172
Epoch [33/300], Train Loss: 0.000438
Validation Loss: 0.00069139
Epoch [34/300], Train Loss: 0.000442
Validation Loss: 0.00073486
Epoch [35/300], Train Loss: 0.000438
Validation Loss: 0.00068959
Epoch [36/300], Train Loss: 0.000433
Validation Loss: 0.00069391
Epoch [37/300], Train Loss: 0.000428
Validation Loss: 0.00069457
Epoch [38/300], Train Loss: 0.000422
Validation Loss: 0.00069425
Epoch [39/300], Train Loss: 0.000423
Validation Loss: 0.00068924
Early stopping triggered

Evaluating model for: Microwave
Run 9/72 completed in 338.32 seconds with: {'MAE': np.float32(9.787418), 'MSE': np.float32(7414.087), 'RMSE': np.float32(86.105095), 'SAE': np.float32(0.15263481), 'NDE': np.float32(0.796857)}

Run 10/72: hidden=128, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Microwave
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.000638
Validation Loss: 0.00090953
Epoch [2/300], Train Loss: 0.000656
Validation Loss: 0.00090673
Epoch [3/300], Train Loss: 0.000630
Validation Loss: 0.00090156
Epoch [4/300], Train Loss: 0.000615
Validation Loss: 0.00089058
Epoch [5/300], Train Loss: 0.000596
Validation Loss: 0.00087549
Epoch [6/300], Train Loss: 0.000589
Validation Loss: 0.00086077
Epoch [7/300], Train Loss: 0.000576
Validation Loss: 0.00083018
Epoch [8/300], Train Loss: 0.000561
Validation Loss: 0.00078692
Epoch [9/300], Train Loss: 0.000537
Validation Loss: 0.00076304
Epoch [10/300], Train Loss: 0.000505
Validation Loss: 0.00077031
Epoch [11/300], Train Loss: 0.000487
Validation Loss: 0.00075904
Epoch [12/300], Train Loss: 0.000483
Validation Loss: 0.00075040
Epoch [13/300], Train Loss: 0.000477
Validation Loss: 0.00076625
Epoch [14/300], Train Loss: 0.000472
Validation Loss: 0.00074200
Epoch [15/300], Train Loss: 0.000545
Validation Loss: 0.00076725
Epoch [16/300], Train Loss: 0.000481
Validation Loss: 0.00076314
Epoch [17/300], Train Loss: 0.000481
Validation Loss: 0.00073124
Epoch [18/300], Train Loss: 0.000467
Validation Loss: 0.00073895
Epoch [19/300], Train Loss: 0.000468
Validation Loss: 0.00072676
Epoch [20/300], Train Loss: 0.000468
Validation Loss: 0.00072571
Epoch [21/300], Train Loss: 0.000462
Validation Loss: 0.00073297
Epoch [22/300], Train Loss: 0.000459
Validation Loss: 0.00073960
Epoch [23/300], Train Loss: 0.000465
Validation Loss: 0.00071967
Epoch [24/300], Train Loss: 0.000464
Validation Loss: 0.00074209
Epoch [25/300], Train Loss: 0.000468
Validation Loss: 0.00072848
Epoch [26/300], Train Loss: 0.000455
Validation Loss: 0.00072716
Epoch [27/300], Train Loss: 0.000452
Validation Loss: 0.00071925
Epoch [28/300], Train Loss: 0.000454
Validation Loss: 0.00071461
Epoch [29/300], Train Loss: 0.000565
Validation Loss: 0.00071097
Epoch [30/300], Train Loss: 0.000519
Validation Loss: 0.00072452
Epoch [31/300], Train Loss: 0.000448
Validation Loss: 0.00071966
Epoch [32/300], Train Loss: 0.000444
Validation Loss: 0.00072404
Epoch [33/300], Train Loss: 0.000445
Validation Loss: 0.00071325
Epoch [34/300], Train Loss: 0.000448
Validation Loss: 0.00074131
Epoch [35/300], Train Loss: 0.000440
Validation Loss: 0.00070893
Epoch [36/300], Train Loss: 0.000427
Validation Loss: 0.00071109
Epoch [37/300], Train Loss: 0.000425
Validation Loss: 0.00070273
Epoch [38/300], Train Loss: 0.000419
Validation Loss: 0.00070431
Epoch [39/300], Train Loss: 0.000418
Validation Loss: 0.00069656
Epoch [40/300], Train Loss: 0.000471
Validation Loss: 0.00069941
Epoch [41/300], Train Loss: 0.000501
Validation Loss: 0.00068734
Epoch [42/300], Train Loss: 0.000435
Validation Loss: 0.00069562
Epoch [43/300], Train Loss: 0.000414
Validation Loss: 0.00067770
Epoch [44/300], Train Loss: 0.000428
Validation Loss: 0.00067213
Epoch [45/300], Train Loss: 0.000463
Validation Loss: 0.00067185
Epoch [46/300], Train Loss: 0.000426
Validation Loss: 0.00066630
Epoch [47/300], Train Loss: 0.000401
Validation Loss: 0.00066109
Epoch [48/300], Train Loss: 0.000403
Validation Loss: 0.00067107
Epoch [49/300], Train Loss: 0.000395
Validation Loss: 0.00065953
Epoch [50/300], Train Loss: 0.000399
Validation Loss: 0.00067753
Epoch [51/300], Train Loss: 0.000407
Validation Loss: 0.00066263
Epoch [52/300], Train Loss: 0.000391
Validation Loss: 0.00066486
Epoch [53/300], Train Loss: 0.000391
Validation Loss: 0.00065373
Epoch [54/300], Train Loss: 0.000390
Validation Loss: 0.00065068
Epoch [55/300], Train Loss: 0.000394
Validation Loss: 0.00066732
Epoch [56/300], Train Loss: 0.000389
Validation Loss: 0.00065897
Epoch [57/300], Train Loss: 0.000390
Validation Loss: 0.00065281
Epoch [58/300], Train Loss: 0.000392
Validation Loss: 0.00064893
Epoch [59/300], Train Loss: 0.000386
Validation Loss: 0.00064609
Epoch [60/300], Train Loss: 0.000384
Validation Loss: 0.00064305
Epoch [61/300], Train Loss: 0.000378
Validation Loss: 0.00063741
Epoch [62/300], Train Loss: 0.000378
Validation Loss: 0.00063436
Epoch [63/300], Train Loss: 0.000379
Validation Loss: 0.00064963
Epoch [64/300], Train Loss: 0.000373
Validation Loss: 0.00063857
Epoch [65/300], Train Loss: 0.000380
Validation Loss: 0.00063629
Epoch [66/300], Train Loss: 0.000377
Validation Loss: 0.00062509
Epoch [67/300], Train Loss: 0.000372
Validation Loss: 0.00064010
Epoch [68/300], Train Loss: 0.000379
Validation Loss: 0.00062634
Epoch [69/300], Train Loss: 0.000402
Validation Loss: 0.00064135
Epoch [70/300], Train Loss: 0.000400
Validation Loss: 0.00062160
Epoch [71/300], Train Loss: 0.000372
Validation Loss: 0.00064223
Epoch [72/300], Train Loss: 0.000367
Validation Loss: 0.00062211
Epoch [73/300], Train Loss: 0.000368
Validation Loss: 0.00063830
Epoch [74/300], Train Loss: 0.000406
Validation Loss: 0.00060662
Epoch [75/300], Train Loss: 0.000369
Validation Loss: 0.00062210
Epoch [76/300], Train Loss: 0.000363
Validation Loss: 0.00061835
Epoch [77/300], Train Loss: 0.000358
Validation Loss: 0.00061174
Epoch [78/300], Train Loss: 0.000360
Validation Loss: 0.00061566
Epoch [79/300], Train Loss: 0.000357
Validation Loss: 0.00063338
Epoch [80/300], Train Loss: 0.000355
Validation Loss: 0.00060523
Epoch [81/300], Train Loss: 0.000355
Validation Loss: 0.00060547
Epoch [82/300], Train Loss: 0.000355
Validation Loss: 0.00060504
Epoch [83/300], Train Loss: 0.000364
Validation Loss: 0.00060676
Epoch [84/300], Train Loss: 0.000350
Validation Loss: 0.00060355
Epoch [85/300], Train Loss: 0.000356
Validation Loss: 0.00060537
Epoch [86/300], Train Loss: 0.000350
Validation Loss: 0.00059824
Epoch [87/300], Train Loss: 0.000353
Validation Loss: 0.00060340
Epoch [88/300], Train Loss: 0.000346
Validation Loss: 0.00061176
Epoch [89/300], Train Loss: 0.000352
Validation Loss: 0.00064338
Epoch [90/300], Train Loss: 0.000403
Validation Loss: 0.00059049
Epoch [91/300], Train Loss: 0.000379
Validation Loss: 0.00059862
Epoch [92/300], Train Loss: 0.000347
Validation Loss: 0.00059885
Epoch [93/300], Train Loss: 0.000347
Validation Loss: 0.00059296
Epoch [94/300], Train Loss: 0.000359
Validation Loss: 0.00062326
Epoch [95/300], Train Loss: 0.000355
Validation Loss: 0.00060013
Epoch [96/300], Train Loss: 0.000342
Validation Loss: 0.00060691
Epoch [97/300], Train Loss: 0.000343
Validation Loss: 0.00057966
Epoch [98/300], Train Loss: 0.000342
Validation Loss: 0.00060391
Epoch [99/300], Train Loss: 0.000352
Validation Loss: 0.00060952
Epoch [100/300], Train Loss: 0.000341
Validation Loss: 0.00059655
Epoch [101/300], Train Loss: 0.000340
Validation Loss: 0.00059649
Epoch [102/300], Train Loss: 0.000338
Validation Loss: 0.00057779
Epoch [103/300], Train Loss: 0.000341
Validation Loss: 0.00059820
Epoch [104/300], Train Loss: 0.000339
Validation Loss: 0.00059396
Epoch [105/300], Train Loss: 0.000335
Validation Loss: 0.00058179
Epoch [106/300], Train Loss: 0.000337
Validation Loss: 0.00057535
Epoch [107/300], Train Loss: 0.000344
Validation Loss: 0.00059049
Epoch [108/300], Train Loss: 0.000335
Validation Loss: 0.00058536
Epoch [109/300], Train Loss: 0.000335
Validation Loss: 0.00058564
Epoch [110/300], Train Loss: 0.000376
Validation Loss: 0.00057666
Epoch [111/300], Train Loss: 0.000339
Validation Loss: 0.00058439
Epoch [112/300], Train Loss: 0.000337
Validation Loss: 0.00056962
Epoch [113/300], Train Loss: 0.000351
Validation Loss: 0.00057653
Epoch [114/300], Train Loss: 0.000329
Validation Loss: 0.00057016
Epoch [115/300], Train Loss: 0.000328
Validation Loss: 0.00057300
Epoch [116/300], Train Loss: 0.000330
Validation Loss: 0.00056998
Epoch [117/300], Train Loss: 0.000333
Validation Loss: 0.00056624
Epoch [118/300], Train Loss: 0.000329
Validation Loss: 0.00058265
Epoch [119/300], Train Loss: 0.000330
Validation Loss: 0.00058339
Epoch [120/300], Train Loss: 0.000376
Validation Loss: 0.00057481
Epoch [121/300], Train Loss: 0.000333
Validation Loss: 0.00057401
Epoch [122/300], Train Loss: 0.000323
Validation Loss: 0.00056422
Epoch [123/300], Train Loss: 0.000335
Validation Loss: 0.00057940
Epoch [124/300], Train Loss: 0.000323
Validation Loss: 0.00059645
Epoch [125/300], Train Loss: 0.000356
Validation Loss: 0.00056461
Epoch [126/300], Train Loss: 0.000323
Validation Loss: 0.00057888
Epoch [127/300], Train Loss: 0.000324
Validation Loss: 0.00057120
Epoch [128/300], Train Loss: 0.000340
Validation Loss: 0.00056001
Epoch [129/300], Train Loss: 0.000325
Validation Loss: 0.00056013
Epoch [130/300], Train Loss: 0.000326
Validation Loss: 0.00056560
Epoch [131/300], Train Loss: 0.000322
Validation Loss: 0.00056739
Epoch [132/300], Train Loss: 0.000319
Validation Loss: 0.00055870
Epoch [133/300], Train Loss: 0.000321
Validation Loss: 0.00056847
Epoch [134/300], Train Loss: 0.000336
Validation Loss: 0.00056901
Epoch [135/300], Train Loss: 0.000325
Validation Loss: 0.00055542
Epoch [136/300], Train Loss: 0.000315
Validation Loss: 0.00055809
Epoch [137/300], Train Loss: 0.000318
Validation Loss: 0.00056486
Epoch [138/300], Train Loss: 0.000330
Validation Loss: 0.00055543
Epoch [139/300], Train Loss: 0.000320
Validation Loss: 0.00056813
Epoch [140/300], Train Loss: 0.000317
Validation Loss: 0.00056603
Epoch [141/300], Train Loss: 0.000315
Validation Loss: 0.00055134
Epoch [142/300], Train Loss: 0.000318
Validation Loss: 0.00055466
Epoch [143/300], Train Loss: 0.000329
Validation Loss: 0.00056352
Epoch [144/300], Train Loss: 0.000314
Validation Loss: 0.00055270
Epoch [145/300], Train Loss: 0.000315
Validation Loss: 0.00054937
Epoch [146/300], Train Loss: 0.000316
Validation Loss: 0.00057202
Epoch [147/300], Train Loss: 0.000312
Validation Loss: 0.00055642
Epoch [148/300], Train Loss: 0.000322
Validation Loss: 0.00054380
Epoch [149/300], Train Loss: 0.000314
Validation Loss: 0.00054683
Epoch [150/300], Train Loss: 0.000313
Validation Loss: 0.00056033
Epoch [151/300], Train Loss: 0.000310
Validation Loss: 0.00055062
Epoch [152/300], Train Loss: 0.000317
Validation Loss: 0.00054746
Epoch [153/300], Train Loss: 0.000317
Validation Loss: 0.00055565
Epoch [154/300], Train Loss: 0.000311
Validation Loss: 0.00054718
Epoch [155/300], Train Loss: 0.000309
Validation Loss: 0.00055782
Epoch [156/300], Train Loss: 0.000306
Validation Loss: 0.00054313
Epoch [157/300], Train Loss: 0.000322
Validation Loss: 0.00056089
Epoch [158/300], Train Loss: 0.000320
Validation Loss: 0.00055870
Epoch [159/300], Train Loss: 0.000316
Validation Loss: 0.00055402
Epoch [160/300], Train Loss: 0.000310
Validation Loss: 0.00055588
Epoch [161/300], Train Loss: 0.000306
Validation Loss: 0.00055266
Epoch [162/300], Train Loss: 0.000304
Validation Loss: 0.00054794
Epoch [163/300], Train Loss: 0.000306
Validation Loss: 0.00054766
Epoch [164/300], Train Loss: 0.000305
Validation Loss: 0.00054226
Epoch [165/300], Train Loss: 0.000304
Validation Loss: 0.00054262
Epoch [166/300], Train Loss: 0.000303
Validation Loss: 0.00054077
Epoch [167/300], Train Loss: 0.000314
Validation Loss: 0.00054424
Epoch [168/300], Train Loss: 0.000304
Validation Loss: 0.00054487
Epoch [169/300], Train Loss: 0.000339
Validation Loss: 0.00056042
Epoch [170/300], Train Loss: 0.000304
Validation Loss: 0.00054667
Epoch [171/300], Train Loss: 0.000303
Validation Loss: 0.00054039
Epoch [172/300], Train Loss: 0.000307
Validation Loss: 0.00054332
Epoch [173/300], Train Loss: 0.000304
Validation Loss: 0.00053874
Epoch [174/300], Train Loss: 0.000302
Validation Loss: 0.00054197
Epoch [175/300], Train Loss: 0.000298
Validation Loss: 0.00054358
Epoch [176/300], Train Loss: 0.000300
Validation Loss: 0.00053673
Epoch [177/300], Train Loss: 0.000299
Validation Loss: 0.00053921
Epoch [178/300], Train Loss: 0.000331
Validation Loss: 0.00055629
Epoch [179/300], Train Loss: 0.000307
Validation Loss: 0.00055768
Epoch [180/300], Train Loss: 0.000299
Validation Loss: 0.00053551
Epoch [181/300], Train Loss: 0.000295
Validation Loss: 0.00053951
Epoch [182/300], Train Loss: 0.000300
Validation Loss: 0.00054104
Epoch [183/300], Train Loss: 0.000304
Validation Loss: 0.00053277
Epoch [184/300], Train Loss: 0.000298
Validation Loss: 0.00053996
Epoch [185/300], Train Loss: 0.000335
Validation Loss: 0.00054041
Epoch [186/300], Train Loss: 0.000300
Validation Loss: 0.00053576
Epoch [187/300], Train Loss: 0.000293
Validation Loss: 0.00053716
Epoch [188/300], Train Loss: 0.000292
Validation Loss: 0.00055085
Epoch [189/300], Train Loss: 0.000305
Validation Loss: 0.00053681
Epoch [190/300], Train Loss: 0.000302
Validation Loss: 0.00054110
Epoch [191/300], Train Loss: 0.000298
Validation Loss: 0.00053584
Epoch [192/300], Train Loss: 0.000349
Validation Loss: 0.00053562
Epoch [193/300], Train Loss: 0.000300
Validation Loss: 0.00053347
Early stopping triggered

Evaluating model for: Microwave
Run 10/72 completed in 1800.67 seconds with: {'MAE': np.float32(7.1218143), 'MSE': np.float32(5537.9634), 'RMSE': np.float32(74.417496), 'SAE': np.float32(0.1431557), 'NDE': np.float32(0.68869364)}

Run 11/72: hidden=128, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Microwave
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.000617
Validation Loss: 0.00091223
Epoch [2/300], Train Loss: 0.000651
Validation Loss: 0.00090883
Epoch [3/300], Train Loss: 0.000628
Validation Loss: 0.00090848
Epoch [4/300], Train Loss: 0.000617
Validation Loss: 0.00090582
Epoch [5/300], Train Loss: 0.000605
Validation Loss: 0.00089893
Epoch [6/300], Train Loss: 0.000597
Validation Loss: 0.00088231
Epoch [7/300], Train Loss: 0.000585
Validation Loss: 0.00084761
Epoch [8/300], Train Loss: 0.000555
Validation Loss: 0.00075323
Epoch [9/300], Train Loss: 0.000546
Validation Loss: 0.00074155
Epoch [10/300], Train Loss: 0.000499
Validation Loss: 0.00078943
Epoch [11/300], Train Loss: 0.000495
Validation Loss: 0.00075602
Epoch [12/300], Train Loss: 0.000482
Validation Loss: 0.00074570
Epoch [13/300], Train Loss: 0.000477
Validation Loss: 0.00076708
Epoch [14/300], Train Loss: 0.000472
Validation Loss: 0.00074333
Epoch [15/300], Train Loss: 0.000548
Validation Loss: 0.00076552
Epoch [16/300], Train Loss: 0.000485
Validation Loss: 0.00077016
Epoch [17/300], Train Loss: 0.000484
Validation Loss: 0.00072749
Epoch [18/300], Train Loss: 0.000469
Validation Loss: 0.00073267
Epoch [19/300], Train Loss: 0.000469
Validation Loss: 0.00072756
Epoch [20/300], Train Loss: 0.000469
Validation Loss: 0.00072042
Epoch [21/300], Train Loss: 0.000465
Validation Loss: 0.00072724
Epoch [22/300], Train Loss: 0.000462
Validation Loss: 0.00074037
Epoch [23/300], Train Loss: 0.000471
Validation Loss: 0.00071795
Epoch [24/300], Train Loss: 0.000466
Validation Loss: 0.00073877
Epoch [25/300], Train Loss: 0.000468
Validation Loss: 0.00072300
Epoch [26/300], Train Loss: 0.000457
Validation Loss: 0.00072317
Epoch [27/300], Train Loss: 0.000454
Validation Loss: 0.00071812
Epoch [28/300], Train Loss: 0.000455
Validation Loss: 0.00071600
Epoch [29/300], Train Loss: 0.000575
Validation Loss: 0.00071117
Epoch [30/300], Train Loss: 0.000501
Validation Loss: 0.00071350
Epoch [31/300], Train Loss: 0.000449
Validation Loss: 0.00070944
Epoch [32/300], Train Loss: 0.000446
Validation Loss: 0.00072113
Epoch [33/300], Train Loss: 0.000448
Validation Loss: 0.00070745
Epoch [34/300], Train Loss: 0.000453
Validation Loss: 0.00073128
Epoch [35/300], Train Loss: 0.000450
Validation Loss: 0.00071748
Epoch [36/300], Train Loss: 0.000444
Validation Loss: 0.00070706
Epoch [37/300], Train Loss: 0.000442
Validation Loss: 0.00070057
Epoch [38/300], Train Loss: 0.000437
Validation Loss: 0.00071269
Epoch [39/300], Train Loss: 0.000437
Validation Loss: 0.00070138
Epoch [40/300], Train Loss: 0.000485
Validation Loss: 0.00068685
Epoch [41/300], Train Loss: 0.000532
Validation Loss: 0.00068547
Epoch [42/300], Train Loss: 0.000458
Validation Loss: 0.00069091
Epoch [43/300], Train Loss: 0.000432
Validation Loss: 0.00067181
Epoch [44/300], Train Loss: 0.000438
Validation Loss: 0.00066313
Epoch [45/300], Train Loss: 0.000499
Validation Loss: 0.00067445
Epoch [46/300], Train Loss: 0.000442
Validation Loss: 0.00066376
Epoch [47/300], Train Loss: 0.000415
Validation Loss: 0.00065819
Epoch [48/300], Train Loss: 0.000413
Validation Loss: 0.00066734
Epoch [49/300], Train Loss: 0.000405
Validation Loss: 0.00064605
Epoch [50/300], Train Loss: 0.000408
Validation Loss: 0.00067634
Epoch [51/300], Train Loss: 0.000419
Validation Loss: 0.00065602
Epoch [52/300], Train Loss: 0.000401
Validation Loss: 0.00065526
Epoch [53/300], Train Loss: 0.000403
Validation Loss: 0.00064071
Epoch [54/300], Train Loss: 0.000399
Validation Loss: 0.00064344
Epoch [55/300], Train Loss: 0.000406
Validation Loss: 0.00069648
Epoch [56/300], Train Loss: 0.000405
Validation Loss: 0.00063197
Epoch [57/300], Train Loss: 0.000400
Validation Loss: 0.00065769
Epoch [58/300], Train Loss: 0.000406
Validation Loss: 0.00064374
Epoch [59/300], Train Loss: 0.000397
Validation Loss: 0.00063850
Epoch [60/300], Train Loss: 0.000396
Validation Loss: 0.00064367
Epoch [61/300], Train Loss: 0.000389
Validation Loss: 0.00062573
Epoch [62/300], Train Loss: 0.000387
Validation Loss: 0.00062586
Epoch [63/300], Train Loss: 0.000390
Validation Loss: 0.00064860
Epoch [64/300], Train Loss: 0.000383
Validation Loss: 0.00061621
Epoch [65/300], Train Loss: 0.000386
Validation Loss: 0.00062229
Epoch [66/300], Train Loss: 0.000390
Validation Loss: 0.00061833
Epoch [67/300], Train Loss: 0.000389
Validation Loss: 0.00064309
Epoch [68/300], Train Loss: 0.000393
Validation Loss: 0.00061494
Epoch [69/300], Train Loss: 0.000407
Validation Loss: 0.00061673
Epoch [70/300], Train Loss: 0.000412
Validation Loss: 0.00061385
Epoch [71/300], Train Loss: 0.000387
Validation Loss: 0.00061691
Epoch [72/300], Train Loss: 0.000375
Validation Loss: 0.00061944
Epoch [73/300], Train Loss: 0.000381
Validation Loss: 0.00061429
Epoch [74/300], Train Loss: 0.000416
Validation Loss: 0.00059329
Epoch [75/300], Train Loss: 0.000384
Validation Loss: 0.00060138
Epoch [76/300], Train Loss: 0.000373
Validation Loss: 0.00060408
Epoch [77/300], Train Loss: 0.000369
Validation Loss: 0.00060216
Epoch [78/300], Train Loss: 0.000372
Validation Loss: 0.00060088
Epoch [79/300], Train Loss: 0.000363
Validation Loss: 0.00060544
Epoch [80/300], Train Loss: 0.000359
Validation Loss: 0.00059315
Epoch [81/300], Train Loss: 0.000356
Validation Loss: 0.00059432
Epoch [82/300], Train Loss: 0.000359
Validation Loss: 0.00059066
Epoch [83/300], Train Loss: 0.000362
Validation Loss: 0.00060967
Epoch [84/300], Train Loss: 0.000352
Validation Loss: 0.00059501
Epoch [85/300], Train Loss: 0.000357
Validation Loss: 0.00059880
Epoch [86/300], Train Loss: 0.000353
Validation Loss: 0.00059114
Epoch [87/300], Train Loss: 0.000349
Validation Loss: 0.00058794
Epoch [88/300], Train Loss: 0.000346
Validation Loss: 0.00059432
Epoch [89/300], Train Loss: 0.000349
Validation Loss: 0.00063167
Epoch [90/300], Train Loss: 0.000400
Validation Loss: 0.00058514
Epoch [91/300], Train Loss: 0.000375
Validation Loss: 0.00059920
Epoch [92/300], Train Loss: 0.000349
Validation Loss: 0.00060499
Epoch [93/300], Train Loss: 0.000344
Validation Loss: 0.00058537
Epoch [94/300], Train Loss: 0.000346
Validation Loss: 0.00058623
Epoch [95/300], Train Loss: 0.000342
Validation Loss: 0.00058343
Epoch [96/300], Train Loss: 0.000340
Validation Loss: 0.00059701
Epoch [97/300], Train Loss: 0.000342
Validation Loss: 0.00058177
Epoch [98/300], Train Loss: 0.000339
Validation Loss: 0.00060122
Epoch [99/300], Train Loss: 0.000346
Validation Loss: 0.00059477
Epoch [100/300], Train Loss: 0.000346
Validation Loss: 0.00060332
Epoch [101/300], Train Loss: 0.000338
Validation Loss: 0.00059222
Epoch [102/300], Train Loss: 0.000334
Validation Loss: 0.00059149
Epoch [103/300], Train Loss: 0.000342
Validation Loss: 0.00061668
Epoch [104/300], Train Loss: 0.000338
Validation Loss: 0.00060686
Epoch [105/300], Train Loss: 0.000334
Validation Loss: 0.00059185
Epoch [106/300], Train Loss: 0.000335
Validation Loss: 0.00058755
Epoch [107/300], Train Loss: 0.000341
Validation Loss: 0.00058720
Early stopping triggered

Evaluating model for: Microwave
Run 11/72 completed in 1037.92 seconds with: {'MAE': np.float32(7.2111235), 'MSE': np.float32(6201.1997), 'RMSE': np.float32(78.747696), 'SAE': np.float32(0.15413505), 'NDE': np.float32(0.7287662)}

Run 12/72: hidden=128, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Microwave
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.001098
Validation Loss: 0.00093072
Epoch [2/300], Train Loss: 0.000688
Validation Loss: 0.00092335
Epoch [3/300], Train Loss: 0.000664
Validation Loss: 0.00092212
Epoch [4/300], Train Loss: 0.000652
Validation Loss: 0.00092099
Epoch [5/300], Train Loss: 0.000639
Validation Loss: 0.00092130
Epoch [6/300], Train Loss: 0.000637
Validation Loss: 0.00091946
Epoch [7/300], Train Loss: 0.000634
Validation Loss: 0.00091823
Epoch [8/300], Train Loss: 0.000640
Validation Loss: 0.00091729
Epoch [9/300], Train Loss: 0.000630
Validation Loss: 0.00091937
Epoch [10/300], Train Loss: 0.000626
Validation Loss: 0.00091583
Epoch [11/300], Train Loss: 0.000621
Validation Loss: 0.00090185
Epoch [12/300], Train Loss: 0.000606
Validation Loss: 0.00086511
Epoch [13/300], Train Loss: 0.000587
Validation Loss: 0.00087106
Epoch [14/300], Train Loss: 0.000556
Validation Loss: 0.00076859
Epoch [15/300], Train Loss: 0.000581
Validation Loss: 0.00081383
Epoch [16/300], Train Loss: 0.000516
Validation Loss: 0.00080288
Epoch [17/300], Train Loss: 0.000521
Validation Loss: 0.00074934
Epoch [18/300], Train Loss: 0.000499
Validation Loss: 0.00076467
Epoch [19/300], Train Loss: 0.000498
Validation Loss: 0.00074865
Epoch [20/300], Train Loss: 0.000494
Validation Loss: 0.00075034
Epoch [21/300], Train Loss: 0.000486
Validation Loss: 0.00075496
Epoch [22/300], Train Loss: 0.000483
Validation Loss: 0.00076149
Epoch [23/300], Train Loss: 0.000492
Validation Loss: 0.00074042
Epoch [24/300], Train Loss: 0.000488
Validation Loss: 0.00076222
Epoch [25/300], Train Loss: 0.000490
Validation Loss: 0.00074984
Epoch [26/300], Train Loss: 0.000477
Validation Loss: 0.00074754
Epoch [27/300], Train Loss: 0.000474
Validation Loss: 0.00074170
Epoch [28/300], Train Loss: 0.000476
Validation Loss: 0.00074094
Epoch [29/300], Train Loss: 0.000599
Validation Loss: 0.00074346
Epoch [30/300], Train Loss: 0.000521
Validation Loss: 0.00073840
Epoch [31/300], Train Loss: 0.000466
Validation Loss: 0.00073922
Epoch [32/300], Train Loss: 0.000465
Validation Loss: 0.00074779
Epoch [33/300], Train Loss: 0.000468
Validation Loss: 0.00074100
Epoch [34/300], Train Loss: 0.000474
Validation Loss: 0.00075665
Epoch [35/300], Train Loss: 0.000469
Validation Loss: 0.00073976
Epoch [36/300], Train Loss: 0.000461
Validation Loss: 0.00074527
Epoch [37/300], Train Loss: 0.000462
Validation Loss: 0.00073566
Epoch [38/300], Train Loss: 0.000459
Validation Loss: 0.00073552
Epoch [39/300], Train Loss: 0.000457
Validation Loss: 0.00073735
Epoch [40/300], Train Loss: 0.000509
Validation Loss: 0.00073069
Epoch [41/300], Train Loss: 0.000544
Validation Loss: 0.00072446
Epoch [42/300], Train Loss: 0.000475
Validation Loss: 0.00072445
Epoch [43/300], Train Loss: 0.000453
Validation Loss: 0.00071638
Epoch [44/300], Train Loss: 0.000470
Validation Loss: 0.00070104
Epoch [45/300], Train Loss: 0.000506
Validation Loss: 0.00069664
Epoch [46/300], Train Loss: 0.000465
Validation Loss: 0.00070109
Epoch [47/300], Train Loss: 0.000435
Validation Loss: 0.00069464
Epoch [48/300], Train Loss: 0.000434
Validation Loss: 0.00068984
Epoch [49/300], Train Loss: 0.000424
Validation Loss: 0.00066490
Epoch [50/300], Train Loss: 0.000422
Validation Loss: 0.00069473
Epoch [51/300], Train Loss: 0.000430
Validation Loss: 0.00066017
Epoch [52/300], Train Loss: 0.000411
Validation Loss: 0.00066594
Epoch [53/300], Train Loss: 0.000409
Validation Loss: 0.00064271
Epoch [54/300], Train Loss: 0.000401
Validation Loss: 0.00063877
Epoch [55/300], Train Loss: 0.000400
Validation Loss: 0.00068190
Epoch [56/300], Train Loss: 0.000394
Validation Loss: 0.00062882
Epoch [57/300], Train Loss: 0.000394
Validation Loss: 0.00064818
Epoch [58/300], Train Loss: 0.000394
Validation Loss: 0.00063931
Epoch [59/300], Train Loss: 0.000381
Validation Loss: 0.00062623
Epoch [60/300], Train Loss: 0.000379
Validation Loss: 0.00063462
Epoch [61/300], Train Loss: 0.000372
Validation Loss: 0.00062151
Epoch [62/300], Train Loss: 0.000372
Validation Loss: 0.00061411
Epoch [63/300], Train Loss: 0.000373
Validation Loss: 0.00063421
Epoch [64/300], Train Loss: 0.000363
Validation Loss: 0.00062744
Epoch [65/300], Train Loss: 0.000368
Validation Loss: 0.00061992
Epoch [66/300], Train Loss: 0.000370
Validation Loss: 0.00061145
Epoch [67/300], Train Loss: 0.000361
Validation Loss: 0.00061645
Epoch [68/300], Train Loss: 0.000368
Validation Loss: 0.00060066
Epoch [69/300], Train Loss: 0.000382
Validation Loss: 0.00066245
Epoch [70/300], Train Loss: 0.000459
Validation Loss: 0.00059215
Epoch [71/300], Train Loss: 0.000371
Validation Loss: 0.00063367
Epoch [72/300], Train Loss: 0.000359
Validation Loss: 0.00061121
Epoch [73/300], Train Loss: 0.000354
Validation Loss: 0.00061575
Epoch [74/300], Train Loss: 0.000389
Validation Loss: 0.00058979
Epoch [75/300], Train Loss: 0.000357
Validation Loss: 0.00060817
Epoch [76/300], Train Loss: 0.000348
Validation Loss: 0.00060115
Epoch [77/300], Train Loss: 0.000345
Validation Loss: 0.00059957
Epoch [78/300], Train Loss: 0.000352
Validation Loss: 0.00060070
Epoch [79/300], Train Loss: 0.000344
Validation Loss: 0.00061794
Epoch [80/300], Train Loss: 0.000344
Validation Loss: 0.00058595
Epoch [81/300], Train Loss: 0.000343
Validation Loss: 0.00058766
Epoch [82/300], Train Loss: 0.000344
Validation Loss: 0.00057940
Epoch [83/300], Train Loss: 0.000348
Validation Loss: 0.00058926
Epoch [84/300], Train Loss: 0.000339
Validation Loss: 0.00058774
Epoch [85/300], Train Loss: 0.000345
Validation Loss: 0.00059453
Epoch [86/300], Train Loss: 0.000341
Validation Loss: 0.00058501
Epoch [87/300], Train Loss: 0.000340
Validation Loss: 0.00059077
Epoch [88/300], Train Loss: 0.000336
Validation Loss: 0.00058639
Epoch [89/300], Train Loss: 0.000337
Validation Loss: 0.00060899
Epoch [90/300], Train Loss: 0.000389
Validation Loss: 0.00057383
Epoch [91/300], Train Loss: 0.000363
Validation Loss: 0.00058179
Epoch [92/300], Train Loss: 0.000334
Validation Loss: 0.00058230
Epoch [93/300], Train Loss: 0.000332
Validation Loss: 0.00057078
Epoch [94/300], Train Loss: 0.000336
Validation Loss: 0.00057874
Epoch [95/300], Train Loss: 0.000331
Validation Loss: 0.00057435
Epoch [96/300], Train Loss: 0.000327
Validation Loss: 0.00058808
Epoch [97/300], Train Loss: 0.000330
Validation Loss: 0.00056480
Epoch [98/300], Train Loss: 0.000329
Validation Loss: 0.00058590
Epoch [99/300], Train Loss: 0.000338
Validation Loss: 0.00057603
Epoch [100/300], Train Loss: 0.000330
Validation Loss: 0.00058975
Epoch [101/300], Train Loss: 0.000328
Validation Loss: 0.00058509
Epoch [102/300], Train Loss: 0.000326
Validation Loss: 0.00056078
Epoch [103/300], Train Loss: 0.000329
Validation Loss: 0.00058587
Epoch [104/300], Train Loss: 0.000324
Validation Loss: 0.00056917
Epoch [105/300], Train Loss: 0.000322
Validation Loss: 0.00056702
Epoch [106/300], Train Loss: 0.000326
Validation Loss: 0.00056117
Epoch [107/300], Train Loss: 0.000331
Validation Loss: 0.00057093
Epoch [108/300], Train Loss: 0.000320
Validation Loss: 0.00056528
Epoch [109/300], Train Loss: 0.000320
Validation Loss: 0.00057219
Epoch [110/300], Train Loss: 0.000364
Validation Loss: 0.00056713
Epoch [111/300], Train Loss: 0.000332
Validation Loss: 0.00056700
Epoch [112/300], Train Loss: 0.000323
Validation Loss: 0.00056064
Epoch [113/300], Train Loss: 0.000338
Validation Loss: 0.00056027
Epoch [114/300], Train Loss: 0.000318
Validation Loss: 0.00056221
Epoch [115/300], Train Loss: 0.000316
Validation Loss: 0.00055554
Epoch [116/300], Train Loss: 0.000318
Validation Loss: 0.00055660
Epoch [117/300], Train Loss: 0.000318
Validation Loss: 0.00055415
Epoch [118/300], Train Loss: 0.000317
Validation Loss: 0.00056688
Epoch [119/300], Train Loss: 0.000318
Validation Loss: 0.00056086
Epoch [120/300], Train Loss: 0.000346
Validation Loss: 0.00055143
Epoch [121/300], Train Loss: 0.000346
Validation Loss: 0.00058329
Epoch [122/300], Train Loss: 0.000313
Validation Loss: 0.00057781
Epoch [123/300], Train Loss: 0.000321
Validation Loss: 0.00058324
Epoch [124/300], Train Loss: 0.000312
Validation Loss: 0.00058535
Epoch [125/300], Train Loss: 0.000348
Validation Loss: 0.00056161
Epoch [126/300], Train Loss: 0.000309
Validation Loss: 0.00056513
Epoch [127/300], Train Loss: 0.000313
Validation Loss: 0.00057042
Epoch [128/300], Train Loss: 0.000323
Validation Loss: 0.00055461
Epoch [129/300], Train Loss: 0.000313
Validation Loss: 0.00055826
Epoch [130/300], Train Loss: 0.000307
Validation Loss: 0.00057184
Early stopping triggered

Evaluating model for: Microwave
Run 12/72 completed in 1297.04 seconds with: {'MAE': np.float32(7.3024406), 'MSE': np.float32(5612.2314), 'RMSE': np.float32(74.914825), 'SAE': np.float32(0.10417738), 'NDE': np.float32(0.6932963)}

Run 13/72: hidden=128, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Microwave
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.000707
Validation Loss: 0.00081495
Epoch [2/300], Train Loss: 0.000556
Validation Loss: 0.00078667
Epoch [3/300], Train Loss: 0.000548
Validation Loss: 0.00078544
Epoch [4/300], Train Loss: 0.000547
Validation Loss: 0.00078483
Epoch [5/300], Train Loss: 0.000550
Validation Loss: 0.00078381
Epoch [6/300], Train Loss: 0.000552
Validation Loss: 0.00078269
Epoch [7/300], Train Loss: 0.000543
Validation Loss: 0.00078172
Epoch [8/300], Train Loss: 0.000541
Validation Loss: 0.00077992
Epoch [9/300], Train Loss: 0.000540
Validation Loss: 0.00077753
Epoch [10/300], Train Loss: 0.000538
Validation Loss: 0.00077555
Epoch [11/300], Train Loss: 0.000571
Validation Loss: 0.00077273
Epoch [12/300], Train Loss: 0.000535
Validation Loss: 0.00077052
Epoch [13/300], Train Loss: 0.000532
Validation Loss: 0.00076675
Epoch [14/300], Train Loss: 0.000533
Validation Loss: 0.00076506
Epoch [15/300], Train Loss: 0.000586
Validation Loss: 0.00075956
Epoch [16/300], Train Loss: 0.000652
Validation Loss: 0.00075275
Epoch [17/300], Train Loss: 0.000534
Validation Loss: 0.00074351
Epoch [18/300], Train Loss: 0.000521
Validation Loss: 0.00073757
Epoch [19/300], Train Loss: 0.000515
Validation Loss: 0.00073051
Epoch [20/300], Train Loss: 0.000510
Validation Loss: 0.00072245
Epoch [21/300], Train Loss: 0.000505
Validation Loss: 0.00071076
Epoch [22/300], Train Loss: 0.000515
Validation Loss: 0.00069934
Epoch [23/300], Train Loss: 0.000498
Validation Loss: 0.00067625
Epoch [24/300], Train Loss: 0.000492
Validation Loss: 0.00063693
Epoch [25/300], Train Loss: 0.000457
Validation Loss: 0.00062596
Epoch [26/300], Train Loss: 0.000515
Validation Loss: 0.00062254
Epoch [27/300], Train Loss: 0.000482
Validation Loss: 0.00056386
Epoch [28/300], Train Loss: 0.000435
Validation Loss: 0.00057739
Epoch [29/300], Train Loss: 0.000455
Validation Loss: 0.00055527
Epoch [30/300], Train Loss: 0.000439
Validation Loss: 0.00056651
Epoch [31/300], Train Loss: 0.000427
Validation Loss: 0.00057135
Epoch [32/300], Train Loss: 0.000424
Validation Loss: 0.00055881
Epoch [33/300], Train Loss: 0.000517
Validation Loss: 0.00055955
Epoch [34/300], Train Loss: 0.000519
Validation Loss: 0.00058113
Epoch [35/300], Train Loss: 0.000432
Validation Loss: 0.00057879
Epoch [36/300], Train Loss: 0.000428
Validation Loss: 0.00055765
Epoch [37/300], Train Loss: 0.000422
Validation Loss: 0.00056001
Epoch [38/300], Train Loss: 0.000419
Validation Loss: 0.00056564
Epoch [39/300], Train Loss: 0.000421
Validation Loss: 0.00056479
Early stopping triggered

Evaluating model for: Microwave
Run 13/72 completed in 163.65 seconds with: {'MAE': np.float32(16.240746), 'MSE': np.float32(11416.185), 'RMSE': np.float32(106.84655), 'SAE': np.float32(0.011678738), 'NDE': np.float32(0.81740093)}

Run 14/72: hidden=128, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Microwave
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.000621
Validation Loss: 0.00079454
Epoch [2/300], Train Loss: 0.000550
Validation Loss: 0.00078676
Epoch [3/300], Train Loss: 0.000547
Validation Loss: 0.00078532
Epoch [4/300], Train Loss: 0.000545
Validation Loss: 0.00078449
Epoch [5/300], Train Loss: 0.000549
Validation Loss: 0.00078318
Epoch [6/300], Train Loss: 0.000550
Validation Loss: 0.00078187
Epoch [7/300], Train Loss: 0.000540
Validation Loss: 0.00078089
Epoch [8/300], Train Loss: 0.000538
Validation Loss: 0.00077886
Epoch [9/300], Train Loss: 0.000536
Validation Loss: 0.00077525
Epoch [10/300], Train Loss: 0.000534
Validation Loss: 0.00077202
Epoch [11/300], Train Loss: 0.000567
Validation Loss: 0.00076894
Epoch [12/300], Train Loss: 0.000531
Validation Loss: 0.00076478
Epoch [13/300], Train Loss: 0.000528
Validation Loss: 0.00076044
Epoch [14/300], Train Loss: 0.000529
Validation Loss: 0.00075660
Epoch [15/300], Train Loss: 0.000581
Validation Loss: 0.00075123
Epoch [16/300], Train Loss: 0.000644
Validation Loss: 0.00074206
Epoch [17/300], Train Loss: 0.000526
Validation Loss: 0.00072636
Epoch [18/300], Train Loss: 0.000510
Validation Loss: 0.00071119
Epoch [19/300], Train Loss: 0.000496
Validation Loss: 0.00067879
Epoch [20/300], Train Loss: 0.000480
Validation Loss: 0.00061904
Epoch [21/300], Train Loss: 0.000461
Validation Loss: 0.00060539
Epoch [22/300], Train Loss: 0.000475
Validation Loss: 0.00059773
Epoch [23/300], Train Loss: 0.000454
Validation Loss: 0.00058835
Epoch [24/300], Train Loss: 0.000462
Validation Loss: 0.00056429
Epoch [25/300], Train Loss: 0.000437
Validation Loss: 0.00071155
Epoch [26/300], Train Loss: 0.000588
Validation Loss: 0.00057409
Epoch [27/300], Train Loss: 0.000477
Validation Loss: 0.00058512
Epoch [28/300], Train Loss: 0.000446
Validation Loss: 0.00058238
Epoch [29/300], Train Loss: 0.000460
Validation Loss: 0.00056117
Epoch [30/300], Train Loss: 0.000443
Validation Loss: 0.00057981
Epoch [31/300], Train Loss: 0.000433
Validation Loss: 0.00057771
Epoch [32/300], Train Loss: 0.000431
Validation Loss: 0.00056576
Epoch [33/300], Train Loss: 0.000525
Validation Loss: 0.00056596
Epoch [34/300], Train Loss: 0.000530
Validation Loss: 0.00058671
Epoch [35/300], Train Loss: 0.000440
Validation Loss: 0.00057965
Epoch [36/300], Train Loss: 0.000434
Validation Loss: 0.00056087
Epoch [37/300], Train Loss: 0.000429
Validation Loss: 0.00056446
Epoch [38/300], Train Loss: 0.000427
Validation Loss: 0.00057280
Epoch [39/300], Train Loss: 0.000431
Validation Loss: 0.00056877
Epoch [40/300], Train Loss: 0.000435
Validation Loss: 0.00057697
Epoch [41/300], Train Loss: 0.000432
Validation Loss: 0.00056567
Epoch [42/300], Train Loss: 0.000501
Validation Loss: 0.00056705
Epoch [43/300], Train Loss: 0.000458
Validation Loss: 0.00057213
Epoch [44/300], Train Loss: 0.000431
Validation Loss: 0.00056280
Epoch [45/300], Train Loss: 0.000430
Validation Loss: 0.00057058
Epoch [46/300], Train Loss: 0.000423
Validation Loss: 0.00056101
Early stopping triggered

Evaluating model for: Microwave
Run 14/72 completed in 207.52 seconds with: {'MAE': np.float32(12.231255), 'MSE': np.float32(11817.347), 'RMSE': np.float32(108.70762), 'SAE': np.float32(0.32614288), 'NDE': np.float32(0.8316378)}

Run 15/72: hidden=128, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Microwave
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.001191
Validation Loss: 0.00080654
Epoch [2/300], Train Loss: 0.000581
Validation Loss: 0.00080041
Epoch [3/300], Train Loss: 0.000567
Validation Loss: 0.00079494
Epoch [4/300], Train Loss: 0.000564
Validation Loss: 0.00079447
Epoch [5/300], Train Loss: 0.000568
Validation Loss: 0.00079397
Epoch [6/300], Train Loss: 0.000570
Validation Loss: 0.00079366
Epoch [7/300], Train Loss: 0.000561
Validation Loss: 0.00079338
Epoch [8/300], Train Loss: 0.000560
Validation Loss: 0.00079229
Epoch [9/300], Train Loss: 0.000558
Validation Loss: 0.00079155
Epoch [10/300], Train Loss: 0.000557
Validation Loss: 0.00079059
Epoch [11/300], Train Loss: 0.000590
Validation Loss: 0.00078999
Epoch [12/300], Train Loss: 0.000554
Validation Loss: 0.00078893
Epoch [13/300], Train Loss: 0.000552
Validation Loss: 0.00078763
Epoch [14/300], Train Loss: 0.000553
Validation Loss: 0.00078834
Epoch [15/300], Train Loss: 0.000608
Validation Loss: 0.00078352
Epoch [16/300], Train Loss: 0.000679
Validation Loss: 0.00078102
Epoch [17/300], Train Loss: 0.000558
Validation Loss: 0.00077609
Epoch [18/300], Train Loss: 0.000545
Validation Loss: 0.00077133
Epoch [19/300], Train Loss: 0.000539
Validation Loss: 0.00076427
Epoch [20/300], Train Loss: 0.000535
Validation Loss: 0.00075292
Epoch [21/300], Train Loss: 0.000528
Validation Loss: 0.00072920
Epoch [22/300], Train Loss: 0.000538
Validation Loss: 0.00068581
Epoch [23/300], Train Loss: 0.000514
Validation Loss: 0.00066862
Epoch [24/300], Train Loss: 0.000500
Validation Loss: 0.00061851
Epoch [25/300], Train Loss: 0.000469
Validation Loss: 0.00070520
Epoch [26/300], Train Loss: 0.000551
Validation Loss: 0.00071499
Epoch [27/300], Train Loss: 0.000547
Validation Loss: 0.00066889
Epoch [28/300], Train Loss: 0.000474
Validation Loss: 0.00058979
Epoch [29/300], Train Loss: 0.000469
Validation Loss: 0.00057761
Epoch [30/300], Train Loss: 0.000460
Validation Loss: 0.00059249
Epoch [31/300], Train Loss: 0.000449
Validation Loss: 0.00058116
Epoch [32/300], Train Loss: 0.000446
Validation Loss: 0.00056768
Epoch [33/300], Train Loss: 0.000542
Validation Loss: 0.00057430
Epoch [34/300], Train Loss: 0.000549
Validation Loss: 0.00059676
Epoch [35/300], Train Loss: 0.000453
Validation Loss: 0.00058229
Epoch [36/300], Train Loss: 0.000446
Validation Loss: 0.00056302
Epoch [37/300], Train Loss: 0.000441
Validation Loss: 0.00056891
Epoch [38/300], Train Loss: 0.000441
Validation Loss: 0.00058173
Epoch [39/300], Train Loss: 0.000444
Validation Loss: 0.00056521
Epoch [40/300], Train Loss: 0.000448
Validation Loss: 0.00058410
Epoch [41/300], Train Loss: 0.000442
Validation Loss: 0.00056805
Epoch [42/300], Train Loss: 0.000511
Validation Loss: 0.00056879
Epoch [43/300], Train Loss: 0.000466
Validation Loss: 0.00058785
Epoch [44/300], Train Loss: 0.000444
Validation Loss: 0.00056203
Epoch [45/300], Train Loss: 0.000444
Validation Loss: 0.00058568
Epoch [46/300], Train Loss: 0.000437
Validation Loss: 0.00056414
Epoch [47/300], Train Loss: 0.000439
Validation Loss: 0.00056930
Epoch [48/300], Train Loss: 0.000440
Validation Loss: 0.00059167
Epoch [49/300], Train Loss: 0.000446
Validation Loss: 0.00056555
Epoch [50/300], Train Loss: 0.000471
Validation Loss: 0.00056813
Epoch [51/300], Train Loss: 0.000433
Validation Loss: 0.00056967
Epoch [52/300], Train Loss: 0.000441
Validation Loss: 0.00057189
Epoch [53/300], Train Loss: 0.000433
Validation Loss: 0.00055985
Epoch [54/300], Train Loss: 0.000436
Validation Loss: 0.00056515
Epoch [55/300], Train Loss: 0.000438
Validation Loss: 0.00056798
Epoch [56/300], Train Loss: 0.000458
Validation Loss: 0.00055437
Epoch [57/300], Train Loss: 0.000441
Validation Loss: 0.00055477
Epoch [58/300], Train Loss: 0.000439
Validation Loss: 0.00058254
Epoch [59/300], Train Loss: 0.000453
Validation Loss: 0.00055960
Epoch [60/300], Train Loss: 0.000603
Validation Loss: 0.00055379
Epoch [61/300], Train Loss: 0.000469
Validation Loss: 0.00055919
Epoch [62/300], Train Loss: 0.000435
Validation Loss: 0.00055216
Epoch [63/300], Train Loss: 0.000432
Validation Loss: 0.00054708
Epoch [64/300], Train Loss: 0.000452
Validation Loss: 0.00055063
Epoch [65/300], Train Loss: 0.000437
Validation Loss: 0.00055200
Epoch [66/300], Train Loss: 0.000443
Validation Loss: 0.00054859
Epoch [67/300], Train Loss: 0.000462
Validation Loss: 0.00054836
Epoch [68/300], Train Loss: 0.000453
Validation Loss: 0.00055138
Epoch [69/300], Train Loss: 0.000431
Validation Loss: 0.00056251
Epoch [70/300], Train Loss: 0.000454
Validation Loss: 0.00054722
Epoch [71/300], Train Loss: 0.000433
Validation Loss: 0.00054570
Epoch [72/300], Train Loss: 0.000437
Validation Loss: 0.00054347
Epoch [73/300], Train Loss: 0.000483
Validation Loss: 0.00055079
Epoch [74/300], Train Loss: 0.000441
Validation Loss: 0.00055408
Epoch [75/300], Train Loss: 0.000489
Validation Loss: 0.00054103
Epoch [76/300], Train Loss: 0.000435
Validation Loss: 0.00054179
Epoch [77/300], Train Loss: 0.000516
Validation Loss: 0.00053946
Epoch [78/300], Train Loss: 0.000452
Validation Loss: 0.00056777
Epoch [79/300], Train Loss: 0.000443
Validation Loss: 0.00054066
Epoch [80/300], Train Loss: 0.000431
Validation Loss: 0.00053631
Epoch [81/300], Train Loss: 0.000486
Validation Loss: 0.00054700
Epoch [82/300], Train Loss: 0.000445
Validation Loss: 0.00054235
Epoch [83/300], Train Loss: 0.000423
Validation Loss: 0.00053969
Epoch [84/300], Train Loss: 0.000458
Validation Loss: 0.00054394
Epoch [85/300], Train Loss: 0.000422
Validation Loss: 0.00053699
Epoch [86/300], Train Loss: 0.000429
Validation Loss: 0.00054629
Epoch [87/300], Train Loss: 0.000425
Validation Loss: 0.00053310
Epoch [88/300], Train Loss: 0.000580
Validation Loss: 0.00054919
Epoch [89/300], Train Loss: 0.000420
Validation Loss: 0.00052773
Epoch [90/300], Train Loss: 0.000502
Validation Loss: 0.00053099
Epoch [91/300], Train Loss: 0.000422
Validation Loss: 0.00053766
Epoch [92/300], Train Loss: 0.000431
Validation Loss: 0.00053497
Epoch [93/300], Train Loss: 0.000429
Validation Loss: 0.00053782
Epoch [94/300], Train Loss: 0.000484
Validation Loss: 0.00053619
Epoch [95/300], Train Loss: 0.000440
Validation Loss: 0.00053916
Epoch [96/300], Train Loss: 0.000420
Validation Loss: 0.00053479
Epoch [97/300], Train Loss: 0.000418
Validation Loss: 0.00054339
Epoch [98/300], Train Loss: 0.000434
Validation Loss: 0.00053072
Epoch [99/300], Train Loss: 0.000430
Validation Loss: 0.00053247
Early stopping triggered

Evaluating model for: Microwave
Run 15/72 completed in 470.45 seconds with: {'MAE': np.float32(12.150479), 'MSE': np.float32(11650.289), 'RMSE': np.float32(107.93651), 'SAE': np.float32(0.30153045), 'NDE': np.float32(0.8257379)}

Run 16/72: hidden=128, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Microwave
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.000544
Validation Loss: 0.00078712
Epoch [2/300], Train Loss: 0.000541
Validation Loss: 0.00078584
Epoch [3/300], Train Loss: 0.000540
Validation Loss: 0.00078522
Epoch [4/300], Train Loss: 0.000539
Validation Loss: 0.00078468
Epoch [5/300], Train Loss: 0.000544
Validation Loss: 0.00078670
Epoch [6/300], Train Loss: 0.000546
Validation Loss: 0.00078462
Epoch [7/300], Train Loss: 0.000537
Validation Loss: 0.00078491
Epoch [8/300], Train Loss: 0.000536
Validation Loss: 0.00078443
Epoch [9/300], Train Loss: 0.000536
Validation Loss: 0.00078341
Epoch [10/300], Train Loss: 0.000535
Validation Loss: 0.00078142
Epoch [11/300], Train Loss: 0.000568
Validation Loss: 0.00077836
Epoch [12/300], Train Loss: 0.000531
Validation Loss: 0.00077034
Epoch [13/300], Train Loss: 0.000527
Validation Loss: 0.00076611
Epoch [14/300], Train Loss: 0.000527
Validation Loss: 0.00075386
Epoch [15/300], Train Loss: 0.000571
Validation Loss: 0.00073348
Epoch [16/300], Train Loss: 0.000611
Validation Loss: 0.00068367
Epoch [17/300], Train Loss: 0.000499
Validation Loss: 0.00066256
Epoch [18/300], Train Loss: 0.000476
Validation Loss: 0.00061900
Epoch [19/300], Train Loss: 0.000456
Validation Loss: 0.00066009
Epoch [20/300], Train Loss: 0.000481
Validation Loss: 0.00057280
Epoch [21/300], Train Loss: 0.000455
Validation Loss: 0.00058574
Epoch [22/300], Train Loss: 0.000481
Validation Loss: 0.00057070
Epoch [23/300], Train Loss: 0.000461
Validation Loss: 0.00056620
Epoch [24/300], Train Loss: 0.000467
Validation Loss: 0.00056648
Epoch [25/300], Train Loss: 0.000437
Validation Loss: 0.00069599
Epoch [26/300], Train Loss: 0.000577
Validation Loss: 0.00055983
Epoch [27/300], Train Loss: 0.000491
Validation Loss: 0.00062249
Epoch [28/300], Train Loss: 0.000457
Validation Loss: 0.00056399
Epoch [29/300], Train Loss: 0.000461
Validation Loss: 0.00055725
Epoch [30/300], Train Loss: 0.000452
Validation Loss: 0.00057579
Epoch [31/300], Train Loss: 0.000441
Validation Loss: 0.00056779
Epoch [32/300], Train Loss: 0.000440
Validation Loss: 0.00055880
Epoch [33/300], Train Loss: 0.000531
Validation Loss: 0.00056676
Epoch [34/300], Train Loss: 0.000536
Validation Loss: 0.00057540
Epoch [35/300], Train Loss: 0.000443
Validation Loss: 0.00057651
Epoch [36/300], Train Loss: 0.000440
Validation Loss: 0.00055953
Epoch [37/300], Train Loss: 0.000436
Validation Loss: 0.00056230
Epoch [38/300], Train Loss: 0.000435
Validation Loss: 0.00057144
Epoch [39/300], Train Loss: 0.000440
Validation Loss: 0.00056415
Early stopping triggered

Evaluating model for: Microwave
Run 16/72 completed in 193.57 seconds with: {'MAE': np.float32(14.980317), 'MSE': np.float32(12064.532), 'RMSE': np.float32(109.83866), 'SAE': np.float32(0.12096329), 'NDE': np.float32(0.8402909)}

Run 17/72: hidden=128, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Microwave
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.001005
Validation Loss: 0.00063277
Epoch [2/300], Train Loss: 0.000653
Validation Loss: 0.00062490
Epoch [3/300], Train Loss: 0.000652
Validation Loss: 0.00062416
Epoch [4/300], Train Loss: 0.000649
Validation Loss: 0.00062352
Epoch [5/300], Train Loss: 0.000655
Validation Loss: 0.00062272
Epoch [6/300], Train Loss: 0.000649
Validation Loss: 0.00062180
Epoch [7/300], Train Loss: 0.000643
Validation Loss: 0.00062097
Epoch [8/300], Train Loss: 0.000646
Validation Loss: 0.00061970
Epoch [9/300], Train Loss: 0.000660
Validation Loss: 0.00061846
Epoch [10/300], Train Loss: 0.000635
Validation Loss: 0.00061590
Epoch [11/300], Train Loss: 0.000633
Validation Loss: 0.00061539
Epoch [12/300], Train Loss: 0.000639
Validation Loss: 0.00061109
Epoch [13/300], Train Loss: 0.000631
Validation Loss: 0.00060763
Epoch [14/300], Train Loss: 0.000623
Validation Loss: 0.00060347
Epoch [15/300], Train Loss: 0.000620
Validation Loss: 0.00059967
Epoch [16/300], Train Loss: 0.000616
Validation Loss: 0.00059369
Epoch [17/300], Train Loss: 0.000608
Validation Loss: 0.00058600
Epoch [18/300], Train Loss: 0.000603
Validation Loss: 0.00057664
Epoch [19/300], Train Loss: 0.000594
Validation Loss: 0.00056511
Epoch [20/300], Train Loss: 0.000588
Validation Loss: 0.00054598
Epoch [21/300], Train Loss: 0.000573
Validation Loss: 0.00051847
Epoch [22/300], Train Loss: 0.000559
Validation Loss: 0.00045986
Epoch [23/300], Train Loss: 0.000513
Validation Loss: 0.00045385
Epoch [24/300], Train Loss: 0.000525
Validation Loss: 0.00047171
Epoch [25/300], Train Loss: 0.000500
Validation Loss: 0.00045910
Epoch [26/300], Train Loss: 0.000506
Validation Loss: 0.00045996
Epoch [27/300], Train Loss: 0.000512
Validation Loss: 0.00043841
Epoch [28/300], Train Loss: 0.000496
Validation Loss: 0.00043158
Epoch [29/300], Train Loss: 0.000493
Validation Loss: 0.00043449
Epoch [30/300], Train Loss: 0.000495
Validation Loss: 0.00043068
Epoch [31/300], Train Loss: 0.000493
Validation Loss: 0.00042350
Epoch [32/300], Train Loss: 0.000492
Validation Loss: 0.00043117
Epoch [33/300], Train Loss: 0.000500
Validation Loss: 0.00044304
Epoch [34/300], Train Loss: 0.000498
Validation Loss: 0.00041951
Epoch [35/300], Train Loss: 0.000496
Validation Loss: 0.00041928
Epoch [36/300], Train Loss: 0.000486
Validation Loss: 0.00043235
Epoch [37/300], Train Loss: 0.000492
Validation Loss: 0.00041650
Epoch [38/300], Train Loss: 0.000492
Validation Loss: 0.00042534
Epoch [39/300], Train Loss: 0.000484
Validation Loss: 0.00042082
Epoch [40/300], Train Loss: 0.000491
Validation Loss: 0.00041506
Epoch [41/300], Train Loss: 0.000488
Validation Loss: 0.00041963
Epoch [42/300], Train Loss: 0.000486
Validation Loss: 0.00041256
Epoch [43/300], Train Loss: 0.000485
Validation Loss: 0.00041061
Epoch [44/300], Train Loss: 0.000491
Validation Loss: 0.00041139
Epoch [45/300], Train Loss: 0.000488
Validation Loss: 0.00041089
Epoch [46/300], Train Loss: 0.000479
Validation Loss: 0.00041279
Epoch [47/300], Train Loss: 0.000483
Validation Loss: 0.00041386
Epoch [48/300], Train Loss: 0.000477
Validation Loss: 0.00041006
Epoch [49/300], Train Loss: 0.000477
Validation Loss: 0.00040778
Epoch [50/300], Train Loss: 0.000477
Validation Loss: 0.00041647
Epoch [51/300], Train Loss: 0.000476
Validation Loss: 0.00040670
Epoch [52/300], Train Loss: 0.000480
Validation Loss: 0.00041064
Epoch [53/300], Train Loss: 0.000478
Validation Loss: 0.00042718
Epoch [54/300], Train Loss: 0.000494
Validation Loss: 0.00043095
Epoch [55/300], Train Loss: 0.000483
Validation Loss: 0.00042300
Epoch [56/300], Train Loss: 0.000480
Validation Loss: 0.00040349
Epoch [57/300], Train Loss: 0.000473
Validation Loss: 0.00040435
Epoch [58/300], Train Loss: 0.000473
Validation Loss: 0.00040399
Epoch [59/300], Train Loss: 0.000473
Validation Loss: 0.00040699
Epoch [60/300], Train Loss: 0.000482
Validation Loss: 0.00043463
Epoch [61/300], Train Loss: 0.000478
Validation Loss: 0.00040537
Epoch [62/300], Train Loss: 0.000491
Validation Loss: 0.00039999
Epoch [63/300], Train Loss: 0.000468
Validation Loss: 0.00040019
Epoch [64/300], Train Loss: 0.000470
Validation Loss: 0.00039856
Epoch [65/300], Train Loss: 0.000473
Validation Loss: 0.00041272
Epoch [66/300], Train Loss: 0.000475
Validation Loss: 0.00039843
Epoch [67/300], Train Loss: 0.000467
Validation Loss: 0.00039656
Epoch [68/300], Train Loss: 0.000470
Validation Loss: 0.00040546
Epoch [69/300], Train Loss: 0.000479
Validation Loss: 0.00039714
Epoch [70/300], Train Loss: 0.000468
Validation Loss: 0.00040101
Epoch [71/300], Train Loss: 0.000463
Validation Loss: 0.00039404
Epoch [72/300], Train Loss: 0.000469
Validation Loss: 0.00040511
Epoch [73/300], Train Loss: 0.000462
Validation Loss: 0.00039139
Epoch [74/300], Train Loss: 0.000462
Validation Loss: 0.00039215
Epoch [75/300], Train Loss: 0.000465
Validation Loss: 0.00039457
Epoch [76/300], Train Loss: 0.000466
Validation Loss: 0.00038905
Epoch [77/300], Train Loss: 0.000467
Validation Loss: 0.00039906
Epoch [78/300], Train Loss: 0.000456
Validation Loss: 0.00038912
Epoch [79/300], Train Loss: 0.000462
Validation Loss: 0.00038242
Epoch [80/300], Train Loss: 0.000471
Validation Loss: 0.00039005
Epoch [81/300], Train Loss: 0.000461
Validation Loss: 0.00039297
Epoch [82/300], Train Loss: 0.000458
Validation Loss: 0.00039937
Epoch [83/300], Train Loss: 0.000459
Validation Loss: 0.00038353
Epoch [84/300], Train Loss: 0.000455
Validation Loss: 0.00038166
Epoch [85/300], Train Loss: 0.000454
Validation Loss: 0.00038203
Epoch [86/300], Train Loss: 0.000449
Validation Loss: 0.00038119
Epoch [87/300], Train Loss: 0.000448
Validation Loss: 0.00037606
Epoch [88/300], Train Loss: 0.000446
Validation Loss: 0.00038461
Epoch [89/300], Train Loss: 0.000451
Validation Loss: 0.00037413
Epoch [90/300], Train Loss: 0.000448
Validation Loss: 0.00039228
Epoch [91/300], Train Loss: 0.000438
Validation Loss: 0.00037292
Epoch [92/300], Train Loss: 0.000444
Validation Loss: 0.00038018
Epoch [93/300], Train Loss: 0.000442
Validation Loss: 0.00037728
Epoch [94/300], Train Loss: 0.000444
Validation Loss: 0.00037233
Epoch [95/300], Train Loss: 0.000445
Validation Loss: 0.00036688
Epoch [96/300], Train Loss: 0.000442
Validation Loss: 0.00037030
Epoch [97/300], Train Loss: 0.000445
Validation Loss: 0.00036540
Epoch [98/300], Train Loss: 0.000445
Validation Loss: 0.00036420
Epoch [99/300], Train Loss: 0.000442
Validation Loss: 0.00036951
Epoch [100/300], Train Loss: 0.000437
Validation Loss: 0.00036285
Epoch [101/300], Train Loss: 0.000433
Validation Loss: 0.00036322
Epoch [102/300], Train Loss: 0.000430
Validation Loss: 0.00036946
Epoch [103/300], Train Loss: 0.000439
Validation Loss: 0.00036227
Epoch [104/300], Train Loss: 0.000435
Validation Loss: 0.00036231
Epoch [105/300], Train Loss: 0.000435
Validation Loss: 0.00035629
Epoch [106/300], Train Loss: 0.000442
Validation Loss: 0.00035888
Epoch [107/300], Train Loss: 0.000426
Validation Loss: 0.00036118
Epoch [108/300], Train Loss: 0.000428
Validation Loss: 0.00035210
Epoch [109/300], Train Loss: 0.000434
Validation Loss: 0.00036415
Epoch [110/300], Train Loss: 0.000432
Validation Loss: 0.00036623
Epoch [111/300], Train Loss: 0.000435
Validation Loss: 0.00036312
Epoch [112/300], Train Loss: 0.000442
Validation Loss: 0.00037970
Epoch [113/300], Train Loss: 0.000435
Validation Loss: 0.00035230
Epoch [114/300], Train Loss: 0.000424
Validation Loss: 0.00035335
Epoch [115/300], Train Loss: 0.000423
Validation Loss: 0.00035589
Epoch [116/300], Train Loss: 0.000421
Validation Loss: 0.00035074
Epoch [117/300], Train Loss: 0.000421
Validation Loss: 0.00035405
Epoch [118/300], Train Loss: 0.000419
Validation Loss: 0.00035219
Epoch [119/300], Train Loss: 0.000415
Validation Loss: 0.00034695
Epoch [120/300], Train Loss: 0.000417
Validation Loss: 0.00034852
Epoch [121/300], Train Loss: 0.000427
Validation Loss: 0.00035470
Epoch [122/300], Train Loss: 0.000414
Validation Loss: 0.00034248
Epoch [123/300], Train Loss: 0.000411
Validation Loss: 0.00035082
Epoch [124/300], Train Loss: 0.000414
Validation Loss: 0.00034011
Epoch [125/300], Train Loss: 0.000408
Validation Loss: 0.00034587
Epoch [126/300], Train Loss: 0.000425
Validation Loss: 0.00033983
Epoch [127/300], Train Loss: 0.000420
Validation Loss: 0.00034368
Epoch [128/300], Train Loss: 0.000411
Validation Loss: 0.00033828
Epoch [129/300], Train Loss: 0.000406
Validation Loss: 0.00034235
Epoch [130/300], Train Loss: 0.000404
Validation Loss: 0.00033995
Epoch [131/300], Train Loss: 0.000407
Validation Loss: 0.00034117
Epoch [132/300], Train Loss: 0.000402
Validation Loss: 0.00033857
Epoch [133/300], Train Loss: 0.000411
Validation Loss: 0.00034364
Epoch [134/300], Train Loss: 0.000415
Validation Loss: 0.00034033
Epoch [135/300], Train Loss: 0.000411
Validation Loss: 0.00032790
Epoch [136/300], Train Loss: 0.000405
Validation Loss: 0.00033435
Epoch [137/300], Train Loss: 0.000398
Validation Loss: 0.00033450
Epoch [138/300], Train Loss: 0.000398
Validation Loss: 0.00032965
Epoch [139/300], Train Loss: 0.000407
Validation Loss: 0.00033091
Epoch [140/300], Train Loss: 0.000401
Validation Loss: 0.00033005
Epoch [141/300], Train Loss: 0.000399
Validation Loss: 0.00033565
Epoch [142/300], Train Loss: 0.000396
Validation Loss: 0.00033143
Epoch [143/300], Train Loss: 0.000402
Validation Loss: 0.00032705
Epoch [144/300], Train Loss: 0.000393
Validation Loss: 0.00033098
Epoch [145/300], Train Loss: 0.000395
Validation Loss: 0.00033782
Epoch [146/300], Train Loss: 0.000401
Validation Loss: 0.00033586
Epoch [147/300], Train Loss: 0.000391
Validation Loss: 0.00032598
Epoch [148/300], Train Loss: 0.000397
Validation Loss: 0.00032086
Epoch [149/300], Train Loss: 0.000397
Validation Loss: 0.00032347
Epoch [150/300], Train Loss: 0.000391
Validation Loss: 0.00031556
Epoch [151/300], Train Loss: 0.000388
Validation Loss: 0.00030813
Epoch [152/300], Train Loss: 0.000392
Validation Loss: 0.00028921
Epoch [153/300], Train Loss: 0.000380
Validation Loss: 0.00027445
Epoch [154/300], Train Loss: 0.000390
Validation Loss: 0.00028051
Epoch [155/300], Train Loss: 0.000381
Validation Loss: 0.00027966
Epoch [156/300], Train Loss: 0.000392
Validation Loss: 0.00028172
Epoch [157/300], Train Loss: 0.000379
Validation Loss: 0.00029074
Epoch [158/300], Train Loss: 0.000379
Validation Loss: 0.00028764
Epoch [159/300], Train Loss: 0.000380
Validation Loss: 0.00027095
Epoch [160/300], Train Loss: 0.000375
Validation Loss: 0.00028012
Epoch [161/300], Train Loss: 0.000379
Validation Loss: 0.00028600
Epoch [162/300], Train Loss: 0.000379
Validation Loss: 0.00026857
Epoch [163/300], Train Loss: 0.000377
Validation Loss: 0.00028057
Epoch [164/300], Train Loss: 0.000373
Validation Loss: 0.00028078
Epoch [165/300], Train Loss: 0.000375
Validation Loss: 0.00026671
Epoch [166/300], Train Loss: 0.000378
Validation Loss: 0.00027318
Epoch [167/300], Train Loss: 0.000373
Validation Loss: 0.00027530
Epoch [168/300], Train Loss: 0.000380
Validation Loss: 0.00026149
Epoch [169/300], Train Loss: 0.000376
Validation Loss: 0.00028819
Epoch [170/300], Train Loss: 0.000372
Validation Loss: 0.00027173
Epoch [171/300], Train Loss: 0.000377
Validation Loss: 0.00028104
Epoch [172/300], Train Loss: 0.000426
Validation Loss: 0.00028480
Epoch [173/300], Train Loss: 0.000381
Validation Loss: 0.00028593
Epoch [174/300], Train Loss: 0.000378
Validation Loss: 0.00027254
Epoch [175/300], Train Loss: 0.000374
Validation Loss: 0.00026140
Epoch [176/300], Train Loss: 0.000377
Validation Loss: 0.00028167
Epoch [177/300], Train Loss: 0.000377
Validation Loss: 0.00026657
Epoch [178/300], Train Loss: 0.000363
Validation Loss: 0.00026210
Epoch [179/300], Train Loss: 0.000391
Validation Loss: 0.00028323
Epoch [180/300], Train Loss: 0.000378
Validation Loss: 0.00027909
Epoch [181/300], Train Loss: 0.000362
Validation Loss: 0.00027593
Epoch [182/300], Train Loss: 0.000371
Validation Loss: 0.00026011
Epoch [183/300], Train Loss: 0.000376
Validation Loss: 0.00029098
Epoch [184/300], Train Loss: 0.000374
Validation Loss: 0.00027427
Epoch [185/300], Train Loss: 0.000366
Validation Loss: 0.00026912
Epoch [186/300], Train Loss: 0.000361
Validation Loss: 0.00026806
Epoch [187/300], Train Loss: 0.000377
Validation Loss: 0.00027497
Epoch [188/300], Train Loss: 0.000368
Validation Loss: 0.00026250
Epoch [189/300], Train Loss: 0.000362
Validation Loss: 0.00026186
Epoch [190/300], Train Loss: 0.000364
Validation Loss: 0.00025943
Epoch [191/300], Train Loss: 0.000361
Validation Loss: 0.00026037
Epoch [192/300], Train Loss: 0.000363
Validation Loss: 0.00026760
Epoch [193/300], Train Loss: 0.000362
Validation Loss: 0.00026146
Epoch [194/300], Train Loss: 0.000362
Validation Loss: 0.00026111
Epoch [195/300], Train Loss: 0.000358
Validation Loss: 0.00026521
Epoch [196/300], Train Loss: 0.000359
Validation Loss: 0.00026079
Epoch [197/300], Train Loss: 0.000359
Validation Loss: 0.00026703
Epoch [198/300], Train Loss: 0.000365
Validation Loss: 0.00025349
Epoch [199/300], Train Loss: 0.000369
Validation Loss: 0.00025861
Epoch [200/300], Train Loss: 0.000366
Validation Loss: 0.00025984
Epoch [201/300], Train Loss: 0.000356
Validation Loss: 0.00025786
Epoch [202/300], Train Loss: 0.000362
Validation Loss: 0.00026079
Epoch [203/300], Train Loss: 0.000354
Validation Loss: 0.00026210
Epoch [204/300], Train Loss: 0.000360
Validation Loss: 0.00025997
Epoch [205/300], Train Loss: 0.000360
Validation Loss: 0.00026231
Epoch [206/300], Train Loss: 0.000354
Validation Loss: 0.00025523
Epoch [207/300], Train Loss: 0.000356
Validation Loss: 0.00025791
Epoch [208/300], Train Loss: 0.000355
Validation Loss: 0.00025892
Early stopping triggered

Evaluating model for: Microwave
Run 17/72 completed in 973.72 seconds with: {'MAE': np.float32(7.835441), 'MSE': np.float32(5333.765), 'RMSE': np.float32(73.03263), 'SAE': np.float32(0.08119437), 'NDE': np.float32(0.6885964)}

Run 18/72: hidden=128, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Microwave
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.000663
Validation Loss: 0.00063240
Epoch [2/300], Train Loss: 0.000647
Validation Loss: 0.00062666
Epoch [3/300], Train Loss: 0.000654
Validation Loss: 0.00062622
Epoch [4/300], Train Loss: 0.000649
Validation Loss: 0.00062368
Epoch [5/300], Train Loss: 0.000654
Validation Loss: 0.00062189
Epoch [6/300], Train Loss: 0.000646
Validation Loss: 0.00061896
Epoch [7/300], Train Loss: 0.000637
Validation Loss: 0.00061516
Epoch [8/300], Train Loss: 0.000637
Validation Loss: 0.00061072
Epoch [9/300], Train Loss: 0.000648
Validation Loss: 0.00060563
Epoch [10/300], Train Loss: 0.000620
Validation Loss: 0.00059742
Epoch [11/300], Train Loss: 0.000615
Validation Loss: 0.00059018
Epoch [12/300], Train Loss: 0.000616
Validation Loss: 0.00058060
Epoch [13/300], Train Loss: 0.000598
Validation Loss: 0.00055077
Epoch [14/300], Train Loss: 0.000573
Validation Loss: 0.00050626
Epoch [15/300], Train Loss: 0.000539
Validation Loss: 0.00048537
Epoch [16/300], Train Loss: 0.000527
Validation Loss: 0.00046685
Epoch [17/300], Train Loss: 0.000530
Validation Loss: 0.00053294
Epoch [18/300], Train Loss: 0.000537
Validation Loss: 0.00045524
Epoch [19/300], Train Loss: 0.000508
Validation Loss: 0.00045518
Epoch [20/300], Train Loss: 0.000513
Validation Loss: 0.00044712
Epoch [21/300], Train Loss: 0.000517
Validation Loss: 0.00045842
Epoch [22/300], Train Loss: 0.000524
Validation Loss: 0.00044104
Epoch [23/300], Train Loss: 0.000508
Validation Loss: 0.00047549
Epoch [24/300], Train Loss: 0.000537
Validation Loss: 0.00048837
Epoch [25/300], Train Loss: 0.000514
Validation Loss: 0.00047913
Epoch [26/300], Train Loss: 0.000527
Validation Loss: 0.00044772
Epoch [27/300], Train Loss: 0.000503
Validation Loss: 0.00042753
Epoch [28/300], Train Loss: 0.000498
Validation Loss: 0.00043342
Epoch [29/300], Train Loss: 0.000496
Validation Loss: 0.00042898
Epoch [30/300], Train Loss: 0.000497
Validation Loss: 0.00042946
Epoch [31/300], Train Loss: 0.000496
Validation Loss: 0.00041829
Epoch [32/300], Train Loss: 0.000499
Validation Loss: 0.00044119
Epoch [33/300], Train Loss: 0.000504
Validation Loss: 0.00042951
Epoch [34/300], Train Loss: 0.000505
Validation Loss: 0.00041114
Epoch [35/300], Train Loss: 0.000505
Validation Loss: 0.00041655
Epoch [36/300], Train Loss: 0.000490
Validation Loss: 0.00043609
Epoch [37/300], Train Loss: 0.000497
Validation Loss: 0.00041184
Epoch [38/300], Train Loss: 0.000495
Validation Loss: 0.00043332
Epoch [39/300], Train Loss: 0.000489
Validation Loss: 0.00042304
Epoch [40/300], Train Loss: 0.000495
Validation Loss: 0.00040645
Epoch [41/300], Train Loss: 0.000489
Validation Loss: 0.00041347
Epoch [42/300], Train Loss: 0.000488
Validation Loss: 0.00040081
Epoch [43/300], Train Loss: 0.000485
Validation Loss: 0.00039583
Epoch [44/300], Train Loss: 0.000496
Validation Loss: 0.00040164
Epoch [45/300], Train Loss: 0.000494
Validation Loss: 0.00039397
Epoch [46/300], Train Loss: 0.000482
Validation Loss: 0.00040112
Epoch [47/300], Train Loss: 0.000483
Validation Loss: 0.00039978
Epoch [48/300], Train Loss: 0.000479
Validation Loss: 0.00039713
Epoch [49/300], Train Loss: 0.000478
Validation Loss: 0.00039459
Epoch [50/300], Train Loss: 0.000478
Validation Loss: 0.00041347
Epoch [51/300], Train Loss: 0.000476
Validation Loss: 0.00039284
Epoch [52/300], Train Loss: 0.000481
Validation Loss: 0.00040405
Epoch [53/300], Train Loss: 0.000481
Validation Loss: 0.00043386
Epoch [54/300], Train Loss: 0.000495
Validation Loss: 0.00042354
Epoch [55/300], Train Loss: 0.000479
Validation Loss: 0.00041419
Epoch [56/300], Train Loss: 0.000475
Validation Loss: 0.00039175
Epoch [57/300], Train Loss: 0.000470
Validation Loss: 0.00038855
Epoch [58/300], Train Loss: 0.000469
Validation Loss: 0.00038850
Epoch [59/300], Train Loss: 0.000472
Validation Loss: 0.00039344
Epoch [60/300], Train Loss: 0.000484
Validation Loss: 0.00043361
Epoch [61/300], Train Loss: 0.000473
Validation Loss: 0.00039006
Epoch [62/300], Train Loss: 0.000492
Validation Loss: 0.00037874
Epoch [63/300], Train Loss: 0.000465
Validation Loss: 0.00037690
Epoch [64/300], Train Loss: 0.000462
Validation Loss: 0.00036417
Epoch [65/300], Train Loss: 0.000467
Validation Loss: 0.00036383
Epoch [66/300], Train Loss: 0.000464
Validation Loss: 0.00033534
Epoch [67/300], Train Loss: 0.000456
Validation Loss: 0.00031959
Epoch [68/300], Train Loss: 0.000458
Validation Loss: 0.00034962
Epoch [69/300], Train Loss: 0.000460
Validation Loss: 0.00031527
Epoch [70/300], Train Loss: 0.000456
Validation Loss: 0.00034239
Epoch [71/300], Train Loss: 0.000446
Validation Loss: 0.00031998
Epoch [72/300], Train Loss: 0.000451
Validation Loss: 0.00034576
Epoch [73/300], Train Loss: 0.000445
Validation Loss: 0.00031945
Epoch [74/300], Train Loss: 0.000444
Validation Loss: 0.00033443
Epoch [75/300], Train Loss: 0.000451
Validation Loss: 0.00033441
Epoch [76/300], Train Loss: 0.000447
Validation Loss: 0.00031457
Epoch [77/300], Train Loss: 0.000451
Validation Loss: 0.00034527
Epoch [78/300], Train Loss: 0.000440
Validation Loss: 0.00031508
Epoch [79/300], Train Loss: 0.000443
Validation Loss: 0.00031601
Epoch [80/300], Train Loss: 0.000452
Validation Loss: 0.00031906
Epoch [81/300], Train Loss: 0.000441
Validation Loss: 0.00033806
Epoch [82/300], Train Loss: 0.000439
Validation Loss: 0.00033775
Epoch [83/300], Train Loss: 0.000440
Validation Loss: 0.00031082
Epoch [84/300], Train Loss: 0.000436
Validation Loss: 0.00030954
Epoch [85/300], Train Loss: 0.000433
Validation Loss: 0.00032490
Epoch [86/300], Train Loss: 0.000428
Validation Loss: 0.00031026
Epoch [87/300], Train Loss: 0.000428
Validation Loss: 0.00031029
Epoch [88/300], Train Loss: 0.000425
Validation Loss: 0.00033886
Epoch [89/300], Train Loss: 0.000431
Validation Loss: 0.00030163
Epoch [90/300], Train Loss: 0.000428
Validation Loss: 0.00032165
Epoch [91/300], Train Loss: 0.000428
Validation Loss: 0.00029983
Epoch [92/300], Train Loss: 0.000423
Validation Loss: 0.00031831
Epoch [93/300], Train Loss: 0.000422
Validation Loss: 0.00030454
Epoch [94/300], Train Loss: 0.000419
Validation Loss: 0.00030573
Epoch [95/300], Train Loss: 0.000422
Validation Loss: 0.00030944
Epoch [96/300], Train Loss: 0.000419
Validation Loss: 0.00032033
Epoch [97/300], Train Loss: 0.000425
Validation Loss: 0.00029689
Epoch [98/300], Train Loss: 0.000419
Validation Loss: 0.00029956
Epoch [99/300], Train Loss: 0.000419
Validation Loss: 0.00035060
Epoch [100/300], Train Loss: 0.000422
Validation Loss: 0.00029730
Epoch [101/300], Train Loss: 0.000415
Validation Loss: 0.00032798
Epoch [102/300], Train Loss: 0.000411
Validation Loss: 0.00030790
Epoch [103/300], Train Loss: 0.000418
Validation Loss: 0.00031005
Epoch [104/300], Train Loss: 0.000415
Validation Loss: 0.00031299
Epoch [105/300], Train Loss: 0.000417
Validation Loss: 0.00029525
Epoch [106/300], Train Loss: 0.000415
Validation Loss: 0.00030938
Epoch [107/300], Train Loss: 0.000409
Validation Loss: 0.00030163
Epoch [108/300], Train Loss: 0.000411
Validation Loss: 0.00028684
Epoch [109/300], Train Loss: 0.000414
Validation Loss: 0.00030698
Epoch [110/300], Train Loss: 0.000410
Validation Loss: 0.00029933
Epoch [111/300], Train Loss: 0.000417
Validation Loss: 0.00032101
Epoch [112/300], Train Loss: 0.000418
Validation Loss: 0.00031690
Epoch [113/300], Train Loss: 0.000414
Validation Loss: 0.00028665
Epoch [114/300], Train Loss: 0.000405
Validation Loss: 0.00031954
Epoch [115/300], Train Loss: 0.000404
Validation Loss: 0.00028738
Epoch [116/300], Train Loss: 0.000404
Validation Loss: 0.00029197
Epoch [117/300], Train Loss: 0.000404
Validation Loss: 0.00030693
Epoch [118/300], Train Loss: 0.000405
Validation Loss: 0.00028719
Epoch [119/300], Train Loss: 0.000400
Validation Loss: 0.00029772
Epoch [120/300], Train Loss: 0.000397
Validation Loss: 0.00027999
Epoch [121/300], Train Loss: 0.000409
Validation Loss: 0.00029700
Epoch [122/300], Train Loss: 0.000399
Validation Loss: 0.00029072
Epoch [123/300], Train Loss: 0.000397
Validation Loss: 0.00028625
Epoch [124/300], Train Loss: 0.000400
Validation Loss: 0.00028180
Epoch [125/300], Train Loss: 0.000393
Validation Loss: 0.00029256
Epoch [126/300], Train Loss: 0.000413
Validation Loss: 0.00027995
Epoch [127/300], Train Loss: 0.000405
Validation Loss: 0.00027616
Epoch [128/300], Train Loss: 0.000400
Validation Loss: 0.00027336
Epoch [129/300], Train Loss: 0.000401
Validation Loss: 0.00028806
Epoch [130/300], Train Loss: 0.000395
Validation Loss: 0.00027828
Epoch [131/300], Train Loss: 0.000396
Validation Loss: 0.00028477
Epoch [132/300], Train Loss: 0.000392
Validation Loss: 0.00028454
Epoch [133/300], Train Loss: 0.000405
Validation Loss: 0.00027811
Epoch [134/300], Train Loss: 0.000405
Validation Loss: 0.00028582
Epoch [135/300], Train Loss: 0.000401
Validation Loss: 0.00027680
Epoch [136/300], Train Loss: 0.000396
Validation Loss: 0.00028559
Epoch [137/300], Train Loss: 0.000388
Validation Loss: 0.00028636
Epoch [138/300], Train Loss: 0.000386
Validation Loss: 0.00027185
Epoch [139/300], Train Loss: 0.000400
Validation Loss: 0.00029913
Epoch [140/300], Train Loss: 0.000391
Validation Loss: 0.00028194
Epoch [141/300], Train Loss: 0.000392
Validation Loss: 0.00028211
Epoch [142/300], Train Loss: 0.000388
Validation Loss: 0.00028695
Epoch [143/300], Train Loss: 0.000396
Validation Loss: 0.00027560
Epoch [144/300], Train Loss: 0.000386
Validation Loss: 0.00028876
Epoch [145/300], Train Loss: 0.000390
Validation Loss: 0.00028804
Epoch [146/300], Train Loss: 0.000394
Validation Loss: 0.00030124
Epoch [147/300], Train Loss: 0.000390
Validation Loss: 0.00027912
Epoch [148/300], Train Loss: 0.000394
Validation Loss: 0.00027885
Early stopping triggered

Evaluating model for: Microwave
Run 18/72 completed in 758.91 seconds with: {'MAE': np.float32(9.190222), 'MSE': np.float32(5728.805), 'RMSE': np.float32(75.68887), 'SAE': np.float32(0.02084281), 'NDE': np.float32(0.7136413)}

Run 19/72: hidden=128, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Microwave
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.000721
Validation Loss: 0.00063027
Epoch [2/300], Train Loss: 0.000653
Validation Loss: 0.00063027
Epoch [3/300], Train Loss: 0.000660
Validation Loss: 0.00062963
Epoch [4/300], Train Loss: 0.000657
Validation Loss: 0.00063000
Epoch [5/300], Train Loss: 0.000663
Validation Loss: 0.00062938
Epoch [6/300], Train Loss: 0.000657
Validation Loss: 0.00062916
Epoch [7/300], Train Loss: 0.000651
Validation Loss: 0.00062913
Epoch [8/300], Train Loss: 0.000655
Validation Loss: 0.00062886
Epoch [9/300], Train Loss: 0.000670
Validation Loss: 0.00062926
Epoch [10/300], Train Loss: 0.000645
Validation Loss: 0.00062809
Epoch [11/300], Train Loss: 0.000644
Validation Loss: 0.00062779
Epoch [12/300], Train Loss: 0.000651
Validation Loss: 0.00062736
Epoch [13/300], Train Loss: 0.000645
Validation Loss: 0.00062392
Epoch [14/300], Train Loss: 0.000637
Validation Loss: 0.00062070
Epoch [15/300], Train Loss: 0.000635
Validation Loss: 0.00061788
Epoch [16/300], Train Loss: 0.000632
Validation Loss: 0.00061277
Epoch [17/300], Train Loss: 0.000625
Validation Loss: 0.00060947
Epoch [18/300], Train Loss: 0.000625
Validation Loss: 0.00060681
Epoch [19/300], Train Loss: 0.000620
Validation Loss: 0.00060014
Epoch [20/300], Train Loss: 0.000621
Validation Loss: 0.00059300
Epoch [21/300], Train Loss: 0.000616
Validation Loss: 0.00058436
Epoch [22/300], Train Loss: 0.000613
Validation Loss: 0.00055130
Epoch [23/300], Train Loss: 0.000575
Validation Loss: 0.00048261
Epoch [24/300], Train Loss: 0.000548
Validation Loss: 0.00046886
Epoch [25/300], Train Loss: 0.000520
Validation Loss: 0.00047229
Epoch [26/300], Train Loss: 0.000526
Validation Loss: 0.00045717
Epoch [27/300], Train Loss: 0.000526
Validation Loss: 0.00044793
Epoch [28/300], Train Loss: 0.000513
Validation Loss: 0.00042973
Epoch [29/300], Train Loss: 0.000507
Validation Loss: 0.00042532
Epoch [30/300], Train Loss: 0.000507
Validation Loss: 0.00042292
Epoch [31/300], Train Loss: 0.000509
Validation Loss: 0.00041706
Epoch [32/300], Train Loss: 0.000511
Validation Loss: 0.00044317
Epoch [33/300], Train Loss: 0.000513
Validation Loss: 0.00043358
Epoch [34/300], Train Loss: 0.000512
Validation Loss: 0.00041079
Epoch [35/300], Train Loss: 0.000516
Validation Loss: 0.00040970
Epoch [36/300], Train Loss: 0.000497
Validation Loss: 0.00041971
Epoch [37/300], Train Loss: 0.000503
Validation Loss: 0.00040862
Epoch [38/300], Train Loss: 0.000506
Validation Loss: 0.00042700
Epoch [39/300], Train Loss: 0.000499
Validation Loss: 0.00042590
Epoch [40/300], Train Loss: 0.000503
Validation Loss: 0.00040417
Epoch [41/300], Train Loss: 0.000498
Validation Loss: 0.00040471
Epoch [42/300], Train Loss: 0.000493
Validation Loss: 0.00039814
Epoch [43/300], Train Loss: 0.000491
Validation Loss: 0.00039203
Epoch [44/300], Train Loss: 0.000497
Validation Loss: 0.00039088
Epoch [45/300], Train Loss: 0.000497
Validation Loss: 0.00038270
Epoch [46/300], Train Loss: 0.000486
Validation Loss: 0.00038406
Epoch [47/300], Train Loss: 0.000483
Validation Loss: 0.00038000
Epoch [48/300], Train Loss: 0.000481
Validation Loss: 0.00037480
Epoch [49/300], Train Loss: 0.000478
Validation Loss: 0.00036914
Epoch [50/300], Train Loss: 0.000475
Validation Loss: 0.00037558
Epoch [51/300], Train Loss: 0.000472
Validation Loss: 0.00034937
Epoch [52/300], Train Loss: 0.000476
Validation Loss: 0.00035328
Epoch [53/300], Train Loss: 0.000480
Validation Loss: 0.00038683
Epoch [54/300], Train Loss: 0.000480
Validation Loss: 0.00035065
Epoch [55/300], Train Loss: 0.000471
Validation Loss: 0.00033811
Epoch [56/300], Train Loss: 0.000467
Validation Loss: 0.00031826
Epoch [57/300], Train Loss: 0.000460
Validation Loss: 0.00031931
Epoch [58/300], Train Loss: 0.000462
Validation Loss: 0.00031021
Epoch [59/300], Train Loss: 0.000463
Validation Loss: 0.00032078
Epoch [60/300], Train Loss: 0.000472
Validation Loss: 0.00036626
Epoch [61/300], Train Loss: 0.000460
Validation Loss: 0.00031673
Epoch [62/300], Train Loss: 0.000480
Validation Loss: 0.00030688
Epoch [63/300], Train Loss: 0.000455
Validation Loss: 0.00031386
Epoch [64/300], Train Loss: 0.000456
Validation Loss: 0.00030701
Epoch [65/300], Train Loss: 0.000458
Validation Loss: 0.00031855
Epoch [66/300], Train Loss: 0.000458
Validation Loss: 0.00030651
Epoch [67/300], Train Loss: 0.000454
Validation Loss: 0.00030164
Epoch [68/300], Train Loss: 0.000454
Validation Loss: 0.00032025
Epoch [69/300], Train Loss: 0.000462
Validation Loss: 0.00030286
Epoch [70/300], Train Loss: 0.000453
Validation Loss: 0.00030966
Epoch [71/300], Train Loss: 0.000449
Validation Loss: 0.00030658
Epoch [72/300], Train Loss: 0.000453
Validation Loss: 0.00031145
Epoch [73/300], Train Loss: 0.000446
Validation Loss: 0.00029503
Epoch [74/300], Train Loss: 0.000446
Validation Loss: 0.00030210
Epoch [75/300], Train Loss: 0.000452
Validation Loss: 0.00030972
Epoch [76/300], Train Loss: 0.000448
Validation Loss: 0.00029360
Epoch [77/300], Train Loss: 0.000451
Validation Loss: 0.00030424
Epoch [78/300], Train Loss: 0.000443
Validation Loss: 0.00028985
Epoch [79/300], Train Loss: 0.000454
Validation Loss: 0.00030198
Epoch [80/300], Train Loss: 0.000457
Validation Loss: 0.00029972
Epoch [81/300], Train Loss: 0.000444
Validation Loss: 0.00030287
Epoch [82/300], Train Loss: 0.000441
Validation Loss: 0.00030425
Epoch [83/300], Train Loss: 0.000445
Validation Loss: 0.00028920
Epoch [84/300], Train Loss: 0.000439
Validation Loss: 0.00029018
Epoch [85/300], Train Loss: 0.000439
Validation Loss: 0.00029595
Epoch [86/300], Train Loss: 0.000435
Validation Loss: 0.00028427
Epoch [87/300], Train Loss: 0.000434
Validation Loss: 0.00028616
Epoch [88/300], Train Loss: 0.000433
Validation Loss: 0.00031159
Epoch [89/300], Train Loss: 0.000440
Validation Loss: 0.00028723
Epoch [90/300], Train Loss: 0.000437
Validation Loss: 0.00029590
Epoch [91/300], Train Loss: 0.000434
Validation Loss: 0.00028048
Epoch [92/300], Train Loss: 0.000434
Validation Loss: 0.00028325
Epoch [93/300], Train Loss: 0.000440
Validation Loss: 0.00029622
Epoch [94/300], Train Loss: 0.000432
Validation Loss: 0.00028595
Epoch [95/300], Train Loss: 0.000431
Validation Loss: 0.00028512
Epoch [96/300], Train Loss: 0.000430
Validation Loss: 0.00028808
Epoch [97/300], Train Loss: 0.000438
Validation Loss: 0.00027699
Epoch [98/300], Train Loss: 0.000429
Validation Loss: 0.00027468
Epoch [99/300], Train Loss: 0.000428
Validation Loss: 0.00029496
Epoch [100/300], Train Loss: 0.000431
Validation Loss: 0.00027334
Epoch [101/300], Train Loss: 0.000425
Validation Loss: 0.00027912
Epoch [102/300], Train Loss: 0.000421
Validation Loss: 0.00028030
Epoch [103/300], Train Loss: 0.000429
Validation Loss: 0.00027780
Epoch [104/300], Train Loss: 0.000425
Validation Loss: 0.00027353
Epoch [105/300], Train Loss: 0.000427
Validation Loss: 0.00027695
Epoch [106/300], Train Loss: 0.000421
Validation Loss: 0.00027182
Epoch [107/300], Train Loss: 0.000414
Validation Loss: 0.00027423
Epoch [108/300], Train Loss: 0.000413
Validation Loss: 0.00026629
Epoch [109/300], Train Loss: 0.000428
Validation Loss: 0.00028082
Epoch [110/300], Train Loss: 0.000421
Validation Loss: 0.00029544
Epoch [111/300], Train Loss: 0.000419
Validation Loss: 0.00028155
Epoch [112/300], Train Loss: 0.000425
Validation Loss: 0.00029644
Epoch [113/300], Train Loss: 0.000415
Validation Loss: 0.00027690
Epoch [114/300], Train Loss: 0.000413
Validation Loss: 0.00029461
Epoch [115/300], Train Loss: 0.000408
Validation Loss: 0.00026623
Epoch [116/300], Train Loss: 0.000405
Validation Loss: 0.00026638
Epoch [117/300], Train Loss: 0.000403
Validation Loss: 0.00028566
Epoch [118/300], Train Loss: 0.000407
Validation Loss: 0.00027197
Epoch [119/300], Train Loss: 0.000399
Validation Loss: 0.00030318
Epoch [120/300], Train Loss: 0.000397
Validation Loss: 0.00026826
Epoch [121/300], Train Loss: 0.000407
Validation Loss: 0.00027213
Epoch [122/300], Train Loss: 0.000397
Validation Loss: 0.00027284
Epoch [123/300], Train Loss: 0.000395
Validation Loss: 0.00026862
Epoch [124/300], Train Loss: 0.000396
Validation Loss: 0.00026587
Epoch [125/300], Train Loss: 0.000390
Validation Loss: 0.00027287
Epoch [126/300], Train Loss: 0.000410
Validation Loss: 0.00026596
Epoch [127/300], Train Loss: 0.000399
Validation Loss: 0.00026821
Epoch [128/300], Train Loss: 0.000391
Validation Loss: 0.00025973
Epoch [129/300], Train Loss: 0.000389
Validation Loss: 0.00026392
Epoch [130/300], Train Loss: 0.000392
Validation Loss: 0.00025724
Epoch [131/300], Train Loss: 0.000393
Validation Loss: 0.00026691
Epoch [132/300], Train Loss: 0.000387
Validation Loss: 0.00025940
Epoch [133/300], Train Loss: 0.000400
Validation Loss: 0.00025960
Epoch [134/300], Train Loss: 0.000400
Validation Loss: 0.00026183
Epoch [135/300], Train Loss: 0.000395
Validation Loss: 0.00026892
Epoch [136/300], Train Loss: 0.000391
Validation Loss: 0.00027627
Epoch [137/300], Train Loss: 0.000380
Validation Loss: 0.00027967
Epoch [138/300], Train Loss: 0.000376
Validation Loss: 0.00026319
Epoch [139/300], Train Loss: 0.000398
Validation Loss: 0.00028557
Epoch [140/300], Train Loss: 0.000387
Validation Loss: 0.00026885
Early stopping triggered

Evaluating model for: Microwave
Run 19/72 completed in 778.48 seconds with: {'MAE': np.float32(9.861909), 'MSE': np.float32(5758.2046), 'RMSE': np.float32(75.882835), 'SAE': np.float32(0.07663771), 'NDE': np.float32(0.71547043)}

Run 20/72: hidden=128, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Microwave
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.000685
Validation Loss: 0.00062772
Epoch [2/300], Train Loss: 0.000647
Validation Loss: 0.00062822
Epoch [3/300], Train Loss: 0.000654
Validation Loss: 0.00062776
Epoch [4/300], Train Loss: 0.000651
Validation Loss: 0.00062788
Epoch [5/300], Train Loss: 0.000657
Validation Loss: 0.00062746
Epoch [6/300], Train Loss: 0.000651
Validation Loss: 0.00062734
Epoch [7/300], Train Loss: 0.000645
Validation Loss: 0.00062738
Epoch [8/300], Train Loss: 0.000648
Validation Loss: 0.00062707
Epoch [9/300], Train Loss: 0.000664
Validation Loss: 0.00062747
Epoch [10/300], Train Loss: 0.000638
Validation Loss: 0.00062574
Epoch [11/300], Train Loss: 0.000637
Validation Loss: 0.00062410
Epoch [12/300], Train Loss: 0.000642
Validation Loss: 0.00061935
Epoch [13/300], Train Loss: 0.000630
Validation Loss: 0.00060514
Epoch [14/300], Train Loss: 0.000616
Validation Loss: 0.00059185
Epoch [15/300], Train Loss: 0.000603
Validation Loss: 0.00056553
Epoch [16/300], Train Loss: 0.000587
Validation Loss: 0.00055399
Epoch [17/300], Train Loss: 0.000576
Validation Loss: 0.00055229
Epoch [18/300], Train Loss: 0.000559
Validation Loss: 0.00047993
Epoch [19/300], Train Loss: 0.000525
Validation Loss: 0.00047265
Epoch [20/300], Train Loss: 0.000533
Validation Loss: 0.00046301
Epoch [21/300], Train Loss: 0.000532
Validation Loss: 0.00048550
Epoch [22/300], Train Loss: 0.000532
Validation Loss: 0.00045587
Epoch [23/300], Train Loss: 0.000517
Validation Loss: 0.00049328
Epoch [24/300], Train Loss: 0.000549
Validation Loss: 0.00051311
Epoch [25/300], Train Loss: 0.000532
Validation Loss: 0.00048568
Epoch [26/300], Train Loss: 0.000537
Validation Loss: 0.00044798
Epoch [27/300], Train Loss: 0.000511
Validation Loss: 0.00044488
Epoch [28/300], Train Loss: 0.000510
Validation Loss: 0.00045726
Epoch [29/300], Train Loss: 0.000508
Validation Loss: 0.00044497
Epoch [30/300], Train Loss: 0.000507
Validation Loss: 0.00044835
Epoch [31/300], Train Loss: 0.000508
Validation Loss: 0.00043609
Epoch [32/300], Train Loss: 0.000510
Validation Loss: 0.00044855
Epoch [33/300], Train Loss: 0.000517
Validation Loss: 0.00043713
Epoch [34/300], Train Loss: 0.000522
Validation Loss: 0.00044758
Epoch [35/300], Train Loss: 0.000514
Validation Loss: 0.00043721
Epoch [36/300], Train Loss: 0.000504
Validation Loss: 0.00044549
Epoch [37/300], Train Loss: 0.000508
Validation Loss: 0.00043010
Epoch [38/300], Train Loss: 0.000508
Validation Loss: 0.00045581
Epoch [39/300], Train Loss: 0.000505
Validation Loss: 0.00043273
Epoch [40/300], Train Loss: 0.000507
Validation Loss: 0.00042722
Epoch [41/300], Train Loss: 0.000503
Validation Loss: 0.00043140
Epoch [42/300], Train Loss: 0.000500
Validation Loss: 0.00042249
Epoch [43/300], Train Loss: 0.000502
Validation Loss: 0.00042003
Epoch [44/300], Train Loss: 0.000503
Validation Loss: 0.00042334
Epoch [45/300], Train Loss: 0.000504
Validation Loss: 0.00041833
Epoch [46/300], Train Loss: 0.000495
Validation Loss: 0.00042624
Epoch [47/300], Train Loss: 0.000494
Validation Loss: 0.00042236
Epoch [48/300], Train Loss: 0.000490
Validation Loss: 0.00042196
Epoch [49/300], Train Loss: 0.000489
Validation Loss: 0.00041470
Epoch [50/300], Train Loss: 0.000489
Validation Loss: 0.00041753
Epoch [51/300], Train Loss: 0.000486
Validation Loss: 0.00041071
Epoch [52/300], Train Loss: 0.000494
Validation Loss: 0.00043101
Epoch [53/300], Train Loss: 0.000488
Validation Loss: 0.00042476
Epoch [54/300], Train Loss: 0.000494
Validation Loss: 0.00042265
Epoch [55/300], Train Loss: 0.000489
Validation Loss: 0.00041369
Epoch [56/300], Train Loss: 0.000482
Validation Loss: 0.00040127
Epoch [57/300], Train Loss: 0.000479
Validation Loss: 0.00039954
Epoch [58/300], Train Loss: 0.000479
Validation Loss: 0.00039699
Epoch [59/300], Train Loss: 0.000478
Validation Loss: 0.00040230
Epoch [60/300], Train Loss: 0.000493
Validation Loss: 0.00043011
Epoch [61/300], Train Loss: 0.000480
Validation Loss: 0.00039193
Epoch [62/300], Train Loss: 0.000497
Validation Loss: 0.00038575
Epoch [63/300], Train Loss: 0.000471
Validation Loss: 0.00037831
Epoch [64/300], Train Loss: 0.000470
Validation Loss: 0.00034652
Epoch [65/300], Train Loss: 0.000472
Validation Loss: 0.00035617
Epoch [66/300], Train Loss: 0.000470
Validation Loss: 0.00033422
Epoch [67/300], Train Loss: 0.000464
Validation Loss: 0.00032701
Epoch [68/300], Train Loss: 0.000465
Validation Loss: 0.00035374
Epoch [69/300], Train Loss: 0.000467
Validation Loss: 0.00032278
Epoch [70/300], Train Loss: 0.000462
Validation Loss: 0.00035077
Epoch [71/300], Train Loss: 0.000455
Validation Loss: 0.00032561
Epoch [72/300], Train Loss: 0.000461
Validation Loss: 0.00034834
Epoch [73/300], Train Loss: 0.000454
Validation Loss: 0.00032619
Epoch [74/300], Train Loss: 0.000455
Validation Loss: 0.00033407
Epoch [75/300], Train Loss: 0.000460
Validation Loss: 0.00033644
Epoch [76/300], Train Loss: 0.000459
Validation Loss: 0.00032227
Epoch [77/300], Train Loss: 0.000465
Validation Loss: 0.00035165
Epoch [78/300], Train Loss: 0.000454
Validation Loss: 0.00032101
Epoch [79/300], Train Loss: 0.000458
Validation Loss: 0.00032641
Epoch [80/300], Train Loss: 0.000465
Validation Loss: 0.00033073
Epoch [81/300], Train Loss: 0.000456
Validation Loss: 0.00034026
Epoch [82/300], Train Loss: 0.000455
Validation Loss: 0.00033684
Epoch [83/300], Train Loss: 0.000454
Validation Loss: 0.00031986
Epoch [84/300], Train Loss: 0.000452
Validation Loss: 0.00032627
Epoch [85/300], Train Loss: 0.000448
Validation Loss: 0.00032654
Epoch [86/300], Train Loss: 0.000443
Validation Loss: 0.00031696
Epoch [87/300], Train Loss: 0.000444
Validation Loss: 0.00031836
Epoch [88/300], Train Loss: 0.000443
Validation Loss: 0.00032783
Epoch [89/300], Train Loss: 0.000449
Validation Loss: 0.00030769
Epoch [90/300], Train Loss: 0.000444
Validation Loss: 0.00034315
Epoch [91/300], Train Loss: 0.000443
Validation Loss: 0.00030821
Epoch [92/300], Train Loss: 0.000440
Validation Loss: 0.00032192
Epoch [93/300], Train Loss: 0.000438
Validation Loss: 0.00030983
Epoch [94/300], Train Loss: 0.000436
Validation Loss: 0.00031260
Epoch [95/300], Train Loss: 0.000439
Validation Loss: 0.00031190
Epoch [96/300], Train Loss: 0.000439
Validation Loss: 0.00031678
Epoch [97/300], Train Loss: 0.000444
Validation Loss: 0.00030136
Epoch [98/300], Train Loss: 0.000437
Validation Loss: 0.00030327
Epoch [99/300], Train Loss: 0.000436
Validation Loss: 0.00032616
Epoch [100/300], Train Loss: 0.000437
Validation Loss: 0.00030025
Epoch [101/300], Train Loss: 0.000432
Validation Loss: 0.00030956
Epoch [102/300], Train Loss: 0.000429
Validation Loss: 0.00030707
Epoch [103/300], Train Loss: 0.000430
Validation Loss: 0.00030409
Epoch [104/300], Train Loss: 0.000431
Validation Loss: 0.00030927
Epoch [105/300], Train Loss: 0.000435
Validation Loss: 0.00030076
Epoch [106/300], Train Loss: 0.000434
Validation Loss: 0.00030993
Epoch [107/300], Train Loss: 0.000425
Validation Loss: 0.00030012
Epoch [108/300], Train Loss: 0.000429
Validation Loss: 0.00029940
Epoch [109/300], Train Loss: 0.000426
Validation Loss: 0.00030282
Epoch [110/300], Train Loss: 0.000427
Validation Loss: 0.00030208
Epoch [111/300], Train Loss: 0.000430
Validation Loss: 0.00031200
Epoch [112/300], Train Loss: 0.000434
Validation Loss: 0.00030837
Epoch [113/300], Train Loss: 0.000429
Validation Loss: 0.00029471
Epoch [114/300], Train Loss: 0.000422
Validation Loss: 0.00030352
Epoch [115/300], Train Loss: 0.000423
Validation Loss: 0.00029706
Epoch [116/300], Train Loss: 0.000420
Validation Loss: 0.00029203
Epoch [117/300], Train Loss: 0.000421
Validation Loss: 0.00029776
Epoch [118/300], Train Loss: 0.000418
Validation Loss: 0.00029611
Epoch [119/300], Train Loss: 0.000417
Validation Loss: 0.00029139
Epoch [120/300], Train Loss: 0.000414
Validation Loss: 0.00029085
Epoch [121/300], Train Loss: 0.000426
Validation Loss: 0.00030086
Epoch [122/300], Train Loss: 0.000416
Validation Loss: 0.00028809
Epoch [123/300], Train Loss: 0.000413
Validation Loss: 0.00028844
Epoch [124/300], Train Loss: 0.000416
Validation Loss: 0.00028884
Epoch [125/300], Train Loss: 0.000412
Validation Loss: 0.00029340
Epoch [126/300], Train Loss: 0.000429
Validation Loss: 0.00028798
Epoch [127/300], Train Loss: 0.000421
Validation Loss: 0.00028337
Epoch [128/300], Train Loss: 0.000416
Validation Loss: 0.00028041
Epoch [129/300], Train Loss: 0.000412
Validation Loss: 0.00029092
Epoch [130/300], Train Loss: 0.000410
Validation Loss: 0.00028489
Epoch [131/300], Train Loss: 0.000413
Validation Loss: 0.00028645
Epoch [132/300], Train Loss: 0.000410
Validation Loss: 0.00028686
Epoch [133/300], Train Loss: 0.000421
Validation Loss: 0.00028147
Epoch [134/300], Train Loss: 0.000421
Validation Loss: 0.00029083
Epoch [135/300], Train Loss: 0.000417
Validation Loss: 0.00027899
Epoch [136/300], Train Loss: 0.000411
Validation Loss: 0.00028449
Epoch [137/300], Train Loss: 0.000406
Validation Loss: 0.00028187
Epoch [138/300], Train Loss: 0.000404
Validation Loss: 0.00028193
Epoch [139/300], Train Loss: 0.000413
Validation Loss: 0.00028855
Epoch [140/300], Train Loss: 0.000409
Validation Loss: 0.00027695
Epoch [141/300], Train Loss: 0.000411
Validation Loss: 0.00028302
Epoch [142/300], Train Loss: 0.000404
Validation Loss: 0.00028005
Epoch [143/300], Train Loss: 0.000414
Validation Loss: 0.00027467
Epoch [144/300], Train Loss: 0.000403
Validation Loss: 0.00028142
Epoch [145/300], Train Loss: 0.000409
Validation Loss: 0.00028352
Epoch [146/300], Train Loss: 0.000409
Validation Loss: 0.00028556
Epoch [147/300], Train Loss: 0.000404
Validation Loss: 0.00028349
Epoch [148/300], Train Loss: 0.000409
Validation Loss: 0.00027431
Epoch [149/300], Train Loss: 0.000405
Validation Loss: 0.00027787
Epoch [150/300], Train Loss: 0.000405
Validation Loss: 0.00028018
Epoch [151/300], Train Loss: 0.000404
Validation Loss: 0.00027283
Epoch [152/300], Train Loss: 0.000404
Validation Loss: 0.00027873
Epoch [153/300], Train Loss: 0.000399
Validation Loss: 0.00027299
Epoch [154/300], Train Loss: 0.000409
Validation Loss: 0.00027799
Epoch [155/300], Train Loss: 0.000403
Validation Loss: 0.00027889
Epoch [156/300], Train Loss: 0.000412
Validation Loss: 0.00027659
Epoch [157/300], Train Loss: 0.000395
Validation Loss: 0.00028162
Epoch [158/300], Train Loss: 0.000399
Validation Loss: 0.00027999
Epoch [159/300], Train Loss: 0.000399
Validation Loss: 0.00027001
Epoch [160/300], Train Loss: 0.000395
Validation Loss: 0.00028191
Epoch [161/300], Train Loss: 0.000402
Validation Loss: 0.00028239
Epoch [162/300], Train Loss: 0.000400
Validation Loss: 0.00027304
Epoch [163/300], Train Loss: 0.000397
Validation Loss: 0.00028029
Epoch [164/300], Train Loss: 0.000395
Validation Loss: 0.00027359
Epoch [165/300], Train Loss: 0.000395
Validation Loss: 0.00027016
Epoch [166/300], Train Loss: 0.000400
Validation Loss: 0.00027513
Epoch [167/300], Train Loss: 0.000395
Validation Loss: 0.00026965
Epoch [168/300], Train Loss: 0.000397
Validation Loss: 0.00027086
Epoch [169/300], Train Loss: 0.000396
Validation Loss: 0.00027854
Epoch [170/300], Train Loss: 0.000394
Validation Loss: 0.00026982
Epoch [171/300], Train Loss: 0.000396
Validation Loss: 0.00027056
Epoch [172/300], Train Loss: 0.000400
Validation Loss: 0.00027209
Epoch [173/300], Train Loss: 0.000393
Validation Loss: 0.00027119
Epoch [174/300], Train Loss: 0.000399
Validation Loss: 0.00027281
Epoch [175/300], Train Loss: 0.000397
Validation Loss: 0.00027061
Epoch [176/300], Train Loss: 0.000394
Validation Loss: 0.00027206
Epoch [177/300], Train Loss: 0.000401
Validation Loss: 0.00026911
Epoch [178/300], Train Loss: 0.000391
Validation Loss: 0.00026946
Epoch [179/300], Train Loss: 0.000401
Validation Loss: 0.00027402
Epoch [180/300], Train Loss: 0.000400
Validation Loss: 0.00027453
Epoch [181/300], Train Loss: 0.000391
Validation Loss: 0.00027723
Epoch [182/300], Train Loss: 0.000393
Validation Loss: 0.00027301
Epoch [183/300], Train Loss: 0.000391
Validation Loss: 0.00027275
Epoch [184/300], Train Loss: 0.000394
Validation Loss: 0.00027198
Epoch [185/300], Train Loss: 0.000394
Validation Loss: 0.00027241
Epoch [186/300], Train Loss: 0.000388
Validation Loss: 0.00026939
Epoch [187/300], Train Loss: 0.000389
Validation Loss: 0.00027394
Early stopping triggered

Evaluating model for: Microwave
Run 20/72 completed in 1056.77 seconds with: {'MAE': np.float32(8.065707), 'MSE': np.float32(5557.8384), 'RMSE': np.float32(74.55091), 'SAE': np.float32(0.027640466), 'NDE': np.float32(0.7029104)}

Run 21/72: hidden=128, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Microwave
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.001775
Validation Loss: 0.00072594
Epoch [2/300], Train Loss: 0.000832
Validation Loss: 0.00028362
Epoch [3/300], Train Loss: 0.000709
Validation Loss: 0.00029853
Epoch [4/300], Train Loss: 0.000695
Validation Loss: 0.00028350
Epoch [5/300], Train Loss: 0.000690
Validation Loss: 0.00028425
Epoch [6/300], Train Loss: 0.000685
Validation Loss: 0.00028038
Epoch [7/300], Train Loss: 0.000682
Validation Loss: 0.00028051
Epoch [8/300], Train Loss: 0.000680
Validation Loss: 0.00028051
Epoch [9/300], Train Loss: 0.000681
Validation Loss: 0.00027946
Epoch [10/300], Train Loss: 0.000679
Validation Loss: 0.00027959
Epoch [11/300], Train Loss: 0.000677
Validation Loss: 0.00027858
Epoch [12/300], Train Loss: 0.000676
Validation Loss: 0.00027820
Epoch [13/300], Train Loss: 0.000678
Validation Loss: 0.00027743
Epoch [14/300], Train Loss: 0.000675
Validation Loss: 0.00027656
Epoch [15/300], Train Loss: 0.000674
Validation Loss: 0.00027696
Epoch [16/300], Train Loss: 0.000668
Validation Loss: 0.00027615
Epoch [17/300], Train Loss: 0.000669
Validation Loss: 0.00027522
Epoch [18/300], Train Loss: 0.000665
Validation Loss: 0.00027500
Epoch [19/300], Train Loss: 0.000662
Validation Loss: 0.00027501
Epoch [20/300], Train Loss: 0.000662
Validation Loss: 0.00027401
Epoch [21/300], Train Loss: 0.000661
Validation Loss: 0.00027325
Epoch [22/300], Train Loss: 0.000658
Validation Loss: 0.00027277
Epoch [23/300], Train Loss: 0.000656
Validation Loss: 0.00027270
Epoch [24/300], Train Loss: 0.000652
Validation Loss: 0.00027244
Epoch [25/300], Train Loss: 0.000652
Validation Loss: 0.00027151
Epoch [26/300], Train Loss: 0.000650
Validation Loss: 0.00027067
Epoch [27/300], Train Loss: 0.000647
Validation Loss: 0.00026999
Epoch [28/300], Train Loss: 0.000641
Validation Loss: 0.00026973
Epoch [29/300], Train Loss: 0.000638
Validation Loss: 0.00026810
Epoch [30/300], Train Loss: 0.000634
Validation Loss: 0.00026801
Epoch [31/300], Train Loss: 0.000630
Validation Loss: 0.00026640
Epoch [32/300], Train Loss: 0.000625
Validation Loss: 0.00026541
Epoch [33/300], Train Loss: 0.000622
Validation Loss: 0.00026329
Epoch [34/300], Train Loss: 0.000613
Validation Loss: 0.00026282
Epoch [35/300], Train Loss: 0.000606
Validation Loss: 0.00025925
Epoch [36/300], Train Loss: 0.000596
Validation Loss: 0.00025730
Epoch [37/300], Train Loss: 0.000587
Validation Loss: 0.00025746
Epoch [38/300], Train Loss: 0.000576
Validation Loss: 0.00025431
Epoch [39/300], Train Loss: 0.000557
Validation Loss: 0.00026542
Epoch [40/300], Train Loss: 0.000553
Validation Loss: 0.00026088
Epoch [41/300], Train Loss: 0.000535
Validation Loss: 0.00025731
Epoch [42/300], Train Loss: 0.000527
Validation Loss: 0.00028237
Epoch [43/300], Train Loss: 0.000524
Validation Loss: 0.00026008
Epoch [44/300], Train Loss: 0.000511
Validation Loss: 0.00026753
Epoch [45/300], Train Loss: 0.000513
Validation Loss: 0.00025629
Epoch [46/300], Train Loss: 0.000523
Validation Loss: 0.00025853
Epoch [47/300], Train Loss: 0.000519
Validation Loss: 0.00025825
Epoch [48/300], Train Loss: 0.000510
Validation Loss: 0.00025874
Early stopping triggered

Evaluating model for: Microwave
Run 21/72 completed in 113.91 seconds with: {'MAE': np.float32(12.665191), 'MSE': np.float32(10813.914), 'RMSE': np.float32(103.98997), 'SAE': np.float32(0.13804083), 'NDE': np.float32(0.8490742)}

Run 22/72: hidden=128, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Microwave
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.001348
Validation Loss: 0.00041268
Epoch [2/300], Train Loss: 0.000715
Validation Loss: 0.00030259
Epoch [3/300], Train Loss: 0.000698
Validation Loss: 0.00028516
Epoch [4/300], Train Loss: 0.000679
Validation Loss: 0.00027882
Epoch [5/300], Train Loss: 0.000681
Validation Loss: 0.00027814
Epoch [6/300], Train Loss: 0.000677
Validation Loss: 0.00027880
Epoch [7/300], Train Loss: 0.000675
Validation Loss: 0.00027812
Epoch [8/300], Train Loss: 0.000674
Validation Loss: 0.00027790
Epoch [9/300], Train Loss: 0.000675
Validation Loss: 0.00027782
Epoch [10/300], Train Loss: 0.000673
Validation Loss: 0.00027766
Epoch [11/300], Train Loss: 0.000672
Validation Loss: 0.00027735
Epoch [12/300], Train Loss: 0.000672
Validation Loss: 0.00027734
Epoch [13/300], Train Loss: 0.000675
Validation Loss: 0.00027697
Epoch [14/300], Train Loss: 0.000672
Validation Loss: 0.00027681
Epoch [15/300], Train Loss: 0.000673
Validation Loss: 0.00027709
Epoch [16/300], Train Loss: 0.000667
Validation Loss: 0.00027672
Epoch [17/300], Train Loss: 0.000669
Validation Loss: 0.00027605
Epoch [18/300], Train Loss: 0.000664
Validation Loss: 0.00027597
Epoch [19/300], Train Loss: 0.000663
Validation Loss: 0.00027628
Epoch [20/300], Train Loss: 0.000664
Validation Loss: 0.00027514
Epoch [21/300], Train Loss: 0.000663
Validation Loss: 0.00027434
Epoch [22/300], Train Loss: 0.000660
Validation Loss: 0.00027386
Epoch [23/300], Train Loss: 0.000658
Validation Loss: 0.00027361
Epoch [24/300], Train Loss: 0.000654
Validation Loss: 0.00027393
Epoch [25/300], Train Loss: 0.000654
Validation Loss: 0.00027387
Epoch [26/300], Train Loss: 0.000650
Validation Loss: 0.00027323
Epoch [27/300], Train Loss: 0.000648
Validation Loss: 0.00027370
Epoch [28/300], Train Loss: 0.000641
Validation Loss: 0.00027453
Epoch [29/300], Train Loss: 0.000639
Validation Loss: 0.00027588
Epoch [30/300], Train Loss: 0.000635
Validation Loss: 0.00027591
Epoch [31/300], Train Loss: 0.000631
Validation Loss: 0.00027433
Epoch [32/300], Train Loss: 0.000622
Validation Loss: 0.00027253
Epoch [33/300], Train Loss: 0.000615
Validation Loss: 0.00026926
Epoch [34/300], Train Loss: 0.000598
Validation Loss: 0.00027205
Epoch [35/300], Train Loss: 0.000582
Validation Loss: 0.00027315
Epoch [36/300], Train Loss: 0.000555
Validation Loss: 0.00026969
Epoch [37/300], Train Loss: 0.000551
Validation Loss: 0.00028392
Epoch [38/300], Train Loss: 0.000552
Validation Loss: 0.00026631
Epoch [39/300], Train Loss: 0.000533
Validation Loss: 0.00027675
Epoch [40/300], Train Loss: 0.000575
Validation Loss: 0.00026746
Epoch [41/300], Train Loss: 0.000541
Validation Loss: 0.00027191
Epoch [42/300], Train Loss: 0.000534
Validation Loss: 0.00027620
Epoch [43/300], Train Loss: 0.000526
Validation Loss: 0.00026689
Epoch [44/300], Train Loss: 0.000520
Validation Loss: 0.00026887
Epoch [45/300], Train Loss: 0.000524
Validation Loss: 0.00026523
Epoch [46/300], Train Loss: 0.000533
Validation Loss: 0.00026424
Epoch [47/300], Train Loss: 0.000531
Validation Loss: 0.00026681
Epoch [48/300], Train Loss: 0.000519
Validation Loss: 0.00026430
Epoch [49/300], Train Loss: 0.000519
Validation Loss: 0.00026890
Epoch [50/300], Train Loss: 0.000516
Validation Loss: 0.00026670
Epoch [51/300], Train Loss: 0.000516
Validation Loss: 0.00026551
Epoch [52/300], Train Loss: 0.000519
Validation Loss: 0.00026531
Epoch [53/300], Train Loss: 0.000516
Validation Loss: 0.00026689
Epoch [54/300], Train Loss: 0.000516
Validation Loss: 0.00026699
Epoch [55/300], Train Loss: 0.000517
Validation Loss: 0.00026357
Epoch [56/300], Train Loss: 0.000518
Validation Loss: 0.00026716
Epoch [57/300], Train Loss: 0.000515
Validation Loss: 0.00026500
Epoch [58/300], Train Loss: 0.000514
Validation Loss: 0.00026527
Epoch [59/300], Train Loss: 0.000514
Validation Loss: 0.00026818
Epoch [60/300], Train Loss: 0.000513
Validation Loss: 0.00026463
Epoch [61/300], Train Loss: 0.000512
Validation Loss: 0.00026751
Epoch [62/300], Train Loss: 0.000510
Validation Loss: 0.00026301
Epoch [63/300], Train Loss: 0.000513
Validation Loss: 0.00026593
Epoch [64/300], Train Loss: 0.000513
Validation Loss: 0.00026218
Epoch [65/300], Train Loss: 0.000509
Validation Loss: 0.00026925
Epoch [66/300], Train Loss: 0.000510
Validation Loss: 0.00026180
Epoch [67/300], Train Loss: 0.000512
Validation Loss: 0.00026494
Epoch [68/300], Train Loss: 0.000508
Validation Loss: 0.00026227
Epoch [69/300], Train Loss: 0.000510
Validation Loss: 0.00026660
Epoch [70/300], Train Loss: 0.000513
Validation Loss: 0.00026182
Epoch [71/300], Train Loss: 0.000507
Validation Loss: 0.00026739
Epoch [72/300], Train Loss: 0.000515
Validation Loss: 0.00026032
Epoch [73/300], Train Loss: 0.000508
Validation Loss: 0.00026879
Epoch [74/300], Train Loss: 0.000511
Validation Loss: 0.00026136
Epoch [75/300], Train Loss: 0.000513
Validation Loss: 0.00026171
Epoch [76/300], Train Loss: 0.000505
Validation Loss: 0.00026661
Epoch [77/300], Train Loss: 0.000507
Validation Loss: 0.00026079
Epoch [78/300], Train Loss: 0.000506
Validation Loss: 0.00026244
Epoch [79/300], Train Loss: 0.000505
Validation Loss: 0.00026295
Epoch [80/300], Train Loss: 0.000505
Validation Loss: 0.00026283
Epoch [81/300], Train Loss: 0.000505
Validation Loss: 0.00026392
Epoch [82/300], Train Loss: 0.000506
Validation Loss: 0.00026044
Early stopping triggered

Evaluating model for: Microwave
Run 22/72 completed in 212.03 seconds with: {'MAE': np.float32(11.402341), 'MSE': np.float32(10688.796), 'RMSE': np.float32(103.386635), 'SAE': np.float32(0.34047374), 'NDE': np.float32(0.84414774)}

Run 23/72: hidden=128, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Microwave
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.000915
Validation Loss: 0.00027875
Epoch [2/300], Train Loss: 0.000688
Validation Loss: 0.00030232
Epoch [3/300], Train Loss: 0.000679
Validation Loss: 0.00027796
Epoch [4/300], Train Loss: 0.000673
Validation Loss: 0.00027715
Epoch [5/300], Train Loss: 0.000674
Validation Loss: 0.00027796
Epoch [6/300], Train Loss: 0.000672
Validation Loss: 0.00027702
Epoch [7/300], Train Loss: 0.000669
Validation Loss: 0.00027741
Epoch [8/300], Train Loss: 0.000667
Validation Loss: 0.00027697
Epoch [9/300], Train Loss: 0.000669
Validation Loss: 0.00027685
Epoch [10/300], Train Loss: 0.000667
Validation Loss: 0.00027688
Epoch [11/300], Train Loss: 0.000665
Validation Loss: 0.00027643
Epoch [12/300], Train Loss: 0.000666
Validation Loss: 0.00027641
Epoch [13/300], Train Loss: 0.000669
Validation Loss: 0.00027586
Epoch [14/300], Train Loss: 0.000666
Validation Loss: 0.00027553
Epoch [15/300], Train Loss: 0.000666
Validation Loss: 0.00027653
Epoch [16/300], Train Loss: 0.000660
Validation Loss: 0.00027528
Epoch [17/300], Train Loss: 0.000661
Validation Loss: 0.00027450
Epoch [18/300], Train Loss: 0.000656
Validation Loss: 0.00027398
Epoch [19/300], Train Loss: 0.000655
Validation Loss: 0.00027588
Epoch [20/300], Train Loss: 0.000655
Validation Loss: 0.00027421
Epoch [21/300], Train Loss: 0.000654
Validation Loss: 0.00027348
Epoch [22/300], Train Loss: 0.000651
Validation Loss: 0.00027500
Epoch [23/300], Train Loss: 0.000649
Validation Loss: 0.00027358
Epoch [24/300], Train Loss: 0.000645
Validation Loss: 0.00027408
Epoch [25/300], Train Loss: 0.000643
Validation Loss: 0.00027476
Epoch [26/300], Train Loss: 0.000641
Validation Loss: 0.00027414
Epoch [27/300], Train Loss: 0.000636
Validation Loss: 0.00027470
Epoch [28/300], Train Loss: 0.000625
Validation Loss: 0.00027338
Epoch [29/300], Train Loss: 0.000616
Validation Loss: 0.00027589
Epoch [30/300], Train Loss: 0.000591
Validation Loss: 0.00027329
Epoch [31/300], Train Loss: 0.000562
Validation Loss: 0.00027406
Epoch [32/300], Train Loss: 0.000537
Validation Loss: 0.00027130
Epoch [33/300], Train Loss: 0.000540
Validation Loss: 0.00027894
Epoch [34/300], Train Loss: 0.000553
Validation Loss: 0.00026835
Epoch [35/300], Train Loss: 0.000537
Validation Loss: 0.00028974
Epoch [36/300], Train Loss: 0.000524
Validation Loss: 0.00027156
Epoch [37/300], Train Loss: 0.000522
Validation Loss: 0.00027957
Epoch [38/300], Train Loss: 0.000525
Validation Loss: 0.00026990
Epoch [39/300], Train Loss: 0.000524
Validation Loss: 0.00028616
Epoch [40/300], Train Loss: 0.000555
Validation Loss: 0.00026938
Epoch [41/300], Train Loss: 0.000522
Validation Loss: 0.00027385
Epoch [42/300], Train Loss: 0.000520
Validation Loss: 0.00027694
Epoch [43/300], Train Loss: 0.000514
Validation Loss: 0.00026990
Epoch [44/300], Train Loss: 0.000510
Validation Loss: 0.00027363
Early stopping triggered

Evaluating model for: Microwave
Run 23/72 completed in 116.23 seconds with: {'MAE': np.float32(13.247909), 'MSE': np.float32(10530.069), 'RMSE': np.float32(102.61613), 'SAE': np.float32(0.1299382), 'NDE': np.float32(0.8378576)}

Run 24/72: hidden=128, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Microwave
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.002090
Validation Loss: 0.00079185
Epoch [2/300], Train Loss: 0.000843
Validation Loss: 0.00028333
Epoch [3/300], Train Loss: 0.000729
Validation Loss: 0.00029656
Epoch [4/300], Train Loss: 0.000698
Validation Loss: 0.00028575
Epoch [5/300], Train Loss: 0.000696
Validation Loss: 0.00028385
Epoch [6/300], Train Loss: 0.000691
Validation Loss: 0.00028037
Epoch [7/300], Train Loss: 0.000688
Validation Loss: 0.00028086
Epoch [8/300], Train Loss: 0.000687
Validation Loss: 0.00028133
Epoch [9/300], Train Loss: 0.000689
Validation Loss: 0.00028061
Epoch [10/300], Train Loss: 0.000687
Validation Loss: 0.00028115
Epoch [11/300], Train Loss: 0.000685
Validation Loss: 0.00028077
Epoch [12/300], Train Loss: 0.000686
Validation Loss: 0.00028063
Epoch [13/300], Train Loss: 0.000689
Validation Loss: 0.00028072
Epoch [14/300], Train Loss: 0.000686
Validation Loss: 0.00028071
Epoch [15/300], Train Loss: 0.000688
Validation Loss: 0.00028066
Epoch [16/300], Train Loss: 0.000682
Validation Loss: 0.00028122
Early stopping triggered

Evaluating model for: Microwave
Run 24/72 completed in 44.69 seconds with: {'MAE': np.float32(16.285845), 'MSE': np.float32(14865.768), 'RMSE': np.float32(121.925255), 'SAE': np.float32(0.12355566), 'NDE': np.float32(0.99551785)}

Run 25/72: hidden=256, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Microwave
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.000718
Validation Loss: 0.00057189
Epoch [2/300], Train Loss: 0.000637
Validation Loss: 0.00055674
Epoch [3/300], Train Loss: 0.000613
Validation Loss: 0.00053039
Epoch [4/300], Train Loss: 0.000561
Validation Loss: 0.00055231
Epoch [5/300], Train Loss: 0.000514
Validation Loss: 0.00050755
Epoch [6/300], Train Loss: 0.000500
Validation Loss: 0.00049013
Epoch [7/300], Train Loss: 0.000498
Validation Loss: 0.00050602
Epoch [8/300], Train Loss: 0.000493
Validation Loss: 0.00049346
Epoch [9/300], Train Loss: 0.000481
Validation Loss: 0.00048998
Epoch [10/300], Train Loss: 0.000476
Validation Loss: 0.00052448
Epoch [11/300], Train Loss: 0.000483
Validation Loss: 0.00049596
Epoch [12/300], Train Loss: 0.000473
Validation Loss: 0.00050277
Epoch [13/300], Train Loss: 0.000455
Validation Loss: 0.00048412
Epoch [14/300], Train Loss: 0.000458
Validation Loss: 0.00051713
Epoch [15/300], Train Loss: 0.000442
Validation Loss: 0.00055412
Epoch [16/300], Train Loss: 0.000434
Validation Loss: 0.00048979
Epoch [17/300], Train Loss: 0.000428
Validation Loss: 0.00055770
Epoch [18/300], Train Loss: 0.000437
Validation Loss: 0.00048122
Epoch [19/300], Train Loss: 0.000461
Validation Loss: 0.00045346
Epoch [20/300], Train Loss: 0.000455
Validation Loss: 0.00049951
Epoch [21/300], Train Loss: 0.000438
Validation Loss: 0.00047424
Epoch [22/300], Train Loss: 0.000413
Validation Loss: 0.00053468
Epoch [23/300], Train Loss: 0.000402
Validation Loss: 0.00046961
Epoch [24/300], Train Loss: 0.000407
Validation Loss: 0.00047403
Epoch [25/300], Train Loss: 0.000398
Validation Loss: 0.00046560
Epoch [26/300], Train Loss: 0.000395
Validation Loss: 0.00046722
Epoch [27/300], Train Loss: 0.000401
Validation Loss: 0.00046256
Epoch [28/300], Train Loss: 0.000412
Validation Loss: 0.00045955
Epoch [29/300], Train Loss: 0.000386
Validation Loss: 0.00050742
Early stopping triggered

Evaluating model for: Microwave
Run 25/72 completed in 784.20 seconds with: {'MAE': np.float32(10.336089), 'MSE': np.float32(6448.391), 'RMSE': np.float32(80.30187), 'SAE': np.float32(0.05376878), 'NDE': np.float32(0.69745404)}

Run 26/72: hidden=256, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Microwave
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.000674
Validation Loss: 0.00056915
Epoch [2/300], Train Loss: 0.000633
Validation Loss: 0.00055589
Epoch [3/300], Train Loss: 0.000602
Validation Loss: 0.00053669
Epoch [4/300], Train Loss: 0.000542
Validation Loss: 0.00055058
Epoch [5/300], Train Loss: 0.000535
Validation Loss: 0.00054131
Epoch [6/300], Train Loss: 0.000499
Validation Loss: 0.00053336
Epoch [7/300], Train Loss: 0.000502
Validation Loss: 0.00054343
Epoch [8/300], Train Loss: 0.000495
Validation Loss: 0.00054312
Epoch [9/300], Train Loss: 0.000482
Validation Loss: 0.00055297
Epoch [10/300], Train Loss: 0.000485
Validation Loss: 0.00053906
Epoch [11/300], Train Loss: 0.000489
Validation Loss: 0.00054473
Epoch [12/300], Train Loss: 0.000477
Validation Loss: 0.00055951
Epoch [13/300], Train Loss: 0.000463
Validation Loss: 0.00053789
Epoch [14/300], Train Loss: 0.000463
Validation Loss: 0.00054630
Epoch [15/300], Train Loss: 0.000449
Validation Loss: 0.00052931
Epoch [16/300], Train Loss: 0.000459
Validation Loss: 0.00054116
Epoch [17/300], Train Loss: 0.000431
Validation Loss: 0.00050247
Epoch [18/300], Train Loss: 0.000423
Validation Loss: 0.00050462
Epoch [19/300], Train Loss: 0.000418
Validation Loss: 0.00048533
Epoch [20/300], Train Loss: 0.000409
Validation Loss: 0.00056279
Epoch [21/300], Train Loss: 0.000400
Validation Loss: 0.00050994
Epoch [22/300], Train Loss: 0.000501
Validation Loss: 0.00063537
Epoch [23/300], Train Loss: 0.000523
Validation Loss: 0.00050755
Epoch [24/300], Train Loss: 0.000413
Validation Loss: 0.00045422
Epoch [25/300], Train Loss: 0.000384
Validation Loss: 0.00047187
Epoch [26/300], Train Loss: 0.000378
Validation Loss: 0.00047600
Epoch [27/300], Train Loss: 0.000369
Validation Loss: 0.00046707
Epoch [28/300], Train Loss: 0.000368
Validation Loss: 0.00046362
Epoch [29/300], Train Loss: 0.000379
Validation Loss: 0.00050269
Epoch [30/300], Train Loss: 0.000363
Validation Loss: 0.00048985
Epoch [31/300], Train Loss: 0.000352
Validation Loss: 0.00043991
Epoch [32/300], Train Loss: 0.000362
Validation Loss: 0.00045441
Epoch [33/300], Train Loss: 0.000353
Validation Loss: 0.00051106
Epoch [34/300], Train Loss: 0.000348
Validation Loss: 0.00046606
Epoch [35/300], Train Loss: 0.000358
Validation Loss: 0.00044611
Epoch [36/300], Train Loss: 0.000342
Validation Loss: 0.00045715
Epoch [37/300], Train Loss: 0.000335
Validation Loss: 0.00043347
Epoch [38/300], Train Loss: 0.000334
Validation Loss: 0.00046456
Epoch [39/300], Train Loss: 0.000333
Validation Loss: 0.00044495
Epoch [40/300], Train Loss: 0.000332
Validation Loss: 0.00045342
Epoch [41/300], Train Loss: 0.000337
Validation Loss: 0.00043327
Epoch [42/300], Train Loss: 0.000332
Validation Loss: 0.00042329
Epoch [43/300], Train Loss: 0.000318
Validation Loss: 0.00041578
Epoch [44/300], Train Loss: 0.000315
Validation Loss: 0.00043489
Epoch [45/300], Train Loss: 0.000317
Validation Loss: 0.00041051
Epoch [46/300], Train Loss: 0.000307
Validation Loss: 0.00043941
Epoch [47/300], Train Loss: 0.000308
Validation Loss: 0.00040323
Epoch [48/300], Train Loss: 0.000304
Validation Loss: 0.00041807
Epoch [49/300], Train Loss: 0.000306
Validation Loss: 0.00040779
Epoch [50/300], Train Loss: 0.000298
Validation Loss: 0.00040189
Epoch [51/300], Train Loss: 0.000305
Validation Loss: 0.00041106
Epoch [52/300], Train Loss: 0.000301
Validation Loss: 0.00040891
Epoch [53/300], Train Loss: 0.000289
Validation Loss: 0.00039768
Epoch [54/300], Train Loss: 0.000295
Validation Loss: 0.00041350
Epoch [55/300], Train Loss: 0.000305
Validation Loss: 0.00041661
Epoch [56/300], Train Loss: 0.000290
Validation Loss: 0.00039346
Epoch [57/300], Train Loss: 0.000285
Validation Loss: 0.00041645
Epoch [58/300], Train Loss: 0.000282
Validation Loss: 0.00039395
Epoch [59/300], Train Loss: 0.000286
Validation Loss: 0.00040809
Epoch [60/300], Train Loss: 0.000274
Validation Loss: 0.00042094
Epoch [61/300], Train Loss: 0.000269
Validation Loss: 0.00037014
Epoch [62/300], Train Loss: 0.000272
Validation Loss: 0.00041622
Epoch [63/300], Train Loss: 0.000276
Validation Loss: 0.00041198
Epoch [64/300], Train Loss: 0.000271
Validation Loss: 0.00037121
Epoch [65/300], Train Loss: 0.000266
Validation Loss: 0.00038120
Epoch [66/300], Train Loss: 0.000263
Validation Loss: 0.00039213
Epoch [67/300], Train Loss: 0.000261
Validation Loss: 0.00041284
Epoch [68/300], Train Loss: 0.000264
Validation Loss: 0.00039859
Epoch [69/300], Train Loss: 0.000264
Validation Loss: 0.00038385
Epoch [70/300], Train Loss: 0.000259
Validation Loss: 0.00040065
Epoch [71/300], Train Loss: 0.000259
Validation Loss: 0.00037329
Early stopping triggered

Evaluating model for: Microwave
Run 26/72 completed in 2131.91 seconds with: {'MAE': np.float32(6.1814227), 'MSE': np.float32(4976.5347), 'RMSE': np.float32(70.544556), 'SAE': np.float32(0.1078813), 'NDE': np.float32(0.6127065)}

Run 27/72: hidden=256, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Microwave
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.000654
Validation Loss: 0.00056826
Epoch [2/300], Train Loss: 0.000634
Validation Loss: 0.00056452
Epoch [3/300], Train Loss: 0.000616
Validation Loss: 0.00053565
Epoch [4/300], Train Loss: 0.000544
Validation Loss: 0.00054532
Epoch [5/300], Train Loss: 0.000513
Validation Loss: 0.00053158
Epoch [6/300], Train Loss: 0.000500
Validation Loss: 0.00052338
Epoch [7/300], Train Loss: 0.000505
Validation Loss: 0.00053677
Epoch [8/300], Train Loss: 0.000497
Validation Loss: 0.00052172
Epoch [9/300], Train Loss: 0.000485
Validation Loss: 0.00054202
Epoch [10/300], Train Loss: 0.000481
Validation Loss: 0.00055830
Epoch [11/300], Train Loss: 0.000519
Validation Loss: 0.00056462
Epoch [12/300], Train Loss: 0.000483
Validation Loss: 0.00055559
Epoch [13/300], Train Loss: 0.000466
Validation Loss: 0.00053684
Epoch [14/300], Train Loss: 0.000473
Validation Loss: 0.00055410
Epoch [15/300], Train Loss: 0.000460
Validation Loss: 0.00058538
Epoch [16/300], Train Loss: 0.000454
Validation Loss: 0.00052653
Epoch [17/300], Train Loss: 0.000442
Validation Loss: 0.00051146
Epoch [18/300], Train Loss: 0.000441
Validation Loss: 0.00051347
Epoch [19/300], Train Loss: 0.000422
Validation Loss: 0.00049326
Epoch [20/300], Train Loss: 0.000410
Validation Loss: 0.00054261
Epoch [21/300], Train Loss: 0.000401
Validation Loss: 0.00050318
Epoch [22/300], Train Loss: 0.000392
Validation Loss: 0.00055079
Epoch [23/300], Train Loss: 0.000390
Validation Loss: 0.00046185
Epoch [24/300], Train Loss: 0.000388
Validation Loss: 0.00051055
Epoch [25/300], Train Loss: 0.000374
Validation Loss: 0.00050579
Epoch [26/300], Train Loss: 0.000368
Validation Loss: 0.00043873
Epoch [27/300], Train Loss: 0.000359
Validation Loss: 0.00043911
Epoch [28/300], Train Loss: 0.000367
Validation Loss: 0.00042323
Epoch [29/300], Train Loss: 0.000371
Validation Loss: 0.00048007
Epoch [30/300], Train Loss: 0.000355
Validation Loss: 0.00045180
Epoch [31/300], Train Loss: 0.000340
Validation Loss: 0.00041196
Epoch [32/300], Train Loss: 0.000358
Validation Loss: 0.00041591
Epoch [33/300], Train Loss: 0.000336
Validation Loss: 0.00044312
Epoch [34/300], Train Loss: 0.000335
Validation Loss: 0.00044366
Epoch [35/300], Train Loss: 0.000348
Validation Loss: 0.00041497
Epoch [36/300], Train Loss: 0.000330
Validation Loss: 0.00043049
Epoch [37/300], Train Loss: 0.000325
Validation Loss: 0.00041617
Epoch [38/300], Train Loss: 0.000325
Validation Loss: 0.00043823
Epoch [39/300], Train Loss: 0.000323
Validation Loss: 0.00043159
Epoch [40/300], Train Loss: 0.000314
Validation Loss: 0.00045036
Epoch [41/300], Train Loss: 0.000312
Validation Loss: 0.00042258
Early stopping triggered

Evaluating model for: Microwave
Run 27/72 completed in 1260.64 seconds with: {'MAE': np.float32(7.7908106), 'MSE': np.float32(5873.346), 'RMSE': np.float32(76.63776), 'SAE': np.float32(0.014764233), 'NDE': np.float32(0.6656315)}

Run 28/72: hidden=256, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Microwave
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.000664
Validation Loss: 0.00057078
Epoch [2/300], Train Loss: 0.000639
Validation Loss: 0.00056557
Epoch [3/300], Train Loss: 0.000626
Validation Loss: 0.00055552
Epoch [4/300], Train Loss: 0.000585
Validation Loss: 0.00056061
Epoch [5/300], Train Loss: 0.000586
Validation Loss: 0.00054968
Epoch [6/300], Train Loss: 0.000527
Validation Loss: 0.00053986
Epoch [7/300], Train Loss: 0.000520
Validation Loss: 0.00055114
Epoch [8/300], Train Loss: 0.000506
Validation Loss: 0.00056037
Epoch [9/300], Train Loss: 0.000496
Validation Loss: 0.00056164
Epoch [10/300], Train Loss: 0.000497
Validation Loss: 0.00056406
Epoch [11/300], Train Loss: 0.000498
Validation Loss: 0.00056998
Epoch [12/300], Train Loss: 0.000499
Validation Loss: 0.00060485
Epoch [13/300], Train Loss: 0.000478
Validation Loss: 0.00056786
Epoch [14/300], Train Loss: 0.000487
Validation Loss: 0.00060289
Epoch [15/300], Train Loss: 0.000477
Validation Loss: 0.00059434
Epoch [16/300], Train Loss: 0.000473
Validation Loss: 0.00057900
Early stopping triggered

Evaluating model for: Microwave
Run 28/72 completed in 560.98 seconds with: {'MAE': np.float32(8.194243), 'MSE': np.float32(8520.497), 'RMSE': np.float32(92.30654), 'SAE': np.float32(0.25935173), 'NDE': np.float32(0.80171806)}

Run 29/72: hidden=256, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Microwave
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.000637
Validation Loss: 0.00096391
Epoch [2/300], Train Loss: 0.000620
Validation Loss: 0.00093914
Epoch [3/300], Train Loss: 0.000606
Validation Loss: 0.00089898
Epoch [4/300], Train Loss: 0.000585
Validation Loss: 0.00084518
Epoch [5/300], Train Loss: 0.000537
Validation Loss: 0.00071020
Epoch [6/300], Train Loss: 0.000518
Validation Loss: 0.00064607
Epoch [7/300], Train Loss: 0.000514
Validation Loss: 0.00064541
Epoch [8/300], Train Loss: 0.000508
Validation Loss: 0.00073463
Epoch [9/300], Train Loss: 0.000503
Validation Loss: 0.00073095
Epoch [10/300], Train Loss: 0.000518
Validation Loss: 0.00067845
Epoch [11/300], Train Loss: 0.000497
Validation Loss: 0.00070202
Epoch [12/300], Train Loss: 0.000491
Validation Loss: 0.00067387
Epoch [13/300], Train Loss: 0.000488
Validation Loss: 0.00069620
Epoch [14/300], Train Loss: 0.000486
Validation Loss: 0.00065811
Epoch [15/300], Train Loss: 0.000489
Validation Loss: 0.00071954
Epoch [16/300], Train Loss: 0.000468
Validation Loss: 0.00080740
Epoch [17/300], Train Loss: 0.000487
Validation Loss: 0.00070886
Early stopping triggered

Evaluating model for: Microwave
Run 29/72 completed in 223.73 seconds with: {'MAE': np.float32(11.171677), 'MSE': np.float32(7092.5815), 'RMSE': np.float32(84.21747), 'SAE': np.float32(0.33492187), 'NDE': np.float32(0.92877585)}

Run 30/72: hidden=256, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Microwave
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.000734
Validation Loss: 0.00098863
Epoch [2/300], Train Loss: 0.000641
Validation Loss: 0.00098350
Epoch [3/300], Train Loss: 0.000636
Validation Loss: 0.00097638
Epoch [4/300], Train Loss: 0.000632
Validation Loss: 0.00096022
Epoch [5/300], Train Loss: 0.000619
Validation Loss: 0.00092285
Epoch [6/300], Train Loss: 0.000598
Validation Loss: 0.00082975
Epoch [7/300], Train Loss: 0.000590
Validation Loss: 0.00081829
Epoch [8/300], Train Loss: 0.000561
Validation Loss: 0.00081252
Epoch [9/300], Train Loss: 0.000546
Validation Loss: 0.00079839
Epoch [10/300], Train Loss: 0.000555
Validation Loss: 0.00075359
Epoch [11/300], Train Loss: 0.000532
Validation Loss: 0.00071926
Epoch [12/300], Train Loss: 0.000521
Validation Loss: 0.00071905
Epoch [13/300], Train Loss: 0.000514
Validation Loss: 0.00069752
Epoch [14/300], Train Loss: 0.000507
Validation Loss: 0.00068947
Epoch [15/300], Train Loss: 0.000511
Validation Loss: 0.00075816
Epoch [16/300], Train Loss: 0.000495
Validation Loss: 0.00081891
Epoch [17/300], Train Loss: 0.000502
Validation Loss: 0.00071216
Epoch [18/300], Train Loss: 0.000492
Validation Loss: 0.00073119
Epoch [19/300], Train Loss: 0.000494
Validation Loss: 0.00070284
Epoch [20/300], Train Loss: 0.000491
Validation Loss: 0.00070506
Epoch [21/300], Train Loss: 0.000495
Validation Loss: 0.00071409
Epoch [22/300], Train Loss: 0.000501
Validation Loss: 0.00070354
Epoch [23/300], Train Loss: 0.000486
Validation Loss: 0.00065771
Epoch [24/300], Train Loss: 0.000485
Validation Loss: 0.00072275
Epoch [25/300], Train Loss: 0.000483
Validation Loss: 0.00072830
Epoch [26/300], Train Loss: 0.000483
Validation Loss: 0.00068773
Epoch [27/300], Train Loss: 0.000533
Validation Loss: 0.00074984
Epoch [28/300], Train Loss: 0.000503
Validation Loss: 0.00072445
Epoch [29/300], Train Loss: 0.000497
Validation Loss: 0.00069790
Epoch [30/300], Train Loss: 0.000481
Validation Loss: 0.00070271
Epoch [31/300], Train Loss: 0.000482
Validation Loss: 0.00073431
Epoch [32/300], Train Loss: 0.000492
Validation Loss: 0.00070779
Epoch [33/300], Train Loss: 0.000476
Validation Loss: 0.00070918
Early stopping triggered

Evaluating model for: Microwave
Run 30/72 completed in 473.76 seconds with: {'MAE': np.float32(9.544636), 'MSE': np.float32(7199.787), 'RMSE': np.float32(84.85156), 'SAE': np.float32(0.21702556), 'NDE': np.float32(0.93576837)}

Run 31/72: hidden=256, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Microwave
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.000634
Validation Loss: 0.00097630
Epoch [2/300], Train Loss: 0.000629
Validation Loss: 0.00097207
Epoch [3/300], Train Loss: 0.000624
Validation Loss: 0.00095763
Epoch [4/300], Train Loss: 0.000613
Validation Loss: 0.00091778
Epoch [5/300], Train Loss: 0.000560
Validation Loss: 0.00078568
Epoch [6/300], Train Loss: 0.000560
Validation Loss: 0.00077771
Epoch [7/300], Train Loss: 0.000519
Validation Loss: 0.00067305
Epoch [8/300], Train Loss: 0.000515
Validation Loss: 0.00081732
Epoch [9/300], Train Loss: 0.000512
Validation Loss: 0.00077167
Epoch [10/300], Train Loss: 0.000527
Validation Loss: 0.00070560
Epoch [11/300], Train Loss: 0.000510
Validation Loss: 0.00073505
Epoch [12/300], Train Loss: 0.000500
Validation Loss: 0.00071321
Epoch [13/300], Train Loss: 0.000497
Validation Loss: 0.00072990
Epoch [14/300], Train Loss: 0.000497
Validation Loss: 0.00069272
Epoch [15/300], Train Loss: 0.000498
Validation Loss: 0.00074732
Epoch [16/300], Train Loss: 0.000476
Validation Loss: 0.00085268
Epoch [17/300], Train Loss: 0.000507
Validation Loss: 0.00074060
Early stopping triggered

Evaluating model for: Microwave
Run 31/72 completed in 264.63 seconds with: {'MAE': np.float32(10.448191), 'MSE': np.float32(7357.7915), 'RMSE': np.float32(85.77757), 'SAE': np.float32(0.028575767), 'NDE': np.float32(0.9459813)}

Run 32/72: hidden=256, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Microwave
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.000772
Validation Loss: 0.00099070
Epoch [2/300], Train Loss: 0.000647
Validation Loss: 0.00098707
Epoch [3/300], Train Loss: 0.000643
Validation Loss: 0.00098408
Epoch [4/300], Train Loss: 0.000641
Validation Loss: 0.00098098
Epoch [5/300], Train Loss: 0.000635
Validation Loss: 0.00097612
Epoch [6/300], Train Loss: 0.000626
Validation Loss: 0.00093375
Epoch [7/300], Train Loss: 0.000601
Validation Loss: 0.00083065
Epoch [8/300], Train Loss: 0.000548
Validation Loss: 0.00083200
Epoch [9/300], Train Loss: 0.000539
Validation Loss: 0.00082732
Epoch [10/300], Train Loss: 0.000559
Validation Loss: 0.00074154
Epoch [11/300], Train Loss: 0.000543
Validation Loss: 0.00069746
Epoch [12/300], Train Loss: 0.000519
Validation Loss: 0.00071927
Epoch [13/300], Train Loss: 0.000511
Validation Loss: 0.00071188
Epoch [14/300], Train Loss: 0.000507
Validation Loss: 0.00069151
Epoch [15/300], Train Loss: 0.000510
Validation Loss: 0.00074487
Epoch [16/300], Train Loss: 0.000489
Validation Loss: 0.00083608
Epoch [17/300], Train Loss: 0.000508
Validation Loss: 0.00072824
Epoch [18/300], Train Loss: 0.000494
Validation Loss: 0.00073454
Epoch [19/300], Train Loss: 0.000491
Validation Loss: 0.00071983
Epoch [20/300], Train Loss: 0.000491
Validation Loss: 0.00072085
Epoch [21/300], Train Loss: 0.000494
Validation Loss: 0.00072077
Epoch [22/300], Train Loss: 0.000489
Validation Loss: 0.00068874
Epoch [23/300], Train Loss: 0.000482
Validation Loss: 0.00067054
Epoch [24/300], Train Loss: 0.000477
Validation Loss: 0.00071946
Epoch [25/300], Train Loss: 0.000474
Validation Loss: 0.00070635
Epoch [26/300], Train Loss: 0.000472
Validation Loss: 0.00067393
Epoch [27/300], Train Loss: 0.000468
Validation Loss: 0.00063390
Epoch [28/300], Train Loss: 0.000461
Validation Loss: 0.00069733
Epoch [29/300], Train Loss: 0.000466
Validation Loss: 0.00065278
Epoch [30/300], Train Loss: 0.000446
Validation Loss: 0.00063332
Epoch [31/300], Train Loss: 0.000460
Validation Loss: 0.00072439
Epoch [32/300], Train Loss: 0.000445
Validation Loss: 0.00063579
Epoch [33/300], Train Loss: 0.000442
Validation Loss: 0.00064621
Epoch [34/300], Train Loss: 0.000436
Validation Loss: 0.00071009
Epoch [35/300], Train Loss: 0.000441
Validation Loss: 0.00064893
Epoch [36/300], Train Loss: 0.000424
Validation Loss: 0.00068638
Epoch [37/300], Train Loss: 0.000428
Validation Loss: 0.00063063
Epoch [38/300], Train Loss: 0.000424
Validation Loss: 0.00060160
Epoch [39/300], Train Loss: 0.000430
Validation Loss: 0.00067250
Epoch [40/300], Train Loss: 0.000418
Validation Loss: 0.00060091
Epoch [41/300], Train Loss: 0.000430
Validation Loss: 0.00060124
Epoch [42/300], Train Loss: 0.000416
Validation Loss: 0.00068000
Epoch [43/300], Train Loss: 0.000411
Validation Loss: 0.00060644
Epoch [44/300], Train Loss: 0.000448
Validation Loss: 0.00081745
Epoch [45/300], Train Loss: 0.000515
Validation Loss: 0.00087132
Epoch [46/300], Train Loss: 0.000500
Validation Loss: 0.00085467
Epoch [47/300], Train Loss: 0.000500
Validation Loss: 0.00090738
Epoch [48/300], Train Loss: 0.000583
Validation Loss: 0.00089082
Epoch [49/300], Train Loss: 0.000543
Validation Loss: 0.00082650
Epoch [50/300], Train Loss: 0.000504
Validation Loss: 0.00085913
Early stopping triggered

Evaluating model for: Microwave
Run 32/72 completed in 889.58 seconds with: {'MAE': np.float32(6.7151585), 'MSE': np.float32(7557.2593), 'RMSE': np.float32(86.932495), 'SAE': np.float32(0.38134643), 'NDE': np.float32(0.9587167)}

Run 33/72: hidden=256, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Microwave
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.000679
Validation Loss: 0.00090538
Epoch [2/300], Train Loss: 0.000648
Validation Loss: 0.00089768
Epoch [3/300], Train Loss: 0.000622
Validation Loss: 0.00088812
Epoch [4/300], Train Loss: 0.000605
Validation Loss: 0.00087414
Epoch [5/300], Train Loss: 0.000585
Validation Loss: 0.00084962
Epoch [6/300], Train Loss: 0.000566
Validation Loss: 0.00079593
Epoch [7/300], Train Loss: 0.000526
Validation Loss: 0.00076027
Epoch [8/300], Train Loss: 0.000501
Validation Loss: 0.00069304
Epoch [9/300], Train Loss: 0.000527
Validation Loss: 0.00071527
Epoch [10/300], Train Loss: 0.000484
Validation Loss: 0.00074694
Epoch [11/300], Train Loss: 0.000481
Validation Loss: 0.00071443
Epoch [12/300], Train Loss: 0.000477
Validation Loss: 0.00071950
Epoch [13/300], Train Loss: 0.000475
Validation Loss: 0.00075633
Epoch [14/300], Train Loss: 0.000465
Validation Loss: 0.00069082
Epoch [15/300], Train Loss: 0.000532
Validation Loss: 0.00074073
Epoch [16/300], Train Loss: 0.000480
Validation Loss: 0.00073293
Epoch [17/300], Train Loss: 0.000467
Validation Loss: 0.00068963
Epoch [18/300], Train Loss: 0.000458
Validation Loss: 0.00069465
Epoch [19/300], Train Loss: 0.000460
Validation Loss: 0.00069334
Epoch [20/300], Train Loss: 0.000457
Validation Loss: 0.00067824
Epoch [21/300], Train Loss: 0.000451
Validation Loss: 0.00069875
Epoch [22/300], Train Loss: 0.000449
Validation Loss: 0.00071041
Epoch [23/300], Train Loss: 0.000453
Validation Loss: 0.00068256
Epoch [24/300], Train Loss: 0.000451
Validation Loss: 0.00072274
Epoch [25/300], Train Loss: 0.000457
Validation Loss: 0.00067963
Epoch [26/300], Train Loss: 0.000448
Validation Loss: 0.00069129
Epoch [27/300], Train Loss: 0.000443
Validation Loss: 0.00069966
Epoch [28/300], Train Loss: 0.000437
Validation Loss: 0.00070127
Epoch [29/300], Train Loss: 0.000544
Validation Loss: 0.00067345
Epoch [30/300], Train Loss: 0.000509
Validation Loss: 0.00066579
Epoch [31/300], Train Loss: 0.000427
Validation Loss: 0.00068770
Epoch [32/300], Train Loss: 0.000419
Validation Loss: 0.00069650
Epoch [33/300], Train Loss: 0.000427
Validation Loss: 0.00067803
Epoch [34/300], Train Loss: 0.000424
Validation Loss: 0.00073541
Epoch [35/300], Train Loss: 0.000425
Validation Loss: 0.00070487
Epoch [36/300], Train Loss: 0.000418
Validation Loss: 0.00068208
Epoch [37/300], Train Loss: 0.000413
Validation Loss: 0.00071150
Epoch [38/300], Train Loss: 0.000411
Validation Loss: 0.00070626
Epoch [39/300], Train Loss: 0.000412
Validation Loss: 0.00070512
Epoch [40/300], Train Loss: 0.000462
Validation Loss: 0.00068730
Early stopping triggered

Evaluating model for: Microwave
Run 33/72 completed in 473.21 seconds with: {'MAE': np.float32(12.578708), 'MSE': np.float32(7545.096), 'RMSE': np.float32(86.86251), 'SAE': np.float32(0.15343946), 'NDE': np.float32(0.8038685)}

Run 34/72: hidden=256, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Microwave
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.000633
Validation Loss: 0.00091045
Epoch [2/300], Train Loss: 0.000653
Validation Loss: 0.00090536
Epoch [3/300], Train Loss: 0.000627
Validation Loss: 0.00089813
Epoch [4/300], Train Loss: 0.000613
Validation Loss: 0.00088819
Epoch [5/300], Train Loss: 0.000594
Validation Loss: 0.00087959
Epoch [6/300], Train Loss: 0.000585
Validation Loss: 0.00085465
Epoch [7/300], Train Loss: 0.000569
Validation Loss: 0.00080912
Epoch [8/300], Train Loss: 0.000545
Validation Loss: 0.00075804
Epoch [9/300], Train Loss: 0.000551
Validation Loss: 0.00079360
Epoch [10/300], Train Loss: 0.000511
Validation Loss: 0.00079033
Epoch [11/300], Train Loss: 0.000488
Validation Loss: 0.00076407
Epoch [12/300], Train Loss: 0.000491
Validation Loss: 0.00076724
Epoch [13/300], Train Loss: 0.000478
Validation Loss: 0.00077467
Epoch [14/300], Train Loss: 0.000473
Validation Loss: 0.00074340
Epoch [15/300], Train Loss: 0.000547
Validation Loss: 0.00081128
Epoch [16/300], Train Loss: 0.000496
Validation Loss: 0.00078592
Epoch [17/300], Train Loss: 0.000484
Validation Loss: 0.00073919
Epoch [18/300], Train Loss: 0.000465
Validation Loss: 0.00074440
Epoch [19/300], Train Loss: 0.000466
Validation Loss: 0.00073355
Epoch [20/300], Train Loss: 0.000469
Validation Loss: 0.00073052
Epoch [21/300], Train Loss: 0.000457
Validation Loss: 0.00074733
Epoch [22/300], Train Loss: 0.000455
Validation Loss: 0.00074615
Epoch [23/300], Train Loss: 0.000461
Validation Loss: 0.00072460
Epoch [24/300], Train Loss: 0.000463
Validation Loss: 0.00076404
Epoch [25/300], Train Loss: 0.000470
Validation Loss: 0.00073282
Epoch [26/300], Train Loss: 0.000451
Validation Loss: 0.00073152
Epoch [27/300], Train Loss: 0.000451
Validation Loss: 0.00072566
Epoch [28/300], Train Loss: 0.000456
Validation Loss: 0.00071595
Epoch [29/300], Train Loss: 0.000555
Validation Loss: 0.00071086
Epoch [30/300], Train Loss: 0.000543
Validation Loss: 0.00072211
Epoch [31/300], Train Loss: 0.000444
Validation Loss: 0.00072513
Epoch [32/300], Train Loss: 0.000440
Validation Loss: 0.00072819
Epoch [33/300], Train Loss: 0.000444
Validation Loss: 0.00072500
Epoch [34/300], Train Loss: 0.000440
Validation Loss: 0.00075808
Epoch [35/300], Train Loss: 0.000443
Validation Loss: 0.00070712
Epoch [36/300], Train Loss: 0.000425
Validation Loss: 0.00071632
Epoch [37/300], Train Loss: 0.000424
Validation Loss: 0.00071988
Epoch [38/300], Train Loss: 0.000422
Validation Loss: 0.00071107
Epoch [39/300], Train Loss: 0.000420
Validation Loss: 0.00070705
Epoch [40/300], Train Loss: 0.000468
Validation Loss: 0.00071322
Epoch [41/300], Train Loss: 0.000492
Validation Loss: 0.00070099
Epoch [42/300], Train Loss: 0.000444
Validation Loss: 0.00071254
Epoch [43/300], Train Loss: 0.000520
Validation Loss: 0.00084718
Epoch [44/300], Train Loss: 0.000595
Validation Loss: 0.00084546
Epoch [45/300], Train Loss: 0.000544
Validation Loss: 0.00068989
Epoch [46/300], Train Loss: 0.000432
Validation Loss: 0.00069187
Epoch [47/300], Train Loss: 0.000405
Validation Loss: 0.00067928
Epoch [48/300], Train Loss: 0.000406
Validation Loss: 0.00068978
Epoch [49/300], Train Loss: 0.000398
Validation Loss: 0.00067565
Epoch [50/300], Train Loss: 0.000398
Validation Loss: 0.00069671
Epoch [51/300], Train Loss: 0.000410
Validation Loss: 0.00066337
Epoch [52/300], Train Loss: 0.000394
Validation Loss: 0.00068491
Epoch [53/300], Train Loss: 0.000386
Validation Loss: 0.00068934
Epoch [54/300], Train Loss: 0.000391
Validation Loss: 0.00066785
Epoch [55/300], Train Loss: 0.000383
Validation Loss: 0.00070475
Epoch [56/300], Train Loss: 0.000387
Validation Loss: 0.00065987
Epoch [57/300], Train Loss: 0.000401
Validation Loss: 0.00066205
Epoch [58/300], Train Loss: 0.000412
Validation Loss: 0.00065670
Epoch [59/300], Train Loss: 0.000401
Validation Loss: 0.00063430
Epoch [60/300], Train Loss: 0.000388
Validation Loss: 0.00064733
Epoch [61/300], Train Loss: 0.000382
Validation Loss: 0.00062774
Epoch [62/300], Train Loss: 0.000374
Validation Loss: 0.00061623
Epoch [63/300], Train Loss: 0.000374
Validation Loss: 0.00062040
Epoch [64/300], Train Loss: 0.000376
Validation Loss: 0.00063339
Epoch [65/300], Train Loss: 0.000374
Validation Loss: 0.00062461
Epoch [66/300], Train Loss: 0.000372
Validation Loss: 0.00062153
Epoch [67/300], Train Loss: 0.000358
Validation Loss: 0.00064364
Epoch [68/300], Train Loss: 0.000369
Validation Loss: 0.00061484
Epoch [69/300], Train Loss: 0.000387
Validation Loss: 0.00063617
Epoch [70/300], Train Loss: 0.000384
Validation Loss: 0.00060673
Epoch [71/300], Train Loss: 0.000365
Validation Loss: 0.00060245
Epoch [72/300], Train Loss: 0.000355
Validation Loss: 0.00061084
Epoch [73/300], Train Loss: 0.000355
Validation Loss: 0.00063192
Epoch [74/300], Train Loss: 0.000414
Validation Loss: 0.00062638
Epoch [75/300], Train Loss: 0.000352
Validation Loss: 0.00060764
Epoch [76/300], Train Loss: 0.000344
Validation Loss: 0.00059670
Epoch [77/300], Train Loss: 0.000337
Validation Loss: 0.00060748
Epoch [78/300], Train Loss: 0.000340
Validation Loss: 0.00060301
Epoch [79/300], Train Loss: 0.000338
Validation Loss: 0.00060153
Epoch [80/300], Train Loss: 0.000345
Validation Loss: 0.00060922
Epoch [81/300], Train Loss: 0.000338
Validation Loss: 0.00059576
Epoch [82/300], Train Loss: 0.000348
Validation Loss: 0.00056290
Epoch [83/300], Train Loss: 0.000363
Validation Loss: 0.00062142
Epoch [84/300], Train Loss: 0.000344
Validation Loss: 0.00059401
Epoch [85/300], Train Loss: 0.000333
Validation Loss: 0.00060566
Epoch [86/300], Train Loss: 0.000333
Validation Loss: 0.00059244
Epoch [87/300], Train Loss: 0.000328
Validation Loss: 0.00058817
Epoch [88/300], Train Loss: 0.000330
Validation Loss: 0.00058903
Epoch [89/300], Train Loss: 0.000327
Validation Loss: 0.00061706
Epoch [90/300], Train Loss: 0.000383
Validation Loss: 0.00059888
Epoch [91/300], Train Loss: 0.000383
Validation Loss: 0.00058954
Epoch [92/300], Train Loss: 0.000325
Validation Loss: 0.00059581
Early stopping triggered

Evaluating model for: Microwave
Run 34/72 completed in 1264.75 seconds with: {'MAE': np.float32(7.6926227), 'MSE': np.float32(6243.15), 'RMSE': np.float32(79.0136), 'SAE': np.float32(0.22965623), 'NDE': np.float32(0.73122907)}

Run 35/72: hidden=256, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Microwave
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.000667
Validation Loss: 0.00091592
Epoch [2/300], Train Loss: 0.000657
Validation Loss: 0.00091104
Epoch [3/300], Train Loss: 0.000634
Validation Loss: 0.00090917
Epoch [4/300], Train Loss: 0.000622
Validation Loss: 0.00090391
Epoch [5/300], Train Loss: 0.000606
Validation Loss: 0.00088833
Epoch [6/300], Train Loss: 0.000598
Validation Loss: 0.00087238
Epoch [7/300], Train Loss: 0.000587
Validation Loss: 0.00084469
Epoch [8/300], Train Loss: 0.000582
Validation Loss: 0.00085873
Epoch [9/300], Train Loss: 0.000553
Validation Loss: 0.00084647
Epoch [10/300], Train Loss: 0.000529
Validation Loss: 0.00082365
Epoch [11/300], Train Loss: 0.000515
Validation Loss: 0.00075601
Epoch [12/300], Train Loss: 0.000498
Validation Loss: 0.00076107
Epoch [13/300], Train Loss: 0.000491
Validation Loss: 0.00075543
Epoch [14/300], Train Loss: 0.000480
Validation Loss: 0.00071841
Epoch [15/300], Train Loss: 0.000550
Validation Loss: 0.00077783
Epoch [16/300], Train Loss: 0.000500
Validation Loss: 0.00077786
Epoch [17/300], Train Loss: 0.000490
Validation Loss: 0.00071902
Epoch [18/300], Train Loss: 0.000475
Validation Loss: 0.00073189
Epoch [19/300], Train Loss: 0.000477
Validation Loss: 0.00071818
Epoch [20/300], Train Loss: 0.000476
Validation Loss: 0.00070603
Epoch [21/300], Train Loss: 0.000463
Validation Loss: 0.00072281
Epoch [22/300], Train Loss: 0.000460
Validation Loss: 0.00072760
Epoch [23/300], Train Loss: 0.000462
Validation Loss: 0.00070571
Epoch [24/300], Train Loss: 0.000461
Validation Loss: 0.00076693
Epoch [25/300], Train Loss: 0.000470
Validation Loss: 0.00069802
Epoch [26/300], Train Loss: 0.000443
Validation Loss: 0.00071081
Epoch [27/300], Train Loss: 0.000444
Validation Loss: 0.00069804
Epoch [28/300], Train Loss: 0.000433
Validation Loss: 0.00070205
Epoch [29/300], Train Loss: 0.000541
Validation Loss: 0.00064716
Epoch [30/300], Train Loss: 0.000507
Validation Loss: 0.00070455
Epoch [31/300], Train Loss: 0.000424
Validation Loss: 0.00068577
Epoch [32/300], Train Loss: 0.000407
Validation Loss: 0.00069793
Epoch [33/300], Train Loss: 0.000418
Validation Loss: 0.00063180
Epoch [34/300], Train Loss: 0.000415
Validation Loss: 0.00074256
Epoch [35/300], Train Loss: 0.000405
Validation Loss: 0.00066421
Epoch [36/300], Train Loss: 0.000394
Validation Loss: 0.00064079
Epoch [37/300], Train Loss: 0.000398
Validation Loss: 0.00065188
Epoch [38/300], Train Loss: 0.000404
Validation Loss: 0.00067998
Epoch [39/300], Train Loss: 0.000392
Validation Loss: 0.00064940
Epoch [40/300], Train Loss: 0.000436
Validation Loss: 0.00064196
Epoch [41/300], Train Loss: 0.000459
Validation Loss: 0.00062660
Epoch [42/300], Train Loss: 0.000410
Validation Loss: 0.00063976
Epoch [43/300], Train Loss: 0.000380
Validation Loss: 0.00063339
Epoch [44/300], Train Loss: 0.000383
Validation Loss: 0.00060025
Epoch [45/300], Train Loss: 0.000416
Validation Loss: 0.00061065
Epoch [46/300], Train Loss: 0.000390
Validation Loss: 0.00060469
Epoch [47/300], Train Loss: 0.000358
Validation Loss: 0.00059850
Epoch [48/300], Train Loss: 0.000365
Validation Loss: 0.00066276
Epoch [49/300], Train Loss: 0.000360
Validation Loss: 0.00063553
Epoch [50/300], Train Loss: 0.000352
Validation Loss: 0.00062345
Epoch [51/300], Train Loss: 0.000370
Validation Loss: 0.00059113
Epoch [52/300], Train Loss: 0.000349
Validation Loss: 0.00059800
Epoch [53/300], Train Loss: 0.000347
Validation Loss: 0.00061683
Epoch [54/300], Train Loss: 0.000369
Validation Loss: 0.00058540
Epoch [55/300], Train Loss: 0.000351
Validation Loss: 0.00063670
Epoch [56/300], Train Loss: 0.000350
Validation Loss: 0.00063014
Epoch [57/300], Train Loss: 0.000349
Validation Loss: 0.00060133
Epoch [58/300], Train Loss: 0.000356
Validation Loss: 0.00058187
Epoch [59/300], Train Loss: 0.000344
Validation Loss: 0.00058429
Epoch [60/300], Train Loss: 0.000343
Validation Loss: 0.00058787
Epoch [61/300], Train Loss: 0.000336
Validation Loss: 0.00058767
Epoch [62/300], Train Loss: 0.000335
Validation Loss: 0.00058187
Epoch [63/300], Train Loss: 0.000342
Validation Loss: 0.00059239
Epoch [64/300], Train Loss: 0.000333
Validation Loss: 0.00060280
Epoch [65/300], Train Loss: 0.000342
Validation Loss: 0.00060419
Epoch [66/300], Train Loss: 0.000347
Validation Loss: 0.00057828
Epoch [67/300], Train Loss: 0.000333
Validation Loss: 0.00060130
Epoch [68/300], Train Loss: 0.000338
Validation Loss: 0.00057602
Epoch [69/300], Train Loss: 0.000354
Validation Loss: 0.00059464
Epoch [70/300], Train Loss: 0.000358
Validation Loss: 0.00057882
Epoch [71/300], Train Loss: 0.000336
Validation Loss: 0.00063652
Epoch [72/300], Train Loss: 0.000333
Validation Loss: 0.00057668
Epoch [73/300], Train Loss: 0.000329
Validation Loss: 0.00059342
Epoch [74/300], Train Loss: 0.000366
Validation Loss: 0.00057525
Epoch [75/300], Train Loss: 0.000332
Validation Loss: 0.00059457
Epoch [76/300], Train Loss: 0.000325
Validation Loss: 0.00058624
Epoch [77/300], Train Loss: 0.000320
Validation Loss: 0.00056808
Epoch [78/300], Train Loss: 0.000328
Validation Loss: 0.00058696
Epoch [79/300], Train Loss: 0.000321
Validation Loss: 0.00059754
Epoch [80/300], Train Loss: 0.000320
Validation Loss: 0.00057980
Epoch [81/300], Train Loss: 0.000320
Validation Loss: 0.00058010
Epoch [82/300], Train Loss: 0.000323
Validation Loss: 0.00055997
Epoch [83/300], Train Loss: 0.000324
Validation Loss: 0.00057638
Epoch [84/300], Train Loss: 0.000314
Validation Loss: 0.00056003
Epoch [85/300], Train Loss: 0.000323
Validation Loss: 0.00059577
Epoch [86/300], Train Loss: 0.000322
Validation Loss: 0.00057280
Epoch [87/300], Train Loss: 0.000317
Validation Loss: 0.00055619
Epoch [88/300], Train Loss: 0.000312
Validation Loss: 0.00056693
Epoch [89/300], Train Loss: 0.000316
Validation Loss: 0.00058892
Epoch [90/300], Train Loss: 0.000372
Validation Loss: 0.00055940
Epoch [91/300], Train Loss: 0.000338
Validation Loss: 0.00056437
Epoch [92/300], Train Loss: 0.000312
Validation Loss: 0.00055478
Epoch [93/300], Train Loss: 0.000313
Validation Loss: 0.00055004
Epoch [94/300], Train Loss: 0.000316
Validation Loss: 0.00055469
Epoch [95/300], Train Loss: 0.000309
Validation Loss: 0.00054813
Epoch [96/300], Train Loss: 0.000308
Validation Loss: 0.00056609
Epoch [97/300], Train Loss: 0.000309
Validation Loss: 0.00053875
Epoch [98/300], Train Loss: 0.000308
Validation Loss: 0.00056281
Epoch [99/300], Train Loss: 0.000320
Validation Loss: 0.00056625
Epoch [100/300], Train Loss: 0.000309
Validation Loss: 0.00056656
Epoch [101/300], Train Loss: 0.000305
Validation Loss: 0.00055856
Epoch [102/300], Train Loss: 0.000305
Validation Loss: 0.00054569
Epoch [103/300], Train Loss: 0.000307
Validation Loss: 0.00057786
Epoch [104/300], Train Loss: 0.000305
Validation Loss: 0.00056899
Epoch [105/300], Train Loss: 0.000300
Validation Loss: 0.00055548
Epoch [106/300], Train Loss: 0.000304
Validation Loss: 0.00054639
Epoch [107/300], Train Loss: 0.000310
Validation Loss: 0.00054968
Early stopping triggered

Evaluating model for: Microwave
Run 35/72 completed in 1648.68 seconds with: {'MAE': np.float32(6.9961953), 'MSE': np.float32(5469.42), 'RMSE': np.float32(73.95553), 'SAE': np.float32(0.12673303), 'NDE': np.float32(0.684418)}

Run 36/72: hidden=256, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Microwave
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.000761
Validation Loss: 0.00092053
Epoch [2/300], Train Loss: 0.000659
Validation Loss: 0.00091562
Epoch [3/300], Train Loss: 0.000638
Validation Loss: 0.00091532
Epoch [4/300], Train Loss: 0.000628
Validation Loss: 0.00091368
Epoch [5/300], Train Loss: 0.000617
Validation Loss: 0.00091496
Epoch [6/300], Train Loss: 0.000615
Validation Loss: 0.00091057
Epoch [7/300], Train Loss: 0.000611
Validation Loss: 0.00089704
Epoch [8/300], Train Loss: 0.000610
Validation Loss: 0.00088121
Epoch [9/300], Train Loss: 0.000591
Validation Loss: 0.00086253
Epoch [10/300], Train Loss: 0.000564
Validation Loss: 0.00089365
Epoch [11/300], Train Loss: 0.000596
Validation Loss: 0.00083675
Epoch [12/300], Train Loss: 0.000530
Validation Loss: 0.00078326
Epoch [13/300], Train Loss: 0.000506
Validation Loss: 0.00076740
Epoch [14/300], Train Loss: 0.000490
Validation Loss: 0.00074135
Epoch [15/300], Train Loss: 0.000559
Validation Loss: 0.00080982
Epoch [16/300], Train Loss: 0.000503
Validation Loss: 0.00076889
Epoch [17/300], Train Loss: 0.000495
Validation Loss: 0.00073955
Epoch [18/300], Train Loss: 0.000482
Validation Loss: 0.00076270
Epoch [19/300], Train Loss: 0.000486
Validation Loss: 0.00073511
Epoch [20/300], Train Loss: 0.000484
Validation Loss: 0.00072900
Epoch [21/300], Train Loss: 0.000469
Validation Loss: 0.00074318
Epoch [22/300], Train Loss: 0.000467
Validation Loss: 0.00075059
Epoch [23/300], Train Loss: 0.000470
Validation Loss: 0.00071950
Epoch [24/300], Train Loss: 0.000460
Validation Loss: 0.00078243
Epoch [25/300], Train Loss: 0.000463
Validation Loss: 0.00072173
Epoch [26/300], Train Loss: 0.000443
Validation Loss: 0.00072874
Epoch [27/300], Train Loss: 0.000443
Validation Loss: 0.00072262
Epoch [28/300], Train Loss: 0.000447
Validation Loss: 0.00074037
Epoch [29/300], Train Loss: 0.000563
Validation Loss: 0.00071178
Epoch [30/300], Train Loss: 0.000507
Validation Loss: 0.00071264
Epoch [31/300], Train Loss: 0.000435
Validation Loss: 0.00072084
Epoch [32/300], Train Loss: 0.000433
Validation Loss: 0.00072293
Epoch [33/300], Train Loss: 0.000437
Validation Loss: 0.00071187
Epoch [34/300], Train Loss: 0.000438
Validation Loss: 0.00074240
Epoch [35/300], Train Loss: 0.000443
Validation Loss: 0.00071304
Epoch [36/300], Train Loss: 0.000424
Validation Loss: 0.00070267
Epoch [37/300], Train Loss: 0.000423
Validation Loss: 0.00079290
Epoch [38/300], Train Loss: 0.000448
Validation Loss: 0.00069732
Epoch [39/300], Train Loss: 0.000451
Validation Loss: 0.00070006
Epoch [40/300], Train Loss: 0.000497
Validation Loss: 0.00068566
Epoch [41/300], Train Loss: 0.000514
Validation Loss: 0.00067483
Epoch [42/300], Train Loss: 0.000462
Validation Loss: 0.00068823
Epoch [43/300], Train Loss: 0.000416
Validation Loss: 0.00066049
Epoch [44/300], Train Loss: 0.000425
Validation Loss: 0.00064974
Epoch [45/300], Train Loss: 0.000452
Validation Loss: 0.00067334
Epoch [46/300], Train Loss: 0.000418
Validation Loss: 0.00065780
Epoch [47/300], Train Loss: 0.000394
Validation Loss: 0.00064332
Epoch [48/300], Train Loss: 0.000391
Validation Loss: 0.00066982
Epoch [49/300], Train Loss: 0.000382
Validation Loss: 0.00065900
Epoch [50/300], Train Loss: 0.000384
Validation Loss: 0.00064041
Epoch [51/300], Train Loss: 0.000394
Validation Loss: 0.00063602
Epoch [52/300], Train Loss: 0.000378
Validation Loss: 0.00064205
Epoch [53/300], Train Loss: 0.000375
Validation Loss: 0.00065299
Epoch [54/300], Train Loss: 0.000376
Validation Loss: 0.00065431
Epoch [55/300], Train Loss: 0.000377
Validation Loss: 0.00069154
Epoch [56/300], Train Loss: 0.000379
Validation Loss: 0.00065069
Epoch [57/300], Train Loss: 0.000387
Validation Loss: 0.00063707
Epoch [58/300], Train Loss: 0.000376
Validation Loss: 0.00062384
Epoch [59/300], Train Loss: 0.000370
Validation Loss: 0.00062156
Epoch [60/300], Train Loss: 0.000367
Validation Loss: 0.00061837
Epoch [61/300], Train Loss: 0.000360
Validation Loss: 0.00061132
Epoch [62/300], Train Loss: 0.000357
Validation Loss: 0.00061592
Epoch [63/300], Train Loss: 0.000363
Validation Loss: 0.00061519
Epoch [64/300], Train Loss: 0.000355
Validation Loss: 0.00065182
Epoch [65/300], Train Loss: 0.000359
Validation Loss: 0.00062723
Epoch [66/300], Train Loss: 0.000367
Validation Loss: 0.00060942
Epoch [67/300], Train Loss: 0.000350
Validation Loss: 0.00062280
Epoch [68/300], Train Loss: 0.000354
Validation Loss: 0.00061277
Epoch [69/300], Train Loss: 0.000381
Validation Loss: 0.00060265
Epoch [70/300], Train Loss: 0.000379
Validation Loss: 0.00057086
Epoch [71/300], Train Loss: 0.000346
Validation Loss: 0.00062288
Epoch [72/300], Train Loss: 0.000342
Validation Loss: 0.00058815
Epoch [73/300], Train Loss: 0.000344
Validation Loss: 0.00058526
Epoch [74/300], Train Loss: 0.000391
Validation Loss: 0.00058876
Epoch [75/300], Train Loss: 0.000350
Validation Loss: 0.00059914
Epoch [76/300], Train Loss: 0.000333
Validation Loss: 0.00058863
Epoch [77/300], Train Loss: 0.000333
Validation Loss: 0.00058422
Epoch [78/300], Train Loss: 0.000341
Validation Loss: 0.00059043
Epoch [79/300], Train Loss: 0.000329
Validation Loss: 0.00059340
Epoch [80/300], Train Loss: 0.000331
Validation Loss: 0.00059257
Early stopping triggered

Evaluating model for: Microwave
Run 36/72 completed in 1552.22 seconds with: {'MAE': np.float32(8.525785), 'MSE': np.float32(6044.766), 'RMSE': np.float32(77.74809), 'SAE': np.float32(0.022084551), 'NDE': np.float32(0.7195168)}

Run 37/72: hidden=256, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Microwave
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.000568
Validation Loss: 0.00078953
Epoch [2/300], Train Loss: 0.000542
Validation Loss: 0.00078217
Epoch [3/300], Train Loss: 0.000540
Validation Loss: 0.00077962
Epoch [4/300], Train Loss: 0.000538
Validation Loss: 0.00077723
Epoch [5/300], Train Loss: 0.000542
Validation Loss: 0.00077636
Epoch [6/300], Train Loss: 0.000542
Validation Loss: 0.00077193
Epoch [7/300], Train Loss: 0.000532
Validation Loss: 0.00076955
Epoch [8/300], Train Loss: 0.000530
Validation Loss: 0.00076587
Epoch [9/300], Train Loss: 0.000528
Validation Loss: 0.00076076
Epoch [10/300], Train Loss: 0.000524
Validation Loss: 0.00075621
Epoch [11/300], Train Loss: 0.000555
Validation Loss: 0.00074663
Epoch [12/300], Train Loss: 0.000517
Validation Loss: 0.00074425
Epoch [13/300], Train Loss: 0.000512
Validation Loss: 0.00072899
Epoch [14/300], Train Loss: 0.000508
Validation Loss: 0.00071733
Epoch [15/300], Train Loss: 0.000549
Validation Loss: 0.00069504
Epoch [16/300], Train Loss: 0.000588
Validation Loss: 0.00066989
Epoch [17/300], Train Loss: 0.000485
Validation Loss: 0.00061515
Epoch [18/300], Train Loss: 0.000467
Validation Loss: 0.00059271
Epoch [19/300], Train Loss: 0.000643
Validation Loss: 0.00066813
Epoch [20/300], Train Loss: 0.000461
Validation Loss: 0.00059658
Epoch [21/300], Train Loss: 0.000439
Validation Loss: 0.00057673
Epoch [22/300], Train Loss: 0.000456
Validation Loss: 0.00055779
Epoch [23/300], Train Loss: 0.000435
Validation Loss: 0.00057372
Epoch [24/300], Train Loss: 0.000446
Validation Loss: 0.00055273
Epoch [25/300], Train Loss: 0.000421
Validation Loss: 0.00066495
Epoch [26/300], Train Loss: 0.000509
Validation Loss: 0.00068345
Epoch [27/300], Train Loss: 0.000484
Validation Loss: 0.00055998
Epoch [28/300], Train Loss: 0.000429
Validation Loss: 0.00057007
Epoch [29/300], Train Loss: 0.000446
Validation Loss: 0.00054373
Epoch [30/300], Train Loss: 0.000432
Validation Loss: 0.00056592
Epoch [31/300], Train Loss: 0.000420
Validation Loss: 0.00056775
Epoch [32/300], Train Loss: 0.000418
Validation Loss: 0.00054510
Epoch [33/300], Train Loss: 0.000506
Validation Loss: 0.00054497
Epoch [34/300], Train Loss: 0.000511
Validation Loss: 0.00056991
Epoch [35/300], Train Loss: 0.000426
Validation Loss: 0.00057096
Epoch [36/300], Train Loss: 0.000419
Validation Loss: 0.00054341
Epoch [37/300], Train Loss: 0.000415
Validation Loss: 0.00054473
Epoch [38/300], Train Loss: 0.000411
Validation Loss: 0.00055092
Epoch [39/300], Train Loss: 0.000413
Validation Loss: 0.00055034
Epoch [40/300], Train Loss: 0.000425
Validation Loss: 0.00055713
Epoch [41/300], Train Loss: 0.000418
Validation Loss: 0.00054907
Epoch [42/300], Train Loss: 0.000490
Validation Loss: 0.00054505
Epoch [43/300], Train Loss: 0.000445
Validation Loss: 0.00055570
Epoch [44/300], Train Loss: 0.000421
Validation Loss: 0.00054017
Epoch [45/300], Train Loss: 0.000416
Validation Loss: 0.00054608
Epoch [46/300], Train Loss: 0.000405
Validation Loss: 0.00053845
Epoch [47/300], Train Loss: 0.000411
Validation Loss: 0.00053970
Epoch [48/300], Train Loss: 0.000411
Validation Loss: 0.00056352
Epoch [49/300], Train Loss: 0.000411
Validation Loss: 0.00054647
Epoch [50/300], Train Loss: 0.000437
Validation Loss: 0.00053784
Epoch [51/300], Train Loss: 0.000404
Validation Loss: 0.00054091
Epoch [52/300], Train Loss: 0.000410
Validation Loss: 0.00053692
Epoch [53/300], Train Loss: 0.000402
Validation Loss: 0.00053613
Epoch [54/300], Train Loss: 0.000404
Validation Loss: 0.00053185
Epoch [55/300], Train Loss: 0.000406
Validation Loss: 0.00054151
Epoch [56/300], Train Loss: 0.000426
Validation Loss: 0.00053309
Epoch [57/300], Train Loss: 0.000408
Validation Loss: 0.00052783
Epoch [58/300], Train Loss: 0.000407
Validation Loss: 0.00055183
Epoch [59/300], Train Loss: 0.000418
Validation Loss: 0.00054549
Epoch [60/300], Train Loss: 0.000557
Validation Loss: 0.00053727
Epoch [61/300], Train Loss: 0.000444
Validation Loss: 0.00053462
Epoch [62/300], Train Loss: 0.000404
Validation Loss: 0.00051871
Epoch [63/300], Train Loss: 0.000395
Validation Loss: 0.00052015
Epoch [64/300], Train Loss: 0.000416
Validation Loss: 0.00050135
Epoch [65/300], Train Loss: 0.000399
Validation Loss: 0.00049641
Epoch [66/300], Train Loss: 0.000401
Validation Loss: 0.00050229
Epoch [67/300], Train Loss: 0.000422
Validation Loss: 0.00048410
Epoch [68/300], Train Loss: 0.000409
Validation Loss: 0.00048842
Epoch [69/300], Train Loss: 0.000392
Validation Loss: 0.00050922
Epoch [70/300], Train Loss: 0.000408
Validation Loss: 0.00048060
Epoch [71/300], Train Loss: 0.000390
Validation Loss: 0.00048141
Epoch [72/300], Train Loss: 0.000393
Validation Loss: 0.00048515
Epoch [73/300], Train Loss: 0.000437
Validation Loss: 0.00048330
Epoch [74/300], Train Loss: 0.000398
Validation Loss: 0.00050667
Epoch [75/300], Train Loss: 0.000448
Validation Loss: 0.00047884
Epoch [76/300], Train Loss: 0.000395
Validation Loss: 0.00046932
Epoch [77/300], Train Loss: 0.000458
Validation Loss: 0.00046814
Epoch [78/300], Train Loss: 0.000409
Validation Loss: 0.00049824
Epoch [79/300], Train Loss: 0.000399
Validation Loss: 0.00046770
Epoch [80/300], Train Loss: 0.000386
Validation Loss: 0.00045986
Epoch [81/300], Train Loss: 0.000435
Validation Loss: 0.00047178
Epoch [82/300], Train Loss: 0.000393
Validation Loss: 0.00045957
Epoch [83/300], Train Loss: 0.000378
Validation Loss: 0.00046039
Epoch [84/300], Train Loss: 0.000404
Validation Loss: 0.00046761
Epoch [85/300], Train Loss: 0.000375
Validation Loss: 0.00045760
Epoch [86/300], Train Loss: 0.000381
Validation Loss: 0.00046767
Epoch [87/300], Train Loss: 0.000378
Validation Loss: 0.00045793
Epoch [88/300], Train Loss: 0.000515
Validation Loss: 0.00046188
Epoch [89/300], Train Loss: 0.000377
Validation Loss: 0.00045662
Epoch [90/300], Train Loss: 0.000431
Validation Loss: 0.00046189
Epoch [91/300], Train Loss: 0.000372
Validation Loss: 0.00045902
Epoch [92/300], Train Loss: 0.000389
Validation Loss: 0.00045625
Epoch [93/300], Train Loss: 0.000387
Validation Loss: 0.00046219
Epoch [94/300], Train Loss: 0.000416
Validation Loss: 0.00045913
Epoch [95/300], Train Loss: 0.000384
Validation Loss: 0.00045043
Epoch [96/300], Train Loss: 0.000364
Validation Loss: 0.00045637
Epoch [97/300], Train Loss: 0.000363
Validation Loss: 0.00045391
Epoch [98/300], Train Loss: 0.000370
Validation Loss: 0.00043672
Epoch [99/300], Train Loss: 0.000368
Validation Loss: 0.00044612
Epoch [100/300], Train Loss: 0.000367
Validation Loss: 0.00044203
Epoch [101/300], Train Loss: 0.000363
Validation Loss: 0.00042603
Epoch [102/300], Train Loss: 0.000356
Validation Loss: 0.00043472
Epoch [103/300], Train Loss: 0.000368
Validation Loss: 0.00042395
Epoch [104/300], Train Loss: 0.000491
Validation Loss: 0.00042355
Epoch [105/300], Train Loss: 0.000451
Validation Loss: 0.00044551
Epoch [106/300], Train Loss: 0.000372
Validation Loss: 0.00042601
Epoch [107/300], Train Loss: 0.000356
Validation Loss: 0.00043256
Epoch [108/300], Train Loss: 0.000368
Validation Loss: 0.00042184
Epoch [109/300], Train Loss: 0.000349
Validation Loss: 0.00042707
Epoch [110/300], Train Loss: 0.000352
Validation Loss: 0.00041129
Epoch [111/300], Train Loss: 0.000352
Validation Loss: 0.00043681
Epoch [112/300], Train Loss: 0.000356
Validation Loss: 0.00042555
Epoch [113/300], Train Loss: 0.000344
Validation Loss: 0.00040748
Epoch [114/300], Train Loss: 0.000393
Validation Loss: 0.00045314
Epoch [115/300], Train Loss: 0.000364
Validation Loss: 0.00040069
Epoch [116/300], Train Loss: 0.000343
Validation Loss: 0.00040736
Epoch [117/300], Train Loss: 0.000340
Validation Loss: 0.00039921
Epoch [118/300], Train Loss: 0.000341
Validation Loss: 0.00040610
Epoch [119/300], Train Loss: 0.000358
Validation Loss: 0.00039856
Epoch [120/300], Train Loss: 0.000339
Validation Loss: 0.00041050
Epoch [121/300], Train Loss: 0.000375
Validation Loss: 0.00041972
Epoch [122/300], Train Loss: 0.000336
Validation Loss: 0.00039806
Epoch [123/300], Train Loss: 0.000331
Validation Loss: 0.00041667
Epoch [124/300], Train Loss: 0.000338
Validation Loss: 0.00040551
Epoch [125/300], Train Loss: 0.000342
Validation Loss: 0.00039562
Epoch [126/300], Train Loss: 0.000329
Validation Loss: 0.00039772
Epoch [127/300], Train Loss: 0.000350
Validation Loss: 0.00040265
Epoch [128/300], Train Loss: 0.000337
Validation Loss: 0.00039535
Epoch [129/300], Train Loss: 0.000337
Validation Loss: 0.00038491
Epoch [130/300], Train Loss: 0.000325
Validation Loss: 0.00040771
Epoch [131/300], Train Loss: 0.000336
Validation Loss: 0.00038856
Epoch [132/300], Train Loss: 0.000337
Validation Loss: 0.00037931
Epoch [133/300], Train Loss: 0.000332
Validation Loss: 0.00038457
Epoch [134/300], Train Loss: 0.000325
Validation Loss: 0.00038633
Epoch [135/300], Train Loss: 0.000324
Validation Loss: 0.00040488
Epoch [136/300], Train Loss: 0.000323
Validation Loss: 0.00038798
Epoch [137/300], Train Loss: 0.000322
Validation Loss: 0.00038544
Epoch [138/300], Train Loss: 0.000324
Validation Loss: 0.00038506
Epoch [139/300], Train Loss: 0.000343
Validation Loss: 0.00037855
Epoch [140/300], Train Loss: 0.000343
Validation Loss: 0.00039223
Epoch [141/300], Train Loss: 0.000321
Validation Loss: 0.00037375
Epoch [142/300], Train Loss: 0.000322
Validation Loss: 0.00037157
Epoch [143/300], Train Loss: 0.000372
Validation Loss: 0.00037968
Epoch [144/300], Train Loss: 0.000319
Validation Loss: 0.00037375
Epoch [145/300], Train Loss: 0.000328
Validation Loss: 0.00038861
Epoch [146/300], Train Loss: 0.000325
Validation Loss: 0.00038157
Epoch [147/300], Train Loss: 0.000318
Validation Loss: 0.00038979
Epoch [148/300], Train Loss: 0.000322
Validation Loss: 0.00037226
Epoch [149/300], Train Loss: 0.000318
Validation Loss: 0.00037090
Epoch [150/300], Train Loss: 0.000322
Validation Loss: 0.00038652
Epoch [151/300], Train Loss: 0.000318
Validation Loss: 0.00038216
Epoch [152/300], Train Loss: 0.000320
Validation Loss: 0.00037538
Epoch [153/300], Train Loss: 0.000419
Validation Loss: 0.00037303
Epoch [154/300], Train Loss: 0.000319
Validation Loss: 0.00037491
Epoch [155/300], Train Loss: 0.000323
Validation Loss: 0.00037218
Epoch [156/300], Train Loss: 0.000321
Validation Loss: 0.00037410
Epoch [157/300], Train Loss: 0.000326
Validation Loss: 0.00038341
Epoch [158/300], Train Loss: 0.000328
Validation Loss: 0.00036641
Epoch [159/300], Train Loss: 0.000311
Validation Loss: 0.00038670
Epoch [160/300], Train Loss: 0.000310
Validation Loss: 0.00036320
Epoch [161/300], Train Loss: 0.000356
Validation Loss: 0.00038773
Epoch [162/300], Train Loss: 0.000321
Validation Loss: 0.00037588
Epoch [163/300], Train Loss: 0.000314
Validation Loss: 0.00036591
Epoch [164/300], Train Loss: 0.000311
Validation Loss: 0.00036125
Epoch [165/300], Train Loss: 0.000310
Validation Loss: 0.00037441
Epoch [166/300], Train Loss: 0.000314
Validation Loss: 0.00036360
Epoch [167/300], Train Loss: 0.000311
Validation Loss: 0.00037888
Epoch [168/300], Train Loss: 0.000319
Validation Loss: 0.00037999
Epoch [169/300], Train Loss: 0.000334
Validation Loss: 0.00037015
Epoch [170/300], Train Loss: 0.000322
Validation Loss: 0.00037256
Epoch [171/300], Train Loss: 0.000324
Validation Loss: 0.00040867
Epoch [172/300], Train Loss: 0.000341
Validation Loss: 0.00053142
Epoch [173/300], Train Loss: 0.000424
Validation Loss: 0.00037423
Epoch [174/300], Train Loss: 0.000367
Validation Loss: 0.00038259
Early stopping triggered

Evaluating model for: Microwave
Run 37/72 completed in 1028.16 seconds with: {'MAE': np.float32(10.785088), 'MSE': np.float32(9250.678), 'RMSE': np.float32(96.18044), 'SAE': np.float32(0.21582605), 'NDE': np.float32(0.7358018)}

Run 38/72: hidden=256, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Microwave
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.000794
Validation Loss: 0.00078929
Epoch [2/300], Train Loss: 0.000554
Validation Loss: 0.00078885
Epoch [3/300], Train Loss: 0.000548
Validation Loss: 0.00078747
Epoch [4/300], Train Loss: 0.000546
Validation Loss: 0.00078634
Epoch [5/300], Train Loss: 0.000550
Validation Loss: 0.00078489
Epoch [6/300], Train Loss: 0.000551
Validation Loss: 0.00078308
Epoch [7/300], Train Loss: 0.000542
Validation Loss: 0.00078099
Epoch [8/300], Train Loss: 0.000539
Validation Loss: 0.00077772
Epoch [9/300], Train Loss: 0.000537
Validation Loss: 0.00077179
Epoch [10/300], Train Loss: 0.000534
Validation Loss: 0.00076548
Epoch [11/300], Train Loss: 0.000565
Validation Loss: 0.00075914
Epoch [12/300], Train Loss: 0.000529
Validation Loss: 0.00075396
Epoch [13/300], Train Loss: 0.000525
Validation Loss: 0.00075084
Epoch [14/300], Train Loss: 0.000525
Validation Loss: 0.00074151
Epoch [15/300], Train Loss: 0.000571
Validation Loss: 0.00073372
Epoch [16/300], Train Loss: 0.000621
Validation Loss: 0.00070104
Epoch [17/300], Train Loss: 0.000511
Validation Loss: 0.00074574
Epoch [18/300], Train Loss: 0.000518
Validation Loss: 0.00069708
Epoch [19/300], Train Loss: 0.000489
Validation Loss: 0.00066448
Epoch [20/300], Train Loss: 0.000479
Validation Loss: 0.00062687
Epoch [21/300], Train Loss: 0.000458
Validation Loss: 0.00060600
Epoch [22/300], Train Loss: 0.000480
Validation Loss: 0.00059288
Epoch [23/300], Train Loss: 0.000459
Validation Loss: 0.00062062
Epoch [24/300], Train Loss: 0.000474
Validation Loss: 0.00059094
Epoch [25/300], Train Loss: 0.000438
Validation Loss: 0.00067406
Epoch [26/300], Train Loss: 0.000526
Validation Loss: 0.00073106
Epoch [27/300], Train Loss: 0.000515
Validation Loss: 0.00063678
Epoch [28/300], Train Loss: 0.000460
Validation Loss: 0.00058484
Epoch [29/300], Train Loss: 0.000462
Validation Loss: 0.00057116
Epoch [30/300], Train Loss: 0.000446
Validation Loss: 0.00058556
Epoch [31/300], Train Loss: 0.000433
Validation Loss: 0.00058504
Epoch [32/300], Train Loss: 0.000430
Validation Loss: 0.00057501
Epoch [33/300], Train Loss: 0.000528
Validation Loss: 0.00057560
Epoch [34/300], Train Loss: 0.000522
Validation Loss: 0.00058586
Epoch [35/300], Train Loss: 0.000437
Validation Loss: 0.00059182
Epoch [36/300], Train Loss: 0.000430
Validation Loss: 0.00057094
Epoch [37/300], Train Loss: 0.000428
Validation Loss: 0.00057603
Epoch [38/300], Train Loss: 0.000423
Validation Loss: 0.00058176
Epoch [39/300], Train Loss: 0.000426
Validation Loss: 0.00057673
Epoch [40/300], Train Loss: 0.000435
Validation Loss: 0.00059432
Epoch [41/300], Train Loss: 0.000426
Validation Loss: 0.00057592
Epoch [42/300], Train Loss: 0.000502
Validation Loss: 0.00057561
Epoch [43/300], Train Loss: 0.000456
Validation Loss: 0.00059265
Epoch [44/300], Train Loss: 0.000433
Validation Loss: 0.00056958
Epoch [45/300], Train Loss: 0.000426
Validation Loss: 0.00057453
Epoch [46/300], Train Loss: 0.000419
Validation Loss: 0.00056963
Epoch [47/300], Train Loss: 0.000423
Validation Loss: 0.00057477
Epoch [48/300], Train Loss: 0.000424
Validation Loss: 0.00059451
Epoch [49/300], Train Loss: 0.000424
Validation Loss: 0.00057488
Epoch [50/300], Train Loss: 0.000449
Validation Loss: 0.00056360
Epoch [51/300], Train Loss: 0.000417
Validation Loss: 0.00057125
Epoch [52/300], Train Loss: 0.000423
Validation Loss: 0.00057121
Epoch [53/300], Train Loss: 0.000414
Validation Loss: 0.00057036
Epoch [54/300], Train Loss: 0.000416
Validation Loss: 0.00056922
Epoch [55/300], Train Loss: 0.000417
Validation Loss: 0.00056854
Epoch [56/300], Train Loss: 0.000443
Validation Loss: 0.00055484
Epoch [57/300], Train Loss: 0.000420
Validation Loss: 0.00055603
Epoch [58/300], Train Loss: 0.000419
Validation Loss: 0.00058305
Epoch [59/300], Train Loss: 0.000432
Validation Loss: 0.00057530
Epoch [60/300], Train Loss: 0.000591
Validation Loss: 0.00056584
Epoch [61/300], Train Loss: 0.000438
Validation Loss: 0.00055801
Epoch [62/300], Train Loss: 0.000416
Validation Loss: 0.00055556
Epoch [63/300], Train Loss: 0.000407
Validation Loss: 0.00056639
Epoch [64/300], Train Loss: 0.000432
Validation Loss: 0.00055116
Epoch [65/300], Train Loss: 0.000414
Validation Loss: 0.00055722
Epoch [66/300], Train Loss: 0.000416
Validation Loss: 0.00055606
Epoch [67/300], Train Loss: 0.000437
Validation Loss: 0.00055415
Epoch [68/300], Train Loss: 0.000423
Validation Loss: 0.00055866
Epoch [69/300], Train Loss: 0.000405
Validation Loss: 0.00056966
Epoch [70/300], Train Loss: 0.000421
Validation Loss: 0.00055316
Epoch [71/300], Train Loss: 0.000409
Validation Loss: 0.00055479
Epoch [72/300], Train Loss: 0.000415
Validation Loss: 0.00055796
Epoch [73/300], Train Loss: 0.000454
Validation Loss: 0.00055072
Epoch [74/300], Train Loss: 0.000414
Validation Loss: 0.00057611
Epoch [75/300], Train Loss: 0.000477
Validation Loss: 0.00053895
Epoch [76/300], Train Loss: 0.000408
Validation Loss: 0.00053739
Epoch [77/300], Train Loss: 0.000483
Validation Loss: 0.00053584
Epoch [78/300], Train Loss: 0.000417
Validation Loss: 0.00054115
Epoch [79/300], Train Loss: 0.000405
Validation Loss: 0.00052085
Epoch [80/300], Train Loss: 0.000395
Validation Loss: 0.00052834
Epoch [81/300], Train Loss: 0.000459
Validation Loss: 0.00053831
Epoch [82/300], Train Loss: 0.000401
Validation Loss: 0.00051518
Epoch [83/300], Train Loss: 0.000382
Validation Loss: 0.00050562
Epoch [84/300], Train Loss: 0.000409
Validation Loss: 0.00050415
Epoch [85/300], Train Loss: 0.000382
Validation Loss: 0.00048904
Epoch [86/300], Train Loss: 0.000390
Validation Loss: 0.00050640
Epoch [87/300], Train Loss: 0.000389
Validation Loss: 0.00048974
Epoch [88/300], Train Loss: 0.000532
Validation Loss: 0.00050587
Epoch [89/300], Train Loss: 0.000378
Validation Loss: 0.00048054
Epoch [90/300], Train Loss: 0.000428
Validation Loss: 0.00048772
Epoch [91/300], Train Loss: 0.000376
Validation Loss: 0.00049374
Epoch [92/300], Train Loss: 0.000392
Validation Loss: 0.00048706
Epoch [93/300], Train Loss: 0.000397
Validation Loss: 0.00053639
Epoch [94/300], Train Loss: 0.000421
Validation Loss: 0.00048178
Epoch [95/300], Train Loss: 0.000398
Validation Loss: 0.00048612
Epoch [96/300], Train Loss: 0.000370
Validation Loss: 0.00048338
Epoch [97/300], Train Loss: 0.000370
Validation Loss: 0.00048004
Epoch [98/300], Train Loss: 0.000385
Validation Loss: 0.00047984
Epoch [99/300], Train Loss: 0.000373
Validation Loss: 0.00047395
Epoch [100/300], Train Loss: 0.000377
Validation Loss: 0.00048245
Epoch [101/300], Train Loss: 0.000375
Validation Loss: 0.00045875
Epoch [102/300], Train Loss: 0.000367
Validation Loss: 0.00047155
Epoch [103/300], Train Loss: 0.000381
Validation Loss: 0.00045779
Epoch [104/300], Train Loss: 0.000510
Validation Loss: 0.00046049
Epoch [105/300], Train Loss: 0.000467
Validation Loss: 0.00048764
Epoch [106/300], Train Loss: 0.000380
Validation Loss: 0.00046624
Epoch [107/300], Train Loss: 0.000366
Validation Loss: 0.00046961
Epoch [108/300], Train Loss: 0.000377
Validation Loss: 0.00045934
Epoch [109/300], Train Loss: 0.000363
Validation Loss: 0.00046512
Epoch [110/300], Train Loss: 0.000367
Validation Loss: 0.00045826
Epoch [111/300], Train Loss: 0.000368
Validation Loss: 0.00047858
Epoch [112/300], Train Loss: 0.000366
Validation Loss: 0.00046612
Epoch [113/300], Train Loss: 0.000358
Validation Loss: 0.00045598
Epoch [114/300], Train Loss: 0.000422
Validation Loss: 0.00047284
Epoch [115/300], Train Loss: 0.000372
Validation Loss: 0.00045854
Epoch [116/300], Train Loss: 0.000354
Validation Loss: 0.00044922
Epoch [117/300], Train Loss: 0.000364
Validation Loss: 0.00044204
Epoch [118/300], Train Loss: 0.000356
Validation Loss: 0.00045759
Epoch [119/300], Train Loss: 0.000376
Validation Loss: 0.00044307
Epoch [120/300], Train Loss: 0.000360
Validation Loss: 0.00044959
Epoch [121/300], Train Loss: 0.000401
Validation Loss: 0.00046462
Epoch [122/300], Train Loss: 0.000356
Validation Loss: 0.00044427
Epoch [123/300], Train Loss: 0.000351
Validation Loss: 0.00045837
Epoch [124/300], Train Loss: 0.000354
Validation Loss: 0.00045789
Epoch [125/300], Train Loss: 0.000356
Validation Loss: 0.00044669
Epoch [126/300], Train Loss: 0.000350
Validation Loss: 0.00044491
Epoch [127/300], Train Loss: 0.000368
Validation Loss: 0.00045105
Early stopping triggered

Evaluating model for: Microwave
Run 38/72 completed in 859.90 seconds with: {'MAE': np.float32(10.422764), 'MSE': np.float32(10575.284), 'RMSE': np.float32(102.836205), 'SAE': np.float32(0.2517356), 'NDE': np.float32(0.7867199)}

Run 39/72: hidden=256, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Microwave
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.000739
Validation Loss: 0.00078857
Epoch [2/300], Train Loss: 0.000551
Validation Loss: 0.00078996
Epoch [3/300], Train Loss: 0.000548
Validation Loss: 0.00078878
Epoch [4/300], Train Loss: 0.000547
Validation Loss: 0.00078790
Epoch [5/300], Train Loss: 0.000551
Validation Loss: 0.00078771
Epoch [6/300], Train Loss: 0.000554
Validation Loss: 0.00078761
Epoch [7/300], Train Loss: 0.000545
Validation Loss: 0.00078797
Epoch [8/300], Train Loss: 0.000544
Validation Loss: 0.00078735
Epoch [9/300], Train Loss: 0.000543
Validation Loss: 0.00078635
Epoch [10/300], Train Loss: 0.000542
Validation Loss: 0.00078579
Epoch [11/300], Train Loss: 0.000576
Validation Loss: 0.00078538
Epoch [12/300], Train Loss: 0.000541
Validation Loss: 0.00078332
Epoch [13/300], Train Loss: 0.000538
Validation Loss: 0.00078172
Epoch [14/300], Train Loss: 0.000538
Validation Loss: 0.00077587
Epoch [15/300], Train Loss: 0.000590
Validation Loss: 0.00077526
Epoch [16/300], Train Loss: 0.000660
Validation Loss: 0.00076589
Epoch [17/300], Train Loss: 0.000542
Validation Loss: 0.00075051
Epoch [18/300], Train Loss: 0.000528
Validation Loss: 0.00074872
Epoch [19/300], Train Loss: 0.000518
Validation Loss: 0.00072530
Epoch [20/300], Train Loss: 0.000508
Validation Loss: 0.00068858
Epoch [21/300], Train Loss: 0.000494
Validation Loss: 0.00066995
Epoch [22/300], Train Loss: 0.000514
Validation Loss: 0.00066518
Epoch [23/300], Train Loss: 0.000485
Validation Loss: 0.00064955
Epoch [24/300], Train Loss: 0.000488
Validation Loss: 0.00060386
Epoch [25/300], Train Loss: 0.000447
Validation Loss: 0.00066832
Epoch [26/300], Train Loss: 0.000548
Validation Loss: 0.00060278
Epoch [27/300], Train Loss: 0.000510
Validation Loss: 0.00058608
Epoch [28/300], Train Loss: 0.000458
Validation Loss: 0.00062923
Epoch [29/300], Train Loss: 0.000480
Validation Loss: 0.00056560
Epoch [30/300], Train Loss: 0.000459
Validation Loss: 0.00059996
Epoch [31/300], Train Loss: 0.000449
Validation Loss: 0.00059014
Epoch [32/300], Train Loss: 0.000444
Validation Loss: 0.00055665
Epoch [33/300], Train Loss: 0.000549
Validation Loss: 0.00057168
Epoch [34/300], Train Loss: 0.000542
Validation Loss: 0.00058596
Epoch [35/300], Train Loss: 0.000449
Validation Loss: 0.00060501
Epoch [36/300], Train Loss: 0.000447
Validation Loss: 0.00055683
Epoch [37/300], Train Loss: 0.000440
Validation Loss: 0.00056522
Epoch [38/300], Train Loss: 0.000436
Validation Loss: 0.00058466
Epoch [39/300], Train Loss: 0.000441
Validation Loss: 0.00056752
Epoch [40/300], Train Loss: 0.000449
Validation Loss: 0.00057102
Epoch [41/300], Train Loss: 0.000439
Validation Loss: 0.00056997
Epoch [42/300], Train Loss: 0.000508
Validation Loss: 0.00056656
Early stopping triggered

Evaluating model for: Microwave
Run 39/72 completed in 327.09 seconds with: {'MAE': np.float32(14.750625), 'MSE': np.float32(12328.501), 'RMSE': np.float32(111.03378), 'SAE': np.float32(0.5432892), 'NDE': np.float32(0.8494343)}

Run 40/72: hidden=256, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Microwave
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.000576
Validation Loss: 0.00079669
Epoch [2/300], Train Loss: 0.000542
Validation Loss: 0.00078757
Epoch [3/300], Train Loss: 0.000540
Validation Loss: 0.00078645
Epoch [4/300], Train Loss: 0.000540
Validation Loss: 0.00078508
Epoch [5/300], Train Loss: 0.000544
Validation Loss: 0.00078673
Epoch [6/300], Train Loss: 0.000547
Validation Loss: 0.00078502
Epoch [7/300], Train Loss: 0.000538
Validation Loss: 0.00078512
Epoch [8/300], Train Loss: 0.000538
Validation Loss: 0.00078462
Epoch [9/300], Train Loss: 0.000537
Validation Loss: 0.00078349
Epoch [10/300], Train Loss: 0.000536
Validation Loss: 0.00078190
Epoch [11/300], Train Loss: 0.000570
Validation Loss: 0.00077764
Epoch [12/300], Train Loss: 0.000533
Validation Loss: 0.00077140
Epoch [13/300], Train Loss: 0.000530
Validation Loss: 0.00077141
Epoch [14/300], Train Loss: 0.000531
Validation Loss: 0.00076458
Epoch [15/300], Train Loss: 0.000583
Validation Loss: 0.00076635
Epoch [16/300], Train Loss: 0.000655
Validation Loss: 0.00076099
Epoch [17/300], Train Loss: 0.000538
Validation Loss: 0.00075400
Epoch [18/300], Train Loss: 0.000527
Validation Loss: 0.00075481
Epoch [19/300], Train Loss: 0.000521
Validation Loss: 0.00074475
Epoch [20/300], Train Loss: 0.000517
Validation Loss: 0.00072915
Epoch [21/300], Train Loss: 0.000502
Validation Loss: 0.00066268
Epoch [22/300], Train Loss: 0.000515
Validation Loss: 0.00070488
Epoch [23/300], Train Loss: 0.000484
Validation Loss: 0.00062341
Epoch [24/300], Train Loss: 0.000474
Validation Loss: 0.00056649
Epoch [25/300], Train Loss: 0.000438
Validation Loss: 0.00071145
Epoch [26/300], Train Loss: 0.000557
Validation Loss: 0.00062187
Epoch [27/300], Train Loss: 0.000512
Validation Loss: 0.00059603
Epoch [28/300], Train Loss: 0.000452
Validation Loss: 0.00060595
Epoch [29/300], Train Loss: 0.000469
Validation Loss: 0.00055196
Epoch [30/300], Train Loss: 0.000448
Validation Loss: 0.00059253
Epoch [31/300], Train Loss: 0.000439
Validation Loss: 0.00058588
Epoch [32/300], Train Loss: 0.000434
Validation Loss: 0.00056004
Epoch [33/300], Train Loss: 0.000538
Validation Loss: 0.00056802
Epoch [34/300], Train Loss: 0.000536
Validation Loss: 0.00056826
Epoch [35/300], Train Loss: 0.000440
Validation Loss: 0.00058847
Epoch [36/300], Train Loss: 0.000438
Validation Loss: 0.00054608
Epoch [37/300], Train Loss: 0.000431
Validation Loss: 0.00055487
Epoch [38/300], Train Loss: 0.000426
Validation Loss: 0.00057753
Epoch [39/300], Train Loss: 0.000430
Validation Loss: 0.00054985
Epoch [40/300], Train Loss: 0.000443
Validation Loss: 0.00056760
Epoch [41/300], Train Loss: 0.000426
Validation Loss: 0.00056275
Epoch [42/300], Train Loss: 0.000498
Validation Loss: 0.00056291
Epoch [43/300], Train Loss: 0.000454
Validation Loss: 0.00057847
Epoch [44/300], Train Loss: 0.000430
Validation Loss: 0.00054584
Epoch [45/300], Train Loss: 0.000424
Validation Loss: 0.00055942
Epoch [46/300], Train Loss: 0.000416
Validation Loss: 0.00055427
Epoch [47/300], Train Loss: 0.000420
Validation Loss: 0.00056265
Epoch [48/300], Train Loss: 0.000421
Validation Loss: 0.00057818
Epoch [49/300], Train Loss: 0.000425
Validation Loss: 0.00056752
Epoch [50/300], Train Loss: 0.000456
Validation Loss: 0.00055755
Epoch [51/300], Train Loss: 0.000408
Validation Loss: 0.00054923
Epoch [52/300], Train Loss: 0.000417
Validation Loss: 0.00054751
Epoch [53/300], Train Loss: 0.000406
Validation Loss: 0.00054101
Epoch [54/300], Train Loss: 0.000407
Validation Loss: 0.00052356
Epoch [55/300], Train Loss: 0.000410
Validation Loss: 0.00055163
Epoch [56/300], Train Loss: 0.000425
Validation Loss: 0.00051583
Epoch [57/300], Train Loss: 0.000411
Validation Loss: 0.00050785
Epoch [58/300], Train Loss: 0.000407
Validation Loss: 0.00056196
Epoch [59/300], Train Loss: 0.000420
Validation Loss: 0.00055446
Epoch [60/300], Train Loss: 0.000554
Validation Loss: 0.00049608
Epoch [61/300], Train Loss: 0.000486
Validation Loss: 0.00060225
Epoch [62/300], Train Loss: 0.000430
Validation Loss: 0.00056732
Epoch [63/300], Train Loss: 0.000412
Validation Loss: 0.00053569
Epoch [64/300], Train Loss: 0.000426
Validation Loss: 0.00051391
Epoch [65/300], Train Loss: 0.000411
Validation Loss: 0.00049174
Epoch [66/300], Train Loss: 0.000406
Validation Loss: 0.00047917
Epoch [67/300], Train Loss: 0.000418
Validation Loss: 0.00048149
Epoch [68/300], Train Loss: 0.000408
Validation Loss: 0.00049124
Epoch [69/300], Train Loss: 0.000391
Validation Loss: 0.00050502
Epoch [70/300], Train Loss: 0.000411
Validation Loss: 0.00048432
Epoch [71/300], Train Loss: 0.000391
Validation Loss: 0.00047812
Epoch [72/300], Train Loss: 0.000391
Validation Loss: 0.00048541
Epoch [73/300], Train Loss: 0.000444
Validation Loss: 0.00048761
Epoch [74/300], Train Loss: 0.000398
Validation Loss: 0.00050465
Epoch [75/300], Train Loss: 0.000447
Validation Loss: 0.00046420
Epoch [76/300], Train Loss: 0.000393
Validation Loss: 0.00046309
Epoch [77/300], Train Loss: 0.000450
Validation Loss: 0.00045872
Epoch [78/300], Train Loss: 0.000407
Validation Loss: 0.00051052
Epoch [79/300], Train Loss: 0.000401
Validation Loss: 0.00047171
Epoch [80/300], Train Loss: 0.000392
Validation Loss: 0.00045783
Epoch [81/300], Train Loss: 0.000438
Validation Loss: 0.00048996
Epoch [82/300], Train Loss: 0.000393
Validation Loss: 0.00045462
Epoch [83/300], Train Loss: 0.000377
Validation Loss: 0.00046681
Epoch [84/300], Train Loss: 0.000420
Validation Loss: 0.00052025
Epoch [85/300], Train Loss: 0.000383
Validation Loss: 0.00050083
Epoch [86/300], Train Loss: 0.000387
Validation Loss: 0.00050681
Epoch [87/300], Train Loss: 0.000381
Validation Loss: 0.00048194
Epoch [88/300], Train Loss: 0.000520
Validation Loss: 0.00047940
Epoch [89/300], Train Loss: 0.000378
Validation Loss: 0.00045344
Epoch [90/300], Train Loss: 0.000435
Validation Loss: 0.00045886
Epoch [91/300], Train Loss: 0.000372
Validation Loss: 0.00046859
Epoch [92/300], Train Loss: 0.000408
Validation Loss: 0.00045533
Epoch [93/300], Train Loss: 0.000421
Validation Loss: 0.00057216
Epoch [94/300], Train Loss: 0.000446
Validation Loss: 0.00048858
Epoch [95/300], Train Loss: 0.000400
Validation Loss: 0.00047486
Epoch [96/300], Train Loss: 0.000375
Validation Loss: 0.00046786
Epoch [97/300], Train Loss: 0.000368
Validation Loss: 0.00046327
Epoch [98/300], Train Loss: 0.000373
Validation Loss: 0.00044765
Epoch [99/300], Train Loss: 0.000373
Validation Loss: 0.00046455
Epoch [100/300], Train Loss: 0.000373
Validation Loss: 0.00045073
Epoch [101/300], Train Loss: 0.000374
Validation Loss: 0.00043956
Epoch [102/300], Train Loss: 0.000366
Validation Loss: 0.00044122
Epoch [103/300], Train Loss: 0.000372
Validation Loss: 0.00043447
Epoch [104/300], Train Loss: 0.000486
Validation Loss: 0.00041965
Epoch [105/300], Train Loss: 0.000466
Validation Loss: 0.00044652
Epoch [106/300], Train Loss: 0.000386
Validation Loss: 0.00043621
Epoch [107/300], Train Loss: 0.000368
Validation Loss: 0.00044316
Epoch [108/300], Train Loss: 0.000377
Validation Loss: 0.00042959
Epoch [109/300], Train Loss: 0.000363
Validation Loss: 0.00044442
Epoch [110/300], Train Loss: 0.000372
Validation Loss: 0.00041672
Epoch [111/300], Train Loss: 0.000363
Validation Loss: 0.00044552
Epoch [112/300], Train Loss: 0.000360
Validation Loss: 0.00043861
Epoch [113/300], Train Loss: 0.000354
Validation Loss: 0.00041105
Epoch [114/300], Train Loss: 0.000414
Validation Loss: 0.00043864
Epoch [115/300], Train Loss: 0.000367
Validation Loss: 0.00040940
Epoch [116/300], Train Loss: 0.000351
Validation Loss: 0.00041602
Epoch [117/300], Train Loss: 0.000354
Validation Loss: 0.00040077
Epoch [118/300], Train Loss: 0.000352
Validation Loss: 0.00041688
Epoch [119/300], Train Loss: 0.000377
Validation Loss: 0.00039789
Epoch [120/300], Train Loss: 0.000352
Validation Loss: 0.00040709
Epoch [121/300], Train Loss: 0.000404
Validation Loss: 0.00045912
Epoch [122/300], Train Loss: 0.000351
Validation Loss: 0.00040572
Epoch [123/300], Train Loss: 0.000342
Validation Loss: 0.00041696
Epoch [124/300], Train Loss: 0.000345
Validation Loss: 0.00041566
Epoch [125/300], Train Loss: 0.000347
Validation Loss: 0.00040211
Epoch [126/300], Train Loss: 0.000336
Validation Loss: 0.00040126
Epoch [127/300], Train Loss: 0.000356
Validation Loss: 0.00045065
Epoch [128/300], Train Loss: 0.000348
Validation Loss: 0.00041315
Epoch [129/300], Train Loss: 0.000349
Validation Loss: 0.00039158
Epoch [130/300], Train Loss: 0.000332
Validation Loss: 0.00041525
Epoch [131/300], Train Loss: 0.000340
Validation Loss: 0.00040799
Epoch [132/300], Train Loss: 0.000349
Validation Loss: 0.00038256
Epoch [133/300], Train Loss: 0.000338
Validation Loss: 0.00039656
Epoch [134/300], Train Loss: 0.000331
Validation Loss: 0.00039874
Epoch [135/300], Train Loss: 0.000340
Validation Loss: 0.00045809
Epoch [136/300], Train Loss: 0.000353
Validation Loss: 0.00040091
Epoch [137/300], Train Loss: 0.000338
Validation Loss: 0.00041198
Epoch [138/300], Train Loss: 0.000334
Validation Loss: 0.00038523
Epoch [139/300], Train Loss: 0.000348
Validation Loss: 0.00037758
Epoch [140/300], Train Loss: 0.000344
Validation Loss: 0.00040052
Epoch [141/300], Train Loss: 0.000324
Validation Loss: 0.00037825
Epoch [142/300], Train Loss: 0.000324
Validation Loss: 0.00037640
Epoch [143/300], Train Loss: 0.000375
Validation Loss: 0.00036986
Epoch [144/300], Train Loss: 0.000323
Validation Loss: 0.00037698
Epoch [145/300], Train Loss: 0.000330
Validation Loss: 0.00039699
Epoch [146/300], Train Loss: 0.000327
Validation Loss: 0.00036153
Epoch [147/300], Train Loss: 0.000320
Validation Loss: 0.00040904
Epoch [148/300], Train Loss: 0.000324
Validation Loss: 0.00036285
Epoch [149/300], Train Loss: 0.000318
Validation Loss: 0.00039259
Epoch [150/300], Train Loss: 0.000329
Validation Loss: 0.00044675
Epoch [151/300], Train Loss: 0.000329
Validation Loss: 0.00037713
Epoch [152/300], Train Loss: 0.000338
Validation Loss: 0.00039399
Epoch [153/300], Train Loss: 0.000427
Validation Loss: 0.00038104
Epoch [154/300], Train Loss: 0.000328
Validation Loss: 0.00036709
Epoch [155/300], Train Loss: 0.000329
Validation Loss: 0.00035787
Epoch [156/300], Train Loss: 0.000328
Validation Loss: 0.00037184
Epoch [157/300], Train Loss: 0.000332
Validation Loss: 0.00038969
Epoch [158/300], Train Loss: 0.000331
Validation Loss: 0.00035231
Epoch [159/300], Train Loss: 0.000314
Validation Loss: 0.00038057
Epoch [160/300], Train Loss: 0.000314
Validation Loss: 0.00036049
Epoch [161/300], Train Loss: 0.000361
Validation Loss: 0.00038640
Epoch [162/300], Train Loss: 0.000317
Validation Loss: 0.00038277
Epoch [163/300], Train Loss: 0.000315
Validation Loss: 0.00036500
Epoch [164/300], Train Loss: 0.000314
Validation Loss: 0.00036175
Epoch [165/300], Train Loss: 0.000312
Validation Loss: 0.00038991
Epoch [166/300], Train Loss: 0.000326
Validation Loss: 0.00036666
Epoch [167/300], Train Loss: 0.000316
Validation Loss: 0.00037903
Epoch [168/300], Train Loss: 0.000321
Validation Loss: 0.00038997
Early stopping triggered

Evaluating model for: Microwave
Run 40/72 completed in 1635.33 seconds with: {'MAE': np.float32(9.629768), 'MSE': np.float32(10208.219), 'RMSE': np.float32(101.03573), 'SAE': np.float32(0.25229666), 'NDE': np.float32(0.7729453)}

Run 41/72: hidden=256, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Microwave
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.000642
Validation Loss: 0.00062279
Epoch [2/300], Train Loss: 0.000635
Validation Loss: 0.00062066
Epoch [3/300], Train Loss: 0.000640
Validation Loss: 0.00061668
Epoch [4/300], Train Loss: 0.000635
Validation Loss: 0.00061491
Epoch [5/300], Train Loss: 0.000638
Validation Loss: 0.00061008
Epoch [6/300], Train Loss: 0.000630
Validation Loss: 0.00060458
Epoch [7/300], Train Loss: 0.000620
Validation Loss: 0.00059932
Epoch [8/300], Train Loss: 0.000618
Validation Loss: 0.00059149
Epoch [9/300], Train Loss: 0.000629
Validation Loss: 0.00058565
Epoch [10/300], Train Loss: 0.000602
Validation Loss: 0.00057848
Epoch [11/300], Train Loss: 0.000593
Validation Loss: 0.00056763
Epoch [12/300], Train Loss: 0.000586
Validation Loss: 0.00053530
Epoch [13/300], Train Loss: 0.000544
Validation Loss: 0.00048443
Epoch [14/300], Train Loss: 0.000506
Validation Loss: 0.00044513
Epoch [15/300], Train Loss: 0.000501
Validation Loss: 0.00044223
Epoch [16/300], Train Loss: 0.000513
Validation Loss: 0.00057371
Epoch [17/300], Train Loss: 0.000616
Validation Loss: 0.00059598
Epoch [18/300], Train Loss: 0.000607
Validation Loss: 0.00058139
Epoch [19/300], Train Loss: 0.000593
Validation Loss: 0.00056699
Epoch [20/300], Train Loss: 0.000577
Validation Loss: 0.00052840
Epoch [21/300], Train Loss: 0.000543
Validation Loss: 0.00047613
Epoch [22/300], Train Loss: 0.000527
Validation Loss: 0.00044172
Epoch [23/300], Train Loss: 0.000502
Validation Loss: 0.00045821
Epoch [24/300], Train Loss: 0.000522
Validation Loss: 0.00047779
Epoch [25/300], Train Loss: 0.000504
Validation Loss: 0.00047318
Epoch [26/300], Train Loss: 0.000520
Validation Loss: 0.00045854
Epoch [27/300], Train Loss: 0.000500
Validation Loss: 0.00043476
Epoch [28/300], Train Loss: 0.000490
Validation Loss: 0.00043941
Epoch [29/300], Train Loss: 0.000491
Validation Loss: 0.00044448
Epoch [30/300], Train Loss: 0.000496
Validation Loss: 0.00044370
Epoch [31/300], Train Loss: 0.000492
Validation Loss: 0.00043279
Epoch [32/300], Train Loss: 0.000490
Validation Loss: 0.00044208
Epoch [33/300], Train Loss: 0.000499
Validation Loss: 0.00044447
Epoch [34/300], Train Loss: 0.000498
Validation Loss: 0.00043082
Epoch [35/300], Train Loss: 0.000494
Validation Loss: 0.00043478
Epoch [36/300], Train Loss: 0.000486
Validation Loss: 0.00045099
Epoch [37/300], Train Loss: 0.000494
Validation Loss: 0.00042530
Epoch [38/300], Train Loss: 0.000490
Validation Loss: 0.00043216
Epoch [39/300], Train Loss: 0.000483
Validation Loss: 0.00042806
Epoch [40/300], Train Loss: 0.000492
Validation Loss: 0.00041786
Epoch [41/300], Train Loss: 0.000486
Validation Loss: 0.00042346
Epoch [42/300], Train Loss: 0.000484
Validation Loss: 0.00041724
Epoch [43/300], Train Loss: 0.000482
Validation Loss: 0.00041406
Epoch [44/300], Train Loss: 0.000496
Validation Loss: 0.00041431
Epoch [45/300], Train Loss: 0.000485
Validation Loss: 0.00041566
Epoch [46/300], Train Loss: 0.000475
Validation Loss: 0.00042071
Epoch [47/300], Train Loss: 0.000482
Validation Loss: 0.00042066
Epoch [48/300], Train Loss: 0.000475
Validation Loss: 0.00041121
Epoch [49/300], Train Loss: 0.000474
Validation Loss: 0.00040998
Epoch [50/300], Train Loss: 0.000476
Validation Loss: 0.00041835
Epoch [51/300], Train Loss: 0.000472
Validation Loss: 0.00041086
Epoch [52/300], Train Loss: 0.000472
Validation Loss: 0.00041040
Epoch [53/300], Train Loss: 0.000478
Validation Loss: 0.00045404
Epoch [54/300], Train Loss: 0.000492
Validation Loss: 0.00042802
Epoch [55/300], Train Loss: 0.000476
Validation Loss: 0.00043152
Epoch [56/300], Train Loss: 0.000471
Validation Loss: 0.00040791
Epoch [57/300], Train Loss: 0.000468
Validation Loss: 0.00040961
Epoch [58/300], Train Loss: 0.000465
Validation Loss: 0.00041172
Epoch [59/300], Train Loss: 0.000470
Validation Loss: 0.00040710
Epoch [60/300], Train Loss: 0.000480
Validation Loss: 0.00046087
Epoch [61/300], Train Loss: 0.000481
Validation Loss: 0.00040823
Epoch [62/300], Train Loss: 0.000485
Validation Loss: 0.00040148
Epoch [63/300], Train Loss: 0.000463
Validation Loss: 0.00040403
Epoch [64/300], Train Loss: 0.000462
Validation Loss: 0.00040279
Epoch [65/300], Train Loss: 0.000471
Validation Loss: 0.00044916
Epoch [66/300], Train Loss: 0.000486
Validation Loss: 0.00042284
Epoch [67/300], Train Loss: 0.000467
Validation Loss: 0.00040527
Epoch [68/300], Train Loss: 0.000464
Validation Loss: 0.00041710
Epoch [69/300], Train Loss: 0.000473
Validation Loss: 0.00039773
Epoch [70/300], Train Loss: 0.000462
Validation Loss: 0.00040587
Epoch [71/300], Train Loss: 0.000451
Validation Loss: 0.00040081
Epoch [72/300], Train Loss: 0.000459
Validation Loss: 0.00041482
Epoch [73/300], Train Loss: 0.000452
Validation Loss: 0.00039372
Epoch [74/300], Train Loss: 0.000451
Validation Loss: 0.00040391
Epoch [75/300], Train Loss: 0.000457
Validation Loss: 0.00040377
Epoch [76/300], Train Loss: 0.000451
Validation Loss: 0.00039418
Epoch [77/300], Train Loss: 0.000455
Validation Loss: 0.00040436
Epoch [78/300], Train Loss: 0.000442
Validation Loss: 0.00038868
Epoch [79/300], Train Loss: 0.000448
Validation Loss: 0.00038647
Epoch [80/300], Train Loss: 0.000455
Validation Loss: 0.00038745
Epoch [81/300], Train Loss: 0.000447
Validation Loss: 0.00040165
Epoch [82/300], Train Loss: 0.000444
Validation Loss: 0.00041883
Epoch [83/300], Train Loss: 0.000442
Validation Loss: 0.00039523
Epoch [84/300], Train Loss: 0.000442
Validation Loss: 0.00038834
Epoch [85/300], Train Loss: 0.000443
Validation Loss: 0.00039645
Epoch [86/300], Train Loss: 0.000435
Validation Loss: 0.00039164
Epoch [87/300], Train Loss: 0.000433
Validation Loss: 0.00038821
Epoch [88/300], Train Loss: 0.000429
Validation Loss: 0.00040844
Epoch [89/300], Train Loss: 0.000436
Validation Loss: 0.00038036
Epoch [90/300], Train Loss: 0.000434
Validation Loss: 0.00040667
Epoch [91/300], Train Loss: 0.000425
Validation Loss: 0.00038265
Epoch [92/300], Train Loss: 0.000429
Validation Loss: 0.00040693
Epoch [93/300], Train Loss: 0.000429
Validation Loss: 0.00038506
Epoch [94/300], Train Loss: 0.000426
Validation Loss: 0.00038418
Epoch [95/300], Train Loss: 0.000427
Validation Loss: 0.00037636
Epoch [96/300], Train Loss: 0.000427
Validation Loss: 0.00038237
Epoch [97/300], Train Loss: 0.000430
Validation Loss: 0.00037226
Epoch [98/300], Train Loss: 0.000428
Validation Loss: 0.00037434
Epoch [99/300], Train Loss: 0.000424
Validation Loss: 0.00040196
Epoch [100/300], Train Loss: 0.000425
Validation Loss: 0.00036800
Epoch [101/300], Train Loss: 0.000423
Validation Loss: 0.00037914
Epoch [102/300], Train Loss: 0.000416
Validation Loss: 0.00038336
Epoch [103/300], Train Loss: 0.000425
Validation Loss: 0.00037477
Epoch [104/300], Train Loss: 0.000421
Validation Loss: 0.00037221
Epoch [105/300], Train Loss: 0.000422
Validation Loss: 0.00036840
Epoch [106/300], Train Loss: 0.000425
Validation Loss: 0.00037087
Epoch [107/300], Train Loss: 0.000411
Validation Loss: 0.00037984
Epoch [108/300], Train Loss: 0.000414
Validation Loss: 0.00035859
Epoch [109/300], Train Loss: 0.000425
Validation Loss: 0.00036566
Epoch [110/300], Train Loss: 0.000417
Validation Loss: 0.00037987
Epoch [111/300], Train Loss: 0.000428
Validation Loss: 0.00037798
Epoch [112/300], Train Loss: 0.000431
Validation Loss: 0.00040125
Epoch [113/300], Train Loss: 0.000423
Validation Loss: 0.00036052
Epoch [114/300], Train Loss: 0.000413
Validation Loss: 0.00036321
Epoch [115/300], Train Loss: 0.000411
Validation Loss: 0.00036299
Epoch [116/300], Train Loss: 0.000410
Validation Loss: 0.00035924
Epoch [117/300], Train Loss: 0.000409
Validation Loss: 0.00035937
Epoch [118/300], Train Loss: 0.000409
Validation Loss: 0.00035562
Epoch [119/300], Train Loss: 0.000403
Validation Loss: 0.00035770
Epoch [120/300], Train Loss: 0.000405
Validation Loss: 0.00035124
Epoch [121/300], Train Loss: 0.000416
Validation Loss: 0.00036595
Epoch [122/300], Train Loss: 0.000402
Validation Loss: 0.00034971
Epoch [123/300], Train Loss: 0.000402
Validation Loss: 0.00035687
Epoch [124/300], Train Loss: 0.000404
Validation Loss: 0.00034098
Epoch [125/300], Train Loss: 0.000399
Validation Loss: 0.00035276
Epoch [126/300], Train Loss: 0.000415
Validation Loss: 0.00034747
Epoch [127/300], Train Loss: 0.000409
Validation Loss: 0.00034297
Epoch [128/300], Train Loss: 0.000402
Validation Loss: 0.00034115
Epoch [129/300], Train Loss: 0.000398
Validation Loss: 0.00034385
Epoch [130/300], Train Loss: 0.000396
Validation Loss: 0.00034069
Epoch [131/300], Train Loss: 0.000397
Validation Loss: 0.00035354
Epoch [132/300], Train Loss: 0.000394
Validation Loss: 0.00034212
Epoch [133/300], Train Loss: 0.000402
Validation Loss: 0.00036437
Epoch [134/300], Train Loss: 0.000416
Validation Loss: 0.00033584
Epoch [135/300], Train Loss: 0.000413
Validation Loss: 0.00033877
Epoch [136/300], Train Loss: 0.000399
Validation Loss: 0.00033629
Epoch [137/300], Train Loss: 0.000393
Validation Loss: 0.00033871
Epoch [138/300], Train Loss: 0.000392
Validation Loss: 0.00032815
Epoch [139/300], Train Loss: 0.000400
Validation Loss: 0.00033842
Epoch [140/300], Train Loss: 0.000397
Validation Loss: 0.00033112
Epoch [141/300], Train Loss: 0.000396
Validation Loss: 0.00033373
Epoch [142/300], Train Loss: 0.000394
Validation Loss: 0.00032844
Epoch [143/300], Train Loss: 0.000397
Validation Loss: 0.00032535
Epoch [144/300], Train Loss: 0.000386
Validation Loss: 0.00034321
Epoch [145/300], Train Loss: 0.000390
Validation Loss: 0.00032920
Epoch [146/300], Train Loss: 0.000396
Validation Loss: 0.00034038
Epoch [147/300], Train Loss: 0.000390
Validation Loss: 0.00033728
Epoch [148/300], Train Loss: 0.000393
Validation Loss: 0.00032006
Epoch [149/300], Train Loss: 0.000395
Validation Loss: 0.00032173
Epoch [150/300], Train Loss: 0.000393
Validation Loss: 0.00032829
Epoch [151/300], Train Loss: 0.000392
Validation Loss: 0.00032080
Epoch [152/300], Train Loss: 0.000387
Validation Loss: 0.00032566
Epoch [153/300], Train Loss: 0.000385
Validation Loss: 0.00031700
Epoch [154/300], Train Loss: 0.000395
Validation Loss: 0.00031810
Epoch [155/300], Train Loss: 0.000387
Validation Loss: 0.00033029
Epoch [156/300], Train Loss: 0.000403
Validation Loss: 0.00034807
Epoch [157/300], Train Loss: 0.000397
Validation Loss: 0.00033178
Epoch [158/300], Train Loss: 0.000386
Validation Loss: 0.00032044
Epoch [159/300], Train Loss: 0.000385
Validation Loss: 0.00031798
Epoch [160/300], Train Loss: 0.000382
Validation Loss: 0.00032620
Epoch [161/300], Train Loss: 0.000386
Validation Loss: 0.00032015
Epoch [162/300], Train Loss: 0.000389
Validation Loss: 0.00031187
Epoch [163/300], Train Loss: 0.000386
Validation Loss: 0.00031822
Epoch [164/300], Train Loss: 0.000380
Validation Loss: 0.00031996
Epoch [165/300], Train Loss: 0.000380
Validation Loss: 0.00031850
Epoch [166/300], Train Loss: 0.000387
Validation Loss: 0.00030909
Epoch [167/300], Train Loss: 0.000377
Validation Loss: 0.00030845
Epoch [168/300], Train Loss: 0.000386
Validation Loss: 0.00030147
Epoch [169/300], Train Loss: 0.000383
Validation Loss: 0.00031611
Epoch [170/300], Train Loss: 0.000378
Validation Loss: 0.00030473
Epoch [171/300], Train Loss: 0.000380
Validation Loss: 0.00034381
Epoch [172/300], Train Loss: 0.000397
Validation Loss: 0.00030651
Epoch [173/300], Train Loss: 0.000379
Validation Loss: 0.00030903
Epoch [174/300], Train Loss: 0.000382
Validation Loss: 0.00030205
Epoch [175/300], Train Loss: 0.000380
Validation Loss: 0.00029733
Epoch [176/300], Train Loss: 0.000390
Validation Loss: 0.00031527
Epoch [177/300], Train Loss: 0.000386
Validation Loss: 0.00030282
Epoch [178/300], Train Loss: 0.000374
Validation Loss: 0.00030319
Epoch [179/300], Train Loss: 0.000396
Validation Loss: 0.00034002
Epoch [180/300], Train Loss: 0.000400
Validation Loss: 0.00031165
Epoch [181/300], Train Loss: 0.000378
Validation Loss: 0.00030667
Epoch [182/300], Train Loss: 0.000375
Validation Loss: 0.00030752
Epoch [183/300], Train Loss: 0.000376
Validation Loss: 0.00030361
Epoch [184/300], Train Loss: 0.000375
Validation Loss: 0.00029515
Epoch [185/300], Train Loss: 0.000379
Validation Loss: 0.00030170
Epoch [186/300], Train Loss: 0.000371
Validation Loss: 0.00030372
Epoch [187/300], Train Loss: 0.000374
Validation Loss: 0.00030220
Epoch [188/300], Train Loss: 0.000378
Validation Loss: 0.00029476
Epoch [189/300], Train Loss: 0.000373
Validation Loss: 0.00029383
Epoch [190/300], Train Loss: 0.000377
Validation Loss: 0.00029056
Epoch [191/300], Train Loss: 0.000376
Validation Loss: 0.00029743
Epoch [192/300], Train Loss: 0.000370
Validation Loss: 0.00029283
Epoch [193/300], Train Loss: 0.000384
Validation Loss: 0.00028918
Epoch [194/300], Train Loss: 0.000379
Validation Loss: 0.00028976
Epoch [195/300], Train Loss: 0.000375
Validation Loss: 0.00029402
Epoch [196/300], Train Loss: 0.000368
Validation Loss: 0.00030090
Epoch [197/300], Train Loss: 0.000368
Validation Loss: 0.00029035
Epoch [198/300], Train Loss: 0.000373
Validation Loss: 0.00029270
Epoch [199/300], Train Loss: 0.000379
Validation Loss: 0.00029116
Epoch [200/300], Train Loss: 0.000373
Validation Loss: 0.00028684
Epoch [201/300], Train Loss: 0.000364
Validation Loss: 0.00028858
Epoch [202/300], Train Loss: 0.000370
Validation Loss: 0.00028107
Epoch [203/300], Train Loss: 0.000373
Validation Loss: 0.00030032
Epoch [204/300], Train Loss: 0.000381
Validation Loss: 0.00030507
Epoch [205/300], Train Loss: 0.000377
Validation Loss: 0.00029494
Epoch [206/300], Train Loss: 0.000371
Validation Loss: 0.00030273
Epoch [207/300], Train Loss: 0.000374
Validation Loss: 0.00029333
Epoch [208/300], Train Loss: 0.000372
Validation Loss: 0.00029598
Epoch [209/300], Train Loss: 0.000367
Validation Loss: 0.00029763
Epoch [210/300], Train Loss: 0.000371
Validation Loss: 0.00029628
Epoch [211/300], Train Loss: 0.000365
Validation Loss: 0.00029801
Epoch [212/300], Train Loss: 0.000370
Validation Loss: 0.00029466
Early stopping triggered

Evaluating model for: Microwave
Run 41/72 completed in 1580.87 seconds with: {'MAE': np.float32(10.497657), 'MSE': np.float32(5544.6147), 'RMSE': np.float32(74.46217), 'SAE': np.float32(0.14678487), 'NDE': np.float32(0.7020763)}

Run 42/72: hidden=256, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Microwave
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.000915
Validation Loss: 0.00063013
Epoch [2/300], Train Loss: 0.000649
Validation Loss: 0.00063060
Epoch [3/300], Train Loss: 0.000653
Validation Loss: 0.00062798
Epoch [4/300], Train Loss: 0.000651
Validation Loss: 0.00062757
Epoch [5/300], Train Loss: 0.000657
Validation Loss: 0.00062670
Epoch [6/300], Train Loss: 0.000651
Validation Loss: 0.00062570
Epoch [7/300], Train Loss: 0.000645
Validation Loss: 0.00062442
Epoch [8/300], Train Loss: 0.000647
Validation Loss: 0.00062216
Epoch [9/300], Train Loss: 0.000659
Validation Loss: 0.00061893
Epoch [10/300], Train Loss: 0.000631
Validation Loss: 0.00061124
Epoch [11/300], Train Loss: 0.000622
Validation Loss: 0.00060154
Epoch [12/300], Train Loss: 0.000621
Validation Loss: 0.00058751
Epoch [13/300], Train Loss: 0.000596
Validation Loss: 0.00054266
Epoch [14/300], Train Loss: 0.000569
Validation Loss: 0.00054766
Epoch [15/300], Train Loss: 0.000566
Validation Loss: 0.00051810
Epoch [16/300], Train Loss: 0.000534
Validation Loss: 0.00048015
Epoch [17/300], Train Loss: 0.000517
Validation Loss: 0.00047504
Epoch [18/300], Train Loss: 0.000511
Validation Loss: 0.00045666
Epoch [19/300], Train Loss: 0.000503
Validation Loss: 0.00045881
Epoch [20/300], Train Loss: 0.000507
Validation Loss: 0.00045815
Epoch [21/300], Train Loss: 0.000512
Validation Loss: 0.00046189
Epoch [22/300], Train Loss: 0.000520
Validation Loss: 0.00045589
Epoch [23/300], Train Loss: 0.000500
Validation Loss: 0.00046819
Epoch [24/300], Train Loss: 0.000520
Validation Loss: 0.00048037
Epoch [25/300], Train Loss: 0.000499
Validation Loss: 0.00048157
Epoch [26/300], Train Loss: 0.000514
Validation Loss: 0.00047784
Epoch [27/300], Train Loss: 0.000506
Validation Loss: 0.00044712
Epoch [28/300], Train Loss: 0.000493
Validation Loss: 0.00044945
Epoch [29/300], Train Loss: 0.000494
Validation Loss: 0.00045281
Epoch [30/300], Train Loss: 0.000497
Validation Loss: 0.00045338
Epoch [31/300], Train Loss: 0.000497
Validation Loss: 0.00044644
Epoch [32/300], Train Loss: 0.000497
Validation Loss: 0.00045116
Epoch [33/300], Train Loss: 0.000503
Validation Loss: 0.00047185
Epoch [34/300], Train Loss: 0.000503
Validation Loss: 0.00043945
Epoch [35/300], Train Loss: 0.000499
Validation Loss: 0.00044202
Epoch [36/300], Train Loss: 0.000488
Validation Loss: 0.00045232
Epoch [37/300], Train Loss: 0.000496
Validation Loss: 0.00043791
Epoch [38/300], Train Loss: 0.000495
Validation Loss: 0.00044511
Epoch [39/300], Train Loss: 0.000488
Validation Loss: 0.00044084
Epoch [40/300], Train Loss: 0.000494
Validation Loss: 0.00043428
Epoch [41/300], Train Loss: 0.000490
Validation Loss: 0.00043861
Epoch [42/300], Train Loss: 0.000487
Validation Loss: 0.00043051
Epoch [43/300], Train Loss: 0.000487
Validation Loss: 0.00043059
Epoch [44/300], Train Loss: 0.000496
Validation Loss: 0.00042801
Epoch [45/300], Train Loss: 0.000490
Validation Loss: 0.00042784
Epoch [46/300], Train Loss: 0.000480
Validation Loss: 0.00042978
Epoch [47/300], Train Loss: 0.000485
Validation Loss: 0.00043378
Epoch [48/300], Train Loss: 0.000480
Validation Loss: 0.00042264
Epoch [49/300], Train Loss: 0.000477
Validation Loss: 0.00041943
Epoch [50/300], Train Loss: 0.000476
Validation Loss: 0.00042843
Epoch [51/300], Train Loss: 0.000476
Validation Loss: 0.00042160
Epoch [52/300], Train Loss: 0.000475
Validation Loss: 0.00041652
Epoch [53/300], Train Loss: 0.000475
Validation Loss: 0.00041755
Epoch [54/300], Train Loss: 0.000491
Validation Loss: 0.00046320
Epoch [55/300], Train Loss: 0.000484
Validation Loss: 0.00043261
Epoch [56/300], Train Loss: 0.000473
Validation Loss: 0.00040984
Epoch [57/300], Train Loss: 0.000470
Validation Loss: 0.00041536
Epoch [58/300], Train Loss: 0.000469
Validation Loss: 0.00041635
Epoch [59/300], Train Loss: 0.000469
Validation Loss: 0.00041346
Epoch [60/300], Train Loss: 0.000487
Validation Loss: 0.00046380
Epoch [61/300], Train Loss: 0.000480
Validation Loss: 0.00041559
Epoch [62/300], Train Loss: 0.000487
Validation Loss: 0.00040558
Epoch [63/300], Train Loss: 0.000465
Validation Loss: 0.00040618
Epoch [64/300], Train Loss: 0.000464
Validation Loss: 0.00040491
Epoch [65/300], Train Loss: 0.000467
Validation Loss: 0.00045250
Epoch [66/300], Train Loss: 0.000488
Validation Loss: 0.00041466
Epoch [67/300], Train Loss: 0.000461
Validation Loss: 0.00040892
Epoch [68/300], Train Loss: 0.000461
Validation Loss: 0.00041016
Epoch [69/300], Train Loss: 0.000477
Validation Loss: 0.00041600
Epoch [70/300], Train Loss: 0.000465
Validation Loss: 0.00040600
Epoch [71/300], Train Loss: 0.000453
Validation Loss: 0.00044641
Epoch [72/300], Train Loss: 0.000457
Validation Loss: 0.00040577
Epoch [73/300], Train Loss: 0.000451
Validation Loss: 0.00039868
Epoch [74/300], Train Loss: 0.000452
Validation Loss: 0.00039625
Epoch [75/300], Train Loss: 0.000451
Validation Loss: 0.00039394
Epoch [76/300], Train Loss: 0.000453
Validation Loss: 0.00039969
Epoch [77/300], Train Loss: 0.000454
Validation Loss: 0.00039590
Epoch [78/300], Train Loss: 0.000437
Validation Loss: 0.00039236
Epoch [79/300], Train Loss: 0.000445
Validation Loss: 0.00039526
Epoch [80/300], Train Loss: 0.000460
Validation Loss: 0.00038649
Epoch [81/300], Train Loss: 0.000455
Validation Loss: 0.00039493
Epoch [82/300], Train Loss: 0.000445
Validation Loss: 0.00042751
Epoch [83/300], Train Loss: 0.000449
Validation Loss: 0.00038622
Epoch [84/300], Train Loss: 0.000444
Validation Loss: 0.00038656
Epoch [85/300], Train Loss: 0.000437
Validation Loss: 0.00038757
Epoch [86/300], Train Loss: 0.000434
Validation Loss: 0.00038511
Epoch [87/300], Train Loss: 0.000432
Validation Loss: 0.00038425
Epoch [88/300], Train Loss: 0.000428
Validation Loss: 0.00039133
Epoch [89/300], Train Loss: 0.000434
Validation Loss: 0.00038368
Epoch [90/300], Train Loss: 0.000438
Validation Loss: 0.00039146
Epoch [91/300], Train Loss: 0.000428
Validation Loss: 0.00038903
Epoch [92/300], Train Loss: 0.000427
Validation Loss: 0.00040124
Epoch [93/300], Train Loss: 0.000428
Validation Loss: 0.00038115
Epoch [94/300], Train Loss: 0.000428
Validation Loss: 0.00038419
Epoch [95/300], Train Loss: 0.000433
Validation Loss: 0.00038797
Epoch [96/300], Train Loss: 0.000432
Validation Loss: 0.00037515
Epoch [97/300], Train Loss: 0.000432
Validation Loss: 0.00037150
Epoch [98/300], Train Loss: 0.000426
Validation Loss: 0.00037280
Epoch [99/300], Train Loss: 0.000424
Validation Loss: 0.00040623
Epoch [100/300], Train Loss: 0.000424
Validation Loss: 0.00036984
Epoch [101/300], Train Loss: 0.000417
Validation Loss: 0.00037882
Epoch [102/300], Train Loss: 0.000417
Validation Loss: 0.00037347
Epoch [103/300], Train Loss: 0.000426
Validation Loss: 0.00037561
Epoch [104/300], Train Loss: 0.000426
Validation Loss: 0.00036745
Epoch [105/300], Train Loss: 0.000421
Validation Loss: 0.00037237
Epoch [106/300], Train Loss: 0.000424
Validation Loss: 0.00037359
Epoch [107/300], Train Loss: 0.000413
Validation Loss: 0.00037561
Epoch [108/300], Train Loss: 0.000415
Validation Loss: 0.00036244
Epoch [109/300], Train Loss: 0.000430
Validation Loss: 0.00037833
Epoch [110/300], Train Loss: 0.000418
Validation Loss: 0.00037640
Epoch [111/300], Train Loss: 0.000424
Validation Loss: 0.00037983
Epoch [112/300], Train Loss: 0.000432
Validation Loss: 0.00040670
Epoch [113/300], Train Loss: 0.000426
Validation Loss: 0.00035747
Epoch [114/300], Train Loss: 0.000414
Validation Loss: 0.00037048
Epoch [115/300], Train Loss: 0.000412
Validation Loss: 0.00035941
Epoch [116/300], Train Loss: 0.000413
Validation Loss: 0.00036063
Epoch [117/300], Train Loss: 0.000409
Validation Loss: 0.00038426
Epoch [118/300], Train Loss: 0.000416
Validation Loss: 0.00035566
Epoch [119/300], Train Loss: 0.000405
Validation Loss: 0.00037199
Epoch [120/300], Train Loss: 0.000410
Validation Loss: 0.00034747
Epoch [121/300], Train Loss: 0.000418
Validation Loss: 0.00037335
Epoch [122/300], Train Loss: 0.000404
Validation Loss: 0.00035514
Epoch [123/300], Train Loss: 0.000404
Validation Loss: 0.00036716
Epoch [124/300], Train Loss: 0.000409
Validation Loss: 0.00035082
Epoch [125/300], Train Loss: 0.000404
Validation Loss: 0.00035821
Epoch [126/300], Train Loss: 0.000421
Validation Loss: 0.00035058
Epoch [127/300], Train Loss: 0.000418
Validation Loss: 0.00034785
Epoch [128/300], Train Loss: 0.000408
Validation Loss: 0.00034190
Epoch [129/300], Train Loss: 0.000403
Validation Loss: 0.00035317
Epoch [130/300], Train Loss: 0.000401
Validation Loss: 0.00034954
Epoch [131/300], Train Loss: 0.000402
Validation Loss: 0.00035431
Epoch [132/300], Train Loss: 0.000399
Validation Loss: 0.00035440
Epoch [133/300], Train Loss: 0.000408
Validation Loss: 0.00035282
Epoch [134/300], Train Loss: 0.000414
Validation Loss: 0.00034429
Epoch [135/300], Train Loss: 0.000410
Validation Loss: 0.00034152
Epoch [136/300], Train Loss: 0.000403
Validation Loss: 0.00034898
Epoch [137/300], Train Loss: 0.000397
Validation Loss: 0.00034727
Epoch [138/300], Train Loss: 0.000398
Validation Loss: 0.00034266
Epoch [139/300], Train Loss: 0.000407
Validation Loss: 0.00033983
Epoch [140/300], Train Loss: 0.000401
Validation Loss: 0.00034117
Epoch [141/300], Train Loss: 0.000400
Validation Loss: 0.00034421
Epoch [142/300], Train Loss: 0.000398
Validation Loss: 0.00034090
Epoch [143/300], Train Loss: 0.000401
Validation Loss: 0.00033751
Epoch [144/300], Train Loss: 0.000394
Validation Loss: 0.00036018
Epoch [145/300], Train Loss: 0.000398
Validation Loss: 0.00033967
Epoch [146/300], Train Loss: 0.000403
Validation Loss: 0.00037832
Epoch [147/300], Train Loss: 0.000400
Validation Loss: 0.00034513
Epoch [148/300], Train Loss: 0.000401
Validation Loss: 0.00032956
Epoch [149/300], Train Loss: 0.000398
Validation Loss: 0.00033902
Epoch [150/300], Train Loss: 0.000399
Validation Loss: 0.00034481
Epoch [151/300], Train Loss: 0.000397
Validation Loss: 0.00032929
Epoch [152/300], Train Loss: 0.000396
Validation Loss: 0.00033309
Epoch [153/300], Train Loss: 0.000393
Validation Loss: 0.00032915
Epoch [154/300], Train Loss: 0.000400
Validation Loss: 0.00033701
Epoch [155/300], Train Loss: 0.000394
Validation Loss: 0.00034503
Epoch [156/300], Train Loss: 0.000413
Validation Loss: 0.00034405
Epoch [157/300], Train Loss: 0.000395
Validation Loss: 0.00033480
Epoch [158/300], Train Loss: 0.000389
Validation Loss: 0.00033056
Epoch [159/300], Train Loss: 0.000390
Validation Loss: 0.00032648
Epoch [160/300], Train Loss: 0.000385
Validation Loss: 0.00034801
Epoch [161/300], Train Loss: 0.000392
Validation Loss: 0.00033195
Epoch [162/300], Train Loss: 0.000391
Validation Loss: 0.00032569
Epoch [163/300], Train Loss: 0.000388
Validation Loss: 0.00032850
Epoch [164/300], Train Loss: 0.000386
Validation Loss: 0.00033047
Epoch [165/300], Train Loss: 0.000388
Validation Loss: 0.00032501
Epoch [166/300], Train Loss: 0.000392
Validation Loss: 0.00032588
Epoch [167/300], Train Loss: 0.000384
Validation Loss: 0.00032432
Epoch [168/300], Train Loss: 0.000390
Validation Loss: 0.00031654
Epoch [169/300], Train Loss: 0.000390
Validation Loss: 0.00033517
Epoch [170/300], Train Loss: 0.000385
Validation Loss: 0.00031518
Epoch [171/300], Train Loss: 0.000392
Validation Loss: 0.00033073
Epoch [172/300], Train Loss: 0.000394
Validation Loss: 0.00031815
Epoch [173/300], Train Loss: 0.000384
Validation Loss: 0.00032403
Epoch [174/300], Train Loss: 0.000389
Validation Loss: 0.00031857
Epoch [175/300], Train Loss: 0.000389
Validation Loss: 0.00031551
Epoch [176/300], Train Loss: 0.000396
Validation Loss: 0.00034113
Epoch [177/300], Train Loss: 0.000394
Validation Loss: 0.00031407
Epoch [178/300], Train Loss: 0.000384
Validation Loss: 0.00031158
Epoch [179/300], Train Loss: 0.000394
Validation Loss: 0.00035698
Epoch [180/300], Train Loss: 0.000401
Validation Loss: 0.00032007
Epoch [181/300], Train Loss: 0.000382
Validation Loss: 0.00032378
Epoch [182/300], Train Loss: 0.000384
Validation Loss: 0.00031956
Epoch [183/300], Train Loss: 0.000382
Validation Loss: 0.00032131
Epoch [184/300], Train Loss: 0.000385
Validation Loss: 0.00031377
Epoch [185/300], Train Loss: 0.000386
Validation Loss: 0.00031734
Epoch [186/300], Train Loss: 0.000382
Validation Loss: 0.00031446
Epoch [187/300], Train Loss: 0.000384
Validation Loss: 0.00032176
Epoch [188/300], Train Loss: 0.000384
Validation Loss: 0.00030295
Epoch [189/300], Train Loss: 0.000385
Validation Loss: 0.00031126
Epoch [190/300], Train Loss: 0.000386
Validation Loss: 0.00031668
Epoch [191/300], Train Loss: 0.000384
Validation Loss: 0.00030523
Epoch [192/300], Train Loss: 0.000386
Validation Loss: 0.00031131
Epoch [193/300], Train Loss: 0.000388
Validation Loss: 0.00030883
Epoch [194/300], Train Loss: 0.000382
Validation Loss: 0.00030477
Epoch [195/300], Train Loss: 0.000379
Validation Loss: 0.00031041
Epoch [196/300], Train Loss: 0.000378
Validation Loss: 0.00030819
Epoch [197/300], Train Loss: 0.000378
Validation Loss: 0.00031092
Epoch [198/300], Train Loss: 0.000382
Validation Loss: 0.00031698
Early stopping triggered

Evaluating model for: Microwave
Run 42/72 completed in 1897.24 seconds with: {'MAE': np.float32(7.8233886), 'MSE': np.float32(5935.336), 'RMSE': np.float32(77.04113), 'SAE': np.float32(0.17301093), 'NDE': np.float32(0.72638917)}

Run 43/72: hidden=256, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Microwave
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.000649
Validation Loss: 0.00062822
Epoch [2/300], Train Loss: 0.000641
Validation Loss: 0.00062675
Epoch [3/300], Train Loss: 0.000649
Validation Loss: 0.00062588
Epoch [4/300], Train Loss: 0.000646
Validation Loss: 0.00062426
Epoch [5/300], Train Loss: 0.000648
Validation Loss: 0.00062227
Epoch [6/300], Train Loss: 0.000639
Validation Loss: 0.00061348
Epoch [7/300], Train Loss: 0.000629
Validation Loss: 0.00060666
Epoch [8/300], Train Loss: 0.000626
Validation Loss: 0.00059901
Epoch [9/300], Train Loss: 0.000631
Validation Loss: 0.00058104
Epoch [10/300], Train Loss: 0.000584
Validation Loss: 0.00049657
Epoch [11/300], Train Loss: 0.000523
Validation Loss: 0.00047060
Epoch [12/300], Train Loss: 0.000539
Validation Loss: 0.00047435
Epoch [13/300], Train Loss: 0.000525
Validation Loss: 0.00045520
Epoch [14/300], Train Loss: 0.000512
Validation Loss: 0.00044851
Epoch [15/300], Train Loss: 0.000510
Validation Loss: 0.00046690
Epoch [16/300], Train Loss: 0.000509
Validation Loss: 0.00044582
Epoch [17/300], Train Loss: 0.000506
Validation Loss: 0.00045342
Epoch [18/300], Train Loss: 0.000506
Validation Loss: 0.00043257
Epoch [19/300], Train Loss: 0.000499
Validation Loss: 0.00043393
Epoch [20/300], Train Loss: 0.000497
Validation Loss: 0.00043905
Epoch [21/300], Train Loss: 0.000507
Validation Loss: 0.00043370
Epoch [22/300], Train Loss: 0.000513
Validation Loss: 0.00043202
Epoch [23/300], Train Loss: 0.000494
Validation Loss: 0.00044715
Epoch [24/300], Train Loss: 0.000519
Validation Loss: 0.00045797
Epoch [25/300], Train Loss: 0.000493
Validation Loss: 0.00045162
Epoch [26/300], Train Loss: 0.000505
Validation Loss: 0.00044751
Epoch [27/300], Train Loss: 0.000501
Validation Loss: 0.00041549
Epoch [28/300], Train Loss: 0.000487
Validation Loss: 0.00041211
Epoch [29/300], Train Loss: 0.000482
Validation Loss: 0.00041052
Epoch [30/300], Train Loss: 0.000485
Validation Loss: 0.00040770
Epoch [31/300], Train Loss: 0.000479
Validation Loss: 0.00040193
Epoch [32/300], Train Loss: 0.000481
Validation Loss: 0.00041729
Epoch [33/300], Train Loss: 0.000485
Validation Loss: 0.00039985
Epoch [34/300], Train Loss: 0.000479
Validation Loss: 0.00036685
Epoch [35/300], Train Loss: 0.000477
Validation Loss: 0.00033741
Epoch [36/300], Train Loss: 0.000455
Validation Loss: 0.00034515
Epoch [37/300], Train Loss: 0.000457
Validation Loss: 0.00033211
Epoch [38/300], Train Loss: 0.000453
Validation Loss: 0.00035135
Epoch [39/300], Train Loss: 0.000450
Validation Loss: 0.00036880
Epoch [40/300], Train Loss: 0.000449
Validation Loss: 0.00032562
Epoch [41/300], Train Loss: 0.000443
Validation Loss: 0.00033880
Epoch [42/300], Train Loss: 0.000441
Validation Loss: 0.00031517
Epoch [43/300], Train Loss: 0.000433
Validation Loss: 0.00030696
Epoch [44/300], Train Loss: 0.000440
Validation Loss: 0.00033843
Epoch [45/300], Train Loss: 0.000441
Validation Loss: 0.00030112
Epoch [46/300], Train Loss: 0.000425
Validation Loss: 0.00031949
Epoch [47/300], Train Loss: 0.000434
Validation Loss: 0.00031244
Epoch [48/300], Train Loss: 0.000425
Validation Loss: 0.00030505
Epoch [49/300], Train Loss: 0.000421
Validation Loss: 0.00031349
Epoch [50/300], Train Loss: 0.000418
Validation Loss: 0.00031426
Epoch [51/300], Train Loss: 0.000416
Validation Loss: 0.00028770
Epoch [52/300], Train Loss: 0.000428
Validation Loss: 0.00035403
Epoch [53/300], Train Loss: 0.000429
Validation Loss: 0.00033458
Epoch [54/300], Train Loss: 0.000431
Validation Loss: 0.00030943
Epoch [55/300], Train Loss: 0.000424
Validation Loss: 0.00030786
Epoch [56/300], Train Loss: 0.000420
Validation Loss: 0.00029902
Epoch [57/300], Train Loss: 0.000407
Validation Loss: 0.00028589
Epoch [58/300], Train Loss: 0.000407
Validation Loss: 0.00027554
Epoch [59/300], Train Loss: 0.000410
Validation Loss: 0.00029069
Epoch [60/300], Train Loss: 0.000428
Validation Loss: 0.00034659
Epoch [61/300], Train Loss: 0.000411
Validation Loss: 0.00028859
Epoch [62/300], Train Loss: 0.000441
Validation Loss: 0.00029488
Epoch [63/300], Train Loss: 0.000400
Validation Loss: 0.00028246
Epoch [64/300], Train Loss: 0.000400
Validation Loss: 0.00034256
Epoch [65/300], Train Loss: 0.000405
Validation Loss: 0.00028384
Epoch [66/300], Train Loss: 0.000407
Validation Loss: 0.00029287
Epoch [67/300], Train Loss: 0.000404
Validation Loss: 0.00034177
Epoch [68/300], Train Loss: 0.000402
Validation Loss: 0.00029930
Early stopping triggered

Evaluating model for: Microwave
Run 43/72 completed in 781.40 seconds with: {'MAE': np.float32(9.187259), 'MSE': np.float32(6073.6294), 'RMSE': np.float32(77.933495), 'SAE': np.float32(0.18243544), 'NDE': np.float32(0.73480546)}

Run 44/72: hidden=256, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Microwave
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.001211
Validation Loss: 0.00066803
Epoch [2/300], Train Loss: 0.000657
Validation Loss: 0.00063230
Epoch [3/300], Train Loss: 0.000659
Validation Loss: 0.00063163
Epoch [4/300], Train Loss: 0.000657
Validation Loss: 0.00063223
Epoch [5/300], Train Loss: 0.000663
Validation Loss: 0.00063145
Epoch [6/300], Train Loss: 0.000658
Validation Loss: 0.00063134
Epoch [7/300], Train Loss: 0.000653
Validation Loss: 0.00063154
Epoch [8/300], Train Loss: 0.000657
Validation Loss: 0.00063143
Epoch [9/300], Train Loss: 0.000672
Validation Loss: 0.00063139
Epoch [10/300], Train Loss: 0.000648
Validation Loss: 0.00063126
Epoch [11/300], Train Loss: 0.000648
Validation Loss: 0.00063273
Epoch [12/300], Train Loss: 0.000656
Validation Loss: 0.00063075
Epoch [13/300], Train Loss: 0.000651
Validation Loss: 0.00062985
Epoch [14/300], Train Loss: 0.000645
Validation Loss: 0.00062951
Epoch [15/300], Train Loss: 0.000645
Validation Loss: 0.00062797
Epoch [16/300], Train Loss: 0.000642
Validation Loss: 0.00062375
Epoch [17/300], Train Loss: 0.000634
Validation Loss: 0.00061721
Epoch [18/300], Train Loss: 0.000629
Validation Loss: 0.00060908
Epoch [19/300], Train Loss: 0.000620
Validation Loss: 0.00059572
Epoch [20/300], Train Loss: 0.000614
Validation Loss: 0.00056999
Epoch [21/300], Train Loss: 0.000601
Validation Loss: 0.00054981
Epoch [22/300], Train Loss: 0.000575
Validation Loss: 0.00045714
Epoch [23/300], Train Loss: 0.000521
Validation Loss: 0.00044852
Epoch [24/300], Train Loss: 0.000532
Validation Loss: 0.00046727
Epoch [25/300], Train Loss: 0.000518
Validation Loss: 0.00046728
Epoch [26/300], Train Loss: 0.000522
Validation Loss: 0.00045156
Epoch [27/300], Train Loss: 0.000522
Validation Loss: 0.00043292
Epoch [28/300], Train Loss: 0.000509
Validation Loss: 0.00042429
Epoch [29/300], Train Loss: 0.000506
Validation Loss: 0.00041718
Epoch [30/300], Train Loss: 0.000506
Validation Loss: 0.00041761
Epoch [31/300], Train Loss: 0.000507
Validation Loss: 0.00041203
Epoch [32/300], Train Loss: 0.000511
Validation Loss: 0.00044310
Epoch [33/300], Train Loss: 0.000513
Validation Loss: 0.00042831
Epoch [34/300], Train Loss: 0.000513
Validation Loss: 0.00041017
Epoch [35/300], Train Loss: 0.000516
Validation Loss: 0.00040961
Epoch [36/300], Train Loss: 0.000498
Validation Loss: 0.00042250
Epoch [37/300], Train Loss: 0.000502
Validation Loss: 0.00040927
Epoch [38/300], Train Loss: 0.000503
Validation Loss: 0.00043226
Epoch [39/300], Train Loss: 0.000501
Validation Loss: 0.00042946
Epoch [40/300], Train Loss: 0.000503
Validation Loss: 0.00040402
Epoch [41/300], Train Loss: 0.000497
Validation Loss: 0.00040533
Epoch [42/300], Train Loss: 0.000494
Validation Loss: 0.00039912
Epoch [43/300], Train Loss: 0.000490
Validation Loss: 0.00039933
Epoch [44/300], Train Loss: 0.000501
Validation Loss: 0.00039010
Epoch [45/300], Train Loss: 0.000496
Validation Loss: 0.00038654
Epoch [46/300], Train Loss: 0.000486
Validation Loss: 0.00039192
Epoch [47/300], Train Loss: 0.000487
Validation Loss: 0.00039307
Epoch [48/300], Train Loss: 0.000480
Validation Loss: 0.00038375
Epoch [49/300], Train Loss: 0.000476
Validation Loss: 0.00037664
Epoch [50/300], Train Loss: 0.000476
Validation Loss: 0.00039449
Epoch [51/300], Train Loss: 0.000475
Validation Loss: 0.00037030
Epoch [52/300], Train Loss: 0.000477
Validation Loss: 0.00037527
Epoch [53/300], Train Loss: 0.000476
Validation Loss: 0.00038826
Epoch [54/300], Train Loss: 0.000479
Validation Loss: 0.00036146
Epoch [55/300], Train Loss: 0.000466
Validation Loss: 0.00032940
Epoch [56/300], Train Loss: 0.000456
Validation Loss: 0.00031842
Epoch [57/300], Train Loss: 0.000450
Validation Loss: 0.00032349
Epoch [58/300], Train Loss: 0.000452
Validation Loss: 0.00031256
Epoch [59/300], Train Loss: 0.000457
Validation Loss: 0.00033383
Epoch [60/300], Train Loss: 0.000489
Validation Loss: 0.00039905
Epoch [61/300], Train Loss: 0.000470
Validation Loss: 0.00031445
Epoch [62/300], Train Loss: 0.000479
Validation Loss: 0.00030497
Epoch [63/300], Train Loss: 0.000448
Validation Loss: 0.00031052
Epoch [64/300], Train Loss: 0.000444
Validation Loss: 0.00032810
Epoch [65/300], Train Loss: 0.000445
Validation Loss: 0.00032154
Epoch [66/300], Train Loss: 0.000447
Validation Loss: 0.00031565
Epoch [67/300], Train Loss: 0.000443
Validation Loss: 0.00030151
Epoch [68/300], Train Loss: 0.000445
Validation Loss: 0.00033681
Epoch [69/300], Train Loss: 0.000444
Validation Loss: 0.00029912
Epoch [70/300], Train Loss: 0.000433
Validation Loss: 0.00031498
Epoch [71/300], Train Loss: 0.000429
Validation Loss: 0.00032646
Epoch [72/300], Train Loss: 0.000437
Validation Loss: 0.00033573
Epoch [73/300], Train Loss: 0.000429
Validation Loss: 0.00031235
Epoch [74/300], Train Loss: 0.000432
Validation Loss: 0.00034123
Epoch [75/300], Train Loss: 0.000441
Validation Loss: 0.00037142
Epoch [76/300], Train Loss: 0.000439
Validation Loss: 0.00029181
Epoch [77/300], Train Loss: 0.000445
Validation Loss: 0.00035224
Epoch [78/300], Train Loss: 0.000417
Validation Loss: 0.00030786
Epoch [79/300], Train Loss: 0.000427
Validation Loss: 0.00031966
Epoch [80/300], Train Loss: 0.000432
Validation Loss: 0.00033067
Epoch [81/300], Train Loss: 0.000422
Validation Loss: 0.00031680
Epoch [82/300], Train Loss: 0.000422
Validation Loss: 0.00033629
Epoch [83/300], Train Loss: 0.000463
Validation Loss: 0.00028709
Epoch [84/300], Train Loss: 0.000443
Validation Loss: 0.00029221
Epoch [85/300], Train Loss: 0.000428
Validation Loss: 0.00028964
Epoch [86/300], Train Loss: 0.000418
Validation Loss: 0.00028471
Epoch [87/300], Train Loss: 0.000417
Validation Loss: 0.00030825
Epoch [88/300], Train Loss: 0.000412
Validation Loss: 0.00032833
Epoch [89/300], Train Loss: 0.000406
Validation Loss: 0.00031126
Epoch [90/300], Train Loss: 0.000403
Validation Loss: 0.00030363
Epoch [91/300], Train Loss: 0.000407
Validation Loss: 0.00031038
Epoch [92/300], Train Loss: 0.000399
Validation Loss: 0.00030490
Epoch [93/300], Train Loss: 0.000396
Validation Loss: 0.00028753
Epoch [94/300], Train Loss: 0.000395
Validation Loss: 0.00029868
Epoch [95/300], Train Loss: 0.000395
Validation Loss: 0.00029294
Epoch [96/300], Train Loss: 0.000390
Validation Loss: 0.00031189
Early stopping triggered

Evaluating model for: Microwave
Run 44/72 completed in 1517.93 seconds with: {'MAE': np.float32(10.438353), 'MSE': np.float32(5928.5415), 'RMSE': np.float32(76.997025), 'SAE': np.float32(0.12260764), 'NDE': np.float32(0.7259746)}

Run 45/72: hidden=256, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Microwave
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.000872
Validation Loss: 0.00032902
Epoch [2/300], Train Loss: 0.000701
Validation Loss: 0.00027730
Epoch [3/300], Train Loss: 0.000677
Validation Loss: 0.00027798
Epoch [4/300], Train Loss: 0.000671
Validation Loss: 0.00028010
Epoch [5/300], Train Loss: 0.000672
Validation Loss: 0.00027642
Epoch [6/300], Train Loss: 0.000669
Validation Loss: 0.00027689
Epoch [7/300], Train Loss: 0.000666
Validation Loss: 0.00027599
Epoch [8/300], Train Loss: 0.000665
Validation Loss: 0.00027558
Epoch [9/300], Train Loss: 0.000666
Validation Loss: 0.00027556
Epoch [10/300], Train Loss: 0.000664
Validation Loss: 0.00027463
Epoch [11/300], Train Loss: 0.000662
Validation Loss: 0.00027460
Epoch [12/300], Train Loss: 0.000662
Validation Loss: 0.00027392
Epoch [13/300], Train Loss: 0.000663
Validation Loss: 0.00027305
Epoch [14/300], Train Loss: 0.000660
Validation Loss: 0.00027234
Epoch [15/300], Train Loss: 0.000660
Validation Loss: 0.00027313
Epoch [16/300], Train Loss: 0.000654
Validation Loss: 0.00027231
Epoch [17/300], Train Loss: 0.000653
Validation Loss: 0.00027048
Epoch [18/300], Train Loss: 0.000647
Validation Loss: 0.00026945
Epoch [19/300], Train Loss: 0.000644
Validation Loss: 0.00027086
Epoch [20/300], Train Loss: 0.000643
Validation Loss: 0.00026962
Epoch [21/300], Train Loss: 0.000639
Validation Loss: 0.00026940
Epoch [22/300], Train Loss: 0.000634
Validation Loss: 0.00026806
Epoch [23/300], Train Loss: 0.000629
Validation Loss: 0.00026773
Epoch [24/300], Train Loss: 0.000623
Validation Loss: 0.00026765
Epoch [25/300], Train Loss: 0.000621
Validation Loss: 0.00026832
Epoch [26/300], Train Loss: 0.000614
Validation Loss: 0.00027012
Epoch [27/300], Train Loss: 0.000604
Validation Loss: 0.00026749
Epoch [28/300], Train Loss: 0.000568
Validation Loss: 0.00026085
Epoch [29/300], Train Loss: 0.000537
Validation Loss: 0.00025670
Epoch [30/300], Train Loss: 0.000566
Validation Loss: 0.00026071
Epoch [31/300], Train Loss: 0.000581
Validation Loss: 0.00025140
Epoch [32/300], Train Loss: 0.000544
Validation Loss: 0.00024943
Epoch [33/300], Train Loss: 0.000530
Validation Loss: 0.00025092
Epoch [34/300], Train Loss: 0.000518
Validation Loss: 0.00025791
Epoch [35/300], Train Loss: 0.000516
Validation Loss: 0.00024983
Epoch [36/300], Train Loss: 0.000508
Validation Loss: 0.00024785
Epoch [37/300], Train Loss: 0.000524
Validation Loss: 0.00025375
Epoch [38/300], Train Loss: 0.000526
Validation Loss: 0.00024801
Epoch [39/300], Train Loss: 0.000510
Validation Loss: 0.00026444
Epoch [40/300], Train Loss: 0.000540
Validation Loss: 0.00024522
Epoch [41/300], Train Loss: 0.000509
Validation Loss: 0.00024409
Epoch [42/300], Train Loss: 0.000511
Validation Loss: 0.00026028
Epoch [43/300], Train Loss: 0.000508
Validation Loss: 0.00024451
Epoch [44/300], Train Loss: 0.000500
Validation Loss: 0.00024753
Epoch [45/300], Train Loss: 0.000503
Validation Loss: 0.00024310
Epoch [46/300], Train Loss: 0.000509
Validation Loss: 0.00024396
Epoch [47/300], Train Loss: 0.000509
Validation Loss: 0.00024316
Epoch [48/300], Train Loss: 0.000504
Validation Loss: 0.00024496
Epoch [49/300], Train Loss: 0.000499
Validation Loss: 0.00024257
Epoch [50/300], Train Loss: 0.000498
Validation Loss: 0.00024727
Epoch [51/300], Train Loss: 0.000496
Validation Loss: 0.00024285
Epoch [52/300], Train Loss: 0.000498
Validation Loss: 0.00024414
Epoch [53/300], Train Loss: 0.000505
Validation Loss: 0.00024073
Epoch [54/300], Train Loss: 0.000496
Validation Loss: 0.00024873
Epoch [55/300], Train Loss: 0.000500
Validation Loss: 0.00023996
Epoch [56/300], Train Loss: 0.000502
Validation Loss: 0.00024899
Epoch [57/300], Train Loss: 0.000497
Validation Loss: 0.00024108
Epoch [58/300], Train Loss: 0.000501
Validation Loss: 0.00024536
Epoch [59/300], Train Loss: 0.000494
Validation Loss: 0.00024432
Epoch [60/300], Train Loss: 0.000497
Validation Loss: 0.00024342
Epoch [61/300], Train Loss: 0.000494
Validation Loss: 0.00024280
Epoch [62/300], Train Loss: 0.000493
Validation Loss: 0.00024073
Epoch [63/300], Train Loss: 0.000495
Validation Loss: 0.00024027
Epoch [64/300], Train Loss: 0.000501
Validation Loss: 0.00023900
Epoch [65/300], Train Loss: 0.000492
Validation Loss: 0.00024473
Epoch [66/300], Train Loss: 0.000492
Validation Loss: 0.00024034
Epoch [67/300], Train Loss: 0.000496
Validation Loss: 0.00023975
Epoch [68/300], Train Loss: 0.000492
Validation Loss: 0.00024023
Epoch [69/300], Train Loss: 0.000492
Validation Loss: 0.00024207
Epoch [70/300], Train Loss: 0.000497
Validation Loss: 0.00023936
Epoch [71/300], Train Loss: 0.000491
Validation Loss: 0.00024337
Epoch [72/300], Train Loss: 0.000492
Validation Loss: 0.00023781
Epoch [73/300], Train Loss: 0.000487
Validation Loss: 0.00024888
Epoch [74/300], Train Loss: 0.000491
Validation Loss: 0.00023868
Epoch [75/300], Train Loss: 0.000488
Validation Loss: 0.00024246
Epoch [76/300], Train Loss: 0.000488
Validation Loss: 0.00024081
Epoch [77/300], Train Loss: 0.000490
Validation Loss: 0.00023834
Epoch [78/300], Train Loss: 0.000490
Validation Loss: 0.00024001
Epoch [79/300], Train Loss: 0.000487
Validation Loss: 0.00024107
Epoch [80/300], Train Loss: 0.000488
Validation Loss: 0.00023828
Epoch [81/300], Train Loss: 0.000487
Validation Loss: 0.00024391
Epoch [82/300], Train Loss: 0.000486
Validation Loss: 0.00023632
Epoch [83/300], Train Loss: 0.000494
Validation Loss: 0.00024076
Epoch [84/300], Train Loss: 0.000493
Validation Loss: 0.00023689
Epoch [85/300], Train Loss: 0.000487
Validation Loss: 0.00023837
Epoch [86/300], Train Loss: 0.000488
Validation Loss: 0.00023635
Epoch [87/300], Train Loss: 0.000483
Validation Loss: 0.00024017
Epoch [88/300], Train Loss: 0.000491
Validation Loss: 0.00023533
Epoch [89/300], Train Loss: 0.000486
Validation Loss: 0.00024189
Epoch [90/300], Train Loss: 0.000485
Validation Loss: 0.00023699
Epoch [91/300], Train Loss: 0.000484
Validation Loss: 0.00023595
Epoch [92/300], Train Loss: 0.000484
Validation Loss: 0.00023751
Epoch [93/300], Train Loss: 0.000481
Validation Loss: 0.00023814
Epoch [94/300], Train Loss: 0.000482
Validation Loss: 0.00023543
Epoch [95/300], Train Loss: 0.000483
Validation Loss: 0.00024263
Epoch [96/300], Train Loss: 0.000484
Validation Loss: 0.00023442
Epoch [97/300], Train Loss: 0.000483
Validation Loss: 0.00023733
Epoch [98/300], Train Loss: 0.000481
Validation Loss: 0.00023914
Epoch [99/300], Train Loss: 0.000486
Validation Loss: 0.00023389
Epoch [100/300], Train Loss: 0.000478
Validation Loss: 0.00023779
Epoch [101/300], Train Loss: 0.000481
Validation Loss: 0.00023501
Epoch [102/300], Train Loss: 0.000481
Validation Loss: 0.00023970
Epoch [103/300], Train Loss: 0.000479
Validation Loss: 0.00023483
Epoch [104/300], Train Loss: 0.000481
Validation Loss: 0.00023566
Epoch [105/300], Train Loss: 0.000478
Validation Loss: 0.00023334
Epoch [106/300], Train Loss: 0.000476
Validation Loss: 0.00023313
Epoch [107/300], Train Loss: 0.000480
Validation Loss: 0.00023288
Epoch [108/300], Train Loss: 0.000479
Validation Loss: 0.00023469
Epoch [109/300], Train Loss: 0.000475
Validation Loss: 0.00023288
Epoch [110/300], Train Loss: 0.000477
Validation Loss: 0.00023209
Epoch [111/300], Train Loss: 0.000478
Validation Loss: 0.00023231
Epoch [112/300], Train Loss: 0.000476
Validation Loss: 0.00023687
Epoch [113/300], Train Loss: 0.000474
Validation Loss: 0.00023015
Epoch [114/300], Train Loss: 0.000475
Validation Loss: 0.00023294
Epoch [115/300], Train Loss: 0.000474
Validation Loss: 0.00023258
Epoch [116/300], Train Loss: 0.000478
Validation Loss: 0.00022924
Epoch [117/300], Train Loss: 0.000474
Validation Loss: 0.00023416
Epoch [118/300], Train Loss: 0.000472
Validation Loss: 0.00022878
Epoch [119/300], Train Loss: 0.000475
Validation Loss: 0.00023084
Epoch [120/300], Train Loss: 0.000474
Validation Loss: 0.00023096
Epoch [121/300], Train Loss: 0.000474
Validation Loss: 0.00023016
Epoch [122/300], Train Loss: 0.000471
Validation Loss: 0.00022907
Epoch [123/300], Train Loss: 0.000472
Validation Loss: 0.00023128
Epoch [124/300], Train Loss: 0.000469
Validation Loss: 0.00022927
Epoch [125/300], Train Loss: 0.000468
Validation Loss: 0.00022932
Epoch [126/300], Train Loss: 0.000469
Validation Loss: 0.00022863
Epoch [127/300], Train Loss: 0.000470
Validation Loss: 0.00022879
Epoch [128/300], Train Loss: 0.000472
Validation Loss: 0.00022705
Epoch [129/300], Train Loss: 0.000478
Validation Loss: 0.00022753
Epoch [130/300], Train Loss: 0.000473
Validation Loss: 0.00022670
Epoch [131/300], Train Loss: 0.000468
Validation Loss: 0.00022945
Epoch [132/300], Train Loss: 0.000463
Validation Loss: 0.00022414
Epoch [133/300], Train Loss: 0.000465
Validation Loss: 0.00022867
Epoch [134/300], Train Loss: 0.000468
Validation Loss: 0.00022450
Epoch [135/300], Train Loss: 0.000461
Validation Loss: 0.00022777
Epoch [136/300], Train Loss: 0.000463
Validation Loss: 0.00022434
Epoch [137/300], Train Loss: 0.000469
Validation Loss: 0.00022426
Epoch [138/300], Train Loss: 0.000470
Validation Loss: 0.00022276
Epoch [139/300], Train Loss: 0.000470
Validation Loss: 0.00022217
Epoch [140/300], Train Loss: 0.000472
Validation Loss: 0.00022288
Epoch [141/300], Train Loss: 0.000462
Validation Loss: 0.00022125
Epoch [142/300], Train Loss: 0.000464
Validation Loss: 0.00022442
Epoch [143/300], Train Loss: 0.000463
Validation Loss: 0.00022146
Epoch [144/300], Train Loss: 0.000463
Validation Loss: 0.00022118
Epoch [145/300], Train Loss: 0.000462
Validation Loss: 0.00022173
Epoch [146/300], Train Loss: 0.000459
Validation Loss: 0.00022292
Epoch [147/300], Train Loss: 0.000456
Validation Loss: 0.00021966
Epoch [148/300], Train Loss: 0.000463
Validation Loss: 0.00021822
Epoch [149/300], Train Loss: 0.000458
Validation Loss: 0.00021934
Epoch [150/300], Train Loss: 0.000455
Validation Loss: 0.00021919
Epoch [151/300], Train Loss: 0.000457
Validation Loss: 0.00021884
Epoch [152/300], Train Loss: 0.000457
Validation Loss: 0.00021809
Epoch [153/300], Train Loss: 0.000454
Validation Loss: 0.00021781
Epoch [154/300], Train Loss: 0.000455
Validation Loss: 0.00021824
Epoch [155/300], Train Loss: 0.000454
Validation Loss: 0.00021755
Epoch [156/300], Train Loss: 0.000457
Validation Loss: 0.00021618
Epoch [157/300], Train Loss: 0.000463
Validation Loss: 0.00021349
Epoch [158/300], Train Loss: 0.000453
Validation Loss: 0.00021688
Epoch [159/300], Train Loss: 0.000451
Validation Loss: 0.00021560
Epoch [160/300], Train Loss: 0.000461
Validation Loss: 0.00021352
Epoch [161/300], Train Loss: 0.000456
Validation Loss: 0.00021438
Epoch [162/300], Train Loss: 0.000450
Validation Loss: 0.00021176
Epoch [163/300], Train Loss: 0.000455
Validation Loss: 0.00021062
Epoch [164/300], Train Loss: 0.000451
Validation Loss: 0.00021013
Epoch [165/300], Train Loss: 0.000451
Validation Loss: 0.00020998
Epoch [166/300], Train Loss: 0.000453
Validation Loss: 0.00020927
Epoch [167/300], Train Loss: 0.000448
Validation Loss: 0.00021005
Epoch [168/300], Train Loss: 0.000447
Validation Loss: 0.00020971
Epoch [169/300], Train Loss: 0.000447
Validation Loss: 0.00020861
Epoch [170/300], Train Loss: 0.000448
Validation Loss: 0.00020648
Epoch [171/300], Train Loss: 0.000449
Validation Loss: 0.00020704
Epoch [172/300], Train Loss: 0.000446
Validation Loss: 0.00020658
Epoch [173/300], Train Loss: 0.000442
Validation Loss: 0.00020573
Epoch [174/300], Train Loss: 0.000444
Validation Loss: 0.00020490
Epoch [175/300], Train Loss: 0.000443
Validation Loss: 0.00020431
Epoch [176/300], Train Loss: 0.000444
Validation Loss: 0.00020451
Epoch [177/300], Train Loss: 0.000447
Validation Loss: 0.00020284
Epoch [178/300], Train Loss: 0.000448
Validation Loss: 0.00020319
Epoch [179/300], Train Loss: 0.000444
Validation Loss: 0.00020047
Epoch [180/300], Train Loss: 0.000442
Validation Loss: 0.00020222
Epoch [181/300], Train Loss: 0.000443
Validation Loss: 0.00020091
Epoch [182/300], Train Loss: 0.000437
Validation Loss: 0.00020198
Epoch [183/300], Train Loss: 0.000441
Validation Loss: 0.00020055
Epoch [184/300], Train Loss: 0.000438
Validation Loss: 0.00019938
Epoch [185/300], Train Loss: 0.000447
Validation Loss: 0.00019886
Epoch [186/300], Train Loss: 0.000439
Validation Loss: 0.00019991
Epoch [187/300], Train Loss: 0.000437
Validation Loss: 0.00019826
Epoch [188/300], Train Loss: 0.000438
Validation Loss: 0.00019966
Epoch [189/300], Train Loss: 0.000434
Validation Loss: 0.00019893
Epoch [190/300], Train Loss: 0.000438
Validation Loss: 0.00019742
Epoch [191/300], Train Loss: 0.000435
Validation Loss: 0.00019836
Epoch [192/300], Train Loss: 0.000434
Validation Loss: 0.00019535
Epoch [193/300], Train Loss: 0.000434
Validation Loss: 0.00019731
Epoch [194/300], Train Loss: 0.000437
Validation Loss: 0.00019725
Epoch [195/300], Train Loss: 0.000433
Validation Loss: 0.00019583
Epoch [196/300], Train Loss: 0.000432
Validation Loss: 0.00019495
Epoch [197/300], Train Loss: 0.000431
Validation Loss: 0.00019440
Epoch [198/300], Train Loss: 0.000433
Validation Loss: 0.00019468
Epoch [199/300], Train Loss: 0.000433
Validation Loss: 0.00019393
Epoch [200/300], Train Loss: 0.000430
Validation Loss: 0.00019162
Epoch [201/300], Train Loss: 0.000430
Validation Loss: 0.00019450
Epoch [202/300], Train Loss: 0.000431
Validation Loss: 0.00019258
Epoch [203/300], Train Loss: 0.000430
Validation Loss: 0.00019330
Epoch [204/300], Train Loss: 0.000433
Validation Loss: 0.00019414
Epoch [205/300], Train Loss: 0.000437
Validation Loss: 0.00019004
Epoch [206/300], Train Loss: 0.000435
Validation Loss: 0.00019378
Epoch [207/300], Train Loss: 0.000432
Validation Loss: 0.00018992
Epoch [208/300], Train Loss: 0.000430
Validation Loss: 0.00019096
Epoch [209/300], Train Loss: 0.000426
Validation Loss: 0.00019121
Epoch [210/300], Train Loss: 0.000429
Validation Loss: 0.00018910
Epoch [211/300], Train Loss: 0.000435
Validation Loss: 0.00018958
Epoch [212/300], Train Loss: 0.000428
Validation Loss: 0.00019197
Epoch [213/300], Train Loss: 0.000428
Validation Loss: 0.00018965
Epoch [214/300], Train Loss: 0.000429
Validation Loss: 0.00019106
Epoch [215/300], Train Loss: 0.000427
Validation Loss: 0.00018867
Epoch [216/300], Train Loss: 0.000424
Validation Loss: 0.00018899
Epoch [217/300], Train Loss: 0.000427
Validation Loss: 0.00018860
Epoch [218/300], Train Loss: 0.000427
Validation Loss: 0.00018931
Epoch [219/300], Train Loss: 0.000425
Validation Loss: 0.00018818
Epoch [220/300], Train Loss: 0.000423
Validation Loss: 0.00018655
Epoch [221/300], Train Loss: 0.000424
Validation Loss: 0.00018783
Epoch [222/300], Train Loss: 0.000422
Validation Loss: 0.00018941
Epoch [223/300], Train Loss: 0.000420
Validation Loss: 0.00018537
Epoch [224/300], Train Loss: 0.000429
Validation Loss: 0.00018826
Epoch [225/300], Train Loss: 0.000420
Validation Loss: 0.00018600
Epoch [226/300], Train Loss: 0.000423
Validation Loss: 0.00018867
Epoch [227/300], Train Loss: 0.000424
Validation Loss: 0.00018560
Epoch [228/300], Train Loss: 0.000423
Validation Loss: 0.00018633
Epoch [229/300], Train Loss: 0.000421
Validation Loss: 0.00018638
Epoch [230/300], Train Loss: 0.000420
Validation Loss: 0.00018560
Epoch [231/300], Train Loss: 0.000421
Validation Loss: 0.00018573
Epoch [232/300], Train Loss: 0.000422
Validation Loss: 0.00018670
Epoch [233/300], Train Loss: 0.000422
Validation Loss: 0.00018323
Epoch [234/300], Train Loss: 0.000418
Validation Loss: 0.00018695
Epoch [235/300], Train Loss: 0.000422
Validation Loss: 0.00018591
Epoch [236/300], Train Loss: 0.000419
Validation Loss: 0.00018544
Epoch [237/300], Train Loss: 0.000419
Validation Loss: 0.00018438
Epoch [238/300], Train Loss: 0.000421
Validation Loss: 0.00018593
Epoch [239/300], Train Loss: 0.000417
Validation Loss: 0.00018359
Epoch [240/300], Train Loss: 0.000418
Validation Loss: 0.00018300
Epoch [241/300], Train Loss: 0.000419
Validation Loss: 0.00018555
Epoch [242/300], Train Loss: 0.000421
Validation Loss: 0.00018293
Epoch [243/300], Train Loss: 0.000418
Validation Loss: 0.00018389
Epoch [244/300], Train Loss: 0.000416
Validation Loss: 0.00018468
Epoch [245/300], Train Loss: 0.000416
Validation Loss: 0.00018362
Epoch [246/300], Train Loss: 0.000418
Validation Loss: 0.00018281
Epoch [247/300], Train Loss: 0.000416
Validation Loss: 0.00018315
Epoch [248/300], Train Loss: 0.000418
Validation Loss: 0.00018249
Epoch [249/300], Train Loss: 0.000424
Validation Loss: 0.00018257
Epoch [250/300], Train Loss: 0.000421
Validation Loss: 0.00018273
Epoch [251/300], Train Loss: 0.000419
Validation Loss: 0.00018292
Epoch [252/300], Train Loss: 0.000416
Validation Loss: 0.00018244
Epoch [253/300], Train Loss: 0.000416
Validation Loss: 0.00018193
Epoch [254/300], Train Loss: 0.000422
Validation Loss: 0.00018185
Epoch [255/300], Train Loss: 0.000416
Validation Loss: 0.00018128
Epoch [256/300], Train Loss: 0.000414
Validation Loss: 0.00018119
Epoch [257/300], Train Loss: 0.000414
Validation Loss: 0.00018161
Epoch [258/300], Train Loss: 0.000415
Validation Loss: 0.00018093
Epoch [259/300], Train Loss: 0.000413
Validation Loss: 0.00018197
Epoch [260/300], Train Loss: 0.000413
Validation Loss: 0.00018105
Epoch [261/300], Train Loss: 0.000417
Validation Loss: 0.00018209
Epoch [262/300], Train Loss: 0.000417
Validation Loss: 0.00018064
Epoch [263/300], Train Loss: 0.000413
Validation Loss: 0.00018078
Epoch [264/300], Train Loss: 0.000414
Validation Loss: 0.00018078
Epoch [265/300], Train Loss: 0.000415
Validation Loss: 0.00018115
Epoch [266/300], Train Loss: 0.000414
Validation Loss: 0.00018084
Epoch [267/300], Train Loss: 0.000413
Validation Loss: 0.00018042
Epoch [268/300], Train Loss: 0.000412
Validation Loss: 0.00018053
Epoch [269/300], Train Loss: 0.000409
Validation Loss: 0.00018042
Epoch [270/300], Train Loss: 0.000414
Validation Loss: 0.00018034
Epoch [271/300], Train Loss: 0.000412
Validation Loss: 0.00017998
Epoch [272/300], Train Loss: 0.000412
Validation Loss: 0.00018042
Epoch [273/300], Train Loss: 0.000413
Validation Loss: 0.00017951
Epoch [274/300], Train Loss: 0.000412
Validation Loss: 0.00017980
Epoch [275/300], Train Loss: 0.000410
Validation Loss: 0.00018056
Epoch [276/300], Train Loss: 0.000410
Validation Loss: 0.00017993
Epoch [277/300], Train Loss: 0.000411
Validation Loss: 0.00017961
Epoch [278/300], Train Loss: 0.000410
Validation Loss: 0.00017916
Epoch [279/300], Train Loss: 0.000414
Validation Loss: 0.00018047
Epoch [280/300], Train Loss: 0.000429
Validation Loss: 0.00017651
Epoch [281/300], Train Loss: 0.000417
Validation Loss: 0.00017864
Epoch [282/300], Train Loss: 0.000409
Validation Loss: 0.00018077
Epoch [283/300], Train Loss: 0.000413
Validation Loss: 0.00018031
Epoch [284/300], Train Loss: 0.000412
Validation Loss: 0.00017809
Epoch [285/300], Train Loss: 0.000412
Validation Loss: 0.00018053
Epoch [286/300], Train Loss: 0.000411
Validation Loss: 0.00017892
Epoch [287/300], Train Loss: 0.000413
Validation Loss: 0.00017749
Epoch [288/300], Train Loss: 0.000410
Validation Loss: 0.00017975
Epoch [289/300], Train Loss: 0.000407
Validation Loss: 0.00017852
Epoch [290/300], Train Loss: 0.000407
Validation Loss: 0.00017918
Early stopping triggered

Evaluating model for: Microwave
Run 45/72 completed in 1112.64 seconds with: {'MAE': np.float32(11.872016), 'MSE': np.float32(8459.837), 'RMSE': np.float32(91.97737), 'SAE': np.float32(0.10558635), 'NDE': np.float32(0.7509916)}

Run 46/72: hidden=256, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Microwave
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.000810
Validation Loss: 0.00035168
Epoch [2/300], Train Loss: 0.000691
Validation Loss: 0.00028565
Epoch [3/300], Train Loss: 0.000677
Validation Loss: 0.00028161
Epoch [4/300], Train Loss: 0.000674
Validation Loss: 0.00027756
Epoch [5/300], Train Loss: 0.000675
Validation Loss: 0.00027785
Epoch [6/300], Train Loss: 0.000671
Validation Loss: 0.00027788
Epoch [7/300], Train Loss: 0.000668
Validation Loss: 0.00027765
Epoch [8/300], Train Loss: 0.000667
Validation Loss: 0.00027741
Epoch [9/300], Train Loss: 0.000669
Validation Loss: 0.00027835
Epoch [10/300], Train Loss: 0.000667
Validation Loss: 0.00027699
Epoch [11/300], Train Loss: 0.000666
Validation Loss: 0.00027756
Epoch [12/300], Train Loss: 0.000666
Validation Loss: 0.00027711
Epoch [13/300], Train Loss: 0.000668
Validation Loss: 0.00027655
Epoch [14/300], Train Loss: 0.000666
Validation Loss: 0.00027631
Epoch [15/300], Train Loss: 0.000666
Validation Loss: 0.00027779
Epoch [16/300], Train Loss: 0.000661
Validation Loss: 0.00027741
Epoch [17/300], Train Loss: 0.000661
Validation Loss: 0.00027630
Epoch [18/300], Train Loss: 0.000656
Validation Loss: 0.00027562
Epoch [19/300], Train Loss: 0.000655
Validation Loss: 0.00027716
Epoch [20/300], Train Loss: 0.000655
Validation Loss: 0.00027676
Epoch [21/300], Train Loss: 0.000653
Validation Loss: 0.00027669
Epoch [22/300], Train Loss: 0.000650
Validation Loss: 0.00027651
Epoch [23/300], Train Loss: 0.000649
Validation Loss: 0.00027623
Epoch [24/300], Train Loss: 0.000644
Validation Loss: 0.00027567
Epoch [25/300], Train Loss: 0.000644
Validation Loss: 0.00027592
Epoch [26/300], Train Loss: 0.000641
Validation Loss: 0.00027655
Epoch [27/300], Train Loss: 0.000638
Validation Loss: 0.00027440
Epoch [28/300], Train Loss: 0.000627
Validation Loss: 0.00027282
Epoch [29/300], Train Loss: 0.000619
Validation Loss: 0.00027068
Epoch [30/300], Train Loss: 0.000594
Validation Loss: 0.00026451
Epoch [31/300], Train Loss: 0.000559
Validation Loss: 0.00026090
Epoch [32/300], Train Loss: 0.000544
Validation Loss: 0.00026162
Epoch [33/300], Train Loss: 0.000527
Validation Loss: 0.00025591
Epoch [34/300], Train Loss: 0.000527
Validation Loss: 0.00025586
Epoch [35/300], Train Loss: 0.000521
Validation Loss: 0.00025697
Epoch [36/300], Train Loss: 0.000511
Validation Loss: 0.00025126
Epoch [37/300], Train Loss: 0.000517
Validation Loss: 0.00028345
Epoch [38/300], Train Loss: 0.000538
Validation Loss: 0.00025175
Epoch [39/300], Train Loss: 0.000507
Validation Loss: 0.00026009
Epoch [40/300], Train Loss: 0.000554
Validation Loss: 0.00024836
Epoch [41/300], Train Loss: 0.000519
Validation Loss: 0.00024897
Epoch [42/300], Train Loss: 0.000517
Validation Loss: 0.00026176
Epoch [43/300], Train Loss: 0.000510
Validation Loss: 0.00024820
Epoch [44/300], Train Loss: 0.000502
Validation Loss: 0.00025192
Epoch [45/300], Train Loss: 0.000504
Validation Loss: 0.00024639
Epoch [46/300], Train Loss: 0.000511
Validation Loss: 0.00024664
Epoch [47/300], Train Loss: 0.000511
Validation Loss: 0.00024635
Epoch [48/300], Train Loss: 0.000503
Validation Loss: 0.00024674
Epoch [49/300], Train Loss: 0.000499
Validation Loss: 0.00024632
Epoch [50/300], Train Loss: 0.000498
Validation Loss: 0.00024920
Epoch [51/300], Train Loss: 0.000496
Validation Loss: 0.00024529
Epoch [52/300], Train Loss: 0.000499
Validation Loss: 0.00024734
Epoch [53/300], Train Loss: 0.000499
Validation Loss: 0.00024493
Epoch [54/300], Train Loss: 0.000495
Validation Loss: 0.00024836
Epoch [55/300], Train Loss: 0.000501
Validation Loss: 0.00024251
Epoch [56/300], Train Loss: 0.000503
Validation Loss: 0.00025007
Epoch [57/300], Train Loss: 0.000496
Validation Loss: 0.00024488
Epoch [58/300], Train Loss: 0.000499
Validation Loss: 0.00024779
Epoch [59/300], Train Loss: 0.000491
Validation Loss: 0.00024824
Epoch [60/300], Train Loss: 0.000494
Validation Loss: 0.00024489
Epoch [61/300], Train Loss: 0.000487
Validation Loss: 0.00024745
Epoch [62/300], Train Loss: 0.000485
Validation Loss: 0.00024345
Epoch [63/300], Train Loss: 0.000485
Validation Loss: 0.00024586
Epoch [64/300], Train Loss: 0.000482
Validation Loss: 0.00024397
Epoch [65/300], Train Loss: 0.000475
Validation Loss: 0.00024965
Early stopping triggered

Evaluating model for: Microwave
Run 46/72 completed in 316.15 seconds with: {'MAE': np.float32(13.46085), 'MSE': np.float32(10250.791), 'RMSE': np.float32(101.24619), 'SAE': np.float32(0.04934443), 'NDE': np.float32(0.82667214)}

Run 47/72: hidden=256, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Microwave
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.000935
Validation Loss: 0.00034180
Epoch [2/300], Train Loss: 0.000704
Validation Loss: 0.00027809
Epoch [3/300], Train Loss: 0.000677
Validation Loss: 0.00027760
Epoch [4/300], Train Loss: 0.000672
Validation Loss: 0.00028004
Epoch [5/300], Train Loss: 0.000672
Validation Loss: 0.00027749
Epoch [6/300], Train Loss: 0.000669
Validation Loss: 0.00027862
Epoch [7/300], Train Loss: 0.000667
Validation Loss: 0.00027759
Epoch [8/300], Train Loss: 0.000666
Validation Loss: 0.00027765
Epoch [9/300], Train Loss: 0.000668
Validation Loss: 0.00027788
Epoch [10/300], Train Loss: 0.000667
Validation Loss: 0.00027725
Epoch [11/300], Train Loss: 0.000666
Validation Loss: 0.00027750
Epoch [12/300], Train Loss: 0.000666
Validation Loss: 0.00027716
Epoch [13/300], Train Loss: 0.000669
Validation Loss: 0.00027686
Epoch [14/300], Train Loss: 0.000667
Validation Loss: 0.00027657
Epoch [15/300], Train Loss: 0.000667
Validation Loss: 0.00027766
Epoch [16/300], Train Loss: 0.000662
Validation Loss: 0.00027638
Epoch [17/300], Train Loss: 0.000663
Validation Loss: 0.00027550
Epoch [18/300], Train Loss: 0.000659
Validation Loss: 0.00027447
Epoch [19/300], Train Loss: 0.000656
Validation Loss: 0.00027575
Epoch [20/300], Train Loss: 0.000655
Validation Loss: 0.00027488
Epoch [21/300], Train Loss: 0.000652
Validation Loss: 0.00027519
Epoch [22/300], Train Loss: 0.000650
Validation Loss: 0.00027574
Epoch [23/300], Train Loss: 0.000647
Validation Loss: 0.00027482
Epoch [24/300], Train Loss: 0.000644
Validation Loss: 0.00027498
Epoch [25/300], Train Loss: 0.000645
Validation Loss: 0.00027429
Epoch [26/300], Train Loss: 0.000643
Validation Loss: 0.00027592
Epoch [27/300], Train Loss: 0.000641
Validation Loss: 0.00027380
Epoch [28/300], Train Loss: 0.000633
Validation Loss: 0.00027234
Epoch [29/300], Train Loss: 0.000630
Validation Loss: 0.00027027
Epoch [30/300], Train Loss: 0.000623
Validation Loss: 0.00026712
Epoch [31/300], Train Loss: 0.000614
Validation Loss: 0.00026437
Epoch [32/300], Train Loss: 0.000600
Validation Loss: 0.00026229
Epoch [33/300], Train Loss: 0.000588
Validation Loss: 0.00026103
Epoch [34/300], Train Loss: 0.000570
Validation Loss: 0.00026060
Epoch [35/300], Train Loss: 0.000559
Validation Loss: 0.00026464
Epoch [36/300], Train Loss: 0.000537
Validation Loss: 0.00026057
Epoch [37/300], Train Loss: 0.000534
Validation Loss: 0.00029125
Epoch [38/300], Train Loss: 0.000558
Validation Loss: 0.00026020
Epoch [39/300], Train Loss: 0.000524
Validation Loss: 0.00026794
Epoch [40/300], Train Loss: 0.000589
Validation Loss: 0.00025665
Epoch [41/300], Train Loss: 0.000547
Validation Loss: 0.00025945
Epoch [42/300], Train Loss: 0.000531
Validation Loss: 0.00027205
Epoch [43/300], Train Loss: 0.000520
Validation Loss: 0.00025864
Epoch [44/300], Train Loss: 0.000511
Validation Loss: 0.00026584
Epoch [45/300], Train Loss: 0.000514
Validation Loss: 0.00025621
Epoch [46/300], Train Loss: 0.000522
Validation Loss: 0.00025790
Epoch [47/300], Train Loss: 0.000523
Validation Loss: 0.00025631
Epoch [48/300], Train Loss: 0.000513
Validation Loss: 0.00025794
Epoch [49/300], Train Loss: 0.000511
Validation Loss: 0.00025953
Epoch [50/300], Train Loss: 0.000510
Validation Loss: 0.00026125
Epoch [51/300], Train Loss: 0.000506
Validation Loss: 0.00025674
Epoch [52/300], Train Loss: 0.000509
Validation Loss: 0.00026090
Epoch [53/300], Train Loss: 0.000508
Validation Loss: 0.00025806
Epoch [54/300], Train Loss: 0.000508
Validation Loss: 0.00026054
Epoch [55/300], Train Loss: 0.000511
Validation Loss: 0.00025151
Epoch [56/300], Train Loss: 0.000519
Validation Loss: 0.00025760
Epoch [57/300], Train Loss: 0.000510
Validation Loss: 0.00025447
Epoch [58/300], Train Loss: 0.000509
Validation Loss: 0.00025779
Epoch [59/300], Train Loss: 0.000503
Validation Loss: 0.00026128
Epoch [60/300], Train Loss: 0.000507
Validation Loss: 0.00025577
Epoch [61/300], Train Loss: 0.000500
Validation Loss: 0.00025902
Epoch [62/300], Train Loss: 0.000500
Validation Loss: 0.00025328
Epoch [63/300], Train Loss: 0.000502
Validation Loss: 0.00025526
Epoch [64/300], Train Loss: 0.000502
Validation Loss: 0.00025167
Epoch [65/300], Train Loss: 0.000495
Validation Loss: 0.00026059
Early stopping triggered

Evaluating model for: Microwave
Run 47/72 completed in 377.26 seconds with: {'MAE': np.float32(12.95393), 'MSE': np.float32(10487.661), 'RMSE': np.float32(102.40928), 'SAE': np.float32(0.088099316), 'NDE': np.float32(0.8361691)}

Run 48/72: hidden=256, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Microwave
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.000668
Validation Loss: 0.00027734
Epoch [2/300], Train Loss: 0.000668
Validation Loss: 0.00027590
Epoch [3/300], Train Loss: 0.000666
Validation Loss: 0.00027883
Epoch [4/300], Train Loss: 0.000666
Validation Loss: 0.00027641
Epoch [5/300], Train Loss: 0.000668
Validation Loss: 0.00027572
Epoch [6/300], Train Loss: 0.000665
Validation Loss: 0.00027870
Epoch [7/300], Train Loss: 0.000662
Validation Loss: 0.00027876
Epoch [8/300], Train Loss: 0.000660
Validation Loss: 0.00027571
Epoch [9/300], Train Loss: 0.000661
Validation Loss: 0.00027435
Epoch [10/300], Train Loss: 0.000658
Validation Loss: 0.00027464
Epoch [11/300], Train Loss: 0.000651
Validation Loss: 0.00027374
Epoch [12/300], Train Loss: 0.000644
Validation Loss: 0.00027626
Epoch [13/300], Train Loss: 0.000640
Validation Loss: 0.00027724
Epoch [14/300], Train Loss: 0.000632
Validation Loss: 0.00026750
Epoch [15/300], Train Loss: 0.000615
Validation Loss: 0.00026203
Epoch [16/300], Train Loss: 0.000595
Validation Loss: 0.00025603
Epoch [17/300], Train Loss: 0.000571
Validation Loss: 0.00025990
Epoch [18/300], Train Loss: 0.000540
Validation Loss: 0.00025015
Epoch [19/300], Train Loss: 0.000532
Validation Loss: 0.00027674
Epoch [20/300], Train Loss: 0.000545
Validation Loss: 0.00024973
Epoch [21/300], Train Loss: 0.000532
Validation Loss: 0.00024607
Epoch [22/300], Train Loss: 0.000533
Validation Loss: 0.00025173
Epoch [23/300], Train Loss: 0.000550
Validation Loss: 0.00025532
Epoch [24/300], Train Loss: 0.000531
Validation Loss: 0.00025713
Epoch [25/300], Train Loss: 0.000535
Validation Loss: 0.00024867
Epoch [26/300], Train Loss: 0.000531
Validation Loss: 0.00025342
Epoch [27/300], Train Loss: 0.000537
Validation Loss: 0.00026213
Epoch [28/300], Train Loss: 0.000520
Validation Loss: 0.00025689
Epoch [29/300], Train Loss: 0.000519
Validation Loss: 0.00025199
Epoch [30/300], Train Loss: 0.000525
Validation Loss: 0.00025430
Epoch [31/300], Train Loss: 0.000519
Validation Loss: 0.00025254
Early stopping triggered

Evaluating model for: Microwave
Run 48/72 completed in 245.23 seconds with: {'MAE': np.float32(12.365145), 'MSE': np.float32(11061.572), 'RMSE': np.float32(105.17401), 'SAE': np.float32(0.1663059), 'NDE': np.float32(0.85874087)}

Run 49/72: hidden=512, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Microwave
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.000635
Validation Loss: 0.00055260
Epoch [2/300], Train Loss: 0.000598
Validation Loss: 0.00051237
Epoch [3/300], Train Loss: 0.000638
Validation Loss: 0.00052115
Epoch [4/300], Train Loss: 0.000545
Validation Loss: 0.00049497
Epoch [5/300], Train Loss: 0.000515
Validation Loss: 0.00050337
Epoch [6/300], Train Loss: 0.000498
Validation Loss: 0.00049200
Epoch [7/300], Train Loss: 0.000499
Validation Loss: 0.00051463
Epoch [8/300], Train Loss: 0.000497
Validation Loss: 0.00050566
Epoch [9/300], Train Loss: 0.000481
Validation Loss: 0.00051190
Epoch [10/300], Train Loss: 0.000478
Validation Loss: 0.00052118
Epoch [11/300], Train Loss: 0.000479
Validation Loss: 0.00050282
Epoch [12/300], Train Loss: 0.000463
Validation Loss: 0.00049338
Epoch [13/300], Train Loss: 0.000437
Validation Loss: 0.00049053
Epoch [14/300], Train Loss: 0.000446
Validation Loss: 0.00049197
Epoch [15/300], Train Loss: 0.000424
Validation Loss: 0.00049265
Epoch [16/300], Train Loss: 0.000428
Validation Loss: 0.00045682
Epoch [17/300], Train Loss: 0.000401
Validation Loss: 0.00047233
Epoch [18/300], Train Loss: 0.000395
Validation Loss: 0.00046164
Epoch [19/300], Train Loss: 0.000379
Validation Loss: 0.00046044
Epoch [20/300], Train Loss: 0.000385
Validation Loss: 0.00052044
Epoch [21/300], Train Loss: 0.000371
Validation Loss: 0.00046132
Epoch [22/300], Train Loss: 0.000364
Validation Loss: 0.00048818
Epoch [23/300], Train Loss: 0.000364
Validation Loss: 0.00042251
Epoch [24/300], Train Loss: 0.000362
Validation Loss: 0.00046030
Epoch [25/300], Train Loss: 0.000348
Validation Loss: 0.00047823
Epoch [26/300], Train Loss: 0.000338
Validation Loss: 0.00040957
Epoch [27/300], Train Loss: 0.000333
Validation Loss: 0.00041800
Epoch [28/300], Train Loss: 0.000339
Validation Loss: 0.00040966
Epoch [29/300], Train Loss: 0.000350
Validation Loss: 0.00040440
Epoch [30/300], Train Loss: 0.000331
Validation Loss: 0.00040748
Epoch [31/300], Train Loss: 0.000322
Validation Loss: 0.00037659
Epoch [32/300], Train Loss: 0.000332
Validation Loss: 0.00039362
Epoch [33/300], Train Loss: 0.000314
Validation Loss: 0.00042162
Epoch [34/300], Train Loss: 0.000321
Validation Loss: 0.00041422
Epoch [35/300], Train Loss: 0.000320
Validation Loss: 0.00038085
Epoch [36/300], Train Loss: 0.000319
Validation Loss: 0.00039236
Epoch [37/300], Train Loss: 0.000297
Validation Loss: 0.00038334
Epoch [38/300], Train Loss: 0.000300
Validation Loss: 0.00041025
Epoch [39/300], Train Loss: 0.000359
Validation Loss: 0.00041632
Epoch [40/300], Train Loss: 0.000310
Validation Loss: 0.00042104
Epoch [41/300], Train Loss: 0.000293
Validation Loss: 0.00041271
Early stopping triggered

Evaluating model for: Microwave
Run 49/72 completed in 1283.01 seconds with: {'MAE': np.float32(6.8780427), 'MSE': np.float32(5516.6865), 'RMSE': np.float32(74.2744), 'SAE': np.float32(0.15517476), 'NDE': np.float32(0.64510226)}

Run 50/72: hidden=512, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Microwave
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.000640
Validation Loss: 0.00055725
Epoch [2/300], Train Loss: 0.000614
Validation Loss: 0.00053138
Epoch [3/300], Train Loss: 0.000597
Validation Loss: 0.00054208
Epoch [4/300], Train Loss: 0.000573
Validation Loss: 0.00050819
Epoch [5/300], Train Loss: 0.000524
Validation Loss: 0.00051878
Epoch [6/300], Train Loss: 0.000507
Validation Loss: 0.00048981
Epoch [7/300], Train Loss: 0.000509
Validation Loss: 0.00051081
Epoch [8/300], Train Loss: 0.000507
Validation Loss: 0.00050852
Epoch [9/300], Train Loss: 0.000494
Validation Loss: 0.00049185
Epoch [10/300], Train Loss: 0.000492
Validation Loss: 0.00052448
Epoch [11/300], Train Loss: 0.000503
Validation Loss: 0.00048648
Epoch [12/300], Train Loss: 0.000488
Validation Loss: 0.00050114
Epoch [13/300], Train Loss: 0.000472
Validation Loss: 0.00050595
Epoch [14/300], Train Loss: 0.000482
Validation Loss: 0.00050260
Epoch [15/300], Train Loss: 0.000471
Validation Loss: 0.00048259
Epoch [16/300], Train Loss: 0.000464
Validation Loss: 0.00047720
Epoch [17/300], Train Loss: 0.000458
Validation Loss: 0.00047823
Epoch [18/300], Train Loss: 0.000453
Validation Loss: 0.00049290
Epoch [19/300], Train Loss: 0.000457
Validation Loss: 0.00046734
Epoch [20/300], Train Loss: 0.000440
Validation Loss: 0.00050926
Epoch [21/300], Train Loss: 0.000433
Validation Loss: 0.00047098
Epoch [22/300], Train Loss: 0.000428
Validation Loss: 0.00059450
Epoch [23/300], Train Loss: 0.000423
Validation Loss: 0.00045443
Epoch [24/300], Train Loss: 0.000430
Validation Loss: 0.00049241
Epoch [25/300], Train Loss: 0.000411
Validation Loss: 0.00050845
Epoch [26/300], Train Loss: 0.000401
Validation Loss: 0.00043877
Epoch [27/300], Train Loss: 0.000392
Validation Loss: 0.00044395
Epoch [28/300], Train Loss: 0.000404
Validation Loss: 0.00042609
Epoch [29/300], Train Loss: 0.000393
Validation Loss: 0.00044694
Epoch [30/300], Train Loss: 0.000382
Validation Loss: 0.00045037
Epoch [31/300], Train Loss: 0.000365
Validation Loss: 0.00041383
Epoch [32/300], Train Loss: 0.000373
Validation Loss: 0.00043224
Epoch [33/300], Train Loss: 0.000353
Validation Loss: 0.00043879
Epoch [34/300], Train Loss: 0.000369
Validation Loss: 0.00045589
Epoch [35/300], Train Loss: 0.000416
Validation Loss: 0.00040550
Epoch [36/300], Train Loss: 0.000351
Validation Loss: 0.00044725
Epoch [37/300], Train Loss: 0.000349
Validation Loss: 0.00040540
Epoch [38/300], Train Loss: 0.000344
Validation Loss: 0.00044274
Epoch [39/300], Train Loss: 0.000336
Validation Loss: 0.00042827
Epoch [40/300], Train Loss: 0.000336
Validation Loss: 0.00043274
Epoch [41/300], Train Loss: 0.000336
Validation Loss: 0.00043355
Epoch [42/300], Train Loss: 0.000340
Validation Loss: 0.00045079
Epoch [43/300], Train Loss: 0.000334
Validation Loss: 0.00038774
Epoch [44/300], Train Loss: 0.000325
Validation Loss: 0.00040540
Epoch [45/300], Train Loss: 0.000320
Validation Loss: 0.00040855
Epoch [46/300], Train Loss: 0.000315
Validation Loss: 0.00043050
Epoch [47/300], Train Loss: 0.000335
Validation Loss: 0.00037833
Epoch [48/300], Train Loss: 0.000316
Validation Loss: 0.00039475
Epoch [49/300], Train Loss: 0.000318
Validation Loss: 0.00039675
Epoch [50/300], Train Loss: 0.000306
Validation Loss: 0.00039543
Epoch [51/300], Train Loss: 0.000333
Validation Loss: 0.00041576
Epoch [52/300], Train Loss: 0.000317
Validation Loss: 0.00041696
Epoch [53/300], Train Loss: 0.000305
Validation Loss: 0.00038733
Epoch [54/300], Train Loss: 0.000308
Validation Loss: 0.00039951
Epoch [55/300], Train Loss: 0.000302
Validation Loss: 0.00041732
Epoch [56/300], Train Loss: 0.000292
Validation Loss: 0.00038478
Epoch [57/300], Train Loss: 0.000288
Validation Loss: 0.00041371
Early stopping triggered

Evaluating model for: Microwave
Run 50/72 completed in 1975.08 seconds with: {'MAE': np.float32(7.6401067), 'MSE': np.float32(5439.5176), 'RMSE': np.float32(73.75308), 'SAE': np.float32(0.025923897), 'NDE': np.float32(0.6405726)}

Run 51/72: hidden=512, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Microwave
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.000636
Validation Loss: 0.00056035
Epoch [2/300], Train Loss: 0.000607
Validation Loss: 0.00053856
Epoch [3/300], Train Loss: 0.000561
Validation Loss: 0.00049478
Epoch [4/300], Train Loss: 0.000522
Validation Loss: 0.00051061
Epoch [5/300], Train Loss: 0.000517
Validation Loss: 0.00050713
Epoch [6/300], Train Loss: 0.000495
Validation Loss: 0.00048726
Epoch [7/300], Train Loss: 0.000504
Validation Loss: 0.00051964
Epoch [8/300], Train Loss: 0.000494
Validation Loss: 0.00049819
Epoch [9/300], Train Loss: 0.000481
Validation Loss: 0.00049090
Epoch [10/300], Train Loss: 0.000483
Validation Loss: 0.00052040
Epoch [11/300], Train Loss: 0.000501
Validation Loss: 0.00046962
Epoch [12/300], Train Loss: 0.000481
Validation Loss: 0.00046398
Epoch [13/300], Train Loss: 0.000475
Validation Loss: 0.00048091
Epoch [14/300], Train Loss: 0.000467
Validation Loss: 0.00052025
Epoch [15/300], Train Loss: 0.000448
Validation Loss: 0.00051055
Epoch [16/300], Train Loss: 0.000476
Validation Loss: 0.00055803
Epoch [17/300], Train Loss: 0.000427
Validation Loss: 0.00044250
Epoch [18/300], Train Loss: 0.000430
Validation Loss: 0.00048316
Epoch [19/300], Train Loss: 0.000418
Validation Loss: 0.00045482
Epoch [20/300], Train Loss: 0.000403
Validation Loss: 0.00054537
Epoch [21/300], Train Loss: 0.000396
Validation Loss: 0.00046633
Epoch [22/300], Train Loss: 0.000392
Validation Loss: 0.00058808
Epoch [23/300], Train Loss: 0.000381
Validation Loss: 0.00045067
Epoch [24/300], Train Loss: 0.000388
Validation Loss: 0.00051375
Epoch [25/300], Train Loss: 0.000376
Validation Loss: 0.00049635
Epoch [26/300], Train Loss: 0.000360
Validation Loss: 0.00042837
Epoch [27/300], Train Loss: 0.000351
Validation Loss: 0.00045411
Epoch [28/300], Train Loss: 0.000370
Validation Loss: 0.00044381
Epoch [29/300], Train Loss: 0.000401
Validation Loss: 0.00047456
Epoch [30/300], Train Loss: 0.000354
Validation Loss: 0.00045035
Epoch [31/300], Train Loss: 0.000341
Validation Loss: 0.00038888
Epoch [32/300], Train Loss: 0.000348
Validation Loss: 0.00040702
Epoch [33/300], Train Loss: 0.000327
Validation Loss: 0.00043692
Epoch [34/300], Train Loss: 0.000356
Validation Loss: 0.00044516
Epoch [35/300], Train Loss: 0.000342
Validation Loss: 0.00040334
Epoch [36/300], Train Loss: 0.000324
Validation Loss: 0.00042155
Epoch [37/300], Train Loss: 0.000309
Validation Loss: 0.00040295
Epoch [38/300], Train Loss: 0.000309
Validation Loss: 0.00041517
Epoch [39/300], Train Loss: 0.000310
Validation Loss: 0.00042450
Epoch [40/300], Train Loss: 0.000296
Validation Loss: 0.00043453
Epoch [41/300], Train Loss: 0.000309
Validation Loss: 0.00041553
Early stopping triggered

Evaluating model for: Microwave
Run 51/72 completed in 1547.71 seconds with: {'MAE': np.float32(6.075004), 'MSE': np.float32(5800.438), 'RMSE': np.float32(76.16061), 'SAE': np.float32(0.14569986), 'NDE': np.float32(0.6614842)}

Run 52/72: hidden=512, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Microwave
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.000646
Validation Loss: 0.00056602
Epoch [2/300], Train Loss: 0.000629
Validation Loss: 0.00055191
Epoch [3/300], Train Loss: 0.000605
Validation Loss: 0.00051896
Epoch [4/300], Train Loss: 0.000543
Validation Loss: 0.00054289
Epoch [5/300], Train Loss: 0.000517
Validation Loss: 0.00052810
Epoch [6/300], Train Loss: 0.000505
Validation Loss: 0.00051912
Epoch [7/300], Train Loss: 0.000511
Validation Loss: 0.00053607
Epoch [8/300], Train Loss: 0.000500
Validation Loss: 0.00052634
Epoch [9/300], Train Loss: 0.000486
Validation Loss: 0.00053429
Epoch [10/300], Train Loss: 0.000490
Validation Loss: 0.00054175
Epoch [11/300], Train Loss: 0.000496
Validation Loss: 0.00053014
Epoch [12/300], Train Loss: 0.000488
Validation Loss: 0.00054087
Epoch [13/300], Train Loss: 0.000466
Validation Loss: 0.00049914
Epoch [14/300], Train Loss: 0.000482
Validation Loss: 0.00052225
Epoch [15/300], Train Loss: 0.000443
Validation Loss: 0.00047463
Epoch [16/300], Train Loss: 0.000453
Validation Loss: 0.00052041
Epoch [17/300], Train Loss: 0.000571
Validation Loss: 0.00057864
Epoch [18/300], Train Loss: 0.000538
Validation Loss: 0.00056379
Epoch [19/300], Train Loss: 0.000527
Validation Loss: 0.00051563
Epoch [20/300], Train Loss: 0.000413
Validation Loss: 0.00053277
Epoch [21/300], Train Loss: 0.000387
Validation Loss: 0.00048747
Epoch [22/300], Train Loss: 0.000379
Validation Loss: 0.00056079
Epoch [23/300], Train Loss: 0.000381
Validation Loss: 0.00045273
Epoch [24/300], Train Loss: 0.000383
Validation Loss: 0.00050245
Epoch [25/300], Train Loss: 0.000365
Validation Loss: 0.00049163
Epoch [26/300], Train Loss: 0.000365
Validation Loss: 0.00044533
Epoch [27/300], Train Loss: 0.000355
Validation Loss: 0.00043187
Epoch [28/300], Train Loss: 0.000356
Validation Loss: 0.00042755
Epoch [29/300], Train Loss: 0.000390
Validation Loss: 0.00049259
Epoch [30/300], Train Loss: 0.000357
Validation Loss: 0.00043088
Epoch [31/300], Train Loss: 0.000340
Validation Loss: 0.00039428
Epoch [32/300], Train Loss: 0.000346
Validation Loss: 0.00040846
Epoch [33/300], Train Loss: 0.000331
Validation Loss: 0.00044276
Epoch [34/300], Train Loss: 0.000330
Validation Loss: 0.00043982
Epoch [35/300], Train Loss: 0.000348
Validation Loss: 0.00041416
Epoch [36/300], Train Loss: 0.000329
Validation Loss: 0.00041446
Epoch [37/300], Train Loss: 0.000317
Validation Loss: 0.00041464
Epoch [38/300], Train Loss: 0.000311
Validation Loss: 0.00043632
Epoch [39/300], Train Loss: 0.000317
Validation Loss: 0.00044118
Epoch [40/300], Train Loss: 0.000314
Validation Loss: 0.00042520
Epoch [41/300], Train Loss: 0.000301
Validation Loss: 0.00041999
Early stopping triggered

Evaluating model for: Microwave
Run 52/72 completed in 1771.87 seconds with: {'MAE': np.float32(6.377701), 'MSE': np.float32(6420.942), 'RMSE': np.float32(80.13078), 'SAE': np.float32(0.20106311), 'NDE': np.float32(0.6959661)}

Run 53/72: hidden=512, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Microwave
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.000665
Validation Loss: 0.00097577
Epoch [2/300], Train Loss: 0.000629
Validation Loss: 0.00095911
Epoch [3/300], Train Loss: 0.000617
Validation Loss: 0.00093102
Epoch [4/300], Train Loss: 0.000606
Validation Loss: 0.00091125
Epoch [5/300], Train Loss: 0.000582
Validation Loss: 0.00075637
Epoch [6/300], Train Loss: 0.000652
Validation Loss: 0.00093644
Epoch [7/300], Train Loss: 0.000602
Validation Loss: 0.00090412
Epoch [8/300], Train Loss: 0.000587
Validation Loss: 0.00085388
Epoch [9/300], Train Loss: 0.000560
Validation Loss: 0.00081624
Epoch [10/300], Train Loss: 0.000538
Validation Loss: 0.00072549
Epoch [11/300], Train Loss: 0.000510
Validation Loss: 0.00070381
Epoch [12/300], Train Loss: 0.000505
Validation Loss: 0.00068078
Epoch [13/300], Train Loss: 0.000518
Validation Loss: 0.00067369
Epoch [14/300], Train Loss: 0.000498
Validation Loss: 0.00063362
Epoch [15/300], Train Loss: 0.000501
Validation Loss: 0.00070580
Epoch [16/300], Train Loss: 0.000476
Validation Loss: 0.00079544
Epoch [17/300], Train Loss: 0.000488
Validation Loss: 0.00069564
Epoch [18/300], Train Loss: 0.000475
Validation Loss: 0.00072738
Epoch [19/300], Train Loss: 0.000479
Validation Loss: 0.00068264
Epoch [20/300], Train Loss: 0.000473
Validation Loss: 0.00069518
Epoch [21/300], Train Loss: 0.000476
Validation Loss: 0.00069078
Epoch [22/300], Train Loss: 0.000478
Validation Loss: 0.00068224
Epoch [23/300], Train Loss: 0.000467
Validation Loss: 0.00062609
Epoch [24/300], Train Loss: 0.000467
Validation Loss: 0.00070836
Epoch [25/300], Train Loss: 0.000465
Validation Loss: 0.00069229
Epoch [26/300], Train Loss: 0.000461
Validation Loss: 0.00067954
Epoch [27/300], Train Loss: 0.000493
Validation Loss: 0.00064920
Epoch [28/300], Train Loss: 0.000464
Validation Loss: 0.00068233
Epoch [29/300], Train Loss: 0.000467
Validation Loss: 0.00068940
Epoch [30/300], Train Loss: 0.000449
Validation Loss: 0.00063119
Epoch [31/300], Train Loss: 0.000450
Validation Loss: 0.00069647
Epoch [32/300], Train Loss: 0.000453
Validation Loss: 0.00062519
Epoch [33/300], Train Loss: 0.000436
Validation Loss: 0.00061294
Epoch [34/300], Train Loss: 0.000466
Validation Loss: 0.00063720
Epoch [35/300], Train Loss: 0.000439
Validation Loss: 0.00064712
Epoch [36/300], Train Loss: 0.000425
Validation Loss: 0.00065447
Epoch [37/300], Train Loss: 0.000431
Validation Loss: 0.00060480
Epoch [38/300], Train Loss: 0.000422
Validation Loss: 0.00059687
Epoch [39/300], Train Loss: 0.000433
Validation Loss: 0.00063534
Epoch [40/300], Train Loss: 0.000420
Validation Loss: 0.00059428
Epoch [41/300], Train Loss: 0.000429
Validation Loss: 0.00054898
Epoch [42/300], Train Loss: 0.000421
Validation Loss: 0.00064193
Epoch [43/300], Train Loss: 0.000416
Validation Loss: 0.00052984
Epoch [44/300], Train Loss: 0.000426
Validation Loss: 0.00057269
Epoch [45/300], Train Loss: 0.000419
Validation Loss: 0.00055936
Epoch [46/300], Train Loss: 0.000419
Validation Loss: 0.00060369
Epoch [47/300], Train Loss: 0.000415
Validation Loss: 0.00068494
Epoch [48/300], Train Loss: 0.000424
Validation Loss: 0.00051658
Epoch [49/300], Train Loss: 0.000414
Validation Loss: 0.00059050
Epoch [50/300], Train Loss: 0.000406
Validation Loss: 0.00056709
Epoch [51/300], Train Loss: 0.000417
Validation Loss: 0.00058444
Epoch [52/300], Train Loss: 0.000407
Validation Loss: 0.00054975
Epoch [53/300], Train Loss: 0.000414
Validation Loss: 0.00059842
Epoch [54/300], Train Loss: 0.000395
Validation Loss: 0.00053832
Epoch [55/300], Train Loss: 0.000396
Validation Loss: 0.00056915
Epoch [56/300], Train Loss: 0.000400
Validation Loss: 0.00059979
Epoch [57/300], Train Loss: 0.000395
Validation Loss: 0.00057671
Epoch [58/300], Train Loss: 0.000393
Validation Loss: 0.00055355
Early stopping triggered

Evaluating model for: Microwave
Run 53/72 completed in 912.90 seconds with: {'MAE': np.float32(13.556002), 'MSE': np.float32(5160.399), 'RMSE': np.float32(71.835915), 'SAE': np.float32(0.43662333), 'NDE': np.float32(0.7922286)}

Run 54/72: hidden=512, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Microwave
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.000632
Validation Loss: 0.00096992
Epoch [2/300], Train Loss: 0.000616
Validation Loss: 0.00094078
Epoch [3/300], Train Loss: 0.000593
Validation Loss: 0.00079437
Epoch [4/300], Train Loss: 0.000544
Validation Loss: 0.00085367
Epoch [5/300], Train Loss: 0.000552
Validation Loss: 0.00068498
Epoch [6/300], Train Loss: 0.000512
Validation Loss: 0.00063768
Epoch [7/300], Train Loss: 0.000522
Validation Loss: 0.00063956
Epoch [8/300], Train Loss: 0.000505
Validation Loss: 0.00074316
Epoch [9/300], Train Loss: 0.000505
Validation Loss: 0.00077292
Epoch [10/300], Train Loss: 0.000526
Validation Loss: 0.00069413
Epoch [11/300], Train Loss: 0.000490
Validation Loss: 0.00074729
Epoch [12/300], Train Loss: 0.000491
Validation Loss: 0.00067316
Epoch [13/300], Train Loss: 0.000490
Validation Loss: 0.00070559
Epoch [14/300], Train Loss: 0.000495
Validation Loss: 0.00063943
Epoch [15/300], Train Loss: 0.000490
Validation Loss: 0.00070741
Epoch [16/300], Train Loss: 0.000466
Validation Loss: 0.00079974
Early stopping triggered

Evaluating model for: Microwave
Run 54/72 completed in 278.19 seconds with: {'MAE': np.float32(10.087836), 'MSE': np.float32(7312.9526), 'RMSE': np.float32(85.5158), 'SAE': np.float32(0.6492317), 'NDE': np.float32(0.9430943)}

Run 55/72: hidden=512, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Microwave
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.000637
Validation Loss: 0.00097806
Epoch [2/300], Train Loss: 0.000624
Validation Loss: 0.00095944
Epoch [3/300], Train Loss: 0.000607
Validation Loss: 0.00085570
Epoch [4/300], Train Loss: 0.000561
Validation Loss: 0.00087457
Epoch [5/300], Train Loss: 0.000567
Validation Loss: 0.00072901
Epoch [6/300], Train Loss: 0.000558
Validation Loss: 0.00078320
Epoch [7/300], Train Loss: 0.000516
Validation Loss: 0.00066901
Epoch [8/300], Train Loss: 0.000504
Validation Loss: 0.00081798
Epoch [9/300], Train Loss: 0.000503
Validation Loss: 0.00081034
Epoch [10/300], Train Loss: 0.000523
Validation Loss: 0.00070295
Epoch [11/300], Train Loss: 0.000504
Validation Loss: 0.00075671
Epoch [12/300], Train Loss: 0.000496
Validation Loss: 0.00071457
Epoch [13/300], Train Loss: 0.000493
Validation Loss: 0.00072787
Epoch [14/300], Train Loss: 0.000495
Validation Loss: 0.00067370
Epoch [15/300], Train Loss: 0.000492
Validation Loss: 0.00074670
Epoch [16/300], Train Loss: 0.000470
Validation Loss: 0.00084401
Epoch [17/300], Train Loss: 0.000497
Validation Loss: 0.00073487
Early stopping triggered

Evaluating model for: Microwave
Run 55/72 completed in 319.66 seconds with: {'MAE': np.float32(10.913417), 'MSE': np.float32(7281.567), 'RMSE': np.float32(85.3321), 'SAE': np.float32(0.031172015), 'NDE': np.float32(0.94106823)}

Run 56/72: hidden=512, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Microwave
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.000649
Validation Loss: 0.00098196
Epoch [2/300], Train Loss: 0.000633
Validation Loss: 0.00097842
Epoch [3/300], Train Loss: 0.000629
Validation Loss: 0.00096639
Epoch [4/300], Train Loss: 0.000622
Validation Loss: 0.00094285
Epoch [5/300], Train Loss: 0.000603
Validation Loss: 0.00077984
Epoch [6/300], Train Loss: 0.000595
Validation Loss: 0.00083896
Epoch [7/300], Train Loss: 0.000545
Validation Loss: 0.00065860
Epoch [8/300], Train Loss: 0.000522
Validation Loss: 0.00082073
Epoch [9/300], Train Loss: 0.000524
Validation Loss: 0.00077546
Epoch [10/300], Train Loss: 0.000575
Validation Loss: 0.00090271
Epoch [11/300], Train Loss: 0.000547
Validation Loss: 0.00066685
Epoch [12/300], Train Loss: 0.000509
Validation Loss: 0.00064646
Epoch [13/300], Train Loss: 0.000501
Validation Loss: 0.00067321
Epoch [14/300], Train Loss: 0.000516
Validation Loss: 0.00064008
Epoch [15/300], Train Loss: 0.000512
Validation Loss: 0.00068975
Epoch [16/300], Train Loss: 0.000488
Validation Loss: 0.00080022
Epoch [17/300], Train Loss: 0.000494
Validation Loss: 0.00068261
Epoch [18/300], Train Loss: 0.000504
Validation Loss: 0.00081540
Epoch [19/300], Train Loss: 0.000536
Validation Loss: 0.00066201
Epoch [20/300], Train Loss: 0.000482
Validation Loss: 0.00068629
Epoch [21/300], Train Loss: 0.000485
Validation Loss: 0.00069804
Epoch [22/300], Train Loss: 0.000481
Validation Loss: 0.00069448
Epoch [23/300], Train Loss: 0.000473
Validation Loss: 0.00063918
Epoch [24/300], Train Loss: 0.000470
Validation Loss: 0.00073326
Epoch [25/300], Train Loss: 0.000474
Validation Loss: 0.00073796
Epoch [26/300], Train Loss: 0.000473
Validation Loss: 0.00068171
Epoch [27/300], Train Loss: 0.000525
Validation Loss: 0.00075030
Epoch [28/300], Train Loss: 0.000519
Validation Loss: 0.00080314
Epoch [29/300], Train Loss: 0.000513
Validation Loss: 0.00083812
Epoch [30/300], Train Loss: 0.000514
Validation Loss: 0.00074184
Epoch [31/300], Train Loss: 0.000509
Validation Loss: 0.00086593
Epoch [32/300], Train Loss: 0.000529
Validation Loss: 0.00085258
Epoch [33/300], Train Loss: 0.000511
Validation Loss: 0.00082940
Early stopping triggered

Evaluating model for: Microwave
Run 56/72 completed in 716.20 seconds with: {'MAE': np.float32(10.870233), 'MSE': np.float32(7858.2583), 'RMSE': np.float32(88.64682), 'SAE': np.float32(0.031053707), 'NDE': np.float32(0.9776243)}

Run 57/72: hidden=512, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Microwave
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.000616
Validation Loss: 0.00090683
Epoch [2/300], Train Loss: 0.000641
Validation Loss: 0.00088809
Epoch [3/300], Train Loss: 0.000606
Validation Loss: 0.00086057
Epoch [4/300], Train Loss: 0.000580
Validation Loss: 0.00082956
Epoch [5/300], Train Loss: 0.000537
Validation Loss: 0.00077559
Epoch [6/300], Train Loss: 0.000525
Validation Loss: 0.00072568
Epoch [7/300], Train Loss: 0.000502
Validation Loss: 0.00071802
Epoch [8/300], Train Loss: 0.000504
Validation Loss: 0.00070333
Epoch [9/300], Train Loss: 0.000508
Validation Loss: 0.00071221
Epoch [10/300], Train Loss: 0.000477
Validation Loss: 0.00073488
Epoch [11/300], Train Loss: 0.000470
Validation Loss: 0.00072117
Epoch [12/300], Train Loss: 0.000471
Validation Loss: 0.00072158
Epoch [13/300], Train Loss: 0.000469
Validation Loss: 0.00076306
Epoch [14/300], Train Loss: 0.000461
Validation Loss: 0.00069795
Epoch [15/300], Train Loss: 0.000526
Validation Loss: 0.00074970
Epoch [16/300], Train Loss: 0.000481
Validation Loss: 0.00073009
Epoch [17/300], Train Loss: 0.000464
Validation Loss: 0.00069929
Epoch [18/300], Train Loss: 0.000454
Validation Loss: 0.00068915
Epoch [19/300], Train Loss: 0.000455
Validation Loss: 0.00069600
Epoch [20/300], Train Loss: 0.000452
Validation Loss: 0.00067015
Epoch [21/300], Train Loss: 0.000447
Validation Loss: 0.00068358
Epoch [22/300], Train Loss: 0.000443
Validation Loss: 0.00069746
Epoch [23/300], Train Loss: 0.000444
Validation Loss: 0.00067181
Epoch [24/300], Train Loss: 0.000445
Validation Loss: 0.00070438
Epoch [25/300], Train Loss: 0.000448
Validation Loss: 0.00066365
Epoch [26/300], Train Loss: 0.000437
Validation Loss: 0.00069826
Epoch [27/300], Train Loss: 0.000433
Validation Loss: 0.00068811
Epoch [28/300], Train Loss: 0.000427
Validation Loss: 0.00068679
Epoch [29/300], Train Loss: 0.000541
Validation Loss: 0.00063750
Epoch [30/300], Train Loss: 0.000483
Validation Loss: 0.00067600
Epoch [31/300], Train Loss: 0.000420
Validation Loss: 0.00066556
Epoch [32/300], Train Loss: 0.000408
Validation Loss: 0.00066500
Epoch [33/300], Train Loss: 0.000422
Validation Loss: 0.00063556
Epoch [34/300], Train Loss: 0.000420
Validation Loss: 0.00069684
Epoch [35/300], Train Loss: 0.000422
Validation Loss: 0.00066747
Epoch [36/300], Train Loss: 0.000411
Validation Loss: 0.00063461
Epoch [37/300], Train Loss: 0.000413
Validation Loss: 0.00066701
Epoch [38/300], Train Loss: 0.000419
Validation Loss: 0.00065576
Epoch [39/300], Train Loss: 0.000405
Validation Loss: 0.00064082
Epoch [40/300], Train Loss: 0.000452
Validation Loss: 0.00064634
Epoch [41/300], Train Loss: 0.000476
Validation Loss: 0.00063735
Epoch [42/300], Train Loss: 0.000439
Validation Loss: 0.00062044
Epoch [43/300], Train Loss: 0.000398
Validation Loss: 0.00060682
Epoch [44/300], Train Loss: 0.000406
Validation Loss: 0.00060587
Epoch [45/300], Train Loss: 0.000451
Validation Loss: 0.00062616
Epoch [46/300], Train Loss: 0.000421
Validation Loss: 0.00060415
Epoch [47/300], Train Loss: 0.000387
Validation Loss: 0.00060632
Epoch [48/300], Train Loss: 0.000394
Validation Loss: 0.00068081
Epoch [49/300], Train Loss: 0.000389
Validation Loss: 0.00060373
Epoch [50/300], Train Loss: 0.000376
Validation Loss: 0.00063142
Epoch [51/300], Train Loss: 0.000401
Validation Loss: 0.00060724
Epoch [52/300], Train Loss: 0.000375
Validation Loss: 0.00060662
Epoch [53/300], Train Loss: 0.000371
Validation Loss: 0.00059615
Epoch [54/300], Train Loss: 0.000371
Validation Loss: 0.00060360
Epoch [55/300], Train Loss: 0.000375
Validation Loss: 0.00064872
Epoch [56/300], Train Loss: 0.000371
Validation Loss: 0.00059892
Epoch [57/300], Train Loss: 0.000379
Validation Loss: 0.00063914
Epoch [58/300], Train Loss: 0.000382
Validation Loss: 0.00060023
Epoch [59/300], Train Loss: 0.000371
Validation Loss: 0.00058671
Epoch [60/300], Train Loss: 0.000363
Validation Loss: 0.00059476
Epoch [61/300], Train Loss: 0.000353
Validation Loss: 0.00060149
Epoch [62/300], Train Loss: 0.000348
Validation Loss: 0.00058248
Epoch [63/300], Train Loss: 0.000348
Validation Loss: 0.00057999
Epoch [64/300], Train Loss: 0.000341
Validation Loss: 0.00059119
Epoch [65/300], Train Loss: 0.000347
Validation Loss: 0.00059193
Epoch [66/300], Train Loss: 0.000349
Validation Loss: 0.00069640
Epoch [67/300], Train Loss: 0.000350
Validation Loss: 0.00059905
Epoch [68/300], Train Loss: 0.000344
Validation Loss: 0.00056010
Epoch [69/300], Train Loss: 0.000435
Validation Loss: 0.00058867
Epoch [70/300], Train Loss: 0.000371
Validation Loss: 0.00057177
Epoch [71/300], Train Loss: 0.000338
Validation Loss: 0.00061198
Epoch [72/300], Train Loss: 0.000353
Validation Loss: 0.00058347
Epoch [73/300], Train Loss: 0.000341
Validation Loss: 0.00069468
Epoch [74/300], Train Loss: 0.000365
Validation Loss: 0.00059976
Epoch [75/300], Train Loss: 0.000339
Validation Loss: 0.00058994
Epoch [76/300], Train Loss: 0.000333
Validation Loss: 0.00059058
Epoch [77/300], Train Loss: 0.000322
Validation Loss: 0.00055273
Epoch [78/300], Train Loss: 0.000322
Validation Loss: 0.00056662
Epoch [79/300], Train Loss: 0.000318
Validation Loss: 0.00060339
Epoch [80/300], Train Loss: 0.000317
Validation Loss: 0.00055569
Epoch [81/300], Train Loss: 0.000314
Validation Loss: 0.00055695
Epoch [82/300], Train Loss: 0.000315
Validation Loss: 0.00054104
Epoch [83/300], Train Loss: 0.000316
Validation Loss: 0.00054373
Epoch [84/300], Train Loss: 0.000304
Validation Loss: 0.00054586
Epoch [85/300], Train Loss: 0.000319
Validation Loss: 0.00056219
Epoch [86/300], Train Loss: 0.000313
Validation Loss: 0.00054469
Epoch [87/300], Train Loss: 0.000306
Validation Loss: 0.00054276
Epoch [88/300], Train Loss: 0.000303
Validation Loss: 0.00055275
Epoch [89/300], Train Loss: 0.000303
Validation Loss: 0.00057703
Epoch [90/300], Train Loss: 0.000351
Validation Loss: 0.00054674
Epoch [91/300], Train Loss: 0.000330
Validation Loss: 0.00055437
Epoch [92/300], Train Loss: 0.000297
Validation Loss: 0.00055140
Early stopping triggered

Evaluating model for: Microwave
Run 57/72 completed in 1360.55 seconds with: {'MAE': np.float32(7.7150803), 'MSE': np.float32(5447.771), 'RMSE': np.float32(73.80901), 'SAE': np.float32(0.15907943), 'NDE': np.float32(0.68306315)}

Run 58/72: hidden=512, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Microwave
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.000618
Validation Loss: 0.00090841
Epoch [2/300], Train Loss: 0.000646
Validation Loss: 0.00089501
Epoch [3/300], Train Loss: 0.000617
Validation Loss: 0.00088587
Epoch [4/300], Train Loss: 0.000605
Validation Loss: 0.00087684
Epoch [5/300], Train Loss: 0.000584
Validation Loss: 0.00085113
Epoch [6/300], Train Loss: 0.000530
Validation Loss: 0.00078006
Epoch [7/300], Train Loss: 0.000514
Validation Loss: 0.00078708
Epoch [8/300], Train Loss: 0.000511
Validation Loss: 0.00077459
Epoch [9/300], Train Loss: 0.000524
Validation Loss: 0.00075211
Epoch [10/300], Train Loss: 0.000499
Validation Loss: 0.00076292
Epoch [11/300], Train Loss: 0.000472
Validation Loss: 0.00076430
Epoch [12/300], Train Loss: 0.000476
Validation Loss: 0.00074464
Epoch [13/300], Train Loss: 0.000470
Validation Loss: 0.00077393
Epoch [14/300], Train Loss: 0.000468
Validation Loss: 0.00073880
Epoch [15/300], Train Loss: 0.000537
Validation Loss: 0.00082318
Epoch [16/300], Train Loss: 0.000479
Validation Loss: 0.00072923
Epoch [17/300], Train Loss: 0.000464
Validation Loss: 0.00073482
Epoch [18/300], Train Loss: 0.000453
Validation Loss: 0.00071916
Epoch [19/300], Train Loss: 0.000437
Validation Loss: 0.00071417
Epoch [20/300], Train Loss: 0.000440
Validation Loss: 0.00070613
Epoch [21/300], Train Loss: 0.000425
Validation Loss: 0.00071144
Epoch [22/300], Train Loss: 0.000422
Validation Loss: 0.00072731
Epoch [23/300], Train Loss: 0.000428
Validation Loss: 0.00070424
Epoch [24/300], Train Loss: 0.000418
Validation Loss: 0.00079388
Epoch [25/300], Train Loss: 0.000553
Validation Loss: 0.00091173
Epoch [26/300], Train Loss: 0.000571
Validation Loss: 0.00091128
Epoch [27/300], Train Loss: 0.000570
Validation Loss: 0.00091054
Epoch [28/300], Train Loss: 0.000569
Validation Loss: 0.00086580
Epoch [29/300], Train Loss: 0.000759
Validation Loss: 0.00086823
Epoch [30/300], Train Loss: 0.000573
Validation Loss: 0.00085734
Epoch [31/300], Train Loss: 0.000568
Validation Loss: 0.00085082
Epoch [32/300], Train Loss: 0.000568
Validation Loss: 0.00084130
Epoch [33/300], Train Loss: 0.000569
Validation Loss: 0.00085075
Early stopping triggered

Evaluating model for: Microwave
Run 58/72 completed in 619.28 seconds with: {'MAE': np.float32(12.402063), 'MSE': np.float32(10796.747), 'RMSE': np.float32(103.907394), 'SAE': np.float32(0.031627294), 'NDE': np.float32(0.9616085)}

Run 59/72: hidden=512, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Microwave
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.000616
Validation Loss: 0.00091088
Epoch [2/300], Train Loss: 0.000647
Validation Loss: 0.00090039
Epoch [3/300], Train Loss: 0.000618
Validation Loss: 0.00088485
Epoch [4/300], Train Loss: 0.000602
Validation Loss: 0.00086015
Epoch [5/300], Train Loss: 0.000568
Validation Loss: 0.00080725
Epoch [6/300], Train Loss: 0.000586
Validation Loss: 0.00079853
Epoch [7/300], Train Loss: 0.000520
Validation Loss: 0.00075030
Epoch [8/300], Train Loss: 0.000499
Validation Loss: 0.00072493
Epoch [9/300], Train Loss: 0.000530
Validation Loss: 0.00074109
Epoch [10/300], Train Loss: 0.000489
Validation Loss: 0.00080985
Epoch [11/300], Train Loss: 0.000489
Validation Loss: 0.00074930
Epoch [12/300], Train Loss: 0.000475
Validation Loss: 0.00074571
Epoch [13/300], Train Loss: 0.000473
Validation Loss: 0.00078307
Epoch [14/300], Train Loss: 0.000462
Validation Loss: 0.00069631
Epoch [15/300], Train Loss: 0.000522
Validation Loss: 0.00073835
Epoch [16/300], Train Loss: 0.000484
Validation Loss: 0.00072071
Epoch [17/300], Train Loss: 0.000462
Validation Loss: 0.00070049
Epoch [18/300], Train Loss: 0.000451
Validation Loss: 0.00069380
Epoch [19/300], Train Loss: 0.000461
Validation Loss: 0.00071522
Epoch [20/300], Train Loss: 0.000465
Validation Loss: 0.00067044
Epoch [21/300], Train Loss: 0.000453
Validation Loss: 0.00069106
Epoch [22/300], Train Loss: 0.000448
Validation Loss: 0.00071142
Epoch [23/300], Train Loss: 0.000450
Validation Loss: 0.00066666
Epoch [24/300], Train Loss: 0.000446
Validation Loss: 0.00072220
Epoch [25/300], Train Loss: 0.000445
Validation Loss: 0.00065799
Epoch [26/300], Train Loss: 0.000430
Validation Loss: 0.00066745
Epoch [27/300], Train Loss: 0.000422
Validation Loss: 0.00066839
Epoch [28/300], Train Loss: 0.000414
Validation Loss: 0.00070259
Epoch [29/300], Train Loss: 0.000535
Validation Loss: 0.00062403
Epoch [30/300], Train Loss: 0.000495
Validation Loss: 0.00067056
Epoch [31/300], Train Loss: 0.000397
Validation Loss: 0.00065072
Epoch [32/300], Train Loss: 0.000380
Validation Loss: 0.00067229
Epoch [33/300], Train Loss: 0.000391
Validation Loss: 0.00059583
Epoch [34/300], Train Loss: 0.000382
Validation Loss: 0.00067355
Epoch [35/300], Train Loss: 0.000397
Validation Loss: 0.00060768
Epoch [36/300], Train Loss: 0.000391
Validation Loss: 0.00062286
Epoch [37/300], Train Loss: 0.000411
Validation Loss: 0.00068843
Epoch [38/300], Train Loss: 0.000393
Validation Loss: 0.00067596
Epoch [39/300], Train Loss: 0.000376
Validation Loss: 0.00064631
Epoch [40/300], Train Loss: 0.000416
Validation Loss: 0.00061092
Epoch [41/300], Train Loss: 0.000447
Validation Loss: 0.00060702
Epoch [42/300], Train Loss: 0.000395
Validation Loss: 0.00062493
Epoch [43/300], Train Loss: 0.000369
Validation Loss: 0.00059465
Epoch [44/300], Train Loss: 0.000376
Validation Loss: 0.00056724
Epoch [45/300], Train Loss: 0.000592
Validation Loss: 0.00087779
Epoch [46/300], Train Loss: 0.000489
Validation Loss: 0.00063316
Epoch [47/300], Train Loss: 0.000371
Validation Loss: 0.00060592
Epoch [48/300], Train Loss: 0.000366
Validation Loss: 0.00067014
Epoch [49/300], Train Loss: 0.000354
Validation Loss: 0.00063553
Epoch [50/300], Train Loss: 0.000345
Validation Loss: 0.00060540
Epoch [51/300], Train Loss: 0.000363
Validation Loss: 0.00059876
Epoch [52/300], Train Loss: 0.000341
Validation Loss: 0.00062144
Epoch [53/300], Train Loss: 0.000337
Validation Loss: 0.00065339
Epoch [54/300], Train Loss: 0.000340
Validation Loss: 0.00062601
Early stopping triggered

Evaluating model for: Microwave
Run 59/72 completed in 1199.92 seconds with: {'MAE': np.float32(7.4748936), 'MSE': np.float32(5935.953), 'RMSE': np.float32(77.045135), 'SAE': np.float32(0.07616212), 'NDE': np.float32(0.7130109)}

Run 60/72: hidden=512, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Microwave
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.000611
Validation Loss: 0.00091437
Epoch [2/300], Train Loss: 0.000650
Validation Loss: 0.00090859
Epoch [3/300], Train Loss: 0.000627
Validation Loss: 0.00090791
Epoch [4/300], Train Loss: 0.000618
Validation Loss: 0.00090434
Epoch [5/300], Train Loss: 0.000600
Validation Loss: 0.00089299
Epoch [6/300], Train Loss: 0.000599
Validation Loss: 0.00086341
Epoch [7/300], Train Loss: 0.000606
Validation Loss: 0.00090130
Epoch [8/300], Train Loss: 0.000610
Validation Loss: 0.00089313
Epoch [9/300], Train Loss: 0.000595
Validation Loss: 0.00088981
Epoch [10/300], Train Loss: 0.000592
Validation Loss: 0.00087411
Epoch [11/300], Train Loss: 0.000574
Validation Loss: 0.00085630
Epoch [12/300], Train Loss: 0.000592
Validation Loss: 0.00092288
Epoch [13/300], Train Loss: 0.000599
Validation Loss: 0.00089023
Epoch [14/300], Train Loss: 0.000586
Validation Loss: 0.00085746
Epoch [15/300], Train Loss: 0.000631
Validation Loss: 0.00091057
Epoch [16/300], Train Loss: 0.000576
Validation Loss: 0.00091125
Epoch [17/300], Train Loss: 0.000605
Validation Loss: 0.00090579
Epoch [18/300], Train Loss: 0.000600
Validation Loss: 0.00089821
Epoch [19/300], Train Loss: 0.000592
Validation Loss: 0.00088087
Epoch [20/300], Train Loss: 0.000579
Validation Loss: 0.00085124
Epoch [21/300], Train Loss: 0.000535
Validation Loss: 0.00078422
Epoch [22/300], Train Loss: 0.000512
Validation Loss: 0.00075232
Epoch [23/300], Train Loss: 0.000493
Validation Loss: 0.00074425
Epoch [24/300], Train Loss: 0.000493
Validation Loss: 0.00079912
Epoch [25/300], Train Loss: 0.000499
Validation Loss: 0.00074781
Epoch [26/300], Train Loss: 0.000480
Validation Loss: 0.00075003
Epoch [27/300], Train Loss: 0.000468
Validation Loss: 0.00073719
Epoch [28/300], Train Loss: 0.000469
Validation Loss: 0.00074653
Epoch [29/300], Train Loss: 0.000603
Validation Loss: 0.00072565
Epoch [30/300], Train Loss: 0.000578
Validation Loss: 0.00074314
Epoch [31/300], Train Loss: 0.000463
Validation Loss: 0.00073722
Epoch [32/300], Train Loss: 0.000459
Validation Loss: 0.00073560
Epoch [33/300], Train Loss: 0.000461
Validation Loss: 0.00072671
Epoch [34/300], Train Loss: 0.000462
Validation Loss: 0.00074914
Epoch [35/300], Train Loss: 0.000462
Validation Loss: 0.00072656
Epoch [36/300], Train Loss: 0.000450
Validation Loss: 0.00072699
Epoch [37/300], Train Loss: 0.000448
Validation Loss: 0.00072677
Epoch [38/300], Train Loss: 0.000447
Validation Loss: 0.00071975
Epoch [39/300], Train Loss: 0.000445
Validation Loss: 0.00072683
Epoch [40/300], Train Loss: 0.000499
Validation Loss: 0.00071572
Epoch [41/300], Train Loss: 0.000506
Validation Loss: 0.00071289
Epoch [42/300], Train Loss: 0.000468
Validation Loss: 0.00071659
Epoch [43/300], Train Loss: 0.000447
Validation Loss: 0.00070424
Epoch [44/300], Train Loss: 0.000470
Validation Loss: 0.00070540
Epoch [45/300], Train Loss: 0.000506
Validation Loss: 0.00069983
Epoch [46/300], Train Loss: 0.000475
Validation Loss: 0.00072089
Epoch [47/300], Train Loss: 0.000429
Validation Loss: 0.00071606
Epoch [48/300], Train Loss: 0.000427
Validation Loss: 0.00070147
Epoch [49/300], Train Loss: 0.000432
Validation Loss: 0.00070949
Epoch [50/300], Train Loss: 0.000415
Validation Loss: 0.00074565
Epoch [51/300], Train Loss: 0.000428
Validation Loss: 0.00070992
Epoch [52/300], Train Loss: 0.000412
Validation Loss: 0.00070261
Epoch [53/300], Train Loss: 0.000404
Validation Loss: 0.00070437
Epoch [54/300], Train Loss: 0.000405
Validation Loss: 0.00070765
Epoch [55/300], Train Loss: 0.000405
Validation Loss: 0.00069803
Epoch [56/300], Train Loss: 0.000402
Validation Loss: 0.00069503
Epoch [57/300], Train Loss: 0.000402
Validation Loss: 0.00069115
Epoch [58/300], Train Loss: 0.000429
Validation Loss: 0.00069554
Epoch [59/300], Train Loss: 0.000400
Validation Loss: 0.00069651
Epoch [60/300], Train Loss: 0.000400
Validation Loss: 0.00069372
Epoch [61/300], Train Loss: 0.000399
Validation Loss: 0.00069150
Epoch [62/300], Train Loss: 0.000398
Validation Loss: 0.00068841
Epoch [63/300], Train Loss: 0.000402
Validation Loss: 0.00068624
Epoch [64/300], Train Loss: 0.000404
Validation Loss: 0.00068955
Epoch [65/300], Train Loss: 0.000399
Validation Loss: 0.00069110
Epoch [66/300], Train Loss: 0.000395
Validation Loss: 0.00068400
Epoch [67/300], Train Loss: 0.000398
Validation Loss: 0.00069314
Epoch [68/300], Train Loss: 0.000419
Validation Loss: 0.00068987
Epoch [69/300], Train Loss: 0.000409
Validation Loss: 0.00068887
Epoch [70/300], Train Loss: 0.000415
Validation Loss: 0.00069105
Epoch [71/300], Train Loss: 0.000427
Validation Loss: 0.00083536
Epoch [72/300], Train Loss: 0.000481
Validation Loss: 0.00069322
Epoch [73/300], Train Loss: 0.000412
Validation Loss: 0.00069666
Epoch [74/300], Train Loss: 0.000440
Validation Loss: 0.00069251
Epoch [75/300], Train Loss: 0.000411
Validation Loss: 0.00069435
Epoch [76/300], Train Loss: 0.000399
Validation Loss: 0.00068514
Early stopping triggered

Evaluating model for: Microwave
Run 60/72 completed in 2120.20 seconds with: {'MAE': np.float32(8.613265), 'MSE': np.float32(6961.85), 'RMSE': np.float32(83.4377), 'SAE': np.float32(0.07105479), 'NDE': np.float32(0.7721714)}

Run 61/72: hidden=512, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Microwave
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.000540
Validation Loss: 0.00077756
Epoch [2/300], Train Loss: 0.000534
Validation Loss: 0.00077009
Epoch [3/300], Train Loss: 0.000526
Validation Loss: 0.00075643
Epoch [4/300], Train Loss: 0.000520
Validation Loss: 0.00074693
Epoch [5/300], Train Loss: 0.000518
Validation Loss: 0.00074316
Epoch [6/300], Train Loss: 0.000518
Validation Loss: 0.00071735
Epoch [7/300], Train Loss: 0.000495
Validation Loss: 0.00069196
Epoch [8/300], Train Loss: 0.000468
Validation Loss: 0.00061187
Epoch [9/300], Train Loss: 0.000460
Validation Loss: 0.00055714
Epoch [10/300], Train Loss: 0.000437
Validation Loss: 0.00054291
Epoch [11/300], Train Loss: 0.000483
Validation Loss: 0.00060613
Epoch [12/300], Train Loss: 0.000440
Validation Loss: 0.00055170
Epoch [13/300], Train Loss: 0.000419
Validation Loss: 0.00058361
Epoch [14/300], Train Loss: 0.000440
Validation Loss: 0.00060363
Epoch [15/300], Train Loss: 0.000487
Validation Loss: 0.00054794
Epoch [16/300], Train Loss: 0.000491
Validation Loss: 0.00054817
Epoch [17/300], Train Loss: 0.000473
Validation Loss: 0.00060445
Epoch [18/300], Train Loss: 0.000437
Validation Loss: 0.00057408
Epoch [19/300], Train Loss: 0.000427
Validation Loss: 0.00058052
Epoch [20/300], Train Loss: 0.000443
Validation Loss: 0.00055561
Early stopping triggered

Evaluating model for: Microwave
Run 61/72 completed in 153.26 seconds with: {'MAE': np.float32(17.87379), 'MSE': np.float32(11944.996), 'RMSE': np.float32(109.29317), 'SAE': np.float32(0.39143798), 'NDE': np.float32(0.8361183)}

Run 62/72: hidden=512, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Microwave
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.000543
Validation Loss: 0.00078488
Epoch [2/300], Train Loss: 0.000538
Validation Loss: 0.00078478
Epoch [3/300], Train Loss: 0.000537
Validation Loss: 0.00078388
Epoch [4/300], Train Loss: 0.000536
Validation Loss: 0.00077938
Epoch [5/300], Train Loss: 0.000537
Validation Loss: 0.00078124
Epoch [6/300], Train Loss: 0.000539
Validation Loss: 0.00077156
Epoch [7/300], Train Loss: 0.000524
Validation Loss: 0.00075539
Epoch [8/300], Train Loss: 0.000518
Validation Loss: 0.00074289
Epoch [9/300], Train Loss: 0.000506
Validation Loss: 0.00070321
Epoch [10/300], Train Loss: 0.000473
Validation Loss: 0.00061420
Epoch [11/300], Train Loss: 0.000488
Validation Loss: 0.00062312
Epoch [12/300], Train Loss: 0.000451
Validation Loss: 0.00061831
Epoch [13/300], Train Loss: 0.000440
Validation Loss: 0.00061679
Epoch [14/300], Train Loss: 0.000449
Validation Loss: 0.00063014
Epoch [15/300], Train Loss: 0.000495
Validation Loss: 0.00058823
Epoch [16/300], Train Loss: 0.000511
Validation Loss: 0.00060371
Epoch [17/300], Train Loss: 0.000468
Validation Loss: 0.00056554
Epoch [18/300], Train Loss: 0.000431
Validation Loss: 0.00057165
Epoch [19/300], Train Loss: 0.000424
Validation Loss: 0.00059775
Epoch [20/300], Train Loss: 0.000432
Validation Loss: 0.00056618
Epoch [21/300], Train Loss: 0.000426
Validation Loss: 0.00058190
Epoch [22/300], Train Loss: 0.000443
Validation Loss: 0.00056740
Epoch [23/300], Train Loss: 0.000430
Validation Loss: 0.00059207
Epoch [24/300], Train Loss: 0.000447
Validation Loss: 0.00056927
Epoch [25/300], Train Loss: 0.000416
Validation Loss: 0.00065272
Epoch [26/300], Train Loss: 0.000489
Validation Loss: 0.00072924
Epoch [27/300], Train Loss: 0.000490
Validation Loss: 0.00057779
Early stopping triggered

Evaluating model for: Microwave
Run 62/72 completed in 254.94 seconds with: {'MAE': np.float32(15.77537), 'MSE': np.float32(13234.405), 'RMSE': np.float32(115.040886), 'SAE': np.float32(0.47093835), 'NDE': np.float32(0.8800895)}

Run 63/72: hidden=512, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Microwave
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.000626
Validation Loss: 0.00078786
Epoch [2/300], Train Loss: 0.000543
Validation Loss: 0.00078749
Epoch [3/300], Train Loss: 0.000541
Validation Loss: 0.00078773
Epoch [4/300], Train Loss: 0.000541
Validation Loss: 0.00078629
Epoch [5/300], Train Loss: 0.000546
Validation Loss: 0.00078577
Epoch [6/300], Train Loss: 0.000547
Validation Loss: 0.00078434
Epoch [7/300], Train Loss: 0.000537
Validation Loss: 0.00078188
Epoch [8/300], Train Loss: 0.000535
Validation Loss: 0.00077476
Epoch [9/300], Train Loss: 0.000531
Validation Loss: 0.00076410
Epoch [10/300], Train Loss: 0.000528
Validation Loss: 0.00074942
Epoch [11/300], Train Loss: 0.000560
Validation Loss: 0.00075419
Epoch [12/300], Train Loss: 0.000521
Validation Loss: 0.00071520
Epoch [13/300], Train Loss: 0.000512
Validation Loss: 0.00073861
Epoch [14/300], Train Loss: 0.000511
Validation Loss: 0.00066319
Epoch [15/300], Train Loss: 0.000537
Validation Loss: 0.00060345
Epoch [16/300], Train Loss: 0.000533
Validation Loss: 0.00058663
Epoch [17/300], Train Loss: 0.000498
Validation Loss: 0.00062512
Epoch [18/300], Train Loss: 0.000482
Validation Loss: 0.00061107
Epoch [19/300], Train Loss: 0.000465
Validation Loss: 0.00064870
Epoch [20/300], Train Loss: 0.000476
Validation Loss: 0.00057232
Epoch [21/300], Train Loss: 0.000476
Validation Loss: 0.00056157
Epoch [22/300], Train Loss: 0.000488
Validation Loss: 0.00055517
Epoch [23/300], Train Loss: 0.000470
Validation Loss: 0.00057124
Epoch [24/300], Train Loss: 0.000471
Validation Loss: 0.00055008
Epoch [25/300], Train Loss: 0.000437
Validation Loss: 0.00073137
Epoch [26/300], Train Loss: 0.000578
Validation Loss: 0.00054613
Epoch [27/300], Train Loss: 0.000516
Validation Loss: 0.00062769
Epoch [28/300], Train Loss: 0.000467
Validation Loss: 0.00055169
Epoch [29/300], Train Loss: 0.000469
Validation Loss: 0.00053256
Epoch [30/300], Train Loss: 0.000454
Validation Loss: 0.00057650
Epoch [31/300], Train Loss: 0.000445
Validation Loss: 0.00053850
Epoch [32/300], Train Loss: 0.000440
Validation Loss: 0.00052220
Epoch [33/300], Train Loss: 0.000528
Validation Loss: 0.00054602
Epoch [34/300], Train Loss: 0.000539
Validation Loss: 0.00057490
Epoch [35/300], Train Loss: 0.000449
Validation Loss: 0.00056591
Epoch [36/300], Train Loss: 0.000442
Validation Loss: 0.00052044
Epoch [37/300], Train Loss: 0.000436
Validation Loss: 0.00053084
Epoch [38/300], Train Loss: 0.000430
Validation Loss: 0.00056333
Epoch [39/300], Train Loss: 0.000439
Validation Loss: 0.00051885
Epoch [40/300], Train Loss: 0.000440
Validation Loss: 0.00053112
Epoch [41/300], Train Loss: 0.000434
Validation Loss: 0.00053422
Epoch [42/300], Train Loss: 0.000496
Validation Loss: 0.00052094
Epoch [43/300], Train Loss: 0.000453
Validation Loss: 0.00056467
Epoch [44/300], Train Loss: 0.000433
Validation Loss: 0.00051684
Epoch [45/300], Train Loss: 0.000429
Validation Loss: 0.00055942
Epoch [46/300], Train Loss: 0.000422
Validation Loss: 0.00051520
Epoch [47/300], Train Loss: 0.000422
Validation Loss: 0.00052834
Epoch [48/300], Train Loss: 0.000422
Validation Loss: 0.00055083
Epoch [49/300], Train Loss: 0.000430
Validation Loss: 0.00053521
Epoch [50/300], Train Loss: 0.000460
Validation Loss: 0.00055046
Epoch [51/300], Train Loss: 0.000410
Validation Loss: 0.00050604
Epoch [52/300], Train Loss: 0.000415
Validation Loss: 0.00050452
Epoch [53/300], Train Loss: 0.000403
Validation Loss: 0.00049645
Epoch [54/300], Train Loss: 0.000404
Validation Loss: 0.00051280
Epoch [55/300], Train Loss: 0.000409
Validation Loss: 0.00056220
Epoch [56/300], Train Loss: 0.000423
Validation Loss: 0.00048088
Epoch [57/300], Train Loss: 0.000407
Validation Loss: 0.00046447
Epoch [58/300], Train Loss: 0.000397
Validation Loss: 0.00052132
Epoch [59/300], Train Loss: 0.000402
Validation Loss: 0.00047991
Epoch [60/300], Train Loss: 0.000542
Validation Loss: 0.00046246
Epoch [61/300], Train Loss: 0.000461
Validation Loss: 0.00055941
Epoch [62/300], Train Loss: 0.000406
Validation Loss: 0.00050154
Epoch [63/300], Train Loss: 0.000384
Validation Loss: 0.00048351
Epoch [64/300], Train Loss: 0.000411
Validation Loss: 0.00047234
Epoch [65/300], Train Loss: 0.000383
Validation Loss: 0.00047119
Epoch [66/300], Train Loss: 0.000398
Validation Loss: 0.00046642
Epoch [67/300], Train Loss: 0.000405
Validation Loss: 0.00046019
Epoch [68/300], Train Loss: 0.000400
Validation Loss: 0.00047618
Epoch [69/300], Train Loss: 0.000388
Validation Loss: 0.00046638
Epoch [70/300], Train Loss: 0.000393
Validation Loss: 0.00044832
Epoch [71/300], Train Loss: 0.000391
Validation Loss: 0.00045351
Epoch [72/300], Train Loss: 0.000376
Validation Loss: 0.00044757
Epoch [73/300], Train Loss: 0.000419
Validation Loss: 0.00044671
Epoch [74/300], Train Loss: 0.000373
Validation Loss: 0.00044202
Epoch [75/300], Train Loss: 0.000414
Validation Loss: 0.00043095
Epoch [76/300], Train Loss: 0.000371
Validation Loss: 0.00044293
Epoch [77/300], Train Loss: 0.000434
Validation Loss: 0.00039288
Epoch [78/300], Train Loss: 0.000363
Validation Loss: 0.00041881
Epoch [79/300], Train Loss: 0.000362
Validation Loss: 0.00038839
Epoch [80/300], Train Loss: 0.000357
Validation Loss: 0.00037946
Epoch [81/300], Train Loss: 0.000410
Validation Loss: 0.00052327
Epoch [82/300], Train Loss: 0.000451
Validation Loss: 0.00042937
Epoch [83/300], Train Loss: 0.000352
Validation Loss: 0.00037515
Epoch [84/300], Train Loss: 0.000364
Validation Loss: 0.00039946
Epoch [85/300], Train Loss: 0.000346
Validation Loss: 0.00037846
Epoch [86/300], Train Loss: 0.000347
Validation Loss: 0.00038444
Epoch [87/300], Train Loss: 0.000352
Validation Loss: 0.00037867
Epoch [88/300], Train Loss: 0.000499
Validation Loss: 0.00039141
Epoch [89/300], Train Loss: 0.000348
Validation Loss: 0.00037434
Epoch [90/300], Train Loss: 0.000377
Validation Loss: 0.00037925
Epoch [91/300], Train Loss: 0.000345
Validation Loss: 0.00037327
Epoch [92/300], Train Loss: 0.000337
Validation Loss: 0.00036796
Epoch [93/300], Train Loss: 0.000339
Validation Loss: 0.00038311
Epoch [94/300], Train Loss: 0.000374
Validation Loss: 0.00038641
Epoch [95/300], Train Loss: 0.000383
Validation Loss: 0.00039187
Epoch [96/300], Train Loss: 0.000341
Validation Loss: 0.00038869
Epoch [97/300], Train Loss: 0.000327
Validation Loss: 0.00036917
Epoch [98/300], Train Loss: 0.000338
Validation Loss: 0.00036884
Epoch [99/300], Train Loss: 0.000333
Validation Loss: 0.00036543
Epoch [100/300], Train Loss: 0.000339
Validation Loss: 0.00036827
Epoch [101/300], Train Loss: 0.000350
Validation Loss: 0.00036320
Epoch [102/300], Train Loss: 0.000322
Validation Loss: 0.00036718
Epoch [103/300], Train Loss: 0.000349
Validation Loss: 0.00035382
Epoch [104/300], Train Loss: 0.000501
Validation Loss: 0.00037746
Epoch [105/300], Train Loss: 0.000415
Validation Loss: 0.00036074
Epoch [106/300], Train Loss: 0.000335
Validation Loss: 0.00036635
Epoch [107/300], Train Loss: 0.000323
Validation Loss: 0.00035521
Epoch [108/300], Train Loss: 0.000328
Validation Loss: 0.00036029
Epoch [109/300], Train Loss: 0.000319
Validation Loss: 0.00035225
Epoch [110/300], Train Loss: 0.000319
Validation Loss: 0.00035543
Epoch [111/300], Train Loss: 0.000330
Validation Loss: 0.00038160
Epoch [112/300], Train Loss: 0.000330
Validation Loss: 0.00035998
Epoch [113/300], Train Loss: 0.000314
Validation Loss: 0.00035025
Epoch [114/300], Train Loss: 0.000368
Validation Loss: 0.00037671
Epoch [115/300], Train Loss: 0.000319
Validation Loss: 0.00035112
Epoch [116/300], Train Loss: 0.000310
Validation Loss: 0.00034082
Epoch [117/300], Train Loss: 0.000321
Validation Loss: 0.00033864
Epoch [118/300], Train Loss: 0.000307
Validation Loss: 0.00035358
Epoch [119/300], Train Loss: 0.000328
Validation Loss: 0.00034083
Epoch [120/300], Train Loss: 0.000311
Validation Loss: 0.00034806
Epoch [121/300], Train Loss: 0.000340
Validation Loss: 0.00036617
Epoch [122/300], Train Loss: 0.000309
Validation Loss: 0.00035634
Epoch [123/300], Train Loss: 0.000300
Validation Loss: 0.00034409
Epoch [124/300], Train Loss: 0.000301
Validation Loss: 0.00034388
Epoch [125/300], Train Loss: 0.000310
Validation Loss: 0.00036671
Epoch [126/300], Train Loss: 0.000296
Validation Loss: 0.00034331
Epoch [127/300], Train Loss: 0.000315
Validation Loss: 0.00034125
Early stopping triggered

Evaluating model for: Microwave
Run 63/72 completed in 1421.83 seconds with: {'MAE': np.float32(9.463331), 'MSE': np.float32(9150.17), 'RMSE': np.float32(95.65652), 'SAE': np.float32(0.2180304), 'NDE': np.float32(0.73179454)}

Run 64/72: hidden=512, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Microwave
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.000550
Validation Loss: 0.00078489
Epoch [2/300], Train Loss: 0.000540
Validation Loss: 0.00078877
Epoch [3/300], Train Loss: 0.000539
Validation Loss: 0.00078517
Epoch [4/300], Train Loss: 0.000538
Validation Loss: 0.00078500
Epoch [5/300], Train Loss: 0.000543
Validation Loss: 0.00078638
Epoch [6/300], Train Loss: 0.000546
Validation Loss: 0.00078487
Epoch [7/300], Train Loss: 0.000537
Validation Loss: 0.00078633
Epoch [8/300], Train Loss: 0.000537
Validation Loss: 0.00078476
Epoch [9/300], Train Loss: 0.000536
Validation Loss: 0.00078494
Epoch [10/300], Train Loss: 0.000536
Validation Loss: 0.00078512
Epoch [11/300], Train Loss: 0.000570
Validation Loss: 0.00078235
Epoch [12/300], Train Loss: 0.000536
Validation Loss: 0.00078782
Epoch [13/300], Train Loss: 0.000532
Validation Loss: 0.00076480
Epoch [14/300], Train Loss: 0.000527
Validation Loss: 0.00075406
Epoch [15/300], Train Loss: 0.000568
Validation Loss: 0.00078289
Epoch [16/300], Train Loss: 0.000600
Validation Loss: 0.00062970
Epoch [17/300], Train Loss: 0.000503
Validation Loss: 0.00060110
Epoch [18/300], Train Loss: 0.000474
Validation Loss: 0.00063923
Epoch [19/300], Train Loss: 0.000456
Validation Loss: 0.00060202
Epoch [20/300], Train Loss: 0.000463
Validation Loss: 0.00058408
Epoch [21/300], Train Loss: 0.000455
Validation Loss: 0.00058424
Epoch [22/300], Train Loss: 0.000472
Validation Loss: 0.00057496
Epoch [23/300], Train Loss: 0.000446
Validation Loss: 0.00061810
Epoch [24/300], Train Loss: 0.000463
Validation Loss: 0.00055345
Epoch [25/300], Train Loss: 0.000428
Validation Loss: 0.00069196
Epoch [26/300], Train Loss: 0.000531
Validation Loss: 0.00063035
Epoch [27/300], Train Loss: 0.000517
Validation Loss: 0.00061612
Epoch [28/300], Train Loss: 0.000458
Validation Loss: 0.00059243
Epoch [29/300], Train Loss: 0.000467
Validation Loss: 0.00060621
Epoch [30/300], Train Loss: 0.000452
Validation Loss: 0.00058069
Epoch [31/300], Train Loss: 0.000437
Validation Loss: 0.00057732
Epoch [32/300], Train Loss: 0.000436
Validation Loss: 0.00055794
Epoch [33/300], Train Loss: 0.000542
Validation Loss: 0.00057997
Epoch [34/300], Train Loss: 0.000527
Validation Loss: 0.00056959
Early stopping triggered

Evaluating model for: Microwave
Run 64/72 completed in 481.01 seconds with: {'MAE': np.float32(16.915155), 'MSE': np.float32(13080.239), 'RMSE': np.float32(114.36887), 'SAE': np.float32(0.0372426), 'NDE': np.float32(0.8749489)}

Run 65/72: hidden=512, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Microwave
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.000784
Validation Loss: 0.00064279
Epoch [2/300], Train Loss: 0.000641
Validation Loss: 0.00062427
Epoch [3/300], Train Loss: 0.000644
Validation Loss: 0.00062041
Epoch [4/300], Train Loss: 0.000639
Validation Loss: 0.00061355
Epoch [5/300], Train Loss: 0.000640
Validation Loss: 0.00061031
Epoch [6/300], Train Loss: 0.000630
Validation Loss: 0.00059867
Epoch [7/300], Train Loss: 0.000619
Validation Loss: 0.00058803
Epoch [8/300], Train Loss: 0.000616
Validation Loss: 0.00057912
Epoch [9/300], Train Loss: 0.000623
Validation Loss: 0.00056293
Epoch [10/300], Train Loss: 0.000583
Validation Loss: 0.00052255
Epoch [11/300], Train Loss: 0.000719
Validation Loss: 0.00054926
Epoch [12/300], Train Loss: 0.000584
Validation Loss: 0.00053219
Epoch [13/300], Train Loss: 0.000562
Validation Loss: 0.00050162
Epoch [14/300], Train Loss: 0.000541
Validation Loss: 0.00046703
Epoch [15/300], Train Loss: 0.000522
Validation Loss: 0.00044621
Epoch [16/300], Train Loss: 0.000510
Validation Loss: 0.00043625
Epoch [17/300], Train Loss: 0.000511
Validation Loss: 0.00049397
Epoch [18/300], Train Loss: 0.000518
Validation Loss: 0.00042659
Epoch [19/300], Train Loss: 0.000498
Validation Loss: 0.00042355
Epoch [20/300], Train Loss: 0.000497
Validation Loss: 0.00043057
Epoch [21/300], Train Loss: 0.000503
Validation Loss: 0.00042511
Epoch [22/300], Train Loss: 0.000521
Validation Loss: 0.00042295
Epoch [23/300], Train Loss: 0.000497
Validation Loss: 0.00044983
Epoch [24/300], Train Loss: 0.000524
Validation Loss: 0.00046649
Epoch [25/300], Train Loss: 0.000496
Validation Loss: 0.00046789
Epoch [26/300], Train Loss: 0.000512
Validation Loss: 0.00044679
Epoch [27/300], Train Loss: 0.000499
Validation Loss: 0.00041562
Epoch [28/300], Train Loss: 0.000486
Validation Loss: 0.00041556
Epoch [29/300], Train Loss: 0.000484
Validation Loss: 0.00041066
Epoch [30/300], Train Loss: 0.000484
Validation Loss: 0.00041238
Epoch [31/300], Train Loss: 0.000482
Validation Loss: 0.00040376
Epoch [32/300], Train Loss: 0.000486
Validation Loss: 0.00042006
Epoch [33/300], Train Loss: 0.000490
Validation Loss: 0.00041421
Epoch [34/300], Train Loss: 0.000489
Validation Loss: 0.00039732
Epoch [35/300], Train Loss: 0.000495
Validation Loss: 0.00039679
Epoch [36/300], Train Loss: 0.000475
Validation Loss: 0.00041486
Epoch [37/300], Train Loss: 0.000482
Validation Loss: 0.00039642
Epoch [38/300], Train Loss: 0.000482
Validation Loss: 0.00041657
Epoch [39/300], Train Loss: 0.000476
Validation Loss: 0.00041747
Epoch [40/300], Train Loss: 0.000479
Validation Loss: 0.00039115
Epoch [41/300], Train Loss: 0.000473
Validation Loss: 0.00039250
Epoch [42/300], Train Loss: 0.000469
Validation Loss: 0.00038128
Epoch [43/300], Train Loss: 0.000467
Validation Loss: 0.00037660
Epoch [44/300], Train Loss: 0.000477
Validation Loss: 0.00037687
Epoch [45/300], Train Loss: 0.000471
Validation Loss: 0.00036984
Epoch [46/300], Train Loss: 0.000459
Validation Loss: 0.00037527
Epoch [47/300], Train Loss: 0.000453
Validation Loss: 0.00038391
Epoch [48/300], Train Loss: 0.000458
Validation Loss: 0.00037543
Epoch [49/300], Train Loss: 0.000446
Validation Loss: 0.00036938
Epoch [50/300], Train Loss: 0.000442
Validation Loss: 0.00038568
Epoch [51/300], Train Loss: 0.000445
Validation Loss: 0.00036960
Epoch [52/300], Train Loss: 0.000445
Validation Loss: 0.00037923
Epoch [53/300], Train Loss: 0.000447
Validation Loss: 0.00041127
Epoch [54/300], Train Loss: 0.000448
Validation Loss: 0.00038264
Epoch [55/300], Train Loss: 0.000446
Validation Loss: 0.00038219
Epoch [56/300], Train Loss: 0.000439
Validation Loss: 0.00036568
Epoch [57/300], Train Loss: 0.000431
Validation Loss: 0.00036055
Epoch [58/300], Train Loss: 0.000442
Validation Loss: 0.00035603
Epoch [59/300], Train Loss: 0.000431
Validation Loss: 0.00037517
Epoch [60/300], Train Loss: 0.000449
Validation Loss: 0.00043154
Epoch [61/300], Train Loss: 0.000442
Validation Loss: 0.00036137
Epoch [62/300], Train Loss: 0.000460
Validation Loss: 0.00035248
Epoch [63/300], Train Loss: 0.000420
Validation Loss: 0.00035357
Epoch [64/300], Train Loss: 0.000419
Validation Loss: 0.00035249
Epoch [65/300], Train Loss: 0.000421
Validation Loss: 0.00037176
Epoch [66/300], Train Loss: 0.000432
Validation Loss: 0.00035172
Epoch [67/300], Train Loss: 0.000426
Validation Loss: 0.00035011
Epoch [68/300], Train Loss: 0.000419
Validation Loss: 0.00036310
Epoch [69/300], Train Loss: 0.000427
Validation Loss: 0.00034233
Epoch [70/300], Train Loss: 0.000416
Validation Loss: 0.00035689
Epoch [71/300], Train Loss: 0.000411
Validation Loss: 0.00034743
Epoch [72/300], Train Loss: 0.000418
Validation Loss: 0.00036827
Epoch [73/300], Train Loss: 0.000409
Validation Loss: 0.00033175
Epoch [74/300], Train Loss: 0.000410
Validation Loss: 0.00034133
Epoch [75/300], Train Loss: 0.000414
Validation Loss: 0.00036254
Epoch [76/300], Train Loss: 0.000406
Validation Loss: 0.00033236
Epoch [77/300], Train Loss: 0.000422
Validation Loss: 0.00035219
Epoch [78/300], Train Loss: 0.000403
Validation Loss: 0.00034561
Epoch [79/300], Train Loss: 0.000407
Validation Loss: 0.00034965
Epoch [80/300], Train Loss: 0.000417
Validation Loss: 0.00032726
Epoch [81/300], Train Loss: 0.000403
Validation Loss: 0.00033603
Epoch [82/300], Train Loss: 0.000397
Validation Loss: 0.00035016
Epoch [83/300], Train Loss: 0.000406
Validation Loss: 0.00033013
Epoch [84/300], Train Loss: 0.000404
Validation Loss: 0.00032885
Epoch [85/300], Train Loss: 0.000397
Validation Loss: 0.00032703
Epoch [86/300], Train Loss: 0.000398
Validation Loss: 0.00032912
Epoch [87/300], Train Loss: 0.000393
Validation Loss: 0.00032139
Epoch [88/300], Train Loss: 0.000392
Validation Loss: 0.00033876
Epoch [89/300], Train Loss: 0.000395
Validation Loss: 0.00031423
Epoch [90/300], Train Loss: 0.000397
Validation Loss: 0.00034541
Epoch [91/300], Train Loss: 0.000391
Validation Loss: 0.00032308
Epoch [92/300], Train Loss: 0.000395
Validation Loss: 0.00032280
Epoch [93/300], Train Loss: 0.000393
Validation Loss: 0.00030908
Epoch [94/300], Train Loss: 0.000389
Validation Loss: 0.00030747
Epoch [95/300], Train Loss: 0.000386
Validation Loss: 0.00030762
Epoch [96/300], Train Loss: 0.000388
Validation Loss: 0.00032633
Epoch [97/300], Train Loss: 0.000394
Validation Loss: 0.00029812
Epoch [98/300], Train Loss: 0.000385
Validation Loss: 0.00029700
Epoch [99/300], Train Loss: 0.000386
Validation Loss: 0.00034396
Epoch [100/300], Train Loss: 0.000393
Validation Loss: 0.00028988
Epoch [101/300], Train Loss: 0.000385
Validation Loss: 0.00032027
Epoch [102/300], Train Loss: 0.000377
Validation Loss: 0.00030022
Epoch [103/300], Train Loss: 0.000383
Validation Loss: 0.00031601
Epoch [104/300], Train Loss: 0.000378
Validation Loss: 0.00026526
Epoch [105/300], Train Loss: 0.000375
Validation Loss: 0.00026721
Epoch [106/300], Train Loss: 0.000371
Validation Loss: 0.00026567
Epoch [107/300], Train Loss: 0.000366
Validation Loss: 0.00025117
Epoch [108/300], Train Loss: 0.000367
Validation Loss: 0.00025262
Epoch [109/300], Train Loss: 0.000368
Validation Loss: 0.00024419
Epoch [110/300], Train Loss: 0.000365
Validation Loss: 0.00025422
Epoch [111/300], Train Loss: 0.000385
Validation Loss: 0.00025722
Epoch [112/300], Train Loss: 0.000385
Validation Loss: 0.00026139
Epoch [113/300], Train Loss: 0.000375
Validation Loss: 0.00029788
Epoch [114/300], Train Loss: 0.000370
Validation Loss: 0.00029074
Epoch [115/300], Train Loss: 0.000367
Validation Loss: 0.00024146
Epoch [116/300], Train Loss: 0.000363
Validation Loss: 0.00024306
Epoch [117/300], Train Loss: 0.000354
Validation Loss: 0.00026030
Epoch [118/300], Train Loss: 0.000360
Validation Loss: 0.00025334
Epoch [119/300], Train Loss: 0.000352
Validation Loss: 0.00028152
Epoch [120/300], Train Loss: 0.000354
Validation Loss: 0.00024069
Epoch [121/300], Train Loss: 0.000365
Validation Loss: 0.00024312
Epoch [122/300], Train Loss: 0.000353
Validation Loss: 0.00023858
Epoch [123/300], Train Loss: 0.000353
Validation Loss: 0.00025300
Epoch [124/300], Train Loss: 0.000351
Validation Loss: 0.00023080
Epoch [125/300], Train Loss: 0.000346
Validation Loss: 0.00024539
Epoch [126/300], Train Loss: 0.000358
Validation Loss: 0.00024028
Epoch [127/300], Train Loss: 0.000352
Validation Loss: 0.00024036
Epoch [128/300], Train Loss: 0.000346
Validation Loss: 0.00023036
Epoch [129/300], Train Loss: 0.000342
Validation Loss: 0.00022980
Epoch [130/300], Train Loss: 0.000347
Validation Loss: 0.00022725
Epoch [131/300], Train Loss: 0.000346
Validation Loss: 0.00024718
Epoch [132/300], Train Loss: 0.000339
Validation Loss: 0.00023344
Epoch [133/300], Train Loss: 0.000347
Validation Loss: 0.00024507
Epoch [134/300], Train Loss: 0.000354
Validation Loss: 0.00022646
Epoch [135/300], Train Loss: 0.000356
Validation Loss: 0.00023678
Epoch [136/300], Train Loss: 0.000344
Validation Loss: 0.00023722
Epoch [137/300], Train Loss: 0.000337
Validation Loss: 0.00024618
Epoch [138/300], Train Loss: 0.000338
Validation Loss: 0.00022740
Epoch [139/300], Train Loss: 0.000344
Validation Loss: 0.00022712
Epoch [140/300], Train Loss: 0.000341
Validation Loss: 0.00022760
Epoch [141/300], Train Loss: 0.000332
Validation Loss: 0.00022895
Epoch [142/300], Train Loss: 0.000342
Validation Loss: 0.00025286
Epoch [143/300], Train Loss: 0.000485
Validation Loss: 0.00049433
Epoch [144/300], Train Loss: 0.000473
Validation Loss: 0.00042272
Early stopping triggered

Evaluating model for: Microwave
Run 65/72 completed in 1493.99 seconds with: {'MAE': np.float32(11.405955), 'MSE': np.float32(6704.5933), 'RMSE': np.float32(81.881584), 'SAE': np.float32(0.10916172), 'NDE': np.float32(0.7720298)}

Run 66/72: hidden=512, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Microwave
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.000643
Validation Loss: 0.00062844
Epoch [2/300], Train Loss: 0.000635
Validation Loss: 0.00062360
Epoch [3/300], Train Loss: 0.000641
Validation Loss: 0.00061805
Epoch [4/300], Train Loss: 0.000637
Validation Loss: 0.00061883
Epoch [5/300], Train Loss: 0.000642
Validation Loss: 0.00061219
Epoch [6/300], Train Loss: 0.000632
Validation Loss: 0.00060763
Epoch [7/300], Train Loss: 0.000623
Validation Loss: 0.00060137
Epoch [8/300], Train Loss: 0.000619
Validation Loss: 0.00058723
Epoch [9/300], Train Loss: 0.000622
Validation Loss: 0.00056802
Epoch [10/300], Train Loss: 0.000567
Validation Loss: 0.00047233
Epoch [11/300], Train Loss: 0.000539
Validation Loss: 0.00050693
Epoch [12/300], Train Loss: 0.000591
Validation Loss: 0.00059404
Epoch [13/300], Train Loss: 0.000599
Validation Loss: 0.00053172
Epoch [14/300], Train Loss: 0.000541
Validation Loss: 0.00046534
Epoch [15/300], Train Loss: 0.000513
Validation Loss: 0.00046511
Epoch [16/300], Train Loss: 0.000509
Validation Loss: 0.00045586
Epoch [17/300], Train Loss: 0.000503
Validation Loss: 0.00046466
Epoch [18/300], Train Loss: 0.000506
Validation Loss: 0.00044279
Epoch [19/300], Train Loss: 0.000498
Validation Loss: 0.00044829
Epoch [20/300], Train Loss: 0.000501
Validation Loss: 0.00044757
Epoch [21/300], Train Loss: 0.000508
Validation Loss: 0.00044193
Epoch [22/300], Train Loss: 0.000518
Validation Loss: 0.00043882
Epoch [23/300], Train Loss: 0.000489
Validation Loss: 0.00043547
Epoch [24/300], Train Loss: 0.000510
Validation Loss: 0.00046466
Epoch [25/300], Train Loss: 0.000485
Validation Loss: 0.00045616
Epoch [26/300], Train Loss: 0.000495
Validation Loss: 0.00045111
Epoch [27/300], Train Loss: 0.000492
Validation Loss: 0.00037839
Epoch [28/300], Train Loss: 0.000471
Validation Loss: 0.00036726
Epoch [29/300], Train Loss: 0.000466
Validation Loss: 0.00037549
Epoch [30/300], Train Loss: 0.000468
Validation Loss: 0.00036699
Epoch [31/300], Train Loss: 0.000461
Validation Loss: 0.00035134
Epoch [32/300], Train Loss: 0.000463
Validation Loss: 0.00039915
Epoch [33/300], Train Loss: 0.000465
Validation Loss: 0.00034105
Epoch [34/300], Train Loss: 0.000465
Validation Loss: 0.00033657
Epoch [35/300], Train Loss: 0.000465
Validation Loss: 0.00032563
Epoch [36/300], Train Loss: 0.000451
Validation Loss: 0.00037469
Epoch [37/300], Train Loss: 0.000456
Validation Loss: 0.00033393
Epoch [38/300], Train Loss: 0.000448
Validation Loss: 0.00036214
Epoch [39/300], Train Loss: 0.000445
Validation Loss: 0.00036408
Epoch [40/300], Train Loss: 0.000441
Validation Loss: 0.00031559
Epoch [41/300], Train Loss: 0.000432
Validation Loss: 0.00034416
Epoch [42/300], Train Loss: 0.000432
Validation Loss: 0.00031152
Epoch [43/300], Train Loss: 0.000429
Validation Loss: 0.00032518
Epoch [44/300], Train Loss: 0.000433
Validation Loss: 0.00035792
Epoch [45/300], Train Loss: 0.000464
Validation Loss: 0.00031861
Epoch [46/300], Train Loss: 0.000437
Validation Loss: 0.00031829
Epoch [47/300], Train Loss: 0.000427
Validation Loss: 0.00029100
Epoch [48/300], Train Loss: 0.000429
Validation Loss: 0.00028648
Epoch [49/300], Train Loss: 0.000412
Validation Loss: 0.00030802
Epoch [50/300], Train Loss: 0.000412
Validation Loss: 0.00032857
Epoch [51/300], Train Loss: 0.000411
Validation Loss: 0.00029566
Epoch [52/300], Train Loss: 0.000412
Validation Loss: 0.00029172
Epoch [53/300], Train Loss: 0.000418
Validation Loss: 0.00034276
Epoch [54/300], Train Loss: 0.000416
Validation Loss: 0.00032006
Epoch [55/300], Train Loss: 0.000414
Validation Loss: 0.00031305
Epoch [56/300], Train Loss: 0.000428
Validation Loss: 0.00031434
Epoch [57/300], Train Loss: 0.000395
Validation Loss: 0.00027857
Epoch [58/300], Train Loss: 0.000403
Validation Loss: 0.00026765
Epoch [59/300], Train Loss: 0.000402
Validation Loss: 0.00030381
Epoch [60/300], Train Loss: 0.000432
Validation Loss: 0.00043246
Epoch [61/300], Train Loss: 0.000422
Validation Loss: 0.00029307
Epoch [62/300], Train Loss: 0.000434
Validation Loss: 0.00035572
Epoch [63/300], Train Loss: 0.000388
Validation Loss: 0.00027212
Epoch [64/300], Train Loss: 0.000387
Validation Loss: 0.00028044
Epoch [65/300], Train Loss: 0.000390
Validation Loss: 0.00030075
Epoch [66/300], Train Loss: 0.000398
Validation Loss: 0.00027941
Epoch [67/300], Train Loss: 0.000387
Validation Loss: 0.00026322
Epoch [68/300], Train Loss: 0.000391
Validation Loss: 0.00028901
Epoch [69/300], Train Loss: 0.000395
Validation Loss: 0.00028620
Epoch [70/300], Train Loss: 0.000388
Validation Loss: 0.00027566
Epoch [71/300], Train Loss: 0.000376
Validation Loss: 0.00026487
Epoch [72/300], Train Loss: 0.000381
Validation Loss: 0.00027359
Epoch [73/300], Train Loss: 0.000373
Validation Loss: 0.00025847
Epoch [74/300], Train Loss: 0.000376
Validation Loss: 0.00027402
Epoch [75/300], Train Loss: 0.000382
Validation Loss: 0.00030596
Epoch [76/300], Train Loss: 0.000374
Validation Loss: 0.00024947
Epoch [77/300], Train Loss: 0.000378
Validation Loss: 0.00026160
Epoch [78/300], Train Loss: 0.000367
Validation Loss: 0.00025995
Epoch [79/300], Train Loss: 0.000373
Validation Loss: 0.00025061
Epoch [80/300], Train Loss: 0.000385
Validation Loss: 0.00025469
Epoch [81/300], Train Loss: 0.000374
Validation Loss: 0.00026313
Epoch [82/300], Train Loss: 0.000364
Validation Loss: 0.00027892
Epoch [83/300], Train Loss: 0.000372
Validation Loss: 0.00025577
Epoch [84/300], Train Loss: 0.000370
Validation Loss: 0.00025575
Epoch [85/300], Train Loss: 0.000374
Validation Loss: 0.00026472
Epoch [86/300], Train Loss: 0.000362
Validation Loss: 0.00024899
Epoch [87/300], Train Loss: 0.000361
Validation Loss: 0.00025626
Epoch [88/300], Train Loss: 0.000358
Validation Loss: 0.00029712
Epoch [89/300], Train Loss: 0.000368
Validation Loss: 0.00023733
Epoch [90/300], Train Loss: 0.000368
Validation Loss: 0.00026023
Epoch [91/300], Train Loss: 0.000361
Validation Loss: 0.00024099
Epoch [92/300], Train Loss: 0.000359
Validation Loss: 0.00026406
Epoch [93/300], Train Loss: 0.000356
Validation Loss: 0.00024425
Epoch [94/300], Train Loss: 0.000357
Validation Loss: 0.00024600
Epoch [95/300], Train Loss: 0.000358
Validation Loss: 0.00024737
Epoch [96/300], Train Loss: 0.000353
Validation Loss: 0.00025587
Epoch [97/300], Train Loss: 0.000359
Validation Loss: 0.00023353
Epoch [98/300], Train Loss: 0.000357
Validation Loss: 0.00023290
Epoch [99/300], Train Loss: 0.000359
Validation Loss: 0.00030264
Epoch [100/300], Train Loss: 0.000362
Validation Loss: 0.00024247
Epoch [101/300], Train Loss: 0.000352
Validation Loss: 0.00026645
Epoch [102/300], Train Loss: 0.000350
Validation Loss: 0.00024337
Epoch [103/300], Train Loss: 0.000354
Validation Loss: 0.00025344
Epoch [104/300], Train Loss: 0.000349
Validation Loss: 0.00024343
Epoch [105/300], Train Loss: 0.000352
Validation Loss: 0.00024072
Epoch [106/300], Train Loss: 0.000351
Validation Loss: 0.00024651
Epoch [107/300], Train Loss: 0.000344
Validation Loss: 0.00024085
Epoch [108/300], Train Loss: 0.000345
Validation Loss: 0.00022583
Epoch [109/300], Train Loss: 0.000346
Validation Loss: 0.00023806
Epoch [110/300], Train Loss: 0.000344
Validation Loss: 0.00024142
Epoch [111/300], Train Loss: 0.000354
Validation Loss: 0.00023239
Epoch [112/300], Train Loss: 0.000361
Validation Loss: 0.00028689
Epoch [113/300], Train Loss: 0.000350
Validation Loss: 0.00024440
Epoch [114/300], Train Loss: 0.000348
Validation Loss: 0.00024898
Epoch [115/300], Train Loss: 0.000344
Validation Loss: 0.00022915
Epoch [116/300], Train Loss: 0.000343
Validation Loss: 0.00022730
Epoch [117/300], Train Loss: 0.000337
Validation Loss: 0.00025489
Epoch [118/300], Train Loss: 0.000345
Validation Loss: 0.00024504
Early stopping triggered

Evaluating model for: Microwave
Run 66/72 completed in 1631.32 seconds with: {'MAE': np.float32(7.842779), 'MSE': np.float32(4791.9517), 'RMSE': np.float32(69.22392), 'SAE': np.float32(0.015443979), 'NDE': np.float32(0.65268373)}

Run 67/72: hidden=512, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Microwave
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.000826
Validation Loss: 0.00064156
Epoch [2/300], Train Loss: 0.000644
Validation Loss: 0.00062916
Epoch [3/300], Train Loss: 0.000650
Validation Loss: 0.00062956
Epoch [4/300], Train Loss: 0.000648
Validation Loss: 0.00062838
Epoch [5/300], Train Loss: 0.000655
Validation Loss: 0.00062816
Epoch [6/300], Train Loss: 0.000649
Validation Loss: 0.00062798
Epoch [7/300], Train Loss: 0.000644
Validation Loss: 0.00062725
Epoch [8/300], Train Loss: 0.000648
Validation Loss: 0.00062667
Epoch [9/300], Train Loss: 0.000662
Validation Loss: 0.00062482
Epoch [10/300], Train Loss: 0.000634
Validation Loss: 0.00061835
Epoch [11/300], Train Loss: 0.000629
Validation Loss: 0.00061316
Epoch [12/300], Train Loss: 0.000633
Validation Loss: 0.00060781
Epoch [13/300], Train Loss: 0.000615
Validation Loss: 0.00057361
Epoch [14/300], Train Loss: 0.000564
Validation Loss: 0.00047166
Epoch [15/300], Train Loss: 0.000524
Validation Loss: 0.00045419
Epoch [16/300], Train Loss: 0.000524
Validation Loss: 0.00051134
Epoch [17/300], Train Loss: 0.000523
Validation Loss: 0.00047047
Epoch [18/300], Train Loss: 0.000521
Validation Loss: 0.00045099
Epoch [19/300], Train Loss: 0.000515
Validation Loss: 0.00045943
Epoch [20/300], Train Loss: 0.000516
Validation Loss: 0.00044175
Epoch [21/300], Train Loss: 0.000523
Validation Loss: 0.00046148
Epoch [22/300], Train Loss: 0.000533
Validation Loss: 0.00043643
Epoch [23/300], Train Loss: 0.000504
Validation Loss: 0.00045568
Epoch [24/300], Train Loss: 0.000534
Validation Loss: 0.00049782
Epoch [25/300], Train Loss: 0.000509
Validation Loss: 0.00048631
Epoch [26/300], Train Loss: 0.000526
Validation Loss: 0.00047106
Epoch [27/300], Train Loss: 0.000512
Validation Loss: 0.00042264
Epoch [28/300], Train Loss: 0.000497
Validation Loss: 0.00042924
Epoch [29/300], Train Loss: 0.000494
Validation Loss: 0.00042629
Epoch [30/300], Train Loss: 0.000495
Validation Loss: 0.00042245
Epoch [31/300], Train Loss: 0.000490
Validation Loss: 0.00041306
Epoch [32/300], Train Loss: 0.000496
Validation Loss: 0.00043222
Epoch [33/300], Train Loss: 0.000501
Validation Loss: 0.00041303
Epoch [34/300], Train Loss: 0.000502
Validation Loss: 0.00041171
Epoch [35/300], Train Loss: 0.000503
Validation Loss: 0.00041442
Epoch [36/300], Train Loss: 0.000484
Validation Loss: 0.00043673
Epoch [37/300], Train Loss: 0.000491
Validation Loss: 0.00039714
Epoch [38/300], Train Loss: 0.000483
Validation Loss: 0.00041200
Epoch [39/300], Train Loss: 0.000481
Validation Loss: 0.00037127
Epoch [40/300], Train Loss: 0.000486
Validation Loss: 0.00036636
Epoch [41/300], Train Loss: 0.000470
Validation Loss: 0.00036909
Epoch [42/300], Train Loss: 0.000470
Validation Loss: 0.00034093
Epoch [43/300], Train Loss: 0.000468
Validation Loss: 0.00032795
Epoch [44/300], Train Loss: 0.000473
Validation Loss: 0.00034058
Epoch [45/300], Train Loss: 0.000472
Validation Loss: 0.00035892
Epoch [46/300], Train Loss: 0.000459
Validation Loss: 0.00033968
Epoch [47/300], Train Loss: 0.000455
Validation Loss: 0.00032341
Epoch [48/300], Train Loss: 0.000463
Validation Loss: 0.00032993
Epoch [49/300], Train Loss: 0.000449
Validation Loss: 0.00033200
Epoch [50/300], Train Loss: 0.000448
Validation Loss: 0.00034429
Epoch [51/300], Train Loss: 0.000448
Validation Loss: 0.00031427
Epoch [52/300], Train Loss: 0.000456
Validation Loss: 0.00036240
Epoch [53/300], Train Loss: 0.000453
Validation Loss: 0.00034659
Epoch [54/300], Train Loss: 0.000476
Validation Loss: 0.00043276
Epoch [55/300], Train Loss: 0.000458
Validation Loss: 0.00036708
Epoch [56/300], Train Loss: 0.000438
Validation Loss: 0.00030244
Epoch [57/300], Train Loss: 0.000430
Validation Loss: 0.00032287
Epoch [58/300], Train Loss: 0.000457
Validation Loss: 0.00040477
Epoch [59/300], Train Loss: 0.000475
Validation Loss: 0.00039274
Epoch [60/300], Train Loss: 0.000468
Validation Loss: 0.00040545
Epoch [61/300], Train Loss: 0.000453
Validation Loss: 0.00034403
Epoch [62/300], Train Loss: 0.000479
Validation Loss: 0.00031970
Epoch [63/300], Train Loss: 0.000456
Validation Loss: 0.00039529
Epoch [64/300], Train Loss: 0.000455
Validation Loss: 0.00037150
Epoch [65/300], Train Loss: 0.000454
Validation Loss: 0.00041155
Epoch [66/300], Train Loss: 0.000461
Validation Loss: 0.00036869
Early stopping triggered

Evaluating model for: Microwave
Run 67/72 completed in 1180.41 seconds with: {'MAE': np.float32(14.2595625), 'MSE': np.float32(6677.7705), 'RMSE': np.float32(81.71763), 'SAE': np.float32(0.37888056), 'NDE': np.float32(0.7704868)}

Run 68/72: hidden=512, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Microwave
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.000683
Validation Loss: 0.00063284
Epoch [2/300], Train Loss: 0.000641
Validation Loss: 0.00062844
Epoch [3/300], Train Loss: 0.000649
Validation Loss: 0.00062850
Epoch [4/300], Train Loss: 0.000648
Validation Loss: 0.00062825
Epoch [5/300], Train Loss: 0.000655
Validation Loss: 0.00063039
Epoch [6/300], Train Loss: 0.000650
Validation Loss: 0.00062787
Epoch [7/300], Train Loss: 0.000644
Validation Loss: 0.00062749
Epoch [8/300], Train Loss: 0.000647
Validation Loss: 0.00062657
Epoch [9/300], Train Loss: 0.000661
Validation Loss: 0.00062344
Epoch [10/300], Train Loss: 0.000631
Validation Loss: 0.00061762
Epoch [11/300], Train Loss: 0.000629
Validation Loss: 0.00061425
Epoch [12/300], Train Loss: 0.000635
Validation Loss: 0.00061656
Epoch [13/300], Train Loss: 0.000625
Validation Loss: 0.00060091
Epoch [14/300], Train Loss: 0.000602
Validation Loss: 0.00054139
Epoch [15/300], Train Loss: 0.000543
Validation Loss: 0.00045464
Epoch [16/300], Train Loss: 0.000555
Validation Loss: 0.00046778
Epoch [17/300], Train Loss: 0.000517
Validation Loss: 0.00045741
Epoch [18/300], Train Loss: 0.000516
Validation Loss: 0.00044812
Epoch [19/300], Train Loss: 0.000510
Validation Loss: 0.00045367
Epoch [20/300], Train Loss: 0.000513
Validation Loss: 0.00049652
Epoch [21/300], Train Loss: 0.000529
Validation Loss: 0.00044664
Epoch [22/300], Train Loss: 0.000534
Validation Loss: 0.00043934
Epoch [23/300], Train Loss: 0.000498
Validation Loss: 0.00043414
Epoch [24/300], Train Loss: 0.000520
Validation Loss: 0.00046714
Epoch [25/300], Train Loss: 0.000496
Validation Loss: 0.00045465
Epoch [26/300], Train Loss: 0.000503
Validation Loss: 0.00046304
Epoch [27/300], Train Loss: 0.000518
Validation Loss: 0.00046655
Epoch [28/300], Train Loss: 0.000499
Validation Loss: 0.00041572
Epoch [29/300], Train Loss: 0.000486
Validation Loss: 0.00041467
Epoch [30/300], Train Loss: 0.000486
Validation Loss: 0.00040026
Epoch [31/300], Train Loss: 0.000481
Validation Loss: 0.00039268
Epoch [32/300], Train Loss: 0.000482
Validation Loss: 0.00042916
Epoch [33/300], Train Loss: 0.000482
Validation Loss: 0.00041922
Epoch [34/300], Train Loss: 0.000498
Validation Loss: 0.00042715
Epoch [35/300], Train Loss: 0.000498
Validation Loss: 0.00038110
Epoch [36/300], Train Loss: 0.000471
Validation Loss: 0.00040234
Epoch [37/300], Train Loss: 0.000475
Validation Loss: 0.00033997
Epoch [38/300], Train Loss: 0.000464
Validation Loss: 0.00035791
Epoch [39/300], Train Loss: 0.000459
Validation Loss: 0.00034032
Epoch [40/300], Train Loss: 0.000459
Validation Loss: 0.00031983
Epoch [41/300], Train Loss: 0.000452
Validation Loss: 0.00036404
Epoch [42/300], Train Loss: 0.000457
Validation Loss: 0.00031740
Epoch [43/300], Train Loss: 0.000454
Validation Loss: 0.00030806
Epoch [44/300], Train Loss: 0.000448
Validation Loss: 0.00032094
Epoch [45/300], Train Loss: 0.000462
Validation Loss: 0.00030418
Epoch [46/300], Train Loss: 0.000434
Validation Loss: 0.00031826
Epoch [47/300], Train Loss: 0.000435
Validation Loss: 0.00030387
Epoch [48/300], Train Loss: 0.000447
Validation Loss: 0.00029745
Epoch [49/300], Train Loss: 0.000437
Validation Loss: 0.00039243
Epoch [50/300], Train Loss: 0.000450
Validation Loss: 0.00036524
Epoch [51/300], Train Loss: 0.000431
Validation Loss: 0.00029485
Epoch [52/300], Train Loss: 0.000431
Validation Loss: 0.00030622
Epoch [53/300], Train Loss: 0.000422
Validation Loss: 0.00029340
Epoch [54/300], Train Loss: 0.000442
Validation Loss: 0.00040463
Epoch [55/300], Train Loss: 0.000431
Validation Loss: 0.00036155
Epoch [56/300], Train Loss: 0.000425
Validation Loss: 0.00030029
Epoch [57/300], Train Loss: 0.000464
Validation Loss: 0.00033187
Epoch [58/300], Train Loss: 0.000421
Validation Loss: 0.00028462
Epoch [59/300], Train Loss: 0.000418
Validation Loss: 0.00032112
Epoch [60/300], Train Loss: 0.000468
Validation Loss: 0.00044109
Epoch [61/300], Train Loss: 0.000454
Validation Loss: 0.00029301
Epoch [62/300], Train Loss: 0.000459
Validation Loss: 0.00027863
Epoch [63/300], Train Loss: 0.000414
Validation Loss: 0.00028515
Epoch [64/300], Train Loss: 0.000411
Validation Loss: 0.00027435
Epoch [65/300], Train Loss: 0.000411
Validation Loss: 0.00031095
Epoch [66/300], Train Loss: 0.000416
Validation Loss: 0.00028264
Epoch [67/300], Train Loss: 0.000428
Validation Loss: 0.00030749
Epoch [68/300], Train Loss: 0.000466
Validation Loss: 0.00039358
Epoch [69/300], Train Loss: 0.000493
Validation Loss: 0.00033450
Epoch [70/300], Train Loss: 0.000451
Validation Loss: 0.00030986
Epoch [71/300], Train Loss: 0.000434
Validation Loss: 0.00027627
Epoch [72/300], Train Loss: 0.000433
Validation Loss: 0.00029019
Epoch [73/300], Train Loss: 0.000421
Validation Loss: 0.00030714
Epoch [74/300], Train Loss: 0.000415
Validation Loss: 0.00028107
Early stopping triggered

Evaluating model for: Microwave
Run 68/72 completed in 1716.18 seconds with: {'MAE': np.float32(10.537689), 'MSE': np.float32(6547.097), 'RMSE': np.float32(80.91413), 'SAE': np.float32(0.09167559), 'NDE': np.float32(0.7629094)}

Run 69/72: hidden=512, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Microwave
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.000847
Validation Loss: 0.00031697
Epoch [2/300], Train Loss: 0.000681
Validation Loss: 0.00029026
Epoch [3/300], Train Loss: 0.000670
Validation Loss: 0.00027657
Epoch [4/300], Train Loss: 0.000666
Validation Loss: 0.00027650
Epoch [5/300], Train Loss: 0.000666
Validation Loss: 0.00027655
Epoch [6/300], Train Loss: 0.000662
Validation Loss: 0.00027578
Epoch [7/300], Train Loss: 0.000658
Validation Loss: 0.00027507
Epoch [8/300], Train Loss: 0.000655
Validation Loss: 0.00027457
Epoch [9/300], Train Loss: 0.000655
Validation Loss: 0.00027572
Epoch [10/300], Train Loss: 0.000652
Validation Loss: 0.00027414
Epoch [11/300], Train Loss: 0.000649
Validation Loss: 0.00027462
Epoch [12/300], Train Loss: 0.000647
Validation Loss: 0.00027449
Epoch [13/300], Train Loss: 0.000646
Validation Loss: 0.00027459
Epoch [14/300], Train Loss: 0.000642
Validation Loss: 0.00027642
Epoch [15/300], Train Loss: 0.000640
Validation Loss: 0.00027717
Epoch [16/300], Train Loss: 0.000634
Validation Loss: 0.00027580
Epoch [17/300], Train Loss: 0.000630
Validation Loss: 0.00027368
Epoch [18/300], Train Loss: 0.000618
Validation Loss: 0.00027223
Epoch [19/300], Train Loss: 0.000608
Validation Loss: 0.00027081
Epoch [20/300], Train Loss: 0.000590
Validation Loss: 0.00026248
Epoch [21/300], Train Loss: 0.000561
Validation Loss: 0.00026339
Epoch [22/300], Train Loss: 0.000877
Validation Loss: 0.00026843
Epoch [23/300], Train Loss: 0.000633
Validation Loss: 0.00026717
Epoch [24/300], Train Loss: 0.000617
Validation Loss: 0.00026532
Epoch [25/300], Train Loss: 0.000605
Validation Loss: 0.00026699
Epoch [26/300], Train Loss: 0.000599
Validation Loss: 0.00026338
Epoch [27/300], Train Loss: 0.000592
Validation Loss: 0.00026290
Epoch [28/300], Train Loss: 0.000583
Validation Loss: 0.00026226
Epoch [29/300], Train Loss: 0.000577
Validation Loss: 0.00026072
Epoch [30/300], Train Loss: 0.000571
Validation Loss: 0.00025868
Epoch [31/300], Train Loss: 0.000565
Validation Loss: 0.00026051
Epoch [32/300], Train Loss: 0.000557
Validation Loss: 0.00025900
Epoch [33/300], Train Loss: 0.000554
Validation Loss: 0.00025864
Epoch [34/300], Train Loss: 0.000547
Validation Loss: 0.00025801
Epoch [35/300], Train Loss: 0.000540
Validation Loss: 0.00026103
Epoch [36/300], Train Loss: 0.000533
Validation Loss: 0.00025913
Epoch [37/300], Train Loss: 0.000532
Validation Loss: 0.00025980
Epoch [38/300], Train Loss: 0.000527
Validation Loss: 0.00025590
Epoch [39/300], Train Loss: 0.000519
Validation Loss: 0.00027469
Epoch [40/300], Train Loss: 0.000574
Validation Loss: 0.00025339
Epoch [41/300], Train Loss: 0.000528
Validation Loss: 0.00026422
Epoch [42/300], Train Loss: 0.000515
Validation Loss: 0.00026209
Epoch [43/300], Train Loss: 0.000506
Validation Loss: 0.00025903
Epoch [44/300], Train Loss: 0.000501
Validation Loss: 0.00026084
Epoch [45/300], Train Loss: 0.000503
Validation Loss: 0.00025381
Epoch [46/300], Train Loss: 0.000509
Validation Loss: 0.00025565
Epoch [47/300], Train Loss: 0.000509
Validation Loss: 0.00025492
Epoch [48/300], Train Loss: 0.000501
Validation Loss: 0.00025428
Epoch [49/300], Train Loss: 0.000500
Validation Loss: 0.00025715
Epoch [50/300], Train Loss: 0.000498
Validation Loss: 0.00025753
Early stopping triggered

Evaluating model for: Microwave
Run 69/72 completed in 266.10 seconds with: {'MAE': np.float32(13.173975), 'MSE': np.float32(10375.202), 'RMSE': np.float32(101.858734), 'SAE': np.float32(0.16295506), 'NDE': np.float32(0.83167315)}

Run 70/72: hidden=512, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Microwave
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.000725
Validation Loss: 0.00029285
Epoch [2/300], Train Loss: 0.000671
Validation Loss: 0.00027845
Epoch [3/300], Train Loss: 0.000664
Validation Loss: 0.00027908
Epoch [4/300], Train Loss: 0.000663
Validation Loss: 0.00027502
Epoch [5/300], Train Loss: 0.000665
Validation Loss: 0.00027441
Epoch [6/300], Train Loss: 0.000661
Validation Loss: 0.00027567
Epoch [7/300], Train Loss: 0.000658
Validation Loss: 0.00027382
Epoch [8/300], Train Loss: 0.000656
Validation Loss: 0.00027211
Epoch [9/300], Train Loss: 0.000656
Validation Loss: 0.00027209
Epoch [10/300], Train Loss: 0.000654
Validation Loss: 0.00027152
Epoch [11/300], Train Loss: 0.000652
Validation Loss: 0.00027176
Epoch [12/300], Train Loss: 0.000651
Validation Loss: 0.00027440
Epoch [13/300], Train Loss: 0.000652
Validation Loss: 0.00027265
Epoch [14/300], Train Loss: 0.000647
Validation Loss: 0.00027510
Epoch [15/300], Train Loss: 0.000648
Validation Loss: 0.00027163
Epoch [16/300], Train Loss: 0.000639
Validation Loss: 0.00027556
Epoch [17/300], Train Loss: 0.000639
Validation Loss: 0.00027326
Epoch [18/300], Train Loss: 0.000630
Validation Loss: 0.00027003
Epoch [19/300], Train Loss: 0.000624
Validation Loss: 0.00027372
Epoch [20/300], Train Loss: 0.000615
Validation Loss: 0.00026193
Epoch [21/300], Train Loss: 0.000601
Validation Loss: 0.00026180
Epoch [22/300], Train Loss: 0.000593
Validation Loss: 0.00027198
Epoch [23/300], Train Loss: 0.000613
Validation Loss: 0.00027271
Epoch [24/300], Train Loss: 0.000564
Validation Loss: 0.00026400
Epoch [25/300], Train Loss: 0.000532
Validation Loss: 0.00027929
Epoch [26/300], Train Loss: 0.000524
Validation Loss: 0.00025978
Epoch [27/300], Train Loss: 0.000532
Validation Loss: 0.00025597
Epoch [28/300], Train Loss: 0.000556
Validation Loss: 0.00026087
Epoch [29/300], Train Loss: 0.000509
Validation Loss: 0.00025076
Epoch [30/300], Train Loss: 0.000519
Validation Loss: 0.00025863
Epoch [31/300], Train Loss: 0.000509
Validation Loss: 0.00025038
Epoch [32/300], Train Loss: 0.000502
Validation Loss: 0.00025219
Epoch [33/300], Train Loss: 0.000510
Validation Loss: 0.00024518
Epoch [34/300], Train Loss: 0.000506
Validation Loss: 0.00025487
Epoch [35/300], Train Loss: 0.000510
Validation Loss: 0.00024912
Epoch [36/300], Train Loss: 0.000499
Validation Loss: 0.00024385
Epoch [37/300], Train Loss: 0.000503
Validation Loss: 0.00029051
Epoch [38/300], Train Loss: 0.000528
Validation Loss: 0.00025075
Epoch [39/300], Train Loss: 0.000492
Validation Loss: 0.00025587
Epoch [40/300], Train Loss: 0.000531
Validation Loss: 0.00026238
Epoch [41/300], Train Loss: 0.000500
Validation Loss: 0.00024772
Epoch [42/300], Train Loss: 0.000497
Validation Loss: 0.00026195
Epoch [43/300], Train Loss: 0.000492
Validation Loss: 0.00025415
Epoch [44/300], Train Loss: 0.000493
Validation Loss: 0.00025031
Epoch [45/300], Train Loss: 0.000494
Validation Loss: 0.00024082
Epoch [46/300], Train Loss: 0.000498
Validation Loss: 0.00025273
Epoch [47/300], Train Loss: 0.000503
Validation Loss: 0.00024631
Epoch [48/300], Train Loss: 0.000501
Validation Loss: 0.00024299
Epoch [49/300], Train Loss: 0.000484
Validation Loss: 0.00024494
Epoch [50/300], Train Loss: 0.000481
Validation Loss: 0.00024807
Epoch [51/300], Train Loss: 0.000476
Validation Loss: 0.00024478
Epoch [52/300], Train Loss: 0.000472
Validation Loss: 0.00024765
Epoch [53/300], Train Loss: 0.000477
Validation Loss: 0.00024022
Epoch [54/300], Train Loss: 0.000467
Validation Loss: 0.00025824
Epoch [55/300], Train Loss: 0.000466
Validation Loss: 0.00024401
Epoch [56/300], Train Loss: 0.000463
Validation Loss: 0.00026059
Epoch [57/300], Train Loss: 0.000460
Validation Loss: 0.00023946
Epoch [58/300], Train Loss: 0.000470
Validation Loss: 0.00024438
Epoch [59/300], Train Loss: 0.000469
Validation Loss: 0.00024949
Epoch [60/300], Train Loss: 0.000467
Validation Loss: 0.00025213
Epoch [61/300], Train Loss: 0.000464
Validation Loss: 0.00024004
Epoch [62/300], Train Loss: 0.000462
Validation Loss: 0.00023881
Epoch [63/300], Train Loss: 0.000458
Validation Loss: 0.00023866
Epoch [64/300], Train Loss: 0.000461
Validation Loss: 0.00024621
Epoch [65/300], Train Loss: 0.000454
Validation Loss: 0.00024285
Epoch [66/300], Train Loss: 0.000452
Validation Loss: 0.00023749
Epoch [67/300], Train Loss: 0.000453
Validation Loss: 0.00024089
Epoch [68/300], Train Loss: 0.000452
Validation Loss: 0.00023331
Epoch [69/300], Train Loss: 0.000454
Validation Loss: 0.00024542
Epoch [70/300], Train Loss: 0.000455
Validation Loss: 0.00023255
Epoch [71/300], Train Loss: 0.000446
Validation Loss: 0.00024138
Epoch [72/300], Train Loss: 0.000460
Validation Loss: 0.00022905
Epoch [73/300], Train Loss: 0.000442
Validation Loss: 0.00025305
Epoch [74/300], Train Loss: 0.000449
Validation Loss: 0.00022956
Epoch [75/300], Train Loss: 0.000443
Validation Loss: 0.00023530
Epoch [76/300], Train Loss: 0.000444
Validation Loss: 0.00022813
Epoch [77/300], Train Loss: 0.000444
Validation Loss: 0.00022895
Epoch [78/300], Train Loss: 0.000444
Validation Loss: 0.00022668
Epoch [79/300], Train Loss: 0.000441
Validation Loss: 0.00023047
Epoch [80/300], Train Loss: 0.000441
Validation Loss: 0.00022316
Epoch [81/300], Train Loss: 0.000438
Validation Loss: 0.00023092
Epoch [82/300], Train Loss: 0.000436
Validation Loss: 0.00022068
Epoch [83/300], Train Loss: 0.000444
Validation Loss: 0.00023106
Epoch [84/300], Train Loss: 0.000454
Validation Loss: 0.00021639
Epoch [85/300], Train Loss: 0.000438
Validation Loss: 0.00023206
Epoch [86/300], Train Loss: 0.000488
Validation Loss: 0.00021387
Epoch [87/300], Train Loss: 0.000445
Validation Loss: 0.00023510
Epoch [88/300], Train Loss: 0.000449
Validation Loss: 0.00021974
Epoch [89/300], Train Loss: 0.000441
Validation Loss: 0.00022330
Epoch [90/300], Train Loss: 0.000437
Validation Loss: 0.00021808
Epoch [91/300], Train Loss: 0.000434
Validation Loss: 0.00021399
Epoch [92/300], Train Loss: 0.000430
Validation Loss: 0.00021963
Epoch [93/300], Train Loss: 0.000432
Validation Loss: 0.00021367
Epoch [94/300], Train Loss: 0.000430
Validation Loss: 0.00021488
Epoch [95/300], Train Loss: 0.000429
Validation Loss: 0.00022002
Epoch [96/300], Train Loss: 0.000428
Validation Loss: 0.00020841
Epoch [97/300], Train Loss: 0.000427
Validation Loss: 0.00021843
Epoch [98/300], Train Loss: 0.000432
Validation Loss: 0.00021009
Epoch [99/300], Train Loss: 0.000428
Validation Loss: 0.00022450
Epoch [100/300], Train Loss: 0.000442
Validation Loss: 0.00020800
Epoch [101/300], Train Loss: 0.000429
Validation Loss: 0.00021097
Epoch [102/300], Train Loss: 0.000432
Validation Loss: 0.00020762
Epoch [103/300], Train Loss: 0.000425
Validation Loss: 0.00020911
Epoch [104/300], Train Loss: 0.000429
Validation Loss: 0.00020834
Epoch [105/300], Train Loss: 0.000423
Validation Loss: 0.00020170
Epoch [106/300], Train Loss: 0.000422
Validation Loss: 0.00020238
Epoch [107/300], Train Loss: 0.000431
Validation Loss: 0.00021491
Epoch [108/300], Train Loss: 0.000435
Validation Loss: 0.00020864
Epoch [109/300], Train Loss: 0.000428
Validation Loss: 0.00020205
Epoch [110/300], Train Loss: 0.000427
Validation Loss: 0.00020594
Epoch [111/300], Train Loss: 0.000422
Validation Loss: 0.00019337
Epoch [112/300], Train Loss: 0.000418
Validation Loss: 0.00019858
Epoch [113/300], Train Loss: 0.000414
Validation Loss: 0.00019306
Epoch [114/300], Train Loss: 0.000415
Validation Loss: 0.00019786
Epoch [115/300], Train Loss: 0.000412
Validation Loss: 0.00019398
Epoch [116/300], Train Loss: 0.000419
Validation Loss: 0.00018544
Epoch [117/300], Train Loss: 0.000412
Validation Loss: 0.00020251
Epoch [118/300], Train Loss: 0.000413
Validation Loss: 0.00018513
Epoch [119/300], Train Loss: 0.000411
Validation Loss: 0.00019089
Epoch [120/300], Train Loss: 0.000410
Validation Loss: 0.00018718
Epoch [121/300], Train Loss: 0.000417
Validation Loss: 0.00018440
Epoch [122/300], Train Loss: 0.000410
Validation Loss: 0.00021402
Epoch [123/300], Train Loss: 0.000420
Validation Loss: 0.00019652
Epoch [124/300], Train Loss: 0.000408
Validation Loss: 0.00019765
Epoch [125/300], Train Loss: 0.000413
Validation Loss: 0.00018428
Epoch [126/300], Train Loss: 0.000408
Validation Loss: 0.00018833
Epoch [127/300], Train Loss: 0.000409
Validation Loss: 0.00018559
Epoch [128/300], Train Loss: 0.000408
Validation Loss: 0.00018287
Epoch [129/300], Train Loss: 0.000406
Validation Loss: 0.00018110
Epoch [130/300], Train Loss: 0.000404
Validation Loss: 0.00018262
Epoch [131/300], Train Loss: 0.000404
Validation Loss: 0.00017932
Epoch [132/300], Train Loss: 0.000402
Validation Loss: 0.00019458
Epoch [133/300], Train Loss: 0.000402
Validation Loss: 0.00017568
Epoch [134/300], Train Loss: 0.000403
Validation Loss: 0.00017342
Epoch [135/300], Train Loss: 0.000395
Validation Loss: 0.00017164
Epoch [136/300], Train Loss: 0.000396
Validation Loss: 0.00016954
Epoch [137/300], Train Loss: 0.000399
Validation Loss: 0.00018818
Epoch [138/300], Train Loss: 0.000408
Validation Loss: 0.00017047
Epoch [139/300], Train Loss: 0.000399
Validation Loss: 0.00017353
Epoch [140/300], Train Loss: 0.000403
Validation Loss: 0.00019861
Epoch [141/300], Train Loss: 0.000408
Validation Loss: 0.00016845
Epoch [142/300], Train Loss: 0.000395
Validation Loss: 0.00018296
Epoch [143/300], Train Loss: 0.000396
Validation Loss: 0.00018656
Epoch [144/300], Train Loss: 0.000391
Validation Loss: 0.00016737
Epoch [145/300], Train Loss: 0.000404
Validation Loss: 0.00019056
Epoch [146/300], Train Loss: 0.000393
Validation Loss: 0.00016961
Epoch [147/300], Train Loss: 0.000392
Validation Loss: 0.00016712
Epoch [148/300], Train Loss: 0.000393
Validation Loss: 0.00017505
Epoch [149/300], Train Loss: 0.000390
Validation Loss: 0.00016073
Epoch [150/300], Train Loss: 0.000392
Validation Loss: 0.00016700
Epoch [151/300], Train Loss: 0.000391
Validation Loss: 0.00016256
Epoch [152/300], Train Loss: 0.000389
Validation Loss: 0.00017519
Epoch [153/300], Train Loss: 0.000386
Validation Loss: 0.00016273
Epoch [154/300], Train Loss: 0.000387
Validation Loss: 0.00016044
Epoch [155/300], Train Loss: 0.000388
Validation Loss: 0.00016233
Epoch [156/300], Train Loss: 0.000387
Validation Loss: 0.00016477
Epoch [157/300], Train Loss: 0.000390
Validation Loss: 0.00016090
Epoch [158/300], Train Loss: 0.000384
Validation Loss: 0.00016117
Epoch [159/300], Train Loss: 0.000380
Validation Loss: 0.00016537
Epoch [160/300], Train Loss: 0.000388
Validation Loss: 0.00016352
Epoch [161/300], Train Loss: 0.000382
Validation Loss: 0.00016909
Epoch [162/300], Train Loss: 0.000380
Validation Loss: 0.00016325
Epoch [163/300], Train Loss: 0.000383
Validation Loss: 0.00015826
Epoch [164/300], Train Loss: 0.000385
Validation Loss: 0.00015737
Epoch [165/300], Train Loss: 0.000379
Validation Loss: 0.00016226
Epoch [166/300], Train Loss: 0.000385
Validation Loss: 0.00016656
Epoch [167/300], Train Loss: 0.000377
Validation Loss: 0.00016234
Epoch [168/300], Train Loss: 0.000376
Validation Loss: 0.00016906
Epoch [169/300], Train Loss: 0.000380
Validation Loss: 0.00016584
Epoch [170/300], Train Loss: 0.000383
Validation Loss: 0.00018129
Epoch [171/300], Train Loss: 0.000386
Validation Loss: 0.00017378
Epoch [172/300], Train Loss: 0.000381
Validation Loss: 0.00017232
Epoch [173/300], Train Loss: 0.000377
Validation Loss: 0.00018072
Epoch [174/300], Train Loss: 0.000380
Validation Loss: 0.00016052
Early stopping triggered

Evaluating model for: Microwave
Run 70/72 completed in 1222.76 seconds with: {'MAE': np.float32(10.510713), 'MSE': np.float32(7278.319), 'RMSE': np.float32(85.313065), 'SAE': np.float32(0.0966362), 'NDE': np.float32(0.6965779)}

Run 71/72: hidden=512, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Microwave
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.000768
Validation Loss: 0.00028764
Epoch [2/300], Train Loss: 0.000674
Validation Loss: 0.00028007
Epoch [3/300], Train Loss: 0.000667
Validation Loss: 0.00028270
Epoch [4/300], Train Loss: 0.000666
Validation Loss: 0.00027624
Epoch [5/300], Train Loss: 0.000668
Validation Loss: 0.00027609
Epoch [6/300], Train Loss: 0.000665
Validation Loss: 0.00027815
Epoch [7/300], Train Loss: 0.000663
Validation Loss: 0.00027593
Epoch [8/300], Train Loss: 0.000661
Validation Loss: 0.00027520
Epoch [9/300], Train Loss: 0.000662
Validation Loss: 0.00027525
Epoch [10/300], Train Loss: 0.000660
Validation Loss: 0.00027332
Epoch [11/300], Train Loss: 0.000657
Validation Loss: 0.00027238
Epoch [12/300], Train Loss: 0.000653
Validation Loss: 0.00027103
Epoch [13/300], Train Loss: 0.000648
Validation Loss: 0.00027291
Epoch [14/300], Train Loss: 0.000641
Validation Loss: 0.00027240
Epoch [15/300], Train Loss: 0.000634
Validation Loss: 0.00026781
Epoch [16/300], Train Loss: 0.000617
Validation Loss: 0.00026371
Epoch [17/300], Train Loss: 0.000600
Validation Loss: 0.00024865
Epoch [18/300], Train Loss: 0.000560
Validation Loss: 0.00024490
Epoch [19/300], Train Loss: 0.000547
Validation Loss: 0.00028582
Epoch [20/300], Train Loss: 0.000570
Validation Loss: 0.00024934
Epoch [21/300], Train Loss: 0.000556
Validation Loss: 0.00025769
Epoch [22/300], Train Loss: 0.000559
Validation Loss: 0.00025091
Epoch [23/300], Train Loss: 0.000518
Validation Loss: 0.00025211
Epoch [24/300], Train Loss: 0.000515
Validation Loss: 0.00024869
Epoch [25/300], Train Loss: 0.000531
Validation Loss: 0.00024747
Epoch [26/300], Train Loss: 0.000523
Validation Loss: 0.00025454
Epoch [27/300], Train Loss: 0.000532
Validation Loss: 0.00026365
Epoch [28/300], Train Loss: 0.000518
Validation Loss: 0.00025310
Early stopping triggered

Evaluating model for: Microwave
Run 71/72 completed in 253.35 seconds with: {'MAE': np.float32(16.391201), 'MSE': np.float32(10852.468), 'RMSE': np.float32(104.17518), 'SAE': np.float32(0.099392675), 'NDE': np.float32(0.8505872)}

Run 72/72: hidden=512, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Microwave
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.000932
Validation Loss: 0.00032423
Epoch [2/300], Train Loss: 0.000685
Validation Loss: 0.00028104
Epoch [3/300], Train Loss: 0.000669
Validation Loss: 0.00028210
Epoch [4/300], Train Loss: 0.000667
Validation Loss: 0.00027768
Epoch [5/300], Train Loss: 0.000669
Validation Loss: 0.00027827
Epoch [6/300], Train Loss: 0.000667
Validation Loss: 0.00027834
Epoch [7/300], Train Loss: 0.000665
Validation Loss: 0.00027769
Epoch [8/300], Train Loss: 0.000664
Validation Loss: 0.00027772
Epoch [9/300], Train Loss: 0.000666
Validation Loss: 0.00027921
Epoch [10/300], Train Loss: 0.000665
Validation Loss: 0.00027741
Epoch [11/300], Train Loss: 0.000664
Validation Loss: 0.00027768
Epoch [12/300], Train Loss: 0.000665
Validation Loss: 0.00027828
Epoch [13/300], Train Loss: 0.000668
Validation Loss: 0.00027723
Epoch [14/300], Train Loss: 0.000666
Validation Loss: 0.00027702
Epoch [15/300], Train Loss: 0.000667
Validation Loss: 0.00027877
Epoch [16/300], Train Loss: 0.000663
Validation Loss: 0.00027888
Epoch [17/300], Train Loss: 0.000664
Validation Loss: 0.00027685
Epoch [18/300], Train Loss: 0.000661
Validation Loss: 0.00027590
Epoch [19/300], Train Loss: 0.000660
Validation Loss: 0.00027668
Epoch [20/300], Train Loss: 0.000660
Validation Loss: 0.00027535
Epoch [21/300], Train Loss: 0.000658
Validation Loss: 0.00027432
Epoch [22/300], Train Loss: 0.000656
Validation Loss: 0.00027329
Epoch [23/300], Train Loss: 0.000653
Validation Loss: 0.00027245
Epoch [24/300], Train Loss: 0.000650
Validation Loss: 0.00027304
Epoch [25/300], Train Loss: 0.000651
Validation Loss: 0.00027456
Epoch [26/300], Train Loss: 0.000649
Validation Loss: 0.00027478
Epoch [27/300], Train Loss: 0.000647
Validation Loss: 0.00027452
Epoch [28/300], Train Loss: 0.000639
Validation Loss: 0.00027669
Epoch [29/300], Train Loss: 0.000635
Validation Loss: 0.00027329
Epoch [30/300], Train Loss: 0.000620
Validation Loss: 0.00027459
Epoch [31/300], Train Loss: 0.000612
Validation Loss: 0.00027212
Epoch [32/300], Train Loss: 0.000566
Validation Loss: 0.00027400
Epoch [33/300], Train Loss: 0.000571
Validation Loss: 0.00026901
Epoch [34/300], Train Loss: 0.000573
Validation Loss: 0.00026546
Epoch [35/300], Train Loss: 0.000550
Validation Loss: 0.00027739
Epoch [36/300], Train Loss: 0.000541
Validation Loss: 0.00026552
Epoch [37/300], Train Loss: 0.000544
Validation Loss: 0.00030465
Epoch [38/300], Train Loss: 0.000571
Validation Loss: 0.00026331
Epoch [39/300], Train Loss: 0.000541
Validation Loss: 0.00027295
Epoch [40/300], Train Loss: 0.000619
Validation Loss: 0.00026366
Epoch [41/300], Train Loss: 0.000578
Validation Loss: 0.00026578
Epoch [42/300], Train Loss: 0.000534
Validation Loss: 0.00027284
Epoch [43/300], Train Loss: 0.000529
Validation Loss: 0.00026501
Epoch [44/300], Train Loss: 0.000521
Validation Loss: 0.00026691
Epoch [45/300], Train Loss: 0.000525
Validation Loss: 0.00025905
Epoch [46/300], Train Loss: 0.000530
Validation Loss: 0.00026247
Epoch [47/300], Train Loss: 0.000529
Validation Loss: 0.00025828
Epoch [48/300], Train Loss: 0.000523
Validation Loss: 0.00026014
Epoch [49/300], Train Loss: 0.000516
Validation Loss: 0.00026013
Epoch [50/300], Train Loss: 0.000515
Validation Loss: 0.00026212
Epoch [51/300], Train Loss: 0.000510
Validation Loss: 0.00025697
Epoch [52/300], Train Loss: 0.000510
Validation Loss: 0.00026219
Epoch [53/300], Train Loss: 0.000510
Validation Loss: 0.00025845
Epoch [54/300], Train Loss: 0.000522
Validation Loss: 0.00025162
Epoch [55/300], Train Loss: 0.000521
Validation Loss: 0.00025342
Epoch [56/300], Train Loss: 0.000516
Validation Loss: 0.00025928
Epoch [57/300], Train Loss: 0.000513
Validation Loss: 0.00025122
Epoch [58/300], Train Loss: 0.000518
Validation Loss: 0.00025818
Epoch [59/300], Train Loss: 0.000511
Validation Loss: 0.00026103
Epoch [60/300], Train Loss: 0.000515
Validation Loss: 0.00025568
Epoch [61/300], Train Loss: 0.000506
Validation Loss: 0.00025811
Epoch [62/300], Train Loss: 0.000502
Validation Loss: 0.00025279
Epoch [63/300], Train Loss: 0.000500
Validation Loss: 0.00025028
Epoch [64/300], Train Loss: 0.000502
Validation Loss: 0.00025165
Epoch [65/300], Train Loss: 0.000492
Validation Loss: 0.00025371
Epoch [66/300], Train Loss: 0.000490
Validation Loss: 0.00024560
Epoch [67/300], Train Loss: 0.000493
Validation Loss: 0.00024856
Epoch [68/300], Train Loss: 0.000480
Validation Loss: 0.00024414
Epoch [69/300], Train Loss: 0.000479
Validation Loss: 0.00026026
Epoch [70/300], Train Loss: 0.000477
Validation Loss: 0.00024335
Epoch [71/300], Train Loss: 0.000463
Validation Loss: 0.00024667
Epoch [72/300], Train Loss: 0.000474
Validation Loss: 0.00023880
Epoch [73/300], Train Loss: 0.000459
Validation Loss: 0.00025070
Epoch [74/300], Train Loss: 0.000463
Validation Loss: 0.00024092
Epoch [75/300], Train Loss: 0.000476
Validation Loss: 0.00024243
Epoch [76/300], Train Loss: 0.000456
Validation Loss: 0.00024286
Epoch [77/300], Train Loss: 0.000456
Validation Loss: 0.00024013
Epoch [78/300], Train Loss: 0.000477
Validation Loss: 0.00024023
Epoch [79/300], Train Loss: 0.000477
Validation Loss: 0.00024865
Epoch [80/300], Train Loss: 0.000459
Validation Loss: 0.00024145
Epoch [81/300], Train Loss: 0.000451
Validation Loss: 0.00024447
Epoch [82/300], Train Loss: 0.000449
Validation Loss: 0.00024128
Early stopping triggered

Evaluating model for: Microwave
Run 72/72 completed in 959.09 seconds with: {'MAE': np.float32(13.09948), 'MSE': np.float32(9757.023), 'RMSE': np.float32(98.77765), 'SAE': np.float32(0.5246389), 'NDE': np.float32(0.80651706)}
    hidden_size  seq_length  stride  num_layers  eval_result
50          512         120    0.25           4     6.075004
25          256         120    0.25           3     6.181423
51          512         120    0.25           5     6.377701
31          256         120    0.50           5     6.715158
48          512         120    0.25           2     6.878043
..          ...         ...     ...         ...          ...
12          128         360    0.50           2    16.240746
23          128         720    0.50           5    16.285845
70          512         720    0.50           4    16.391201
63          512         360    0.50           5    16.915155
60          512         360    0.50           2    17.873791

[72 rows x 5 columns]
