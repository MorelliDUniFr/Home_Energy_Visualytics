Using device: cuda

Run 1/72: hidden=128, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Router
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.087236
Validation Loss: 0.06305356
Epoch [2/300], Train Loss: 0.029152
Validation Loss: 0.00867339
Epoch [3/300], Train Loss: 0.008741
Validation Loss: 0.00844734
Epoch [4/300], Train Loss: 0.008386
Validation Loss: 0.00822521
Epoch [5/300], Train Loss: 0.008216
Validation Loss: 0.00806156
Epoch [6/300], Train Loss: 0.008063
Validation Loss: 0.00789444
Epoch [7/300], Train Loss: 0.007851
Validation Loss: 0.00773879
Epoch [8/300], Train Loss: 0.007671
Validation Loss: 0.00760534
Epoch [9/300], Train Loss: 0.007536
Validation Loss: 0.00744885
Epoch [10/300], Train Loss: 0.007411
Validation Loss: 0.00733664
Epoch [11/300], Train Loss: 0.007310
Validation Loss: 0.00720603
Epoch [12/300], Train Loss: 0.007131
Validation Loss: 0.00710084
Epoch [13/300], Train Loss: 0.007042
Validation Loss: 0.00701909
Epoch [14/300], Train Loss: 0.006922
Validation Loss: 0.00692156
Epoch [15/300], Train Loss: 0.006832
Validation Loss: 0.00685885
Epoch [16/300], Train Loss: 0.006751
Validation Loss: 0.00679567
Epoch [17/300], Train Loss: 0.006700
Validation Loss: 0.00674121
Epoch [18/300], Train Loss: 0.006629
Validation Loss: 0.00668632
Epoch [19/300], Train Loss: 0.006607
Validation Loss: 0.00663972
Epoch [20/300], Train Loss: 0.006533
Validation Loss: 0.00659323
Epoch [21/300], Train Loss: 0.006495
Validation Loss: 0.00654909
Epoch [22/300], Train Loss: 0.006450
Validation Loss: 0.00650702
Epoch [23/300], Train Loss: 0.006440
Validation Loss: 0.00647525
Epoch [24/300], Train Loss: 0.006397
Validation Loss: 0.00643776
Epoch [25/300], Train Loss: 0.006284
Validation Loss: 0.00638879
Epoch [26/300], Train Loss: 0.006269
Validation Loss: 0.00637637
Epoch [27/300], Train Loss: 0.006217
Validation Loss: 0.00632154
Epoch [28/300], Train Loss: 0.006164
Validation Loss: 0.00628690
Epoch [29/300], Train Loss: 0.006168
Validation Loss: 0.00627748
Epoch [30/300], Train Loss: 0.006089
Validation Loss: 0.00624365
Epoch [31/300], Train Loss: 0.006109
Validation Loss: 0.00619955
Epoch [32/300], Train Loss: 0.006064
Validation Loss: 0.00617781
Epoch [33/300], Train Loss: 0.006034
Validation Loss: 0.00615895
Epoch [34/300], Train Loss: 0.005963
Validation Loss: 0.00613716
Epoch [35/300], Train Loss: 0.005964
Validation Loss: 0.00612249
Epoch [36/300], Train Loss: 0.005930
Validation Loss: 0.00608286
Epoch [37/300], Train Loss: 0.005899
Validation Loss: 0.00609986
Epoch [38/300], Train Loss: 0.005920
Validation Loss: 0.00604525
Epoch [39/300], Train Loss: 0.005871
Validation Loss: 0.00605152
Epoch [40/300], Train Loss: 0.005828
Validation Loss: 0.00600366
Epoch [41/300], Train Loss: 0.005845
Validation Loss: 0.00598606
Epoch [42/300], Train Loss: 0.005828
Validation Loss: 0.00598011
Epoch [43/300], Train Loss: 0.005808
Validation Loss: 0.00595802
Epoch [44/300], Train Loss: 0.005789
Validation Loss: 0.00593701
Epoch [45/300], Train Loss: 0.005782
Validation Loss: 0.00592181
Epoch [46/300], Train Loss: 0.005732
Validation Loss: 0.00591252
Epoch [47/300], Train Loss: 0.005750
Validation Loss: 0.00590260
Epoch [48/300], Train Loss: 0.005692
Validation Loss: 0.00588385
Epoch [49/300], Train Loss: 0.005694
Validation Loss: 0.00587275
Epoch [50/300], Train Loss: 0.005683
Validation Loss: 0.00586559
Epoch [51/300], Train Loss: 0.005664
Validation Loss: 0.00584866
Epoch [52/300], Train Loss: 0.005670
Validation Loss: 0.00583878
Epoch [53/300], Train Loss: 0.005660
Validation Loss: 0.00583593
Epoch [54/300], Train Loss: 0.005625
Validation Loss: 0.00581984
Epoch [55/300], Train Loss: 0.005596
Validation Loss: 0.00580795
Epoch [56/300], Train Loss: 0.005607
Validation Loss: 0.00580004
Epoch [57/300], Train Loss: 0.005621
Validation Loss: 0.00579132
Epoch [58/300], Train Loss: 0.005602
Validation Loss: 0.00579615
Epoch [59/300], Train Loss: 0.005557
Validation Loss: 0.00577328
Epoch [60/300], Train Loss: 0.005574
Validation Loss: 0.00576708
Epoch [61/300], Train Loss: 0.005573
Validation Loss: 0.00575502
Epoch [62/300], Train Loss: 0.005535
Validation Loss: 0.00574839
Epoch [63/300], Train Loss: 0.005557
Validation Loss: 0.00574307
Epoch [64/300], Train Loss: 0.005528
Validation Loss: 0.00573381
Epoch [65/300], Train Loss: 0.005532
Validation Loss: 0.00572776
Epoch [66/300], Train Loss: 0.005516
Validation Loss: 0.00573287
Epoch [67/300], Train Loss: 0.005495
Validation Loss: 0.00573476
Epoch [68/300], Train Loss: 0.005498
Validation Loss: 0.00570904
Epoch [69/300], Train Loss: 0.005491
Validation Loss: 0.00571204
Epoch [70/300], Train Loss: 0.005471
Validation Loss: 0.00569784
Epoch [71/300], Train Loss: 0.005457
Validation Loss: 0.00569666
Epoch [72/300], Train Loss: 0.005448
Validation Loss: 0.00568552
Epoch [73/300], Train Loss: 0.005475
Validation Loss: 0.00568106
Epoch [74/300], Train Loss: 0.005429
Validation Loss: 0.00567502
Epoch [75/300], Train Loss: 0.005465
Validation Loss: 0.00567054
Epoch [76/300], Train Loss: 0.005421
Validation Loss: 0.00566738
Epoch [77/300], Train Loss: 0.005467
Validation Loss: 0.00566270
Epoch [78/300], Train Loss: 0.005444
Validation Loss: 0.00565986
Epoch [79/300], Train Loss: 0.005411
Validation Loss: 0.00567460
Epoch [80/300], Train Loss: 0.005418
Validation Loss: 0.00565118
Epoch [81/300], Train Loss: 0.005448
Validation Loss: 0.00565476
Epoch [82/300], Train Loss: 0.005404
Validation Loss: 0.00564463
Epoch [83/300], Train Loss: 0.005406
Validation Loss: 0.00564808
Epoch [84/300], Train Loss: 0.005389
Validation Loss: 0.00564470
Epoch [85/300], Train Loss: 0.005394
Validation Loss: 0.00563492
Epoch [86/300], Train Loss: 0.005410
Validation Loss: 0.00563969
Epoch [87/300], Train Loss: 0.005422
Validation Loss: 0.00563510
Epoch [88/300], Train Loss: 0.005384
Validation Loss: 0.00562648
Epoch [89/300], Train Loss: 0.005396
Validation Loss: 0.00564652
Epoch [90/300], Train Loss: 0.005382
Validation Loss: 0.00562242
Epoch [91/300], Train Loss: 0.005399
Validation Loss: 0.00561812
Epoch [92/300], Train Loss: 0.005414
Validation Loss: 0.00561497
Epoch [93/300], Train Loss: 0.005373
Validation Loss: 0.00561467
Epoch [94/300], Train Loss: 0.005357
Validation Loss: 0.00561192
Epoch [95/300], Train Loss: 0.005357
Validation Loss: 0.00561063
Epoch [96/300], Train Loss: 0.005361
Validation Loss: 0.00560571
Epoch [97/300], Train Loss: 0.005367
Validation Loss: 0.00561670
Epoch [98/300], Train Loss: 0.005349
Validation Loss: 0.00560031
Epoch [99/300], Train Loss: 0.005348
Validation Loss: 0.00559991
Epoch [100/300], Train Loss: 0.005380
Validation Loss: 0.00559782
Epoch [101/300], Train Loss: 0.005376
Validation Loss: 0.00558821
Epoch [102/300], Train Loss: 0.005351
Validation Loss: 0.00558875
Epoch [103/300], Train Loss: 0.005348
Validation Loss: 0.00558061
Epoch [104/300], Train Loss: 0.005368
Validation Loss: 0.00558806
Epoch [105/300], Train Loss: 0.005329
Validation Loss: 0.00557339
Epoch [106/300], Train Loss: 0.005326
Validation Loss: 0.00557023
Epoch [107/300], Train Loss: 0.005324
Validation Loss: 0.00557146
Epoch [108/300], Train Loss: 0.005356
Validation Loss: 0.00557665
Epoch [109/300], Train Loss: 0.005328
Validation Loss: 0.00556268
Epoch [110/300], Train Loss: 0.005330
Validation Loss: 0.00555694
Epoch [111/300], Train Loss: 0.005323
Validation Loss: 0.00555426
Epoch [112/300], Train Loss: 0.005307
Validation Loss: 0.00554976
Epoch [113/300], Train Loss: 0.005351
Validation Loss: 0.00554307
Epoch [114/300], Train Loss: 0.005314
Validation Loss: 0.00553470
Epoch [115/300], Train Loss: 0.005304
Validation Loss: 0.00553007
Epoch [116/300], Train Loss: 0.005323
Validation Loss: 0.00553229
Epoch [117/300], Train Loss: 0.005288
Validation Loss: 0.00552647
Epoch [118/300], Train Loss: 0.005328
Validation Loss: 0.00551757
Epoch [119/300], Train Loss: 0.005295
Validation Loss: 0.00552061
Epoch [120/300], Train Loss: 0.005316
Validation Loss: 0.00550025
Epoch [121/300], Train Loss: 0.005267
Validation Loss: 0.00548497
Epoch [122/300], Train Loss: 0.005268
Validation Loss: 0.00551370
Epoch [123/300], Train Loss: 0.005257
Validation Loss: 0.00550779
Epoch [124/300], Train Loss: 0.005267
Validation Loss: 0.00545036
Epoch [125/300], Train Loss: 0.005208
Validation Loss: 0.00542651
Epoch [126/300], Train Loss: 0.005222
Validation Loss: 0.00541254
Epoch [127/300], Train Loss: 0.005184
Validation Loss: 0.00537938
Epoch [128/300], Train Loss: 0.005162
Validation Loss: 0.00535623
Epoch [129/300], Train Loss: 0.005165
Validation Loss: 0.00536129
Epoch [130/300], Train Loss: 0.005124
Validation Loss: 0.00533356
Epoch [131/300], Train Loss: 0.005125
Validation Loss: 0.00533392
Epoch [132/300], Train Loss: 0.005070
Validation Loss: 0.00528747
Epoch [133/300], Train Loss: 0.005048
Validation Loss: 0.00521852
Epoch [134/300], Train Loss: 0.004984
Validation Loss: 0.00518935
Epoch [135/300], Train Loss: 0.005019
Validation Loss: 0.00519756
Epoch [136/300], Train Loss: 0.004957
Validation Loss: 0.00522340
Epoch [137/300], Train Loss: 0.004918
Validation Loss: 0.00513060
Epoch [138/300], Train Loss: 0.004938
Validation Loss: 0.00511159
Epoch [139/300], Train Loss: 0.004943
Validation Loss: 0.00510537
Epoch [140/300], Train Loss: 0.004875
Validation Loss: 0.00527760
Epoch [141/300], Train Loss: 0.004908
Validation Loss: 0.00507468
Epoch [142/300], Train Loss: 0.004916
Validation Loss: 0.00531230
Epoch [143/300], Train Loss: 0.004972
Validation Loss: 0.00513676
Epoch [144/300], Train Loss: 0.004886
Validation Loss: 0.00505776
Epoch [145/300], Train Loss: 0.004864
Validation Loss: 0.00532314
Epoch [146/300], Train Loss: 0.004980
Validation Loss: 0.00516631
Epoch [147/300], Train Loss: 0.004851
Validation Loss: 0.00507475
Epoch [148/300], Train Loss: 0.004842
Validation Loss: 0.00503261
Epoch [149/300], Train Loss: 0.004810
Validation Loss: 0.00499932
Epoch [150/300], Train Loss: 0.004823
Validation Loss: 0.00503186
Epoch [151/300], Train Loss: 0.004816
Validation Loss: 0.00505247
Epoch [152/300], Train Loss: 0.004826
Validation Loss: 0.00497687
Epoch [153/300], Train Loss: 0.004812
Validation Loss: 0.00497569
Epoch [154/300], Train Loss: 0.004791
Validation Loss: 0.00497647
Epoch [155/300], Train Loss: 0.004776
Validation Loss: 0.00497231
Epoch [156/300], Train Loss: 0.004786
Validation Loss: 0.00496170
Epoch [157/300], Train Loss: 0.004792
Validation Loss: 0.00494729
Epoch [158/300], Train Loss: 0.004770
Validation Loss: 0.00494783
Epoch [159/300], Train Loss: 0.004806
Validation Loss: 0.00499058
Epoch [160/300], Train Loss: 0.004775
Validation Loss: 0.00493707
Epoch [161/300], Train Loss: 0.004749
Validation Loss: 0.00494336
Epoch [162/300], Train Loss: 0.004743
Validation Loss: 0.00497063
Epoch [163/300], Train Loss: 0.004796
Validation Loss: 0.00494539
Epoch [164/300], Train Loss: 0.004773
Validation Loss: 0.00492127
Epoch [165/300], Train Loss: 0.004758
Validation Loss: 0.00492867
Epoch [166/300], Train Loss: 0.004739
Validation Loss: 0.00494486
Epoch [167/300], Train Loss: 0.004733
Validation Loss: 0.00490369
Epoch [168/300], Train Loss: 0.004733
Validation Loss: 0.00492841
Epoch [169/300], Train Loss: 0.004743
Validation Loss: 0.00492600
Epoch [170/300], Train Loss: 0.004729
Validation Loss: 0.00498457
Epoch [171/300], Train Loss: 0.004748
Validation Loss: 0.00489057
Epoch [172/300], Train Loss: 0.004722
Validation Loss: 0.00489084
Epoch [173/300], Train Loss: 0.004741
Validation Loss: 0.00491220
Epoch [174/300], Train Loss: 0.004762
Validation Loss: 0.00488352
Epoch [175/300], Train Loss: 0.004706
Validation Loss: 0.00487977
Epoch [176/300], Train Loss: 0.004697
Validation Loss: 0.00488709
Epoch [177/300], Train Loss: 0.004721
Validation Loss: 0.00487374
Epoch [178/300], Train Loss: 0.004705
Validation Loss: 0.00487497
Epoch [179/300], Train Loss: 0.004695
Validation Loss: 0.00486779
Epoch [180/300], Train Loss: 0.004710
Validation Loss: 0.00487290
Epoch [181/300], Train Loss: 0.004710
Validation Loss: 0.00486303
Epoch [182/300], Train Loss: 0.004702
Validation Loss: 0.00485680
Epoch [183/300], Train Loss: 0.004703
Validation Loss: 0.00485467
Epoch [184/300], Train Loss: 0.004686
Validation Loss: 0.00489681
Epoch [185/300], Train Loss: 0.004704
Validation Loss: 0.00485338
Epoch [186/300], Train Loss: 0.004687
Validation Loss: 0.00509024
Epoch [187/300], Train Loss: 0.004706
Validation Loss: 0.00485340
Epoch [188/300], Train Loss: 0.004699
Validation Loss: 0.00486425
Epoch [189/300], Train Loss: 0.004675
Validation Loss: 0.00485044
Epoch [190/300], Train Loss: 0.004669
Validation Loss: 0.00483738
Epoch [191/300], Train Loss: 0.004679
Validation Loss: 0.00484642
Epoch [192/300], Train Loss: 0.004674
Validation Loss: 0.00485804
Epoch [193/300], Train Loss: 0.004682
Validation Loss: 0.00484240
Epoch [194/300], Train Loss: 0.004684
Validation Loss: 0.00485395
Epoch [195/300], Train Loss: 0.004677
Validation Loss: 0.00482568
Epoch [196/300], Train Loss: 0.004669
Validation Loss: 0.00484086
Epoch [197/300], Train Loss: 0.004682
Validation Loss: 0.00484287
Epoch [198/300], Train Loss: 0.004658
Validation Loss: 0.00485256
Epoch [199/300], Train Loss: 0.004656
Validation Loss: 0.00483515
Epoch [200/300], Train Loss: 0.004671
Validation Loss: 0.00481699
Epoch [201/300], Train Loss: 0.004673
Validation Loss: 0.00483387
Epoch [202/300], Train Loss: 0.004665
Validation Loss: 0.00483259
Epoch [203/300], Train Loss: 0.004675
Validation Loss: 0.00481159
Epoch [204/300], Train Loss: 0.004674
Validation Loss: 0.00482274
Epoch [205/300], Train Loss: 0.004658
Validation Loss: 0.00489319
Epoch [206/300], Train Loss: 0.004659
Validation Loss: 0.00481504
Epoch [207/300], Train Loss: 0.004650
Validation Loss: 0.00481710
Epoch [208/300], Train Loss: 0.004672
Validation Loss: 0.00480767
Epoch [209/300], Train Loss: 0.004652
Validation Loss: 0.00480649
Epoch [210/300], Train Loss: 0.004651
Validation Loss: 0.00480786
Epoch [211/300], Train Loss: 0.004666
Validation Loss: 0.00480806
Epoch [212/300], Train Loss: 0.004662
Validation Loss: 0.00488902
Epoch [213/300], Train Loss: 0.004654
Validation Loss: 0.00480317
Epoch [214/300], Train Loss: 0.004643
Validation Loss: 0.00485629
Epoch [215/300], Train Loss: 0.004737
Validation Loss: 0.00482486
Epoch [216/300], Train Loss: 0.004633
Validation Loss: 0.00480220
Epoch [217/300], Train Loss: 0.004647
Validation Loss: 0.00483511
Epoch [218/300], Train Loss: 0.004647
Validation Loss: 0.00479337
Epoch [219/300], Train Loss: 0.004637
Validation Loss: 0.00480215
Epoch [220/300], Train Loss: 0.004660
Validation Loss: 0.00482646
Epoch [221/300], Train Loss: 0.004639
Validation Loss: 0.00482001
Epoch [222/300], Train Loss: 0.004634
Validation Loss: 0.00480619
Epoch [223/300], Train Loss: 0.004645
Validation Loss: 0.00480078
Epoch [224/300], Train Loss: 0.004623
Validation Loss: 0.00481394
Epoch [225/300], Train Loss: 0.004636
Validation Loss: 0.00478688
Epoch [226/300], Train Loss: 0.004640
Validation Loss: 0.00478906
Epoch [227/300], Train Loss: 0.004631
Validation Loss: 0.00483785
Epoch [228/300], Train Loss: 0.004629
Validation Loss: 0.00482624
Epoch [229/300], Train Loss: 0.004629
Validation Loss: 0.00478597
Epoch [230/300], Train Loss: 0.004617
Validation Loss: 0.00478611
Epoch [231/300], Train Loss: 0.004619
Validation Loss: 0.00479564
Epoch [232/300], Train Loss: 0.004626
Validation Loss: 0.00481577
Epoch [233/300], Train Loss: 0.004637
Validation Loss: 0.00478260
Epoch [234/300], Train Loss: 0.004637
Validation Loss: 0.00477963
Epoch [235/300], Train Loss: 0.004635
Validation Loss: 0.00478822
Epoch [236/300], Train Loss: 0.004621
Validation Loss: 0.00478324
Epoch [237/300], Train Loss: 0.004611
Validation Loss: 0.00479732
Epoch [238/300], Train Loss: 0.004628
Validation Loss: 0.00477207
Epoch [239/300], Train Loss: 0.004608
Validation Loss: 0.00479151
Epoch [240/300], Train Loss: 0.004604
Validation Loss: 0.00478093
Epoch [241/300], Train Loss: 0.004601
Validation Loss: 0.00477317
Epoch [242/300], Train Loss: 0.004602
Validation Loss: 0.00477232
Epoch [243/300], Train Loss: 0.004608
Validation Loss: 0.00477682
Epoch [244/300], Train Loss: 0.004597
Validation Loss: 0.00477914
Epoch [245/300], Train Loss: 0.004638
Validation Loss: 0.00477542
Epoch [246/300], Train Loss: 0.004629
Validation Loss: 0.00477118
Epoch [247/300], Train Loss: 0.004619
Validation Loss: 0.00476619
Epoch [248/300], Train Loss: 0.004608
Validation Loss: 0.00477454
Epoch [249/300], Train Loss: 0.004594
Validation Loss: 0.00479355
Epoch [250/300], Train Loss: 0.004622
Validation Loss: 0.00477855
Epoch [251/300], Train Loss: 0.004601
Validation Loss: 0.00476775
Epoch [252/300], Train Loss: 0.004604
Validation Loss: 0.00479483
Epoch [253/300], Train Loss: 0.004650
Validation Loss: 0.00476338
Epoch [254/300], Train Loss: 0.004588
Validation Loss: 0.00477177
Epoch [255/300], Train Loss: 0.004613
Validation Loss: 0.00483312
Epoch [256/300], Train Loss: 0.004612
Validation Loss: 0.00476542
Epoch [257/300], Train Loss: 0.004610
Validation Loss: 0.00476105
Epoch [258/300], Train Loss: 0.004608
Validation Loss: 0.00476537
Epoch [259/300], Train Loss: 0.004582
Validation Loss: 0.00477493
Epoch [260/300], Train Loss: 0.004583
Validation Loss: 0.00475790
Epoch [261/300], Train Loss: 0.004581
Validation Loss: 0.00476227
Epoch [262/300], Train Loss: 0.004583
Validation Loss: 0.00477896
Epoch [263/300], Train Loss: 0.004583
Validation Loss: 0.00475194
Epoch [264/300], Train Loss: 0.004585
Validation Loss: 0.00476263
Epoch [265/300], Train Loss: 0.004591
Validation Loss: 0.00476240
Epoch [266/300], Train Loss: 0.004571
Validation Loss: 0.00478274
Epoch [267/300], Train Loss: 0.004600
Validation Loss: 0.00475127
Epoch [268/300], Train Loss: 0.004580
Validation Loss: 0.00475620
Epoch [269/300], Train Loss: 0.004576
Validation Loss: 0.00475018
Epoch [270/300], Train Loss: 0.004570
Validation Loss: 0.00476386
Epoch [271/300], Train Loss: 0.004584
Validation Loss: 0.00475501
Epoch [272/300], Train Loss: 0.004603
Validation Loss: 0.00474837
Epoch [273/300], Train Loss: 0.004592
Validation Loss: 0.00475735
Epoch [274/300], Train Loss: 0.004617
Validation Loss: 0.00482107
Epoch [275/300], Train Loss: 0.004586
Validation Loss: 0.00475894
Epoch [276/300], Train Loss: 0.004588
Validation Loss: 0.00475302
Epoch [277/300], Train Loss: 0.004568
Validation Loss: 0.00474686
Epoch [278/300], Train Loss: 0.004578
Validation Loss: 0.00474534
Epoch [279/300], Train Loss: 0.004591
Validation Loss: 0.00474615
Epoch [280/300], Train Loss: 0.004579
Validation Loss: 0.00474919
Epoch [281/300], Train Loss: 0.004595
Validation Loss: 0.00474193
Epoch [282/300], Train Loss: 0.004632
Validation Loss: 0.00475137
Epoch [283/300], Train Loss: 0.004600
Validation Loss: 0.00475235
Epoch [284/300], Train Loss: 0.004572
Validation Loss: 0.00474783
Epoch [285/300], Train Loss: 0.004580
Validation Loss: 0.00475017
Epoch [286/300], Train Loss: 0.004567
Validation Loss: 0.00474546
Epoch [287/300], Train Loss: 0.004576
Validation Loss: 0.00476682
Epoch [288/300], Train Loss: 0.004579
Validation Loss: 0.00476538
Epoch [289/300], Train Loss: 0.004586
Validation Loss: 0.00475224
Epoch [290/300], Train Loss: 0.004592
Validation Loss: 0.00479495
Epoch [291/300], Train Loss: 0.004577
Validation Loss: 0.00474296
Early stopping triggered

Evaluating model for: Router
Run 1/72 completed in 1569.24 seconds with: {'MAE': np.float32(0.18437928), 'MSE': np.float32(0.057000194), 'RMSE': np.float32(0.23874713), 'SAE': np.float32(0.0004456158), 'NDE': np.float32(0.011932818)}

Run 2/72: hidden=128, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Router
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.089981
Validation Loss: 0.05010633
Epoch [2/300], Train Loss: 0.016707
Validation Loss: 0.00884657
Epoch [3/300], Train Loss: 0.008751
Validation Loss: 0.00862746
Epoch [4/300], Train Loss: 0.008509
Validation Loss: 0.00845546
Epoch [5/300], Train Loss: 0.008348
Validation Loss: 0.00829437
Epoch [6/300], Train Loss: 0.008222
Validation Loss: 0.00813193
Epoch [7/300], Train Loss: 0.007994
Validation Loss: 0.00797611
Epoch [8/300], Train Loss: 0.007812
Validation Loss: 0.00783822
Epoch [9/300], Train Loss: 0.007684
Validation Loss: 0.00767746
Epoch [10/300], Train Loss: 0.007558
Validation Loss: 0.00756106
Epoch [11/300], Train Loss: 0.007456
Validation Loss: 0.00741182
Epoch [12/300], Train Loss: 0.007265
Validation Loss: 0.00729459
Epoch [13/300], Train Loss: 0.007159
Validation Loss: 0.00719901
Epoch [14/300], Train Loss: 0.007045
Validation Loss: 0.00710219
Epoch [15/300], Train Loss: 0.006954
Validation Loss: 0.00702371
Epoch [16/300], Train Loss: 0.006869
Validation Loss: 0.00695784
Epoch [17/300], Train Loss: 0.006817
Validation Loss: 0.00689563
Epoch [18/300], Train Loss: 0.006749
Validation Loss: 0.00683986
Epoch [19/300], Train Loss: 0.006715
Validation Loss: 0.00678837
Epoch [20/300], Train Loss: 0.006645
Validation Loss: 0.00674154
Epoch [21/300], Train Loss: 0.006605
Validation Loss: 0.00669200
Epoch [22/300], Train Loss: 0.006558
Validation Loss: 0.00664884
Epoch [23/300], Train Loss: 0.006542
Validation Loss: 0.00660282
Epoch [24/300], Train Loss: 0.006519
Validation Loss: 0.00657614
Epoch [25/300], Train Loss: 0.006383
Validation Loss: 0.00652113
Epoch [26/300], Train Loss: 0.006378
Validation Loss: 0.00652412
Epoch [27/300], Train Loss: 0.006314
Validation Loss: 0.00644167
Epoch [28/300], Train Loss: 0.006269
Validation Loss: 0.00640663
Epoch [29/300], Train Loss: 0.006255
Validation Loss: 0.00637667
Epoch [30/300], Train Loss: 0.006176
Validation Loss: 0.00636537
Epoch [31/300], Train Loss: 0.006202
Validation Loss: 0.00630827
Epoch [32/300], Train Loss: 0.006146
Validation Loss: 0.00628588
Epoch [33/300], Train Loss: 0.006115
Validation Loss: 0.00625308
Epoch [34/300], Train Loss: 0.006053
Validation Loss: 0.00624030
Epoch [35/300], Train Loss: 0.006041
Validation Loss: 0.00622546
Epoch [36/300], Train Loss: 0.005999
Validation Loss: 0.00617708
Epoch [37/300], Train Loss: 0.005977
Validation Loss: 0.00615302
Epoch [38/300], Train Loss: 0.005998
Validation Loss: 0.00615389
Epoch [39/300], Train Loss: 0.005956
Validation Loss: 0.00612408
Epoch [40/300], Train Loss: 0.005894
Validation Loss: 0.00609607
Epoch [41/300], Train Loss: 0.005910
Validation Loss: 0.00606582
Epoch [42/300], Train Loss: 0.005893
Validation Loss: 0.00606477
Epoch [43/300], Train Loss: 0.005873
Validation Loss: 0.00602926
Epoch [44/300], Train Loss: 0.005847
Validation Loss: 0.00600996
Epoch [45/300], Train Loss: 0.005840
Validation Loss: 0.00600088
Epoch [46/300], Train Loss: 0.005787
Validation Loss: 0.00597243
Epoch [47/300], Train Loss: 0.005801
Validation Loss: 0.00595636
Epoch [48/300], Train Loss: 0.005737
Validation Loss: 0.00594619
Epoch [49/300], Train Loss: 0.005739
Validation Loss: 0.00593638
Epoch [50/300], Train Loss: 0.005725
Validation Loss: 0.00593885
Epoch [51/300], Train Loss: 0.005716
Validation Loss: 0.00590684
Epoch [52/300], Train Loss: 0.005700
Validation Loss: 0.00588856
Epoch [53/300], Train Loss: 0.005702
Validation Loss: 0.00586686
Epoch [54/300], Train Loss: 0.005655
Validation Loss: 0.00585483
Epoch [55/300], Train Loss: 0.005633
Validation Loss: 0.00584199
Epoch [56/300], Train Loss: 0.005633
Validation Loss: 0.00584272
Epoch [57/300], Train Loss: 0.005651
Validation Loss: 0.00581797
Epoch [58/300], Train Loss: 0.005634
Validation Loss: 0.00581207
Epoch [59/300], Train Loss: 0.005588
Validation Loss: 0.00579930
Epoch [60/300], Train Loss: 0.005597
Validation Loss: 0.00578278
Epoch [61/300], Train Loss: 0.005587
Validation Loss: 0.00577870
Epoch [62/300], Train Loss: 0.005547
Validation Loss: 0.00576908
Epoch [63/300], Train Loss: 0.005576
Validation Loss: 0.00576678
Epoch [64/300], Train Loss: 0.005544
Validation Loss: 0.00575949
Epoch [65/300], Train Loss: 0.005538
Validation Loss: 0.00574257
Epoch [66/300], Train Loss: 0.005530
Validation Loss: 0.00574183
Epoch [67/300], Train Loss: 0.005501
Validation Loss: 0.00572858
Epoch [68/300], Train Loss: 0.005503
Validation Loss: 0.00574335
Epoch [69/300], Train Loss: 0.005505
Validation Loss: 0.00571019
Epoch [70/300], Train Loss: 0.005483
Validation Loss: 0.00570442
Epoch [71/300], Train Loss: 0.005471
Validation Loss: 0.00569768
Epoch [72/300], Train Loss: 0.005456
Validation Loss: 0.00569314
Epoch [73/300], Train Loss: 0.005485
Validation Loss: 0.00568699
Epoch [74/300], Train Loss: 0.005437
Validation Loss: 0.00568162
Epoch [75/300], Train Loss: 0.005464
Validation Loss: 0.00570197
Epoch [76/300], Train Loss: 0.005448
Validation Loss: 0.00567340
Epoch [77/300], Train Loss: 0.005490
Validation Loss: 0.00568124
Epoch [78/300], Train Loss: 0.005451
Validation Loss: 0.00566279
Epoch [79/300], Train Loss: 0.005414
Validation Loss: 0.00566274
Epoch [80/300], Train Loss: 0.005430
Validation Loss: 0.00565833
Epoch [81/300], Train Loss: 0.005458
Validation Loss: 0.00568549
Epoch [82/300], Train Loss: 0.005419
Validation Loss: 0.00564758
Epoch [83/300], Train Loss: 0.005409
Validation Loss: 0.00565542
Epoch [84/300], Train Loss: 0.005391
Validation Loss: 0.00563834
Epoch [85/300], Train Loss: 0.005406
Validation Loss: 0.00564761
Epoch [86/300], Train Loss: 0.005413
Validation Loss: 0.00563017
Epoch [87/300], Train Loss: 0.005428
Validation Loss: 0.00562793
Epoch [88/300], Train Loss: 0.005386
Validation Loss: 0.00562712
Epoch [89/300], Train Loss: 0.005398
Validation Loss: 0.00561850
Epoch [90/300], Train Loss: 0.005384
Validation Loss: 0.00562237
Epoch [91/300], Train Loss: 0.005393
Validation Loss: 0.00560012
Epoch [92/300], Train Loss: 0.005414
Validation Loss: 0.00560375
Epoch [93/300], Train Loss: 0.005367
Validation Loss: 0.00558500
Epoch [94/300], Train Loss: 0.005344
Validation Loss: 0.00557329
Epoch [95/300], Train Loss: 0.005337
Validation Loss: 0.00556361
Epoch [96/300], Train Loss: 0.005347
Validation Loss: 0.00555714
Epoch [97/300], Train Loss: 0.005342
Validation Loss: 0.00554184
Epoch [98/300], Train Loss: 0.005318
Validation Loss: 0.00553214
Epoch [99/300], Train Loss: 0.005306
Validation Loss: 0.00551454
Epoch [100/300], Train Loss: 0.005327
Validation Loss: 0.00550063
Epoch [101/300], Train Loss: 0.005349
Validation Loss: 0.00557253
Epoch [102/300], Train Loss: 0.005307
Validation Loss: 0.00550134
Epoch [103/300], Train Loss: 0.005269
Validation Loss: 0.00550961
Epoch [104/300], Train Loss: 0.005291
Validation Loss: 0.00544068
Epoch [105/300], Train Loss: 0.005201
Validation Loss: 0.00538883
Epoch [106/300], Train Loss: 0.005183
Validation Loss: 0.00541630
Epoch [107/300], Train Loss: 0.005178
Validation Loss: 0.00538840
Epoch [108/300], Train Loss: 0.005178
Validation Loss: 0.00547042
Epoch [109/300], Train Loss: 0.005179
Validation Loss: 0.00535745
Epoch [110/300], Train Loss: 0.005158
Validation Loss: 0.00535284
Epoch [111/300], Train Loss: 0.005183
Validation Loss: 0.00539419
Epoch [112/300], Train Loss: 0.005126
Validation Loss: 0.00533531
Epoch [113/300], Train Loss: 0.005150
Validation Loss: 0.00532835
Epoch [114/300], Train Loss: 0.005130
Validation Loss: 0.00533015
Epoch [115/300], Train Loss: 0.005106
Validation Loss: 0.00530956
Epoch [116/300], Train Loss: 0.005113
Validation Loss: 0.00530323
Epoch [117/300], Train Loss: 0.005067
Validation Loss: 0.00530985
Epoch [118/300], Train Loss: 0.005120
Validation Loss: 0.00529164
Epoch [119/300], Train Loss: 0.005066
Validation Loss: 0.00533320
Epoch [120/300], Train Loss: 0.005070
Validation Loss: 0.00527623
Epoch [121/300], Train Loss: 0.005057
Validation Loss: 0.00526129
Epoch [122/300], Train Loss: 0.005044
Validation Loss: 0.00526576
Epoch [123/300], Train Loss: 0.005024
Validation Loss: 0.00525013
Epoch [124/300], Train Loss: 0.005038
Validation Loss: 0.00522474
Epoch [125/300], Train Loss: 0.004991
Validation Loss: 0.00521624
Epoch [126/300], Train Loss: 0.005006
Validation Loss: 0.00523039
Epoch [127/300], Train Loss: 0.004982
Validation Loss: 0.00520920
Epoch [128/300], Train Loss: 0.004978
Validation Loss: 0.00518213
Epoch [129/300], Train Loss: 0.004979
Validation Loss: 0.00516780
Epoch [130/300], Train Loss: 0.004954
Validation Loss: 0.00523430
Epoch [131/300], Train Loss: 0.004980
Validation Loss: 0.00513448
Epoch [132/300], Train Loss: 0.004939
Validation Loss: 0.00511643
Epoch [133/300], Train Loss: 0.004933
Validation Loss: 0.00513219
Epoch [134/300], Train Loss: 0.004918
Validation Loss: 0.00529939
Epoch [135/300], Train Loss: 0.004980
Validation Loss: 0.00508300
Epoch [136/300], Train Loss: 0.004890
Validation Loss: 0.00507131
Epoch [137/300], Train Loss: 0.004864
Validation Loss: 0.00507456
Epoch [138/300], Train Loss: 0.004853
Validation Loss: 0.00504826
Epoch [139/300], Train Loss: 0.004860
Validation Loss: 0.00502801
Epoch [140/300], Train Loss: 0.004832
Validation Loss: 0.00501900
Epoch [141/300], Train Loss: 0.004840
Validation Loss: 0.00501462
Epoch [142/300], Train Loss: 0.004850
Validation Loss: 0.00534107
Epoch [143/300], Train Loss: 0.004933
Validation Loss: 0.00504370
Epoch [144/300], Train Loss: 0.004846
Validation Loss: 0.00506434
Epoch [145/300], Train Loss: 0.004840
Validation Loss: 0.00501884
Epoch [146/300], Train Loss: 0.004856
Validation Loss: 0.00498937
Epoch [147/300], Train Loss: 0.004798
Validation Loss: 0.00502622
Epoch [148/300], Train Loss: 0.004802
Validation Loss: 0.00496471
Epoch [149/300], Train Loss: 0.004785
Validation Loss: 0.00495022
Epoch [150/300], Train Loss: 0.004805
Validation Loss: 0.00499311
Epoch [151/300], Train Loss: 0.004795
Validation Loss: 0.00500337
Epoch [152/300], Train Loss: 0.004807
Validation Loss: 0.00493722
Epoch [153/300], Train Loss: 0.004793
Validation Loss: 0.00493520
Epoch [154/300], Train Loss: 0.004781
Validation Loss: 0.00492936
Epoch [155/300], Train Loss: 0.004759
Validation Loss: 0.00491705
Epoch [156/300], Train Loss: 0.004759
Validation Loss: 0.00491688
Epoch [157/300], Train Loss: 0.004767
Validation Loss: 0.00490221
Epoch [158/300], Train Loss: 0.004749
Validation Loss: 0.00490851
Epoch [159/300], Train Loss: 0.004805
Validation Loss: 0.00493101
Epoch [160/300], Train Loss: 0.004748
Validation Loss: 0.00487465
Epoch [161/300], Train Loss: 0.004725
Validation Loss: 0.00487887
Epoch [162/300], Train Loss: 0.004719
Validation Loss: 0.00490328
Epoch [163/300], Train Loss: 0.004758
Validation Loss: 0.00491299
Epoch [164/300], Train Loss: 0.004738
Validation Loss: 0.00486423
Epoch [165/300], Train Loss: 0.004715
Validation Loss: 0.00485817
Epoch [166/300], Train Loss: 0.004703
Validation Loss: 0.00485520
Epoch [167/300], Train Loss: 0.004705
Validation Loss: 0.00485232
Epoch [168/300], Train Loss: 0.004703
Validation Loss: 0.00485256
Epoch [169/300], Train Loss: 0.004698
Validation Loss: 0.00488473
Epoch [170/300], Train Loss: 0.004709
Validation Loss: 0.00492265
Epoch [171/300], Train Loss: 0.004714
Validation Loss: 0.00483553
Epoch [172/300], Train Loss: 0.004700
Validation Loss: 0.00482856
Epoch [173/300], Train Loss: 0.004694
Validation Loss: 0.00483932
Epoch [174/300], Train Loss: 0.004716
Validation Loss: 0.00481883
Epoch [175/300], Train Loss: 0.004678
Validation Loss: 0.00482827
Epoch [176/300], Train Loss: 0.004670
Validation Loss: 0.00481058
Epoch [177/300], Train Loss: 0.004693
Validation Loss: 0.00481407
Epoch [178/300], Train Loss: 0.004677
Validation Loss: 0.00481221
Epoch [179/300], Train Loss: 0.004668
Validation Loss: 0.00480615
Epoch [180/300], Train Loss: 0.004680
Validation Loss: 0.00479901
Epoch [181/300], Train Loss: 0.004676
Validation Loss: 0.00479568
Epoch [182/300], Train Loss: 0.004680
Validation Loss: 0.00480114
Epoch [183/300], Train Loss: 0.004678
Validation Loss: 0.00479830
Epoch [184/300], Train Loss: 0.004659
Validation Loss: 0.00487059
Epoch [185/300], Train Loss: 0.004697
Validation Loss: 0.00479398
Epoch [186/300], Train Loss: 0.004677
Validation Loss: 0.00501110
Epoch [187/300], Train Loss: 0.004663
Validation Loss: 0.00480173
Epoch [188/300], Train Loss: 0.004669
Validation Loss: 0.00479630
Epoch [189/300], Train Loss: 0.004655
Validation Loss: 0.00478794
Epoch [190/300], Train Loss: 0.004650
Validation Loss: 0.00478500
Epoch [191/300], Train Loss: 0.004653
Validation Loss: 0.00478575
Epoch [192/300], Train Loss: 0.004650
Validation Loss: 0.00480102
Epoch [193/300], Train Loss: 0.004655
Validation Loss: 0.00480131
Epoch [194/300], Train Loss: 0.004665
Validation Loss: 0.00483358
Epoch [195/300], Train Loss: 0.004666
Validation Loss: 0.00477451
Epoch [196/300], Train Loss: 0.004635
Validation Loss: 0.00477848
Epoch [197/300], Train Loss: 0.004654
Validation Loss: 0.00478717
Epoch [198/300], Train Loss: 0.004632
Validation Loss: 0.00479622
Epoch [199/300], Train Loss: 0.004640
Validation Loss: 0.00477345
Epoch [200/300], Train Loss: 0.004646
Validation Loss: 0.00476900
Epoch [201/300], Train Loss: 0.004646
Validation Loss: 0.00478626
Epoch [202/300], Train Loss: 0.004638
Validation Loss: 0.00478435
Epoch [203/300], Train Loss: 0.004649
Validation Loss: 0.00476039
Epoch [204/300], Train Loss: 0.004639
Validation Loss: 0.00477258
Epoch [205/300], Train Loss: 0.004623
Validation Loss: 0.00480063
Epoch [206/300], Train Loss: 0.004628
Validation Loss: 0.00476355
Epoch [207/300], Train Loss: 0.004635
Validation Loss: 0.00478298
Epoch [208/300], Train Loss: 0.004645
Validation Loss: 0.00476816
Epoch [209/300], Train Loss: 0.004635
Validation Loss: 0.00476278
Epoch [210/300], Train Loss: 0.004631
Validation Loss: 0.00475561
Epoch [211/300], Train Loss: 0.004629
Validation Loss: 0.00475466
Epoch [212/300], Train Loss: 0.004635
Validation Loss: 0.00482644
Epoch [213/300], Train Loss: 0.004629
Validation Loss: 0.00476504
Epoch [214/300], Train Loss: 0.004631
Validation Loss: 0.00483313
Epoch [215/300], Train Loss: 0.004719
Validation Loss: 0.00478001
Epoch [216/300], Train Loss: 0.004619
Validation Loss: 0.00476559
Epoch [217/300], Train Loss: 0.004635
Validation Loss: 0.00479178
Epoch [218/300], Train Loss: 0.004616
Validation Loss: 0.00475531
Epoch [219/300], Train Loss: 0.004624
Validation Loss: 0.00475752
Epoch [220/300], Train Loss: 0.004648
Validation Loss: 0.00475608
Epoch [221/300], Train Loss: 0.004631
Validation Loss: 0.00476599
Early stopping triggered

Evaluating model for: Router
Run 2/72 completed in 1210.40 seconds with: {'MAE': np.float32(0.18538763), 'MSE': np.float32(0.056984417), 'RMSE': np.float32(0.23871408), 'SAE': np.float32(5.925742e-06), 'NDE': np.float32(0.011931167)}

Run 3/72: hidden=128, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Router
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.064058
Validation Loss: 0.03035000
Epoch [2/300], Train Loss: 0.011414
Validation Loss: 0.00850278
Epoch [3/300], Train Loss: 0.008259
Validation Loss: 0.00815913
Epoch [4/300], Train Loss: 0.008007
Validation Loss: 0.00797139
Epoch [5/300], Train Loss: 0.007846
Validation Loss: 0.00780204
Epoch [6/300], Train Loss: 0.007703
Validation Loss: 0.00763119
Epoch [7/300], Train Loss: 0.007449
Validation Loss: 0.00746897
Epoch [8/300], Train Loss: 0.007256
Validation Loss: 0.00731030
Epoch [9/300], Train Loss: 0.007113
Validation Loss: 0.00714522
Epoch [10/300], Train Loss: 0.006971
Validation Loss: 0.00701292
Epoch [11/300], Train Loss: 0.006904
Validation Loss: 0.00691074
Epoch [12/300], Train Loss: 0.006731
Validation Loss: 0.00681907
Epoch [13/300], Train Loss: 0.006652
Validation Loss: 0.00673903
Epoch [14/300], Train Loss: 0.006561
Validation Loss: 0.00667518
Epoch [15/300], Train Loss: 0.006460
Validation Loss: 0.00658504
Epoch [16/300], Train Loss: 0.006382
Validation Loss: 0.00651937
Epoch [17/300], Train Loss: 0.006334
Validation Loss: 0.00645367
Epoch [18/300], Train Loss: 0.006248
Validation Loss: 0.00639056
Epoch [19/300], Train Loss: 0.006202
Validation Loss: 0.00633351
Epoch [20/300], Train Loss: 0.006146
Validation Loss: 0.00628176
Epoch [21/300], Train Loss: 0.006089
Validation Loss: 0.00623564
Epoch [22/300], Train Loss: 0.006039
Validation Loss: 0.00620902
Epoch [23/300], Train Loss: 0.006034
Validation Loss: 0.00615557
Epoch [24/300], Train Loss: 0.006028
Validation Loss: 0.00615705
Epoch [25/300], Train Loss: 0.005906
Validation Loss: 0.00609224
Epoch [26/300], Train Loss: 0.005890
Validation Loss: 0.00610549
Epoch [27/300], Train Loss: 0.005842
Validation Loss: 0.00605192
Epoch [28/300], Train Loss: 0.005805
Validation Loss: 0.00604442
Epoch [29/300], Train Loss: 0.005818
Validation Loss: 0.00599009
Epoch [30/300], Train Loss: 0.005746
Validation Loss: 0.00598015
Epoch [31/300], Train Loss: 0.005776
Validation Loss: 0.00595632
Epoch [32/300], Train Loss: 0.005747
Validation Loss: 0.00594001
Epoch [33/300], Train Loss: 0.005727
Validation Loss: 0.00591485
Epoch [34/300], Train Loss: 0.005671
Validation Loss: 0.00591739
Epoch [35/300], Train Loss: 0.005663
Validation Loss: 0.00589683
Epoch [36/300], Train Loss: 0.005634
Validation Loss: 0.00586848
Epoch [37/300], Train Loss: 0.005617
Validation Loss: 0.00585506
Epoch [38/300], Train Loss: 0.005651
Validation Loss: 0.00589096
Epoch [39/300], Train Loss: 0.005614
Validation Loss: 0.00582917
Epoch [40/300], Train Loss: 0.005569
Validation Loss: 0.00583243
Epoch [41/300], Train Loss: 0.005599
Validation Loss: 0.00580470
Epoch [42/300], Train Loss: 0.005582
Validation Loss: 0.00580998
Epoch [43/300], Train Loss: 0.005582
Validation Loss: 0.00578629
Epoch [44/300], Train Loss: 0.005563
Validation Loss: 0.00578273
Epoch [45/300], Train Loss: 0.005562
Validation Loss: 0.00577622
Epoch [46/300], Train Loss: 0.005517
Validation Loss: 0.00575107
Epoch [47/300], Train Loss: 0.005529
Validation Loss: 0.00573202
Epoch [48/300], Train Loss: 0.005476
Validation Loss: 0.00572504
Epoch [49/300], Train Loss: 0.005477
Validation Loss: 0.00572986
Epoch [50/300], Train Loss: 0.005477
Validation Loss: 0.00573248
Epoch [51/300], Train Loss: 0.005467
Validation Loss: 0.00568622
Epoch [52/300], Train Loss: 0.005439
Validation Loss: 0.00565921
Epoch [53/300], Train Loss: 0.005443
Validation Loss: 0.00562977
Epoch [54/300], Train Loss: 0.005393
Validation Loss: 0.00561629
Epoch [55/300], Train Loss: 0.005356
Validation Loss: 0.00558579
Epoch [56/300], Train Loss: 0.005361
Validation Loss: 0.00561643
Epoch [57/300], Train Loss: 0.005323
Validation Loss: 0.00554024
Epoch [58/300], Train Loss: 0.005311
Validation Loss: 0.00545308
Epoch [59/300], Train Loss: 0.005247
Validation Loss: 0.00541364
Epoch [60/300], Train Loss: 0.005211
Validation Loss: 0.00538621
Epoch [61/300], Train Loss: 0.005150
Validation Loss: 0.00544303
Epoch [62/300], Train Loss: 0.005179
Validation Loss: 0.00536024
Epoch [63/300], Train Loss: 0.005109
Validation Loss: 0.00529530
Epoch [64/300], Train Loss: 0.005070
Validation Loss: 0.00527553
Epoch [65/300], Train Loss: 0.005041
Validation Loss: 0.00524922
Epoch [66/300], Train Loss: 0.005059
Validation Loss: 0.00520564
Epoch [67/300], Train Loss: 0.004977
Validation Loss: 0.00522497
Epoch [68/300], Train Loss: 0.004967
Validation Loss: 0.00517117
Epoch [69/300], Train Loss: 0.004951
Validation Loss: 0.00512843
Epoch [70/300], Train Loss: 0.004938
Validation Loss: 0.00510422
Epoch [71/300], Train Loss: 0.004880
Validation Loss: 0.00519777
Epoch [72/300], Train Loss: 0.004926
Validation Loss: 0.00505904
Epoch [73/300], Train Loss: 0.004865
Validation Loss: 0.00503920
Epoch [74/300], Train Loss: 0.004814
Validation Loss: 0.00502780
Epoch [75/300], Train Loss: 0.004825
Validation Loss: 0.00499101
Epoch [76/300], Train Loss: 0.004793
Validation Loss: 0.00499052
Epoch [77/300], Train Loss: 0.004819
Validation Loss: 0.00496012
Epoch [78/300], Train Loss: 0.004803
Validation Loss: 0.00495614
Epoch [79/300], Train Loss: 0.004760
Validation Loss: 0.00494015
Epoch [80/300], Train Loss: 0.004760
Validation Loss: 0.00492336
Epoch [81/300], Train Loss: 0.004744
Validation Loss: 0.00492851
Epoch [82/300], Train Loss: 0.004742
Validation Loss: 0.00495906
Epoch [83/300], Train Loss: 0.004723
Validation Loss: 0.00490400
Epoch [84/300], Train Loss: 0.004711
Validation Loss: 0.00490537
Epoch [85/300], Train Loss: 0.004737
Validation Loss: 0.00486864
Epoch [86/300], Train Loss: 0.004702
Validation Loss: 0.00490650
Epoch [87/300], Train Loss: 0.004691
Validation Loss: 0.00486004
Epoch [88/300], Train Loss: 0.004684
Validation Loss: 0.00485484
Epoch [89/300], Train Loss: 0.004690
Validation Loss: 0.00487959
Epoch [90/300], Train Loss: 0.004670
Validation Loss: 0.00489408
Epoch [91/300], Train Loss: 0.004689
Validation Loss: 0.00485739
Epoch [92/300], Train Loss: 0.004684
Validation Loss: 0.00484493
Epoch [93/300], Train Loss: 0.004656
Validation Loss: 0.00482233
Epoch [94/300], Train Loss: 0.004648
Validation Loss: 0.00488149
Epoch [95/300], Train Loss: 0.004657
Validation Loss: 0.00490619
Epoch [96/300], Train Loss: 0.004716
Validation Loss: 0.00481297
Epoch [97/300], Train Loss: 0.004630
Validation Loss: 0.00480100
Epoch [98/300], Train Loss: 0.004635
Validation Loss: 0.00484426
Epoch [99/300], Train Loss: 0.004632
Validation Loss: 0.00479450
Epoch [100/300], Train Loss: 0.004654
Validation Loss: 0.00479358
Epoch [101/300], Train Loss: 0.004675
Validation Loss: 0.00483190
Epoch [102/300], Train Loss: 0.004643
Validation Loss: 0.00478803
Epoch [103/300], Train Loss: 0.004637
Validation Loss: 0.00481583
Epoch [104/300], Train Loss: 0.004680
Validation Loss: 0.00478560
Epoch [105/300], Train Loss: 0.004620
Validation Loss: 0.00479115
Epoch [106/300], Train Loss: 0.004617
Validation Loss: 0.00478516
Epoch [107/300], Train Loss: 0.004615
Validation Loss: 0.00477364
Epoch [108/300], Train Loss: 0.004614
Validation Loss: 0.00479114
Epoch [109/300], Train Loss: 0.004618
Validation Loss: 0.00476432
Epoch [110/300], Train Loss: 0.004627
Validation Loss: 0.00477886
Epoch [111/300], Train Loss: 0.004635
Validation Loss: 0.00485533
Epoch [112/300], Train Loss: 0.004602
Validation Loss: 0.00482854
Epoch [113/300], Train Loss: 0.004610
Validation Loss: 0.00477744
Epoch [114/300], Train Loss: 0.004619
Validation Loss: 0.00476315
Epoch [115/300], Train Loss: 0.004598
Validation Loss: 0.00477394
Epoch [116/300], Train Loss: 0.004625
Validation Loss: 0.00481277
Epoch [117/300], Train Loss: 0.004584
Validation Loss: 0.00475939
Epoch [118/300], Train Loss: 0.004611
Validation Loss: 0.00476203
Epoch [119/300], Train Loss: 0.004605
Validation Loss: 0.00474756
Epoch [120/300], Train Loss: 0.004588
Validation Loss: 0.00475736
Epoch [121/300], Train Loss: 0.004592
Validation Loss: 0.00474126
Epoch [122/300], Train Loss: 0.004596
Validation Loss: 0.00473773
Epoch [123/300], Train Loss: 0.004585
Validation Loss: 0.00473536
Epoch [124/300], Train Loss: 0.004585
Validation Loss: 0.00477728
Epoch [125/300], Train Loss: 0.004565
Validation Loss: 0.00479030
Epoch [126/300], Train Loss: 0.004600
Validation Loss: 0.00478882
Epoch [127/300], Train Loss: 0.004580
Validation Loss: 0.00480582
Epoch [128/300], Train Loss: 0.004607
Validation Loss: 0.00474870
Epoch [129/300], Train Loss: 0.004573
Validation Loss: 0.00473420
Epoch [130/300], Train Loss: 0.004577
Validation Loss: 0.00485408
Epoch [131/300], Train Loss: 0.004591
Validation Loss: 0.00471863
Epoch [132/300], Train Loss: 0.004594
Validation Loss: 0.00473619
Epoch [133/300], Train Loss: 0.004570
Validation Loss: 0.00476016
Epoch [134/300], Train Loss: 0.004568
Validation Loss: 0.00491109
Epoch [135/300], Train Loss: 0.004639
Validation Loss: 0.00475617
Epoch [136/300], Train Loss: 0.004554
Validation Loss: 0.00471318
Epoch [137/300], Train Loss: 0.004567
Validation Loss: 0.00473171
Epoch [138/300], Train Loss: 0.004539
Validation Loss: 0.00475315
Epoch [139/300], Train Loss: 0.004557
Validation Loss: 0.00471791
Epoch [140/300], Train Loss: 0.004547
Validation Loss: 0.00472395
Epoch [141/300], Train Loss: 0.004545
Validation Loss: 0.00473699
Epoch [142/300], Train Loss: 0.004564
Validation Loss: 0.00495920
Epoch [143/300], Train Loss: 0.004619
Validation Loss: 0.00482914
Epoch [144/300], Train Loss: 0.004576
Validation Loss: 0.00479887
Epoch [145/300], Train Loss: 0.004551
Validation Loss: 0.00470552
Epoch [146/300], Train Loss: 0.004570
Validation Loss: 0.00474294
Epoch [147/300], Train Loss: 0.004543
Validation Loss: 0.00476855
Epoch [148/300], Train Loss: 0.004550
Validation Loss: 0.00469810
Epoch [149/300], Train Loss: 0.004532
Validation Loss: 0.00470839
Epoch [150/300], Train Loss: 0.004562
Validation Loss: 0.00473638
Epoch [151/300], Train Loss: 0.004565
Validation Loss: 0.00476217
Epoch [152/300], Train Loss: 0.004559
Validation Loss: 0.00471866
Epoch [153/300], Train Loss: 0.004553
Validation Loss: 0.00473026
Epoch [154/300], Train Loss: 0.004539
Validation Loss: 0.00470935
Epoch [155/300], Train Loss: 0.004530
Validation Loss: 0.00469939
Epoch [156/300], Train Loss: 0.004530
Validation Loss: 0.00472848
Epoch [157/300], Train Loss: 0.004536
Validation Loss: 0.00468864
Epoch [158/300], Train Loss: 0.004530
Validation Loss: 0.00470974
Epoch [159/300], Train Loss: 0.004559
Validation Loss: 0.00476080
Epoch [160/300], Train Loss: 0.004533
Validation Loss: 0.00471953
Epoch [161/300], Train Loss: 0.004518
Validation Loss: 0.00468763
Epoch [162/300], Train Loss: 0.004515
Validation Loss: 0.00474920
Epoch [163/300], Train Loss: 0.004537
Validation Loss: 0.00470023
Epoch [164/300], Train Loss: 0.004529
Validation Loss: 0.00472483
Epoch [165/300], Train Loss: 0.004511
Validation Loss: 0.00467373
Epoch [166/300], Train Loss: 0.004524
Validation Loss: 0.00467532
Epoch [167/300], Train Loss: 0.004517
Validation Loss: 0.00466999
Epoch [168/300], Train Loss: 0.004522
Validation Loss: 0.00469033
Epoch [169/300], Train Loss: 0.004513
Validation Loss: 0.00473079
Epoch [170/300], Train Loss: 0.004518
Validation Loss: 0.00470568
Epoch [171/300], Train Loss: 0.004520
Validation Loss: 0.00469400
Epoch [172/300], Train Loss: 0.004527
Validation Loss: 0.00467928
Epoch [173/300], Train Loss: 0.004520
Validation Loss: 0.00468732
Epoch [174/300], Train Loss: 0.004572
Validation Loss: 0.00467302
Epoch [175/300], Train Loss: 0.004501
Validation Loss: 0.00466552
Epoch [176/300], Train Loss: 0.004506
Validation Loss: 0.00466510
Epoch [177/300], Train Loss: 0.004512
Validation Loss: 0.00468654
Epoch [178/300], Train Loss: 0.004509
Validation Loss: 0.00467042
Epoch [179/300], Train Loss: 0.004494
Validation Loss: 0.00468396
Epoch [180/300], Train Loss: 0.004503
Validation Loss: 0.00467763
Epoch [181/300], Train Loss: 0.004496
Validation Loss: 0.00467409
Epoch [182/300], Train Loss: 0.004508
Validation Loss: 0.00466276
Epoch [183/300], Train Loss: 0.004506
Validation Loss: 0.00466168
Epoch [184/300], Train Loss: 0.004492
Validation Loss: 0.00468537
Epoch [185/300], Train Loss: 0.004512
Validation Loss: 0.00469566
Epoch [186/300], Train Loss: 0.004490
Validation Loss: 0.00466621
Epoch [187/300], Train Loss: 0.004504
Validation Loss: 0.00470777
Epoch [188/300], Train Loss: 0.004507
Validation Loss: 0.00465394
Epoch [189/300], Train Loss: 0.004470
Validation Loss: 0.00465100
Epoch [190/300], Train Loss: 0.004492
Validation Loss: 0.00465402
Epoch [191/300], Train Loss: 0.004470
Validation Loss: 0.00465003
Epoch [192/300], Train Loss: 0.004477
Validation Loss: 0.00465480
Epoch [193/300], Train Loss: 0.004473
Validation Loss: 0.00473387
Epoch [194/300], Train Loss: 0.004486
Validation Loss: 0.00466067
Epoch [195/300], Train Loss: 0.004492
Validation Loss: 0.00465537
Epoch [196/300], Train Loss: 0.004475
Validation Loss: 0.00468058
Epoch [197/300], Train Loss: 0.004481
Validation Loss: 0.00464434
Epoch [198/300], Train Loss: 0.004475
Validation Loss: 0.00468263
Epoch [199/300], Train Loss: 0.004468
Validation Loss: 0.00464412
Epoch [200/300], Train Loss: 0.004513
Validation Loss: 0.00464018
Epoch [201/300], Train Loss: 0.004495
Validation Loss: 0.00471001
Epoch [202/300], Train Loss: 0.004484
Validation Loss: 0.00466784
Epoch [203/300], Train Loss: 0.004472
Validation Loss: 0.00463259
Epoch [204/300], Train Loss: 0.004470
Validation Loss: 0.00464749
Epoch [205/300], Train Loss: 0.004453
Validation Loss: 0.00465347
Epoch [206/300], Train Loss: 0.004462
Validation Loss: 0.00464120
Epoch [207/300], Train Loss: 0.004455
Validation Loss: 0.00462665
Epoch [208/300], Train Loss: 0.004467
Validation Loss: 0.00462676
Epoch [209/300], Train Loss: 0.004456
Validation Loss: 0.00464852
Epoch [210/300], Train Loss: 0.004469
Validation Loss: 0.00462391
Epoch [211/300], Train Loss: 0.004466
Validation Loss: 0.00462725
Epoch [212/300], Train Loss: 0.004474
Validation Loss: 0.00463088
Epoch [213/300], Train Loss: 0.004448
Validation Loss: 0.00462337
Epoch [214/300], Train Loss: 0.004447
Validation Loss: 0.00461886
Epoch [215/300], Train Loss: 0.004565
Validation Loss: 0.00479776
Epoch [216/300], Train Loss: 0.004451
Validation Loss: 0.00461839
Epoch [217/300], Train Loss: 0.004434
Validation Loss: 0.00462421
Epoch [218/300], Train Loss: 0.004433
Validation Loss: 0.00462151
Epoch [219/300], Train Loss: 0.004444
Validation Loss: 0.00461453
Epoch [220/300], Train Loss: 0.004457
Validation Loss: 0.00460656
Epoch [221/300], Train Loss: 0.004443
Validation Loss: 0.00461452
Epoch [222/300], Train Loss: 0.004442
Validation Loss: 0.00460186
Epoch [223/300], Train Loss: 0.004418
Validation Loss: 0.00459968
Epoch [224/300], Train Loss: 0.004415
Validation Loss: 0.00459882
Epoch [225/300], Train Loss: 0.004416
Validation Loss: 0.00459709
Epoch [226/300], Train Loss: 0.004421
Validation Loss: 0.00459106
Epoch [227/300], Train Loss: 0.004421
Validation Loss: 0.00458721
Epoch [228/300], Train Loss: 0.004435
Validation Loss: 0.00467482
Epoch [229/300], Train Loss: 0.004425
Validation Loss: 0.00460659
Epoch [230/300], Train Loss: 0.004421
Validation Loss: 0.00460148
Epoch [231/300], Train Loss: 0.004400
Validation Loss: 0.00457817
Epoch [232/300], Train Loss: 0.004407
Validation Loss: 0.00457573
Epoch [233/300], Train Loss: 0.004407
Validation Loss: 0.00457137
Epoch [234/300], Train Loss: 0.004439
Validation Loss: 0.00460152
Epoch [235/300], Train Loss: 0.004420
Validation Loss: 0.00456740
Epoch [236/300], Train Loss: 0.004416
Validation Loss: 0.00456506
Epoch [237/300], Train Loss: 0.004399
Validation Loss: 0.00456512
Epoch [238/300], Train Loss: 0.004414
Validation Loss: 0.00456246
Epoch [239/300], Train Loss: 0.004391
Validation Loss: 0.00456045
Epoch [240/300], Train Loss: 0.004387
Validation Loss: 0.00456817
Epoch [241/300], Train Loss: 0.004382
Validation Loss: 0.00456523
Epoch [242/300], Train Loss: 0.004381
Validation Loss: 0.00455429
Epoch [243/300], Train Loss: 0.004397
Validation Loss: 0.00456461
Epoch [244/300], Train Loss: 0.004399
Validation Loss: 0.00455452
Epoch [245/300], Train Loss: 0.004418
Validation Loss: 0.00455341
Epoch [246/300], Train Loss: 0.004390
Validation Loss: 0.00455398
Epoch [247/300], Train Loss: 0.004391
Validation Loss: 0.00456699
Epoch [248/300], Train Loss: 0.004399
Validation Loss: 0.00458200
Epoch [249/300], Train Loss: 0.004389
Validation Loss: 0.00457547
Epoch [250/300], Train Loss: 0.004394
Validation Loss: 0.00454528
Epoch [251/300], Train Loss: 0.004389
Validation Loss: 0.00454825
Epoch [252/300], Train Loss: 0.004394
Validation Loss: 0.00455425
Epoch [253/300], Train Loss: 0.004401
Validation Loss: 0.00454103
Epoch [254/300], Train Loss: 0.004365
Validation Loss: 0.00455744
Epoch [255/300], Train Loss: 0.004385
Validation Loss: 0.00455307
Epoch [256/300], Train Loss: 0.004376
Validation Loss: 0.00454893
Epoch [257/300], Train Loss: 0.004386
Validation Loss: 0.00455417
Epoch [258/300], Train Loss: 0.004380
Validation Loss: 0.00454039
Epoch [259/300], Train Loss: 0.004362
Validation Loss: 0.00453935
Epoch [260/300], Train Loss: 0.004348
Validation Loss: 0.00454194
Epoch [261/300], Train Loss: 0.004372
Validation Loss: 0.00454671
Epoch [262/300], Train Loss: 0.004364
Validation Loss: 0.00456765
Epoch [263/300], Train Loss: 0.004361
Validation Loss: 0.00453362
Epoch [264/300], Train Loss: 0.004362
Validation Loss: 0.00455089
Epoch [265/300], Train Loss: 0.004384
Validation Loss: 0.00455446
Epoch [266/300], Train Loss: 0.004361
Validation Loss: 0.00453624
Epoch [267/300], Train Loss: 0.004503
Validation Loss: 0.00460858
Epoch [268/300], Train Loss: 0.004388
Validation Loss: 0.00454176
Epoch [269/300], Train Loss: 0.004369
Validation Loss: 0.00453463
Epoch [270/300], Train Loss: 0.004349
Validation Loss: 0.00453475
Epoch [271/300], Train Loss: 0.004356
Validation Loss: 0.00453580
Epoch [272/300], Train Loss: 0.004382
Validation Loss: 0.00453529
Epoch [273/300], Train Loss: 0.004380
Validation Loss: 0.00453316
Epoch [274/300], Train Loss: 0.004380
Validation Loss: 0.00453289
Epoch [275/300], Train Loss: 0.004355
Validation Loss: 0.00453771
Epoch [276/300], Train Loss: 0.004356
Validation Loss: 0.00453511
Epoch [277/300], Train Loss: 0.004344
Validation Loss: 0.00453209
Epoch [278/300], Train Loss: 0.004358
Validation Loss: 0.00453573
Epoch [279/300], Train Loss: 0.004373
Validation Loss: 0.00453146
Epoch [280/300], Train Loss: 0.004362
Validation Loss: 0.00452892
Epoch [281/300], Train Loss: 0.004359
Validation Loss: 0.00453569
Epoch [282/300], Train Loss: 0.004391
Validation Loss: 0.00454058
Epoch [283/300], Train Loss: 0.004395
Validation Loss: 0.00452791
Epoch [284/300], Train Loss: 0.004347
Validation Loss: 0.00453753
Epoch [285/300], Train Loss: 0.004342
Validation Loss: 0.00452733
Epoch [286/300], Train Loss: 0.004352
Validation Loss: 0.00452663
Epoch [287/300], Train Loss: 0.004343
Validation Loss: 0.00452387
Epoch [288/300], Train Loss: 0.004350
Validation Loss: 0.00453006
Epoch [289/300], Train Loss: 0.004358
Validation Loss: 0.00452365
Epoch [290/300], Train Loss: 0.004375
Validation Loss: 0.00454429
Epoch [291/300], Train Loss: 0.004374
Validation Loss: 0.00451827
Epoch [292/300], Train Loss: 0.004341
Validation Loss: 0.00453032
Epoch [293/300], Train Loss: 0.004344
Validation Loss: 0.00452342
Epoch [294/300], Train Loss: 0.004347
Validation Loss: 0.00451997
Epoch [295/300], Train Loss: 0.004355
Validation Loss: 0.00451941
Epoch [296/300], Train Loss: 0.004343
Validation Loss: 0.00452420
Epoch [297/300], Train Loss: 0.004339
Validation Loss: 0.00452239
Epoch [298/300], Train Loss: 0.004356
Validation Loss: 0.00451659
Epoch [299/300], Train Loss: 0.004330
Validation Loss: 0.00452899
Epoch [300/300], Train Loss: 0.004359
Validation Loss: 0.00453225

Evaluating model for: Router
Run 3/72 completed in 1749.45 seconds with: {'MAE': np.float32(0.17762433), 'MSE': np.float32(0.054012574), 'RMSE': np.float32(0.23240605), 'SAE': np.float32(0.00044356153), 'NDE': np.float32(0.0116158845)}

Run 4/72: hidden=128, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Router
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.086444
Validation Loss: 0.04235956
Epoch [2/300], Train Loss: 0.014111
Validation Loss: 0.00960168
Epoch [3/300], Train Loss: 0.009218
Validation Loss: 0.00903786
Epoch [4/300], Train Loss: 0.008901
Validation Loss: 0.00877469
Epoch [5/300], Train Loss: 0.008680
Validation Loss: 0.00854603
Epoch [6/300], Train Loss: 0.008499
Validation Loss: 0.00832344
Epoch [7/300], Train Loss: 0.008197
Validation Loss: 0.00811497
Epoch [8/300], Train Loss: 0.007952
Validation Loss: 0.00791759
Epoch [9/300], Train Loss: 0.007784
Validation Loss: 0.00772406
Epoch [10/300], Train Loss: 0.007649
Validation Loss: 0.00758716
Epoch [11/300], Train Loss: 0.007549
Validation Loss: 0.00747286
Epoch [12/300], Train Loss: 0.007377
Validation Loss: 0.00737144
Epoch [13/300], Train Loss: 0.007284
Validation Loss: 0.00727930
Epoch [14/300], Train Loss: 0.007161
Validation Loss: 0.00720584
Epoch [15/300], Train Loss: 0.007067
Validation Loss: 0.00710566
Epoch [16/300], Train Loss: 0.006980
Validation Loss: 0.00703301
Epoch [17/300], Train Loss: 0.006920
Validation Loss: 0.00694788
Epoch [18/300], Train Loss: 0.006815
Validation Loss: 0.00684769
Epoch [19/300], Train Loss: 0.006757
Validation Loss: 0.00676609
Epoch [20/300], Train Loss: 0.006681
Validation Loss: 0.00670554
Epoch [21/300], Train Loss: 0.006617
Validation Loss: 0.00664569
Epoch [22/300], Train Loss: 0.006566
Validation Loss: 0.00660744
Epoch [23/300], Train Loss: 0.006544
Validation Loss: 0.00654596
Epoch [24/300], Train Loss: 0.006514
Validation Loss: 0.00651523
Epoch [25/300], Train Loss: 0.006386
Validation Loss: 0.00644077
Epoch [26/300], Train Loss: 0.006350
Validation Loss: 0.00644262
Epoch [27/300], Train Loss: 0.006285
Validation Loss: 0.00634552
Epoch [28/300], Train Loss: 0.006215
Validation Loss: 0.00637563
Epoch [29/300], Train Loss: 0.006215
Validation Loss: 0.00626347
Epoch [30/300], Train Loss: 0.006116
Validation Loss: 0.00626096
Epoch [31/300], Train Loss: 0.006112
Validation Loss: 0.00619253
Epoch [32/300], Train Loss: 0.006057
Validation Loss: 0.00618353
Epoch [33/300], Train Loss: 0.006032
Validation Loss: 0.00612685
Epoch [34/300], Train Loss: 0.005961
Validation Loss: 0.00607750
Epoch [35/300], Train Loss: 0.005929
Validation Loss: 0.00606659
Epoch [36/300], Train Loss: 0.005871
Validation Loss: 0.00601548
Epoch [37/300], Train Loss: 0.005821
Validation Loss: 0.00597204
Epoch [38/300], Train Loss: 0.005834
Validation Loss: 0.00594379
Epoch [39/300], Train Loss: 0.005769
Validation Loss: 0.00591488
Epoch [40/300], Train Loss: 0.005717
Validation Loss: 0.00587346
Epoch [41/300], Train Loss: 0.005697
Validation Loss: 0.00587297
Epoch [42/300], Train Loss: 0.005649
Validation Loss: 0.00592376
Epoch [43/300], Train Loss: 0.005651
Validation Loss: 0.00582777
Epoch [44/300], Train Loss: 0.005563
Validation Loss: 0.00566773
Epoch [45/300], Train Loss: 0.005520
Validation Loss: 0.00561093
Epoch [46/300], Train Loss: 0.005413
Validation Loss: 0.00557571
Epoch [47/300], Train Loss: 0.005349
Validation Loss: 0.00541159
Epoch [48/300], Train Loss: 0.005254
Validation Loss: 0.00532502
Epoch [49/300], Train Loss: 0.005219
Validation Loss: 0.00526544
Epoch [50/300], Train Loss: 0.005152
Validation Loss: 0.00544405
Epoch [51/300], Train Loss: 0.005161
Validation Loss: 0.00518856
Epoch [52/300], Train Loss: 0.005120
Validation Loss: 0.00516411
Epoch [53/300], Train Loss: 0.005065
Validation Loss: 0.00512638
Epoch [54/300], Train Loss: 0.005070
Validation Loss: 0.00515746
Epoch [55/300], Train Loss: 0.005072
Validation Loss: 0.00510720
Epoch [56/300], Train Loss: 0.005063
Validation Loss: 0.00508871
Epoch [57/300], Train Loss: 0.005031
Validation Loss: 0.00509947
Epoch [58/300], Train Loss: 0.005033
Validation Loss: 0.00508372
Epoch [59/300], Train Loss: 0.004977
Validation Loss: 0.00504631
Epoch [60/300], Train Loss: 0.004990
Validation Loss: 0.00504318
Epoch [61/300], Train Loss: 0.004994
Validation Loss: 0.00501541
Epoch [62/300], Train Loss: 0.004945
Validation Loss: 0.00509155
Epoch [63/300], Train Loss: 0.004966
Validation Loss: 0.00501321
Epoch [64/300], Train Loss: 0.004956
Validation Loss: 0.00498298
Epoch [65/300], Train Loss: 0.004921
Validation Loss: 0.00497981
Epoch [66/300], Train Loss: 0.004911
Validation Loss: 0.00497276
Epoch [67/300], Train Loss: 0.004886
Validation Loss: 0.00498174
Epoch [68/300], Train Loss: 0.004881
Validation Loss: 0.00496198
Epoch [69/300], Train Loss: 0.004881
Validation Loss: 0.00492825
Epoch [70/300], Train Loss: 0.004909
Validation Loss: 0.00493193
Epoch [71/300], Train Loss: 0.004870
Validation Loss: 0.00495105
Epoch [72/300], Train Loss: 0.004874
Validation Loss: 0.00493159
Epoch [73/300], Train Loss: 0.004905
Validation Loss: 0.00494760
Epoch [74/300], Train Loss: 0.004817
Validation Loss: 0.00493645
Epoch [75/300], Train Loss: 0.004824
Validation Loss: 0.00488995
Epoch [76/300], Train Loss: 0.004810
Validation Loss: 0.00494310
Epoch [77/300], Train Loss: 0.004823
Validation Loss: 0.00486519
Epoch [78/300], Train Loss: 0.004801
Validation Loss: 0.00490282
Epoch [79/300], Train Loss: 0.004782
Validation Loss: 0.00484696
Epoch [80/300], Train Loss: 0.004784
Validation Loss: 0.00486760
Epoch [81/300], Train Loss: 0.004756
Validation Loss: 0.00483165
Epoch [82/300], Train Loss: 0.004783
Validation Loss: 0.00484303
Epoch [83/300], Train Loss: 0.004737
Validation Loss: 0.00482804
Epoch [84/300], Train Loss: 0.004746
Validation Loss: 0.00482044
Epoch [85/300], Train Loss: 0.004760
Validation Loss: 0.00482268
Epoch [86/300], Train Loss: 0.004728
Validation Loss: 0.00480616
Epoch [87/300], Train Loss: 0.004714
Validation Loss: 0.00479692
Epoch [88/300], Train Loss: 0.004720
Validation Loss: 0.00481988
Epoch [89/300], Train Loss: 0.004716
Validation Loss: 0.00479176
Epoch [90/300], Train Loss: 0.004698
Validation Loss: 0.00482095
Epoch [91/300], Train Loss: 0.004707
Validation Loss: 0.00480192
Epoch [92/300], Train Loss: 0.004704
Validation Loss: 0.00478444
Epoch [93/300], Train Loss: 0.004673
Validation Loss: 0.00476516
Epoch [94/300], Train Loss: 0.004673
Validation Loss: 0.00481006
Epoch [95/300], Train Loss: 0.004665
Validation Loss: 0.00478429
Epoch [96/300], Train Loss: 0.004725
Validation Loss: 0.00475043
Epoch [97/300], Train Loss: 0.004656
Validation Loss: 0.00474072
Epoch [98/300], Train Loss: 0.004647
Validation Loss: 0.00475523
Epoch [99/300], Train Loss: 0.004645
Validation Loss: 0.00474979
Epoch [100/300], Train Loss: 0.004652
Validation Loss: 0.00472682
Epoch [101/300], Train Loss: 0.004677
Validation Loss: 0.00471429
Epoch [102/300], Train Loss: 0.004644
Validation Loss: 0.00472707
Epoch [103/300], Train Loss: 0.004630
Validation Loss: 0.00475412
Epoch [104/300], Train Loss: 0.004704
Validation Loss: 0.00478400
Epoch [105/300], Train Loss: 0.004635
Validation Loss: 0.00470944
Epoch [106/300], Train Loss: 0.004614
Validation Loss: 0.00472540
Epoch [107/300], Train Loss: 0.004606
Validation Loss: 0.00470389
Epoch [108/300], Train Loss: 0.004608
Validation Loss: 0.00470514
Epoch [109/300], Train Loss: 0.004596
Validation Loss: 0.00469068
Epoch [110/300], Train Loss: 0.004633
Validation Loss: 0.00467473
Epoch [111/300], Train Loss: 0.004602
Validation Loss: 0.00472738
Epoch [112/300], Train Loss: 0.004589
Validation Loss: 0.00472809
Epoch [113/300], Train Loss: 0.004647
Validation Loss: 0.00471255
Epoch [114/300], Train Loss: 0.004614
Validation Loss: 0.00471183
Epoch [115/300], Train Loss: 0.004607
Validation Loss: 0.00470633
Epoch [116/300], Train Loss: 0.004609
Validation Loss: 0.00470078
Epoch [117/300], Train Loss: 0.004569
Validation Loss: 0.00466882
Epoch [118/300], Train Loss: 0.004612
Validation Loss: 0.00469579
Epoch [119/300], Train Loss: 0.004619
Validation Loss: 0.00466199
Epoch [120/300], Train Loss: 0.004564
Validation Loss: 0.00465058
Epoch [121/300], Train Loss: 0.004570
Validation Loss: 0.00469140
Epoch [122/300], Train Loss: 0.004590
Validation Loss: 0.00465842
Epoch [123/300], Train Loss: 0.004562
Validation Loss: 0.00464326
Epoch [124/300], Train Loss: 0.004558
Validation Loss: 0.00470537
Epoch [125/300], Train Loss: 0.004543
Validation Loss: 0.00467845
Epoch [126/300], Train Loss: 0.004556
Validation Loss: 0.00462852
Epoch [127/300], Train Loss: 0.004540
Validation Loss: 0.00476885
Epoch [128/300], Train Loss: 0.004615
Validation Loss: 0.00463528
Epoch [129/300], Train Loss: 0.004551
Validation Loss: 0.00463820
Epoch [130/300], Train Loss: 0.004541
Validation Loss: 0.00473108
Epoch [131/300], Train Loss: 0.004529
Validation Loss: 0.00462240
Epoch [132/300], Train Loss: 0.004559
Validation Loss: 0.00464289
Epoch [133/300], Train Loss: 0.004538
Validation Loss: 0.00464939
Epoch [134/300], Train Loss: 0.004537
Validation Loss: 0.00477872
Epoch [135/300], Train Loss: 0.004595
Validation Loss: 0.00465530
Epoch [136/300], Train Loss: 0.004532
Validation Loss: 0.00466058
Epoch [137/300], Train Loss: 0.004529
Validation Loss: 0.00469522
Epoch [138/300], Train Loss: 0.004514
Validation Loss: 0.00463633
Epoch [139/300], Train Loss: 0.004524
Validation Loss: 0.00460256
Epoch [140/300], Train Loss: 0.004514
Validation Loss: 0.00466793
Epoch [141/300], Train Loss: 0.004528
Validation Loss: 0.00465987
Epoch [142/300], Train Loss: 0.004525
Validation Loss: 0.00489665
Epoch [143/300], Train Loss: 0.004628
Validation Loss: 0.00476755
Epoch [144/300], Train Loss: 0.004547
Validation Loss: 0.00469160
Epoch [145/300], Train Loss: 0.004515
Validation Loss: 0.00465193
Epoch [146/300], Train Loss: 0.004588
Validation Loss: 0.00463368
Epoch [147/300], Train Loss: 0.004499
Validation Loss: 0.00468591
Epoch [148/300], Train Loss: 0.004512
Validation Loss: 0.00460590
Epoch [149/300], Train Loss: 0.004505
Validation Loss: 0.00460478
Early stopping triggered

Evaluating model for: Router
Run 4/72 completed in 857.16 seconds with: {'MAE': np.float32(0.18208496), 'MSE': np.float32(0.055200264), 'RMSE': np.float32(0.23494737), 'SAE': np.float32(0.0003362661), 'NDE': np.float32(0.011742903)}

Run 5/72: hidden=128, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Router
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.078071
Validation Loss: 0.06587311
Epoch [2/300], Train Loss: 0.052925
Validation Loss: 0.03704785
Epoch [3/300], Train Loss: 0.020413
Validation Loss: 0.00810417
Epoch [4/300], Train Loss: 0.008389
Validation Loss: 0.00803806
Epoch [5/300], Train Loss: 0.007651
Validation Loss: 0.00765047
Epoch [6/300], Train Loss: 0.007495
Validation Loss: 0.00754767
Epoch [7/300], Train Loss: 0.007435
Validation Loss: 0.00748699
Epoch [8/300], Train Loss: 0.007366
Validation Loss: 0.00743866
Epoch [9/300], Train Loss: 0.007319
Validation Loss: 0.00739085
Epoch [10/300], Train Loss: 0.007270
Validation Loss: 0.00734404
Epoch [11/300], Train Loss: 0.007227
Validation Loss: 0.00729488
Epoch [12/300], Train Loss: 0.007181
Validation Loss: 0.00725796
Epoch [13/300], Train Loss: 0.007140
Validation Loss: 0.00720281
Epoch [14/300], Train Loss: 0.007059
Validation Loss: 0.00715702
Epoch [15/300], Train Loss: 0.007036
Validation Loss: 0.00711107
Epoch [16/300], Train Loss: 0.006999
Validation Loss: 0.00707766
Epoch [17/300], Train Loss: 0.006941
Validation Loss: 0.00703203
Epoch [18/300], Train Loss: 0.006896
Validation Loss: 0.00699442
Epoch [19/300], Train Loss: 0.006854
Validation Loss: 0.00696139
Epoch [20/300], Train Loss: 0.006827
Validation Loss: 0.00692003
Epoch [21/300], Train Loss: 0.006774
Validation Loss: 0.00688142
Epoch [22/300], Train Loss: 0.006775
Validation Loss: 0.00684829
Epoch [23/300], Train Loss: 0.006718
Validation Loss: 0.00681998
Epoch [24/300], Train Loss: 0.006698
Validation Loss: 0.00677844
Epoch [25/300], Train Loss: 0.006633
Validation Loss: 0.00674515
Epoch [26/300], Train Loss: 0.006609
Validation Loss: 0.00671116
Epoch [27/300], Train Loss: 0.006582
Validation Loss: 0.00668117
Epoch [28/300], Train Loss: 0.006571
Validation Loss: 0.00665500
Epoch [29/300], Train Loss: 0.006537
Validation Loss: 0.00662644
Epoch [30/300], Train Loss: 0.006488
Validation Loss: 0.00660175
Epoch [31/300], Train Loss: 0.006482
Validation Loss: 0.00657187
Epoch [32/300], Train Loss: 0.006452
Validation Loss: 0.00655754
Epoch [33/300], Train Loss: 0.006417
Validation Loss: 0.00652618
Epoch [34/300], Train Loss: 0.006381
Validation Loss: 0.00652189
Epoch [35/300], Train Loss: 0.006360
Validation Loss: 0.00648975
Epoch [36/300], Train Loss: 0.006345
Validation Loss: 0.00646849
Epoch [37/300], Train Loss: 0.006325
Validation Loss: 0.00644452
Epoch [38/300], Train Loss: 0.006317
Validation Loss: 0.00642372
Epoch [39/300], Train Loss: 0.006294
Validation Loss: 0.00640988
Epoch [40/300], Train Loss: 0.006251
Validation Loss: 0.00638509
Epoch [41/300], Train Loss: 0.006242
Validation Loss: 0.00636969
Epoch [42/300], Train Loss: 0.006213
Validation Loss: 0.00634719
Epoch [43/300], Train Loss: 0.006222
Validation Loss: 0.00632692
Epoch [44/300], Train Loss: 0.006175
Validation Loss: 0.00630473
Epoch [45/300], Train Loss: 0.006161
Validation Loss: 0.00628542
Epoch [46/300], Train Loss: 0.006150
Validation Loss: 0.00626957
Epoch [47/300], Train Loss: 0.006130
Validation Loss: 0.00625832
Epoch [48/300], Train Loss: 0.006116
Validation Loss: 0.00624222
Epoch [49/300], Train Loss: 0.006088
Validation Loss: 0.00622959
Epoch [50/300], Train Loss: 0.006079
Validation Loss: 0.00621325
Epoch [51/300], Train Loss: 0.006070
Validation Loss: 0.00620241
Epoch [52/300], Train Loss: 0.006061
Validation Loss: 0.00619845
Epoch [53/300], Train Loss: 0.006034
Validation Loss: 0.00617744
Epoch [54/300], Train Loss: 0.006030
Validation Loss: 0.00616541
Epoch [55/300], Train Loss: 0.006013
Validation Loss: 0.00616048
Epoch [56/300], Train Loss: 0.006016
Validation Loss: 0.00613764
Epoch [57/300], Train Loss: 0.005997
Validation Loss: 0.00612619
Epoch [58/300], Train Loss: 0.005965
Validation Loss: 0.00611516
Epoch [59/300], Train Loss: 0.005965
Validation Loss: 0.00612777
Epoch [60/300], Train Loss: 0.005955
Validation Loss: 0.00608884
Epoch [61/300], Train Loss: 0.005930
Validation Loss: 0.00608362
Epoch [62/300], Train Loss: 0.005935
Validation Loss: 0.00606841
Epoch [63/300], Train Loss: 0.005917
Validation Loss: 0.00605800
Epoch [64/300], Train Loss: 0.005912
Validation Loss: 0.00605449
Epoch [65/300], Train Loss: 0.005915
Validation Loss: 0.00604711
Epoch [66/300], Train Loss: 0.005900
Validation Loss: 0.00602857
Epoch [67/300], Train Loss: 0.005861
Validation Loss: 0.00602504
Epoch [68/300], Train Loss: 0.005873
Validation Loss: 0.00600968
Epoch [69/300], Train Loss: 0.005857
Validation Loss: 0.00600373
Epoch [70/300], Train Loss: 0.005850
Validation Loss: 0.00600296
Epoch [71/300], Train Loss: 0.005834
Validation Loss: 0.00598720
Epoch [72/300], Train Loss: 0.005850
Validation Loss: 0.00597508
Epoch [73/300], Train Loss: 0.005828
Validation Loss: 0.00596950
Epoch [74/300], Train Loss: 0.005799
Validation Loss: 0.00595934
Epoch [75/300], Train Loss: 0.005803
Validation Loss: 0.00595346
Epoch [76/300], Train Loss: 0.005788
Validation Loss: 0.00593835
Epoch [77/300], Train Loss: 0.005798
Validation Loss: 0.00592995
Epoch [78/300], Train Loss: 0.005801
Validation Loss: 0.00593957
Epoch [79/300], Train Loss: 0.005792
Validation Loss: 0.00591953
Epoch [80/300], Train Loss: 0.005777
Validation Loss: 0.00591253
Epoch [81/300], Train Loss: 0.005753
Validation Loss: 0.00590060
Epoch [82/300], Train Loss: 0.005754
Validation Loss: 0.00589306
Epoch [83/300], Train Loss: 0.005745
Validation Loss: 0.00589331
Epoch [84/300], Train Loss: 0.005725
Validation Loss: 0.00588119
Epoch [85/300], Train Loss: 0.005728
Validation Loss: 0.00588478
Epoch [86/300], Train Loss: 0.005726
Validation Loss: 0.00587201
Epoch [87/300], Train Loss: 0.005712
Validation Loss: 0.00587110
Epoch [88/300], Train Loss: 0.005704
Validation Loss: 0.00585097
Epoch [89/300], Train Loss: 0.005696
Validation Loss: 0.00584867
Epoch [90/300], Train Loss: 0.005710
Validation Loss: 0.00583862
Epoch [91/300], Train Loss: 0.005685
Validation Loss: 0.00584121
Epoch [92/300], Train Loss: 0.005675
Validation Loss: 0.00582633
Epoch [93/300], Train Loss: 0.005661
Validation Loss: 0.00581971
Epoch [94/300], Train Loss: 0.005656
Validation Loss: 0.00581878
Epoch [95/300], Train Loss: 0.005686
Validation Loss: 0.00580910
Epoch [96/300], Train Loss: 0.005660
Validation Loss: 0.00581533
Epoch [97/300], Train Loss: 0.005656
Validation Loss: 0.00579742
Epoch [98/300], Train Loss: 0.005655
Validation Loss: 0.00579964
Epoch [99/300], Train Loss: 0.005629
Validation Loss: 0.00578653
Epoch [100/300], Train Loss: 0.005633
Validation Loss: 0.00578114
Epoch [101/300], Train Loss: 0.005628
Validation Loss: 0.00579976
Epoch [102/300], Train Loss: 0.005620
Validation Loss: 0.00577332
Epoch [103/300], Train Loss: 0.005622
Validation Loss: 0.00576672
Epoch [104/300], Train Loss: 0.005615
Validation Loss: 0.00576964
Epoch [105/300], Train Loss: 0.005605
Validation Loss: 0.00576152
Epoch [106/300], Train Loss: 0.005605
Validation Loss: 0.00575327
Epoch [107/300], Train Loss: 0.005606
Validation Loss: 0.00574747
Epoch [108/300], Train Loss: 0.005585
Validation Loss: 0.00574519
Epoch [109/300], Train Loss: 0.005583
Validation Loss: 0.00573890
Epoch [110/300], Train Loss: 0.005582
Validation Loss: 0.00573489
Epoch [111/300], Train Loss: 0.005579
Validation Loss: 0.00573295
Epoch [112/300], Train Loss: 0.005591
Validation Loss: 0.00572687
Epoch [113/300], Train Loss: 0.005583
Validation Loss: 0.00572211
Epoch [114/300], Train Loss: 0.005567
Validation Loss: 0.00573437
Epoch [115/300], Train Loss: 0.005579
Validation Loss: 0.00573497
Epoch [116/300], Train Loss: 0.005555
Validation Loss: 0.00571044
Epoch [117/300], Train Loss: 0.005548
Validation Loss: 0.00570694
Epoch [118/300], Train Loss: 0.005546
Validation Loss: 0.00570252
Epoch [119/300], Train Loss: 0.005560
Validation Loss: 0.00569957
Epoch [120/300], Train Loss: 0.005551
Validation Loss: 0.00569493
Epoch [121/300], Train Loss: 0.005537
Validation Loss: 0.00569545
Epoch [122/300], Train Loss: 0.005532
Validation Loss: 0.00568925
Epoch [123/300], Train Loss: 0.005527
Validation Loss: 0.00568478
Epoch [124/300], Train Loss: 0.005520
Validation Loss: 0.00568232
Epoch [125/300], Train Loss: 0.005519
Validation Loss: 0.00568451
Epoch [126/300], Train Loss: 0.005521
Validation Loss: 0.00567517
Epoch [127/300], Train Loss: 0.005513
Validation Loss: 0.00567176
Epoch [128/300], Train Loss: 0.005520
Validation Loss: 0.00568810
Epoch [129/300], Train Loss: 0.005519
Validation Loss: 0.00566553
Epoch [130/300], Train Loss: 0.005519
Validation Loss: 0.00566387
Epoch [131/300], Train Loss: 0.005509
Validation Loss: 0.00566852
Epoch [132/300], Train Loss: 0.005507
Validation Loss: 0.00566726
Epoch [133/300], Train Loss: 0.005506
Validation Loss: 0.00566062
Epoch [134/300], Train Loss: 0.005504
Validation Loss: 0.00566157
Epoch [135/300], Train Loss: 0.005507
Validation Loss: 0.00565399
Epoch [136/300], Train Loss: 0.005484
Validation Loss: 0.00564790
Epoch [137/300], Train Loss: 0.005495
Validation Loss: 0.00564387
Epoch [138/300], Train Loss: 0.005490
Validation Loss: 0.00564181
Epoch [139/300], Train Loss: 0.005478
Validation Loss: 0.00563889
Epoch [140/300], Train Loss: 0.005479
Validation Loss: 0.00563605
Epoch [141/300], Train Loss: 0.005468
Validation Loss: 0.00563399
Epoch [142/300], Train Loss: 0.005481
Validation Loss: 0.00563136
Epoch [143/300], Train Loss: 0.005465
Validation Loss: 0.00563308
Epoch [144/300], Train Loss: 0.005475
Validation Loss: 0.00562783
Epoch [145/300], Train Loss: 0.005472
Validation Loss: 0.00562523
Epoch [146/300], Train Loss: 0.005483
Validation Loss: 0.00562265
Epoch [147/300], Train Loss: 0.005470
Validation Loss: 0.00561995
Epoch [148/300], Train Loss: 0.005467
Validation Loss: 0.00561722
Epoch [149/300], Train Loss: 0.005479
Validation Loss: 0.00562416
Epoch [150/300], Train Loss: 0.005449
Validation Loss: 0.00561581
Epoch [151/300], Train Loss: 0.005452
Validation Loss: 0.00561377
Epoch [152/300], Train Loss: 0.005474
Validation Loss: 0.00561074
Epoch [153/300], Train Loss: 0.005447
Validation Loss: 0.00560969
Epoch [154/300], Train Loss: 0.005457
Validation Loss: 0.00560492
Epoch [155/300], Train Loss: 0.005449
Validation Loss: 0.00560342
Epoch [156/300], Train Loss: 0.005438
Validation Loss: 0.00560263
Epoch [157/300], Train Loss: 0.005451
Validation Loss: 0.00559924
Epoch [158/300], Train Loss: 0.005442
Validation Loss: 0.00559837
Epoch [159/300], Train Loss: 0.005426
Validation Loss: 0.00559580
Epoch [160/300], Train Loss: 0.005446
Validation Loss: 0.00559707
Epoch [161/300], Train Loss: 0.005464
Validation Loss: 0.00559187
Epoch [162/300], Train Loss: 0.005451
Validation Loss: 0.00559197
Epoch [163/300], Train Loss: 0.005438
Validation Loss: 0.00559028
Epoch [164/300], Train Loss: 0.005415
Validation Loss: 0.00558818
Epoch [165/300], Train Loss: 0.005434
Validation Loss: 0.00558565
Epoch [166/300], Train Loss: 0.005445
Validation Loss: 0.00560062
Epoch [167/300], Train Loss: 0.005432
Validation Loss: 0.00558166
Epoch [168/300], Train Loss: 0.005433
Validation Loss: 0.00558178
Epoch [169/300], Train Loss: 0.005430
Validation Loss: 0.00557907
Epoch [170/300], Train Loss: 0.005435
Validation Loss: 0.00559553
Epoch [171/300], Train Loss: 0.005413
Validation Loss: 0.00558395
Epoch [172/300], Train Loss: 0.005420
Validation Loss: 0.00557831
Epoch [173/300], Train Loss: 0.005411
Validation Loss: 0.00557232
Epoch [174/300], Train Loss: 0.005413
Validation Loss: 0.00557150
Epoch [175/300], Train Loss: 0.005422
Validation Loss: 0.00556954
Epoch [176/300], Train Loss: 0.005406
Validation Loss: 0.00556785
Epoch [177/300], Train Loss: 0.005413
Validation Loss: 0.00556857
Epoch [178/300], Train Loss: 0.005414
Validation Loss: 0.00556508
Epoch [179/300], Train Loss: 0.005411
Validation Loss: 0.00556300
Epoch [180/300], Train Loss: 0.005397
Validation Loss: 0.00556179
Epoch [181/300], Train Loss: 0.005419
Validation Loss: 0.00556210
Epoch [182/300], Train Loss: 0.005404
Validation Loss: 0.00555910
Epoch [183/300], Train Loss: 0.005409
Validation Loss: 0.00555900
Epoch [184/300], Train Loss: 0.005391
Validation Loss: 0.00555851
Epoch [185/300], Train Loss: 0.005394
Validation Loss: 0.00555874
Epoch [186/300], Train Loss: 0.005397
Validation Loss: 0.00555420
Epoch [187/300], Train Loss: 0.005401
Validation Loss: 0.00555385
Epoch [188/300], Train Loss: 0.005379
Validation Loss: 0.00555174
Epoch [189/300], Train Loss: 0.005389
Validation Loss: 0.00555044
Epoch [190/300], Train Loss: 0.005394
Validation Loss: 0.00555456
Epoch [191/300], Train Loss: 0.005412
Validation Loss: 0.00554906
Epoch [192/300], Train Loss: 0.005394
Validation Loss: 0.00554989
Epoch [193/300], Train Loss: 0.005409
Validation Loss: 0.00555309
Epoch [194/300], Train Loss: 0.005391
Validation Loss: 0.00554488
Epoch [195/300], Train Loss: 0.005390
Validation Loss: 0.00554395
Epoch [196/300], Train Loss: 0.005388
Validation Loss: 0.00554269
Epoch [197/300], Train Loss: 0.005379
Validation Loss: 0.00554171
Epoch [198/300], Train Loss: 0.005384
Validation Loss: 0.00554066
Epoch [199/300], Train Loss: 0.005376
Validation Loss: 0.00554100
Epoch [200/300], Train Loss: 0.005375
Validation Loss: 0.00554274
Epoch [201/300], Train Loss: 0.005393
Validation Loss: 0.00554015
Epoch [202/300], Train Loss: 0.005394
Validation Loss: 0.00553764
Epoch [203/300], Train Loss: 0.005395
Validation Loss: 0.00553725
Epoch [204/300], Train Loss: 0.005381
Validation Loss: 0.00553542
Epoch [205/300], Train Loss: 0.005368
Validation Loss: 0.00554203
Epoch [206/300], Train Loss: 0.005373
Validation Loss: 0.00554114
Epoch [207/300], Train Loss: 0.005402
Validation Loss: 0.00553356
Epoch [208/300], Train Loss: 0.005363
Validation Loss: 0.00553616
Epoch [209/300], Train Loss: 0.005370
Validation Loss: 0.00553092
Epoch [210/300], Train Loss: 0.005372
Validation Loss: 0.00553017
Epoch [211/300], Train Loss: 0.005377
Validation Loss: 0.00553359
Epoch [212/300], Train Loss: 0.005382
Validation Loss: 0.00552814
Epoch [213/300], Train Loss: 0.005362
Validation Loss: 0.00553401
Epoch [214/300], Train Loss: 0.005366
Validation Loss: 0.00552846
Epoch [215/300], Train Loss: 0.005366
Validation Loss: 0.00553214
Epoch [216/300], Train Loss: 0.005375
Validation Loss: 0.00552546
Epoch [217/300], Train Loss: 0.005364
Validation Loss: 0.00552603
Epoch [218/300], Train Loss: 0.005362
Validation Loss: 0.00552357
Epoch [219/300], Train Loss: 0.005392
Validation Loss: 0.00552292
Epoch [220/300], Train Loss: 0.005368
Validation Loss: 0.00552690
Epoch [221/300], Train Loss: 0.005360
Validation Loss: 0.00552484
Epoch [222/300], Train Loss: 0.005382
Validation Loss: 0.00552485
Epoch [223/300], Train Loss: 0.005348
Validation Loss: 0.00552186
Epoch [224/300], Train Loss: 0.005364
Validation Loss: 0.00552647
Epoch [225/300], Train Loss: 0.005372
Validation Loss: 0.00551955
Epoch [226/300], Train Loss: 0.005362
Validation Loss: 0.00551866
Epoch [227/300], Train Loss: 0.005358
Validation Loss: 0.00551784
Epoch [228/300], Train Loss: 0.005356
Validation Loss: 0.00551810
Epoch [229/300], Train Loss: 0.005353
Validation Loss: 0.00551666
Epoch [230/300], Train Loss: 0.005351
Validation Loss: 0.00551545
Epoch [231/300], Train Loss: 0.005353
Validation Loss: 0.00551532
Epoch [232/300], Train Loss: 0.005357
Validation Loss: 0.00551418
Epoch [233/300], Train Loss: 0.005352
Validation Loss: 0.00551355
Epoch [234/300], Train Loss: 0.005351
Validation Loss: 0.00551448
Epoch [235/300], Train Loss: 0.005354
Validation Loss: 0.00551337
Epoch [236/300], Train Loss: 0.005340
Validation Loss: 0.00551212
Epoch [237/300], Train Loss: 0.005365
Validation Loss: 0.00551377
Epoch [238/300], Train Loss: 0.005355
Validation Loss: 0.00551267
Epoch [239/300], Train Loss: 0.005343
Validation Loss: 0.00551119
Epoch [240/300], Train Loss: 0.005369
Validation Loss: 0.00551040
Epoch [241/300], Train Loss: 0.005375
Validation Loss: 0.00550910
Epoch [242/300], Train Loss: 0.005334
Validation Loss: 0.00550850
Epoch [243/300], Train Loss: 0.005339
Validation Loss: 0.00550803
Epoch [244/300], Train Loss: 0.005363
Validation Loss: 0.00551023
Epoch [245/300], Train Loss: 0.005336
Validation Loss: 0.00550726
Epoch [246/300], Train Loss: 0.005347
Validation Loss: 0.00550717
Epoch [247/300], Train Loss: 0.005353
Validation Loss: 0.00550782
Epoch [248/300], Train Loss: 0.005348
Validation Loss: 0.00550600
Epoch [249/300], Train Loss: 0.005337
Validation Loss: 0.00551164
Epoch [250/300], Train Loss: 0.005334
Validation Loss: 0.00550448
Epoch [251/300], Train Loss: 0.005333
Validation Loss: 0.00550902
Epoch [252/300], Train Loss: 0.005366
Validation Loss: 0.00550350
Epoch [253/300], Train Loss: 0.005337
Validation Loss: 0.00551049
Epoch [254/300], Train Loss: 0.005333
Validation Loss: 0.00550351
Epoch [255/300], Train Loss: 0.005351
Validation Loss: 0.00550211
Epoch [256/300], Train Loss: 0.005328
Validation Loss: 0.00550201
Epoch [257/300], Train Loss: 0.005329
Validation Loss: 0.00550289
Epoch [258/300], Train Loss: 0.005332
Validation Loss: 0.00550117
Epoch [259/300], Train Loss: 0.005349
Validation Loss: 0.00550051
Epoch [260/300], Train Loss: 0.005335
Validation Loss: 0.00550047
Epoch [261/300], Train Loss: 0.005338
Validation Loss: 0.00550004
Epoch [262/300], Train Loss: 0.005323
Validation Loss: 0.00549923
Epoch [263/300], Train Loss: 0.005330
Validation Loss: 0.00550116
Epoch [264/300], Train Loss: 0.005328
Validation Loss: 0.00549851
Epoch [265/300], Train Loss: 0.005354
Validation Loss: 0.00549817
Epoch [266/300], Train Loss: 0.005335
Validation Loss: 0.00550029
Epoch [267/300], Train Loss: 0.005333
Validation Loss: 0.00549685
Epoch [268/300], Train Loss: 0.005347
Validation Loss: 0.00549709
Epoch [269/300], Train Loss: 0.005333
Validation Loss: 0.00549670
Epoch [270/300], Train Loss: 0.005319
Validation Loss: 0.00549596
Epoch [271/300], Train Loss: 0.005318
Validation Loss: 0.00549575
Epoch [272/300], Train Loss: 0.005325
Validation Loss: 0.00549559
Epoch [273/300], Train Loss: 0.005322
Validation Loss: 0.00549628
Epoch [274/300], Train Loss: 0.005326
Validation Loss: 0.00549407
Epoch [275/300], Train Loss: 0.005316
Validation Loss: 0.00549375
Epoch [276/300], Train Loss: 0.005329
Validation Loss: 0.00549323
Epoch [277/300], Train Loss: 0.005343
Validation Loss: 0.00549445
Epoch [278/300], Train Loss: 0.005323
Validation Loss: 0.00549268
Epoch [279/300], Train Loss: 0.005324
Validation Loss: 0.00549205
Epoch [280/300], Train Loss: 0.005328
Validation Loss: 0.00549228
Epoch [281/300], Train Loss: 0.005316
Validation Loss: 0.00549224
Epoch [282/300], Train Loss: 0.005338
Validation Loss: 0.00549382
Epoch [283/300], Train Loss: 0.005337
Validation Loss: 0.00549384
Epoch [284/300], Train Loss: 0.005317
Validation Loss: 0.00549041
Epoch [285/300], Train Loss: 0.005340
Validation Loss: 0.00549221
Epoch [286/300], Train Loss: 0.005329
Validation Loss: 0.00549093
Epoch [287/300], Train Loss: 0.005330
Validation Loss: 0.00549543
Epoch [288/300], Train Loss: 0.005327
Validation Loss: 0.00548927
Epoch [289/300], Train Loss: 0.005318
Validation Loss: 0.00549018
Epoch [290/300], Train Loss: 0.005322
Validation Loss: 0.00548900
Epoch [291/300], Train Loss: 0.005324
Validation Loss: 0.00548870
Epoch [292/300], Train Loss: 0.005327
Validation Loss: 0.00548797
Epoch [293/300], Train Loss: 0.005322
Validation Loss: 0.00548847
Epoch [294/300], Train Loss: 0.005315
Validation Loss: 0.00548737
Epoch [295/300], Train Loss: 0.005315
Validation Loss: 0.00548773
Epoch [296/300], Train Loss: 0.005313
Validation Loss: 0.00548632
Epoch [297/300], Train Loss: 0.005333
Validation Loss: 0.00549046
Epoch [298/300], Train Loss: 0.005312
Validation Loss: 0.00548605
Epoch [299/300], Train Loss: 0.005318
Validation Loss: 0.00548567
Epoch [300/300], Train Loss: 0.005318
Validation Loss: 0.00548867

Evaluating model for: Router
Run 5/72 completed in 810.16 seconds with: {'MAE': np.float32(0.20057522), 'MSE': np.float32(0.068006106), 'RMSE': np.float32(0.2607798), 'SAE': np.float32(0.000105690124), 'NDE': np.float32(0.013031681)}

Run 6/72: hidden=128, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Router
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.115981
Validation Loss: 0.10195209
Epoch [2/300], Train Loss: 0.088128
Validation Loss: 0.07034103
Epoch [3/300], Train Loss: 0.042052
Validation Loss: 0.00987476
Epoch [4/300], Train Loss: 0.011608
Validation Loss: 0.01054014
Epoch [5/300], Train Loss: 0.009804
Validation Loss: 0.00935586
Epoch [6/300], Train Loss: 0.009419
Validation Loss: 0.00921381
Epoch [7/300], Train Loss: 0.009312
Validation Loss: 0.00912668
Epoch [8/300], Train Loss: 0.009208
Validation Loss: 0.00901629
Epoch [9/300], Train Loss: 0.009102
Validation Loss: 0.00891993
Epoch [10/300], Train Loss: 0.009009
Validation Loss: 0.00881805
Epoch [11/300], Train Loss: 0.008911
Validation Loss: 0.00871551
Epoch [12/300], Train Loss: 0.008823
Validation Loss: 0.00862109
Epoch [13/300], Train Loss: 0.008719
Validation Loss: 0.00851185
Epoch [14/300], Train Loss: 0.008577
Validation Loss: 0.00840733
Epoch [15/300], Train Loss: 0.008480
Validation Loss: 0.00830263
Epoch [16/300], Train Loss: 0.008385
Validation Loss: 0.00822400
Epoch [17/300], Train Loss: 0.008278
Validation Loss: 0.00812055
Epoch [18/300], Train Loss: 0.008178
Validation Loss: 0.00803393
Epoch [19/300], Train Loss: 0.008093
Validation Loss: 0.00795558
Epoch [20/300], Train Loss: 0.008019
Validation Loss: 0.00786577
Epoch [21/300], Train Loss: 0.007915
Validation Loss: 0.00779083
Epoch [22/300], Train Loss: 0.007877
Validation Loss: 0.00774379
Epoch [23/300], Train Loss: 0.007796
Validation Loss: 0.00767461
Epoch [24/300], Train Loss: 0.007711
Validation Loss: 0.00759974
Epoch [25/300], Train Loss: 0.007624
Validation Loss: 0.00752951
Epoch [26/300], Train Loss: 0.007573
Validation Loss: 0.00747749
Epoch [27/300], Train Loss: 0.007527
Validation Loss: 0.00743160
Epoch [28/300], Train Loss: 0.007487
Validation Loss: 0.00740643
Epoch [29/300], Train Loss: 0.007442
Validation Loss: 0.00738868
Epoch [30/300], Train Loss: 0.007376
Validation Loss: 0.00733845
Epoch [31/300], Train Loss: 0.007344
Validation Loss: 0.00726374
Epoch [32/300], Train Loss: 0.007283
Validation Loss: 0.00722170
Epoch [33/300], Train Loss: 0.007249
Validation Loss: 0.00719621
Epoch [34/300], Train Loss: 0.007214
Validation Loss: 0.00718201
Epoch [35/300], Train Loss: 0.007168
Validation Loss: 0.00713159
Epoch [36/300], Train Loss: 0.007126
Validation Loss: 0.00713782
Epoch [37/300], Train Loss: 0.007107
Validation Loss: 0.00709381
Epoch [38/300], Train Loss: 0.007096
Validation Loss: 0.00703430
Epoch [39/300], Train Loss: 0.007040
Validation Loss: 0.00701367
Epoch [40/300], Train Loss: 0.006991
Validation Loss: 0.00699016
Epoch [41/300], Train Loss: 0.006958
Validation Loss: 0.00696055
Epoch [42/300], Train Loss: 0.006930
Validation Loss: 0.00693832
Epoch [43/300], Train Loss: 0.006945
Validation Loss: 0.00689327
Epoch [44/300], Train Loss: 0.006875
Validation Loss: 0.00687871
Epoch [45/300], Train Loss: 0.006866
Validation Loss: 0.00684073
Epoch [46/300], Train Loss: 0.006836
Validation Loss: 0.00682257
Epoch [47/300], Train Loss: 0.006800
Validation Loss: 0.00679469
Epoch [48/300], Train Loss: 0.006766
Validation Loss: 0.00677342
Epoch [49/300], Train Loss: 0.006757
Validation Loss: 0.00678289
Epoch [50/300], Train Loss: 0.006721
Validation Loss: 0.00674392
Epoch [51/300], Train Loss: 0.006705
Validation Loss: 0.00671727
Epoch [52/300], Train Loss: 0.006679
Validation Loss: 0.00668710
Epoch [53/300], Train Loss: 0.006650
Validation Loss: 0.00666189
Epoch [54/300], Train Loss: 0.006621
Validation Loss: 0.00664033
Epoch [55/300], Train Loss: 0.006603
Validation Loss: 0.00662337
Epoch [56/300], Train Loss: 0.006588
Validation Loss: 0.00661339
Epoch [57/300], Train Loss: 0.006559
Validation Loss: 0.00659627
Epoch [58/300], Train Loss: 0.006521
Validation Loss: 0.00655844
Epoch [59/300], Train Loss: 0.006502
Validation Loss: 0.00657332
Epoch [60/300], Train Loss: 0.006495
Validation Loss: 0.00652066
Epoch [61/300], Train Loss: 0.006448
Validation Loss: 0.00650213
Epoch [62/300], Train Loss: 0.006440
Validation Loss: 0.00648102
Epoch [63/300], Train Loss: 0.006420
Validation Loss: 0.00648985
Epoch [64/300], Train Loss: 0.006430
Validation Loss: 0.00644946
Epoch [65/300], Train Loss: 0.006421
Validation Loss: 0.00645170
Epoch [66/300], Train Loss: 0.006376
Validation Loss: 0.00641417
Epoch [67/300], Train Loss: 0.006341
Validation Loss: 0.00639808
Epoch [68/300], Train Loss: 0.006338
Validation Loss: 0.00639377
Epoch [69/300], Train Loss: 0.006311
Validation Loss: 0.00640631
Epoch [70/300], Train Loss: 0.006310
Validation Loss: 0.00635022
Epoch [71/300], Train Loss: 0.006273
Validation Loss: 0.00636238
Epoch [72/300], Train Loss: 0.006282
Validation Loss: 0.00634206
Epoch [73/300], Train Loss: 0.006249
Validation Loss: 0.00630957
Epoch [74/300], Train Loss: 0.006206
Validation Loss: 0.00632135
Epoch [75/300], Train Loss: 0.006203
Validation Loss: 0.00627882
Epoch [76/300], Train Loss: 0.006181
Validation Loss: 0.00626537
Epoch [77/300], Train Loss: 0.006194
Validation Loss: 0.00634379
Epoch [78/300], Train Loss: 0.006202
Validation Loss: 0.00626221
Epoch [79/300], Train Loss: 0.006160
Validation Loss: 0.00623172
Epoch [80/300], Train Loss: 0.006154
Validation Loss: 0.00622437
Epoch [81/300], Train Loss: 0.006120
Validation Loss: 0.00620747
Epoch [82/300], Train Loss: 0.006127
Validation Loss: 0.00621848
Epoch [83/300], Train Loss: 0.006132
Validation Loss: 0.00620367
Epoch [84/300], Train Loss: 0.006079
Validation Loss: 0.00618482
Epoch [85/300], Train Loss: 0.006089
Validation Loss: 0.00616655
Epoch [86/300], Train Loss: 0.006074
Validation Loss: 0.00615361
Epoch [87/300], Train Loss: 0.006065
Validation Loss: 0.00614448
Epoch [88/300], Train Loss: 0.006042
Validation Loss: 0.00613451
Epoch [89/300], Train Loss: 0.006030
Validation Loss: 0.00612500
Epoch [90/300], Train Loss: 0.006035
Validation Loss: 0.00611758
Epoch [91/300], Train Loss: 0.006013
Validation Loss: 0.00610540
Epoch [92/300], Train Loss: 0.006002
Validation Loss: 0.00610150
Epoch [93/300], Train Loss: 0.005984
Validation Loss: 0.00612721
Epoch [94/300], Train Loss: 0.006004
Validation Loss: 0.00609124
Epoch [95/300], Train Loss: 0.006008
Validation Loss: 0.00612347
Epoch [96/300], Train Loss: 0.005988
Validation Loss: 0.00606623
Epoch [97/300], Train Loss: 0.005950
Validation Loss: 0.00605247
Epoch [98/300], Train Loss: 0.005950
Validation Loss: 0.00604635
Epoch [99/300], Train Loss: 0.005929
Validation Loss: 0.00603782
Epoch [100/300], Train Loss: 0.005939
Validation Loss: 0.00602813
Epoch [101/300], Train Loss: 0.005921
Validation Loss: 0.00603888
Epoch [102/300], Train Loss: 0.005910
Validation Loss: 0.00601240
Epoch [103/300], Train Loss: 0.005916
Validation Loss: 0.00600934
Epoch [104/300], Train Loss: 0.005894
Validation Loss: 0.00599385
Epoch [105/300], Train Loss: 0.005897
Validation Loss: 0.00598522
Epoch [106/300], Train Loss: 0.005890
Validation Loss: 0.00598198
Epoch [107/300], Train Loss: 0.005883
Validation Loss: 0.00597406
Epoch [108/300], Train Loss: 0.005855
Validation Loss: 0.00596578
Epoch [109/300], Train Loss: 0.005844
Validation Loss: 0.00596019
Epoch [110/300], Train Loss: 0.005854
Validation Loss: 0.00595575
Epoch [111/300], Train Loss: 0.005852
Validation Loss: 0.00595605
Epoch [112/300], Train Loss: 0.005852
Validation Loss: 0.00593901
Epoch [113/300], Train Loss: 0.005841
Validation Loss: 0.00592949
Epoch [114/300], Train Loss: 0.005822
Validation Loss: 0.00592255
Epoch [115/300], Train Loss: 0.005825
Validation Loss: 0.00592766
Epoch [116/300], Train Loss: 0.005806
Validation Loss: 0.00590947
Epoch [117/300], Train Loss: 0.005792
Validation Loss: 0.00590265
Epoch [118/300], Train Loss: 0.005791
Validation Loss: 0.00589324
Epoch [119/300], Train Loss: 0.005791
Validation Loss: 0.00589541
Epoch [120/300], Train Loss: 0.005784
Validation Loss: 0.00588660
Epoch [121/300], Train Loss: 0.005765
Validation Loss: 0.00587325
Epoch [122/300], Train Loss: 0.005762
Validation Loss: 0.00587753
Epoch [123/300], Train Loss: 0.005771
Validation Loss: 0.00586134
Epoch [124/300], Train Loss: 0.005738
Validation Loss: 0.00586050
Epoch [125/300], Train Loss: 0.005737
Validation Loss: 0.00585457
Epoch [126/300], Train Loss: 0.005734
Validation Loss: 0.00584452
Epoch [127/300], Train Loss: 0.005727
Validation Loss: 0.00584531
Epoch [128/300], Train Loss: 0.005735
Validation Loss: 0.00589470
Epoch [129/300], Train Loss: 0.005726
Validation Loss: 0.00585535
Epoch [130/300], Train Loss: 0.005743
Validation Loss: 0.00583715
Epoch [131/300], Train Loss: 0.005707
Validation Loss: 0.00584387
Epoch [132/300], Train Loss: 0.005729
Validation Loss: 0.00581942
Epoch [133/300], Train Loss: 0.005697
Validation Loss: 0.00582491
Epoch [134/300], Train Loss: 0.005699
Validation Loss: 0.00581806
Epoch [135/300], Train Loss: 0.005703
Validation Loss: 0.00579269
Epoch [136/300], Train Loss: 0.005666
Validation Loss: 0.00578604
Epoch [137/300], Train Loss: 0.005671
Validation Loss: 0.00578167
Epoch [138/300], Train Loss: 0.005666
Validation Loss: 0.00577657
Epoch [139/300], Train Loss: 0.005653
Validation Loss: 0.00577923
Epoch [140/300], Train Loss: 0.005650
Validation Loss: 0.00576686
Epoch [141/300], Train Loss: 0.005644
Validation Loss: 0.00575763
Epoch [142/300], Train Loss: 0.005653
Validation Loss: 0.00575572
Epoch [143/300], Train Loss: 0.005625
Validation Loss: 0.00575114
Epoch [144/300], Train Loss: 0.005638
Validation Loss: 0.00574831
Epoch [145/300], Train Loss: 0.005628
Validation Loss: 0.00574892
Epoch [146/300], Train Loss: 0.005636
Validation Loss: 0.00573119
Epoch [147/300], Train Loss: 0.005614
Validation Loss: 0.00573157
Epoch [148/300], Train Loss: 0.005622
Validation Loss: 0.00572082
Epoch [149/300], Train Loss: 0.005632
Validation Loss: 0.00572937
Epoch [150/300], Train Loss: 0.005592
Validation Loss: 0.00573699
Epoch [151/300], Train Loss: 0.005593
Validation Loss: 0.00570541
Epoch [152/300], Train Loss: 0.005599
Validation Loss: 0.00570019
Epoch [153/300], Train Loss: 0.005577
Validation Loss: 0.00570034
Epoch [154/300], Train Loss: 0.005585
Validation Loss: 0.00569459
Epoch [155/300], Train Loss: 0.005577
Validation Loss: 0.00568620
Epoch [156/300], Train Loss: 0.005562
Validation Loss: 0.00568355
Epoch [157/300], Train Loss: 0.005590
Validation Loss: 0.00567668
Epoch [158/300], Train Loss: 0.005564
Validation Loss: 0.00567224
Epoch [159/300], Train Loss: 0.005553
Validation Loss: 0.00566952
Epoch [160/300], Train Loss: 0.005560
Validation Loss: 0.00566243
Epoch [161/300], Train Loss: 0.005576
Validation Loss: 0.00565795
Epoch [162/300], Train Loss: 0.005553
Validation Loss: 0.00565514
Epoch [163/300], Train Loss: 0.005548
Validation Loss: 0.00565168
Epoch [164/300], Train Loss: 0.005535
Validation Loss: 0.00564712
Epoch [165/300], Train Loss: 0.005544
Validation Loss: 0.00565056
Epoch [166/300], Train Loss: 0.005564
Validation Loss: 0.00565279
Epoch [167/300], Train Loss: 0.005525
Validation Loss: 0.00564160
Epoch [168/300], Train Loss: 0.005527
Validation Loss: 0.00563017
Epoch [169/300], Train Loss: 0.005522
Validation Loss: 0.00563689
Epoch [170/300], Train Loss: 0.005525
Validation Loss: 0.00564217
Epoch [171/300], Train Loss: 0.005506
Validation Loss: 0.00561890
Epoch [172/300], Train Loss: 0.005510
Validation Loss: 0.00561852
Epoch [173/300], Train Loss: 0.005502
Validation Loss: 0.00561174
Epoch [174/300], Train Loss: 0.005504
Validation Loss: 0.00561106
Epoch [175/300], Train Loss: 0.005502
Validation Loss: 0.00560666
Epoch [176/300], Train Loss: 0.005491
Validation Loss: 0.00560393
Epoch [177/300], Train Loss: 0.005490
Validation Loss: 0.00559963
Epoch [178/300], Train Loss: 0.005494
Validation Loss: 0.00559458
Epoch [179/300], Train Loss: 0.005496
Validation Loss: 0.00559235
Epoch [180/300], Train Loss: 0.005471
Validation Loss: 0.00558733
Epoch [181/300], Train Loss: 0.005489
Validation Loss: 0.00558552
Epoch [182/300], Train Loss: 0.005472
Validation Loss: 0.00558303
Epoch [183/300], Train Loss: 0.005476
Validation Loss: 0.00558085
Epoch [184/300], Train Loss: 0.005464
Validation Loss: 0.00558211
Epoch [185/300], Train Loss: 0.005455
Validation Loss: 0.00559296
Epoch [186/300], Train Loss: 0.005461
Validation Loss: 0.00557376
Epoch [187/300], Train Loss: 0.005454
Validation Loss: 0.00556790
Epoch [188/300], Train Loss: 0.005443
Validation Loss: 0.00556484
Epoch [189/300], Train Loss: 0.005458
Validation Loss: 0.00556222
Epoch [190/300], Train Loss: 0.005460
Validation Loss: 0.00557433
Epoch [191/300], Train Loss: 0.005463
Validation Loss: 0.00555701
Epoch [192/300], Train Loss: 0.005448
Validation Loss: 0.00555690
Epoch [193/300], Train Loss: 0.005463
Validation Loss: 0.00556330
Epoch [194/300], Train Loss: 0.005449
Validation Loss: 0.00554992
Epoch [195/300], Train Loss: 0.005438
Validation Loss: 0.00554708
Epoch [196/300], Train Loss: 0.005440
Validation Loss: 0.00554711
Epoch [197/300], Train Loss: 0.005437
Validation Loss: 0.00554298
Epoch [198/300], Train Loss: 0.005431
Validation Loss: 0.00554106
Epoch [199/300], Train Loss: 0.005419
Validation Loss: 0.00554006
Epoch [200/300], Train Loss: 0.005430
Validation Loss: 0.00554809
Epoch [201/300], Train Loss: 0.005431
Validation Loss: 0.00553557
Epoch [202/300], Train Loss: 0.005439
Validation Loss: 0.00553324
Epoch [203/300], Train Loss: 0.005431
Validation Loss: 0.00553617
Epoch [204/300], Train Loss: 0.005426
Validation Loss: 0.00553292
Epoch [205/300], Train Loss: 0.005414
Validation Loss: 0.00554464
Epoch [206/300], Train Loss: 0.005413
Validation Loss: 0.00553547
Epoch [207/300], Train Loss: 0.005440
Validation Loss: 0.00552418
Epoch [208/300], Train Loss: 0.005401
Validation Loss: 0.00553235
Epoch [209/300], Train Loss: 0.005406
Validation Loss: 0.00552165
Epoch [210/300], Train Loss: 0.005410
Validation Loss: 0.00551924
Epoch [211/300], Train Loss: 0.005405
Validation Loss: 0.00553495
Epoch [212/300], Train Loss: 0.005411
Validation Loss: 0.00551616
Epoch [213/300], Train Loss: 0.005398
Validation Loss: 0.00552530
Epoch [214/300], Train Loss: 0.005400
Validation Loss: 0.00551467
Epoch [215/300], Train Loss: 0.005398
Validation Loss: 0.00552232
Epoch [216/300], Train Loss: 0.005405
Validation Loss: 0.00551136
Epoch [217/300], Train Loss: 0.005402
Validation Loss: 0.00551166
Epoch [218/300], Train Loss: 0.005388
Validation Loss: 0.00550866
Epoch [219/300], Train Loss: 0.005419
Validation Loss: 0.00550737
Epoch [220/300], Train Loss: 0.005395
Validation Loss: 0.00552040
Epoch [221/300], Train Loss: 0.005387
Validation Loss: 0.00550920
Epoch [222/300], Train Loss: 0.005411
Validation Loss: 0.00550762
Epoch [223/300], Train Loss: 0.005390
Validation Loss: 0.00550373
Epoch [224/300], Train Loss: 0.005389
Validation Loss: 0.00551179
Epoch [225/300], Train Loss: 0.005409
Validation Loss: 0.00550910
Epoch [226/300], Train Loss: 0.005396
Validation Loss: 0.00550200
Epoch [227/300], Train Loss: 0.005378
Validation Loss: 0.00550084
Epoch [228/300], Train Loss: 0.005392
Validation Loss: 0.00550234
Epoch [229/300], Train Loss: 0.005373
Validation Loss: 0.00550034
Epoch [230/300], Train Loss: 0.005381
Validation Loss: 0.00549636
Epoch [231/300], Train Loss: 0.005381
Validation Loss: 0.00549586
Epoch [232/300], Train Loss: 0.005394
Validation Loss: 0.00549487
Epoch [233/300], Train Loss: 0.005377
Validation Loss: 0.00549418
Epoch [234/300], Train Loss: 0.005391
Validation Loss: 0.00549537
Epoch [235/300], Train Loss: 0.005388
Validation Loss: 0.00549696
Epoch [236/300], Train Loss: 0.005364
Validation Loss: 0.00549341
Epoch [237/300], Train Loss: 0.005384
Validation Loss: 0.00549671
Epoch [238/300], Train Loss: 0.005389
Validation Loss: 0.00549120
Epoch [239/300], Train Loss: 0.005374
Validation Loss: 0.00548992
Epoch [240/300], Train Loss: 0.005396
Validation Loss: 0.00549441
Epoch [241/300], Train Loss: 0.005400
Validation Loss: 0.00548933
Epoch [242/300], Train Loss: 0.005365
Validation Loss: 0.00548804
Epoch [243/300], Train Loss: 0.005367
Validation Loss: 0.00548745
Epoch [244/300], Train Loss: 0.005383
Validation Loss: 0.00549350
Epoch [245/300], Train Loss: 0.005366
Validation Loss: 0.00549051
Epoch [246/300], Train Loss: 0.005379
Validation Loss: 0.00548725
Epoch [247/300], Train Loss: 0.005373
Validation Loss: 0.00548920
Epoch [248/300], Train Loss: 0.005377
Validation Loss: 0.00548481
Epoch [249/300], Train Loss: 0.005368
Validation Loss: 0.00549231
Epoch [250/300], Train Loss: 0.005365
Validation Loss: 0.00548530
Epoch [251/300], Train Loss: 0.005359
Validation Loss: 0.00549098
Epoch [252/300], Train Loss: 0.005395
Validation Loss: 0.00548295
Epoch [253/300], Train Loss: 0.005364
Validation Loss: 0.00550215
Epoch [254/300], Train Loss: 0.005359
Validation Loss: 0.00548747
Epoch [255/300], Train Loss: 0.005382
Validation Loss: 0.00548250
Epoch [256/300], Train Loss: 0.005360
Validation Loss: 0.00548480
Epoch [257/300], Train Loss: 0.005362
Validation Loss: 0.00548577
Epoch [258/300], Train Loss: 0.005355
Validation Loss: 0.00548206
Epoch [259/300], Train Loss: 0.005384
Validation Loss: 0.00548163
Epoch [260/300], Train Loss: 0.005367
Validation Loss: 0.00548275
Epoch [261/300], Train Loss: 0.005367
Validation Loss: 0.00548063
Epoch [262/300], Train Loss: 0.005345
Validation Loss: 0.00548060
Epoch [263/300], Train Loss: 0.005360
Validation Loss: 0.00548865
Epoch [264/300], Train Loss: 0.005369
Validation Loss: 0.00547947
Epoch [265/300], Train Loss: 0.005382
Validation Loss: 0.00547914
Epoch [266/300], Train Loss: 0.005361
Validation Loss: 0.00548552
Epoch [267/300], Train Loss: 0.005369
Validation Loss: 0.00547814
Epoch [268/300], Train Loss: 0.005377
Validation Loss: 0.00547817
Epoch [269/300], Train Loss: 0.005374
Validation Loss: 0.00548005
Epoch [270/300], Train Loss: 0.005344
Validation Loss: 0.00547817
Epoch [271/300], Train Loss: 0.005353
Validation Loss: 0.00547708
Epoch [272/300], Train Loss: 0.005349
Validation Loss: 0.00547914
Epoch [273/300], Train Loss: 0.005355
Validation Loss: 0.00548098
Epoch [274/300], Train Loss: 0.005350
Validation Loss: 0.00547601
Epoch [275/300], Train Loss: 0.005351
Validation Loss: 0.00547597
Epoch [276/300], Train Loss: 0.005361
Validation Loss: 0.00547531
Epoch [277/300], Train Loss: 0.005378
Validation Loss: 0.00547814
Epoch [278/300], Train Loss: 0.005361
Validation Loss: 0.00547614
Epoch [279/300], Train Loss: 0.005361
Validation Loss: 0.00547480
Epoch [280/300], Train Loss: 0.005364
Validation Loss: 0.00547503
Epoch [281/300], Train Loss: 0.005349
Validation Loss: 0.00548025
Epoch [282/300], Train Loss: 0.005370
Validation Loss: 0.00547881
Epoch [283/300], Train Loss: 0.005370
Validation Loss: 0.00548009
Epoch [284/300], Train Loss: 0.005355
Validation Loss: 0.00547444
Epoch [285/300], Train Loss: 0.005372
Validation Loss: 0.00547549
Epoch [286/300], Train Loss: 0.005364
Validation Loss: 0.00547826
Epoch [287/300], Train Loss: 0.005361
Validation Loss: 0.00549123
Epoch [288/300], Train Loss: 0.005360
Validation Loss: 0.00547427
Epoch [289/300], Train Loss: 0.005354
Validation Loss: 0.00547388
Epoch [290/300], Train Loss: 0.005345
Validation Loss: 0.00547653
Epoch [291/300], Train Loss: 0.005362
Validation Loss: 0.00547441
Epoch [292/300], Train Loss: 0.005356
Validation Loss: 0.00547182
Epoch [293/300], Train Loss: 0.005355
Validation Loss: 0.00547868
Epoch [294/300], Train Loss: 0.005346
Validation Loss: 0.00547182
Epoch [295/300], Train Loss: 0.005344
Validation Loss: 0.00547355
Epoch [296/300], Train Loss: 0.005347
Validation Loss: 0.00547094
Epoch [297/300], Train Loss: 0.005354
Validation Loss: 0.00548373
Epoch [298/300], Train Loss: 0.005357
Validation Loss: 0.00547113
Epoch [299/300], Train Loss: 0.005350
Validation Loss: 0.00547033
Epoch [300/300], Train Loss: 0.005348
Validation Loss: 0.00547500

Evaluating model for: Router
Run 6/72 completed in 824.66 seconds with: {'MAE': np.float32(0.20086388), 'MSE': np.float32(0.06792898), 'RMSE': np.float32(0.2606319), 'SAE': np.float32(1.8715959e-05), 'NDE': np.float32(0.013024287)}

Run 7/72: hidden=128, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Router
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.066553
Validation Loss: 0.05528384
Epoch [2/300], Train Loss: 0.042318
Validation Loss: 0.02421456
Epoch [3/300], Train Loss: 0.012003
Validation Loss: 0.00786530
Epoch [4/300], Train Loss: 0.007963
Validation Loss: 0.00774597
Epoch [5/300], Train Loss: 0.007589
Validation Loss: 0.00759441
Epoch [6/300], Train Loss: 0.007507
Validation Loss: 0.00753182
Epoch [7/300], Train Loss: 0.007435
Validation Loss: 0.00746524
Epoch [8/300], Train Loss: 0.007371
Validation Loss: 0.00739087
Epoch [9/300], Train Loss: 0.007285
Validation Loss: 0.00731439
Epoch [10/300], Train Loss: 0.007205
Validation Loss: 0.00723723
Epoch [11/300], Train Loss: 0.007144
Validation Loss: 0.00716014
Epoch [12/300], Train Loss: 0.007074
Validation Loss: 0.00709437
Epoch [13/300], Train Loss: 0.006995
Validation Loss: 0.00702232
Epoch [14/300], Train Loss: 0.006897
Validation Loss: 0.00695825
Epoch [15/300], Train Loss: 0.006860
Validation Loss: 0.00690148
Epoch [16/300], Train Loss: 0.006797
Validation Loss: 0.00685596
Epoch [17/300], Train Loss: 0.006740
Validation Loss: 0.00680836
Epoch [18/300], Train Loss: 0.006705
Validation Loss: 0.00677033
Epoch [19/300], Train Loss: 0.006648
Validation Loss: 0.00674247
Epoch [20/300], Train Loss: 0.006627
Validation Loss: 0.00670159
Epoch [21/300], Train Loss: 0.006580
Validation Loss: 0.00667481
Epoch [22/300], Train Loss: 0.006589
Validation Loss: 0.00667119
Epoch [23/300], Train Loss: 0.006544
Validation Loss: 0.00663788
Epoch [24/300], Train Loss: 0.006505
Validation Loss: 0.00659483
Epoch [25/300], Train Loss: 0.006458
Validation Loss: 0.00655647
Epoch [26/300], Train Loss: 0.006426
Validation Loss: 0.00653257
Epoch [27/300], Train Loss: 0.006399
Validation Loss: 0.00651309
Epoch [28/300], Train Loss: 0.006413
Validation Loss: 0.00651079
Epoch [29/300], Train Loss: 0.006382
Validation Loss: 0.00650311
Epoch [30/300], Train Loss: 0.006337
Validation Loss: 0.00648578
Epoch [31/300], Train Loss: 0.006334
Validation Loss: 0.00642823
Epoch [32/300], Train Loss: 0.006291
Validation Loss: 0.00640589
Epoch [33/300], Train Loss: 0.006267
Validation Loss: 0.00638611
Epoch [34/300], Train Loss: 0.006244
Validation Loss: 0.00639838
Epoch [35/300], Train Loss: 0.006222
Validation Loss: 0.00635149
Epoch [36/300], Train Loss: 0.006200
Validation Loss: 0.00634625
Epoch [37/300], Train Loss: 0.006187
Validation Loss: 0.00633101
Epoch [38/300], Train Loss: 0.006184
Validation Loss: 0.00630312
Epoch [39/300], Train Loss: 0.006160
Validation Loss: 0.00629662
Epoch [40/300], Train Loss: 0.006115
Validation Loss: 0.00627378
Epoch [41/300], Train Loss: 0.006107
Validation Loss: 0.00626228
Epoch [42/300], Train Loss: 0.006073
Validation Loss: 0.00624798
Epoch [43/300], Train Loss: 0.006106
Validation Loss: 0.00621606
Epoch [44/300], Train Loss: 0.006052
Validation Loss: 0.00619830
Epoch [45/300], Train Loss: 0.006035
Validation Loss: 0.00617622
Epoch [46/300], Train Loss: 0.006023
Validation Loss: 0.00616054
Epoch [47/300], Train Loss: 0.005999
Validation Loss: 0.00614446
Epoch [48/300], Train Loss: 0.005977
Validation Loss: 0.00612650
Epoch [49/300], Train Loss: 0.005964
Validation Loss: 0.00613016
Epoch [50/300], Train Loss: 0.005945
Validation Loss: 0.00610517
Epoch [51/300], Train Loss: 0.005937
Validation Loss: 0.00608659
Epoch [52/300], Train Loss: 0.005913
Validation Loss: 0.00606949
Epoch [53/300], Train Loss: 0.005903
Validation Loss: 0.00605388
Epoch [54/300], Train Loss: 0.005886
Validation Loss: 0.00603544
Epoch [55/300], Train Loss: 0.005863
Validation Loss: 0.00602779
Epoch [56/300], Train Loss: 0.005863
Validation Loss: 0.00601718
Epoch [57/300], Train Loss: 0.005843
Validation Loss: 0.00601208
Epoch [58/300], Train Loss: 0.005804
Validation Loss: 0.00597989
Epoch [59/300], Train Loss: 0.005806
Validation Loss: 0.00600790
Epoch [60/300], Train Loss: 0.005798
Validation Loss: 0.00595506
Epoch [61/300], Train Loss: 0.005772
Validation Loss: 0.00595026
Epoch [62/300], Train Loss: 0.005771
Validation Loss: 0.00593464
Epoch [63/300], Train Loss: 0.005755
Validation Loss: 0.00594152
Epoch [64/300], Train Loss: 0.005780
Validation Loss: 0.00591598
Epoch [65/300], Train Loss: 0.005771
Validation Loss: 0.00590340
Epoch [66/300], Train Loss: 0.005739
Validation Loss: 0.00589393
Epoch [67/300], Train Loss: 0.005707
Validation Loss: 0.00588582
Epoch [68/300], Train Loss: 0.005719
Validation Loss: 0.00587815
Epoch [69/300], Train Loss: 0.005704
Validation Loss: 0.00589888
Epoch [70/300], Train Loss: 0.005705
Validation Loss: 0.00587432
Epoch [71/300], Train Loss: 0.005680
Validation Loss: 0.00585901
Epoch [72/300], Train Loss: 0.005699
Validation Loss: 0.00587052
Epoch [73/300], Train Loss: 0.005674
Validation Loss: 0.00583467
Epoch [74/300], Train Loss: 0.005636
Validation Loss: 0.00584239
Epoch [75/300], Train Loss: 0.005646
Validation Loss: 0.00581885
Epoch [76/300], Train Loss: 0.005635
Validation Loss: 0.00581310
Epoch [77/300], Train Loss: 0.005651
Validation Loss: 0.00582327
Epoch [78/300], Train Loss: 0.005659
Validation Loss: 0.00579953
Epoch [79/300], Train Loss: 0.005632
Validation Loss: 0.00580519
Epoch [80/300], Train Loss: 0.005634
Validation Loss: 0.00581838
Epoch [81/300], Train Loss: 0.005618
Validation Loss: 0.00579892
Epoch [82/300], Train Loss: 0.005622
Validation Loss: 0.00577642
Epoch [83/300], Train Loss: 0.005625
Validation Loss: 0.00577260
Epoch [84/300], Train Loss: 0.005578
Validation Loss: 0.00576518
Epoch [85/300], Train Loss: 0.005585
Validation Loss: 0.00576148
Epoch [86/300], Train Loss: 0.005585
Validation Loss: 0.00576195
Epoch [87/300], Train Loss: 0.005582
Validation Loss: 0.00576782
Epoch [88/300], Train Loss: 0.005574
Validation Loss: 0.00575030
Epoch [89/300], Train Loss: 0.005558
Validation Loss: 0.00573879
Epoch [90/300], Train Loss: 0.005577
Validation Loss: 0.00573888
Epoch [91/300], Train Loss: 0.005549
Validation Loss: 0.00572698
Epoch [92/300], Train Loss: 0.005551
Validation Loss: 0.00572248
Epoch [93/300], Train Loss: 0.005538
Validation Loss: 0.00572690
Epoch [94/300], Train Loss: 0.005541
Validation Loss: 0.00572398
Epoch [95/300], Train Loss: 0.005564
Validation Loss: 0.00571959
Epoch [96/300], Train Loss: 0.005549
Validation Loss: 0.00570753
Epoch [97/300], Train Loss: 0.005525
Validation Loss: 0.00570382
Epoch [98/300], Train Loss: 0.005528
Validation Loss: 0.00569879
Epoch [99/300], Train Loss: 0.005518
Validation Loss: 0.00569331
Epoch [100/300], Train Loss: 0.005520
Validation Loss: 0.00568923
Epoch [101/300], Train Loss: 0.005505
Validation Loss: 0.00571068
Epoch [102/300], Train Loss: 0.005505
Validation Loss: 0.00568197
Epoch [103/300], Train Loss: 0.005510
Validation Loss: 0.00568168
Epoch [104/300], Train Loss: 0.005503
Validation Loss: 0.00567470
Epoch [105/300], Train Loss: 0.005505
Validation Loss: 0.00567365
Epoch [106/300], Train Loss: 0.005499
Validation Loss: 0.00567343
Epoch [107/300], Train Loss: 0.005494
Validation Loss: 0.00566300
Epoch [108/300], Train Loss: 0.005478
Validation Loss: 0.00566398
Epoch [109/300], Train Loss: 0.005482
Validation Loss: 0.00566037
Epoch [110/300], Train Loss: 0.005476
Validation Loss: 0.00565761
Epoch [111/300], Train Loss: 0.005489
Validation Loss: 0.00565954
Epoch [112/300], Train Loss: 0.005493
Validation Loss: 0.00564758
Epoch [113/300], Train Loss: 0.005485
Validation Loss: 0.00564471
Epoch [114/300], Train Loss: 0.005476
Validation Loss: 0.00564845
Epoch [115/300], Train Loss: 0.005485
Validation Loss: 0.00567167
Epoch [116/300], Train Loss: 0.005465
Validation Loss: 0.00564509
Epoch [117/300], Train Loss: 0.005449
Validation Loss: 0.00563197
Epoch [118/300], Train Loss: 0.005447
Validation Loss: 0.00562885
Epoch [119/300], Train Loss: 0.005456
Validation Loss: 0.00562997
Epoch [120/300], Train Loss: 0.005462
Validation Loss: 0.00562557
Epoch [121/300], Train Loss: 0.005447
Validation Loss: 0.00562179
Epoch [122/300], Train Loss: 0.005445
Validation Loss: 0.00561943
Epoch [123/300], Train Loss: 0.005446
Validation Loss: 0.00561502
Epoch [124/300], Train Loss: 0.005432
Validation Loss: 0.00561423
Epoch [125/300], Train Loss: 0.005427
Validation Loss: 0.00561536
Epoch [126/300], Train Loss: 0.005429
Validation Loss: 0.00560678
Epoch [127/300], Train Loss: 0.005423
Validation Loss: 0.00560547
Epoch [128/300], Train Loss: 0.005433
Validation Loss: 0.00564030
Epoch [129/300], Train Loss: 0.005435
Validation Loss: 0.00560942
Epoch [130/300], Train Loss: 0.005433
Validation Loss: 0.00560325
Epoch [131/300], Train Loss: 0.005417
Validation Loss: 0.00561234
Epoch [132/300], Train Loss: 0.005433
Validation Loss: 0.00560943
Epoch [133/300], Train Loss: 0.005425
Validation Loss: 0.00561368
Epoch [134/300], Train Loss: 0.005415
Validation Loss: 0.00559726
Epoch [135/300], Train Loss: 0.005425
Validation Loss: 0.00558237
Epoch [136/300], Train Loss: 0.005398
Validation Loss: 0.00558479
Epoch [137/300], Train Loss: 0.005414
Validation Loss: 0.00557845
Epoch [138/300], Train Loss: 0.005402
Validation Loss: 0.00557564
Epoch [139/300], Train Loss: 0.005404
Validation Loss: 0.00557755
Epoch [140/300], Train Loss: 0.005397
Validation Loss: 0.00556926
Epoch [141/300], Train Loss: 0.005395
Validation Loss: 0.00556632
Epoch [142/300], Train Loss: 0.005402
Validation Loss: 0.00556749
Epoch [143/300], Train Loss: 0.005387
Validation Loss: 0.00556545
Epoch [144/300], Train Loss: 0.005397
Validation Loss: 0.00556313
Epoch [145/300], Train Loss: 0.005388
Validation Loss: 0.00556454
Epoch [146/300], Train Loss: 0.005395
Validation Loss: 0.00555213
Epoch [147/300], Train Loss: 0.005393
Validation Loss: 0.00555403
Epoch [148/300], Train Loss: 0.005389
Validation Loss: 0.00554606
Epoch [149/300], Train Loss: 0.005394
Validation Loss: 0.00556046
Epoch [150/300], Train Loss: 0.005368
Validation Loss: 0.00556116
Epoch [151/300], Train Loss: 0.005371
Validation Loss: 0.00554050
Epoch [152/300], Train Loss: 0.005383
Validation Loss: 0.00553585
Epoch [153/300], Train Loss: 0.005363
Validation Loss: 0.00553880
Epoch [154/300], Train Loss: 0.005376
Validation Loss: 0.00553277
Epoch [155/300], Train Loss: 0.005372
Validation Loss: 0.00552860
Epoch [156/300], Train Loss: 0.005363
Validation Loss: 0.00552763
Epoch [157/300], Train Loss: 0.005379
Validation Loss: 0.00552389
Epoch [158/300], Train Loss: 0.005358
Validation Loss: 0.00552100
Epoch [159/300], Train Loss: 0.005341
Validation Loss: 0.00552126
Epoch [160/300], Train Loss: 0.005366
Validation Loss: 0.00551720
Epoch [161/300], Train Loss: 0.005369
Validation Loss: 0.00551342
Epoch [162/300], Train Loss: 0.005360
Validation Loss: 0.00551350
Epoch [163/300], Train Loss: 0.005351
Validation Loss: 0.00551150
Epoch [164/300], Train Loss: 0.005347
Validation Loss: 0.00550889
Epoch [165/300], Train Loss: 0.005354
Validation Loss: 0.00551113
Epoch [166/300], Train Loss: 0.005373
Validation Loss: 0.00552178
Epoch [167/300], Train Loss: 0.005344
Validation Loss: 0.00550562
Epoch [168/300], Train Loss: 0.005342
Validation Loss: 0.00550081
Epoch [169/300], Train Loss: 0.005340
Validation Loss: 0.00550770
Epoch [170/300], Train Loss: 0.005349
Validation Loss: 0.00551423
Epoch [171/300], Train Loss: 0.005328
Validation Loss: 0.00549262
Epoch [172/300], Train Loss: 0.005330
Validation Loss: 0.00548966
Epoch [173/300], Train Loss: 0.005324
Validation Loss: 0.00548562
Epoch [174/300], Train Loss: 0.005326
Validation Loss: 0.00548465
Epoch [175/300], Train Loss: 0.005329
Validation Loss: 0.00548119
Epoch [176/300], Train Loss: 0.005315
Validation Loss: 0.00548215
Epoch [177/300], Train Loss: 0.005317
Validation Loss: 0.00547389
Epoch [178/300], Train Loss: 0.005317
Validation Loss: 0.00547050
Epoch [179/300], Train Loss: 0.005330
Validation Loss: 0.00547326
Epoch [180/300], Train Loss: 0.005301
Validation Loss: 0.00546258
Epoch [181/300], Train Loss: 0.005316
Validation Loss: 0.00545843
Epoch [182/300], Train Loss: 0.005306
Validation Loss: 0.00545594
Epoch [183/300], Train Loss: 0.005303
Validation Loss: 0.00545405
Epoch [184/300], Train Loss: 0.005294
Validation Loss: 0.00545344
Epoch [185/300], Train Loss: 0.005284
Validation Loss: 0.00547169
Epoch [186/300], Train Loss: 0.005284
Validation Loss: 0.00544673
Epoch [187/300], Train Loss: 0.005284
Validation Loss: 0.00543474
Epoch [188/300], Train Loss: 0.005270
Validation Loss: 0.00543321
Epoch [189/300], Train Loss: 0.005278
Validation Loss: 0.00542328
Epoch [190/300], Train Loss: 0.005281
Validation Loss: 0.00543626
Epoch [191/300], Train Loss: 0.005284
Validation Loss: 0.00541154
Epoch [192/300], Train Loss: 0.005261
Validation Loss: 0.00540528
Epoch [193/300], Train Loss: 0.005273
Validation Loss: 0.00539672
Epoch [194/300], Train Loss: 0.005262
Validation Loss: 0.00538945
Epoch [195/300], Train Loss: 0.005242
Validation Loss: 0.00538559
Epoch [196/300], Train Loss: 0.005246
Validation Loss: 0.00537222
Epoch [197/300], Train Loss: 0.005230
Validation Loss: 0.00536209
Epoch [198/300], Train Loss: 0.005231
Validation Loss: 0.00535787
Epoch [199/300], Train Loss: 0.005205
Validation Loss: 0.00534039
Epoch [200/300], Train Loss: 0.005200
Validation Loss: 0.00533011
Epoch [201/300], Train Loss: 0.005189
Validation Loss: 0.00531304
Epoch [202/300], Train Loss: 0.005186
Validation Loss: 0.00530695
Epoch [203/300], Train Loss: 0.005177
Validation Loss: 0.00528105
Epoch [204/300], Train Loss: 0.005151
Validation Loss: 0.00526577
Epoch [205/300], Train Loss: 0.005137
Validation Loss: 0.00524248
Epoch [206/300], Train Loss: 0.005098
Validation Loss: 0.00520919
Epoch [207/300], Train Loss: 0.005122
Validation Loss: 0.00518894
Epoch [208/300], Train Loss: 0.005047
Validation Loss: 0.00515174
Epoch [209/300], Train Loss: 0.005022
Validation Loss: 0.00511733
Epoch [210/300], Train Loss: 0.005000
Validation Loss: 0.00508323
Epoch [211/300], Train Loss: 0.004978
Validation Loss: 0.00514366
Epoch [212/300], Train Loss: 0.005002
Validation Loss: 0.00509321
Epoch [213/300], Train Loss: 0.004951
Validation Loss: 0.00504981
Epoch [214/300], Train Loss: 0.004935
Validation Loss: 0.00502860
Epoch [215/300], Train Loss: 0.004934
Validation Loss: 0.00511248
Epoch [216/300], Train Loss: 0.004944
Validation Loss: 0.00500377
Epoch [217/300], Train Loss: 0.004917
Validation Loss: 0.00498950
Epoch [218/300], Train Loss: 0.004907
Validation Loss: 0.00498878
Epoch [219/300], Train Loss: 0.004905
Validation Loss: 0.00498938
Epoch [220/300], Train Loss: 0.004892
Validation Loss: 0.00494634
Epoch [221/300], Train Loss: 0.004891
Validation Loss: 0.00497994
Epoch [222/300], Train Loss: 0.004908
Validation Loss: 0.00495214
Epoch [223/300], Train Loss: 0.004855
Validation Loss: 0.00491007
Epoch [224/300], Train Loss: 0.004833
Validation Loss: 0.00489440
Epoch [225/300], Train Loss: 0.004840
Validation Loss: 0.00488345
Epoch [226/300], Train Loss: 0.004817
Validation Loss: 0.00487578
Epoch [227/300], Train Loss: 0.004822
Validation Loss: 0.00505992
Epoch [228/300], Train Loss: 0.004867
Validation Loss: 0.00487918
Epoch [229/300], Train Loss: 0.004801
Validation Loss: 0.00485652
Epoch [230/300], Train Loss: 0.004782
Validation Loss: 0.00487601
Epoch [231/300], Train Loss: 0.004790
Validation Loss: 0.00483728
Epoch [232/300], Train Loss: 0.004765
Validation Loss: 0.00481777
Epoch [233/300], Train Loss: 0.004785
Validation Loss: 0.00481360
Epoch [234/300], Train Loss: 0.004776
Validation Loss: 0.00484549
Epoch [235/300], Train Loss: 0.004785
Validation Loss: 0.00480362
Epoch [236/300], Train Loss: 0.004761
Validation Loss: 0.00479258
Epoch [237/300], Train Loss: 0.004773
Validation Loss: 0.00478680
Epoch [238/300], Train Loss: 0.004759
Validation Loss: 0.00478369
Epoch [239/300], Train Loss: 0.004770
Validation Loss: 0.00484581
Epoch [240/300], Train Loss: 0.004798
Validation Loss: 0.00476907
Epoch [241/300], Train Loss: 0.004754
Validation Loss: 0.00476901
Epoch [242/300], Train Loss: 0.004747
Validation Loss: 0.00478307
Epoch [243/300], Train Loss: 0.004720
Validation Loss: 0.00475897
Epoch [244/300], Train Loss: 0.004729
Validation Loss: 0.00476623
Epoch [245/300], Train Loss: 0.004733
Validation Loss: 0.00477896
Epoch [246/300], Train Loss: 0.004724
Validation Loss: 0.00476555
Epoch [247/300], Train Loss: 0.004730
Validation Loss: 0.00474985
Epoch [248/300], Train Loss: 0.004749
Validation Loss: 0.00480321
Epoch [249/300], Train Loss: 0.004773
Validation Loss: 0.00477879
Epoch [250/300], Train Loss: 0.004747
Validation Loss: 0.00475283
Epoch [251/300], Train Loss: 0.004740
Validation Loss: 0.00473738
Epoch [252/300], Train Loss: 0.004746
Validation Loss: 0.00477644
Epoch [253/300], Train Loss: 0.004717
Validation Loss: 0.00473798
Epoch [254/300], Train Loss: 0.004705
Validation Loss: 0.00473707
Epoch [255/300], Train Loss: 0.004718
Validation Loss: 0.00472679
Epoch [256/300], Train Loss: 0.004706
Validation Loss: 0.00472877
Epoch [257/300], Train Loss: 0.004704
Validation Loss: 0.00472209
Epoch [258/300], Train Loss: 0.004708
Validation Loss: 0.00472595
Epoch [259/300], Train Loss: 0.004729
Validation Loss: 0.00474031
Epoch [260/300], Train Loss: 0.004707
Validation Loss: 0.00471674
Epoch [261/300], Train Loss: 0.004696
Validation Loss: 0.00471589
Epoch [262/300], Train Loss: 0.004688
Validation Loss: 0.00471256
Epoch [263/300], Train Loss: 0.004697
Validation Loss: 0.00472248
Epoch [264/300], Train Loss: 0.004696
Validation Loss: 0.00471345
Epoch [265/300], Train Loss: 0.004719
Validation Loss: 0.00471067
Epoch [266/300], Train Loss: 0.004698
Validation Loss: 0.00470478
Epoch [267/300], Train Loss: 0.004691
Validation Loss: 0.00471387
Epoch [268/300], Train Loss: 0.004697
Validation Loss: 0.00470349
Epoch [269/300], Train Loss: 0.004706
Validation Loss: 0.00471907
Epoch [270/300], Train Loss: 0.004688
Validation Loss: 0.00470102
Epoch [271/300], Train Loss: 0.004682
Validation Loss: 0.00470153
Epoch [272/300], Train Loss: 0.004694
Validation Loss: 0.00470882
Epoch [273/300], Train Loss: 0.004681
Validation Loss: 0.00470134
Epoch [274/300], Train Loss: 0.004688
Validation Loss: 0.00469809
Epoch [275/300], Train Loss: 0.004687
Validation Loss: 0.00472335
Epoch [276/300], Train Loss: 0.004683
Validation Loss: 0.00469643
Epoch [277/300], Train Loss: 0.004694
Validation Loss: 0.00469815
Epoch [278/300], Train Loss: 0.004683
Validation Loss: 0.00471788
Epoch [279/300], Train Loss: 0.004681
Validation Loss: 0.00470662
Epoch [280/300], Train Loss: 0.004686
Validation Loss: 0.00469070
Epoch [281/300], Train Loss: 0.004673
Validation Loss: 0.00474959
Epoch [282/300], Train Loss: 0.004692
Validation Loss: 0.00468765
Epoch [283/300], Train Loss: 0.004692
Validation Loss: 0.00468563
Epoch [284/300], Train Loss: 0.004672
Validation Loss: 0.00471073
Epoch [285/300], Train Loss: 0.004699
Validation Loss: 0.00468246
Epoch [286/300], Train Loss: 0.004674
Validation Loss: 0.00468599
Epoch [287/300], Train Loss: 0.004667
Validation Loss: 0.00469427
Epoch [288/300], Train Loss: 0.004674
Validation Loss: 0.00471485
Epoch [289/300], Train Loss: 0.004687
Validation Loss: 0.00467820
Epoch [290/300], Train Loss: 0.004669
Validation Loss: 0.00468117
Epoch [291/300], Train Loss: 0.004680
Validation Loss: 0.00470108
Epoch [292/300], Train Loss: 0.004688
Validation Loss: 0.00467993
Epoch [293/300], Train Loss: 0.004667
Validation Loss: 0.00467694
Epoch [294/300], Train Loss: 0.004674
Validation Loss: 0.00469451
Epoch [295/300], Train Loss: 0.004668
Validation Loss: 0.00467608
Epoch [296/300], Train Loss: 0.004677
Validation Loss: 0.00468670
Epoch [297/300], Train Loss: 0.004665
Validation Loss: 0.00467292
Epoch [298/300], Train Loss: 0.004658
Validation Loss: 0.00467603
Epoch [299/300], Train Loss: 0.004677
Validation Loss: 0.00469881
Epoch [300/300], Train Loss: 0.004677
Validation Loss: 0.00468239

Evaluating model for: Router
Run 7/72 completed in 848.06 seconds with: {'MAE': np.float32(0.19109449), 'MSE': np.float32(0.059981633), 'RMSE': np.float32(0.24491148), 'SAE': np.float32(0.00012487792), 'NDE': np.float32(0.01223871)}

Run 8/72: hidden=128, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Router
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.088918
Validation Loss: 0.07210026
Epoch [2/300], Train Loss: 0.052417
Validation Loss: 0.02458090
Epoch [3/300], Train Loss: 0.012392
Validation Loss: 0.00951395
Epoch [4/300], Train Loss: 0.009031
Validation Loss: 0.00864249
Epoch [5/300], Train Loss: 0.008447
Validation Loss: 0.00840407
Epoch [6/300], Train Loss: 0.008351
Validation Loss: 0.00832447
Epoch [7/300], Train Loss: 0.008251
Validation Loss: 0.00822998
Epoch [8/300], Train Loss: 0.008149
Validation Loss: 0.00813545
Epoch [9/300], Train Loss: 0.008060
Validation Loss: 0.00805047
Epoch [10/300], Train Loss: 0.007972
Validation Loss: 0.00796553
Epoch [11/300], Train Loss: 0.007894
Validation Loss: 0.00787970
Epoch [12/300], Train Loss: 0.007815
Validation Loss: 0.00780938
Epoch [13/300], Train Loss: 0.007733
Validation Loss: 0.00772137
Epoch [14/300], Train Loss: 0.007621
Validation Loss: 0.00764471
Epoch [15/300], Train Loss: 0.007571
Validation Loss: 0.00757013
Epoch [16/300], Train Loss: 0.007494
Validation Loss: 0.00751450
Epoch [17/300], Train Loss: 0.007424
Validation Loss: 0.00744001
Epoch [18/300], Train Loss: 0.007343
Validation Loss: 0.00737940
Epoch [19/300], Train Loss: 0.007272
Validation Loss: 0.00732792
Epoch [20/300], Train Loss: 0.007219
Validation Loss: 0.00726027
Epoch [21/300], Train Loss: 0.007148
Validation Loss: 0.00720562
Epoch [22/300], Train Loss: 0.007134
Validation Loss: 0.00717001
Epoch [23/300], Train Loss: 0.007067
Validation Loss: 0.00712682
Epoch [24/300], Train Loss: 0.007019
Validation Loss: 0.00706862
Epoch [25/300], Train Loss: 0.006951
Validation Loss: 0.00701294
Epoch [26/300], Train Loss: 0.006904
Validation Loss: 0.00697431
Epoch [27/300], Train Loss: 0.006866
Validation Loss: 0.00694220
Epoch [28/300], Train Loss: 0.006862
Validation Loss: 0.00693181
Epoch [29/300], Train Loss: 0.006829
Validation Loss: 0.00692670
Epoch [30/300], Train Loss: 0.006765
Validation Loss: 0.00689488
Epoch [31/300], Train Loss: 0.006755
Validation Loss: 0.00682166
Epoch [32/300], Train Loss: 0.006707
Validation Loss: 0.00678656
Epoch [33/300], Train Loss: 0.006667
Validation Loss: 0.00676362
Epoch [34/300], Train Loss: 0.006656
Validation Loss: 0.00677447
Epoch [35/300], Train Loss: 0.006617
Validation Loss: 0.00671313
Epoch [36/300], Train Loss: 0.006584
Validation Loss: 0.00670542
Epoch [37/300], Train Loss: 0.006566
Validation Loss: 0.00668531
Epoch [38/300], Train Loss: 0.006561
Validation Loss: 0.00664655
Epoch [39/300], Train Loss: 0.006523
Validation Loss: 0.00663522
Epoch [40/300], Train Loss: 0.006483
Validation Loss: 0.00660927
Epoch [41/300], Train Loss: 0.006468
Validation Loss: 0.00659146
Epoch [42/300], Train Loss: 0.006440
Validation Loss: 0.00657166
Epoch [43/300], Train Loss: 0.006456
Validation Loss: 0.00653248
Epoch [44/300], Train Loss: 0.006392
Validation Loss: 0.00651191
Epoch [45/300], Train Loss: 0.006377
Validation Loss: 0.00648427
Epoch [46/300], Train Loss: 0.006376
Validation Loss: 0.00646453
Epoch [47/300], Train Loss: 0.006340
Validation Loss: 0.00644186
Epoch [48/300], Train Loss: 0.006321
Validation Loss: 0.00641951
Epoch [49/300], Train Loss: 0.006299
Validation Loss: 0.00642406
Epoch [50/300], Train Loss: 0.006269
Validation Loss: 0.00639110
Epoch [51/300], Train Loss: 0.006269
Validation Loss: 0.00636707
Epoch [52/300], Train Loss: 0.006236
Validation Loss: 0.00634192
Epoch [53/300], Train Loss: 0.006235
Validation Loss: 0.00631970
Epoch [54/300], Train Loss: 0.006196
Validation Loss: 0.00629886
Epoch [55/300], Train Loss: 0.006178
Validation Loss: 0.00628573
Epoch [56/300], Train Loss: 0.006171
Validation Loss: 0.00627540
Epoch [57/300], Train Loss: 0.006148
Validation Loss: 0.00626531
Epoch [58/300], Train Loss: 0.006105
Validation Loss: 0.00622345
Epoch [59/300], Train Loss: 0.006107
Validation Loss: 0.00624259
Epoch [60/300], Train Loss: 0.006102
Validation Loss: 0.00618505
Epoch [61/300], Train Loss: 0.006064
Validation Loss: 0.00616750
Epoch [62/300], Train Loss: 0.006055
Validation Loss: 0.00614794
Epoch [63/300], Train Loss: 0.006042
Validation Loss: 0.00614335
Epoch [64/300], Train Loss: 0.006048
Validation Loss: 0.00611744
Epoch [65/300], Train Loss: 0.006027
Validation Loss: 0.00610230
Epoch [66/300], Train Loss: 0.005991
Validation Loss: 0.00606877
Epoch [67/300], Train Loss: 0.005993
Validation Loss: 0.00607688
Epoch [68/300], Train Loss: 0.005960
Validation Loss: 0.00607413
Epoch [69/300], Train Loss: 0.005936
Validation Loss: 0.00606156
Epoch [70/300], Train Loss: 0.005917
Validation Loss: 0.00599325
Epoch [71/300], Train Loss: 0.005878
Validation Loss: 0.00596479
Epoch [72/300], Train Loss: 0.005858
Validation Loss: 0.00593509
Epoch [73/300], Train Loss: 0.005845
Validation Loss: 0.00590099
Epoch [74/300], Train Loss: 0.005796
Validation Loss: 0.00593227
Epoch [75/300], Train Loss: 0.005779
Validation Loss: 0.00587102
Epoch [76/300], Train Loss: 0.005740
Validation Loss: 0.00583068
Epoch [77/300], Train Loss: 0.005712
Validation Loss: 0.00579806
Epoch [78/300], Train Loss: 0.005692
Validation Loss: 0.00574279
Epoch [79/300], Train Loss: 0.005632
Validation Loss: 0.00567786
Epoch [80/300], Train Loss: 0.005662
Validation Loss: 0.00572596
Epoch [81/300], Train Loss: 0.005616
Validation Loss: 0.00568816
Epoch [82/300], Train Loss: 0.005580
Validation Loss: 0.00574121
Epoch [83/300], Train Loss: 0.005554
Validation Loss: 0.00555305
Epoch [84/300], Train Loss: 0.005520
Validation Loss: 0.00551706
Epoch [85/300], Train Loss: 0.005474
Validation Loss: 0.00550951
Epoch [86/300], Train Loss: 0.005495
Validation Loss: 0.00546371
Epoch [87/300], Train Loss: 0.005461
Validation Loss: 0.00549131
Epoch [88/300], Train Loss: 0.005449
Validation Loss: 0.00543097
Epoch [89/300], Train Loss: 0.005442
Validation Loss: 0.00541994
Epoch [90/300], Train Loss: 0.005432
Validation Loss: 0.00541368
Epoch [91/300], Train Loss: 0.005372
Validation Loss: 0.00534507
Epoch [92/300], Train Loss: 0.005382
Validation Loss: 0.00538447
Epoch [93/300], Train Loss: 0.005352
Validation Loss: 0.00534967
Epoch [94/300], Train Loss: 0.005335
Validation Loss: 0.00534990
Epoch [95/300], Train Loss: 0.005327
Validation Loss: 0.00535821
Epoch [96/300], Train Loss: 0.005300
Validation Loss: 0.00524884
Epoch [97/300], Train Loss: 0.005291
Validation Loss: 0.00524556
Epoch [98/300], Train Loss: 0.005294
Validation Loss: 0.00531710
Epoch [99/300], Train Loss: 0.005253
Validation Loss: 0.00517278
Epoch [100/300], Train Loss: 0.005240
Validation Loss: 0.00515647
Epoch [101/300], Train Loss: 0.005268
Validation Loss: 0.00515115
Epoch [102/300], Train Loss: 0.005210
Validation Loss: 0.00514131
Epoch [103/300], Train Loss: 0.005199
Validation Loss: 0.00511662
Epoch [104/300], Train Loss: 0.005171
Validation Loss: 0.00511314
Epoch [105/300], Train Loss: 0.005167
Validation Loss: 0.00514675
Epoch [106/300], Train Loss: 0.005208
Validation Loss: 0.00517000
Epoch [107/300], Train Loss: 0.005174
Validation Loss: 0.00506225
Epoch [108/300], Train Loss: 0.005146
Validation Loss: 0.00504961
Epoch [109/300], Train Loss: 0.005170
Validation Loss: 0.00510364
Epoch [110/300], Train Loss: 0.005180
Validation Loss: 0.00509026
Epoch [111/300], Train Loss: 0.005131
Validation Loss: 0.00502164
Epoch [112/300], Train Loss: 0.005127
Validation Loss: 0.00505940
Epoch [113/300], Train Loss: 0.005118
Validation Loss: 0.00502543
Epoch [114/300], Train Loss: 0.005108
Validation Loss: 0.00502818
Epoch [115/300], Train Loss: 0.005103
Validation Loss: 0.00499879
Epoch [116/300], Train Loss: 0.005080
Validation Loss: 0.00498149
Epoch [117/300], Train Loss: 0.005084
Validation Loss: 0.00497830
Epoch [118/300], Train Loss: 0.005109
Validation Loss: 0.00501430
Epoch [119/300], Train Loss: 0.005093
Validation Loss: 0.00501147
Epoch [120/300], Train Loss: 0.005057
Validation Loss: 0.00496061
Epoch [121/300], Train Loss: 0.005033
Validation Loss: 0.00495095
Epoch [122/300], Train Loss: 0.005058
Validation Loss: 0.00498292
Epoch [123/300], Train Loss: 0.005042
Validation Loss: 0.00507518
Epoch [124/300], Train Loss: 0.005040
Validation Loss: 0.00495512
Epoch [125/300], Train Loss: 0.005029
Validation Loss: 0.00502024
Epoch [126/300], Train Loss: 0.005024
Validation Loss: 0.00492539
Epoch [127/300], Train Loss: 0.005012
Validation Loss: 0.00494150
Epoch [128/300], Train Loss: 0.005000
Validation Loss: 0.00494629
Epoch [129/300], Train Loss: 0.004993
Validation Loss: 0.00492457
Epoch [130/300], Train Loss: 0.004995
Validation Loss: 0.00490796
Epoch [131/300], Train Loss: 0.004982
Validation Loss: 0.00490531
Epoch [132/300], Train Loss: 0.004973
Validation Loss: 0.00491616
Epoch [133/300], Train Loss: 0.005000
Validation Loss: 0.00490259
Epoch [134/300], Train Loss: 0.004994
Validation Loss: 0.00490425
Epoch [135/300], Train Loss: 0.004975
Validation Loss: 0.00494604
Epoch [136/300], Train Loss: 0.004967
Validation Loss: 0.00488869
Epoch [137/300], Train Loss: 0.004974
Validation Loss: 0.00491495
Epoch [138/300], Train Loss: 0.004981
Validation Loss: 0.00494102
Epoch [139/300], Train Loss: 0.004942
Validation Loss: 0.00488833
Epoch [140/300], Train Loss: 0.004935
Validation Loss: 0.00486399
Epoch [141/300], Train Loss: 0.004939
Validation Loss: 0.00490056
Epoch [142/300], Train Loss: 0.004949
Validation Loss: 0.00493143
Epoch [143/300], Train Loss: 0.004972
Validation Loss: 0.00496925
Epoch [144/300], Train Loss: 0.004999
Validation Loss: 0.00487422
Epoch [145/300], Train Loss: 0.004964
Validation Loss: 0.00488053
Epoch [146/300], Train Loss: 0.004947
Validation Loss: 0.00486096
Epoch [147/300], Train Loss: 0.004918
Validation Loss: 0.00485703
Epoch [148/300], Train Loss: 0.004918
Validation Loss: 0.00487710
Epoch [149/300], Train Loss: 0.004923
Validation Loss: 0.00484648
Epoch [150/300], Train Loss: 0.004954
Validation Loss: 0.00491706
Epoch [151/300], Train Loss: 0.004914
Validation Loss: 0.00483432
Epoch [152/300], Train Loss: 0.004900
Validation Loss: 0.00482663
Epoch [153/300], Train Loss: 0.004901
Validation Loss: 0.00483867
Epoch [154/300], Train Loss: 0.004892
Validation Loss: 0.00482280
Epoch [155/300], Train Loss: 0.004891
Validation Loss: 0.00485365
Epoch [156/300], Train Loss: 0.004884
Validation Loss: 0.00482413
Epoch [157/300], Train Loss: 0.004889
Validation Loss: 0.00481740
Epoch [158/300], Train Loss: 0.004892
Validation Loss: 0.00483208
Epoch [159/300], Train Loss: 0.004869
Validation Loss: 0.00481290
Epoch [160/300], Train Loss: 0.004891
Validation Loss: 0.00483605
Epoch [161/300], Train Loss: 0.004881
Validation Loss: 0.00480365
Epoch [162/300], Train Loss: 0.004875
Validation Loss: 0.00481584
Epoch [163/300], Train Loss: 0.004875
Validation Loss: 0.00481911
Epoch [164/300], Train Loss: 0.004867
Validation Loss: 0.00480923
Epoch [165/300], Train Loss: 0.004875
Validation Loss: 0.00481877
Epoch [166/300], Train Loss: 0.004880
Validation Loss: 0.00478485
Epoch [167/300], Train Loss: 0.004871
Validation Loss: 0.00484659
Epoch [168/300], Train Loss: 0.004868
Validation Loss: 0.00479767
Epoch [169/300], Train Loss: 0.004857
Validation Loss: 0.00479586
Epoch [170/300], Train Loss: 0.004867
Validation Loss: 0.00477863
Epoch [171/300], Train Loss: 0.004842
Validation Loss: 0.00478642
Epoch [172/300], Train Loss: 0.004859
Validation Loss: 0.00477520
Epoch [173/300], Train Loss: 0.004837
Validation Loss: 0.00477874
Epoch [174/300], Train Loss: 0.004853
Validation Loss: 0.00482328
Epoch [175/300], Train Loss: 0.004864
Validation Loss: 0.00476602
Epoch [176/300], Train Loss: 0.004851
Validation Loss: 0.00479682
Epoch [177/300], Train Loss: 0.004843
Validation Loss: 0.00477731
Epoch [178/300], Train Loss: 0.004830
Validation Loss: 0.00478772
Epoch [179/300], Train Loss: 0.004833
Validation Loss: 0.00476866
Epoch [180/300], Train Loss: 0.004821
Validation Loss: 0.00476689
Epoch [181/300], Train Loss: 0.004832
Validation Loss: 0.00475090
Epoch [182/300], Train Loss: 0.004826
Validation Loss: 0.00478233
Epoch [183/300], Train Loss: 0.004845
Validation Loss: 0.00475737
Epoch [184/300], Train Loss: 0.004824
Validation Loss: 0.00475385
Epoch [185/300], Train Loss: 0.004823
Validation Loss: 0.00477289
Epoch [186/300], Train Loss: 0.004824
Validation Loss: 0.00474628
Epoch [187/300], Train Loss: 0.004816
Validation Loss: 0.00474161
Epoch [188/300], Train Loss: 0.004815
Validation Loss: 0.00473802
Epoch [189/300], Train Loss: 0.004795
Validation Loss: 0.00475422
Epoch [190/300], Train Loss: 0.004832
Validation Loss: 0.00474320
Epoch [191/300], Train Loss: 0.004819
Validation Loss: 0.00474025
Epoch [192/300], Train Loss: 0.004795
Validation Loss: 0.00473357
Epoch [193/300], Train Loss: 0.004801
Validation Loss: 0.00472455
Epoch [194/300], Train Loss: 0.004810
Validation Loss: 0.00474119
Epoch [195/300], Train Loss: 0.004798
Validation Loss: 0.00473244
Epoch [196/300], Train Loss: 0.004783
Validation Loss: 0.00472628
Epoch [197/300], Train Loss: 0.004784
Validation Loss: 0.00474358
Epoch [198/300], Train Loss: 0.004783
Validation Loss: 0.00472067
Epoch [199/300], Train Loss: 0.004790
Validation Loss: 0.00473269
Epoch [200/300], Train Loss: 0.004784
Validation Loss: 0.00471646
Epoch [201/300], Train Loss: 0.004785
Validation Loss: 0.00472165
Epoch [202/300], Train Loss: 0.004782
Validation Loss: 0.00473316
Epoch [203/300], Train Loss: 0.004787
Validation Loss: 0.00471135
Epoch [204/300], Train Loss: 0.004798
Validation Loss: 0.00476024
Epoch [205/300], Train Loss: 0.004775
Validation Loss: 0.00473247
Epoch [206/300], Train Loss: 0.004777
Validation Loss: 0.00470533
Epoch [207/300], Train Loss: 0.004812
Validation Loss: 0.00470971
Epoch [208/300], Train Loss: 0.004773
Validation Loss: 0.00470958
Epoch [209/300], Train Loss: 0.004772
Validation Loss: 0.00470140
Epoch [210/300], Train Loss: 0.004760
Validation Loss: 0.00469900
Epoch [211/300], Train Loss: 0.004757
Validation Loss: 0.00470897
Epoch [212/300], Train Loss: 0.004775
Validation Loss: 0.00470018
Epoch [213/300], Train Loss: 0.004759
Validation Loss: 0.00469420
Epoch [214/300], Train Loss: 0.004751
Validation Loss: 0.00470524
Epoch [215/300], Train Loss: 0.004755
Validation Loss: 0.00469062
Epoch [216/300], Train Loss: 0.004772
Validation Loss: 0.00472415
Epoch [217/300], Train Loss: 0.004752
Validation Loss: 0.00468717
Epoch [218/300], Train Loss: 0.004759
Validation Loss: 0.00470348
Epoch [219/300], Train Loss: 0.004770
Validation Loss: 0.00469809
Epoch [220/300], Train Loss: 0.004762
Validation Loss: 0.00471770
Epoch [221/300], Train Loss: 0.004745
Validation Loss: 0.00469590
Epoch [222/300], Train Loss: 0.004768
Validation Loss: 0.00470328
Epoch [223/300], Train Loss: 0.004749
Validation Loss: 0.00468929
Epoch [224/300], Train Loss: 0.004733
Validation Loss: 0.00467644
Epoch [225/300], Train Loss: 0.004741
Validation Loss: 0.00467962
Epoch [226/300], Train Loss: 0.004741
Validation Loss: 0.00467449
Epoch [227/300], Train Loss: 0.004749
Validation Loss: 0.00472020
Epoch [228/300], Train Loss: 0.004759
Validation Loss: 0.00469297
Epoch [229/300], Train Loss: 0.004742
Validation Loss: 0.00466975
Epoch [230/300], Train Loss: 0.004729
Validation Loss: 0.00470438
Epoch [231/300], Train Loss: 0.004741
Validation Loss: 0.00467534
Epoch [232/300], Train Loss: 0.004728
Validation Loss: 0.00468101
Epoch [233/300], Train Loss: 0.004731
Validation Loss: 0.00468196
Epoch [234/300], Train Loss: 0.004725
Validation Loss: 0.00466985
Epoch [235/300], Train Loss: 0.004747
Validation Loss: 0.00467404
Epoch [236/300], Train Loss: 0.004732
Validation Loss: 0.00467748
Epoch [237/300], Train Loss: 0.004754
Validation Loss: 0.00466059
Epoch [238/300], Train Loss: 0.004732
Validation Loss: 0.00468642
Epoch [239/300], Train Loss: 0.004732
Validation Loss: 0.00466354
Epoch [240/300], Train Loss: 0.004729
Validation Loss: 0.00465720
Epoch [241/300], Train Loss: 0.004733
Validation Loss: 0.00466110
Epoch [242/300], Train Loss: 0.004720
Validation Loss: 0.00466130
Epoch [243/300], Train Loss: 0.004716
Validation Loss: 0.00466764
Epoch [244/300], Train Loss: 0.004716
Validation Loss: 0.00465286
Epoch [245/300], Train Loss: 0.004717
Validation Loss: 0.00465377
Epoch [246/300], Train Loss: 0.004719
Validation Loss: 0.00469590
Epoch [247/300], Train Loss: 0.004734
Validation Loss: 0.00470653
Epoch [248/300], Train Loss: 0.004714
Validation Loss: 0.00465363
Epoch [249/300], Train Loss: 0.004717
Validation Loss: 0.00466982
Epoch [250/300], Train Loss: 0.004710
Validation Loss: 0.00465349
Epoch [251/300], Train Loss: 0.004706
Validation Loss: 0.00464875
Epoch [252/300], Train Loss: 0.004728
Validation Loss: 0.00466191
Epoch [253/300], Train Loss: 0.004723
Validation Loss: 0.00464093
Epoch [254/300], Train Loss: 0.004709
Validation Loss: 0.00466544
Epoch [255/300], Train Loss: 0.004723
Validation Loss: 0.00464969
Epoch [256/300], Train Loss: 0.004696
Validation Loss: 0.00464022
Epoch [257/300], Train Loss: 0.004694
Validation Loss: 0.00464230
Epoch [258/300], Train Loss: 0.004695
Validation Loss: 0.00464166
Epoch [259/300], Train Loss: 0.004712
Validation Loss: 0.00463979
Epoch [260/300], Train Loss: 0.004697
Validation Loss: 0.00463767
Epoch [261/300], Train Loss: 0.004696
Validation Loss: 0.00463611
Epoch [262/300], Train Loss: 0.004680
Validation Loss: 0.00463605
Epoch [263/300], Train Loss: 0.004694
Validation Loss: 0.00463306
Epoch [264/300], Train Loss: 0.004684
Validation Loss: 0.00463899
Epoch [265/300], Train Loss: 0.004709
Validation Loss: 0.00464185
Epoch [266/300], Train Loss: 0.004690
Validation Loss: 0.00462971
Epoch [267/300], Train Loss: 0.004693
Validation Loss: 0.00464730
Epoch [268/300], Train Loss: 0.004693
Validation Loss: 0.00462835
Epoch [269/300], Train Loss: 0.004692
Validation Loss: 0.00462858
Epoch [270/300], Train Loss: 0.004683
Validation Loss: 0.00463659
Epoch [271/300], Train Loss: 0.004681
Validation Loss: 0.00462691
Epoch [272/300], Train Loss: 0.004689
Validation Loss: 0.00465295
Epoch [273/300], Train Loss: 0.004688
Validation Loss: 0.00464596
Epoch [274/300], Train Loss: 0.004692
Validation Loss: 0.00462460
Epoch [275/300], Train Loss: 0.004689
Validation Loss: 0.00463456
Epoch [276/300], Train Loss: 0.004682
Validation Loss: 0.00463848
Epoch [277/300], Train Loss: 0.004689
Validation Loss: 0.00462549
Epoch [278/300], Train Loss: 0.004684
Validation Loss: 0.00462544
Epoch [279/300], Train Loss: 0.004689
Validation Loss: 0.00463651
Epoch [280/300], Train Loss: 0.004688
Validation Loss: 0.00463117
Epoch [281/300], Train Loss: 0.004659
Validation Loss: 0.00466371
Epoch [282/300], Train Loss: 0.004689
Validation Loss: 0.00462135
Epoch [283/300], Train Loss: 0.004681
Validation Loss: 0.00461457
Epoch [284/300], Train Loss: 0.004669
Validation Loss: 0.00463479
Epoch [285/300], Train Loss: 0.004690
Validation Loss: 0.00461278
Epoch [286/300], Train Loss: 0.004672
Validation Loss: 0.00461705
Epoch [287/300], Train Loss: 0.004665
Validation Loss: 0.00461689
Epoch [288/300], Train Loss: 0.004663
Validation Loss: 0.00463939
Epoch [289/300], Train Loss: 0.004672
Validation Loss: 0.00461113
Epoch [290/300], Train Loss: 0.004668
Validation Loss: 0.00460929
Epoch [291/300], Train Loss: 0.004678
Validation Loss: 0.00463904
Epoch [292/300], Train Loss: 0.004684
Validation Loss: 0.00462661
Epoch [293/300], Train Loss: 0.004670
Validation Loss: 0.00460812
Epoch [294/300], Train Loss: 0.004659
Validation Loss: 0.00464185
Epoch [295/300], Train Loss: 0.004671
Validation Loss: 0.00460920
Epoch [296/300], Train Loss: 0.004664
Validation Loss: 0.00461333
Epoch [297/300], Train Loss: 0.004662
Validation Loss: 0.00460490
Epoch [298/300], Train Loss: 0.004658
Validation Loss: 0.00462525
Epoch [299/300], Train Loss: 0.004673
Validation Loss: 0.00461227
Epoch [300/300], Train Loss: 0.004668
Validation Loss: 0.00461120

Evaluating model for: Router
Run 8/72 completed in 892.97 seconds with: {'MAE': np.float32(0.19110566), 'MSE': np.float32(0.05953538), 'RMSE': np.float32(0.24399874), 'SAE': np.float32(2.437793e-05), 'NDE': np.float32(0.012193098)}

Run 9/72: hidden=128, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Router
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.079783
Validation Loss: 0.07453759
Epoch [2/300], Train Loss: 0.065096
Validation Loss: 0.05939079
Epoch [3/300], Train Loss: 0.049464
Validation Loss: 0.04184861
Epoch [4/300], Train Loss: 0.029974
Validation Loss: 0.01809382
Epoch [5/300], Train Loss: 0.009686
Validation Loss: 0.00789830
Epoch [6/300], Train Loss: 0.007104
Validation Loss: 0.00658752
Epoch [7/300], Train Loss: 0.006534
Validation Loss: 0.00585278
Epoch [8/300], Train Loss: 0.006337
Validation Loss: 0.00588625
Epoch [9/300], Train Loss: 0.006301
Validation Loss: 0.00588912
Epoch [10/300], Train Loss: 0.006268
Validation Loss: 0.00586692
Epoch [11/300], Train Loss: 0.006259
Validation Loss: 0.00586938
Epoch [12/300], Train Loss: 0.006249
Validation Loss: 0.00585905
Epoch [13/300], Train Loss: 0.006264
Validation Loss: 0.00586179
Epoch [14/300], Train Loss: 0.006257
Validation Loss: 0.00584674
Epoch [15/300], Train Loss: 0.006235
Validation Loss: 0.00585183
Epoch [16/300], Train Loss: 0.006251
Validation Loss: 0.00585057
Epoch [17/300], Train Loss: 0.006276
Validation Loss: 0.00582786
Epoch [18/300], Train Loss: 0.006225
Validation Loss: 0.00585173
Epoch [19/300], Train Loss: 0.006240
Validation Loss: 0.00581336
Epoch [20/300], Train Loss: 0.006242
Validation Loss: 0.00583212
Epoch [21/300], Train Loss: 0.006207
Validation Loss: 0.00582544
Epoch [22/300], Train Loss: 0.006199
Validation Loss: 0.00582410
Epoch [23/300], Train Loss: 0.006203
Validation Loss: 0.00580363
Epoch [24/300], Train Loss: 0.006180
Validation Loss: 0.00581245
Epoch [25/300], Train Loss: 0.006172
Validation Loss: 0.00580397
Epoch [26/300], Train Loss: 0.006184
Validation Loss: 0.00579597
Epoch [27/300], Train Loss: 0.006168
Validation Loss: 0.00580229
Epoch [28/300], Train Loss: 0.006122
Validation Loss: 0.00578990
Epoch [29/300], Train Loss: 0.006150
Validation Loss: 0.00578804
Epoch [30/300], Train Loss: 0.006163
Validation Loss: 0.00578409
Epoch [31/300], Train Loss: 0.006147
Validation Loss: 0.00578141
Epoch [32/300], Train Loss: 0.006120
Validation Loss: 0.00576112
Epoch [33/300], Train Loss: 0.006108
Validation Loss: 0.00576075
Epoch [34/300], Train Loss: 0.006100
Validation Loss: 0.00579372
Epoch [35/300], Train Loss: 0.006139
Validation Loss: 0.00574421
Epoch [36/300], Train Loss: 0.006106
Validation Loss: 0.00577908
Epoch [37/300], Train Loss: 0.006161
Validation Loss: 0.00573960
Epoch [38/300], Train Loss: 0.006106
Validation Loss: 0.00574649
Epoch [39/300], Train Loss: 0.006090
Validation Loss: 0.00574275
Epoch [40/300], Train Loss: 0.006107
Validation Loss: 0.00572839
Epoch [41/300], Train Loss: 0.006092
Validation Loss: 0.00574189
Epoch [42/300], Train Loss: 0.006078
Validation Loss: 0.00574584
Epoch [43/300], Train Loss: 0.006076
Validation Loss: 0.00572203
Epoch [44/300], Train Loss: 0.006085
Validation Loss: 0.00572413
Epoch [45/300], Train Loss: 0.006064
Validation Loss: 0.00571570
Epoch [46/300], Train Loss: 0.006041
Validation Loss: 0.00570502
Epoch [47/300], Train Loss: 0.006023
Validation Loss: 0.00572026
Epoch [48/300], Train Loss: 0.006022
Validation Loss: 0.00572388
Epoch [49/300], Train Loss: 0.006020
Validation Loss: 0.00568577
Epoch [50/300], Train Loss: 0.006017
Validation Loss: 0.00570308
Epoch [51/300], Train Loss: 0.006012
Validation Loss: 0.00570528
Epoch [52/300], Train Loss: 0.006035
Validation Loss: 0.00567833
Epoch [53/300], Train Loss: 0.006029
Validation Loss: 0.00569101
Epoch [54/300], Train Loss: 0.006010
Validation Loss: 0.00568684
Epoch [55/300], Train Loss: 0.006027
Validation Loss: 0.00568792
Epoch [56/300], Train Loss: 0.005980
Validation Loss: 0.00565909
Epoch [57/300], Train Loss: 0.006006
Validation Loss: 0.00566841
Epoch [58/300], Train Loss: 0.006032
Validation Loss: 0.00565580
Epoch [59/300], Train Loss: 0.005988
Validation Loss: 0.00567548
Epoch [60/300], Train Loss: 0.005978
Validation Loss: 0.00565191
Epoch [61/300], Train Loss: 0.005961
Validation Loss: 0.00565327
Epoch [62/300], Train Loss: 0.005967
Validation Loss: 0.00564596
Epoch [63/300], Train Loss: 0.005948
Validation Loss: 0.00566980
Epoch [64/300], Train Loss: 0.005942
Validation Loss: 0.00562548
Epoch [65/300], Train Loss: 0.005951
Validation Loss: 0.00564774
Epoch [66/300], Train Loss: 0.005926
Validation Loss: 0.00560988
Epoch [67/300], Train Loss: 0.005974
Validation Loss: 0.00568342
Epoch [68/300], Train Loss: 0.005967
Validation Loss: 0.00560299
Epoch [69/300], Train Loss: 0.005974
Validation Loss: 0.00564903
Epoch [70/300], Train Loss: 0.005940
Validation Loss: 0.00560535
Epoch [71/300], Train Loss: 0.005941
Validation Loss: 0.00566627
Epoch [72/300], Train Loss: 0.005902
Validation Loss: 0.00558787
Epoch [73/300], Train Loss: 0.005921
Validation Loss: 0.00562618
Epoch [74/300], Train Loss: 0.005941
Validation Loss: 0.00559302
Epoch [75/300], Train Loss: 0.005923
Validation Loss: 0.00561579
Epoch [76/300], Train Loss: 0.005903
Validation Loss: 0.00559561
Epoch [77/300], Train Loss: 0.005895
Validation Loss: 0.00560912
Epoch [78/300], Train Loss: 0.005897
Validation Loss: 0.00561219
Epoch [79/300], Train Loss: 0.005886
Validation Loss: 0.00558358
Epoch [80/300], Train Loss: 0.005891
Validation Loss: 0.00559858
Epoch [81/300], Train Loss: 0.005906
Validation Loss: 0.00560111
Epoch [82/300], Train Loss: 0.005900
Validation Loss: 0.00558359
Epoch [83/300], Train Loss: 0.005891
Validation Loss: 0.00557052
Epoch [84/300], Train Loss: 0.005871
Validation Loss: 0.00558409
Epoch [85/300], Train Loss: 0.005880
Validation Loss: 0.00557937
Epoch [86/300], Train Loss: 0.005879
Validation Loss: 0.00557305
Epoch [87/300], Train Loss: 0.005884
Validation Loss: 0.00556788
Epoch [88/300], Train Loss: 0.005857
Validation Loss: 0.00557151
Epoch [89/300], Train Loss: 0.005855
Validation Loss: 0.00555082
Epoch [90/300], Train Loss: 0.005883
Validation Loss: 0.00556201
Epoch [91/300], Train Loss: 0.005865
Validation Loss: 0.00556255
Epoch [92/300], Train Loss: 0.005878
Validation Loss: 0.00553672
Epoch [93/300], Train Loss: 0.005924
Validation Loss: 0.00555899
Epoch [94/300], Train Loss: 0.005864
Validation Loss: 0.00553577
Epoch [95/300], Train Loss: 0.005855
Validation Loss: 0.00556136
Epoch [96/300], Train Loss: 0.005862
Validation Loss: 0.00554970
Epoch [97/300], Train Loss: 0.005837
Validation Loss: 0.00553675
Epoch [98/300], Train Loss: 0.005821
Validation Loss: 0.00554491
Epoch [99/300], Train Loss: 0.005819
Validation Loss: 0.00554260
Epoch [100/300], Train Loss: 0.005848
Validation Loss: 0.00552671
Epoch [101/300], Train Loss: 0.005815
Validation Loss: 0.00555492
Epoch [102/300], Train Loss: 0.005830
Validation Loss: 0.00551151
Epoch [103/300], Train Loss: 0.005821
Validation Loss: 0.00556195
Epoch [104/300], Train Loss: 0.005828
Validation Loss: 0.00550806
Epoch [105/300], Train Loss: 0.005833
Validation Loss: 0.00554150
Epoch [106/300], Train Loss: 0.005804
Validation Loss: 0.00549725
Epoch [107/300], Train Loss: 0.005829
Validation Loss: 0.00553049
Epoch [108/300], Train Loss: 0.005816
Validation Loss: 0.00551755
Epoch [109/300], Train Loss: 0.005804
Validation Loss: 0.00550244
Epoch [110/300], Train Loss: 0.005802
Validation Loss: 0.00552334
Epoch [111/300], Train Loss: 0.005782
Validation Loss: 0.00550196
Epoch [112/300], Train Loss: 0.005807
Validation Loss: 0.00551316
Epoch [113/300], Train Loss: 0.005805
Validation Loss: 0.00549909
Epoch [114/300], Train Loss: 0.005787
Validation Loss: 0.00550647
Epoch [115/300], Train Loss: 0.005789
Validation Loss: 0.00549471
Epoch [116/300], Train Loss: 0.005775
Validation Loss: 0.00550822
Epoch [117/300], Train Loss: 0.005782
Validation Loss: 0.00549688
Epoch [118/300], Train Loss: 0.005784
Validation Loss: 0.00548530
Epoch [119/300], Train Loss: 0.005778
Validation Loss: 0.00550681
Epoch [120/300], Train Loss: 0.005777
Validation Loss: 0.00547487
Epoch [121/300], Train Loss: 0.005769
Validation Loss: 0.00551782
Epoch [122/300], Train Loss: 0.005773
Validation Loss: 0.00547124
Epoch [123/300], Train Loss: 0.005780
Validation Loss: 0.00548427
Epoch [124/300], Train Loss: 0.005793
Validation Loss: 0.00551097
Epoch [125/300], Train Loss: 0.005759
Validation Loss: 0.00548262
Epoch [126/300], Train Loss: 0.005830
Validation Loss: 0.00547286
Epoch [127/300], Train Loss: 0.005754
Validation Loss: 0.00548120
Epoch [128/300], Train Loss: 0.005790
Validation Loss: 0.00546321
Epoch [129/300], Train Loss: 0.005754
Validation Loss: 0.00548336
Epoch [130/300], Train Loss: 0.005788
Validation Loss: 0.00546530
Epoch [131/300], Train Loss: 0.005775
Validation Loss: 0.00548514
Epoch [132/300], Train Loss: 0.005784
Validation Loss: 0.00547277
Epoch [133/300], Train Loss: 0.005748
Validation Loss: 0.00546354
Epoch [134/300], Train Loss: 0.005746
Validation Loss: 0.00545782
Epoch [135/300], Train Loss: 0.005749
Validation Loss: 0.00547419
Epoch [136/300], Train Loss: 0.005740
Validation Loss: 0.00546618
Epoch [137/300], Train Loss: 0.005760
Validation Loss: 0.00546992
Epoch [138/300], Train Loss: 0.005736
Validation Loss: 0.00546102
Epoch [139/300], Train Loss: 0.005767
Validation Loss: 0.00547183
Epoch [140/300], Train Loss: 0.005775
Validation Loss: 0.00544298
Epoch [141/300], Train Loss: 0.005751
Validation Loss: 0.00546529
Epoch [142/300], Train Loss: 0.005744
Validation Loss: 0.00545457
Epoch [143/300], Train Loss: 0.005734
Validation Loss: 0.00544278
Epoch [144/300], Train Loss: 0.005734
Validation Loss: 0.00546413
Epoch [145/300], Train Loss: 0.005719
Validation Loss: 0.00544862
Epoch [146/300], Train Loss: 0.005737
Validation Loss: 0.00545381
Epoch [147/300], Train Loss: 0.005724
Validation Loss: 0.00544601
Epoch [148/300], Train Loss: 0.005725
Validation Loss: 0.00544646
Epoch [149/300], Train Loss: 0.005719
Validation Loss: 0.00545057
Epoch [150/300], Train Loss: 0.005732
Validation Loss: 0.00544343
Epoch [151/300], Train Loss: 0.005715
Validation Loss: 0.00544931
Epoch [152/300], Train Loss: 0.005715
Validation Loss: 0.00543525
Epoch [153/300], Train Loss: 0.005704
Validation Loss: 0.00544993
Epoch [154/300], Train Loss: 0.005722
Validation Loss: 0.00543953
Epoch [155/300], Train Loss: 0.005694
Validation Loss: 0.00543194
Epoch [156/300], Train Loss: 0.005719
Validation Loss: 0.00543930
Epoch [157/300], Train Loss: 0.005716
Validation Loss: 0.00544044
Epoch [158/300], Train Loss: 0.005699
Validation Loss: 0.00543744
Epoch [159/300], Train Loss: 0.005742
Validation Loss: 0.00542596
Epoch [160/300], Train Loss: 0.005703
Validation Loss: 0.00544585
Epoch [161/300], Train Loss: 0.005710
Validation Loss: 0.00543159
Epoch [162/300], Train Loss: 0.005687
Validation Loss: 0.00543325
Epoch [163/300], Train Loss: 0.005697
Validation Loss: 0.00542363
Epoch [164/300], Train Loss: 0.005711
Validation Loss: 0.00544841
Epoch [165/300], Train Loss: 0.005720
Validation Loss: 0.00541984
Epoch [166/300], Train Loss: 0.005730
Validation Loss: 0.00542866
Epoch [167/300], Train Loss: 0.005688
Validation Loss: 0.00542172
Epoch [168/300], Train Loss: 0.005682
Validation Loss: 0.00543093
Epoch [169/300], Train Loss: 0.005696
Validation Loss: 0.00542372
Epoch [170/300], Train Loss: 0.005708
Validation Loss: 0.00542207
Epoch [171/300], Train Loss: 0.005697
Validation Loss: 0.00541200
Epoch [172/300], Train Loss: 0.005698
Validation Loss: 0.00540996
Epoch [173/300], Train Loss: 0.005679
Validation Loss: 0.00542334
Epoch [174/300], Train Loss: 0.005710
Validation Loss: 0.00542360
Epoch [175/300], Train Loss: 0.005683
Validation Loss: 0.00541299
Epoch [176/300], Train Loss: 0.005701
Validation Loss: 0.00540705
Epoch [177/300], Train Loss: 0.005691
Validation Loss: 0.00542179
Epoch [178/300], Train Loss: 0.005683
Validation Loss: 0.00541575
Epoch [179/300], Train Loss: 0.005718
Validation Loss: 0.00541048
Epoch [180/300], Train Loss: 0.005698
Validation Loss: 0.00542702
Epoch [181/300], Train Loss: 0.005672
Validation Loss: 0.00541032
Epoch [182/300], Train Loss: 0.005677
Validation Loss: 0.00540979
Epoch [183/300], Train Loss: 0.005686
Validation Loss: 0.00541681
Epoch [184/300], Train Loss: 0.005675
Validation Loss: 0.00540497
Epoch [185/300], Train Loss: 0.005660
Validation Loss: 0.00540367
Epoch [186/300], Train Loss: 0.005673
Validation Loss: 0.00541066
Epoch [187/300], Train Loss: 0.005684
Validation Loss: 0.00540840
Epoch [188/300], Train Loss: 0.005685
Validation Loss: 0.00540499
Epoch [189/300], Train Loss: 0.005679
Validation Loss: 0.00541611
Epoch [190/300], Train Loss: 0.005664
Validation Loss: 0.00539012
Epoch [191/300], Train Loss: 0.005672
Validation Loss: 0.00541775
Epoch [192/300], Train Loss: 0.005683
Validation Loss: 0.00539242
Epoch [193/300], Train Loss: 0.005677
Validation Loss: 0.00541606
Epoch [194/300], Train Loss: 0.005684
Validation Loss: 0.00539269
Epoch [195/300], Train Loss: 0.005675
Validation Loss: 0.00541166
Epoch [196/300], Train Loss: 0.005650
Validation Loss: 0.00540205
Epoch [197/300], Train Loss: 0.005662
Validation Loss: 0.00539220
Epoch [198/300], Train Loss: 0.005663
Validation Loss: 0.00540757
Epoch [199/300], Train Loss: 0.005677
Validation Loss: 0.00538804
Epoch [200/300], Train Loss: 0.005693
Validation Loss: 0.00540651
Epoch [201/300], Train Loss: 0.005671
Validation Loss: 0.00538628
Epoch [202/300], Train Loss: 0.005661
Validation Loss: 0.00540909
Epoch [203/300], Train Loss: 0.005670
Validation Loss: 0.00538347
Epoch [204/300], Train Loss: 0.005635
Validation Loss: 0.00539442
Epoch [205/300], Train Loss: 0.005700
Validation Loss: 0.00539584
Epoch [206/300], Train Loss: 0.005661
Validation Loss: 0.00539188
Epoch [207/300], Train Loss: 0.005667
Validation Loss: 0.00539237
Epoch [208/300], Train Loss: 0.005673
Validation Loss: 0.00538659
Epoch [209/300], Train Loss: 0.005678
Validation Loss: 0.00539043
Epoch [210/300], Train Loss: 0.005643
Validation Loss: 0.00537745
Epoch [211/300], Train Loss: 0.005656
Validation Loss: 0.00539056
Epoch [212/300], Train Loss: 0.005652
Validation Loss: 0.00538708
Epoch [213/300], Train Loss: 0.005634
Validation Loss: 0.00538906
Epoch [214/300], Train Loss: 0.005650
Validation Loss: 0.00539534
Epoch [215/300], Train Loss: 0.005667
Validation Loss: 0.00537728
Epoch [216/300], Train Loss: 0.005662
Validation Loss: 0.00540225
Epoch [217/300], Train Loss: 0.005651
Validation Loss: 0.00536877
Epoch [218/300], Train Loss: 0.005681
Validation Loss: 0.00538894
Epoch [219/300], Train Loss: 0.005668
Validation Loss: 0.00536645
Epoch [220/300], Train Loss: 0.005652
Validation Loss: 0.00539102
Epoch [221/300], Train Loss: 0.005637
Validation Loss: 0.00538040
Epoch [222/300], Train Loss: 0.005651
Validation Loss: 0.00538681
Epoch [223/300], Train Loss: 0.005625
Validation Loss: 0.00537522
Epoch [224/300], Train Loss: 0.005632
Validation Loss: 0.00539012
Epoch [225/300], Train Loss: 0.005646
Validation Loss: 0.00537423
Epoch [226/300], Train Loss: 0.005663
Validation Loss: 0.00538989
Epoch [227/300], Train Loss: 0.005650
Validation Loss: 0.00537916
Epoch [228/300], Train Loss: 0.005640
Validation Loss: 0.00537009
Epoch [229/300], Train Loss: 0.005643
Validation Loss: 0.00538883
Early stopping triggered

Evaluating model for: Router
Run 9/72 completed in 431.55 seconds with: {'MAE': np.float32(0.19889407), 'MSE': np.float32(0.0691501), 'RMSE': np.float32(0.26296407), 'SAE': np.float32(0.000119808195), 'NDE': np.float32(0.013150715)}

Run 10/72: hidden=128, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Router
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.095990
Validation Loss: 0.09000044
Epoch [2/300], Train Loss: 0.078773
Validation Loss: 0.07047745
Epoch [3/300], Train Loss: 0.054870
Validation Loss: 0.03838646
Epoch [4/300], Train Loss: 0.018456
Validation Loss: 0.00880903
Epoch [5/300], Train Loss: 0.008818
Validation Loss: 0.00729668
Epoch [6/300], Train Loss: 0.007233
Validation Loss: 0.00616530
Epoch [7/300], Train Loss: 0.006781
Validation Loss: 0.00618393
Epoch [8/300], Train Loss: 0.006675
Validation Loss: 0.00620718
Epoch [9/300], Train Loss: 0.006665
Validation Loss: 0.00614903
Epoch [10/300], Train Loss: 0.006644
Validation Loss: 0.00618443
Epoch [11/300], Train Loss: 0.006627
Validation Loss: 0.00613910
Epoch [12/300], Train Loss: 0.006617
Validation Loss: 0.00615451
Epoch [13/300], Train Loss: 0.006621
Validation Loss: 0.00612966
Epoch [14/300], Train Loss: 0.006611
Validation Loss: 0.00612813
Epoch [15/300], Train Loss: 0.006589
Validation Loss: 0.00611480
Epoch [16/300], Train Loss: 0.006590
Validation Loss: 0.00612415
Epoch [17/300], Train Loss: 0.006618
Validation Loss: 0.00609132
Epoch [18/300], Train Loss: 0.006563
Validation Loss: 0.00610866
Epoch [19/300], Train Loss: 0.006565
Validation Loss: 0.00607358
Epoch [20/300], Train Loss: 0.006573
Validation Loss: 0.00608543
Epoch [21/300], Train Loss: 0.006522
Validation Loss: 0.00607748
Epoch [22/300], Train Loss: 0.006507
Validation Loss: 0.00608662
Epoch [23/300], Train Loss: 0.006521
Validation Loss: 0.00604039
Epoch [24/300], Train Loss: 0.006487
Validation Loss: 0.00606566
Epoch [25/300], Train Loss: 0.006481
Validation Loss: 0.00604625
Epoch [26/300], Train Loss: 0.006485
Validation Loss: 0.00603388
Epoch [27/300], Train Loss: 0.006457
Validation Loss: 0.00604159
Epoch [28/300], Train Loss: 0.006419
Validation Loss: 0.00602182
Epoch [29/300], Train Loss: 0.006440
Validation Loss: 0.00602331
Epoch [30/300], Train Loss: 0.006440
Validation Loss: 0.00601093
Epoch [31/300], Train Loss: 0.006420
Validation Loss: 0.00601842
Epoch [32/300], Train Loss: 0.006389
Validation Loss: 0.00597514
Epoch [33/300], Train Loss: 0.006380
Validation Loss: 0.00599348
Epoch [34/300], Train Loss: 0.006375
Validation Loss: 0.00602613
Epoch [35/300], Train Loss: 0.006400
Validation Loss: 0.00595969
Epoch [36/300], Train Loss: 0.006358
Validation Loss: 0.00599351
Epoch [37/300], Train Loss: 0.006415
Validation Loss: 0.00595774
Epoch [38/300], Train Loss: 0.006357
Validation Loss: 0.00594608
Epoch [39/300], Train Loss: 0.006340
Validation Loss: 0.00595743
Epoch [40/300], Train Loss: 0.006355
Validation Loss: 0.00594050
Epoch [41/300], Train Loss: 0.006343
Validation Loss: 0.00593448
Epoch [42/300], Train Loss: 0.006329
Validation Loss: 0.00596516
Epoch [43/300], Train Loss: 0.006321
Validation Loss: 0.00591987
Epoch [44/300], Train Loss: 0.006325
Validation Loss: 0.00591579
Epoch [45/300], Train Loss: 0.006290
Validation Loss: 0.00592079
Epoch [46/300], Train Loss: 0.006274
Validation Loss: 0.00589587
Epoch [47/300], Train Loss: 0.006253
Validation Loss: 0.00592422
Epoch [48/300], Train Loss: 0.006262
Validation Loss: 0.00592379
Epoch [49/300], Train Loss: 0.006232
Validation Loss: 0.00586881
Epoch [50/300], Train Loss: 0.006241
Validation Loss: 0.00589454
Epoch [51/300], Train Loss: 0.006233
Validation Loss: 0.00592558
Epoch [52/300], Train Loss: 0.006252
Validation Loss: 0.00584256
Epoch [53/300], Train Loss: 0.006249
Validation Loss: 0.00590211
Epoch [54/300], Train Loss: 0.006229
Validation Loss: 0.00587061
Epoch [55/300], Train Loss: 0.006240
Validation Loss: 0.00585671
Epoch [56/300], Train Loss: 0.006196
Validation Loss: 0.00583603
Epoch [57/300], Train Loss: 0.006215
Validation Loss: 0.00583708
Epoch [58/300], Train Loss: 0.006234
Validation Loss: 0.00582525
Epoch [59/300], Train Loss: 0.006186
Validation Loss: 0.00585415
Epoch [60/300], Train Loss: 0.006184
Validation Loss: 0.00580855
Epoch [61/300], Train Loss: 0.006162
Validation Loss: 0.00583144
Epoch [62/300], Train Loss: 0.006165
Validation Loss: 0.00580597
Epoch [63/300], Train Loss: 0.006148
Validation Loss: 0.00583354
Epoch [64/300], Train Loss: 0.006137
Validation Loss: 0.00578853
Epoch [65/300], Train Loss: 0.006147
Validation Loss: 0.00579479
Epoch [66/300], Train Loss: 0.006121
Validation Loss: 0.00576297
Epoch [67/300], Train Loss: 0.006163
Validation Loss: 0.00589123
Epoch [68/300], Train Loss: 0.006164
Validation Loss: 0.00575095
Epoch [69/300], Train Loss: 0.006167
Validation Loss: 0.00579014
Epoch [70/300], Train Loss: 0.006128
Validation Loss: 0.00576397
Epoch [71/300], Train Loss: 0.006125
Validation Loss: 0.00583046
Epoch [72/300], Train Loss: 0.006097
Validation Loss: 0.00573555
Epoch [73/300], Train Loss: 0.006107
Validation Loss: 0.00576954
Epoch [74/300], Train Loss: 0.006128
Validation Loss: 0.00574376
Epoch [75/300], Train Loss: 0.006098
Validation Loss: 0.00574522
Epoch [76/300], Train Loss: 0.006084
Validation Loss: 0.00574872
Epoch [77/300], Train Loss: 0.006079
Validation Loss: 0.00574808
Epoch [78/300], Train Loss: 0.006080
Validation Loss: 0.00578015
Epoch [79/300], Train Loss: 0.006063
Validation Loss: 0.00571896
Epoch [80/300], Train Loss: 0.006068
Validation Loss: 0.00572452
Epoch [81/300], Train Loss: 0.006083
Validation Loss: 0.00578849
Epoch [82/300], Train Loss: 0.006097
Validation Loss: 0.00571665
Epoch [83/300], Train Loss: 0.006075
Validation Loss: 0.00569031
Epoch [84/300], Train Loss: 0.006054
Validation Loss: 0.00574134
Epoch [85/300], Train Loss: 0.006059
Validation Loss: 0.00571065
Epoch [86/300], Train Loss: 0.006049
Validation Loss: 0.00571952
Epoch [87/300], Train Loss: 0.006045
Validation Loss: 0.00570032
Epoch [88/300], Train Loss: 0.006030
Validation Loss: 0.00569342
Epoch [89/300], Train Loss: 0.006017
Validation Loss: 0.00569826
Epoch [90/300], Train Loss: 0.006058
Validation Loss: 0.00567641
Epoch [91/300], Train Loss: 0.006029
Validation Loss: 0.00569689
Epoch [92/300], Train Loss: 0.006041
Validation Loss: 0.00566436
Epoch [93/300], Train Loss: 0.006092
Validation Loss: 0.00566548
Epoch [94/300], Train Loss: 0.006033
Validation Loss: 0.00567315
Epoch [95/300], Train Loss: 0.006014
Validation Loss: 0.00566973
Epoch [96/300], Train Loss: 0.006017
Validation Loss: 0.00569670
Epoch [97/300], Train Loss: 0.005997
Validation Loss: 0.00565490
Epoch [98/300], Train Loss: 0.005978
Validation Loss: 0.00565698
Epoch [99/300], Train Loss: 0.005975
Validation Loss: 0.00568180
Epoch [100/300], Train Loss: 0.005997
Validation Loss: 0.00563158
Epoch [101/300], Train Loss: 0.005979
Validation Loss: 0.00571131
Epoch [102/300], Train Loss: 0.005977
Validation Loss: 0.00562914
Epoch [103/300], Train Loss: 0.005964
Validation Loss: 0.00569337
Epoch [104/300], Train Loss: 0.005977
Validation Loss: 0.00562576
Epoch [105/300], Train Loss: 0.005979
Validation Loss: 0.00565192
Epoch [106/300], Train Loss: 0.005958
Validation Loss: 0.00561519
Epoch [107/300], Train Loss: 0.005978
Validation Loss: 0.00563712
Epoch [108/300], Train Loss: 0.005968
Validation Loss: 0.00563978
Epoch [109/300], Train Loss: 0.005952
Validation Loss: 0.00561718
Epoch [110/300], Train Loss: 0.005943
Validation Loss: 0.00564225
Epoch [111/300], Train Loss: 0.005927
Validation Loss: 0.00560728
Epoch [112/300], Train Loss: 0.005951
Validation Loss: 0.00562820
Epoch [113/300], Train Loss: 0.005949
Validation Loss: 0.00560304
Epoch [114/300], Train Loss: 0.005939
Validation Loss: 0.00562684
Epoch [115/300], Train Loss: 0.005922
Validation Loss: 0.00561852
Epoch [116/300], Train Loss: 0.005905
Validation Loss: 0.00560996
Epoch [117/300], Train Loss: 0.005918
Validation Loss: 0.00562453
Epoch [118/300], Train Loss: 0.005927
Validation Loss: 0.00558762
Epoch [119/300], Train Loss: 0.005918
Validation Loss: 0.00561820
Epoch [120/300], Train Loss: 0.005906
Validation Loss: 0.00558008
Epoch [121/300], Train Loss: 0.005910
Validation Loss: 0.00562964
Epoch [122/300], Train Loss: 0.005906
Validation Loss: 0.00559440
Epoch [123/300], Train Loss: 0.005917
Validation Loss: 0.00556680
Epoch [124/300], Train Loss: 0.005926
Validation Loss: 0.00567497
Epoch [125/300], Train Loss: 0.005919
Validation Loss: 0.00559344
Epoch [126/300], Train Loss: 0.005981
Validation Loss: 0.00555511
Epoch [127/300], Train Loss: 0.005900
Validation Loss: 0.00561291
Epoch [128/300], Train Loss: 0.005925
Validation Loss: 0.00556033
Epoch [129/300], Train Loss: 0.005885
Validation Loss: 0.00557242
Epoch [130/300], Train Loss: 0.005920
Validation Loss: 0.00558958
Epoch [131/300], Train Loss: 0.005907
Validation Loss: 0.00556791
Epoch [132/300], Train Loss: 0.005913
Validation Loss: 0.00559009
Epoch [133/300], Train Loss: 0.005883
Validation Loss: 0.00555815
Epoch [134/300], Train Loss: 0.005875
Validation Loss: 0.00555811
Epoch [135/300], Train Loss: 0.005871
Validation Loss: 0.00558576
Epoch [136/300], Train Loss: 0.005867
Validation Loss: 0.00555207
Epoch [137/300], Train Loss: 0.005892
Validation Loss: 0.00559965
Epoch [138/300], Train Loss: 0.005862
Validation Loss: 0.00553920
Epoch [139/300], Train Loss: 0.005887
Validation Loss: 0.00560859
Epoch [140/300], Train Loss: 0.005900
Validation Loss: 0.00552436
Epoch [141/300], Train Loss: 0.005882
Validation Loss: 0.00558389
Epoch [142/300], Train Loss: 0.005862
Validation Loss: 0.00554689
Epoch [143/300], Train Loss: 0.005864
Validation Loss: 0.00553218
Epoch [144/300], Train Loss: 0.005860
Validation Loss: 0.00558475
Epoch [145/300], Train Loss: 0.005849
Validation Loss: 0.00553996
Epoch [146/300], Train Loss: 0.005867
Validation Loss: 0.00554914
Epoch [147/300], Train Loss: 0.005852
Validation Loss: 0.00553697
Epoch [148/300], Train Loss: 0.005849
Validation Loss: 0.00554859
Epoch [149/300], Train Loss: 0.005843
Validation Loss: 0.00554430
Epoch [150/300], Train Loss: 0.005858
Validation Loss: 0.00553897
Early stopping triggered

Evaluating model for: Router
Run 10/72 completed in 312.79 seconds with: {'MAE': np.float32(0.20143199), 'MSE': np.float32(0.071598165), 'RMSE': np.float32(0.26757833), 'SAE': np.float32(0.00030350348), 'NDE': np.float32(0.013381472)}

Run 11/72: hidden=128, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Router
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.092115
Validation Loss: 0.08732041
Epoch [2/300], Train Loss: 0.076781
Validation Loss: 0.06961392
Epoch [3/300], Train Loss: 0.055823
Validation Loss: 0.04068811
Epoch [4/300], Train Loss: 0.019325
Validation Loss: 0.01058075
Epoch [5/300], Train Loss: 0.009034
Validation Loss: 0.00774240
Epoch [6/300], Train Loss: 0.007352
Validation Loss: 0.00635119
Epoch [7/300], Train Loss: 0.006916
Validation Loss: 0.00638846
Epoch [8/300], Train Loss: 0.006809
Validation Loss: 0.00635471
Epoch [9/300], Train Loss: 0.006806
Validation Loss: 0.00632240
Epoch [10/300], Train Loss: 0.006789
Validation Loss: 0.00634315
Epoch [11/300], Train Loss: 0.006775
Validation Loss: 0.00630376
Epoch [12/300], Train Loss: 0.006766
Validation Loss: 0.00631512
Epoch [13/300], Train Loss: 0.006758
Validation Loss: 0.00629027
Epoch [14/300], Train Loss: 0.006749
Validation Loss: 0.00628374
Epoch [15/300], Train Loss: 0.006720
Validation Loss: 0.00627020
Epoch [16/300], Train Loss: 0.006721
Validation Loss: 0.00627291
Epoch [17/300], Train Loss: 0.006748
Validation Loss: 0.00623986
Epoch [18/300], Train Loss: 0.006698
Validation Loss: 0.00625717
Epoch [19/300], Train Loss: 0.006699
Validation Loss: 0.00621885
Epoch [20/300], Train Loss: 0.006706
Validation Loss: 0.00622318
Epoch [21/300], Train Loss: 0.006649
Validation Loss: 0.00621532
Epoch [22/300], Train Loss: 0.006642
Validation Loss: 0.00622983
Epoch [23/300], Train Loss: 0.006637
Validation Loss: 0.00616523
Epoch [24/300], Train Loss: 0.006613
Validation Loss: 0.00619448
Epoch [25/300], Train Loss: 0.006594
Validation Loss: 0.00617144
Epoch [26/300], Train Loss: 0.006596
Validation Loss: 0.00615016
Epoch [27/300], Train Loss: 0.006571
Validation Loss: 0.00615533
Epoch [28/300], Train Loss: 0.006526
Validation Loss: 0.00613189
Epoch [29/300], Train Loss: 0.006541
Validation Loss: 0.00612826
Epoch [30/300], Train Loss: 0.006543
Validation Loss: 0.00611426
Epoch [31/300], Train Loss: 0.006508
Validation Loss: 0.00611993
Epoch [32/300], Train Loss: 0.006479
Validation Loss: 0.00606600
Epoch [33/300], Train Loss: 0.006477
Validation Loss: 0.00608452
Epoch [34/300], Train Loss: 0.006469
Validation Loss: 0.00613412
Epoch [35/300], Train Loss: 0.006494
Validation Loss: 0.00604510
Epoch [36/300], Train Loss: 0.006436
Validation Loss: 0.00606728
Epoch [37/300], Train Loss: 0.006491
Validation Loss: 0.00604132
Epoch [38/300], Train Loss: 0.006429
Validation Loss: 0.00601379
Epoch [39/300], Train Loss: 0.006403
Validation Loss: 0.00601922
Epoch [40/300], Train Loss: 0.006420
Validation Loss: 0.00602129
Epoch [41/300], Train Loss: 0.006398
Validation Loss: 0.00598698
Epoch [42/300], Train Loss: 0.006380
Validation Loss: 0.00601535
Epoch [43/300], Train Loss: 0.006368
Validation Loss: 0.00598436
Epoch [44/300], Train Loss: 0.006376
Validation Loss: 0.00595476
Epoch [45/300], Train Loss: 0.006333
Validation Loss: 0.00596925
Epoch [46/300], Train Loss: 0.006311
Validation Loss: 0.00594822
Epoch [47/300], Train Loss: 0.006286
Validation Loss: 0.00595685
Epoch [48/300], Train Loss: 0.006288
Validation Loss: 0.00598826
Epoch [49/300], Train Loss: 0.006267
Validation Loss: 0.00590174
Epoch [50/300], Train Loss: 0.006267
Validation Loss: 0.00590624
Epoch [51/300], Train Loss: 0.006251
Validation Loss: 0.00602232
Epoch [52/300], Train Loss: 0.006269
Validation Loss: 0.00587038
Epoch [53/300], Train Loss: 0.006257
Validation Loss: 0.00588747
Epoch [54/300], Train Loss: 0.006237
Validation Loss: 0.00595650
Epoch [55/300], Train Loss: 0.006265
Validation Loss: 0.00588643
Epoch [56/300], Train Loss: 0.006194
Validation Loss: 0.00583798
Epoch [57/300], Train Loss: 0.006221
Validation Loss: 0.00583939
Epoch [58/300], Train Loss: 0.006239
Validation Loss: 0.00582897
Epoch [59/300], Train Loss: 0.006191
Validation Loss: 0.00587481
Epoch [60/300], Train Loss: 0.006185
Validation Loss: 0.00580977
Epoch [61/300], Train Loss: 0.006165
Validation Loss: 0.00583441
Epoch [62/300], Train Loss: 0.006157
Validation Loss: 0.00583044
Epoch [63/300], Train Loss: 0.006136
Validation Loss: 0.00582315
Epoch [64/300], Train Loss: 0.006130
Validation Loss: 0.00578980
Epoch [65/300], Train Loss: 0.006131
Validation Loss: 0.00576962
Epoch [66/300], Train Loss: 0.006119
Validation Loss: 0.00575546
Epoch [67/300], Train Loss: 0.006149
Validation Loss: 0.00586264
Epoch [68/300], Train Loss: 0.006131
Validation Loss: 0.00577267
Epoch [69/300], Train Loss: 0.006133
Validation Loss: 0.00574823
Epoch [70/300], Train Loss: 0.006115
Validation Loss: 0.00574001
Epoch [71/300], Train Loss: 0.006102
Validation Loss: 0.00583678
Epoch [72/300], Train Loss: 0.006067
Validation Loss: 0.00575431
Epoch [73/300], Train Loss: 0.006084
Validation Loss: 0.00574758
Epoch [74/300], Train Loss: 0.006103
Validation Loss: 0.00572909
Epoch [75/300], Train Loss: 0.006078
Validation Loss: 0.00572196
Epoch [76/300], Train Loss: 0.006058
Validation Loss: 0.00573035
Epoch [77/300], Train Loss: 0.006051
Validation Loss: 0.00573391
Epoch [78/300], Train Loss: 0.006060
Validation Loss: 0.00579928
Epoch [79/300], Train Loss: 0.006043
Validation Loss: 0.00574712
Epoch [80/300], Train Loss: 0.006038
Validation Loss: 0.00568801
Epoch [81/300], Train Loss: 0.006049
Validation Loss: 0.00577799
Epoch [82/300], Train Loss: 0.006057
Validation Loss: 0.00579013
Epoch [83/300], Train Loss: 0.006052
Validation Loss: 0.00566299
Epoch [84/300], Train Loss: 0.006025
Validation Loss: 0.00567654
Epoch [85/300], Train Loss: 0.006042
Validation Loss: 0.00569536
Epoch [86/300], Train Loss: 0.006032
Validation Loss: 0.00575291
Epoch [87/300], Train Loss: 0.006038
Validation Loss: 0.00573110
Epoch [88/300], Train Loss: 0.006008
Validation Loss: 0.00566281
Epoch [89/300], Train Loss: 0.005999
Validation Loss: 0.00568152
Epoch [90/300], Train Loss: 0.006040
Validation Loss: 0.00566418
Epoch [91/300], Train Loss: 0.006007
Validation Loss: 0.00565808
Epoch [92/300], Train Loss: 0.006019
Validation Loss: 0.00564660
Epoch [93/300], Train Loss: 0.006074
Validation Loss: 0.00562742
Epoch [94/300], Train Loss: 0.006018
Validation Loss: 0.00564017
Epoch [95/300], Train Loss: 0.005991
Validation Loss: 0.00563951
Epoch [96/300], Train Loss: 0.005986
Validation Loss: 0.00568393
Epoch [97/300], Train Loss: 0.005978
Validation Loss: 0.00565991
Epoch [98/300], Train Loss: 0.005960
Validation Loss: 0.00561989
Epoch [99/300], Train Loss: 0.005952
Validation Loss: 0.00565667
Epoch [100/300], Train Loss: 0.005981
Validation Loss: 0.00560875
Epoch [101/300], Train Loss: 0.005952
Validation Loss: 0.00569004
Epoch [102/300], Train Loss: 0.005957
Validation Loss: 0.00563769
Epoch [103/300], Train Loss: 0.005951
Validation Loss: 0.00568663
Epoch [104/300], Train Loss: 0.005956
Validation Loss: 0.00561515
Epoch [105/300], Train Loss: 0.005956
Validation Loss: 0.00560840
Epoch [106/300], Train Loss: 0.005940
Validation Loss: 0.00559441
Epoch [107/300], Train Loss: 0.005956
Validation Loss: 0.00560420
Epoch [108/300], Train Loss: 0.005946
Validation Loss: 0.00561352
Epoch [109/300], Train Loss: 0.005924
Validation Loss: 0.00561238
Epoch [110/300], Train Loss: 0.005931
Validation Loss: 0.00563431
Epoch [111/300], Train Loss: 0.005906
Validation Loss: 0.00558328
Epoch [112/300], Train Loss: 0.005925
Validation Loss: 0.00559504
Epoch [113/300], Train Loss: 0.005926
Validation Loss: 0.00557630
Epoch [114/300], Train Loss: 0.005916
Validation Loss: 0.00560273
Epoch [115/300], Train Loss: 0.005898
Validation Loss: 0.00562641
Epoch [116/300], Train Loss: 0.005891
Validation Loss: 0.00559017
Epoch [117/300], Train Loss: 0.005899
Validation Loss: 0.00561075
Epoch [118/300], Train Loss: 0.005920
Validation Loss: 0.00557553
Epoch [119/300], Train Loss: 0.005898
Validation Loss: 0.00557960
Epoch [120/300], Train Loss: 0.005891
Validation Loss: 0.00555920
Epoch [121/300], Train Loss: 0.005889
Validation Loss: 0.00559264
Epoch [122/300], Train Loss: 0.005889
Validation Loss: 0.00561163
Epoch [123/300], Train Loss: 0.005907
Validation Loss: 0.00553914
Epoch [124/300], Train Loss: 0.005896
Validation Loss: 0.00564493
Epoch [125/300], Train Loss: 0.005889
Validation Loss: 0.00565477
Epoch [126/300], Train Loss: 0.005976
Validation Loss: 0.00553425
Epoch [127/300], Train Loss: 0.005891
Validation Loss: 0.00557312
Epoch [128/300], Train Loss: 0.005896
Validation Loss: 0.00556501
Epoch [129/300], Train Loss: 0.005867
Validation Loss: 0.00552804
Epoch [130/300], Train Loss: 0.005898
Validation Loss: 0.00557999
Epoch [131/300], Train Loss: 0.005891
Validation Loss: 0.00554895
Epoch [132/300], Train Loss: 0.005883
Validation Loss: 0.00555913
Epoch [133/300], Train Loss: 0.005862
Validation Loss: 0.00553822
Epoch [134/300], Train Loss: 0.005860
Validation Loss: 0.00552782
Epoch [135/300], Train Loss: 0.005853
Validation Loss: 0.00557408
Epoch [136/300], Train Loss: 0.005851
Validation Loss: 0.00552023
Epoch [137/300], Train Loss: 0.005860
Validation Loss: 0.00559031
Epoch [138/300], Train Loss: 0.005835
Validation Loss: 0.00551161
Epoch [139/300], Train Loss: 0.005855
Validation Loss: 0.00558656
Epoch [140/300], Train Loss: 0.005874
Validation Loss: 0.00549657
Epoch [141/300], Train Loss: 0.005849
Validation Loss: 0.00553443
Epoch [142/300], Train Loss: 0.005839
Validation Loss: 0.00553896
Epoch [143/300], Train Loss: 0.005841
Validation Loss: 0.00549155
Epoch [144/300], Train Loss: 0.005843
Validation Loss: 0.00556648
Epoch [145/300], Train Loss: 0.005820
Validation Loss: 0.00552710
Epoch [146/300], Train Loss: 0.005832
Validation Loss: 0.00550127
Epoch [147/300], Train Loss: 0.005821
Validation Loss: 0.00550090
Epoch [148/300], Train Loss: 0.005826
Validation Loss: 0.00551937
Epoch [149/300], Train Loss: 0.005814
Validation Loss: 0.00551239
Epoch [150/300], Train Loss: 0.005822
Validation Loss: 0.00549635
Epoch [151/300], Train Loss: 0.005802
Validation Loss: 0.00555030
Epoch [152/300], Train Loss: 0.005801
Validation Loss: 0.00547273
Epoch [153/300], Train Loss: 0.005794
Validation Loss: 0.00552670
Epoch [154/300], Train Loss: 0.005807
Validation Loss: 0.00549305
Epoch [155/300], Train Loss: 0.005782
Validation Loss: 0.00548374
Epoch [156/300], Train Loss: 0.005803
Validation Loss: 0.00549038
Epoch [157/300], Train Loss: 0.005796
Validation Loss: 0.00551389
Epoch [158/300], Train Loss: 0.005782
Validation Loss: 0.00546476
Epoch [159/300], Train Loss: 0.005824
Validation Loss: 0.00546702
Epoch [160/300], Train Loss: 0.005786
Validation Loss: 0.00550169
Epoch [161/300], Train Loss: 0.005786
Validation Loss: 0.00549579
Epoch [162/300], Train Loss: 0.005776
Validation Loss: 0.00547618
Epoch [163/300], Train Loss: 0.005772
Validation Loss: 0.00544648
Epoch [164/300], Train Loss: 0.005791
Validation Loss: 0.00557505
Epoch [165/300], Train Loss: 0.005810
Validation Loss: 0.00545606
Epoch [166/300], Train Loss: 0.005816
Validation Loss: 0.00544008
Epoch [167/300], Train Loss: 0.005767
Validation Loss: 0.00549128
Epoch [168/300], Train Loss: 0.005763
Validation Loss: 0.00548916
Epoch [169/300], Train Loss: 0.005760
Validation Loss: 0.00543732
Epoch [170/300], Train Loss: 0.005773
Validation Loss: 0.00545725
Epoch [171/300], Train Loss: 0.005759
Validation Loss: 0.00544155
Epoch [172/300], Train Loss: 0.005764
Validation Loss: 0.00542396
Epoch [173/300], Train Loss: 0.005743
Validation Loss: 0.00551162
Epoch [174/300], Train Loss: 0.005771
Validation Loss: 0.00542634
Epoch [175/300], Train Loss: 0.005747
Validation Loss: 0.00546215
Epoch [176/300], Train Loss: 0.005754
Validation Loss: 0.00542892
Epoch [177/300], Train Loss: 0.005753
Validation Loss: 0.00545150
Epoch [178/300], Train Loss: 0.005744
Validation Loss: 0.00542568
Epoch [179/300], Train Loss: 0.005773
Validation Loss: 0.00548783
Epoch [180/300], Train Loss: 0.005767
Validation Loss: 0.00543071
Epoch [181/300], Train Loss: 0.005730
Validation Loss: 0.00544114
Epoch [182/300], Train Loss: 0.005736
Validation Loss: 0.00543898
Early stopping triggered

Evaluating model for: Router
Run 11/72 completed in 390.12 seconds with: {'MAE': np.float32(0.20029603), 'MSE': np.float32(0.070171416), 'RMSE': np.float32(0.26489887), 'SAE': np.float32(0.00026861252), 'NDE': np.float32(0.013247474)}

Run 12/72: hidden=128, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Router
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.119128
Validation Loss: 0.11116819
Epoch [2/300], Train Loss: 0.097404
Validation Loss: 0.08690355
Epoch [3/300], Train Loss: 0.068480
Validation Loss: 0.04682381
Epoch [4/300], Train Loss: 0.020665
Validation Loss: 0.01290280
Epoch [5/300], Train Loss: 0.009247
Validation Loss: 0.00855827
Epoch [6/300], Train Loss: 0.007682
Validation Loss: 0.00690517
Epoch [7/300], Train Loss: 0.007361
Validation Loss: 0.00688748
Epoch [8/300], Train Loss: 0.007250
Validation Loss: 0.00670555
Epoch [9/300], Train Loss: 0.007206
Validation Loss: 0.00670768
Epoch [10/300], Train Loss: 0.007184
Validation Loss: 0.00670846
Epoch [11/300], Train Loss: 0.007167
Validation Loss: 0.00666914
Epoch [12/300], Train Loss: 0.007153
Validation Loss: 0.00667637
Epoch [13/300], Train Loss: 0.007151
Validation Loss: 0.00664527
Epoch [14/300], Train Loss: 0.007123
Validation Loss: 0.00663792
Epoch [15/300], Train Loss: 0.007111
Validation Loss: 0.00661895
Epoch [16/300], Train Loss: 0.007104
Validation Loss: 0.00661588
Epoch [17/300], Train Loss: 0.007123
Validation Loss: 0.00658259
Epoch [18/300], Train Loss: 0.007076
Validation Loss: 0.00658502
Epoch [19/300], Train Loss: 0.007072
Validation Loss: 0.00655400
Epoch [20/300], Train Loss: 0.007066
Validation Loss: 0.00654742
Epoch [21/300], Train Loss: 0.007015
Validation Loss: 0.00653852
Epoch [22/300], Train Loss: 0.006982
Validation Loss: 0.00655416
Epoch [23/300], Train Loss: 0.006996
Validation Loss: 0.00648341
Epoch [24/300], Train Loss: 0.006968
Validation Loss: 0.00650327
Epoch [25/300], Train Loss: 0.006939
Validation Loss: 0.00648434
Epoch [26/300], Train Loss: 0.006942
Validation Loss: 0.00645156
Epoch [27/300], Train Loss: 0.006921
Validation Loss: 0.00645648
Epoch [28/300], Train Loss: 0.006854
Validation Loss: 0.00642830
Epoch [29/300], Train Loss: 0.006869
Validation Loss: 0.00642348
Epoch [30/300], Train Loss: 0.006861
Validation Loss: 0.00640334
Epoch [31/300], Train Loss: 0.006835
Validation Loss: 0.00640342
Epoch [32/300], Train Loss: 0.006796
Validation Loss: 0.00634992
Epoch [33/300], Train Loss: 0.006792
Validation Loss: 0.00635774
Epoch [34/300], Train Loss: 0.006785
Validation Loss: 0.00640466
Epoch [35/300], Train Loss: 0.006800
Validation Loss: 0.00631618
Epoch [36/300], Train Loss: 0.006750
Validation Loss: 0.00632641
Epoch [37/300], Train Loss: 0.006802
Validation Loss: 0.00630112
Epoch [38/300], Train Loss: 0.006731
Validation Loss: 0.00627210
Epoch [39/300], Train Loss: 0.006710
Validation Loss: 0.00627424
Epoch [40/300], Train Loss: 0.006713
Validation Loss: 0.00626751
Epoch [41/300], Train Loss: 0.006697
Validation Loss: 0.00623364
Epoch [42/300], Train Loss: 0.006671
Validation Loss: 0.00626055
Epoch [43/300], Train Loss: 0.006661
Validation Loss: 0.00622174
Epoch [44/300], Train Loss: 0.006647
Validation Loss: 0.00619343
Epoch [45/300], Train Loss: 0.006610
Validation Loss: 0.00620679
Epoch [46/300], Train Loss: 0.006588
Validation Loss: 0.00617725
Epoch [47/300], Train Loss: 0.006560
Validation Loss: 0.00618560
Epoch [48/300], Train Loss: 0.006562
Validation Loss: 0.00621123
Epoch [49/300], Train Loss: 0.006537
Validation Loss: 0.00612400
Epoch [50/300], Train Loss: 0.006539
Validation Loss: 0.00613556
Epoch [51/300], Train Loss: 0.006523
Validation Loss: 0.00622763
Epoch [52/300], Train Loss: 0.006536
Validation Loss: 0.00608421
Epoch [53/300], Train Loss: 0.006528
Validation Loss: 0.00611182
Epoch [54/300], Train Loss: 0.006499
Validation Loss: 0.00615732
Epoch [55/300], Train Loss: 0.006520
Validation Loss: 0.00608705
Epoch [56/300], Train Loss: 0.006449
Validation Loss: 0.00604432
Epoch [57/300], Train Loss: 0.006475
Validation Loss: 0.00605153
Epoch [58/300], Train Loss: 0.006489
Validation Loss: 0.00603270
Epoch [59/300], Train Loss: 0.006435
Validation Loss: 0.00607055
Epoch [60/300], Train Loss: 0.006426
Validation Loss: 0.00600719
Epoch [61/300], Train Loss: 0.006408
Validation Loss: 0.00603280
Epoch [62/300], Train Loss: 0.006398
Validation Loss: 0.00601634
Epoch [63/300], Train Loss: 0.006385
Validation Loss: 0.00601161
Epoch [64/300], Train Loss: 0.006367
Validation Loss: 0.00597933
Epoch [65/300], Train Loss: 0.006378
Validation Loss: 0.00596042
Epoch [66/300], Train Loss: 0.006350
Validation Loss: 0.00593828
Epoch [67/300], Train Loss: 0.006382
Validation Loss: 0.00606769
Epoch [68/300], Train Loss: 0.006371
Validation Loss: 0.00594055
Epoch [69/300], Train Loss: 0.006377
Validation Loss: 0.00591713
Epoch [70/300], Train Loss: 0.006343
Validation Loss: 0.00591291
Epoch [71/300], Train Loss: 0.006329
Validation Loss: 0.00600736
Epoch [72/300], Train Loss: 0.006288
Validation Loss: 0.00590183
Epoch [73/300], Train Loss: 0.006303
Validation Loss: 0.00589209
Epoch [74/300], Train Loss: 0.006325
Validation Loss: 0.00587610
Epoch [75/300], Train Loss: 0.006298
Validation Loss: 0.00586888
Epoch [76/300], Train Loss: 0.006269
Validation Loss: 0.00587754
Epoch [77/300], Train Loss: 0.006260
Validation Loss: 0.00587028
Epoch [78/300], Train Loss: 0.006268
Validation Loss: 0.00593439
Epoch [79/300], Train Loss: 0.006253
Validation Loss: 0.00587468
Epoch [80/300], Train Loss: 0.006242
Validation Loss: 0.00581680
Epoch [81/300], Train Loss: 0.006246
Validation Loss: 0.00590921
Epoch [82/300], Train Loss: 0.006254
Validation Loss: 0.00591978
Epoch [83/300], Train Loss: 0.006249
Validation Loss: 0.00578939
Epoch [84/300], Train Loss: 0.006228
Validation Loss: 0.00580410
Epoch [85/300], Train Loss: 0.006225
Validation Loss: 0.00582235
Epoch [86/300], Train Loss: 0.006226
Validation Loss: 0.00587954
Epoch [87/300], Train Loss: 0.006223
Validation Loss: 0.00585640
Epoch [88/300], Train Loss: 0.006206
Validation Loss: 0.00578678
Epoch [89/300], Train Loss: 0.006185
Validation Loss: 0.00580702
Epoch [90/300], Train Loss: 0.006228
Validation Loss: 0.00578435
Epoch [91/300], Train Loss: 0.006195
Validation Loss: 0.00577714
Epoch [92/300], Train Loss: 0.006202
Validation Loss: 0.00576309
Epoch [93/300], Train Loss: 0.006256
Validation Loss: 0.00574366
Epoch [94/300], Train Loss: 0.006204
Validation Loss: 0.00575475
Epoch [95/300], Train Loss: 0.006168
Validation Loss: 0.00575157
Epoch [96/300], Train Loss: 0.006171
Validation Loss: 0.00580091
Epoch [97/300], Train Loss: 0.006150
Validation Loss: 0.00577837
Epoch [98/300], Train Loss: 0.006127
Validation Loss: 0.00573148
Epoch [99/300], Train Loss: 0.006121
Validation Loss: 0.00576278
Epoch [100/300], Train Loss: 0.006145
Validation Loss: 0.00571941
Epoch [101/300], Train Loss: 0.006128
Validation Loss: 0.00579255
Epoch [102/300], Train Loss: 0.006121
Validation Loss: 0.00575367
Epoch [103/300], Train Loss: 0.006115
Validation Loss: 0.00580558
Epoch [104/300], Train Loss: 0.006125
Validation Loss: 0.00572515
Epoch [105/300], Train Loss: 0.006117
Validation Loss: 0.00571298
Epoch [106/300], Train Loss: 0.006104
Validation Loss: 0.00569989
Epoch [107/300], Train Loss: 0.006117
Validation Loss: 0.00570571
Epoch [108/300], Train Loss: 0.006102
Validation Loss: 0.00571273
Epoch [109/300], Train Loss: 0.006084
Validation Loss: 0.00572021
Epoch [110/300], Train Loss: 0.006092
Validation Loss: 0.00574618
Epoch [111/300], Train Loss: 0.006067
Validation Loss: 0.00568713
Epoch [112/300], Train Loss: 0.006089
Validation Loss: 0.00569128
Epoch [113/300], Train Loss: 0.006085
Validation Loss: 0.00567563
Epoch [114/300], Train Loss: 0.006079
Validation Loss: 0.00570003
Epoch [115/300], Train Loss: 0.006058
Validation Loss: 0.00573557
Epoch [116/300], Train Loss: 0.006046
Validation Loss: 0.00569314
Epoch [117/300], Train Loss: 0.006052
Validation Loss: 0.00571176
Epoch [118/300], Train Loss: 0.006067
Validation Loss: 0.00567737
Epoch [119/300], Train Loss: 0.006049
Validation Loss: 0.00567675
Epoch [120/300], Train Loss: 0.006033
Validation Loss: 0.00565433
Epoch [121/300], Train Loss: 0.006038
Validation Loss: 0.00568338
Epoch [122/300], Train Loss: 0.006033
Validation Loss: 0.00572018
Epoch [123/300], Train Loss: 0.006058
Validation Loss: 0.00563600
Epoch [124/300], Train Loss: 0.006042
Validation Loss: 0.00572755
Epoch [125/300], Train Loss: 0.006035
Validation Loss: 0.00577524
Epoch [126/300], Train Loss: 0.006121
Validation Loss: 0.00563178
Epoch [127/300], Train Loss: 0.006035
Validation Loss: 0.00565037
Epoch [128/300], Train Loss: 0.006047
Validation Loss: 0.00566177
Epoch [129/300], Train Loss: 0.006007
Validation Loss: 0.00561969
Epoch [130/300], Train Loss: 0.006047
Validation Loss: 0.00566624
Epoch [131/300], Train Loss: 0.006034
Validation Loss: 0.00564136
Epoch [132/300], Train Loss: 0.006031
Validation Loss: 0.00565131
Epoch [133/300], Train Loss: 0.006000
Validation Loss: 0.00562594
Epoch [134/300], Train Loss: 0.006000
Validation Loss: 0.00561384
Epoch [135/300], Train Loss: 0.005985
Validation Loss: 0.00566169
Epoch [136/300], Train Loss: 0.005993
Validation Loss: 0.00560715
Epoch [137/300], Train Loss: 0.006001
Validation Loss: 0.00567352
Epoch [138/300], Train Loss: 0.005969
Validation Loss: 0.00560063
Epoch [139/300], Train Loss: 0.005997
Validation Loss: 0.00566427
Epoch [140/300], Train Loss: 0.006013
Validation Loss: 0.00558354
Epoch [141/300], Train Loss: 0.005991
Validation Loss: 0.00561260
Epoch [142/300], Train Loss: 0.005980
Validation Loss: 0.00562630
Epoch [143/300], Train Loss: 0.005966
Validation Loss: 0.00557824
Epoch [144/300], Train Loss: 0.005976
Validation Loss: 0.00564260
Epoch [145/300], Train Loss: 0.005964
Validation Loss: 0.00562428
Epoch [146/300], Train Loss: 0.005972
Validation Loss: 0.00558552
Epoch [147/300], Train Loss: 0.005961
Validation Loss: 0.00558220
Epoch [148/300], Train Loss: 0.005955
Validation Loss: 0.00560775
Epoch [149/300], Train Loss: 0.005949
Validation Loss: 0.00560016
Epoch [150/300], Train Loss: 0.005960
Validation Loss: 0.00558064
Epoch [151/300], Train Loss: 0.005948
Validation Loss: 0.00563709
Epoch [152/300], Train Loss: 0.005945
Validation Loss: 0.00556068
Epoch [153/300], Train Loss: 0.005928
Validation Loss: 0.00560733
Epoch [154/300], Train Loss: 0.005944
Validation Loss: 0.00558052
Epoch [155/300], Train Loss: 0.005920
Validation Loss: 0.00557227
Epoch [156/300], Train Loss: 0.005937
Validation Loss: 0.00557670
Epoch [157/300], Train Loss: 0.005943
Validation Loss: 0.00560282
Epoch [158/300], Train Loss: 0.005923
Validation Loss: 0.00555222
Epoch [159/300], Train Loss: 0.005967
Validation Loss: 0.00555602
Epoch [160/300], Train Loss: 0.005929
Validation Loss: 0.00558830
Epoch [161/300], Train Loss: 0.005925
Validation Loss: 0.00558591
Epoch [162/300], Train Loss: 0.005913
Validation Loss: 0.00556576
Epoch [163/300], Train Loss: 0.005912
Validation Loss: 0.00553545
Epoch [164/300], Train Loss: 0.005928
Validation Loss: 0.00566555
Epoch [165/300], Train Loss: 0.005958
Validation Loss: 0.00554823
Epoch [166/300], Train Loss: 0.005956
Validation Loss: 0.00552625
Epoch [167/300], Train Loss: 0.005908
Validation Loss: 0.00558187
Epoch [168/300], Train Loss: 0.005901
Validation Loss: 0.00558200
Epoch [169/300], Train Loss: 0.005909
Validation Loss: 0.00552424
Epoch [170/300], Train Loss: 0.005920
Validation Loss: 0.00554566
Epoch [171/300], Train Loss: 0.005903
Validation Loss: 0.00553015
Epoch [172/300], Train Loss: 0.005905
Validation Loss: 0.00550956
Epoch [173/300], Train Loss: 0.005889
Validation Loss: 0.00560098
Epoch [174/300], Train Loss: 0.005915
Validation Loss: 0.00551459
Epoch [175/300], Train Loss: 0.005891
Validation Loss: 0.00554565
Epoch [176/300], Train Loss: 0.005892
Validation Loss: 0.00551959
Epoch [177/300], Train Loss: 0.005898
Validation Loss: 0.00553560
Epoch [178/300], Train Loss: 0.005888
Validation Loss: 0.00551157
Epoch [179/300], Train Loss: 0.005912
Validation Loss: 0.00557827
Epoch [180/300], Train Loss: 0.005913
Validation Loss: 0.00551875
Epoch [181/300], Train Loss: 0.005864
Validation Loss: 0.00552631
Epoch [182/300], Train Loss: 0.005879
Validation Loss: 0.00552432
Early stopping triggered

Evaluating model for: Router
Run 12/72 completed in 415.08 seconds with: {'MAE': np.float32(0.20166518), 'MSE': np.float32(0.0714975), 'RMSE': np.float32(0.26739016), 'SAE': np.float32(0.00023021655), 'NDE': np.float32(0.013372062)}

Run 13/72: hidden=128, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Router
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.076276
Validation Loss: 0.07115743
Epoch [2/300], Train Loss: 0.068841
Validation Loss: 0.06387653
Epoch [3/300], Train Loss: 0.061608
Validation Loss: 0.05658777
Epoch [4/300], Train Loss: 0.054080
Validation Loss: 0.04874479
Epoch [5/300], Train Loss: 0.045896
Validation Loss: 0.04008986
Epoch [6/300], Train Loss: 0.036925
Validation Loss: 0.03047815
Epoch [7/300], Train Loss: 0.026543
Validation Loss: 0.01920895
Epoch [8/300], Train Loss: 0.015081
Validation Loss: 0.00824838
Epoch [9/300], Train Loss: 0.007130
Validation Loss: 0.00631780
Epoch [10/300], Train Loss: 0.008082
Validation Loss: 0.00610139
Epoch [11/300], Train Loss: 0.006537
Validation Loss: 0.00540019
Epoch [12/300], Train Loss: 0.006514
Validation Loss: 0.00565752
Epoch [13/300], Train Loss: 0.006475
Validation Loss: 0.00533681
Epoch [14/300], Train Loss: 0.006290
Validation Loss: 0.00528693
Epoch [15/300], Train Loss: 0.006296
Validation Loss: 0.00527765
Epoch [16/300], Train Loss: 0.006260
Validation Loss: 0.00525997
Epoch [17/300], Train Loss: 0.006264
Validation Loss: 0.00526905
Epoch [18/300], Train Loss: 0.006229
Validation Loss: 0.00525780
Epoch [19/300], Train Loss: 0.006257
Validation Loss: 0.00524847
Epoch [20/300], Train Loss: 0.006218
Validation Loss: 0.00524567
Epoch [21/300], Train Loss: 0.006240
Validation Loss: 0.00524310
Epoch [22/300], Train Loss: 0.006222
Validation Loss: 0.00524332
Epoch [23/300], Train Loss: 0.006215
Validation Loss: 0.00523725
Epoch [24/300], Train Loss: 0.006230
Validation Loss: 0.00523264
Epoch [25/300], Train Loss: 0.006199
Validation Loss: 0.00523295
Epoch [26/300], Train Loss: 0.006199
Validation Loss: 0.00523062
Epoch [27/300], Train Loss: 0.006196
Validation Loss: 0.00522452
Epoch [28/300], Train Loss: 0.006222
Validation Loss: 0.00522049
Epoch [29/300], Train Loss: 0.006227
Validation Loss: 0.00521734
Epoch [30/300], Train Loss: 0.006191
Validation Loss: 0.00522004
Epoch [31/300], Train Loss: 0.006196
Validation Loss: 0.00521490
Epoch [32/300], Train Loss: 0.006199
Validation Loss: 0.00520927
Epoch [33/300], Train Loss: 0.006187
Validation Loss: 0.00520656
Epoch [34/300], Train Loss: 0.006174
Validation Loss: 0.00520720
Epoch [35/300], Train Loss: 0.006171
Validation Loss: 0.00520121
Epoch [36/300], Train Loss: 0.006184
Validation Loss: 0.00519980
Epoch [37/300], Train Loss: 0.006190
Validation Loss: 0.00519938
Epoch [38/300], Train Loss: 0.006165
Validation Loss: 0.00519427
Epoch [39/300], Train Loss: 0.006157
Validation Loss: 0.00519036
Epoch [40/300], Train Loss: 0.006182
Validation Loss: 0.00518770
Epoch [41/300], Train Loss: 0.006166
Validation Loss: 0.00518903
Epoch [42/300], Train Loss: 0.006157
Validation Loss: 0.00518575
Epoch [43/300], Train Loss: 0.006166
Validation Loss: 0.00518022
Epoch [44/300], Train Loss: 0.006159
Validation Loss: 0.00517772
Epoch [45/300], Train Loss: 0.006137
Validation Loss: 0.00517882
Epoch [46/300], Train Loss: 0.006160
Validation Loss: 0.00517294
Epoch [47/300], Train Loss: 0.006122
Validation Loss: 0.00517043
Epoch [48/300], Train Loss: 0.006154
Validation Loss: 0.00516835
Epoch [49/300], Train Loss: 0.006157
Validation Loss: 0.00516763
Epoch [50/300], Train Loss: 0.006146
Validation Loss: 0.00516497
Epoch [51/300], Train Loss: 0.006130
Validation Loss: 0.00516139
Epoch [52/300], Train Loss: 0.006140
Validation Loss: 0.00515934
Epoch [53/300], Train Loss: 0.006128
Validation Loss: 0.00515729
Epoch [54/300], Train Loss: 0.006126
Validation Loss: 0.00515505
Epoch [55/300], Train Loss: 0.006117
Validation Loss: 0.00515487
Epoch [56/300], Train Loss: 0.006129
Validation Loss: 0.00514961
Epoch [57/300], Train Loss: 0.006103
Validation Loss: 0.00514850
Epoch [58/300], Train Loss: 0.006110
Validation Loss: 0.00514865
Epoch [59/300], Train Loss: 0.006092
Validation Loss: 0.00514266
Epoch [60/300], Train Loss: 0.006094
Validation Loss: 0.00514027
Epoch [61/300], Train Loss: 0.006086
Validation Loss: 0.00513997
Epoch [62/300], Train Loss: 0.006085
Validation Loss: 0.00513859
Epoch [63/300], Train Loss: 0.006094
Validation Loss: 0.00513443
Epoch [64/300], Train Loss: 0.006083
Validation Loss: 0.00513297
Epoch [65/300], Train Loss: 0.006099
Validation Loss: 0.00513065
Epoch [66/300], Train Loss: 0.006098
Validation Loss: 0.00513073
Epoch [67/300], Train Loss: 0.006083
Validation Loss: 0.00512647
Epoch [68/300], Train Loss: 0.006099
Validation Loss: 0.00512388
Epoch [69/300], Train Loss: 0.006074
Validation Loss: 0.00512236
Epoch [70/300], Train Loss: 0.006092
Validation Loss: 0.00512064
Epoch [71/300], Train Loss: 0.006079
Validation Loss: 0.00511996
Epoch [72/300], Train Loss: 0.006052
Validation Loss: 0.00511819
Epoch [73/300], Train Loss: 0.006058
Validation Loss: 0.00511571
Epoch [74/300], Train Loss: 0.006072
Validation Loss: 0.00511183
Epoch [75/300], Train Loss: 0.006044
Validation Loss: 0.00511041
Epoch [76/300], Train Loss: 0.006060
Validation Loss: 0.00510935
Epoch [77/300], Train Loss: 0.006056
Validation Loss: 0.00510611
Epoch [78/300], Train Loss: 0.006050
Validation Loss: 0.00510817
Epoch [79/300], Train Loss: 0.006046
Validation Loss: 0.00510274
Epoch [80/300], Train Loss: 0.006045
Validation Loss: 0.00510094
Epoch [81/300], Train Loss: 0.006064
Validation Loss: 0.00510042
Epoch [82/300], Train Loss: 0.006042
Validation Loss: 0.00510041
Epoch [83/300], Train Loss: 0.006041
Validation Loss: 0.00509661
Epoch [84/300], Train Loss: 0.006058
Validation Loss: 0.00509338
Epoch [85/300], Train Loss: 0.006024
Validation Loss: 0.00509275
Epoch [86/300], Train Loss: 0.006046
Validation Loss: 0.00509011
Epoch [87/300], Train Loss: 0.006039
Validation Loss: 0.00508867
Epoch [88/300], Train Loss: 0.006044
Validation Loss: 0.00508753
Epoch [89/300], Train Loss: 0.006026
Validation Loss: 0.00508470
Epoch [90/300], Train Loss: 0.006049
Validation Loss: 0.00508569
Epoch [91/300], Train Loss: 0.006029
Validation Loss: 0.00508119
Epoch [92/300], Train Loss: 0.006029
Validation Loss: 0.00508001
Epoch [93/300], Train Loss: 0.006046
Validation Loss: 0.00507746
Epoch [94/300], Train Loss: 0.006024
Validation Loss: 0.00507677
Epoch [95/300], Train Loss: 0.006014
Validation Loss: 0.00507804
Epoch [96/300], Train Loss: 0.006014
Validation Loss: 0.00507271
Epoch [97/300], Train Loss: 0.006017
Validation Loss: 0.00507116
Epoch [98/300], Train Loss: 0.006008
Validation Loss: 0.00506930
Epoch [99/300], Train Loss: 0.005997
Validation Loss: 0.00506979
Epoch [100/300], Train Loss: 0.005999
Validation Loss: 0.00506620
Epoch [101/300], Train Loss: 0.006012
Validation Loss: 0.00506642
Epoch [102/300], Train Loss: 0.006008
Validation Loss: 0.00506342
Epoch [103/300], Train Loss: 0.005993
Validation Loss: 0.00506106
Epoch [104/300], Train Loss: 0.005997
Validation Loss: 0.00506025
Epoch [105/300], Train Loss: 0.005983
Validation Loss: 0.00505844
Epoch [106/300], Train Loss: 0.006009
Validation Loss: 0.00505628
Epoch [107/300], Train Loss: 0.005992
Validation Loss: 0.00505672
Epoch [108/300], Train Loss: 0.005965
Validation Loss: 0.00505657
Epoch [109/300], Train Loss: 0.005984
Validation Loss: 0.00505198
Epoch [110/300], Train Loss: 0.005989
Validation Loss: 0.00505031
Epoch [111/300], Train Loss: 0.005969
Validation Loss: 0.00505089
Epoch [112/300], Train Loss: 0.005982
Validation Loss: 0.00504922
Epoch [113/300], Train Loss: 0.005965
Validation Loss: 0.00504648
Epoch [114/300], Train Loss: 0.005970
Validation Loss: 0.00504447
Epoch [115/300], Train Loss: 0.005980
Validation Loss: 0.00504424
Epoch [116/300], Train Loss: 0.005976
Validation Loss: 0.00504271
Epoch [117/300], Train Loss: 0.005957
Validation Loss: 0.00504069
Epoch [118/300], Train Loss: 0.005962
Validation Loss: 0.00503867
Epoch [119/300], Train Loss: 0.005971
Validation Loss: 0.00503721
Epoch [120/300], Train Loss: 0.005975
Validation Loss: 0.00503691
Epoch [121/300], Train Loss: 0.005950
Validation Loss: 0.00503470
Epoch [122/300], Train Loss: 0.005958
Validation Loss: 0.00503361
Epoch [123/300], Train Loss: 0.005971
Validation Loss: 0.00503184
Epoch [124/300], Train Loss: 0.005954
Validation Loss: 0.00503028
Epoch [125/300], Train Loss: 0.005957
Validation Loss: 0.00503173
Epoch [126/300], Train Loss: 0.005943
Validation Loss: 0.00502924
Epoch [127/300], Train Loss: 0.005961
Validation Loss: 0.00502612
Epoch [128/300], Train Loss: 0.005956
Validation Loss: 0.00502487
Epoch [129/300], Train Loss: 0.005953
Validation Loss: 0.00502416
Epoch [130/300], Train Loss: 0.005943
Validation Loss: 0.00502584
Epoch [131/300], Train Loss: 0.005937
Validation Loss: 0.00502104
Epoch [132/300], Train Loss: 0.005941
Validation Loss: 0.00501946
Epoch [133/300], Train Loss: 0.005947
Validation Loss: 0.00501811
Epoch [134/300], Train Loss: 0.005928
Validation Loss: 0.00501797
Epoch [135/300], Train Loss: 0.005942
Validation Loss: 0.00501770
Epoch [136/300], Train Loss: 0.005936
Validation Loss: 0.00501426
Epoch [137/300], Train Loss: 0.005918
Validation Loss: 0.00501362
Epoch [138/300], Train Loss: 0.005943
Validation Loss: 0.00501172
Epoch [139/300], Train Loss: 0.005947
Validation Loss: 0.00501342
Epoch [140/300], Train Loss: 0.005934
Validation Loss: 0.00500959
Epoch [141/300], Train Loss: 0.005921
Validation Loss: 0.00500857
Epoch [142/300], Train Loss: 0.005927
Validation Loss: 0.00500701
Epoch [143/300], Train Loss: 0.005927
Validation Loss: 0.00500778
Epoch [144/300], Train Loss: 0.005922
Validation Loss: 0.00500596
Epoch [145/300], Train Loss: 0.005931
Validation Loss: 0.00500338
Epoch [146/300], Train Loss: 0.005918
Validation Loss: 0.00500204
Epoch [147/300], Train Loss: 0.005930
Validation Loss: 0.00500167
Epoch [148/300], Train Loss: 0.005915
Validation Loss: 0.00500233
Epoch [149/300], Train Loss: 0.005906
Validation Loss: 0.00500024
Epoch [150/300], Train Loss: 0.005907
Validation Loss: 0.00499829
Epoch [151/300], Train Loss: 0.005922
Validation Loss: 0.00499612
Epoch [152/300], Train Loss: 0.005899
Validation Loss: 0.00499525
Epoch [153/300], Train Loss: 0.005906
Validation Loss: 0.00499512
Epoch [154/300], Train Loss: 0.005908
Validation Loss: 0.00499378
Epoch [155/300], Train Loss: 0.005914
Validation Loss: 0.00499363
Epoch [156/300], Train Loss: 0.005921
Validation Loss: 0.00499086
Epoch [157/300], Train Loss: 0.005902
Validation Loss: 0.00499058
Epoch [158/300], Train Loss: 0.005902
Validation Loss: 0.00498939
Epoch [159/300], Train Loss: 0.005907
Validation Loss: 0.00498926
Epoch [160/300], Train Loss: 0.005910
Validation Loss: 0.00498647
Epoch [161/300], Train Loss: 0.005922
Validation Loss: 0.00498654
Epoch [162/300], Train Loss: 0.005887
Validation Loss: 0.00498542
Epoch [163/300], Train Loss: 0.005886
Validation Loss: 0.00498351
Epoch [164/300], Train Loss: 0.005902
Validation Loss: 0.00498248
Epoch [165/300], Train Loss: 0.005885
Validation Loss: 0.00498467
Epoch [166/300], Train Loss: 0.005894
Validation Loss: 0.00498207
Epoch [167/300], Train Loss: 0.005882
Validation Loss: 0.00497944
Epoch [168/300], Train Loss: 0.005878
Validation Loss: 0.00497827
Epoch [169/300], Train Loss: 0.005908
Validation Loss: 0.00497761
Epoch [170/300], Train Loss: 0.005881
Validation Loss: 0.00497809
Epoch [171/300], Train Loss: 0.005886
Validation Loss: 0.00497547
Epoch [172/300], Train Loss: 0.005887
Validation Loss: 0.00497474
Epoch [173/300], Train Loss: 0.005888
Validation Loss: 0.00497412
Epoch [174/300], Train Loss: 0.005894
Validation Loss: 0.00497368
Epoch [175/300], Train Loss: 0.005884
Validation Loss: 0.00497269
Epoch [176/300], Train Loss: 0.005882
Validation Loss: 0.00497099
Epoch [177/300], Train Loss: 0.005871
Validation Loss: 0.00497137
Epoch [178/300], Train Loss: 0.005860
Validation Loss: 0.00496997
Epoch [179/300], Train Loss: 0.005863
Validation Loss: 0.00496831
Epoch [180/300], Train Loss: 0.005874
Validation Loss: 0.00496753
Epoch [181/300], Train Loss: 0.005877
Validation Loss: 0.00496654
Epoch [182/300], Train Loss: 0.005888
Validation Loss: 0.00496534
Epoch [183/300], Train Loss: 0.005862
Validation Loss: 0.00496582
Epoch [184/300], Train Loss: 0.005861
Validation Loss: 0.00496504
Epoch [185/300], Train Loss: 0.005879
Validation Loss: 0.00496318
Epoch [186/300], Train Loss: 0.005881
Validation Loss: 0.00496296
Epoch [187/300], Train Loss: 0.005870
Validation Loss: 0.00496109
Epoch [188/300], Train Loss: 0.005864
Validation Loss: 0.00496039
Epoch [189/300], Train Loss: 0.005861
Validation Loss: 0.00496006
Epoch [190/300], Train Loss: 0.005880
Validation Loss: 0.00495843
Epoch [191/300], Train Loss: 0.005870
Validation Loss: 0.00495816
Epoch [192/300], Train Loss: 0.005845
Validation Loss: 0.00495881
Epoch [193/300], Train Loss: 0.005844
Validation Loss: 0.00495753
Epoch [194/300], Train Loss: 0.005873
Validation Loss: 0.00495543
Epoch [195/300], Train Loss: 0.005857
Validation Loss: 0.00495419
Epoch [196/300], Train Loss: 0.005842
Validation Loss: 0.00495378
Epoch [197/300], Train Loss: 0.005854
Validation Loss: 0.00495291
Epoch [198/300], Train Loss: 0.005848
Validation Loss: 0.00495344
Epoch [199/300], Train Loss: 0.005852
Validation Loss: 0.00495242
Epoch [200/300], Train Loss: 0.005854
Validation Loss: 0.00495220
Epoch [201/300], Train Loss: 0.005844
Validation Loss: 0.00494971
Epoch [202/300], Train Loss: 0.005838
Validation Loss: 0.00494893
Epoch [203/300], Train Loss: 0.005844
Validation Loss: 0.00494831
Epoch [204/300], Train Loss: 0.005866
Validation Loss: 0.00494804
Epoch [205/300], Train Loss: 0.005855
Validation Loss: 0.00494743
Epoch [206/300], Train Loss: 0.005856
Validation Loss: 0.00494610
Epoch [207/300], Train Loss: 0.005851
Validation Loss: 0.00494513
Epoch [208/300], Train Loss: 0.005837
Validation Loss: 0.00494544
Epoch [209/300], Train Loss: 0.005852
Validation Loss: 0.00494478
Epoch [210/300], Train Loss: 0.005836
Validation Loss: 0.00494378
Epoch [211/300], Train Loss: 0.005828
Validation Loss: 0.00494306
Epoch [212/300], Train Loss: 0.005830
Validation Loss: 0.00494191
Epoch [213/300], Train Loss: 0.005848
Validation Loss: 0.00494117
Epoch [214/300], Train Loss: 0.005832
Validation Loss: 0.00494116
Epoch [215/300], Train Loss: 0.005825
Validation Loss: 0.00494100
Epoch [216/300], Train Loss: 0.005834
Validation Loss: 0.00493899
Epoch [217/300], Train Loss: 0.005815
Validation Loss: 0.00493813
Epoch [218/300], Train Loss: 0.005859
Validation Loss: 0.00493774
Epoch [219/300], Train Loss: 0.005835
Validation Loss: 0.00493737
Epoch [220/300], Train Loss: 0.005841
Validation Loss: 0.00493729
Epoch [221/300], Train Loss: 0.005830
Validation Loss: 0.00493564
Epoch [222/300], Train Loss: 0.005835
Validation Loss: 0.00493474
Epoch [223/300], Train Loss: 0.005830
Validation Loss: 0.00493464
Epoch [224/300], Train Loss: 0.005843
Validation Loss: 0.00493351
Epoch [225/300], Train Loss: 0.005827
Validation Loss: 0.00493246
Epoch [226/300], Train Loss: 0.005843
Validation Loss: 0.00493169
Epoch [227/300], Train Loss: 0.005823
Validation Loss: 0.00493238
Epoch [228/300], Train Loss: 0.005814
Validation Loss: 0.00493257
Epoch [229/300], Train Loss: 0.005815
Validation Loss: 0.00493084
Epoch [230/300], Train Loss: 0.005827
Validation Loss: 0.00492917
Epoch [231/300], Train Loss: 0.005820
Validation Loss: 0.00492857
Epoch [232/300], Train Loss: 0.005828
Validation Loss: 0.00492876
Epoch [233/300], Train Loss: 0.005833
Validation Loss: 0.00492730
Epoch [234/300], Train Loss: 0.005838
Validation Loss: 0.00492697
Epoch [235/300], Train Loss: 0.005820
Validation Loss: 0.00492621
Epoch [236/300], Train Loss: 0.005832
Validation Loss: 0.00492700
Epoch [237/300], Train Loss: 0.005829
Validation Loss: 0.00492554
Epoch [238/300], Train Loss: 0.005809
Validation Loss: 0.00492446
Epoch [239/300], Train Loss: 0.005818
Validation Loss: 0.00492391
Epoch [240/300], Train Loss: 0.005815
Validation Loss: 0.00492311
Epoch [241/300], Train Loss: 0.005819
Validation Loss: 0.00492272
Epoch [242/300], Train Loss: 0.005817
Validation Loss: 0.00492234
Epoch [243/300], Train Loss: 0.005827
Validation Loss: 0.00492259
Epoch [244/300], Train Loss: 0.005813
Validation Loss: 0.00492290
Epoch [245/300], Train Loss: 0.005818
Validation Loss: 0.00492038
Epoch [246/300], Train Loss: 0.005822
Validation Loss: 0.00491979
Epoch [247/300], Train Loss: 0.005828
Validation Loss: 0.00491953
Epoch [248/300], Train Loss: 0.005804
Validation Loss: 0.00491963
Epoch [249/300], Train Loss: 0.005817
Validation Loss: 0.00492014
Epoch [250/300], Train Loss: 0.005819
Validation Loss: 0.00491776
Epoch [251/300], Train Loss: 0.005804
Validation Loss: 0.00491755
Epoch [252/300], Train Loss: 0.005807
Validation Loss: 0.00491676
Epoch [253/300], Train Loss: 0.005819
Validation Loss: 0.00491612
Epoch [254/300], Train Loss: 0.005798
Validation Loss: 0.00491599
Epoch [255/300], Train Loss: 0.005796
Validation Loss: 0.00491681
Epoch [256/300], Train Loss: 0.005800
Validation Loss: 0.00491548
Epoch [257/300], Train Loss: 0.005806
Validation Loss: 0.00491405
Epoch [258/300], Train Loss: 0.005800
Validation Loss: 0.00491346
Epoch [259/300], Train Loss: 0.005811
Validation Loss: 0.00491311
Epoch [260/300], Train Loss: 0.005816
Validation Loss: 0.00491384
Epoch [261/300], Train Loss: 0.005795
Validation Loss: 0.00491276
Epoch [262/300], Train Loss: 0.005799
Validation Loss: 0.00491167
Epoch [263/300], Train Loss: 0.005789
Validation Loss: 0.00491111
Epoch [264/300], Train Loss: 0.005813
Validation Loss: 0.00491109
Epoch [265/300], Train Loss: 0.005798
Validation Loss: 0.00491041
Epoch [266/300], Train Loss: 0.005815
Validation Loss: 0.00491081
Epoch [267/300], Train Loss: 0.005801
Validation Loss: 0.00490941
Epoch [268/300], Train Loss: 0.005818
Validation Loss: 0.00490864
Epoch [269/300], Train Loss: 0.005806
Validation Loss: 0.00490930
Epoch [270/300], Train Loss: 0.005798
Validation Loss: 0.00490901
Epoch [271/300], Train Loss: 0.005811
Validation Loss: 0.00490733
Epoch [272/300], Train Loss: 0.005793
Validation Loss: 0.00490792
Epoch [273/300], Train Loss: 0.005806
Validation Loss: 0.00490661
Epoch [274/300], Train Loss: 0.005792
Validation Loss: 0.00490657
Epoch [275/300], Train Loss: 0.005801
Validation Loss: 0.00490631
Epoch [276/300], Train Loss: 0.005782
Validation Loss: 0.00490596
Epoch [277/300], Train Loss: 0.005795
Validation Loss: 0.00490465
Epoch [278/300], Train Loss: 0.005800
Validation Loss: 0.00490457
Epoch [279/300], Train Loss: 0.005797
Validation Loss: 0.00490444
Epoch [280/300], Train Loss: 0.005813
Validation Loss: 0.00490370
Epoch [281/300], Train Loss: 0.005786
Validation Loss: 0.00490381
Epoch [282/300], Train Loss: 0.005800
Validation Loss: 0.00490277
Epoch [283/300], Train Loss: 0.005792
Validation Loss: 0.00490270
Epoch [284/300], Train Loss: 0.005780
Validation Loss: 0.00490220
Epoch [285/300], Train Loss: 0.005780
Validation Loss: 0.00490225
Epoch [286/300], Train Loss: 0.005798
Validation Loss: 0.00490084
Epoch [287/300], Train Loss: 0.005797
Validation Loss: 0.00490055
Epoch [288/300], Train Loss: 0.005778
Validation Loss: 0.00490058
Epoch [289/300], Train Loss: 0.005776
Validation Loss: 0.00490015
Epoch [290/300], Train Loss: 0.005771
Validation Loss: 0.00489958
Epoch [291/300], Train Loss: 0.005782
Validation Loss: 0.00489905
Epoch [292/300], Train Loss: 0.005779
Validation Loss: 0.00489905
Epoch [293/300], Train Loss: 0.005783
Validation Loss: 0.00489860
Epoch [294/300], Train Loss: 0.005783
Validation Loss: 0.00489792
Epoch [295/300], Train Loss: 0.005771
Validation Loss: 0.00489770
Epoch [296/300], Train Loss: 0.005794
Validation Loss: 0.00489769
Epoch [297/300], Train Loss: 0.005786
Validation Loss: 0.00489714
Epoch [298/300], Train Loss: 0.005802
Validation Loss: 0.00489630
Epoch [299/300], Train Loss: 0.005789
Validation Loss: 0.00489636
Epoch [300/300], Train Loss: 0.005787
Validation Loss: 0.00489559

Evaluating model for: Router
Run 13/72 completed in 294.36 seconds with: {'MAE': np.float32(0.212037), 'MSE': np.float32(0.077034175), 'RMSE': np.float32(0.2775503), 'SAE': np.float32(0.00070153986), 'NDE': np.float32(0.013882329)}

Run 14/72: hidden=128, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Router
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.079745
Validation Loss: 0.07427265
Epoch [2/300], Train Loss: 0.071775
Validation Loss: 0.06643029
Epoch [3/300], Train Loss: 0.063748
Validation Loss: 0.05810660
Epoch [4/300], Train Loss: 0.055054
Validation Loss: 0.04871517
Epoch [5/300], Train Loss: 0.044830
Validation Loss: 0.03718311
Epoch [6/300], Train Loss: 0.032084
Validation Loss: 0.02260680
Epoch [7/300], Train Loss: 0.016556
Validation Loss: 0.00739942
Epoch [8/300], Train Loss: 0.007663
Validation Loss: 0.00882041
Epoch [9/300], Train Loss: 0.008309
Validation Loss: 0.00544110
Epoch [10/300], Train Loss: 0.006578
Validation Loss: 0.00604060
Epoch [11/300], Train Loss: 0.006885
Validation Loss: 0.00559671
Epoch [12/300], Train Loss: 0.006418
Validation Loss: 0.00540686
Epoch [13/300], Train Loss: 0.006449
Validation Loss: 0.00541878
Epoch [14/300], Train Loss: 0.006383
Validation Loss: 0.00536929
Epoch [15/300], Train Loss: 0.006376
Validation Loss: 0.00539018
Epoch [16/300], Train Loss: 0.006346
Validation Loss: 0.00535294
Epoch [17/300], Train Loss: 0.006352
Validation Loss: 0.00534826
Epoch [18/300], Train Loss: 0.006326
Validation Loss: 0.00534174
Epoch [19/300], Train Loss: 0.006336
Validation Loss: 0.00533769
Epoch [20/300], Train Loss: 0.006300
Validation Loss: 0.00533514
Epoch [21/300], Train Loss: 0.006308
Validation Loss: 0.00532634
Epoch [22/300], Train Loss: 0.006290
Validation Loss: 0.00532286
Epoch [23/300], Train Loss: 0.006296
Validation Loss: 0.00531687
Epoch [24/300], Train Loss: 0.006295
Validation Loss: 0.00531168
Epoch [25/300], Train Loss: 0.006277
Validation Loss: 0.00531243
Epoch [26/300], Train Loss: 0.006276
Validation Loss: 0.00530448
Epoch [27/300], Train Loss: 0.006264
Validation Loss: 0.00529788
Epoch [28/300], Train Loss: 0.006284
Validation Loss: 0.00529341
Epoch [29/300], Train Loss: 0.006278
Validation Loss: 0.00528913
Epoch [30/300], Train Loss: 0.006254
Validation Loss: 0.00529139
Epoch [31/300], Train Loss: 0.006256
Validation Loss: 0.00528128
Epoch [32/300], Train Loss: 0.006265
Validation Loss: 0.00527733
Epoch [33/300], Train Loss: 0.006247
Validation Loss: 0.00527423
Epoch [34/300], Train Loss: 0.006237
Validation Loss: 0.00527529
Epoch [35/300], Train Loss: 0.006223
Validation Loss: 0.00526656
Epoch [36/300], Train Loss: 0.006244
Validation Loss: 0.00526338
Epoch [37/300], Train Loss: 0.006248
Validation Loss: 0.00526296
Epoch [38/300], Train Loss: 0.006223
Validation Loss: 0.00525579
Epoch [39/300], Train Loss: 0.006212
Validation Loss: 0.00525287
Epoch [40/300], Train Loss: 0.006241
Validation Loss: 0.00524888
Epoch [41/300], Train Loss: 0.006231
Validation Loss: 0.00525019
Epoch [42/300], Train Loss: 0.006204
Validation Loss: 0.00524267
Epoch [43/300], Train Loss: 0.006225
Validation Loss: 0.00523898
Epoch [44/300], Train Loss: 0.006200
Validation Loss: 0.00523646
Epoch [45/300], Train Loss: 0.006182
Validation Loss: 0.00523676
Epoch [46/300], Train Loss: 0.006195
Validation Loss: 0.00522966
Epoch [47/300], Train Loss: 0.006178
Validation Loss: 0.00522683
Epoch [48/300], Train Loss: 0.006194
Validation Loss: 0.00522475
Epoch [49/300], Train Loss: 0.006202
Validation Loss: 0.00522283
Epoch [50/300], Train Loss: 0.006198
Validation Loss: 0.00521867
Epoch [51/300], Train Loss: 0.006183
Validation Loss: 0.00521573
Epoch [52/300], Train Loss: 0.006184
Validation Loss: 0.00521377
Epoch [53/300], Train Loss: 0.006172
Validation Loss: 0.00521075
Epoch [54/300], Train Loss: 0.006175
Validation Loss: 0.00520775
Epoch [55/300], Train Loss: 0.006162
Validation Loss: 0.00520714
Epoch [56/300], Train Loss: 0.006180
Validation Loss: 0.00520215
Epoch [57/300], Train Loss: 0.006152
Validation Loss: 0.00520077
Epoch [58/300], Train Loss: 0.006157
Validation Loss: 0.00519981
Epoch [59/300], Train Loss: 0.006147
Validation Loss: 0.00519484
Epoch [60/300], Train Loss: 0.006144
Validation Loss: 0.00519167
Epoch [61/300], Train Loss: 0.006127
Validation Loss: 0.00519217
Epoch [62/300], Train Loss: 0.006128
Validation Loss: 0.00518761
Epoch [63/300], Train Loss: 0.006146
Validation Loss: 0.00518449
Epoch [64/300], Train Loss: 0.006132
Validation Loss: 0.00518324
Epoch [65/300], Train Loss: 0.006140
Validation Loss: 0.00518012
Epoch [66/300], Train Loss: 0.006141
Validation Loss: 0.00517861
Epoch [67/300], Train Loss: 0.006119
Validation Loss: 0.00517507
Epoch [68/300], Train Loss: 0.006144
Validation Loss: 0.00517289
Epoch [69/300], Train Loss: 0.006127
Validation Loss: 0.00517122
Epoch [70/300], Train Loss: 0.006138
Validation Loss: 0.00516837
Epoch [71/300], Train Loss: 0.006127
Validation Loss: 0.00516667
Epoch [72/300], Train Loss: 0.006097
Validation Loss: 0.00516489
Epoch [73/300], Train Loss: 0.006106
Validation Loss: 0.00516238
Epoch [74/300], Train Loss: 0.006115
Validation Loss: 0.00515948
Epoch [75/300], Train Loss: 0.006092
Validation Loss: 0.00515734
Epoch [76/300], Train Loss: 0.006094
Validation Loss: 0.00515532
Epoch [77/300], Train Loss: 0.006108
Validation Loss: 0.00515286
Epoch [78/300], Train Loss: 0.006092
Validation Loss: 0.00515482
Epoch [79/300], Train Loss: 0.006093
Validation Loss: 0.00514837
Epoch [80/300], Train Loss: 0.006088
Validation Loss: 0.00514638
Epoch [81/300], Train Loss: 0.006110
Validation Loss: 0.00514591
Epoch [82/300], Train Loss: 0.006092
Validation Loss: 0.00514458
Epoch [83/300], Train Loss: 0.006086
Validation Loss: 0.00514044
Epoch [84/300], Train Loss: 0.006101
Validation Loss: 0.00513844
Epoch [85/300], Train Loss: 0.006082
Validation Loss: 0.00513866
Epoch [86/300], Train Loss: 0.006098
Validation Loss: 0.00513412
Epoch [87/300], Train Loss: 0.006088
Validation Loss: 0.00513227
Epoch [88/300], Train Loss: 0.006075
Validation Loss: 0.00513117
Epoch [89/300], Train Loss: 0.006069
Validation Loss: 0.00512825
Epoch [90/300], Train Loss: 0.006095
Validation Loss: 0.00512950
Epoch [91/300], Train Loss: 0.006074
Validation Loss: 0.00512418
Epoch [92/300], Train Loss: 0.006066
Validation Loss: 0.00512266
Epoch [93/300], Train Loss: 0.006080
Validation Loss: 0.00512055
Epoch [94/300], Train Loss: 0.006073
Validation Loss: 0.00511993
Epoch [95/300], Train Loss: 0.006059
Validation Loss: 0.00511974
Epoch [96/300], Train Loss: 0.006064
Validation Loss: 0.00511531
Epoch [97/300], Train Loss: 0.006065
Validation Loss: 0.00511351
Epoch [98/300], Train Loss: 0.006044
Validation Loss: 0.00511153
Epoch [99/300], Train Loss: 0.006035
Validation Loss: 0.00511132
Epoch [100/300], Train Loss: 0.006040
Validation Loss: 0.00510782
Epoch [101/300], Train Loss: 0.006057
Validation Loss: 0.00510805
Epoch [102/300], Train Loss: 0.006055
Validation Loss: 0.00510439
Epoch [103/300], Train Loss: 0.006037
Validation Loss: 0.00510235
Epoch [104/300], Train Loss: 0.006043
Validation Loss: 0.00510125
Epoch [105/300], Train Loss: 0.006028
Validation Loss: 0.00509897
Epoch [106/300], Train Loss: 0.006054
Validation Loss: 0.00509701
Epoch [107/300], Train Loss: 0.006027
Validation Loss: 0.00509743
Epoch [108/300], Train Loss: 0.006015
Validation Loss: 0.00509647
Epoch [109/300], Train Loss: 0.006030
Validation Loss: 0.00509213
Epoch [110/300], Train Loss: 0.006030
Validation Loss: 0.00509049
Epoch [111/300], Train Loss: 0.006014
Validation Loss: 0.00509232
Epoch [112/300], Train Loss: 0.006031
Validation Loss: 0.00508780
Epoch [113/300], Train Loss: 0.006015
Validation Loss: 0.00508538
Epoch [114/300], Train Loss: 0.006028
Validation Loss: 0.00508406
Epoch [115/300], Train Loss: 0.006022
Validation Loss: 0.00508462
Epoch [116/300], Train Loss: 0.006019
Validation Loss: 0.00508090
Epoch [117/300], Train Loss: 0.005998
Validation Loss: 0.00507876
Epoch [118/300], Train Loss: 0.006006
Validation Loss: 0.00507709
Epoch [119/300], Train Loss: 0.006003
Validation Loss: 0.00507579
Epoch [120/300], Train Loss: 0.006011
Validation Loss: 0.00507504
Epoch [121/300], Train Loss: 0.006004
Validation Loss: 0.00507226
Epoch [122/300], Train Loss: 0.006006
Validation Loss: 0.00507124
Epoch [123/300], Train Loss: 0.006011
Validation Loss: 0.00506954
Epoch [124/300], Train Loss: 0.005999
Validation Loss: 0.00506777
Epoch [125/300], Train Loss: 0.005989
Validation Loss: 0.00506901
Epoch [126/300], Train Loss: 0.005992
Validation Loss: 0.00506551
Epoch [127/300], Train Loss: 0.006002
Validation Loss: 0.00506338
Epoch [128/300], Train Loss: 0.005989
Validation Loss: 0.00506182
Epoch [129/300], Train Loss: 0.005985
Validation Loss: 0.00506094
Epoch [130/300], Train Loss: 0.005989
Validation Loss: 0.00506146
Epoch [131/300], Train Loss: 0.005975
Validation Loss: 0.00505722
Epoch [132/300], Train Loss: 0.005991
Validation Loss: 0.00505566
Epoch [133/300], Train Loss: 0.005999
Validation Loss: 0.00505435
Epoch [134/300], Train Loss: 0.005961
Validation Loss: 0.00505405
Epoch [135/300], Train Loss: 0.005976
Validation Loss: 0.00505231
Epoch [136/300], Train Loss: 0.005976
Validation Loss: 0.00504982
Epoch [137/300], Train Loss: 0.005958
Validation Loss: 0.00504908
Epoch [138/300], Train Loss: 0.005985
Validation Loss: 0.00504702
Epoch [139/300], Train Loss: 0.005981
Validation Loss: 0.00504890
Epoch [140/300], Train Loss: 0.005965
Validation Loss: 0.00504433
Epoch [141/300], Train Loss: 0.005969
Validation Loss: 0.00504321
Epoch [142/300], Train Loss: 0.005967
Validation Loss: 0.00504179
Epoch [143/300], Train Loss: 0.005973
Validation Loss: 0.00504281
Epoch [144/300], Train Loss: 0.005961
Validation Loss: 0.00503943
Epoch [145/300], Train Loss: 0.005965
Validation Loss: 0.00503772
Epoch [146/300], Train Loss: 0.005968
Validation Loss: 0.00503623
Epoch [147/300], Train Loss: 0.005962
Validation Loss: 0.00503670
Epoch [148/300], Train Loss: 0.005958
Validation Loss: 0.00503580
Epoch [149/300], Train Loss: 0.005946
Validation Loss: 0.00503248
Epoch [150/300], Train Loss: 0.005943
Validation Loss: 0.00503122
Epoch [151/300], Train Loss: 0.005956
Validation Loss: 0.00502964
Epoch [152/300], Train Loss: 0.005947
Validation Loss: 0.00502874
Epoch [153/300], Train Loss: 0.005957
Validation Loss: 0.00502829
Epoch [154/300], Train Loss: 0.005940
Validation Loss: 0.00502617
Epoch [155/300], Train Loss: 0.005955
Validation Loss: 0.00502573
Epoch [156/300], Train Loss: 0.005952
Validation Loss: 0.00502356
Epoch [157/300], Train Loss: 0.005940
Validation Loss: 0.00502328
Epoch [158/300], Train Loss: 0.005940
Validation Loss: 0.00502180
Epoch [159/300], Train Loss: 0.005943
Validation Loss: 0.00502098
Epoch [160/300], Train Loss: 0.005959
Validation Loss: 0.00501900
Epoch [161/300], Train Loss: 0.005958
Validation Loss: 0.00501907
Epoch [162/300], Train Loss: 0.005934
Validation Loss: 0.00501743
Epoch [163/300], Train Loss: 0.005929
Validation Loss: 0.00501505
Epoch [164/300], Train Loss: 0.005946
Validation Loss: 0.00501389
Epoch [165/300], Train Loss: 0.005932
Validation Loss: 0.00501717
Epoch [166/300], Train Loss: 0.005937
Validation Loss: 0.00501264
Epoch [167/300], Train Loss: 0.005923
Validation Loss: 0.00501053
Epoch [168/300], Train Loss: 0.005915
Validation Loss: 0.00500945
Epoch [169/300], Train Loss: 0.005945
Validation Loss: 0.00500873
Epoch [170/300], Train Loss: 0.005924
Validation Loss: 0.00500885
Epoch [171/300], Train Loss: 0.005924
Validation Loss: 0.00500636
Epoch [172/300], Train Loss: 0.005926
Validation Loss: 0.00500520
Epoch [173/300], Train Loss: 0.005927
Validation Loss: 0.00500471
Epoch [174/300], Train Loss: 0.005928
Validation Loss: 0.00500399
Epoch [175/300], Train Loss: 0.005921
Validation Loss: 0.00500242
Epoch [176/300], Train Loss: 0.005927
Validation Loss: 0.00500084
Epoch [177/300], Train Loss: 0.005917
Validation Loss: 0.00500156
Epoch [178/300], Train Loss: 0.005906
Validation Loss: 0.00499943
Epoch [179/300], Train Loss: 0.005904
Validation Loss: 0.00499768
Epoch [180/300], Train Loss: 0.005910
Validation Loss: 0.00499696
Epoch [181/300], Train Loss: 0.005912
Validation Loss: 0.00499599
Epoch [182/300], Train Loss: 0.005925
Validation Loss: 0.00499465
Epoch [183/300], Train Loss: 0.005895
Validation Loss: 0.00499515
Epoch [184/300], Train Loss: 0.005888
Validation Loss: 0.00499371
Epoch [185/300], Train Loss: 0.005912
Validation Loss: 0.00499181
Epoch [186/300], Train Loss: 0.005907
Validation Loss: 0.00499170
Epoch [187/300], Train Loss: 0.005916
Validation Loss: 0.00498980
Epoch [188/300], Train Loss: 0.005908
Validation Loss: 0.00498894
Epoch [189/300], Train Loss: 0.005900
Validation Loss: 0.00498854
Epoch [190/300], Train Loss: 0.005926
Validation Loss: 0.00498690
Epoch [191/300], Train Loss: 0.005906
Validation Loss: 0.00498658
Epoch [192/300], Train Loss: 0.005890
Validation Loss: 0.00498727
Epoch [193/300], Train Loss: 0.005892
Validation Loss: 0.00498488
Epoch [194/300], Train Loss: 0.005912
Validation Loss: 0.00498300
Epoch [195/300], Train Loss: 0.005899
Validation Loss: 0.00498200
Epoch [196/300], Train Loss: 0.005888
Validation Loss: 0.00498176
Epoch [197/300], Train Loss: 0.005890
Validation Loss: 0.00498043
Epoch [198/300], Train Loss: 0.005892
Validation Loss: 0.00498083
Epoch [199/300], Train Loss: 0.005884
Validation Loss: 0.00497913
Epoch [200/300], Train Loss: 0.005897
Validation Loss: 0.00497876
Epoch [201/300], Train Loss: 0.005877
Validation Loss: 0.00497676
Epoch [202/300], Train Loss: 0.005881
Validation Loss: 0.00497590
Epoch [203/300], Train Loss: 0.005884
Validation Loss: 0.00497532
Epoch [204/300], Train Loss: 0.005906
Validation Loss: 0.00497479
Epoch [205/300], Train Loss: 0.005887
Validation Loss: 0.00497374
Epoch [206/300], Train Loss: 0.005894
Validation Loss: 0.00497258
Epoch [207/300], Train Loss: 0.005882
Validation Loss: 0.00497169
Epoch [208/300], Train Loss: 0.005879
Validation Loss: 0.00497235
Epoch [209/300], Train Loss: 0.005896
Validation Loss: 0.00497096
Epoch [210/300], Train Loss: 0.005871
Validation Loss: 0.00496964
Epoch [211/300], Train Loss: 0.005869
Validation Loss: 0.00496896
Epoch [212/300], Train Loss: 0.005857
Validation Loss: 0.00496798
Epoch [213/300], Train Loss: 0.005888
Validation Loss: 0.00496727
Epoch [214/300], Train Loss: 0.005874
Validation Loss: 0.00496710
Epoch [215/300], Train Loss: 0.005872
Validation Loss: 0.00496662
Epoch [216/300], Train Loss: 0.005875
Validation Loss: 0.00496465
Epoch [217/300], Train Loss: 0.005855
Validation Loss: 0.00496393
Epoch [218/300], Train Loss: 0.005908
Validation Loss: 0.00496379
Epoch [219/300], Train Loss: 0.005871
Validation Loss: 0.00496325
Epoch [220/300], Train Loss: 0.005874
Validation Loss: 0.00496279
Epoch [221/300], Train Loss: 0.005869
Validation Loss: 0.00496102
Epoch [222/300], Train Loss: 0.005872
Validation Loss: 0.00496024
Epoch [223/300], Train Loss: 0.005867
Validation Loss: 0.00496025
Epoch [224/300], Train Loss: 0.005873
Validation Loss: 0.00495892
Epoch [225/300], Train Loss: 0.005862
Validation Loss: 0.00495794
Epoch [226/300], Train Loss: 0.005882
Validation Loss: 0.00495722
Epoch [227/300], Train Loss: 0.005868
Validation Loss: 0.00495818
Epoch [228/300], Train Loss: 0.005860
Validation Loss: 0.00495785
Epoch [229/300], Train Loss: 0.005856
Validation Loss: 0.00495569
Epoch [230/300], Train Loss: 0.005860
Validation Loss: 0.00495456
Epoch [231/300], Train Loss: 0.005859
Validation Loss: 0.00495401
Epoch [232/300], Train Loss: 0.005868
Validation Loss: 0.00495447
Epoch [233/300], Train Loss: 0.005875
Validation Loss: 0.00495255
Epoch [234/300], Train Loss: 0.005869
Validation Loss: 0.00495203
Epoch [235/300], Train Loss: 0.005863
Validation Loss: 0.00495135
Epoch [236/300], Train Loss: 0.005863
Validation Loss: 0.00495256
Epoch [237/300], Train Loss: 0.005864
Validation Loss: 0.00495045
Epoch [238/300], Train Loss: 0.005844
Validation Loss: 0.00494927
Epoch [239/300], Train Loss: 0.005850
Validation Loss: 0.00494878
Epoch [240/300], Train Loss: 0.005850
Validation Loss: 0.00494806
Epoch [241/300], Train Loss: 0.005858
Validation Loss: 0.00494753
Epoch [242/300], Train Loss: 0.005857
Validation Loss: 0.00494699
Epoch [243/300], Train Loss: 0.005855
Validation Loss: 0.00494713
Epoch [244/300], Train Loss: 0.005852
Validation Loss: 0.00494711
Epoch [245/300], Train Loss: 0.005859
Validation Loss: 0.00494495
Epoch [246/300], Train Loss: 0.005851
Validation Loss: 0.00494437
Epoch [247/300], Train Loss: 0.005867
Validation Loss: 0.00494418
Epoch [248/300], Train Loss: 0.005833
Validation Loss: 0.00494448
Epoch [249/300], Train Loss: 0.005857
Validation Loss: 0.00494461
Epoch [250/300], Train Loss: 0.005855
Validation Loss: 0.00494188
Epoch [251/300], Train Loss: 0.005836
Validation Loss: 0.00494158
Epoch [252/300], Train Loss: 0.005837
Validation Loss: 0.00494089
Epoch [253/300], Train Loss: 0.005857
Validation Loss: 0.00494021
Epoch [254/300], Train Loss: 0.005838
Validation Loss: 0.00494009
Epoch [255/300], Train Loss: 0.005842
Validation Loss: 0.00494108
Epoch [256/300], Train Loss: 0.005836
Validation Loss: 0.00493914
Epoch [257/300], Train Loss: 0.005843
Validation Loss: 0.00493782
Epoch [258/300], Train Loss: 0.005843
Validation Loss: 0.00493727
Epoch [259/300], Train Loss: 0.005850
Validation Loss: 0.00493698
Epoch [260/300], Train Loss: 0.005856
Validation Loss: 0.00493814
Epoch [261/300], Train Loss: 0.005837
Validation Loss: 0.00493637
Epoch [262/300], Train Loss: 0.005830
Validation Loss: 0.00493517
Epoch [263/300], Train Loss: 0.005825
Validation Loss: 0.00493465
Epoch [264/300], Train Loss: 0.005836
Validation Loss: 0.00493480
Epoch [265/300], Train Loss: 0.005832
Validation Loss: 0.00493384
Epoch [266/300], Train Loss: 0.005842
Validation Loss: 0.00493424
Epoch [267/300], Train Loss: 0.005840
Validation Loss: 0.00493255
Epoch [268/300], Train Loss: 0.005845
Validation Loss: 0.00493187
Epoch [269/300], Train Loss: 0.005835
Validation Loss: 0.00493313
Epoch [270/300], Train Loss: 0.005838
Validation Loss: 0.00493254
Epoch [271/300], Train Loss: 0.005850
Validation Loss: 0.00493036
Epoch [272/300], Train Loss: 0.005827
Validation Loss: 0.00493088
Epoch [273/300], Train Loss: 0.005840
Validation Loss: 0.00492949
Epoch [274/300], Train Loss: 0.005831
Validation Loss: 0.00492967
Epoch [275/300], Train Loss: 0.005838
Validation Loss: 0.00492941
Epoch [276/300], Train Loss: 0.005822
Validation Loss: 0.00492875
Epoch [277/300], Train Loss: 0.005834
Validation Loss: 0.00492757
Epoch [278/300], Train Loss: 0.005842
Validation Loss: 0.00492733
Epoch [279/300], Train Loss: 0.005831
Validation Loss: 0.00492735
Epoch [280/300], Train Loss: 0.005846
Validation Loss: 0.00492637
Epoch [281/300], Train Loss: 0.005823
Validation Loss: 0.00492638
Epoch [282/300], Train Loss: 0.005827
Validation Loss: 0.00492521
Epoch [283/300], Train Loss: 0.005825
Validation Loss: 0.00492504
Epoch [284/300], Train Loss: 0.005808
Validation Loss: 0.00492456
Epoch [285/300], Train Loss: 0.005823
Validation Loss: 0.00492475
Epoch [286/300], Train Loss: 0.005831
Validation Loss: 0.00492331
Epoch [287/300], Train Loss: 0.005835
Validation Loss: 0.00492289
Epoch [288/300], Train Loss: 0.005812
Validation Loss: 0.00492288
Epoch [289/300], Train Loss: 0.005818
Validation Loss: 0.00492242
Epoch [290/300], Train Loss: 0.005804
Validation Loss: 0.00492176
Epoch [291/300], Train Loss: 0.005819
Validation Loss: 0.00492121
Epoch [292/300], Train Loss: 0.005821
Validation Loss: 0.00492119
Epoch [293/300], Train Loss: 0.005825
Validation Loss: 0.00492067
Epoch [294/300], Train Loss: 0.005823
Validation Loss: 0.00491996
Epoch [295/300], Train Loss: 0.005803
Validation Loss: 0.00491963
Epoch [296/300], Train Loss: 0.005829
Validation Loss: 0.00491955
Epoch [297/300], Train Loss: 0.005816
Validation Loss: 0.00491893
Epoch [298/300], Train Loss: 0.005834
Validation Loss: 0.00491821
Epoch [299/300], Train Loss: 0.005822
Validation Loss: 0.00491818
Epoch [300/300], Train Loss: 0.005814
Validation Loss: 0.00491743

Evaluating model for: Router
Run 14/72 completed in 300.30 seconds with: {'MAE': np.float32(0.21209224), 'MSE': np.float32(0.077374436), 'RMSE': np.float32(0.2781626), 'SAE': np.float32(0.0006646707), 'NDE': np.float32(0.013912953)}

Run 15/72: hidden=128, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Router
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.120958
Validation Loss: 0.11435405
Epoch [2/300], Train Loss: 0.111033
Validation Loss: 0.10452534
Epoch [3/300], Train Loss: 0.101208
Validation Loss: 0.09449559
Epoch [4/300], Train Loss: 0.090571
Validation Loss: 0.08284611
Epoch [5/300], Train Loss: 0.077451
Validation Loss: 0.06720242
Epoch [6/300], Train Loss: 0.059559
Validation Loss: 0.04550016
Epoch [7/300], Train Loss: 0.034312
Validation Loss: 0.01589401
Epoch [8/300], Train Loss: 0.010589
Validation Loss: 0.01164013
Epoch [9/300], Train Loss: 0.011765
Validation Loss: 0.00649648
Epoch [10/300], Train Loss: 0.007654
Validation Loss: 0.00707905
Epoch [11/300], Train Loss: 0.008301
Validation Loss: 0.00647363
Epoch [12/300], Train Loss: 0.007447
Validation Loss: 0.00602636
Epoch [13/300], Train Loss: 0.007432
Validation Loss: 0.00609842
Epoch [14/300], Train Loss: 0.007328
Validation Loss: 0.00596254
Epoch [15/300], Train Loss: 0.007304
Validation Loss: 0.00600803
Epoch [16/300], Train Loss: 0.007268
Validation Loss: 0.00594976
Epoch [17/300], Train Loss: 0.007259
Validation Loss: 0.00594956
Epoch [18/300], Train Loss: 0.007232
Validation Loss: 0.00593802
Epoch [19/300], Train Loss: 0.007233
Validation Loss: 0.00593400
Epoch [20/300], Train Loss: 0.007215
Validation Loss: 0.00593168
Epoch [21/300], Train Loss: 0.007219
Validation Loss: 0.00592316
Epoch [22/300], Train Loss: 0.007186
Validation Loss: 0.00591824
Epoch [23/300], Train Loss: 0.007197
Validation Loss: 0.00591315
Epoch [24/300], Train Loss: 0.007198
Validation Loss: 0.00590777
Epoch [25/300], Train Loss: 0.007179
Validation Loss: 0.00590683
Epoch [26/300], Train Loss: 0.007174
Validation Loss: 0.00589895
Epoch [27/300], Train Loss: 0.007168
Validation Loss: 0.00589194
Epoch [28/300], Train Loss: 0.007188
Validation Loss: 0.00588655
Epoch [29/300], Train Loss: 0.007168
Validation Loss: 0.00588102
Epoch [30/300], Train Loss: 0.007139
Validation Loss: 0.00588326
Epoch [31/300], Train Loss: 0.007152
Validation Loss: 0.00587084
Epoch [32/300], Train Loss: 0.007132
Validation Loss: 0.00586579
Epoch [33/300], Train Loss: 0.007135
Validation Loss: 0.00586060
Epoch [34/300], Train Loss: 0.007116
Validation Loss: 0.00585988
Epoch [35/300], Train Loss: 0.007107
Validation Loss: 0.00585055
Epoch [36/300], Train Loss: 0.007131
Validation Loss: 0.00584529
Epoch [37/300], Train Loss: 0.007120
Validation Loss: 0.00584293
Epoch [38/300], Train Loss: 0.007100
Validation Loss: 0.00583460
Epoch [39/300], Train Loss: 0.007058
Validation Loss: 0.00582974
Epoch [40/300], Train Loss: 0.007090
Validation Loss: 0.00582391
Epoch [41/300], Train Loss: 0.007078
Validation Loss: 0.00582157
Epoch [42/300], Train Loss: 0.007058
Validation Loss: 0.00581326
Epoch [43/300], Train Loss: 0.007065
Validation Loss: 0.00580765
Epoch [44/300], Train Loss: 0.007056
Validation Loss: 0.00580273
Epoch [45/300], Train Loss: 0.007034
Validation Loss: 0.00579996
Epoch [46/300], Train Loss: 0.007033
Validation Loss: 0.00579185
Epoch [47/300], Train Loss: 0.007010
Validation Loss: 0.00578614
Epoch [48/300], Train Loss: 0.007022
Validation Loss: 0.00578057
Epoch [49/300], Train Loss: 0.007034
Validation Loss: 0.00577525
Epoch [50/300], Train Loss: 0.007005
Validation Loss: 0.00576806
Epoch [51/300], Train Loss: 0.006991
Validation Loss: 0.00576174
Epoch [52/300], Train Loss: 0.006992
Validation Loss: 0.00575604
Epoch [53/300], Train Loss: 0.006979
Validation Loss: 0.00574917
Epoch [54/300], Train Loss: 0.006967
Validation Loss: 0.00574281
Epoch [55/300], Train Loss: 0.006950
Validation Loss: 0.00573834
Epoch [56/300], Train Loss: 0.006947
Validation Loss: 0.00573089
Epoch [57/300], Train Loss: 0.006932
Validation Loss: 0.00572550
Epoch [58/300], Train Loss: 0.006926
Validation Loss: 0.00572025
Epoch [59/300], Train Loss: 0.006911
Validation Loss: 0.00571402
Epoch [60/300], Train Loss: 0.006894
Validation Loss: 0.00570609
Epoch [61/300], Train Loss: 0.006881
Validation Loss: 0.00570347
Epoch [62/300], Train Loss: 0.006887
Validation Loss: 0.00569509
Epoch [63/300], Train Loss: 0.006887
Validation Loss: 0.00568962
Epoch [64/300], Train Loss: 0.006877
Validation Loss: 0.00568593
Epoch [65/300], Train Loss: 0.006874
Validation Loss: 0.00567864
Epoch [66/300], Train Loss: 0.006872
Validation Loss: 0.00567354
Epoch [67/300], Train Loss: 0.006847
Validation Loss: 0.00566788
Epoch [68/300], Train Loss: 0.006855
Validation Loss: 0.00566280
Epoch [69/300], Train Loss: 0.006834
Validation Loss: 0.00565795
Epoch [70/300], Train Loss: 0.006846
Validation Loss: 0.00565187
Epoch [71/300], Train Loss: 0.006824
Validation Loss: 0.00564723
Epoch [72/300], Train Loss: 0.006797
Validation Loss: 0.00564260
Epoch [73/300], Train Loss: 0.006802
Validation Loss: 0.00563664
Epoch [74/300], Train Loss: 0.006810
Validation Loss: 0.00563144
Epoch [75/300], Train Loss: 0.006784
Validation Loss: 0.00562666
Epoch [76/300], Train Loss: 0.006776
Validation Loss: 0.00562107
Epoch [77/300], Train Loss: 0.006789
Validation Loss: 0.00561747
Epoch [78/300], Train Loss: 0.006780
Validation Loss: 0.00561701
Epoch [79/300], Train Loss: 0.006768
Validation Loss: 0.00560678
Epoch [80/300], Train Loss: 0.006751
Validation Loss: 0.00560210
Epoch [81/300], Train Loss: 0.006770
Validation Loss: 0.00559918
Epoch [82/300], Train Loss: 0.006743
Validation Loss: 0.00559479
Epoch [83/300], Train Loss: 0.006739
Validation Loss: 0.00558819
Epoch [84/300], Train Loss: 0.006763
Validation Loss: 0.00558404
Epoch [85/300], Train Loss: 0.006718
Validation Loss: 0.00558222
Epoch [86/300], Train Loss: 0.006754
Validation Loss: 0.00557447
Epoch [87/300], Train Loss: 0.006722
Validation Loss: 0.00556989
Epoch [88/300], Train Loss: 0.006705
Validation Loss: 0.00556688
Epoch [89/300], Train Loss: 0.006702
Validation Loss: 0.00556068
Epoch [90/300], Train Loss: 0.006734
Validation Loss: 0.00555898
Epoch [91/300], Train Loss: 0.006703
Validation Loss: 0.00555207
Epoch [92/300], Train Loss: 0.006699
Validation Loss: 0.00554818
Epoch [93/300], Train Loss: 0.006707
Validation Loss: 0.00554401
Epoch [94/300], Train Loss: 0.006693
Validation Loss: 0.00554083
Epoch [95/300], Train Loss: 0.006677
Validation Loss: 0.00553758
Epoch [96/300], Train Loss: 0.006687
Validation Loss: 0.00553323
Epoch [97/300], Train Loss: 0.006686
Validation Loss: 0.00552752
Epoch [98/300], Train Loss: 0.006656
Validation Loss: 0.00552298
Epoch [99/300], Train Loss: 0.006641
Validation Loss: 0.00551959
Epoch [100/300], Train Loss: 0.006647
Validation Loss: 0.00551489
Epoch [101/300], Train Loss: 0.006650
Validation Loss: 0.00551277
Epoch [102/300], Train Loss: 0.006643
Validation Loss: 0.00550638
Epoch [103/300], Train Loss: 0.006622
Validation Loss: 0.00550243
Epoch [104/300], Train Loss: 0.006619
Validation Loss: 0.00549907
Epoch [105/300], Train Loss: 0.006622
Validation Loss: 0.00549421
Epoch [106/300], Train Loss: 0.006630
Validation Loss: 0.00549070
Epoch [107/300], Train Loss: 0.006611
Validation Loss: 0.00548959
Epoch [108/300], Train Loss: 0.006603
Validation Loss: 0.00548540
Epoch [109/300], Train Loss: 0.006613
Validation Loss: 0.00548045
Epoch [110/300], Train Loss: 0.006607
Validation Loss: 0.00547570
Epoch [111/300], Train Loss: 0.006585
Validation Loss: 0.00547692
Epoch [112/300], Train Loss: 0.006599
Validation Loss: 0.00546841
Epoch [113/300], Train Loss: 0.006567
Validation Loss: 0.00546484
Epoch [114/300], Train Loss: 0.006581
Validation Loss: 0.00546114
Epoch [115/300], Train Loss: 0.006579
Validation Loss: 0.00546016
Epoch [116/300], Train Loss: 0.006568
Validation Loss: 0.00545381
Epoch [117/300], Train Loss: 0.006555
Validation Loss: 0.00545011
Epoch [118/300], Train Loss: 0.006562
Validation Loss: 0.00544668
Epoch [119/300], Train Loss: 0.006557
Validation Loss: 0.00544319
Epoch [120/300], Train Loss: 0.006570
Validation Loss: 0.00543994
Epoch [121/300], Train Loss: 0.006555
Validation Loss: 0.00543598
Epoch [122/300], Train Loss: 0.006526
Validation Loss: 0.00543329
Epoch [123/300], Train Loss: 0.006550
Validation Loss: 0.00542943
Epoch [124/300], Train Loss: 0.006543
Validation Loss: 0.00542606
Epoch [125/300], Train Loss: 0.006512
Validation Loss: 0.00542594
Epoch [126/300], Train Loss: 0.006529
Validation Loss: 0.00541957
Epoch [127/300], Train Loss: 0.006516
Validation Loss: 0.00541644
Epoch [128/300], Train Loss: 0.006529
Validation Loss: 0.00541341
Epoch [129/300], Train Loss: 0.006505
Validation Loss: 0.00540999
Epoch [130/300], Train Loss: 0.006505
Validation Loss: 0.00540763
Epoch [131/300], Train Loss: 0.006498
Validation Loss: 0.00540358
Epoch [132/300], Train Loss: 0.006496
Validation Loss: 0.00539996
Epoch [133/300], Train Loss: 0.006521
Validation Loss: 0.00539665
Epoch [134/300], Train Loss: 0.006469
Validation Loss: 0.00539392
Epoch [135/300], Train Loss: 0.006488
Validation Loss: 0.00539069
Epoch [136/300], Train Loss: 0.006476
Validation Loss: 0.00538705
Epoch [137/300], Train Loss: 0.006468
Validation Loss: 0.00538510
Epoch [138/300], Train Loss: 0.006477
Validation Loss: 0.00538061
Epoch [139/300], Train Loss: 0.006472
Validation Loss: 0.00538151
Epoch [140/300], Train Loss: 0.006477
Validation Loss: 0.00537579
Epoch [141/300], Train Loss: 0.006467
Validation Loss: 0.00537254
Epoch [142/300], Train Loss: 0.006451
Validation Loss: 0.00536943
Epoch [143/300], Train Loss: 0.006463
Validation Loss: 0.00536877
Epoch [144/300], Train Loss: 0.006452
Validation Loss: 0.00536331
Epoch [145/300], Train Loss: 0.006446
Validation Loss: 0.00536100
Epoch [146/300], Train Loss: 0.006460
Validation Loss: 0.00535764
Epoch [147/300], Train Loss: 0.006440
Validation Loss: 0.00535701
Epoch [148/300], Train Loss: 0.006447
Validation Loss: 0.00535251
Epoch [149/300], Train Loss: 0.006440
Validation Loss: 0.00534887
Epoch [150/300], Train Loss: 0.006420
Validation Loss: 0.00534665
Epoch [151/300], Train Loss: 0.006431
Validation Loss: 0.00534390
Epoch [152/300], Train Loss: 0.006424
Validation Loss: 0.00534166
Epoch [153/300], Train Loss: 0.006418
Validation Loss: 0.00533873
Epoch [154/300], Train Loss: 0.006417
Validation Loss: 0.00533554
Epoch [155/300], Train Loss: 0.006424
Validation Loss: 0.00533436
Epoch [156/300], Train Loss: 0.006411
Validation Loss: 0.00533055
Epoch [157/300], Train Loss: 0.006399
Validation Loss: 0.00532909
Epoch [158/300], Train Loss: 0.006391
Validation Loss: 0.00532520
Epoch [159/300], Train Loss: 0.006396
Validation Loss: 0.00532287
Epoch [160/300], Train Loss: 0.006408
Validation Loss: 0.00532046
Epoch [161/300], Train Loss: 0.006417
Validation Loss: 0.00532155
Epoch [162/300], Train Loss: 0.006384
Validation Loss: 0.00531434
Epoch [163/300], Train Loss: 0.006381
Validation Loss: 0.00531176
Epoch [164/300], Train Loss: 0.006399
Validation Loss: 0.00530945
Epoch [165/300], Train Loss: 0.006366
Validation Loss: 0.00531085
Epoch [166/300], Train Loss: 0.006366
Validation Loss: 0.00530383
Epoch [167/300], Train Loss: 0.006367
Validation Loss: 0.00530185
Epoch [168/300], Train Loss: 0.006364
Validation Loss: 0.00529918
Epoch [169/300], Train Loss: 0.006373
Validation Loss: 0.00529705
Epoch [170/300], Train Loss: 0.006359
Validation Loss: 0.00529461
Epoch [171/300], Train Loss: 0.006378
Validation Loss: 0.00529311
Epoch [172/300], Train Loss: 0.006347
Validation Loss: 0.00529088
Epoch [173/300], Train Loss: 0.006361
Validation Loss: 0.00528797
Epoch [174/300], Train Loss: 0.006358
Validation Loss: 0.00528543
Epoch [175/300], Train Loss: 0.006332
Validation Loss: 0.00528334
Epoch [176/300], Train Loss: 0.006362
Validation Loss: 0.00528070
Epoch [177/300], Train Loss: 0.006335
Validation Loss: 0.00528107
Epoch [178/300], Train Loss: 0.006313
Validation Loss: 0.00527619
Epoch [179/300], Train Loss: 0.006318
Validation Loss: 0.00527384
Epoch [180/300], Train Loss: 0.006325
Validation Loss: 0.00527277
Epoch [181/300], Train Loss: 0.006323
Validation Loss: 0.00526983
Epoch [182/300], Train Loss: 0.006348
Validation Loss: 0.00526760
Epoch [183/300], Train Loss: 0.006317
Validation Loss: 0.00526829
Epoch [184/300], Train Loss: 0.006308
Validation Loss: 0.00526453
Epoch [185/300], Train Loss: 0.006323
Validation Loss: 0.00526169
Epoch [186/300], Train Loss: 0.006318
Validation Loss: 0.00526094
Epoch [187/300], Train Loss: 0.006317
Validation Loss: 0.00525801
Epoch [188/300], Train Loss: 0.006320
Validation Loss: 0.00525584
Epoch [189/300], Train Loss: 0.006307
Validation Loss: 0.00525487
Epoch [190/300], Train Loss: 0.006330
Validation Loss: 0.00525248
Epoch [191/300], Train Loss: 0.006311
Validation Loss: 0.00525190
Epoch [192/300], Train Loss: 0.006287
Validation Loss: 0.00525164
Epoch [193/300], Train Loss: 0.006287
Validation Loss: 0.00524618
Epoch [194/300], Train Loss: 0.006321
Validation Loss: 0.00524427
Epoch [195/300], Train Loss: 0.006297
Validation Loss: 0.00524256
Epoch [196/300], Train Loss: 0.006283
Validation Loss: 0.00524201
Epoch [197/300], Train Loss: 0.006293
Validation Loss: 0.00523900
Epoch [198/300], Train Loss: 0.006283
Validation Loss: 0.00523912
Epoch [199/300], Train Loss: 0.006279
Validation Loss: 0.00523596
Epoch [200/300], Train Loss: 0.006276
Validation Loss: 0.00523478
Epoch [201/300], Train Loss: 0.006273
Validation Loss: 0.00523282
Epoch [202/300], Train Loss: 0.006267
Validation Loss: 0.00523090
Epoch [203/300], Train Loss: 0.006267
Validation Loss: 0.00522985
Epoch [204/300], Train Loss: 0.006293
Validation Loss: 0.00522768
Epoch [205/300], Train Loss: 0.006276
Validation Loss: 0.00522594
Epoch [206/300], Train Loss: 0.006285
Validation Loss: 0.00522422
Epoch [207/300], Train Loss: 0.006270
Validation Loss: 0.00522260
Epoch [208/300], Train Loss: 0.006254
Validation Loss: 0.00522385
Epoch [209/300], Train Loss: 0.006279
Validation Loss: 0.00521958
Epoch [210/300], Train Loss: 0.006255
Validation Loss: 0.00521792
Epoch [211/300], Train Loss: 0.006248
Validation Loss: 0.00521739
Epoch [212/300], Train Loss: 0.006235
Validation Loss: 0.00521522
Epoch [213/300], Train Loss: 0.006271
Validation Loss: 0.00521374
Epoch [214/300], Train Loss: 0.006248
Validation Loss: 0.00521331
Epoch [215/300], Train Loss: 0.006249
Validation Loss: 0.00521200
Epoch [216/300], Train Loss: 0.006251
Validation Loss: 0.00520861
Epoch [217/300], Train Loss: 0.006224
Validation Loss: 0.00520731
Epoch [218/300], Train Loss: 0.006274
Validation Loss: 0.00520674
Epoch [219/300], Train Loss: 0.006248
Validation Loss: 0.00520457
Epoch [220/300], Train Loss: 0.006255
Validation Loss: 0.00520380
Epoch [221/300], Train Loss: 0.006256
Validation Loss: 0.00520151
Epoch [222/300], Train Loss: 0.006248
Validation Loss: 0.00520024
Epoch [223/300], Train Loss: 0.006234
Validation Loss: 0.00520042
Epoch [224/300], Train Loss: 0.006247
Validation Loss: 0.00519760
Epoch [225/300], Train Loss: 0.006235
Validation Loss: 0.00519626
Epoch [226/300], Train Loss: 0.006240
Validation Loss: 0.00519516
Epoch [227/300], Train Loss: 0.006234
Validation Loss: 0.00519704
Epoch [228/300], Train Loss: 0.006207
Validation Loss: 0.00519363
Epoch [229/300], Train Loss: 0.006216
Validation Loss: 0.00519159
Epoch [230/300], Train Loss: 0.006227
Validation Loss: 0.00519043
Epoch [231/300], Train Loss: 0.006222
Validation Loss: 0.00519036
Epoch [232/300], Train Loss: 0.006227
Validation Loss: 0.00518923
Epoch [233/300], Train Loss: 0.006245
Validation Loss: 0.00518799
Epoch [234/300], Train Loss: 0.006231
Validation Loss: 0.00518638
Epoch [235/300], Train Loss: 0.006229
Validation Loss: 0.00518548
Epoch [236/300], Train Loss: 0.006237
Validation Loss: 0.00518643
Epoch [237/300], Train Loss: 0.006220
Validation Loss: 0.00518232
Epoch [238/300], Train Loss: 0.006205
Validation Loss: 0.00518115
Epoch [239/300], Train Loss: 0.006213
Validation Loss: 0.00518136
Epoch [240/300], Train Loss: 0.006203
Validation Loss: 0.00517907
Epoch [241/300], Train Loss: 0.006207
Validation Loss: 0.00517798
Epoch [242/300], Train Loss: 0.006199
Validation Loss: 0.00517722
Epoch [243/300], Train Loss: 0.006213
Validation Loss: 0.00517741
Epoch [244/300], Train Loss: 0.006205
Validation Loss: 0.00517589
Epoch [245/300], Train Loss: 0.006201
Validation Loss: 0.00517534
Epoch [246/300], Train Loss: 0.006208
Validation Loss: 0.00517301
Epoch [247/300], Train Loss: 0.006220
Validation Loss: 0.00517427
Epoch [248/300], Train Loss: 0.006192
Validation Loss: 0.00517194
Epoch [249/300], Train Loss: 0.006198
Validation Loss: 0.00517095
Epoch [250/300], Train Loss: 0.006205
Validation Loss: 0.00516970
Epoch [251/300], Train Loss: 0.006184
Validation Loss: 0.00516984
Epoch [252/300], Train Loss: 0.006200
Validation Loss: 0.00516759
Epoch [253/300], Train Loss: 0.006207
Validation Loss: 0.00516622
Epoch [254/300], Train Loss: 0.006186
Validation Loss: 0.00516592
Epoch [255/300], Train Loss: 0.006192
Validation Loss: 0.00516696
Epoch [256/300], Train Loss: 0.006188
Validation Loss: 0.00516351
Epoch [257/300], Train Loss: 0.006186
Validation Loss: 0.00516269
Epoch [258/300], Train Loss: 0.006185
Validation Loss: 0.00516176
Epoch [259/300], Train Loss: 0.006193
Validation Loss: 0.00516187
Epoch [260/300], Train Loss: 0.006193
Validation Loss: 0.00516233
Epoch [261/300], Train Loss: 0.006180
Validation Loss: 0.00515915
Epoch [262/300], Train Loss: 0.006180
Validation Loss: 0.00515840
Epoch [263/300], Train Loss: 0.006179
Validation Loss: 0.00515790
Epoch [264/300], Train Loss: 0.006177
Validation Loss: 0.00515823
Epoch [265/300], Train Loss: 0.006181
Validation Loss: 0.00515579
Epoch [266/300], Train Loss: 0.006197
Validation Loss: 0.00515613
Epoch [267/300], Train Loss: 0.006183
Validation Loss: 0.00515411
Epoch [268/300], Train Loss: 0.006183
Validation Loss: 0.00515333
Epoch [269/300], Train Loss: 0.006186
Validation Loss: 0.00515697
Epoch [270/300], Train Loss: 0.006180
Validation Loss: 0.00515287
Epoch [271/300], Train Loss: 0.006189
Validation Loss: 0.00515174
Epoch [272/300], Train Loss: 0.006175
Validation Loss: 0.00515215
Epoch [273/300], Train Loss: 0.006174
Validation Loss: 0.00514953
Epoch [274/300], Train Loss: 0.006179
Validation Loss: 0.00514961
Epoch [275/300], Train Loss: 0.006187
Validation Loss: 0.00514876
Epoch [276/300], Train Loss: 0.006161
Validation Loss: 0.00514755
Epoch [277/300], Train Loss: 0.006177
Validation Loss: 0.00514720
Epoch [278/300], Train Loss: 0.006179
Validation Loss: 0.00514667
Epoch [279/300], Train Loss: 0.006163
Validation Loss: 0.00514642
Epoch [280/300], Train Loss: 0.006190
Validation Loss: 0.00514425
Epoch [281/300], Train Loss: 0.006166
Validation Loss: 0.00514387
Epoch [282/300], Train Loss: 0.006171
Validation Loss: 0.00514280
Epoch [283/300], Train Loss: 0.006163
Validation Loss: 0.00514301
Epoch [284/300], Train Loss: 0.006160
Validation Loss: 0.00514178
Epoch [285/300], Train Loss: 0.006150
Validation Loss: 0.00514137
Epoch [286/300], Train Loss: 0.006173
Validation Loss: 0.00514058
Epoch [287/300], Train Loss: 0.006162
Validation Loss: 0.00513941
Epoch [288/300], Train Loss: 0.006154
Validation Loss: 0.00514008
Epoch [289/300], Train Loss: 0.006148
Validation Loss: 0.00513827
Epoch [290/300], Train Loss: 0.006141
Validation Loss: 0.00513731
Epoch [291/300], Train Loss: 0.006145
Validation Loss: 0.00513665
Epoch [292/300], Train Loss: 0.006152
Validation Loss: 0.00513721
Epoch [293/300], Train Loss: 0.006164
Validation Loss: 0.00513587
Epoch [294/300], Train Loss: 0.006152
Validation Loss: 0.00513471
Epoch [295/300], Train Loss: 0.006138
Validation Loss: 0.00513425
Epoch [296/300], Train Loss: 0.006159
Validation Loss: 0.00513433
Epoch [297/300], Train Loss: 0.006157
Validation Loss: 0.00513295
Epoch [298/300], Train Loss: 0.006169
Validation Loss: 0.00513214
Epoch [299/300], Train Loss: 0.006150
Validation Loss: 0.00513214
Epoch [300/300], Train Loss: 0.006157
Validation Loss: 0.00513086

Evaluating model for: Router
Run 15/72 completed in 318.29 seconds with: {'MAE': np.float32(0.21380359), 'MSE': np.float32(0.08031769), 'RMSE': np.float32(0.28340375), 'SAE': np.float32(0.000594801), 'NDE': np.float32(0.014175101)}

Run 16/72: hidden=128, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Router
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.093471
Validation Loss: 0.08857871
Epoch [2/300], Train Loss: 0.086373
Validation Loss: 0.08141326
Epoch [3/300], Train Loss: 0.078933
Validation Loss: 0.07349841
Epoch [4/300], Train Loss: 0.070448
Validation Loss: 0.06407303
Epoch [5/300], Train Loss: 0.060201
Validation Loss: 0.05247850
Epoch [6/300], Train Loss: 0.046893
Validation Loss: 0.03555024
Epoch [7/300], Train Loss: 0.025691
Validation Loss: 0.00975970
Epoch [8/300], Train Loss: 0.009634
Validation Loss: 0.01138149
Epoch [9/300], Train Loss: 0.008706
Validation Loss: 0.00598909
Epoch [10/300], Train Loss: 0.007625
Validation Loss: 0.00674837
Epoch [11/300], Train Loss: 0.007226
Validation Loss: 0.00565745
Epoch [12/300], Train Loss: 0.006805
Validation Loss: 0.00588771
Epoch [13/300], Train Loss: 0.006759
Validation Loss: 0.00563962
Epoch [14/300], Train Loss: 0.006688
Validation Loss: 0.00568142
Epoch [15/300], Train Loss: 0.006669
Validation Loss: 0.00562814
Epoch [16/300], Train Loss: 0.006637
Validation Loss: 0.00563812
Epoch [17/300], Train Loss: 0.006654
Validation Loss: 0.00561915
Epoch [18/300], Train Loss: 0.006625
Validation Loss: 0.00561962
Epoch [19/300], Train Loss: 0.006639
Validation Loss: 0.00561106
Epoch [20/300], Train Loss: 0.006612
Validation Loss: 0.00560615
Epoch [21/300], Train Loss: 0.006609
Validation Loss: 0.00560216
Epoch [22/300], Train Loss: 0.006599
Validation Loss: 0.00559761
Epoch [23/300], Train Loss: 0.006595
Validation Loss: 0.00559307
Epoch [24/300], Train Loss: 0.006599
Validation Loss: 0.00558941
Epoch [25/300], Train Loss: 0.006576
Validation Loss: 0.00558746
Epoch [26/300], Train Loss: 0.006579
Validation Loss: 0.00557937
Epoch [27/300], Train Loss: 0.006562
Validation Loss: 0.00557607
Epoch [28/300], Train Loss: 0.006600
Validation Loss: 0.00557028
Epoch [29/300], Train Loss: 0.006596
Validation Loss: 0.00556516
Epoch [30/300], Train Loss: 0.006565
Validation Loss: 0.00556667
Epoch [31/300], Train Loss: 0.006563
Validation Loss: 0.00555649
Epoch [32/300], Train Loss: 0.006557
Validation Loss: 0.00555254
Epoch [33/300], Train Loss: 0.006561
Validation Loss: 0.00554716
Epoch [34/300], Train Loss: 0.006532
Validation Loss: 0.00554468
Epoch [35/300], Train Loss: 0.006530
Validation Loss: 0.00554138
Epoch [36/300], Train Loss: 0.006554
Validation Loss: 0.00553394
Epoch [37/300], Train Loss: 0.006550
Validation Loss: 0.00553140
Epoch [38/300], Train Loss: 0.006523
Validation Loss: 0.00552527
Epoch [39/300], Train Loss: 0.006497
Validation Loss: 0.00552236
Epoch [40/300], Train Loss: 0.006526
Validation Loss: 0.00551554
Epoch [41/300], Train Loss: 0.006520
Validation Loss: 0.00551302
Epoch [42/300], Train Loss: 0.006499
Validation Loss: 0.00550658
Epoch [43/300], Train Loss: 0.006518
Validation Loss: 0.00550214
Epoch [44/300], Train Loss: 0.006506
Validation Loss: 0.00549734
Epoch [45/300], Train Loss: 0.006473
Validation Loss: 0.00549363
Epoch [46/300], Train Loss: 0.006494
Validation Loss: 0.00548965
Epoch [47/300], Train Loss: 0.006460
Validation Loss: 0.00548364
Epoch [48/300], Train Loss: 0.006479
Validation Loss: 0.00547948
Epoch [49/300], Train Loss: 0.006490
Validation Loss: 0.00547530
Epoch [50/300], Train Loss: 0.006477
Validation Loss: 0.00547081
Epoch [51/300], Train Loss: 0.006466
Validation Loss: 0.00546643
Epoch [52/300], Train Loss: 0.006445
Validation Loss: 0.00546223
Epoch [53/300], Train Loss: 0.006456
Validation Loss: 0.00545772
Epoch [54/300], Train Loss: 0.006449
Validation Loss: 0.00545336
Epoch [55/300], Train Loss: 0.006438
Validation Loss: 0.00545037
Epoch [56/300], Train Loss: 0.006441
Validation Loss: 0.00544573
Epoch [57/300], Train Loss: 0.006423
Validation Loss: 0.00544082
Epoch [58/300], Train Loss: 0.006423
Validation Loss: 0.00543708
Epoch [59/300], Train Loss: 0.006422
Validation Loss: 0.00543367
Epoch [60/300], Train Loss: 0.006397
Validation Loss: 0.00542694
Epoch [61/300], Train Loss: 0.006377
Validation Loss: 0.00542482
Epoch [62/300], Train Loss: 0.006399
Validation Loss: 0.00541868
Epoch [63/300], Train Loss: 0.006399
Validation Loss: 0.00541478
Epoch [64/300], Train Loss: 0.006383
Validation Loss: 0.00541159
Epoch [65/300], Train Loss: 0.006386
Validation Loss: 0.00540640
Epoch [66/300], Train Loss: 0.006382
Validation Loss: 0.00540266
Epoch [67/300], Train Loss: 0.006369
Validation Loss: 0.00539828
Epoch [68/300], Train Loss: 0.006393
Validation Loss: 0.00539476
Epoch [69/300], Train Loss: 0.006363
Validation Loss: 0.00539051
Epoch [70/300], Train Loss: 0.006370
Validation Loss: 0.00538567
Epoch [71/300], Train Loss: 0.006358
Validation Loss: 0.00538194
Epoch [72/300], Train Loss: 0.006328
Validation Loss: 0.00537817
Epoch [73/300], Train Loss: 0.006343
Validation Loss: 0.00537343
Epoch [74/300], Train Loss: 0.006344
Validation Loss: 0.00537057
Epoch [75/300], Train Loss: 0.006323
Validation Loss: 0.00536577
Epoch [76/300], Train Loss: 0.006316
Validation Loss: 0.00536122
Epoch [77/300], Train Loss: 0.006329
Validation Loss: 0.00535952
Epoch [78/300], Train Loss: 0.006324
Validation Loss: 0.00535969
Epoch [79/300], Train Loss: 0.006314
Validation Loss: 0.00535013
Epoch [80/300], Train Loss: 0.006314
Validation Loss: 0.00534610
Epoch [81/300], Train Loss: 0.006336
Validation Loss: 0.00534415
Epoch [82/300], Train Loss: 0.006303
Validation Loss: 0.00533956
Epoch [83/300], Train Loss: 0.006288
Validation Loss: 0.00533472
Epoch [84/300], Train Loss: 0.006314
Validation Loss: 0.00533141
Epoch [85/300], Train Loss: 0.006284
Validation Loss: 0.00533013
Epoch [86/300], Train Loss: 0.006309
Validation Loss: 0.00532363
Epoch [87/300], Train Loss: 0.006285
Validation Loss: 0.00531921
Epoch [88/300], Train Loss: 0.006284
Validation Loss: 0.00531680
Epoch [89/300], Train Loss: 0.006281
Validation Loss: 0.00531146
Epoch [90/300], Train Loss: 0.006290
Validation Loss: 0.00531013
Epoch [91/300], Train Loss: 0.006282
Validation Loss: 0.00530426
Epoch [92/300], Train Loss: 0.006268
Validation Loss: 0.00530068
Epoch [93/300], Train Loss: 0.006279
Validation Loss: 0.00529719
Epoch [94/300], Train Loss: 0.006269
Validation Loss: 0.00529445
Epoch [95/300], Train Loss: 0.006249
Validation Loss: 0.00529107
Epoch [96/300], Train Loss: 0.006255
Validation Loss: 0.00528848
Epoch [97/300], Train Loss: 0.006252
Validation Loss: 0.00528372
Epoch [98/300], Train Loss: 0.006225
Validation Loss: 0.00527929
Epoch [99/300], Train Loss: 0.006229
Validation Loss: 0.00527627
Epoch [100/300], Train Loss: 0.006222
Validation Loss: 0.00527272
Epoch [101/300], Train Loss: 0.006242
Validation Loss: 0.00527157
Epoch [102/300], Train Loss: 0.006226
Validation Loss: 0.00526511
Epoch [103/300], Train Loss: 0.006215
Validation Loss: 0.00526181
Epoch [104/300], Train Loss: 0.006214
Validation Loss: 0.00525908
Epoch [105/300], Train Loss: 0.006202
Validation Loss: 0.00525431
Epoch [106/300], Train Loss: 0.006233
Validation Loss: 0.00525175
Epoch [107/300], Train Loss: 0.006209
Validation Loss: 0.00525050
Epoch [108/300], Train Loss: 0.006191
Validation Loss: 0.00524596
Epoch [109/300], Train Loss: 0.006198
Validation Loss: 0.00524337
Epoch [110/300], Train Loss: 0.006173
Validation Loss: 0.00523831
Epoch [111/300], Train Loss: 0.006175
Validation Loss: 0.00523914
Epoch [112/300], Train Loss: 0.006182
Validation Loss: 0.00523248
Epoch [113/300], Train Loss: 0.006168
Validation Loss: 0.00522887
Epoch [114/300], Train Loss: 0.006171
Validation Loss: 0.00522570
Epoch [115/300], Train Loss: 0.006185
Validation Loss: 0.00522476
Epoch [116/300], Train Loss: 0.006173
Validation Loss: 0.00521986
Epoch [117/300], Train Loss: 0.006155
Validation Loss: 0.00521605
Epoch [118/300], Train Loss: 0.006155
Validation Loss: 0.00521304
Epoch [119/300], Train Loss: 0.006161
Validation Loss: 0.00520980
Epoch [120/300], Train Loss: 0.006152
Validation Loss: 0.00520683
Epoch [121/300], Train Loss: 0.006156
Validation Loss: 0.00520411
Epoch [122/300], Train Loss: 0.006151
Validation Loss: 0.00520158
Epoch [123/300], Train Loss: 0.006165
Validation Loss: 0.00519823
Epoch [124/300], Train Loss: 0.006145
Validation Loss: 0.00519554
Epoch [125/300], Train Loss: 0.006131
Validation Loss: 0.00519562
Epoch [126/300], Train Loss: 0.006131
Validation Loss: 0.00518989
Epoch [127/300], Train Loss: 0.006137
Validation Loss: 0.00518779
Epoch [128/300], Train Loss: 0.006130
Validation Loss: 0.00518485
Epoch [129/300], Train Loss: 0.006132
Validation Loss: 0.00518198
Epoch [130/300], Train Loss: 0.006126
Validation Loss: 0.00518031
Epoch [131/300], Train Loss: 0.006104
Validation Loss: 0.00517795
Epoch [132/300], Train Loss: 0.006126
Validation Loss: 0.00517412
Epoch [133/300], Train Loss: 0.006135
Validation Loss: 0.00517146
Epoch [134/300], Train Loss: 0.006094
Validation Loss: 0.00516903
Epoch [135/300], Train Loss: 0.006116
Validation Loss: 0.00516657
Epoch [136/300], Train Loss: 0.006108
Validation Loss: 0.00516491
Epoch [137/300], Train Loss: 0.006091
Validation Loss: 0.00516331
Epoch [138/300], Train Loss: 0.006112
Validation Loss: 0.00515992
Epoch [139/300], Train Loss: 0.006105
Validation Loss: 0.00516008
Epoch [140/300], Train Loss: 0.006097
Validation Loss: 0.00515701
Epoch [141/300], Train Loss: 0.006100
Validation Loss: 0.00515363
Epoch [142/300], Train Loss: 0.006086
Validation Loss: 0.00515062
Epoch [143/300], Train Loss: 0.006096
Validation Loss: 0.00514978
Epoch [144/300], Train Loss: 0.006084
Validation Loss: 0.00514636
Epoch [145/300], Train Loss: 0.006080
Validation Loss: 0.00514471
Epoch [146/300], Train Loss: 0.006085
Validation Loss: 0.00514191
Epoch [147/300], Train Loss: 0.006080
Validation Loss: 0.00514131
Epoch [148/300], Train Loss: 0.006072
Validation Loss: 0.00513786
Epoch [149/300], Train Loss: 0.006076
Validation Loss: 0.00513537
Epoch [150/300], Train Loss: 0.006055
Validation Loss: 0.00513366
Epoch [151/300], Train Loss: 0.006060
Validation Loss: 0.00513235
Epoch [152/300], Train Loss: 0.006065
Validation Loss: 0.00512991
Epoch [153/300], Train Loss: 0.006064
Validation Loss: 0.00512789
Epoch [154/300], Train Loss: 0.006059
Validation Loss: 0.00512577
Epoch [155/300], Train Loss: 0.006057
Validation Loss: 0.00512467
Epoch [156/300], Train Loss: 0.006058
Validation Loss: 0.00512246
Epoch [157/300], Train Loss: 0.006052
Validation Loss: 0.00512140
Epoch [158/300], Train Loss: 0.006050
Validation Loss: 0.00511830
Epoch [159/300], Train Loss: 0.006056
Validation Loss: 0.00511678
Epoch [160/300], Train Loss: 0.006065
Validation Loss: 0.00511602
Epoch [161/300], Train Loss: 0.006065
Validation Loss: 0.00511611
Epoch [162/300], Train Loss: 0.006038
Validation Loss: 0.00511081
Epoch [163/300], Train Loss: 0.006026
Validation Loss: 0.00510970
Epoch [164/300], Train Loss: 0.006041
Validation Loss: 0.00510777
Epoch [165/300], Train Loss: 0.006034
Validation Loss: 0.00510916
Epoch [166/300], Train Loss: 0.006031
Validation Loss: 0.00510411
Epoch [167/300], Train Loss: 0.006026
Validation Loss: 0.00510275
Epoch [168/300], Train Loss: 0.006033
Validation Loss: 0.00510046
Epoch [169/300], Train Loss: 0.006049
Validation Loss: 0.00509895
Epoch [170/300], Train Loss: 0.006015
Validation Loss: 0.00509739
Epoch [171/300], Train Loss: 0.006030
Validation Loss: 0.00509765
Epoch [172/300], Train Loss: 0.006022
Validation Loss: 0.00509480
Epoch [173/300], Train Loss: 0.006032
Validation Loss: 0.00509274
Epoch [174/300], Train Loss: 0.006020
Validation Loss: 0.00509092
Epoch [175/300], Train Loss: 0.006017
Validation Loss: 0.00508944
Epoch [176/300], Train Loss: 0.006017
Validation Loss: 0.00508776
Epoch [177/300], Train Loss: 0.006009
Validation Loss: 0.00508781
Epoch [178/300], Train Loss: 0.006002
Validation Loss: 0.00508455
Epoch [179/300], Train Loss: 0.006008
Validation Loss: 0.00508295
Epoch [180/300], Train Loss: 0.005999
Validation Loss: 0.00508206
Epoch [181/300], Train Loss: 0.006006
Validation Loss: 0.00508004
Epoch [182/300], Train Loss: 0.006015
Validation Loss: 0.00507884
Epoch [183/300], Train Loss: 0.006003
Validation Loss: 0.00507891
Epoch [184/300], Train Loss: 0.005989
Validation Loss: 0.00507617
Epoch [185/300], Train Loss: 0.006007
Validation Loss: 0.00507454
Epoch [186/300], Train Loss: 0.006007
Validation Loss: 0.00507394
Epoch [187/300], Train Loss: 0.005992
Validation Loss: 0.00507241
Epoch [188/300], Train Loss: 0.005996
Validation Loss: 0.00507023
Epoch [189/300], Train Loss: 0.005995
Validation Loss: 0.00506937
Epoch [190/300], Train Loss: 0.006016
Validation Loss: 0.00506847
Epoch [191/300], Train Loss: 0.005998
Validation Loss: 0.00506746
Epoch [192/300], Train Loss: 0.005980
Validation Loss: 0.00506721
Epoch [193/300], Train Loss: 0.005977
Validation Loss: 0.00506349
Epoch [194/300], Train Loss: 0.006001
Validation Loss: 0.00506232
Epoch [195/300], Train Loss: 0.005979
Validation Loss: 0.00506073
Epoch [196/300], Train Loss: 0.005973
Validation Loss: 0.00506019
Epoch [197/300], Train Loss: 0.005987
Validation Loss: 0.00505843
Epoch [198/300], Train Loss: 0.005973
Validation Loss: 0.00505838
Epoch [199/300], Train Loss: 0.005973
Validation Loss: 0.00505602
Epoch [200/300], Train Loss: 0.005986
Validation Loss: 0.00505500
Epoch [201/300], Train Loss: 0.005956
Validation Loss: 0.00505457
Epoch [202/300], Train Loss: 0.005955
Validation Loss: 0.00505229
Epoch [203/300], Train Loss: 0.005964
Validation Loss: 0.00505134
Epoch [204/300], Train Loss: 0.005986
Validation Loss: 0.00504987
Epoch [205/300], Train Loss: 0.005957
Validation Loss: 0.00504863
Epoch [206/300], Train Loss: 0.005977
Validation Loss: 0.00504744
Epoch [207/300], Train Loss: 0.005961
Validation Loss: 0.00504619
Epoch [208/300], Train Loss: 0.005963
Validation Loss: 0.00504675
Epoch [209/300], Train Loss: 0.005982
Validation Loss: 0.00504373
Epoch [210/300], Train Loss: 0.005950
Validation Loss: 0.00504248
Epoch [211/300], Train Loss: 0.005952
Validation Loss: 0.00504192
Epoch [212/300], Train Loss: 0.005944
Validation Loss: 0.00504031
Epoch [213/300], Train Loss: 0.005965
Validation Loss: 0.00503921
Epoch [214/300], Train Loss: 0.005954
Validation Loss: 0.00503868
Epoch [215/300], Train Loss: 0.005952
Validation Loss: 0.00503756
Epoch [216/300], Train Loss: 0.005946
Validation Loss: 0.00503638
Epoch [217/300], Train Loss: 0.005931
Validation Loss: 0.00503481
Epoch [218/300], Train Loss: 0.005969
Validation Loss: 0.00503419
Epoch [219/300], Train Loss: 0.005944
Validation Loss: 0.00503270
Epoch [220/300], Train Loss: 0.005951
Validation Loss: 0.00503180
Epoch [221/300], Train Loss: 0.005942
Validation Loss: 0.00503050
Epoch [222/300], Train Loss: 0.005952
Validation Loss: 0.00502934
Epoch [223/300], Train Loss: 0.005943
Validation Loss: 0.00502909
Epoch [224/300], Train Loss: 0.005949
Validation Loss: 0.00502724
Epoch [225/300], Train Loss: 0.005930
Validation Loss: 0.00502626
Epoch [226/300], Train Loss: 0.005952
Validation Loss: 0.00502518
Epoch [227/300], Train Loss: 0.005942
Validation Loss: 0.00502645
Epoch [228/300], Train Loss: 0.005914
Validation Loss: 0.00502349
Epoch [229/300], Train Loss: 0.005923
Validation Loss: 0.00502238
Epoch [230/300], Train Loss: 0.005947
Validation Loss: 0.00502139
Epoch [231/300], Train Loss: 0.005934
Validation Loss: 0.00502077
Epoch [232/300], Train Loss: 0.005941
Validation Loss: 0.00501988
Epoch [233/300], Train Loss: 0.005940
Validation Loss: 0.00502013
Epoch [234/300], Train Loss: 0.005940
Validation Loss: 0.00501725
Epoch [235/300], Train Loss: 0.005934
Validation Loss: 0.00501642
Epoch [236/300], Train Loss: 0.005944
Validation Loss: 0.00501729
Epoch [237/300], Train Loss: 0.005931
Validation Loss: 0.00501427
Epoch [238/300], Train Loss: 0.005921
Validation Loss: 0.00501337
Epoch [239/300], Train Loss: 0.005920
Validation Loss: 0.00501261
Epoch [240/300], Train Loss: 0.005923
Validation Loss: 0.00501116
Epoch [241/300], Train Loss: 0.005915
Validation Loss: 0.00501023
Epoch [242/300], Train Loss: 0.005923
Validation Loss: 0.00500933
Epoch [243/300], Train Loss: 0.005925
Validation Loss: 0.00500896
Epoch [244/300], Train Loss: 0.005916
Validation Loss: 0.00500796
Epoch [245/300], Train Loss: 0.005923
Validation Loss: 0.00500824
Epoch [246/300], Train Loss: 0.005920
Validation Loss: 0.00500561
Epoch [247/300], Train Loss: 0.005929
Validation Loss: 0.00500587
Epoch [248/300], Train Loss: 0.005901
Validation Loss: 0.00500398
Epoch [249/300], Train Loss: 0.005905
Validation Loss: 0.00500297
Epoch [250/300], Train Loss: 0.005919
Validation Loss: 0.00500292
Epoch [251/300], Train Loss: 0.005901
Validation Loss: 0.00500152
Epoch [252/300], Train Loss: 0.005911
Validation Loss: 0.00499996
Epoch [253/300], Train Loss: 0.005919
Validation Loss: 0.00499908
Epoch [254/300], Train Loss: 0.005904
Validation Loss: 0.00499806
Epoch [255/300], Train Loss: 0.005895
Validation Loss: 0.00499886
Epoch [256/300], Train Loss: 0.005898
Validation Loss: 0.00499612
Epoch [257/300], Train Loss: 0.005907
Validation Loss: 0.00499579
Epoch [258/300], Train Loss: 0.005894
Validation Loss: 0.00499446
Epoch [259/300], Train Loss: 0.005903
Validation Loss: 0.00499386
Epoch [260/300], Train Loss: 0.005908
Validation Loss: 0.00499411
Epoch [261/300], Train Loss: 0.005894
Validation Loss: 0.00499187
Epoch [262/300], Train Loss: 0.005888
Validation Loss: 0.00499136
Epoch [263/300], Train Loss: 0.005891
Validation Loss: 0.00499016
Epoch [264/300], Train Loss: 0.005896
Validation Loss: 0.00499004
Epoch [265/300], Train Loss: 0.005892
Validation Loss: 0.00498847
Epoch [266/300], Train Loss: 0.005901
Validation Loss: 0.00498804
Epoch [267/300], Train Loss: 0.005895
Validation Loss: 0.00498676
Epoch [268/300], Train Loss: 0.005900
Validation Loss: 0.00498602
Epoch [269/300], Train Loss: 0.005892
Validation Loss: 0.00498822
Epoch [270/300], Train Loss: 0.005883
Validation Loss: 0.00498473
Epoch [271/300], Train Loss: 0.005900
Validation Loss: 0.00498447
Epoch [272/300], Train Loss: 0.005881
Validation Loss: 0.00498358
Epoch [273/300], Train Loss: 0.005893
Validation Loss: 0.00498170
Epoch [274/300], Train Loss: 0.005886
Validation Loss: 0.00498121
Epoch [275/300], Train Loss: 0.005885
Validation Loss: 0.00498031
Epoch [276/300], Train Loss: 0.005873
Validation Loss: 0.00497934
Epoch [277/300], Train Loss: 0.005884
Validation Loss: 0.00497965
Epoch [278/300], Train Loss: 0.005890
Validation Loss: 0.00497842
Epoch [279/300], Train Loss: 0.005876
Validation Loss: 0.00497766
Epoch [280/300], Train Loss: 0.005897
Validation Loss: 0.00497618
Epoch [281/300], Train Loss: 0.005868
Validation Loss: 0.00497527
Epoch [282/300], Train Loss: 0.005873
Validation Loss: 0.00497443
Epoch [283/300], Train Loss: 0.005880
Validation Loss: 0.00497399
Epoch [284/300], Train Loss: 0.005851
Validation Loss: 0.00497288
Epoch [285/300], Train Loss: 0.005862
Validation Loss: 0.00497233
Epoch [286/300], Train Loss: 0.005871
Validation Loss: 0.00497243
Epoch [287/300], Train Loss: 0.005876
Validation Loss: 0.00497063
Epoch [288/300], Train Loss: 0.005853
Validation Loss: 0.00497080
Epoch [289/300], Train Loss: 0.005850
Validation Loss: 0.00496907
Epoch [290/300], Train Loss: 0.005852
Validation Loss: 0.00496838
Epoch [291/300], Train Loss: 0.005860
Validation Loss: 0.00496759
Epoch [292/300], Train Loss: 0.005850
Validation Loss: 0.00496731
Epoch [293/300], Train Loss: 0.005863
Validation Loss: 0.00496620
Epoch [294/300], Train Loss: 0.005856
Validation Loss: 0.00496539
Epoch [295/300], Train Loss: 0.005843
Validation Loss: 0.00496464
Epoch [296/300], Train Loss: 0.005867
Validation Loss: 0.00496428
Epoch [297/300], Train Loss: 0.005850
Validation Loss: 0.00496305
Epoch [298/300], Train Loss: 0.005877
Validation Loss: 0.00496239
Epoch [299/300], Train Loss: 0.005851
Validation Loss: 0.00496188
Epoch [300/300], Train Loss: 0.005856
Validation Loss: 0.00496070

Evaluating model for: Router
Run 16/72 completed in 332.89 seconds with: {'MAE': np.float32(0.21427877), 'MSE': np.float32(0.07811589), 'RMSE': np.float32(0.2794922), 'SAE': np.float32(0.0007564883), 'NDE': np.float32(0.013979456)}

Run 17/72: hidden=128, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Router
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.114638
Validation Loss: 0.10981009
Epoch [2/300], Train Loss: 0.105918
Validation Loss: 0.10163759
Epoch [3/300], Train Loss: 0.098106
Validation Loss: 0.09379008
Epoch [4/300], Train Loss: 0.090260
Validation Loss: 0.08544408
Epoch [5/300], Train Loss: 0.081606
Validation Loss: 0.07671040
Epoch [6/300], Train Loss: 0.072630
Validation Loss: 0.06733371
Epoch [7/300], Train Loss: 0.062806
Validation Loss: 0.05655375
Epoch [8/300], Train Loss: 0.050980
Validation Loss: 0.04306831
Epoch [9/300], Train Loss: 0.035759
Validation Loss: 0.02501476
Epoch [10/300], Train Loss: 0.016372
Validation Loss: 0.00601199
Epoch [11/300], Train Loss: 0.008700
Validation Loss: 0.00812262
Epoch [12/300], Train Loss: 0.007365
Validation Loss: 0.00579871
Epoch [13/300], Train Loss: 0.007007
Validation Loss: 0.00637079
Epoch [14/300], Train Loss: 0.006730
Validation Loss: 0.00541361
Epoch [15/300], Train Loss: 0.006367
Validation Loss: 0.00542162
Epoch [16/300], Train Loss: 0.006425
Validation Loss: 0.00533875
Epoch [17/300], Train Loss: 0.006272
Validation Loss: 0.00542400
Epoch [18/300], Train Loss: 0.006292
Validation Loss: 0.00538045
Epoch [19/300], Train Loss: 0.006260
Validation Loss: 0.00533450
Epoch [20/300], Train Loss: 0.006301
Validation Loss: 0.00533140
Epoch [21/300], Train Loss: 0.006301
Validation Loss: 0.00534193
Epoch [22/300], Train Loss: 0.006284
Validation Loss: 0.00535254
Epoch [23/300], Train Loss: 0.006267
Validation Loss: 0.00533685
Epoch [24/300], Train Loss: 0.006284
Validation Loss: 0.00532413
Epoch [25/300], Train Loss: 0.006254
Validation Loss: 0.00533628
Epoch [26/300], Train Loss: 0.006263
Validation Loss: 0.00533815
Epoch [27/300], Train Loss: 0.006234
Validation Loss: 0.00532327
Epoch [28/300], Train Loss: 0.006219
Validation Loss: 0.00532405
Epoch [29/300], Train Loss: 0.006221
Validation Loss: 0.00532642
Epoch [30/300], Train Loss: 0.006207
Validation Loss: 0.00532048
Epoch [31/300], Train Loss: 0.006213
Validation Loss: 0.00531537
Epoch [32/300], Train Loss: 0.006226
Validation Loss: 0.00531946
Epoch [33/300], Train Loss: 0.006208
Validation Loss: 0.00532420
Epoch [34/300], Train Loss: 0.006211
Validation Loss: 0.00531045
Epoch [35/300], Train Loss: 0.006201
Validation Loss: 0.00530491
Epoch [36/300], Train Loss: 0.006171
Validation Loss: 0.00531127
Epoch [37/300], Train Loss: 0.006189
Validation Loss: 0.00530586
Epoch [38/300], Train Loss: 0.006188
Validation Loss: 0.00530000
Epoch [39/300], Train Loss: 0.006220
Validation Loss: 0.00530824
Epoch [40/300], Train Loss: 0.006222
Validation Loss: 0.00530565
Epoch [41/300], Train Loss: 0.006197
Validation Loss: 0.00530094
Epoch [42/300], Train Loss: 0.006186
Validation Loss: 0.00529667
Epoch [43/300], Train Loss: 0.006178
Validation Loss: 0.00529166
Epoch [44/300], Train Loss: 0.006183
Validation Loss: 0.00528902
Epoch [45/300], Train Loss: 0.006181
Validation Loss: 0.00530387
Epoch [46/300], Train Loss: 0.006174
Validation Loss: 0.00529304
Epoch [47/300], Train Loss: 0.006187
Validation Loss: 0.00528348
Epoch [48/300], Train Loss: 0.006154
Validation Loss: 0.00529210
Epoch [49/300], Train Loss: 0.006142
Validation Loss: 0.00528056
Epoch [50/300], Train Loss: 0.006160
Validation Loss: 0.00528207
Epoch [51/300], Train Loss: 0.006186
Validation Loss: 0.00528469
Epoch [52/300], Train Loss: 0.006130
Validation Loss: 0.00528742
Epoch [53/300], Train Loss: 0.006151
Validation Loss: 0.00528075
Epoch [54/300], Train Loss: 0.006141
Validation Loss: 0.00527114
Epoch [55/300], Train Loss: 0.006158
Validation Loss: 0.00528057
Epoch [56/300], Train Loss: 0.006152
Validation Loss: 0.00528213
Epoch [57/300], Train Loss: 0.006123
Validation Loss: 0.00527365
Epoch [58/300], Train Loss: 0.006150
Validation Loss: 0.00527254
Epoch [59/300], Train Loss: 0.006122
Validation Loss: 0.00526753
Epoch [60/300], Train Loss: 0.006141
Validation Loss: 0.00527192
Epoch [61/300], Train Loss: 0.006152
Validation Loss: 0.00527043
Epoch [62/300], Train Loss: 0.006122
Validation Loss: 0.00527369
Epoch [63/300], Train Loss: 0.006131
Validation Loss: 0.00526484
Epoch [64/300], Train Loss: 0.006123
Validation Loss: 0.00526451
Epoch [65/300], Train Loss: 0.006131
Validation Loss: 0.00526392
Epoch [66/300], Train Loss: 0.006131
Validation Loss: 0.00526357
Epoch [67/300], Train Loss: 0.006140
Validation Loss: 0.00526065
Epoch [68/300], Train Loss: 0.006140
Validation Loss: 0.00527179
Epoch [69/300], Train Loss: 0.006136
Validation Loss: 0.00525758
Epoch [70/300], Train Loss: 0.006159
Validation Loss: 0.00525118
Epoch [71/300], Train Loss: 0.006127
Validation Loss: 0.00527074
Epoch [72/300], Train Loss: 0.006123
Validation Loss: 0.00526595
Epoch [73/300], Train Loss: 0.006109
Validation Loss: 0.00525157
Epoch [74/300], Train Loss: 0.006088
Validation Loss: 0.00525208
Epoch [75/300], Train Loss: 0.006142
Validation Loss: 0.00526204
Epoch [76/300], Train Loss: 0.006067
Validation Loss: 0.00525185
Epoch [77/300], Train Loss: 0.006114
Validation Loss: 0.00524673
Epoch [78/300], Train Loss: 0.006074
Validation Loss: 0.00524474
Epoch [79/300], Train Loss: 0.006133
Validation Loss: 0.00525833
Epoch [80/300], Train Loss: 0.006088
Validation Loss: 0.00524681
Epoch [81/300], Train Loss: 0.006109
Validation Loss: 0.00524263
Epoch [82/300], Train Loss: 0.006088
Validation Loss: 0.00524809
Epoch [83/300], Train Loss: 0.006092
Validation Loss: 0.00524662
Epoch [84/300], Train Loss: 0.006055
Validation Loss: 0.00524009
Epoch [85/300], Train Loss: 0.006108
Validation Loss: 0.00523740
Epoch [86/300], Train Loss: 0.006082
Validation Loss: 0.00525019
Epoch [87/300], Train Loss: 0.006064
Validation Loss: 0.00523813
Epoch [88/300], Train Loss: 0.006101
Validation Loss: 0.00523141
Epoch [89/300], Train Loss: 0.006081
Validation Loss: 0.00525010
Epoch [90/300], Train Loss: 0.006055
Validation Loss: 0.00524984
Epoch [91/300], Train Loss: 0.006041
Validation Loss: 0.00522975
Epoch [92/300], Train Loss: 0.006070
Validation Loss: 0.00523608
Epoch [93/300], Train Loss: 0.006042
Validation Loss: 0.00523740
Epoch [94/300], Train Loss: 0.006058
Validation Loss: 0.00522892
Epoch [95/300], Train Loss: 0.006028
Validation Loss: 0.00523516
Epoch [96/300], Train Loss: 0.006101
Validation Loss: 0.00523580
Epoch [97/300], Train Loss: 0.006066
Validation Loss: 0.00522913
Epoch [98/300], Train Loss: 0.006052
Validation Loss: 0.00522751
Epoch [99/300], Train Loss: 0.006056
Validation Loss: 0.00522648
Epoch [100/300], Train Loss: 0.006028
Validation Loss: 0.00523134
Epoch [101/300], Train Loss: 0.006058
Validation Loss: 0.00522557
Epoch [102/300], Train Loss: 0.006049
Validation Loss: 0.00522344
Epoch [103/300], Train Loss: 0.006044
Validation Loss: 0.00522813
Epoch [104/300], Train Loss: 0.006053
Validation Loss: 0.00521997
Epoch [105/300], Train Loss: 0.006028
Validation Loss: 0.00522195
Epoch [106/300], Train Loss: 0.006049
Validation Loss: 0.00522537
Epoch [107/300], Train Loss: 0.006025
Validation Loss: 0.00522244
Epoch [108/300], Train Loss: 0.006050
Validation Loss: 0.00522306
Epoch [109/300], Train Loss: 0.006015
Validation Loss: 0.00521604
Epoch [110/300], Train Loss: 0.006035
Validation Loss: 0.00521788
Epoch [111/300], Train Loss: 0.006037
Validation Loss: 0.00521662
Epoch [112/300], Train Loss: 0.006024
Validation Loss: 0.00522297
Epoch [113/300], Train Loss: 0.006035
Validation Loss: 0.00521848
Epoch [114/300], Train Loss: 0.006055
Validation Loss: 0.00521013
Epoch [115/300], Train Loss: 0.006016
Validation Loss: 0.00521891
Epoch [116/300], Train Loss: 0.006021
Validation Loss: 0.00521913
Epoch [117/300], Train Loss: 0.006002
Validation Loss: 0.00520959
Epoch [118/300], Train Loss: 0.006021
Validation Loss: 0.00521644
Epoch [119/300], Train Loss: 0.006009
Validation Loss: 0.00521336
Epoch [120/300], Train Loss: 0.006018
Validation Loss: 0.00520384
Epoch [121/300], Train Loss: 0.006040
Validation Loss: 0.00521235
Epoch [122/300], Train Loss: 0.006022
Validation Loss: 0.00521633
Epoch [123/300], Train Loss: 0.006009
Validation Loss: 0.00521104
Epoch [124/300], Train Loss: 0.006004
Validation Loss: 0.00520457
Epoch [125/300], Train Loss: 0.005997
Validation Loss: 0.00521020
Epoch [126/300], Train Loss: 0.005996
Validation Loss: 0.00521146
Epoch [127/300], Train Loss: 0.006018
Validation Loss: 0.00520029
Epoch [128/300], Train Loss: 0.006047
Validation Loss: 0.00520489
Epoch [129/300], Train Loss: 0.005991
Validation Loss: 0.00520907
Epoch [130/300], Train Loss: 0.006000
Validation Loss: 0.00520288
Epoch [131/300], Train Loss: 0.006011
Validation Loss: 0.00520092
Epoch [132/300], Train Loss: 0.005995
Validation Loss: 0.00520370
Epoch [133/300], Train Loss: 0.005987
Validation Loss: 0.00520652
Epoch [134/300], Train Loss: 0.005987
Validation Loss: 0.00520012
Epoch [135/300], Train Loss: 0.005977
Validation Loss: 0.00519491
Epoch [136/300], Train Loss: 0.005965
Validation Loss: 0.00519686
Epoch [137/300], Train Loss: 0.006000
Validation Loss: 0.00519854
Epoch [138/300], Train Loss: 0.005993
Validation Loss: 0.00521007
Epoch [139/300], Train Loss: 0.005990
Validation Loss: 0.00519391
Epoch [140/300], Train Loss: 0.005978
Validation Loss: 0.00519321
Epoch [141/300], Train Loss: 0.005973
Validation Loss: 0.00519730
Epoch [142/300], Train Loss: 0.006004
Validation Loss: 0.00519336
Epoch [143/300], Train Loss: 0.005974
Validation Loss: 0.00519906
Epoch [144/300], Train Loss: 0.005948
Validation Loss: 0.00519108
Epoch [145/300], Train Loss: 0.005973
Validation Loss: 0.00519432
Epoch [146/300], Train Loss: 0.005978
Validation Loss: 0.00519722
Epoch [147/300], Train Loss: 0.005982
Validation Loss: 0.00518825
Epoch [148/300], Train Loss: 0.005996
Validation Loss: 0.00518609
Epoch [149/300], Train Loss: 0.005971
Validation Loss: 0.00519491
Epoch [150/300], Train Loss: 0.005957
Validation Loss: 0.00519252
Epoch [151/300], Train Loss: 0.005966
Validation Loss: 0.00518644
Epoch [152/300], Train Loss: 0.005969
Validation Loss: 0.00518701
Epoch [153/300], Train Loss: 0.005954
Validation Loss: 0.00518919
Epoch [154/300], Train Loss: 0.005938
Validation Loss: 0.00518800
Epoch [155/300], Train Loss: 0.005971
Validation Loss: 0.00518683
Epoch [156/300], Train Loss: 0.005992
Validation Loss: 0.00518565
Epoch [157/300], Train Loss: 0.005971
Validation Loss: 0.00518785
Epoch [158/300], Train Loss: 0.005945
Validation Loss: 0.00518598
Epoch [159/300], Train Loss: 0.005944
Validation Loss: 0.00518245
Epoch [160/300], Train Loss: 0.005958
Validation Loss: 0.00518257
Epoch [161/300], Train Loss: 0.005965
Validation Loss: 0.00518553
Epoch [162/300], Train Loss: 0.005945
Validation Loss: 0.00518757
Epoch [163/300], Train Loss: 0.005973
Validation Loss: 0.00517810
Epoch [164/300], Train Loss: 0.005986
Validation Loss: 0.00518495
Epoch [165/300], Train Loss: 0.005965
Validation Loss: 0.00517456
Epoch [166/300], Train Loss: 0.005958
Validation Loss: 0.00518391
Epoch [167/300], Train Loss: 0.005942
Validation Loss: 0.00518211
Epoch [168/300], Train Loss: 0.005945
Validation Loss: 0.00518059
Epoch [169/300], Train Loss: 0.005920
Validation Loss: 0.00517423
Epoch [170/300], Train Loss: 0.005969
Validation Loss: 0.00517581
Epoch [171/300], Train Loss: 0.005950
Validation Loss: 0.00517767
Epoch [172/300], Train Loss: 0.005970
Validation Loss: 0.00517725
Epoch [173/300], Train Loss: 0.005937
Validation Loss: 0.00518151
Epoch [174/300], Train Loss: 0.005963
Validation Loss: 0.00517362
Epoch [175/300], Train Loss: 0.005952
Validation Loss: 0.00517968
Epoch [176/300], Train Loss: 0.005964
Validation Loss: 0.00517434
Epoch [177/300], Train Loss: 0.005938
Validation Loss: 0.00517482
Epoch [178/300], Train Loss: 0.005959
Validation Loss: 0.00517446
Epoch [179/300], Train Loss: 0.005969
Validation Loss: 0.00517495
Epoch [180/300], Train Loss: 0.005920
Validation Loss: 0.00517459
Epoch [181/300], Train Loss: 0.005950
Validation Loss: 0.00517253
Epoch [182/300], Train Loss: 0.005932
Validation Loss: 0.00517044
Epoch [183/300], Train Loss: 0.005921
Validation Loss: 0.00517080
Epoch [184/300], Train Loss: 0.005930
Validation Loss: 0.00517647
Epoch [185/300], Train Loss: 0.005948
Validation Loss: 0.00517216
Epoch [186/300], Train Loss: 0.005976
Validation Loss: 0.00516689
Epoch [187/300], Train Loss: 0.005943
Validation Loss: 0.00517107
Epoch [188/300], Train Loss: 0.005918
Validation Loss: 0.00517280
Epoch [189/300], Train Loss: 0.005969
Validation Loss: 0.00516745
Epoch [190/300], Train Loss: 0.005895
Validation Loss: 0.00516473
Epoch [191/300], Train Loss: 0.005921
Validation Loss: 0.00516697
Epoch [192/300], Train Loss: 0.005901
Validation Loss: 0.00516817
Epoch [193/300], Train Loss: 0.005945
Validation Loss: 0.00516903
Epoch [194/300], Train Loss: 0.005905
Validation Loss: 0.00516731
Epoch [195/300], Train Loss: 0.005916
Validation Loss: 0.00516503
Epoch [196/300], Train Loss: 0.005960
Validation Loss: 0.00517094
Epoch [197/300], Train Loss: 0.005958
Validation Loss: 0.00516444
Epoch [198/300], Train Loss: 0.005918
Validation Loss: 0.00516243
Epoch [199/300], Train Loss: 0.005902
Validation Loss: 0.00516517
Epoch [200/300], Train Loss: 0.005945
Validation Loss: 0.00516270
Epoch [201/300], Train Loss: 0.005919
Validation Loss: 0.00516209
Epoch [202/300], Train Loss: 0.005898
Validation Loss: 0.00516713
Epoch [203/300], Train Loss: 0.005907
Validation Loss: 0.00515895
Epoch [204/300], Train Loss: 0.005905
Validation Loss: 0.00515812
Epoch [205/300], Train Loss: 0.005932
Validation Loss: 0.00516221
Epoch [206/300], Train Loss: 0.005913
Validation Loss: 0.00517022
Epoch [207/300], Train Loss: 0.005922
Validation Loss: 0.00516020
Epoch [208/300], Train Loss: 0.005987
Validation Loss: 0.00515243
Epoch [209/300], Train Loss: 0.005904
Validation Loss: 0.00516265
Epoch [210/300], Train Loss: 0.005903
Validation Loss: 0.00516472
Epoch [211/300], Train Loss: 0.005930
Validation Loss: 0.00515648
Epoch [212/300], Train Loss: 0.005913
Validation Loss: 0.00515459
Epoch [213/300], Train Loss: 0.005912
Validation Loss: 0.00515716
Epoch [214/300], Train Loss: 0.005875
Validation Loss: 0.00515693
Epoch [215/300], Train Loss: 0.005900
Validation Loss: 0.00515713
Epoch [216/300], Train Loss: 0.005948
Validation Loss: 0.00515301
Epoch [217/300], Train Loss: 0.005918
Validation Loss: 0.00515941
Epoch [218/300], Train Loss: 0.005912
Validation Loss: 0.00515558
Early stopping triggered

Evaluating model for: Router
Run 17/72 completed in 229.77 seconds with: {'MAE': np.float32(0.2090042), 'MSE': np.float32(0.07960258), 'RMSE': np.float32(0.28213927), 'SAE': np.float32(0.00018632284), 'NDE': np.float32(0.014103773)}

Run 18/72: hidden=128, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Router
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.084001
Validation Loss: 0.07825758
Epoch [2/300], Train Loss: 0.073934
Validation Loss: 0.06859623
Epoch [3/300], Train Loss: 0.064375
Validation Loss: 0.05882603
Epoch [4/300], Train Loss: 0.054825
Validation Loss: 0.04904423
Epoch [5/300], Train Loss: 0.044340
Validation Loss: 0.03783802
Epoch [6/300], Train Loss: 0.032604
Validation Loss: 0.02503675
Epoch [7/300], Train Loss: 0.019228
Validation Loss: 0.01098811
Epoch [8/300], Train Loss: 0.007867
Validation Loss: 0.00601909
Epoch [9/300], Train Loss: 0.008001
Validation Loss: 0.00593503
Epoch [10/300], Train Loss: 0.006171
Validation Loss: 0.00545720
Epoch [11/300], Train Loss: 0.006363
Validation Loss: 0.00567738
Epoch [12/300], Train Loss: 0.006090
Validation Loss: 0.00515554
Epoch [13/300], Train Loss: 0.005947
Validation Loss: 0.00517447
Epoch [14/300], Train Loss: 0.005970
Validation Loss: 0.00512725
Epoch [15/300], Train Loss: 0.005863
Validation Loss: 0.00517056
Epoch [16/300], Train Loss: 0.005930
Validation Loss: 0.00516081
Epoch [17/300], Train Loss: 0.005855
Validation Loss: 0.00512986
Epoch [18/300], Train Loss: 0.005870
Validation Loss: 0.00512545
Epoch [19/300], Train Loss: 0.005872
Validation Loss: 0.00513194
Epoch [20/300], Train Loss: 0.005903
Validation Loss: 0.00513703
Epoch [21/300], Train Loss: 0.005918
Validation Loss: 0.00513045
Epoch [22/300], Train Loss: 0.005908
Validation Loss: 0.00513165
Epoch [23/300], Train Loss: 0.005883
Validation Loss: 0.00512900
Epoch [24/300], Train Loss: 0.005900
Validation Loss: 0.00512509
Epoch [25/300], Train Loss: 0.005864
Validation Loss: 0.00513226
Epoch [26/300], Train Loss: 0.005884
Validation Loss: 0.00513170
Epoch [27/300], Train Loss: 0.005848
Validation Loss: 0.00512308
Epoch [28/300], Train Loss: 0.005842
Validation Loss: 0.00512615
Epoch [29/300], Train Loss: 0.005859
Validation Loss: 0.00512858
Epoch [30/300], Train Loss: 0.005828
Validation Loss: 0.00512451
Epoch [31/300], Train Loss: 0.005842
Validation Loss: 0.00512269
Epoch [32/300], Train Loss: 0.005875
Validation Loss: 0.00512622
Epoch [33/300], Train Loss: 0.005856
Validation Loss: 0.00513102
Epoch [34/300], Train Loss: 0.005843
Validation Loss: 0.00512111
Epoch [35/300], Train Loss: 0.005836
Validation Loss: 0.00511814
Epoch [36/300], Train Loss: 0.005813
Validation Loss: 0.00512455
Epoch [37/300], Train Loss: 0.005839
Validation Loss: 0.00512126
Epoch [38/300], Train Loss: 0.005836
Validation Loss: 0.00511706
Epoch [39/300], Train Loss: 0.005865
Validation Loss: 0.00512331
Epoch [40/300], Train Loss: 0.005871
Validation Loss: 0.00512273
Epoch [41/300], Train Loss: 0.005852
Validation Loss: 0.00512119
Epoch [42/300], Train Loss: 0.005843
Validation Loss: 0.00511817
Epoch [43/300], Train Loss: 0.005833
Validation Loss: 0.00511396
Epoch [44/300], Train Loss: 0.005839
Validation Loss: 0.00511360
Epoch [45/300], Train Loss: 0.005830
Validation Loss: 0.00512677
Epoch [46/300], Train Loss: 0.005833
Validation Loss: 0.00511707
Epoch [47/300], Train Loss: 0.005844
Validation Loss: 0.00511101
Epoch [48/300], Train Loss: 0.005802
Validation Loss: 0.00511849
Epoch [49/300], Train Loss: 0.005809
Validation Loss: 0.00510974
Epoch [50/300], Train Loss: 0.005826
Validation Loss: 0.00511202
Epoch [51/300], Train Loss: 0.005853
Validation Loss: 0.00511383
Epoch [52/300], Train Loss: 0.005791
Validation Loss: 0.00511788
Epoch [53/300], Train Loss: 0.005818
Validation Loss: 0.00511210
Epoch [54/300], Train Loss: 0.005806
Validation Loss: 0.00510543
Epoch [55/300], Train Loss: 0.005828
Validation Loss: 0.00511407
Epoch [56/300], Train Loss: 0.005820
Validation Loss: 0.00511548
Epoch [57/300], Train Loss: 0.005801
Validation Loss: 0.00510842
Epoch [58/300], Train Loss: 0.005826
Validation Loss: 0.00510845
Epoch [59/300], Train Loss: 0.005795
Validation Loss: 0.00510519
Epoch [60/300], Train Loss: 0.005813
Validation Loss: 0.00510945
Epoch [61/300], Train Loss: 0.005821
Validation Loss: 0.00510778
Epoch [62/300], Train Loss: 0.005798
Validation Loss: 0.00511129
Epoch [63/300], Train Loss: 0.005809
Validation Loss: 0.00510466
Epoch [64/300], Train Loss: 0.005801
Validation Loss: 0.00510488
Epoch [65/300], Train Loss: 0.005822
Validation Loss: 0.00510421
Epoch [66/300], Train Loss: 0.005810
Validation Loss: 0.00510456
Epoch [67/300], Train Loss: 0.005821
Validation Loss: 0.00510358
Epoch [68/300], Train Loss: 0.005815
Validation Loss: 0.00511345
Epoch [69/300], Train Loss: 0.005823
Validation Loss: 0.00509996
Epoch [70/300], Train Loss: 0.005852
Validation Loss: 0.00509626
Epoch [71/300], Train Loss: 0.005812
Validation Loss: 0.00511545
Epoch [72/300], Train Loss: 0.005826
Validation Loss: 0.00510797
Epoch [73/300], Train Loss: 0.005805
Validation Loss: 0.00509669
Epoch [74/300], Train Loss: 0.005775
Validation Loss: 0.00509901
Epoch [75/300], Train Loss: 0.005830
Validation Loss: 0.00510693
Epoch [76/300], Train Loss: 0.005762
Validation Loss: 0.00509658
Epoch [77/300], Train Loss: 0.005808
Validation Loss: 0.00509439
Epoch [78/300], Train Loss: 0.005768
Validation Loss: 0.00509373
Epoch [79/300], Train Loss: 0.005829
Validation Loss: 0.00510589
Epoch [80/300], Train Loss: 0.005788
Validation Loss: 0.00509414
Epoch [81/300], Train Loss: 0.005809
Validation Loss: 0.00509205
Epoch [82/300], Train Loss: 0.005789
Validation Loss: 0.00509783
Epoch [83/300], Train Loss: 0.005792
Validation Loss: 0.00509560
Epoch [84/300], Train Loss: 0.005759
Validation Loss: 0.00509002
Epoch [85/300], Train Loss: 0.005809
Validation Loss: 0.00508983
Epoch [86/300], Train Loss: 0.005776
Validation Loss: 0.00510149
Epoch [87/300], Train Loss: 0.005759
Validation Loss: 0.00508852
Epoch [88/300], Train Loss: 0.005803
Validation Loss: 0.00508542
Epoch [89/300], Train Loss: 0.005781
Validation Loss: 0.00510558
Epoch [90/300], Train Loss: 0.005763
Validation Loss: 0.00509900
Epoch [91/300], Train Loss: 0.005756
Validation Loss: 0.00508307
Epoch [92/300], Train Loss: 0.005773
Validation Loss: 0.00509219
Epoch [93/300], Train Loss: 0.005743
Validation Loss: 0.00509111
Epoch [94/300], Train Loss: 0.005779
Validation Loss: 0.00508199
Epoch [95/300], Train Loss: 0.005742
Validation Loss: 0.00508991
Epoch [96/300], Train Loss: 0.005805
Validation Loss: 0.00508943
Epoch [97/300], Train Loss: 0.005766
Validation Loss: 0.00508249
Epoch [98/300], Train Loss: 0.005750
Validation Loss: 0.00508286
Epoch [99/300], Train Loss: 0.005771
Validation Loss: 0.00508281
Epoch [100/300], Train Loss: 0.005727
Validation Loss: 0.00508571
Epoch [101/300], Train Loss: 0.005757
Validation Loss: 0.00507997
Epoch [102/300], Train Loss: 0.005752
Validation Loss: 0.00508044
Epoch [103/300], Train Loss: 0.005758
Validation Loss: 0.00508475
Epoch [104/300], Train Loss: 0.005770
Validation Loss: 0.00507596
Epoch [105/300], Train Loss: 0.005741
Validation Loss: 0.00507926
Epoch [106/300], Train Loss: 0.005764
Validation Loss: 0.00508247
Epoch [107/300], Train Loss: 0.005741
Validation Loss: 0.00507840
Epoch [108/300], Train Loss: 0.005755
Validation Loss: 0.00507999
Epoch [109/300], Train Loss: 0.005733
Validation Loss: 0.00507454
Epoch [110/300], Train Loss: 0.005739
Validation Loss: 0.00507647
Epoch [111/300], Train Loss: 0.005749
Validation Loss: 0.00507510
Epoch [112/300], Train Loss: 0.005738
Validation Loss: 0.00508087
Epoch [113/300], Train Loss: 0.005749
Validation Loss: 0.00507529
Epoch [114/300], Train Loss: 0.005772
Validation Loss: 0.00506986
Epoch [115/300], Train Loss: 0.005721
Validation Loss: 0.00508015
Epoch [116/300], Train Loss: 0.005729
Validation Loss: 0.00507711
Epoch [117/300], Train Loss: 0.005707
Validation Loss: 0.00506849
Epoch [118/300], Train Loss: 0.005740
Validation Loss: 0.00507641
Epoch [119/300], Train Loss: 0.005724
Validation Loss: 0.00507258
Epoch [120/300], Train Loss: 0.005738
Validation Loss: 0.00506526
Epoch [121/300], Train Loss: 0.005745
Validation Loss: 0.00507447
Epoch [122/300], Train Loss: 0.005732
Validation Loss: 0.00507610
Epoch [123/300], Train Loss: 0.005718
Validation Loss: 0.00506930
Epoch [124/300], Train Loss: 0.005720
Validation Loss: 0.00506524
Epoch [125/300], Train Loss: 0.005712
Validation Loss: 0.00507219
Epoch [126/300], Train Loss: 0.005708
Validation Loss: 0.00507111
Epoch [127/300], Train Loss: 0.005729
Validation Loss: 0.00506198
Epoch [128/300], Train Loss: 0.005753
Validation Loss: 0.00506728
Epoch [129/300], Train Loss: 0.005708
Validation Loss: 0.00507013
Epoch [130/300], Train Loss: 0.005711
Validation Loss: 0.00506313
Epoch [131/300], Train Loss: 0.005725
Validation Loss: 0.00506250
Epoch [132/300], Train Loss: 0.005706
Validation Loss: 0.00506664
Epoch [133/300], Train Loss: 0.005701
Validation Loss: 0.00506736
Epoch [134/300], Train Loss: 0.005703
Validation Loss: 0.00506074
Epoch [135/300], Train Loss: 0.005691
Validation Loss: 0.00505849
Epoch [136/300], Train Loss: 0.005685
Validation Loss: 0.00506184
Epoch [137/300], Train Loss: 0.005717
Validation Loss: 0.00506194
Epoch [138/300], Train Loss: 0.005704
Validation Loss: 0.00506980
Epoch [139/300], Train Loss: 0.005699
Validation Loss: 0.00505646
Epoch [140/300], Train Loss: 0.005700
Validation Loss: 0.00505786
Epoch [141/300], Train Loss: 0.005695
Validation Loss: 0.00506177
Epoch [142/300], Train Loss: 0.005720
Validation Loss: 0.00505640
Epoch [143/300], Train Loss: 0.005695
Validation Loss: 0.00506160
Epoch [144/300], Train Loss: 0.005666
Validation Loss: 0.00505523
Epoch [145/300], Train Loss: 0.005690
Validation Loss: 0.00505887
Epoch [146/300], Train Loss: 0.005699
Validation Loss: 0.00506041
Epoch [147/300], Train Loss: 0.005695
Validation Loss: 0.00505283
Epoch [148/300], Train Loss: 0.005720
Validation Loss: 0.00505247
Epoch [149/300], Train Loss: 0.005698
Validation Loss: 0.00506199
Epoch [150/300], Train Loss: 0.005676
Validation Loss: 0.00505604
Epoch [151/300], Train Loss: 0.005680
Validation Loss: 0.00505139
Epoch [152/300], Train Loss: 0.005694
Validation Loss: 0.00505325
Epoch [153/300], Train Loss: 0.005670
Validation Loss: 0.00505525
Epoch [154/300], Train Loss: 0.005658
Validation Loss: 0.00505322
Epoch [155/300], Train Loss: 0.005696
Validation Loss: 0.00505197
Epoch [156/300], Train Loss: 0.005709
Validation Loss: 0.00505142
Epoch [157/300], Train Loss: 0.005693
Validation Loss: 0.00505357
Epoch [158/300], Train Loss: 0.005667
Validation Loss: 0.00505224
Epoch [159/300], Train Loss: 0.005672
Validation Loss: 0.00504958
Epoch [160/300], Train Loss: 0.005684
Validation Loss: 0.00504974
Epoch [161/300], Train Loss: 0.005691
Validation Loss: 0.00505231
Epoch [162/300], Train Loss: 0.005661
Validation Loss: 0.00505285
Epoch [163/300], Train Loss: 0.005700
Validation Loss: 0.00504567
Epoch [164/300], Train Loss: 0.005720
Validation Loss: 0.00505326
Epoch [165/300], Train Loss: 0.005682
Validation Loss: 0.00504391
Epoch [166/300], Train Loss: 0.005689
Validation Loss: 0.00505268
Epoch [167/300], Train Loss: 0.005669
Validation Loss: 0.00504915
Epoch [168/300], Train Loss: 0.005668
Validation Loss: 0.00504713
Epoch [169/300], Train Loss: 0.005640
Validation Loss: 0.00504292
Epoch [170/300], Train Loss: 0.005693
Validation Loss: 0.00504509
Epoch [171/300], Train Loss: 0.005670
Validation Loss: 0.00504668
Epoch [172/300], Train Loss: 0.005698
Validation Loss: 0.00504505
Epoch [173/300], Train Loss: 0.005657
Validation Loss: 0.00504877
Epoch [174/300], Train Loss: 0.005682
Validation Loss: 0.00504209
Epoch [175/300], Train Loss: 0.005679
Validation Loss: 0.00504847
Epoch [176/300], Train Loss: 0.005688
Validation Loss: 0.00504256
Epoch [177/300], Train Loss: 0.005676
Validation Loss: 0.00504307
Epoch [178/300], Train Loss: 0.005690
Validation Loss: 0.00504343
Epoch [179/300], Train Loss: 0.005704
Validation Loss: 0.00504369
Epoch [180/300], Train Loss: 0.005652
Validation Loss: 0.00504313
Epoch [181/300], Train Loss: 0.005681
Validation Loss: 0.00504147
Epoch [182/300], Train Loss: 0.005665
Validation Loss: 0.00503980
Epoch [183/300], Train Loss: 0.005651
Validation Loss: 0.00504035
Epoch [184/300], Train Loss: 0.005661
Validation Loss: 0.00504576
Epoch [185/300], Train Loss: 0.005679
Validation Loss: 0.00504020
Epoch [186/300], Train Loss: 0.005710
Validation Loss: 0.00503666
Epoch [187/300], Train Loss: 0.005676
Validation Loss: 0.00504216
Epoch [188/300], Train Loss: 0.005636
Validation Loss: 0.00504259
Epoch [189/300], Train Loss: 0.005702
Validation Loss: 0.00503657
Epoch [190/300], Train Loss: 0.005630
Validation Loss: 0.00503526
Epoch [191/300], Train Loss: 0.005655
Validation Loss: 0.00503837
Epoch [192/300], Train Loss: 0.005642
Validation Loss: 0.00503869
Epoch [193/300], Train Loss: 0.005680
Validation Loss: 0.00503883
Epoch [194/300], Train Loss: 0.005639
Validation Loss: 0.00503742
Epoch [195/300], Train Loss: 0.005655
Validation Loss: 0.00503565
Epoch [196/300], Train Loss: 0.005692
Validation Loss: 0.00504122
Epoch [197/300], Train Loss: 0.005688
Validation Loss: 0.00503441
Epoch [198/300], Train Loss: 0.005650
Validation Loss: 0.00503341
Epoch [199/300], Train Loss: 0.005637
Validation Loss: 0.00503735
Epoch [200/300], Train Loss: 0.005681
Validation Loss: 0.00503448
Epoch [201/300], Train Loss: 0.005658
Validation Loss: 0.00503353
Epoch [202/300], Train Loss: 0.005634
Validation Loss: 0.00503822
Epoch [203/300], Train Loss: 0.005649
Validation Loss: 0.00503057
Epoch [204/300], Train Loss: 0.005643
Validation Loss: 0.00503084
Epoch [205/300], Train Loss: 0.005669
Validation Loss: 0.00503595
Epoch [206/300], Train Loss: 0.005657
Validation Loss: 0.00504161
Epoch [207/300], Train Loss: 0.005664
Validation Loss: 0.00503056
Epoch [208/300], Train Loss: 0.005733
Validation Loss: 0.00502680
Epoch [209/300], Train Loss: 0.005656
Validation Loss: 0.00503959
Epoch [210/300], Train Loss: 0.005640
Validation Loss: 0.00503697
Epoch [211/300], Train Loss: 0.005674
Validation Loss: 0.00502758
Epoch [212/300], Train Loss: 0.005658
Validation Loss: 0.00502740
Epoch [213/300], Train Loss: 0.005646
Validation Loss: 0.00503183
Epoch [214/300], Train Loss: 0.005621
Validation Loss: 0.00503060
Epoch [215/300], Train Loss: 0.005642
Validation Loss: 0.00502947
Epoch [216/300], Train Loss: 0.005694
Validation Loss: 0.00502637
Epoch [217/300], Train Loss: 0.005660
Validation Loss: 0.00503380
Epoch [218/300], Train Loss: 0.005660
Validation Loss: 0.00502931
Epoch [219/300], Train Loss: 0.005650
Validation Loss: 0.00502695
Epoch [220/300], Train Loss: 0.005661
Validation Loss: 0.00503354
Epoch [221/300], Train Loss: 0.005648
Validation Loss: 0.00502655
Epoch [222/300], Train Loss: 0.005654
Validation Loss: 0.00502636
Epoch [223/300], Train Loss: 0.005638
Validation Loss: 0.00502541
Epoch [224/300], Train Loss: 0.005654
Validation Loss: 0.00502943
Epoch [225/300], Train Loss: 0.005643
Validation Loss: 0.00502630
Epoch [226/300], Train Loss: 0.005651
Validation Loss: 0.00502645
Epoch [227/300], Train Loss: 0.005637
Validation Loss: 0.00502386
Epoch [228/300], Train Loss: 0.005638
Validation Loss: 0.00502308
Epoch [229/300], Train Loss: 0.005631
Validation Loss: 0.00503326
Epoch [230/300], Train Loss: 0.005634
Validation Loss: 0.00502934
Epoch [231/300], Train Loss: 0.005649
Validation Loss: 0.00502000
Epoch [232/300], Train Loss: 0.005662
Validation Loss: 0.00502279
Epoch [233/300], Train Loss: 0.005634
Validation Loss: 0.00503069
Epoch [234/300], Train Loss: 0.005654
Validation Loss: 0.00502593
Epoch [235/300], Train Loss: 0.005626
Validation Loss: 0.00502065
Epoch [236/300], Train Loss: 0.005650
Validation Loss: 0.00502511
Epoch [237/300], Train Loss: 0.005623
Validation Loss: 0.00502278
Epoch [238/300], Train Loss: 0.005679
Validation Loss: 0.00501890
Epoch [239/300], Train Loss: 0.005687
Validation Loss: 0.00502140
Epoch [240/300], Train Loss: 0.005622
Validation Loss: 0.00502963
Epoch [241/300], Train Loss: 0.005616
Validation Loss: 0.00502337
Epoch [242/300], Train Loss: 0.005620
Validation Loss: 0.00502028
Epoch [243/300], Train Loss: 0.005656
Validation Loss: 0.00501943
Epoch [244/300], Train Loss: 0.005609
Validation Loss: 0.00501901
Epoch [245/300], Train Loss: 0.005645
Validation Loss: 0.00502195
Epoch [246/300], Train Loss: 0.005652
Validation Loss: 0.00502021
Epoch [247/300], Train Loss: 0.005645
Validation Loss: 0.00502441
Epoch [248/300], Train Loss: 0.005624
Validation Loss: 0.00501898
Early stopping triggered

Evaluating model for: Router
Run 18/72 completed in 281.67 seconds with: {'MAE': np.float32(0.20785922), 'MSE': np.float32(0.07796304), 'RMSE': np.float32(0.2792186), 'SAE': np.float32(4.104456e-05), 'NDE': np.float32(0.013957772)}

Run 19/72: hidden=128, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Router
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.079481
Validation Loss: 0.07469956
Epoch [2/300], Train Loss: 0.071211
Validation Loss: 0.06711665
Epoch [3/300], Train Loss: 0.063968
Validation Loss: 0.05983975
Epoch [4/300], Train Loss: 0.056432
Validation Loss: 0.05151302
Epoch [5/300], Train Loss: 0.047568
Validation Loss: 0.04201902
Epoch [6/300], Train Loss: 0.037026
Validation Loss: 0.02916193
Epoch [7/300], Train Loss: 0.021815
Validation Loss: 0.01090388
Epoch [8/300], Train Loss: 0.008112
Validation Loss: 0.00911969
Epoch [9/300], Train Loss: 0.008151
Validation Loss: 0.00520847
Epoch [10/300], Train Loss: 0.006273
Validation Loss: 0.00614207
Epoch [11/300], Train Loss: 0.006495
Validation Loss: 0.00537727
Epoch [12/300], Train Loss: 0.005915
Validation Loss: 0.00530980
Epoch [13/300], Train Loss: 0.006034
Validation Loss: 0.00521431
Epoch [14/300], Train Loss: 0.005906
Validation Loss: 0.00525446
Epoch [15/300], Train Loss: 0.005882
Validation Loss: 0.00521634
Epoch [16/300], Train Loss: 0.005897
Validation Loss: 0.00518964
Epoch [17/300], Train Loss: 0.005843
Validation Loss: 0.00518865
Epoch [18/300], Train Loss: 0.005850
Validation Loss: 0.00519094
Epoch [19/300], Train Loss: 0.005857
Validation Loss: 0.00519434
Epoch [20/300], Train Loss: 0.005891
Validation Loss: 0.00518815
Epoch [21/300], Train Loss: 0.005906
Validation Loss: 0.00518573
Epoch [22/300], Train Loss: 0.005880
Validation Loss: 0.00519136
Epoch [23/300], Train Loss: 0.005864
Validation Loss: 0.00518554
Epoch [24/300], Train Loss: 0.005891
Validation Loss: 0.00518195
Epoch [25/300], Train Loss: 0.005852
Validation Loss: 0.00518750
Epoch [26/300], Train Loss: 0.005861
Validation Loss: 0.00518549
Epoch [27/300], Train Loss: 0.005831
Validation Loss: 0.00517882
Epoch [28/300], Train Loss: 0.005820
Validation Loss: 0.00518154
Epoch [29/300], Train Loss: 0.005838
Validation Loss: 0.00518113
Epoch [30/300], Train Loss: 0.005813
Validation Loss: 0.00517772
Epoch [31/300], Train Loss: 0.005827
Validation Loss: 0.00517621
Epoch [32/300], Train Loss: 0.005852
Validation Loss: 0.00517784
Epoch [33/300], Train Loss: 0.005836
Validation Loss: 0.00517999
Epoch [34/300], Train Loss: 0.005833
Validation Loss: 0.00517206
Epoch [35/300], Train Loss: 0.005825
Validation Loss: 0.00517045
Epoch [36/300], Train Loss: 0.005795
Validation Loss: 0.00517584
Epoch [37/300], Train Loss: 0.005811
Validation Loss: 0.00516971
Epoch [38/300], Train Loss: 0.005828
Validation Loss: 0.00516703
Epoch [39/300], Train Loss: 0.005843
Validation Loss: 0.00517185
Epoch [40/300], Train Loss: 0.005863
Validation Loss: 0.00516915
Epoch [41/300], Train Loss: 0.005835
Validation Loss: 0.00516663
Epoch [42/300], Train Loss: 0.005826
Validation Loss: 0.00516494
Epoch [43/300], Train Loss: 0.005811
Validation Loss: 0.00516151
Epoch [44/300], Train Loss: 0.005818
Validation Loss: 0.00516112
Epoch [45/300], Train Loss: 0.005812
Validation Loss: 0.00516948
Epoch [46/300], Train Loss: 0.005806
Validation Loss: 0.00515990
Epoch [47/300], Train Loss: 0.005825
Validation Loss: 0.00515711
Epoch [48/300], Train Loss: 0.005792
Validation Loss: 0.00516281
Epoch [49/300], Train Loss: 0.005783
Validation Loss: 0.00515485
Epoch [50/300], Train Loss: 0.005804
Validation Loss: 0.00515543
Epoch [51/300], Train Loss: 0.005827
Validation Loss: 0.00515620
Epoch [52/300], Train Loss: 0.005774
Validation Loss: 0.00515844
Epoch [53/300], Train Loss: 0.005799
Validation Loss: 0.00515266
Epoch [54/300], Train Loss: 0.005787
Validation Loss: 0.00514970
Epoch [55/300], Train Loss: 0.005802
Validation Loss: 0.00515565
Epoch [56/300], Train Loss: 0.005804
Validation Loss: 0.00515214
Epoch [57/300], Train Loss: 0.005781
Validation Loss: 0.00514799
Epoch [58/300], Train Loss: 0.005805
Validation Loss: 0.00514878
Epoch [59/300], Train Loss: 0.005783
Validation Loss: 0.00514536
Epoch [60/300], Train Loss: 0.005803
Validation Loss: 0.00514770
Epoch [61/300], Train Loss: 0.005806
Validation Loss: 0.00514604
Epoch [62/300], Train Loss: 0.005777
Validation Loss: 0.00514764
Epoch [63/300], Train Loss: 0.005790
Validation Loss: 0.00514261
Epoch [64/300], Train Loss: 0.005783
Validation Loss: 0.00514278
Epoch [65/300], Train Loss: 0.005805
Validation Loss: 0.00514132
Epoch [66/300], Train Loss: 0.005795
Validation Loss: 0.00514149
Epoch [67/300], Train Loss: 0.005799
Validation Loss: 0.00514016
Epoch [68/300], Train Loss: 0.005791
Validation Loss: 0.00514677
Epoch [69/300], Train Loss: 0.005802
Validation Loss: 0.00513557
Epoch [70/300], Train Loss: 0.005826
Validation Loss: 0.00513411
Epoch [71/300], Train Loss: 0.005791
Validation Loss: 0.00515219
Epoch [72/300], Train Loss: 0.005808
Validation Loss: 0.00513744
Epoch [73/300], Train Loss: 0.005785
Validation Loss: 0.00513115
Epoch [74/300], Train Loss: 0.005749
Validation Loss: 0.00513470
Epoch [75/300], Train Loss: 0.005812
Validation Loss: 0.00513777
Epoch [76/300], Train Loss: 0.005735
Validation Loss: 0.00512808
Epoch [77/300], Train Loss: 0.005791
Validation Loss: 0.00512806
Epoch [78/300], Train Loss: 0.005741
Validation Loss: 0.00512740
Epoch [79/300], Train Loss: 0.005807
Validation Loss: 0.00513541
Epoch [80/300], Train Loss: 0.005761
Validation Loss: 0.00512434
Epoch [81/300], Train Loss: 0.005782
Validation Loss: 0.00512397
Epoch [82/300], Train Loss: 0.005770
Validation Loss: 0.00512926
Epoch [83/300], Train Loss: 0.005762
Validation Loss: 0.00512409
Epoch [84/300], Train Loss: 0.005732
Validation Loss: 0.00512055
Epoch [85/300], Train Loss: 0.005793
Validation Loss: 0.00512105
Epoch [86/300], Train Loss: 0.005762
Validation Loss: 0.00512871
Epoch [87/300], Train Loss: 0.005742
Validation Loss: 0.00511697
Epoch [88/300], Train Loss: 0.005784
Validation Loss: 0.00511630
Epoch [89/300], Train Loss: 0.005759
Validation Loss: 0.00513452
Epoch [90/300], Train Loss: 0.005741
Validation Loss: 0.00512009
Epoch [91/300], Train Loss: 0.005725
Validation Loss: 0.00511317
Epoch [92/300], Train Loss: 0.005753
Validation Loss: 0.00512270
Epoch [93/300], Train Loss: 0.005724
Validation Loss: 0.00511698
Epoch [94/300], Train Loss: 0.005754
Validation Loss: 0.00511057
Epoch [95/300], Train Loss: 0.005720
Validation Loss: 0.00511811
Epoch [96/300], Train Loss: 0.005787
Validation Loss: 0.00511524
Epoch [97/300], Train Loss: 0.005743
Validation Loss: 0.00510868
Epoch [98/300], Train Loss: 0.005725
Validation Loss: 0.00510966
Epoch [99/300], Train Loss: 0.005745
Validation Loss: 0.00510905
Epoch [100/300], Train Loss: 0.005710
Validation Loss: 0.00510983
Epoch [101/300], Train Loss: 0.005739
Validation Loss: 0.00510578
Epoch [102/300], Train Loss: 0.005733
Validation Loss: 0.00510621
Epoch [103/300], Train Loss: 0.005730
Validation Loss: 0.00510888
Epoch [104/300], Train Loss: 0.005744
Validation Loss: 0.00510184
Epoch [105/300], Train Loss: 0.005720
Validation Loss: 0.00510445
Epoch [106/300], Train Loss: 0.005746
Validation Loss: 0.00510607
Epoch [107/300], Train Loss: 0.005724
Validation Loss: 0.00510144
Epoch [108/300], Train Loss: 0.005736
Validation Loss: 0.00510323
Epoch [109/300], Train Loss: 0.005711
Validation Loss: 0.00509884
Epoch [110/300], Train Loss: 0.005722
Validation Loss: 0.00509979
Epoch [111/300], Train Loss: 0.005735
Validation Loss: 0.00509880
Epoch [112/300], Train Loss: 0.005721
Validation Loss: 0.00510364
Epoch [113/300], Train Loss: 0.005733
Validation Loss: 0.00509726
Epoch [114/300], Train Loss: 0.005752
Validation Loss: 0.00509414
Epoch [115/300], Train Loss: 0.005706
Validation Loss: 0.00510414
Epoch [116/300], Train Loss: 0.005712
Validation Loss: 0.00509740
Epoch [117/300], Train Loss: 0.005700
Validation Loss: 0.00509154
Epoch [118/300], Train Loss: 0.005726
Validation Loss: 0.00509942
Epoch [119/300], Train Loss: 0.005703
Validation Loss: 0.00509302
Epoch [120/300], Train Loss: 0.005724
Validation Loss: 0.00508912
Epoch [121/300], Train Loss: 0.005733
Validation Loss: 0.00509777
Epoch [122/300], Train Loss: 0.005720
Validation Loss: 0.00509549
Epoch [123/300], Train Loss: 0.005702
Validation Loss: 0.00508879
Epoch [124/300], Train Loss: 0.005702
Validation Loss: 0.00508710
Epoch [125/300], Train Loss: 0.005704
Validation Loss: 0.00509398
Epoch [126/300], Train Loss: 0.005695
Validation Loss: 0.00508976
Epoch [127/300], Train Loss: 0.005713
Validation Loss: 0.00508382
Epoch [128/300], Train Loss: 0.005742
Validation Loss: 0.00508943
Epoch [129/300], Train Loss: 0.005686
Validation Loss: 0.00508904
Epoch [130/300], Train Loss: 0.005692
Validation Loss: 0.00508249
Epoch [131/300], Train Loss: 0.005711
Validation Loss: 0.00508306
Epoch [132/300], Train Loss: 0.005686
Validation Loss: 0.00508649
Epoch [133/300], Train Loss: 0.005689
Validation Loss: 0.00508550
Epoch [134/300], Train Loss: 0.005681
Validation Loss: 0.00507974
Epoch [135/300], Train Loss: 0.005675
Validation Loss: 0.00507873
Epoch [136/300], Train Loss: 0.005665
Validation Loss: 0.00508176
Epoch [137/300], Train Loss: 0.005702
Validation Loss: 0.00508036
Epoch [138/300], Train Loss: 0.005690
Validation Loss: 0.00508740
Epoch [139/300], Train Loss: 0.005682
Validation Loss: 0.00507581
Epoch [140/300], Train Loss: 0.005687
Validation Loss: 0.00507721
Epoch [141/300], Train Loss: 0.005677
Validation Loss: 0.00508097
Epoch [142/300], Train Loss: 0.005704
Validation Loss: 0.00507479
Epoch [143/300], Train Loss: 0.005672
Validation Loss: 0.00507985
Epoch [144/300], Train Loss: 0.005653
Validation Loss: 0.00507369
Epoch [145/300], Train Loss: 0.005668
Validation Loss: 0.00507688
Epoch [146/300], Train Loss: 0.005681
Validation Loss: 0.00507701
Epoch [147/300], Train Loss: 0.005684
Validation Loss: 0.00507064
Epoch [148/300], Train Loss: 0.005700
Validation Loss: 0.00507070
Epoch [149/300], Train Loss: 0.005687
Validation Loss: 0.00508004
Epoch [150/300], Train Loss: 0.005666
Validation Loss: 0.00507142
Epoch [151/300], Train Loss: 0.005666
Validation Loss: 0.00506832
Epoch [152/300], Train Loss: 0.005680
Validation Loss: 0.00507112
Epoch [153/300], Train Loss: 0.005652
Validation Loss: 0.00507135
Epoch [154/300], Train Loss: 0.005646
Validation Loss: 0.00506863
Epoch [155/300], Train Loss: 0.005685
Validation Loss: 0.00506818
Epoch [156/300], Train Loss: 0.005701
Validation Loss: 0.00506756
Epoch [157/300], Train Loss: 0.005683
Validation Loss: 0.00506877
Epoch [158/300], Train Loss: 0.005659
Validation Loss: 0.00506689
Epoch [159/300], Train Loss: 0.005659
Validation Loss: 0.00506488
Epoch [160/300], Train Loss: 0.005678
Validation Loss: 0.00506520
Epoch [161/300], Train Loss: 0.005674
Validation Loss: 0.00506756
Epoch [162/300], Train Loss: 0.005650
Validation Loss: 0.00506720
Epoch [163/300], Train Loss: 0.005688
Validation Loss: 0.00506086
Epoch [164/300], Train Loss: 0.005704
Validation Loss: 0.00506795
Epoch [165/300], Train Loss: 0.005673
Validation Loss: 0.00505935
Epoch [166/300], Train Loss: 0.005666
Validation Loss: 0.00506793
Epoch [167/300], Train Loss: 0.005653
Validation Loss: 0.00506267
Epoch [168/300], Train Loss: 0.005659
Validation Loss: 0.00506035
Epoch [169/300], Train Loss: 0.005629
Validation Loss: 0.00505742
Epoch [170/300], Train Loss: 0.005680
Validation Loss: 0.00505998
Epoch [171/300], Train Loss: 0.005657
Validation Loss: 0.00506033
Epoch [172/300], Train Loss: 0.005681
Validation Loss: 0.00505809
Epoch [173/300], Train Loss: 0.005641
Validation Loss: 0.00506189
Epoch [174/300], Train Loss: 0.005674
Validation Loss: 0.00505584
Epoch [175/300], Train Loss: 0.005665
Validation Loss: 0.00506236
Epoch [176/300], Train Loss: 0.005676
Validation Loss: 0.00505568
Epoch [177/300], Train Loss: 0.005657
Validation Loss: 0.00505651
Epoch [178/300], Train Loss: 0.005674
Validation Loss: 0.00505723
Epoch [179/300], Train Loss: 0.005688
Validation Loss: 0.00505692
Epoch [180/300], Train Loss: 0.005635
Validation Loss: 0.00505581
Epoch [181/300], Train Loss: 0.005662
Validation Loss: 0.00505345
Epoch [182/300], Train Loss: 0.005648
Validation Loss: 0.00505188
Epoch [183/300], Train Loss: 0.005635
Validation Loss: 0.00505256
Epoch [184/300], Train Loss: 0.005648
Validation Loss: 0.00505800
Epoch [185/300], Train Loss: 0.005659
Validation Loss: 0.00505109
Epoch [186/300], Train Loss: 0.005692
Validation Loss: 0.00504870
Epoch [187/300], Train Loss: 0.005661
Validation Loss: 0.00505622
Epoch [188/300], Train Loss: 0.005624
Validation Loss: 0.00505309
Epoch [189/300], Train Loss: 0.005687
Validation Loss: 0.00504705
Epoch [190/300], Train Loss: 0.005606
Validation Loss: 0.00504705
Epoch [191/300], Train Loss: 0.005639
Validation Loss: 0.00505100
Epoch [192/300], Train Loss: 0.005630
Validation Loss: 0.00504869
Epoch [193/300], Train Loss: 0.005661
Validation Loss: 0.00504873
Epoch [194/300], Train Loss: 0.005615
Validation Loss: 0.00504786
Epoch [195/300], Train Loss: 0.005637
Validation Loss: 0.00504618
Epoch [196/300], Train Loss: 0.005675
Validation Loss: 0.00505156
Epoch [197/300], Train Loss: 0.005666
Validation Loss: 0.00504335
Epoch [198/300], Train Loss: 0.005637
Validation Loss: 0.00504391
Epoch [199/300], Train Loss: 0.005628
Validation Loss: 0.00504931
Epoch [200/300], Train Loss: 0.005671
Validation Loss: 0.00504371
Epoch [201/300], Train Loss: 0.005638
Validation Loss: 0.00504260
Epoch [202/300], Train Loss: 0.005623
Validation Loss: 0.00504853
Epoch [203/300], Train Loss: 0.005638
Validation Loss: 0.00504022
Epoch [204/300], Train Loss: 0.005629
Validation Loss: 0.00504128
Epoch [205/300], Train Loss: 0.005652
Validation Loss: 0.00504686
Epoch [206/300], Train Loss: 0.005641
Validation Loss: 0.00504918
Epoch [207/300], Train Loss: 0.005643
Validation Loss: 0.00503858
Epoch [208/300], Train Loss: 0.005720
Validation Loss: 0.00503782
Epoch [209/300], Train Loss: 0.005639
Validation Loss: 0.00505668
Epoch [210/300], Train Loss: 0.005630
Validation Loss: 0.00504382
Epoch [211/300], Train Loss: 0.005658
Validation Loss: 0.00503645
Epoch [212/300], Train Loss: 0.005644
Validation Loss: 0.00503770
Epoch [213/300], Train Loss: 0.005629
Validation Loss: 0.00504368
Epoch [214/300], Train Loss: 0.005603
Validation Loss: 0.00503898
Epoch [215/300], Train Loss: 0.005624
Validation Loss: 0.00503764
Epoch [216/300], Train Loss: 0.005677
Validation Loss: 0.00503590
Epoch [217/300], Train Loss: 0.005648
Validation Loss: 0.00504458
Epoch [218/300], Train Loss: 0.005642
Validation Loss: 0.00503743
Epoch [219/300], Train Loss: 0.005636
Validation Loss: 0.00503588
Epoch [220/300], Train Loss: 0.005644
Validation Loss: 0.00504416
Epoch [221/300], Train Loss: 0.005629
Validation Loss: 0.00503515
Epoch [222/300], Train Loss: 0.005636
Validation Loss: 0.00503507
Epoch [223/300], Train Loss: 0.005616
Validation Loss: 0.00503479
Epoch [224/300], Train Loss: 0.005633
Validation Loss: 0.00503880
Epoch [225/300], Train Loss: 0.005623
Validation Loss: 0.00503439
Epoch [226/300], Train Loss: 0.005630
Validation Loss: 0.00503462
Epoch [227/300], Train Loss: 0.005620
Validation Loss: 0.00503281
Epoch [228/300], Train Loss: 0.005628
Validation Loss: 0.00503267
Epoch [229/300], Train Loss: 0.005611
Validation Loss: 0.00504367
Epoch [230/300], Train Loss: 0.005612
Validation Loss: 0.00503569
Epoch [231/300], Train Loss: 0.005633
Validation Loss: 0.00502976
Epoch [232/300], Train Loss: 0.005641
Validation Loss: 0.00503305
Epoch [233/300], Train Loss: 0.005618
Validation Loss: 0.00504157
Epoch [234/300], Train Loss: 0.005630
Validation Loss: 0.00503255
Epoch [235/300], Train Loss: 0.005608
Validation Loss: 0.00502884
Epoch [236/300], Train Loss: 0.005632
Validation Loss: 0.00503496
Epoch [237/300], Train Loss: 0.005609
Validation Loss: 0.00503180
Epoch [238/300], Train Loss: 0.005667
Validation Loss: 0.00502785
Epoch [239/300], Train Loss: 0.005662
Validation Loss: 0.00503040
Epoch [240/300], Train Loss: 0.005609
Validation Loss: 0.00503927
Epoch [241/300], Train Loss: 0.005600
Validation Loss: 0.00503030
Epoch [242/300], Train Loss: 0.005606
Validation Loss: 0.00502781
Epoch [243/300], Train Loss: 0.005640
Validation Loss: 0.00502810
Epoch [244/300], Train Loss: 0.005587
Validation Loss: 0.00502803
Epoch [245/300], Train Loss: 0.005621
Validation Loss: 0.00503017
Epoch [246/300], Train Loss: 0.005630
Validation Loss: 0.00502752
Epoch [247/300], Train Loss: 0.005630
Validation Loss: 0.00503185
Epoch [248/300], Train Loss: 0.005605
Validation Loss: 0.00502676
Epoch [249/300], Train Loss: 0.005626
Validation Loss: 0.00502745
Epoch [250/300], Train Loss: 0.005623
Validation Loss: 0.00502765
Epoch [251/300], Train Loss: 0.005607
Validation Loss: 0.00502587
Epoch [252/300], Train Loss: 0.005584
Validation Loss: 0.00502715
Epoch [253/300], Train Loss: 0.005611
Validation Loss: 0.00502741
Epoch [254/300], Train Loss: 0.005587
Validation Loss: 0.00502747
Epoch [255/300], Train Loss: 0.005649
Validation Loss: 0.00502835
Epoch [256/300], Train Loss: 0.005594
Validation Loss: 0.00502627
Epoch [257/300], Train Loss: 0.005649
Validation Loss: 0.00502378
Epoch [258/300], Train Loss: 0.005598
Validation Loss: 0.00502646
Epoch [259/300], Train Loss: 0.005612
Validation Loss: 0.00502648
Epoch [260/300], Train Loss: 0.005615
Validation Loss: 0.00502589
Epoch [261/300], Train Loss: 0.005586
Validation Loss: 0.00502479
Epoch [262/300], Train Loss: 0.005599
Validation Loss: 0.00502510
Epoch [263/300], Train Loss: 0.005641
Validation Loss: 0.00502286
Epoch [264/300], Train Loss: 0.005604
Validation Loss: 0.00502515
Epoch [265/300], Train Loss: 0.005611
Validation Loss: 0.00502272
Epoch [266/300], Train Loss: 0.005605
Validation Loss: 0.00502160
Epoch [267/300], Train Loss: 0.005627
Validation Loss: 0.00502820
Epoch [268/300], Train Loss: 0.005596
Validation Loss: 0.00502256
Epoch [269/300], Train Loss: 0.005628
Validation Loss: 0.00502023
Epoch [270/300], Train Loss: 0.005590
Validation Loss: 0.00502217
Epoch [271/300], Train Loss: 0.005577
Validation Loss: 0.00502168
Epoch [272/300], Train Loss: 0.005600
Validation Loss: 0.00502034
Epoch [273/300], Train Loss: 0.005600
Validation Loss: 0.00502238
Epoch [274/300], Train Loss: 0.005590
Validation Loss: 0.00501850
Epoch [275/300], Train Loss: 0.005605
Validation Loss: 0.00501892
Epoch [276/300], Train Loss: 0.005579
Validation Loss: 0.00502054
Epoch [277/300], Train Loss: 0.005600
Validation Loss: 0.00502096
Epoch [278/300], Train Loss: 0.005583
Validation Loss: 0.00502101
Epoch [279/300], Train Loss: 0.005564
Validation Loss: 0.00501783
Epoch [280/300], Train Loss: 0.005596
Validation Loss: 0.00501777
Epoch [281/300], Train Loss: 0.005591
Validation Loss: 0.00502137
Epoch [282/300], Train Loss: 0.005602
Validation Loss: 0.00501733
Epoch [283/300], Train Loss: 0.005596
Validation Loss: 0.00501783
Epoch [284/300], Train Loss: 0.005624
Validation Loss: 0.00501932
Epoch [285/300], Train Loss: 0.005593
Validation Loss: 0.00502060
Epoch [286/300], Train Loss: 0.005597
Validation Loss: 0.00501689
Epoch [287/300], Train Loss: 0.005616
Validation Loss: 0.00501527
Epoch [288/300], Train Loss: 0.005586
Validation Loss: 0.00501879
Epoch [289/300], Train Loss: 0.005602
Validation Loss: 0.00501885
Epoch [290/300], Train Loss: 0.005618
Validation Loss: 0.00501657
Epoch [291/300], Train Loss: 0.005595
Validation Loss: 0.00501639
Epoch [292/300], Train Loss: 0.005577
Validation Loss: 0.00501890
Epoch [293/300], Train Loss: 0.005600
Validation Loss: 0.00501617
Epoch [294/300], Train Loss: 0.005592
Validation Loss: 0.00501959
Epoch [295/300], Train Loss: 0.005585
Validation Loss: 0.00501392
Epoch [296/300], Train Loss: 0.005619
Validation Loss: 0.00501257
Epoch [297/300], Train Loss: 0.005581
Validation Loss: 0.00501661
Epoch [298/300], Train Loss: 0.005591
Validation Loss: 0.00502018
Epoch [299/300], Train Loss: 0.005573
Validation Loss: 0.00501630
Epoch [300/300], Train Loss: 0.005589
Validation Loss: 0.00501360

Evaluating model for: Router
Run 19/72 completed in 371.65 seconds with: {'MAE': np.float32(0.20811424), 'MSE': np.float32(0.07793211), 'RMSE': np.float32(0.27916324), 'SAE': np.float32(0.0001082895), 'NDE': np.float32(0.0139550045)}

Run 20/72: hidden=128, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Router
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.082445
Validation Loss: 0.07784223
Epoch [2/300], Train Loss: 0.074161
Validation Loss: 0.06959346
Epoch [3/300], Train Loss: 0.065721
Validation Loss: 0.06047663
Epoch [4/300], Train Loss: 0.056316
Validation Loss: 0.05005906
Epoch [5/300], Train Loss: 0.044698
Validation Loss: 0.03666916
Epoch [6/300], Train Loss: 0.029609
Validation Loss: 0.01857909
Epoch [7/300], Train Loss: 0.011404
Validation Loss: 0.00589616
Epoch [8/300], Train Loss: 0.009199
Validation Loss: 0.00641525
Epoch [9/300], Train Loss: 0.006463
Validation Loss: 0.00609035
Epoch [10/300], Train Loss: 0.006899
Validation Loss: 0.00594434
Epoch [11/300], Train Loss: 0.006267
Validation Loss: 0.00532557
Epoch [12/300], Train Loss: 0.006168
Validation Loss: 0.00545058
Epoch [13/300], Train Loss: 0.006145
Validation Loss: 0.00532033
Epoch [14/300], Train Loss: 0.006115
Validation Loss: 0.00538051
Epoch [15/300], Train Loss: 0.006059
Validation Loss: 0.00531588
Epoch [16/300], Train Loss: 0.006088
Validation Loss: 0.00531195
Epoch [17/300], Train Loss: 0.006033
Validation Loss: 0.00531070
Epoch [18/300], Train Loss: 0.006038
Validation Loss: 0.00531174
Epoch [19/300], Train Loss: 0.006053
Validation Loss: 0.00531126
Epoch [20/300], Train Loss: 0.006067
Validation Loss: 0.00530690
Epoch [21/300], Train Loss: 0.006098
Validation Loss: 0.00530504
Epoch [22/300], Train Loss: 0.006076
Validation Loss: 0.00530971
Epoch [23/300], Train Loss: 0.006050
Validation Loss: 0.00530261
Epoch [24/300], Train Loss: 0.006073
Validation Loss: 0.00529935
Epoch [25/300], Train Loss: 0.006036
Validation Loss: 0.00530291
Epoch [26/300], Train Loss: 0.006045
Validation Loss: 0.00530186
Epoch [27/300], Train Loss: 0.006010
Validation Loss: 0.00529439
Epoch [28/300], Train Loss: 0.006001
Validation Loss: 0.00529592
Epoch [29/300], Train Loss: 0.006027
Validation Loss: 0.00529489
Epoch [30/300], Train Loss: 0.005993
Validation Loss: 0.00529128
Epoch [31/300], Train Loss: 0.006013
Validation Loss: 0.00528944
Epoch [32/300], Train Loss: 0.006029
Validation Loss: 0.00528961
Epoch [33/300], Train Loss: 0.006007
Validation Loss: 0.00529076
Epoch [34/300], Train Loss: 0.006016
Validation Loss: 0.00528301
Epoch [35/300], Train Loss: 0.006006
Validation Loss: 0.00528062
Epoch [36/300], Train Loss: 0.005971
Validation Loss: 0.00528460
Epoch [37/300], Train Loss: 0.005982
Validation Loss: 0.00527813
Epoch [38/300], Train Loss: 0.005997
Validation Loss: 0.00527463
Epoch [39/300], Train Loss: 0.006025
Validation Loss: 0.00527802
Epoch [40/300], Train Loss: 0.006030
Validation Loss: 0.00527486
Epoch [41/300], Train Loss: 0.006011
Validation Loss: 0.00527160
Epoch [42/300], Train Loss: 0.005998
Validation Loss: 0.00526866
Epoch [43/300], Train Loss: 0.005981
Validation Loss: 0.00526399
Epoch [44/300], Train Loss: 0.005992
Validation Loss: 0.00526267
Epoch [45/300], Train Loss: 0.005975
Validation Loss: 0.00527058
Epoch [46/300], Train Loss: 0.005976
Validation Loss: 0.00525913
Epoch [47/300], Train Loss: 0.005999
Validation Loss: 0.00525546
Epoch [48/300], Train Loss: 0.005952
Validation Loss: 0.00526002
Epoch [49/300], Train Loss: 0.005954
Validation Loss: 0.00525077
Epoch [50/300], Train Loss: 0.005966
Validation Loss: 0.00525051
Epoch [51/300], Train Loss: 0.005999
Validation Loss: 0.00525007
Epoch [52/300], Train Loss: 0.005941
Validation Loss: 0.00525157
Epoch [53/300], Train Loss: 0.005959
Validation Loss: 0.00524401
Epoch [54/300], Train Loss: 0.005949
Validation Loss: 0.00523949
Epoch [55/300], Train Loss: 0.005971
Validation Loss: 0.00524522
Epoch [56/300], Train Loss: 0.005964
Validation Loss: 0.00523990
Epoch [57/300], Train Loss: 0.005930
Validation Loss: 0.00523400
Epoch [58/300], Train Loss: 0.005970
Validation Loss: 0.00523371
Epoch [59/300], Train Loss: 0.005936
Validation Loss: 0.00522824
Epoch [60/300], Train Loss: 0.005947
Validation Loss: 0.00522978
Epoch [61/300], Train Loss: 0.005964
Validation Loss: 0.00522627
Epoch [62/300], Train Loss: 0.005937
Validation Loss: 0.00522694
Epoch [63/300], Train Loss: 0.005940
Validation Loss: 0.00522001
Epoch [64/300], Train Loss: 0.005932
Validation Loss: 0.00521886
Epoch [65/300], Train Loss: 0.005953
Validation Loss: 0.00521545
Epoch [66/300], Train Loss: 0.005936
Validation Loss: 0.00521472
Epoch [67/300], Train Loss: 0.005949
Validation Loss: 0.00521243
Epoch [68/300], Train Loss: 0.005945
Validation Loss: 0.00521742
Epoch [69/300], Train Loss: 0.005952
Validation Loss: 0.00520380
Epoch [70/300], Train Loss: 0.005975
Validation Loss: 0.00520177
Epoch [71/300], Train Loss: 0.005940
Validation Loss: 0.00522307
Epoch [72/300], Train Loss: 0.005956
Validation Loss: 0.00520066
Epoch [73/300], Train Loss: 0.005934
Validation Loss: 0.00519469
Epoch [74/300], Train Loss: 0.005887
Validation Loss: 0.00520005
Epoch [75/300], Train Loss: 0.005960
Validation Loss: 0.00519867
Epoch [76/300], Train Loss: 0.005885
Validation Loss: 0.00518749
Epoch [77/300], Train Loss: 0.005934
Validation Loss: 0.00518936
Epoch [78/300], Train Loss: 0.005891
Validation Loss: 0.00518601
Epoch [79/300], Train Loss: 0.005947
Validation Loss: 0.00519423
Epoch [80/300], Train Loss: 0.005906
Validation Loss: 0.00518044
Epoch [81/300], Train Loss: 0.005923
Validation Loss: 0.00518245
Epoch [82/300], Train Loss: 0.005905
Validation Loss: 0.00518648
Epoch [83/300], Train Loss: 0.005904
Validation Loss: 0.00517792
Epoch [84/300], Train Loss: 0.005870
Validation Loss: 0.00517507
Epoch [85/300], Train Loss: 0.005924
Validation Loss: 0.00517782
Epoch [86/300], Train Loss: 0.005889
Validation Loss: 0.00518221
Epoch [87/300], Train Loss: 0.005872
Validation Loss: 0.00516821
Epoch [88/300], Train Loss: 0.005914
Validation Loss: 0.00517085
Epoch [89/300], Train Loss: 0.005892
Validation Loss: 0.00519350
Epoch [90/300], Train Loss: 0.005872
Validation Loss: 0.00516832
Epoch [91/300], Train Loss: 0.005854
Validation Loss: 0.00516335
Epoch [92/300], Train Loss: 0.005882
Validation Loss: 0.00518417
Epoch [93/300], Train Loss: 0.005857
Validation Loss: 0.00516662
Epoch [94/300], Train Loss: 0.005884
Validation Loss: 0.00516006
Epoch [95/300], Train Loss: 0.005845
Validation Loss: 0.00517729
Epoch [96/300], Train Loss: 0.005914
Validation Loss: 0.00516533
Epoch [97/300], Train Loss: 0.005874
Validation Loss: 0.00515767
Epoch [98/300], Train Loss: 0.005855
Validation Loss: 0.00516239
Epoch [99/300], Train Loss: 0.005872
Validation Loss: 0.00515992
Epoch [100/300], Train Loss: 0.005830
Validation Loss: 0.00515942
Epoch [101/300], Train Loss: 0.005872
Validation Loss: 0.00515499
Epoch [102/300], Train Loss: 0.005865
Validation Loss: 0.00515778
Epoch [103/300], Train Loss: 0.005854
Validation Loss: 0.00515887
Epoch [104/300], Train Loss: 0.005886
Validation Loss: 0.00514894
Epoch [105/300], Train Loss: 0.005850
Validation Loss: 0.00515660
Epoch [106/300], Train Loss: 0.005865
Validation Loss: 0.00515419
Epoch [107/300], Train Loss: 0.005850
Validation Loss: 0.00514881
Epoch [108/300], Train Loss: 0.005855
Validation Loss: 0.00515435
Epoch [109/300], Train Loss: 0.005839
Validation Loss: 0.00514619
Epoch [110/300], Train Loss: 0.005839
Validation Loss: 0.00514742
Epoch [111/300], Train Loss: 0.005860
Validation Loss: 0.00514729
Epoch [112/300], Train Loss: 0.005842
Validation Loss: 0.00515365
Epoch [113/300], Train Loss: 0.005855
Validation Loss: 0.00514327
Epoch [114/300], Train Loss: 0.005879
Validation Loss: 0.00513944
Epoch [115/300], Train Loss: 0.005822
Validation Loss: 0.00515579
Epoch [116/300], Train Loss: 0.005832
Validation Loss: 0.00514245
Epoch [117/300], Train Loss: 0.005814
Validation Loss: 0.00513617
Epoch [118/300], Train Loss: 0.005846
Validation Loss: 0.00515171
Epoch [119/300], Train Loss: 0.005834
Validation Loss: 0.00513783
Epoch [120/300], Train Loss: 0.005845
Validation Loss: 0.00513216
Epoch [121/300], Train Loss: 0.005848
Validation Loss: 0.00515219
Epoch [122/300], Train Loss: 0.005845
Validation Loss: 0.00514150
Epoch [123/300], Train Loss: 0.005827
Validation Loss: 0.00513290
Epoch [124/300], Train Loss: 0.005818
Validation Loss: 0.00513315
Epoch [125/300], Train Loss: 0.005816
Validation Loss: 0.00514335
Epoch [126/300], Train Loss: 0.005814
Validation Loss: 0.00513389
Epoch [127/300], Train Loss: 0.005834
Validation Loss: 0.00512671
Epoch [128/300], Train Loss: 0.005860
Validation Loss: 0.00513966
Epoch [129/300], Train Loss: 0.005812
Validation Loss: 0.00513414
Epoch [130/300], Train Loss: 0.005805
Validation Loss: 0.00512580
Epoch [131/300], Train Loss: 0.005825
Validation Loss: 0.00512968
Epoch [132/300], Train Loss: 0.005807
Validation Loss: 0.00513324
Epoch [133/300], Train Loss: 0.005801
Validation Loss: 0.00512857
Epoch [134/300], Train Loss: 0.005801
Validation Loss: 0.00512269
Epoch [135/300], Train Loss: 0.005798
Validation Loss: 0.00512245
Epoch [136/300], Train Loss: 0.005783
Validation Loss: 0.00512687
Epoch [137/300], Train Loss: 0.005813
Validation Loss: 0.00512308
Epoch [138/300], Train Loss: 0.005808
Validation Loss: 0.00513346
Epoch [139/300], Train Loss: 0.005799
Validation Loss: 0.00511691
Epoch [140/300], Train Loss: 0.005791
Validation Loss: 0.00512168
Epoch [141/300], Train Loss: 0.005792
Validation Loss: 0.00512540
Epoch [142/300], Train Loss: 0.005816
Validation Loss: 0.00511574
Epoch [143/300], Train Loss: 0.005787
Validation Loss: 0.00512576
Epoch [144/300], Train Loss: 0.005766
Validation Loss: 0.00511557
Epoch [145/300], Train Loss: 0.005779
Validation Loss: 0.00511961
Epoch [146/300], Train Loss: 0.005795
Validation Loss: 0.00511912
Epoch [147/300], Train Loss: 0.005794
Validation Loss: 0.00511120
Epoch [148/300], Train Loss: 0.005819
Validation Loss: 0.00511301
Epoch [149/300], Train Loss: 0.005794
Validation Loss: 0.00512480
Epoch [150/300], Train Loss: 0.005774
Validation Loss: 0.00511043
Epoch [151/300], Train Loss: 0.005775
Validation Loss: 0.00510902
Epoch [152/300], Train Loss: 0.005790
Validation Loss: 0.00511520
Epoch [153/300], Train Loss: 0.005763
Validation Loss: 0.00511204
Epoch [154/300], Train Loss: 0.005760
Validation Loss: 0.00510831
Epoch [155/300], Train Loss: 0.005787
Validation Loss: 0.00510922
Epoch [156/300], Train Loss: 0.005802
Validation Loss: 0.00510765
Epoch [157/300], Train Loss: 0.005788
Validation Loss: 0.00510866
Epoch [158/300], Train Loss: 0.005757
Validation Loss: 0.00510709
Epoch [159/300], Train Loss: 0.005768
Validation Loss: 0.00510441
Epoch [160/300], Train Loss: 0.005772
Validation Loss: 0.00510493
Epoch [161/300], Train Loss: 0.005788
Validation Loss: 0.00510785
Epoch [162/300], Train Loss: 0.005752
Validation Loss: 0.00510635
Epoch [163/300], Train Loss: 0.005788
Validation Loss: 0.00509866
Epoch [164/300], Train Loss: 0.005812
Validation Loss: 0.00511070
Epoch [165/300], Train Loss: 0.005772
Validation Loss: 0.00509672
Epoch [166/300], Train Loss: 0.005778
Validation Loss: 0.00511101
Epoch [167/300], Train Loss: 0.005764
Validation Loss: 0.00510118
Epoch [168/300], Train Loss: 0.005760
Validation Loss: 0.00509822
Epoch [169/300], Train Loss: 0.005734
Validation Loss: 0.00509525
Epoch [170/300], Train Loss: 0.005789
Validation Loss: 0.00510030
Epoch [171/300], Train Loss: 0.005765
Validation Loss: 0.00509851
Epoch [172/300], Train Loss: 0.005785
Validation Loss: 0.00509520
Epoch [173/300], Train Loss: 0.005748
Validation Loss: 0.00510132
Epoch [174/300], Train Loss: 0.005780
Validation Loss: 0.00509285
Epoch [175/300], Train Loss: 0.005769
Validation Loss: 0.00510227
Epoch [176/300], Train Loss: 0.005782
Validation Loss: 0.00509189
Epoch [177/300], Train Loss: 0.005767
Validation Loss: 0.00509468
Epoch [178/300], Train Loss: 0.005780
Validation Loss: 0.00509583
Epoch [179/300], Train Loss: 0.005792
Validation Loss: 0.00509308
Epoch [180/300], Train Loss: 0.005746
Validation Loss: 0.00509216
Epoch [181/300], Train Loss: 0.005772
Validation Loss: 0.00509124
Epoch [182/300], Train Loss: 0.005743
Validation Loss: 0.00509000
Epoch [183/300], Train Loss: 0.005735
Validation Loss: 0.00508987
Epoch [184/300], Train Loss: 0.005748
Validation Loss: 0.00509536
Epoch [185/300], Train Loss: 0.005755
Validation Loss: 0.00508701
Epoch [186/300], Train Loss: 0.005789
Validation Loss: 0.00508469
Epoch [187/300], Train Loss: 0.005761
Validation Loss: 0.00509450
Epoch [188/300], Train Loss: 0.005721
Validation Loss: 0.00508857
Epoch [189/300], Train Loss: 0.005783
Validation Loss: 0.00508205
Epoch [190/300], Train Loss: 0.005711
Validation Loss: 0.00508288
Epoch [191/300], Train Loss: 0.005746
Validation Loss: 0.00508773
Epoch [192/300], Train Loss: 0.005723
Validation Loss: 0.00508380
Epoch [193/300], Train Loss: 0.005761
Validation Loss: 0.00508420
Epoch [194/300], Train Loss: 0.005713
Validation Loss: 0.00508395
Epoch [195/300], Train Loss: 0.005731
Validation Loss: 0.00508206
Epoch [196/300], Train Loss: 0.005779
Validation Loss: 0.00508730
Epoch [197/300], Train Loss: 0.005763
Validation Loss: 0.00507779
Epoch [198/300], Train Loss: 0.005732
Validation Loss: 0.00507889
Epoch [199/300], Train Loss: 0.005721
Validation Loss: 0.00508552
Epoch [200/300], Train Loss: 0.005760
Validation Loss: 0.00507801
Epoch [201/300], Train Loss: 0.005733
Validation Loss: 0.00507699
Epoch [202/300], Train Loss: 0.005719
Validation Loss: 0.00508384
Epoch [203/300], Train Loss: 0.005729
Validation Loss: 0.00507348
Epoch [204/300], Train Loss: 0.005722
Validation Loss: 0.00507519
Epoch [205/300], Train Loss: 0.005747
Validation Loss: 0.00508210
Epoch [206/300], Train Loss: 0.005736
Validation Loss: 0.00508232
Epoch [207/300], Train Loss: 0.005741
Validation Loss: 0.00507076
Epoch [208/300], Train Loss: 0.005816
Validation Loss: 0.00506972
Epoch [209/300], Train Loss: 0.005740
Validation Loss: 0.00509509
Epoch [210/300], Train Loss: 0.005719
Validation Loss: 0.00507458
Epoch [211/300], Train Loss: 0.005754
Validation Loss: 0.00506781
Epoch [212/300], Train Loss: 0.005730
Validation Loss: 0.00507093
Epoch [213/300], Train Loss: 0.005729
Validation Loss: 0.00507809
Epoch [214/300], Train Loss: 0.005693
Validation Loss: 0.00506958
Epoch [215/300], Train Loss: 0.005716
Validation Loss: 0.00506872
Epoch [216/300], Train Loss: 0.005764
Validation Loss: 0.00506760
Epoch [217/300], Train Loss: 0.005742
Validation Loss: 0.00507786
Epoch [218/300], Train Loss: 0.005729
Validation Loss: 0.00506777
Epoch [219/300], Train Loss: 0.005727
Validation Loss: 0.00506630
Epoch [220/300], Train Loss: 0.005736
Validation Loss: 0.00507725
Epoch [221/300], Train Loss: 0.005723
Validation Loss: 0.00506471
Epoch [222/300], Train Loss: 0.005728
Validation Loss: 0.00506489
Epoch [223/300], Train Loss: 0.005708
Validation Loss: 0.00506498
Epoch [224/300], Train Loss: 0.005730
Validation Loss: 0.00506956
Epoch [225/300], Train Loss: 0.005712
Validation Loss: 0.00506278
Epoch [226/300], Train Loss: 0.005717
Validation Loss: 0.00506369
Epoch [227/300], Train Loss: 0.005706
Validation Loss: 0.00506171
Epoch [228/300], Train Loss: 0.005712
Validation Loss: 0.00506164
Epoch [229/300], Train Loss: 0.005701
Validation Loss: 0.00507419
Epoch [230/300], Train Loss: 0.005696
Validation Loss: 0.00506340
Epoch [231/300], Train Loss: 0.005725
Validation Loss: 0.00505701
Epoch [232/300], Train Loss: 0.005731
Validation Loss: 0.00506284
Epoch [233/300], Train Loss: 0.005713
Validation Loss: 0.00507211
Epoch [234/300], Train Loss: 0.005721
Validation Loss: 0.00505916
Epoch [235/300], Train Loss: 0.005695
Validation Loss: 0.00505558
Epoch [236/300], Train Loss: 0.005724
Validation Loss: 0.00506470
Epoch [237/300], Train Loss: 0.005703
Validation Loss: 0.00505943
Epoch [238/300], Train Loss: 0.005748
Validation Loss: 0.00505417
Epoch [239/300], Train Loss: 0.005753
Validation Loss: 0.00505836
Epoch [240/300], Train Loss: 0.005690
Validation Loss: 0.00506763
Epoch [241/300], Train Loss: 0.005686
Validation Loss: 0.00505572
Epoch [242/300], Train Loss: 0.005695
Validation Loss: 0.00505373
Epoch [243/300], Train Loss: 0.005721
Validation Loss: 0.00505510
Epoch [244/300], Train Loss: 0.005677
Validation Loss: 0.00505456
Epoch [245/300], Train Loss: 0.005703
Validation Loss: 0.00505646
Epoch [246/300], Train Loss: 0.005710
Validation Loss: 0.00505310
Epoch [247/300], Train Loss: 0.005707
Validation Loss: 0.00505834
Epoch [248/300], Train Loss: 0.005684
Validation Loss: 0.00505176
Epoch [249/300], Train Loss: 0.005716
Validation Loss: 0.00505311
Epoch [250/300], Train Loss: 0.005709
Validation Loss: 0.00505280
Epoch [251/300], Train Loss: 0.005690
Validation Loss: 0.00505035
Epoch [252/300], Train Loss: 0.005665
Validation Loss: 0.00505238
Epoch [253/300], Train Loss: 0.005696
Validation Loss: 0.00505238
Epoch [254/300], Train Loss: 0.005673
Validation Loss: 0.00505194
Epoch [255/300], Train Loss: 0.005734
Validation Loss: 0.00505250
Epoch [256/300], Train Loss: 0.005676
Validation Loss: 0.00504999
Epoch [257/300], Train Loss: 0.005738
Validation Loss: 0.00504748
Epoch [258/300], Train Loss: 0.005686
Validation Loss: 0.00505115
Epoch [259/300], Train Loss: 0.005699
Validation Loss: 0.00505038
Epoch [260/300], Train Loss: 0.005699
Validation Loss: 0.00504870
Epoch [261/300], Train Loss: 0.005664
Validation Loss: 0.00504748
Epoch [262/300], Train Loss: 0.005683
Validation Loss: 0.00504820
Epoch [263/300], Train Loss: 0.005721
Validation Loss: 0.00504509
Epoch [264/300], Train Loss: 0.005691
Validation Loss: 0.00504782
Epoch [265/300], Train Loss: 0.005699
Validation Loss: 0.00504458
Epoch [266/300], Train Loss: 0.005686
Validation Loss: 0.00504319
Epoch [267/300], Train Loss: 0.005709
Validation Loss: 0.00505173
Epoch [268/300], Train Loss: 0.005678
Validation Loss: 0.00504373
Epoch [269/300], Train Loss: 0.005712
Validation Loss: 0.00504091
Epoch [270/300], Train Loss: 0.005673
Validation Loss: 0.00504385
Epoch [271/300], Train Loss: 0.005653
Validation Loss: 0.00504273
Epoch [272/300], Train Loss: 0.005686
Validation Loss: 0.00504098
Epoch [273/300], Train Loss: 0.005681
Validation Loss: 0.00504312
Epoch [274/300], Train Loss: 0.005671
Validation Loss: 0.00503817
Epoch [275/300], Train Loss: 0.005684
Validation Loss: 0.00503902
Epoch [276/300], Train Loss: 0.005656
Validation Loss: 0.00504124
Epoch [277/300], Train Loss: 0.005677
Validation Loss: 0.00504102
Epoch [278/300], Train Loss: 0.005672
Validation Loss: 0.00504077
Epoch [279/300], Train Loss: 0.005655
Validation Loss: 0.00503676
Epoch [280/300], Train Loss: 0.005678
Validation Loss: 0.00503677
Epoch [281/300], Train Loss: 0.005677
Validation Loss: 0.00504121
Epoch [282/300], Train Loss: 0.005687
Validation Loss: 0.00503567
Epoch [283/300], Train Loss: 0.005676
Validation Loss: 0.00503634
Epoch [284/300], Train Loss: 0.005699
Validation Loss: 0.00503860
Epoch [285/300], Train Loss: 0.005670
Validation Loss: 0.00503929
Epoch [286/300], Train Loss: 0.005674
Validation Loss: 0.00503441
Epoch [287/300], Train Loss: 0.005690
Validation Loss: 0.00503246
Epoch [288/300], Train Loss: 0.005656
Validation Loss: 0.00503754
Epoch [289/300], Train Loss: 0.005674
Validation Loss: 0.00503689
Epoch [290/300], Train Loss: 0.005694
Validation Loss: 0.00503352
Epoch [291/300], Train Loss: 0.005670
Validation Loss: 0.00503331
Epoch [292/300], Train Loss: 0.005662
Validation Loss: 0.00503643
Epoch [293/300], Train Loss: 0.005669
Validation Loss: 0.00503215
Epoch [294/300], Train Loss: 0.005676
Validation Loss: 0.00503621
Epoch [295/300], Train Loss: 0.005659
Validation Loss: 0.00502865
Epoch [296/300], Train Loss: 0.005699
Validation Loss: 0.00502720
Epoch [297/300], Train Loss: 0.005653
Validation Loss: 0.00503368
Epoch [298/300], Train Loss: 0.005671
Validation Loss: 0.00503717
Epoch [299/300], Train Loss: 0.005653
Validation Loss: 0.00503056
Epoch [300/300], Train Loss: 0.005666
Validation Loss: 0.00502742

Evaluating model for: Router
Run 20/72 completed in 393.81 seconds with: {'MAE': np.float32(0.20847383), 'MSE': np.float32(0.078322634), 'RMSE': np.float32(0.2798618), 'SAE': np.float32(0.0001052071), 'NDE': np.float32(0.013989924)}

Run 21/72: hidden=128, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Router
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.070121
Validation Loss: 0.06732121
Epoch [2/300], Train Loss: 0.066817
Validation Loss: 0.06397222
Epoch [3/300], Train Loss: 0.063888
Validation Loss: 0.06072485
Epoch [4/300], Train Loss: 0.060256
Validation Loss: 0.05760954
Epoch [5/300], Train Loss: 0.056473
Validation Loss: 0.05447963
Epoch [6/300], Train Loss: 0.053554
Validation Loss: 0.05123544
Epoch [7/300], Train Loss: 0.050559
Validation Loss: 0.04783346
Epoch [8/300], Train Loss: 0.046943
Validation Loss: 0.04425284
Epoch [9/300], Train Loss: 0.043017
Validation Loss: 0.04043277
Epoch [10/300], Train Loss: 0.039148
Validation Loss: 0.03626527
Epoch [11/300], Train Loss: 0.034859
Validation Loss: 0.03166243
Epoch [12/300], Train Loss: 0.029964
Validation Loss: 0.02667929
Epoch [13/300], Train Loss: 0.025019
Validation Loss: 0.02122363
Epoch [14/300], Train Loss: 0.019111
Validation Loss: 0.01545497
Epoch [15/300], Train Loss: 0.013405
Validation Loss: 0.00985346
Epoch [16/300], Train Loss: 0.008400
Validation Loss: 0.00635213
Epoch [17/300], Train Loss: 0.006158
Validation Loss: 0.00646424
Epoch [18/300], Train Loss: 0.007042
Validation Loss: 0.00757277
Epoch [19/300], Train Loss: 0.007002
Validation Loss: 0.00645526
Epoch [20/300], Train Loss: 0.006139
Validation Loss: 0.00587506
Epoch [21/300], Train Loss: 0.005870
Validation Loss: 0.00600361
Epoch [22/300], Train Loss: 0.006070
Validation Loss: 0.00611511
Epoch [23/300], Train Loss: 0.006194
Validation Loss: 0.00601988
Epoch [24/300], Train Loss: 0.005947
Validation Loss: 0.00588527
Epoch [25/300], Train Loss: 0.005800
Validation Loss: 0.00587194
Epoch [26/300], Train Loss: 0.005748
Validation Loss: 0.00591584
Epoch [27/300], Train Loss: 0.005887
Validation Loss: 0.00591065
Epoch [28/300], Train Loss: 0.005865
Validation Loss: 0.00587560
Epoch [29/300], Train Loss: 0.005939
Validation Loss: 0.00586095
Epoch [30/300], Train Loss: 0.005751
Validation Loss: 0.00586665
Epoch [31/300], Train Loss: 0.005759
Validation Loss: 0.00586304
Epoch [32/300], Train Loss: 0.005789
Validation Loss: 0.00585912
Epoch [33/300], Train Loss: 0.005948
Validation Loss: 0.00586611
Epoch [34/300], Train Loss: 0.005791
Validation Loss: 0.00586850
Epoch [35/300], Train Loss: 0.005809
Validation Loss: 0.00586395
Epoch [36/300], Train Loss: 0.005838
Validation Loss: 0.00586125
Epoch [37/300], Train Loss: 0.005776
Validation Loss: 0.00585738
Epoch [38/300], Train Loss: 0.005673
Validation Loss: 0.00585618
Epoch [39/300], Train Loss: 0.005769
Validation Loss: 0.00585742
Epoch [40/300], Train Loss: 0.005891
Validation Loss: 0.00585708
Epoch [41/300], Train Loss: 0.005843
Validation Loss: 0.00585410
Epoch [42/300], Train Loss: 0.005958
Validation Loss: 0.00585363
Epoch [43/300], Train Loss: 0.005906
Validation Loss: 0.00585370
Epoch [44/300], Train Loss: 0.005791
Validation Loss: 0.00585238
Epoch [45/300], Train Loss: 0.005779
Validation Loss: 0.00585172
Epoch [46/300], Train Loss: 0.005765
Validation Loss: 0.00585153
Epoch [47/300], Train Loss: 0.005840
Validation Loss: 0.00585334
Epoch [48/300], Train Loss: 0.005962
Validation Loss: 0.00585490
Epoch [49/300], Train Loss: 0.005845
Validation Loss: 0.00585249
Epoch [50/300], Train Loss: 0.005841
Validation Loss: 0.00584945
Epoch [51/300], Train Loss: 0.005834
Validation Loss: 0.00584832
Epoch [52/300], Train Loss: 0.005867
Validation Loss: 0.00584842
Epoch [53/300], Train Loss: 0.005847
Validation Loss: 0.00584764
Epoch [54/300], Train Loss: 0.005797
Validation Loss: 0.00584685
Epoch [55/300], Train Loss: 0.005835
Validation Loss: 0.00584672
Epoch [56/300], Train Loss: 0.005832
Validation Loss: 0.00584600
Epoch [57/300], Train Loss: 0.005913
Validation Loss: 0.00584483
Epoch [58/300], Train Loss: 0.005760
Validation Loss: 0.00584418
Epoch [59/300], Train Loss: 0.005799
Validation Loss: 0.00584502
Epoch [60/300], Train Loss: 0.005797
Validation Loss: 0.00584319
Epoch [61/300], Train Loss: 0.005751
Validation Loss: 0.00584454
Epoch [62/300], Train Loss: 0.005882
Validation Loss: 0.00585126
Epoch [63/300], Train Loss: 0.005677
Validation Loss: 0.00584608
Epoch [64/300], Train Loss: 0.005886
Validation Loss: 0.00584109
Epoch [65/300], Train Loss: 0.005723
Validation Loss: 0.00584055
Epoch [66/300], Train Loss: 0.005910
Validation Loss: 0.00584093
Epoch [67/300], Train Loss: 0.005747
Validation Loss: 0.00584026
Epoch [68/300], Train Loss: 0.005749
Validation Loss: 0.00583879
Epoch [69/300], Train Loss: 0.005778
Validation Loss: 0.00583837
Epoch [70/300], Train Loss: 0.005802
Validation Loss: 0.00583797
Epoch [71/300], Train Loss: 0.005852
Validation Loss: 0.00583723
Epoch [72/300], Train Loss: 0.005640
Validation Loss: 0.00583674
Epoch [73/300], Train Loss: 0.005704
Validation Loss: 0.00583826
Epoch [74/300], Train Loss: 0.005847
Validation Loss: 0.00583797
Epoch [75/300], Train Loss: 0.005706
Validation Loss: 0.00583659
Epoch [76/300], Train Loss: 0.005826
Validation Loss: 0.00583582
Epoch [77/300], Train Loss: 0.005805
Validation Loss: 0.00583485
Epoch [78/300], Train Loss: 0.005838
Validation Loss: 0.00583396
Epoch [79/300], Train Loss: 0.005700
Validation Loss: 0.00583355
Epoch [80/300], Train Loss: 0.005855
Validation Loss: 0.00583402
Epoch [81/300], Train Loss: 0.005701
Validation Loss: 0.00583306
Epoch [82/300], Train Loss: 0.005920
Validation Loss: 0.00583197
Epoch [83/300], Train Loss: 0.005817
Validation Loss: 0.00583150
Epoch [84/300], Train Loss: 0.005715
Validation Loss: 0.00583109
Epoch [85/300], Train Loss: 0.005766
Validation Loss: 0.00583108
Epoch [86/300], Train Loss: 0.005719
Validation Loss: 0.00583105
Epoch [87/300], Train Loss: 0.005810
Validation Loss: 0.00583110
Epoch [88/300], Train Loss: 0.005774
Validation Loss: 0.00582959
Epoch [89/300], Train Loss: 0.005792
Validation Loss: 0.00582892
Epoch [90/300], Train Loss: 0.005906
Validation Loss: 0.00582852
Epoch [91/300], Train Loss: 0.005849
Validation Loss: 0.00582774
Epoch [92/300], Train Loss: 0.005788
Validation Loss: 0.00582900
Epoch [93/300], Train Loss: 0.005832
Validation Loss: 0.00583228
Epoch [94/300], Train Loss: 0.005628
Validation Loss: 0.00583248
Epoch [95/300], Train Loss: 0.005777
Validation Loss: 0.00582893
Epoch [96/300], Train Loss: 0.005846
Validation Loss: 0.00582614
Epoch [97/300], Train Loss: 0.005733
Validation Loss: 0.00582524
Epoch [98/300], Train Loss: 0.005830
Validation Loss: 0.00582479
Epoch [99/300], Train Loss: 0.005782
Validation Loss: 0.00582443
Epoch [100/300], Train Loss: 0.005785
Validation Loss: 0.00582518
Epoch [101/300], Train Loss: 0.005744
Validation Loss: 0.00582744
Epoch [102/300], Train Loss: 0.005821
Validation Loss: 0.00582566
Epoch [103/300], Train Loss: 0.005759
Validation Loss: 0.00582260
Epoch [104/300], Train Loss: 0.005709
Validation Loss: 0.00582249
Epoch [105/300], Train Loss: 0.005795
Validation Loss: 0.00582176
Epoch [106/300], Train Loss: 0.005947
Validation Loss: 0.00582130
Epoch [107/300], Train Loss: 0.005741
Validation Loss: 0.00582091
Epoch [108/300], Train Loss: 0.005922
Validation Loss: 0.00582050
Epoch [109/300], Train Loss: 0.006001
Validation Loss: 0.00582053
Epoch [110/300], Train Loss: 0.005734
Validation Loss: 0.00581993
Epoch [111/300], Train Loss: 0.005713
Validation Loss: 0.00582007
Epoch [112/300], Train Loss: 0.005865
Validation Loss: 0.00582154
Epoch [113/300], Train Loss: 0.005870
Validation Loss: 0.00581995
Epoch [114/300], Train Loss: 0.005889
Validation Loss: 0.00581799
Epoch [115/300], Train Loss: 0.005850
Validation Loss: 0.00581867
Epoch [116/300], Train Loss: 0.005743
Validation Loss: 0.00581722
Epoch [117/300], Train Loss: 0.005768
Validation Loss: 0.00581697
Epoch [118/300], Train Loss: 0.005752
Validation Loss: 0.00581699
Epoch [119/300], Train Loss: 0.005740
Validation Loss: 0.00581671
Epoch [120/300], Train Loss: 0.005762
Validation Loss: 0.00581597
Epoch [121/300], Train Loss: 0.005703
Validation Loss: 0.00581516
Epoch [122/300], Train Loss: 0.005704
Validation Loss: 0.00581500
Epoch [123/300], Train Loss: 0.005790
Validation Loss: 0.00581446
Epoch [124/300], Train Loss: 0.005765
Validation Loss: 0.00581541
Epoch [125/300], Train Loss: 0.005845
Validation Loss: 0.00581645
Epoch [126/300], Train Loss: 0.005838
Validation Loss: 0.00581584
Epoch [127/300], Train Loss: 0.005766
Validation Loss: 0.00581311
Epoch [128/300], Train Loss: 0.005876
Validation Loss: 0.00581267
Epoch [129/300], Train Loss: 0.005706
Validation Loss: 0.00581229
Epoch [130/300], Train Loss: 0.005884
Validation Loss: 0.00581220
Epoch [131/300], Train Loss: 0.005730
Validation Loss: 0.00581257
Epoch [132/300], Train Loss: 0.005731
Validation Loss: 0.00581350
Epoch [133/300], Train Loss: 0.005713
Validation Loss: 0.00581221
Epoch [134/300], Train Loss: 0.005874
Validation Loss: 0.00581186
Epoch [135/300], Train Loss: 0.005664
Validation Loss: 0.00581024
Epoch [136/300], Train Loss: 0.005766
Validation Loss: 0.00581040
Epoch [137/300], Train Loss: 0.005907
Validation Loss: 0.00580988
Epoch [138/300], Train Loss: 0.005731
Validation Loss: 0.00580929
Epoch [139/300], Train Loss: 0.005720
Validation Loss: 0.00580881
Epoch [140/300], Train Loss: 0.005701
Validation Loss: 0.00580889
Epoch [141/300], Train Loss: 0.005615
Validation Loss: 0.00580973
Epoch [142/300], Train Loss: 0.005667
Validation Loss: 0.00580946
Epoch [143/300], Train Loss: 0.005773
Validation Loss: 0.00580912
Epoch [144/300], Train Loss: 0.005745
Validation Loss: 0.00580726
Epoch [145/300], Train Loss: 0.005692
Validation Loss: 0.00580693
Epoch [146/300], Train Loss: 0.005650
Validation Loss: 0.00580705
Epoch [147/300], Train Loss: 0.005824
Validation Loss: 0.00580707
Epoch [148/300], Train Loss: 0.005653
Validation Loss: 0.00580608
Epoch [149/300], Train Loss: 0.005865
Validation Loss: 0.00580566
Epoch [150/300], Train Loss: 0.005972
Validation Loss: 0.00580645
Epoch [151/300], Train Loss: 0.005734
Validation Loss: 0.00580844
Epoch [152/300], Train Loss: 0.005916
Validation Loss: 0.00580675
Epoch [153/300], Train Loss: 0.005625
Validation Loss: 0.00580623
Epoch [154/300], Train Loss: 0.005649
Validation Loss: 0.00580419
Epoch [155/300], Train Loss: 0.005843
Validation Loss: 0.00580533
Epoch [156/300], Train Loss: 0.005767
Validation Loss: 0.00580571
Epoch [157/300], Train Loss: 0.005829
Validation Loss: 0.00580343
Epoch [158/300], Train Loss: 0.005728
Validation Loss: 0.00580305
Epoch [159/300], Train Loss: 0.005867
Validation Loss: 0.00580257
Epoch [160/300], Train Loss: 0.005721
Validation Loss: 0.00580238
Epoch [161/300], Train Loss: 0.005795
Validation Loss: 0.00580257
Epoch [162/300], Train Loss: 0.005694
Validation Loss: 0.00580304
Epoch [163/300], Train Loss: 0.005789
Validation Loss: 0.00580332
Epoch [164/300], Train Loss: 0.005660
Validation Loss: 0.00580215
Epoch [165/300], Train Loss: 0.005637
Validation Loss: 0.00580142
Epoch [166/300], Train Loss: 0.005627
Validation Loss: 0.00580093
Epoch [167/300], Train Loss: 0.005678
Validation Loss: 0.00580064
Epoch [168/300], Train Loss: 0.005690
Validation Loss: 0.00580041
Epoch [169/300], Train Loss: 0.005851
Validation Loss: 0.00579999
Epoch [170/300], Train Loss: 0.005609
Validation Loss: 0.00579932
Epoch [171/300], Train Loss: 0.005781
Validation Loss: 0.00579920
Epoch [172/300], Train Loss: 0.005706
Validation Loss: 0.00579990
Epoch [173/300], Train Loss: 0.005611
Validation Loss: 0.00579969
Epoch [174/300], Train Loss: 0.005832
Validation Loss: 0.00579940
Epoch [175/300], Train Loss: 0.005859
Validation Loss: 0.00579830
Epoch [176/300], Train Loss: 0.005753
Validation Loss: 0.00579768
Epoch [177/300], Train Loss: 0.005597
Validation Loss: 0.00579830
Epoch [178/300], Train Loss: 0.005616
Validation Loss: 0.00579741
Epoch [179/300], Train Loss: 0.005707
Validation Loss: 0.00579697
Epoch [180/300], Train Loss: 0.005919
Validation Loss: 0.00579829
Epoch [181/300], Train Loss: 0.005736
Validation Loss: 0.00579771
Epoch [182/300], Train Loss: 0.005712
Validation Loss: 0.00579717
Epoch [183/300], Train Loss: 0.005895
Validation Loss: 0.00579687
Epoch [184/300], Train Loss: 0.005718
Validation Loss: 0.00579594
Epoch [185/300], Train Loss: 0.005599
Validation Loss: 0.00579527
Epoch [186/300], Train Loss: 0.005802
Validation Loss: 0.00579512
Epoch [187/300], Train Loss: 0.005776
Validation Loss: 0.00579506
Epoch [188/300], Train Loss: 0.005679
Validation Loss: 0.00579487
Epoch [189/300], Train Loss: 0.005775
Validation Loss: 0.00579438
Epoch [190/300], Train Loss: 0.005706
Validation Loss: 0.00579436
Epoch [191/300], Train Loss: 0.005833
Validation Loss: 0.00579422
Epoch [192/300], Train Loss: 0.005601
Validation Loss: 0.00579348
Epoch [193/300], Train Loss: 0.005775
Validation Loss: 0.00579520
Epoch [194/300], Train Loss: 0.005809
Validation Loss: 0.00579663
Epoch [195/300], Train Loss: 0.005726
Validation Loss: 0.00579471
Epoch [196/300], Train Loss: 0.005703
Validation Loss: 0.00579468
Epoch [197/300], Train Loss: 0.005732
Validation Loss: 0.00579387
Epoch [198/300], Train Loss: 0.005725
Validation Loss: 0.00579235
Epoch [199/300], Train Loss: 0.005726
Validation Loss: 0.00579200
Epoch [200/300], Train Loss: 0.005784
Validation Loss: 0.00579217
Epoch [201/300], Train Loss: 0.005977
Validation Loss: 0.00579176
Epoch [202/300], Train Loss: 0.005785
Validation Loss: 0.00579148
Epoch [203/300], Train Loss: 0.005675
Validation Loss: 0.00579150
Epoch [204/300], Train Loss: 0.005807
Validation Loss: 0.00579069
Epoch [205/300], Train Loss: 0.005618
Validation Loss: 0.00579069
Epoch [206/300], Train Loss: 0.005677
Validation Loss: 0.00579120
Epoch [207/300], Train Loss: 0.005640
Validation Loss: 0.00579117
Epoch [208/300], Train Loss: 0.005771
Validation Loss: 0.00579072
Epoch [209/300], Train Loss: 0.005704
Validation Loss: 0.00579005
Epoch [210/300], Train Loss: 0.005797
Validation Loss: 0.00578943
Epoch [211/300], Train Loss: 0.005764
Validation Loss: 0.00578920
Epoch [212/300], Train Loss: 0.005706
Validation Loss: 0.00578901
Epoch [213/300], Train Loss: 0.005870
Validation Loss: 0.00578883
Epoch [214/300], Train Loss: 0.005612
Validation Loss: 0.00578888
Epoch [215/300], Train Loss: 0.005682
Validation Loss: 0.00578852
Epoch [216/300], Train Loss: 0.005964
Validation Loss: 0.00578819
Epoch [217/300], Train Loss: 0.005658
Validation Loss: 0.00578809
Epoch [218/300], Train Loss: 0.005678
Validation Loss: 0.00578786
Epoch [219/300], Train Loss: 0.005705
Validation Loss: 0.00578799
Epoch [220/300], Train Loss: 0.005620
Validation Loss: 0.00578835
Epoch [221/300], Train Loss: 0.005838
Validation Loss: 0.00578938
Epoch [222/300], Train Loss: 0.005685
Validation Loss: 0.00578837
Epoch [223/300], Train Loss: 0.005724
Validation Loss: 0.00578738
Epoch [224/300], Train Loss: 0.005792
Validation Loss: 0.00578679
Epoch [225/300], Train Loss: 0.005706
Validation Loss: 0.00578681
Epoch [226/300], Train Loss: 0.005729
Validation Loss: 0.00578661
Epoch [227/300], Train Loss: 0.005650
Validation Loss: 0.00578625
Epoch [228/300], Train Loss: 0.005547
Validation Loss: 0.00578618
Epoch [229/300], Train Loss: 0.005734
Validation Loss: 0.00578689
Epoch [230/300], Train Loss: 0.005738
Validation Loss: 0.00578722
Epoch [231/300], Train Loss: 0.005619
Validation Loss: 0.00578667
Epoch [232/300], Train Loss: 0.005600
Validation Loss: 0.00578610
Epoch [233/300], Train Loss: 0.005791
Validation Loss: 0.00578589
Epoch [234/300], Train Loss: 0.005745
Validation Loss: 0.00578495
Epoch [235/300], Train Loss: 0.005735
Validation Loss: 0.00578472
Epoch [236/300], Train Loss: 0.005748
Validation Loss: 0.00578451
Epoch [237/300], Train Loss: 0.005619
Validation Loss: 0.00578436
Epoch [238/300], Train Loss: 0.005791
Validation Loss: 0.00578408
Epoch [239/300], Train Loss: 0.005921
Validation Loss: 0.00578388
Epoch [240/300], Train Loss: 0.005745
Validation Loss: 0.00578366
Epoch [241/300], Train Loss: 0.005702
Validation Loss: 0.00578348
Epoch [242/300], Train Loss: 0.005671
Validation Loss: 0.00578359
Epoch [243/300], Train Loss: 0.005727
Validation Loss: 0.00578375
Epoch [244/300], Train Loss: 0.005657
Validation Loss: 0.00578363
Epoch [245/300], Train Loss: 0.005794
Validation Loss: 0.00578392
Epoch [246/300], Train Loss: 0.005654
Validation Loss: 0.00578381
Epoch [247/300], Train Loss: 0.005632
Validation Loss: 0.00578296
Epoch [248/300], Train Loss: 0.005751
Validation Loss: 0.00578246
Epoch [249/300], Train Loss: 0.005680
Validation Loss: 0.00578213
Epoch [250/300], Train Loss: 0.005754
Validation Loss: 0.00578197
Epoch [251/300], Train Loss: 0.005763
Validation Loss: 0.00578186
Epoch [252/300], Train Loss: 0.005759
Validation Loss: 0.00578168
Epoch [253/300], Train Loss: 0.005711
Validation Loss: 0.00578177
Epoch [254/300], Train Loss: 0.005615
Validation Loss: 0.00578156
Epoch [255/300], Train Loss: 0.005797
Validation Loss: 0.00578114
Epoch [256/300], Train Loss: 0.005706
Validation Loss: 0.00578116
Epoch [257/300], Train Loss: 0.005647
Validation Loss: 0.00578133
Epoch [258/300], Train Loss: 0.005951
Validation Loss: 0.00578169
Epoch [259/300], Train Loss: 0.005648
Validation Loss: 0.00578119
Epoch [260/300], Train Loss: 0.005635
Validation Loss: 0.00578073
Epoch [261/300], Train Loss: 0.005649
Validation Loss: 0.00578051
Epoch [262/300], Train Loss: 0.005767
Validation Loss: 0.00578026
Epoch [263/300], Train Loss: 0.005752
Validation Loss: 0.00577990
Epoch [264/300], Train Loss: 0.005734
Validation Loss: 0.00577975
Epoch [265/300], Train Loss: 0.005746
Validation Loss: 0.00577961
Epoch [266/300], Train Loss: 0.005714
Validation Loss: 0.00577946
Epoch [267/300], Train Loss: 0.005661
Validation Loss: 0.00577932
Epoch [268/300], Train Loss: 0.005625
Validation Loss: 0.00577998
Epoch [269/300], Train Loss: 0.005635
Validation Loss: 0.00578074
Epoch [270/300], Train Loss: 0.005740
Validation Loss: 0.00578099
Epoch [271/300], Train Loss: 0.005610
Validation Loss: 0.00578154
Epoch [272/300], Train Loss: 0.005725
Validation Loss: 0.00578047
Epoch [273/300], Train Loss: 0.005643
Validation Loss: 0.00577909
Epoch [274/300], Train Loss: 0.005835
Validation Loss: 0.00577876
Epoch [275/300], Train Loss: 0.005643
Validation Loss: 0.00577825
Epoch [276/300], Train Loss: 0.005749
Validation Loss: 0.00577806
Epoch [277/300], Train Loss: 0.005723
Validation Loss: 0.00577793
Epoch [278/300], Train Loss: 0.005717
Validation Loss: 0.00577773
Epoch [279/300], Train Loss: 0.005718
Validation Loss: 0.00577759
Epoch [280/300], Train Loss: 0.005687
Validation Loss: 0.00577751
Epoch [281/300], Train Loss: 0.005753
Validation Loss: 0.00577753
Epoch [282/300], Train Loss: 0.005726
Validation Loss: 0.00577739
Epoch [283/300], Train Loss: 0.005608
Validation Loss: 0.00577706
Epoch [284/300], Train Loss: 0.005748
Validation Loss: 0.00577693
Epoch [285/300], Train Loss: 0.005701
Validation Loss: 0.00577684
Epoch [286/300], Train Loss: 0.005842
Validation Loss: 0.00577676
Epoch [287/300], Train Loss: 0.005699
Validation Loss: 0.00577666
Epoch [288/300], Train Loss: 0.005650
Validation Loss: 0.00577644
Epoch [289/300], Train Loss: 0.005839
Validation Loss: 0.00577662
Epoch [290/300], Train Loss: 0.005578
Validation Loss: 0.00577668
Epoch [291/300], Train Loss: 0.005566
Validation Loss: 0.00577720
Epoch [292/300], Train Loss: 0.005737
Validation Loss: 0.00577826
Epoch [293/300], Train Loss: 0.005931
Validation Loss: 0.00577765
Epoch [294/300], Train Loss: 0.005594
Validation Loss: 0.00577597
Epoch [295/300], Train Loss: 0.005714
Validation Loss: 0.00577558
Epoch [296/300], Train Loss: 0.005733
Validation Loss: 0.00577541
Epoch [297/300], Train Loss: 0.005778
Validation Loss: 0.00577524
Epoch [298/300], Train Loss: 0.005638
Validation Loss: 0.00577512
Epoch [299/300], Train Loss: 0.005572
Validation Loss: 0.00577497
Epoch [300/300], Train Loss: 0.005782
Validation Loss: 0.00577579

Evaluating model for: Router
Run 21/72 completed in 168.30 seconds with: {'MAE': np.float32(0.19256507), 'MSE': np.float32(0.063027985), 'RMSE': np.float32(0.25105375), 'SAE': np.float32(0.00040622105), 'NDE': np.float32(0.01255574)}

Run 22/72: hidden=128, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Router
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.116806
Validation Loss: 0.11279102
Epoch [2/300], Train Loss: 0.112058
Validation Loss: 0.10779709
Epoch [3/300], Train Loss: 0.107617
Validation Loss: 0.10292222
Epoch [4/300], Train Loss: 0.102213
Validation Loss: 0.09803465
Epoch [5/300], Train Loss: 0.096319
Validation Loss: 0.09297261
Epoch [6/300], Train Loss: 0.091578
Validation Loss: 0.08779832
Epoch [7/300], Train Loss: 0.086595
Validation Loss: 0.08207031
Epoch [8/300], Train Loss: 0.080410
Validation Loss: 0.07562185
Epoch [9/300], Train Loss: 0.073337
Validation Loss: 0.06832241
Epoch [10/300], Train Loss: 0.065654
Validation Loss: 0.05966055
Epoch [11/300], Train Loss: 0.056445
Validation Loss: 0.04916260
Epoch [12/300], Train Loss: 0.044957
Validation Loss: 0.03641075
Epoch [13/300], Train Loss: 0.031537
Validation Loss: 0.02130170
Epoch [14/300], Train Loss: 0.016118
Validation Loss: 0.00793689
Epoch [15/300], Train Loss: 0.007530
Validation Loss: 0.00964496
Epoch [16/300], Train Loss: 0.010853
Validation Loss: 0.01058456
Epoch [17/300], Train Loss: 0.009188
Validation Loss: 0.00667762
Epoch [18/300], Train Loss: 0.006643
Validation Loss: 0.00639428
Epoch [19/300], Train Loss: 0.006938
Validation Loss: 0.00705966
Epoch [20/300], Train Loss: 0.007365
Validation Loss: 0.00689562
Epoch [21/300], Train Loss: 0.006981
Validation Loss: 0.00636332
Epoch [22/300], Train Loss: 0.006511
Validation Loss: 0.00616158
Epoch [23/300], Train Loss: 0.006486
Validation Loss: 0.00632353
Epoch [24/300], Train Loss: 0.006617
Validation Loss: 0.00637218
Epoch [25/300], Train Loss: 0.006484
Validation Loss: 0.00621447
Epoch [26/300], Train Loss: 0.006302
Validation Loss: 0.00615237
Epoch [27/300], Train Loss: 0.006446
Validation Loss: 0.00617704
Epoch [28/300], Train Loss: 0.006405
Validation Loss: 0.00617750
Epoch [29/300], Train Loss: 0.006528
Validation Loss: 0.00615738
Epoch [30/300], Train Loss: 0.006332
Validation Loss: 0.00614910
Epoch [31/300], Train Loss: 0.006330
Validation Loss: 0.00616256
Epoch [32/300], Train Loss: 0.006358
Validation Loss: 0.00617050
Epoch [33/300], Train Loss: 0.006516
Validation Loss: 0.00616740
Epoch [34/300], Train Loss: 0.006360
Validation Loss: 0.00614958
Epoch [35/300], Train Loss: 0.006383
Validation Loss: 0.00614464
Epoch [36/300], Train Loss: 0.006406
Validation Loss: 0.00614389
Epoch [37/300], Train Loss: 0.006348
Validation Loss: 0.00614325
Epoch [38/300], Train Loss: 0.006232
Validation Loss: 0.00614462
Epoch [39/300], Train Loss: 0.006331
Validation Loss: 0.00615254
Epoch [40/300], Train Loss: 0.006446
Validation Loss: 0.00614919
Epoch [41/300], Train Loss: 0.006421
Validation Loss: 0.00614013
Epoch [42/300], Train Loss: 0.006486
Validation Loss: 0.00614024
Epoch [43/300], Train Loss: 0.006447
Validation Loss: 0.00614098
Epoch [44/300], Train Loss: 0.006350
Validation Loss: 0.00613791
Epoch [45/300], Train Loss: 0.006337
Validation Loss: 0.00613755
Epoch [46/300], Train Loss: 0.006310
Validation Loss: 0.00613844
Epoch [47/300], Train Loss: 0.006378
Validation Loss: 0.00614178
Epoch [48/300], Train Loss: 0.006513
Validation Loss: 0.00614221
Epoch [49/300], Train Loss: 0.006400
Validation Loss: 0.00613748
Epoch [50/300], Train Loss: 0.006392
Validation Loss: 0.00613385
Epoch [51/300], Train Loss: 0.006376
Validation Loss: 0.00613297
Epoch [52/300], Train Loss: 0.006410
Validation Loss: 0.00613284
Epoch [53/300], Train Loss: 0.006419
Validation Loss: 0.00613159
Epoch [54/300], Train Loss: 0.006349
Validation Loss: 0.00613309
Epoch [55/300], Train Loss: 0.006383
Validation Loss: 0.00613286
Epoch [56/300], Train Loss: 0.006359
Validation Loss: 0.00613075
Epoch [57/300], Train Loss: 0.006447
Validation Loss: 0.00612879
Epoch [58/300], Train Loss: 0.006309
Validation Loss: 0.00612800
Epoch [59/300], Train Loss: 0.006351
Validation Loss: 0.00612863
Epoch [60/300], Train Loss: 0.006349
Validation Loss: 0.00612657
Epoch [61/300], Train Loss: 0.006297
Validation Loss: 0.00613267
Epoch [62/300], Train Loss: 0.006406
Validation Loss: 0.00614329
Epoch [63/300], Train Loss: 0.006229
Validation Loss: 0.00613120
Epoch [64/300], Train Loss: 0.006436
Validation Loss: 0.00612402
Epoch [65/300], Train Loss: 0.006274
Validation Loss: 0.00612343
Epoch [66/300], Train Loss: 0.006433
Validation Loss: 0.00612471
Epoch [67/300], Train Loss: 0.006288
Validation Loss: 0.00612454
Epoch [68/300], Train Loss: 0.006299
Validation Loss: 0.00612173
Epoch [69/300], Train Loss: 0.006303
Validation Loss: 0.00612075
Epoch [70/300], Train Loss: 0.006344
Validation Loss: 0.00612009
Epoch [71/300], Train Loss: 0.006376
Validation Loss: 0.00611961
Epoch [72/300], Train Loss: 0.006185
Validation Loss: 0.00611962
Epoch [73/300], Train Loss: 0.006239
Validation Loss: 0.00612348
Epoch [74/300], Train Loss: 0.006365
Validation Loss: 0.00612196
Epoch [75/300], Train Loss: 0.006224
Validation Loss: 0.00611908
Epoch [76/300], Train Loss: 0.006353
Validation Loss: 0.00611803
Epoch [77/300], Train Loss: 0.006326
Validation Loss: 0.00611674
Epoch [78/300], Train Loss: 0.006350
Validation Loss: 0.00611560
Epoch [79/300], Train Loss: 0.006229
Validation Loss: 0.00611562
Epoch [80/300], Train Loss: 0.006374
Validation Loss: 0.00611742
Epoch [81/300], Train Loss: 0.006225
Validation Loss: 0.00611516
Epoch [82/300], Train Loss: 0.006450
Validation Loss: 0.00611259
Epoch [83/300], Train Loss: 0.006354
Validation Loss: 0.00611197
Epoch [84/300], Train Loss: 0.006248
Validation Loss: 0.00611195
Epoch [85/300], Train Loss: 0.006273
Validation Loss: 0.00611296
Epoch [86/300], Train Loss: 0.006250
Validation Loss: 0.00611312
Epoch [87/300], Train Loss: 0.006323
Validation Loss: 0.00611327
Epoch [88/300], Train Loss: 0.006306
Validation Loss: 0.00611027
Epoch [89/300], Train Loss: 0.006299
Validation Loss: 0.00610817
Epoch [90/300], Train Loss: 0.006408
Validation Loss: 0.00610752
Epoch [91/300], Train Loss: 0.006394
Validation Loss: 0.00610770
Epoch [92/300], Train Loss: 0.006293
Validation Loss: 0.00611205
Epoch [93/300], Train Loss: 0.006356
Validation Loss: 0.00611718
Epoch [94/300], Train Loss: 0.006152
Validation Loss: 0.00611513
Epoch [95/300], Train Loss: 0.006290
Validation Loss: 0.00610862
Epoch [96/300], Train Loss: 0.006357
Validation Loss: 0.00610482
Epoch [97/300], Train Loss: 0.006255
Validation Loss: 0.00610351
Epoch [98/300], Train Loss: 0.006346
Validation Loss: 0.00610313
Epoch [99/300], Train Loss: 0.006315
Validation Loss: 0.00610420
Epoch [100/300], Train Loss: 0.006303
Validation Loss: 0.00610722
Epoch [101/300], Train Loss: 0.006265
Validation Loss: 0.00611021
Epoch [102/300], Train Loss: 0.006327
Validation Loss: 0.00610492
Epoch [103/300], Train Loss: 0.006277
Validation Loss: 0.00610000
Epoch [104/300], Train Loss: 0.006227
Validation Loss: 0.00609969
Epoch [105/300], Train Loss: 0.006306
Validation Loss: 0.00609897
Epoch [106/300], Train Loss: 0.006453
Validation Loss: 0.00609922
Epoch [107/300], Train Loss: 0.006259
Validation Loss: 0.00609919
Epoch [108/300], Train Loss: 0.006434
Validation Loss: 0.00609847
Epoch [109/300], Train Loss: 0.006509
Validation Loss: 0.00609869
Epoch [110/300], Train Loss: 0.006243
Validation Loss: 0.00609742
Epoch [111/300], Train Loss: 0.006223
Validation Loss: 0.00609785
Epoch [112/300], Train Loss: 0.006359
Validation Loss: 0.00610091
Epoch [113/300], Train Loss: 0.006373
Validation Loss: 0.00609820
Epoch [114/300], Train Loss: 0.006405
Validation Loss: 0.00609388
Epoch [115/300], Train Loss: 0.006345
Validation Loss: 0.00609391
Epoch [116/300], Train Loss: 0.006254
Validation Loss: 0.00609289
Epoch [117/300], Train Loss: 0.006284
Validation Loss: 0.00609519
Epoch [118/300], Train Loss: 0.006264
Validation Loss: 0.00609515
Epoch [119/300], Train Loss: 0.006246
Validation Loss: 0.00609379
Epoch [120/300], Train Loss: 0.006268
Validation Loss: 0.00609182
Epoch [121/300], Train Loss: 0.006211
Validation Loss: 0.00609005
Epoch [122/300], Train Loss: 0.006210
Validation Loss: 0.00608955
Epoch [123/300], Train Loss: 0.006281
Validation Loss: 0.00609025
Epoch [124/300], Train Loss: 0.006268
Validation Loss: 0.00609351
Epoch [125/300], Train Loss: 0.006343
Validation Loss: 0.00609494
Epoch [126/300], Train Loss: 0.006340
Validation Loss: 0.00609224
Epoch [127/300], Train Loss: 0.006266
Validation Loss: 0.00608720
Epoch [128/300], Train Loss: 0.006367
Validation Loss: 0.00608646
Epoch [129/300], Train Loss: 0.006199
Validation Loss: 0.00608618
Epoch [130/300], Train Loss: 0.006384
Validation Loss: 0.00608751
Epoch [131/300], Train Loss: 0.006243
Validation Loss: 0.00608934
Epoch [132/300], Train Loss: 0.006228
Validation Loss: 0.00609056
Epoch [133/300], Train Loss: 0.006211
Validation Loss: 0.00608678
Epoch [134/300], Train Loss: 0.006351
Validation Loss: 0.00608559
Epoch [135/300], Train Loss: 0.006163
Validation Loss: 0.00608280
Epoch [136/300], Train Loss: 0.006247
Validation Loss: 0.00608256
Epoch [137/300], Train Loss: 0.006398
Validation Loss: 0.00608178
Epoch [138/300], Train Loss: 0.006234
Validation Loss: 0.00608146
Epoch [139/300], Train Loss: 0.006212
Validation Loss: 0.00608155
Epoch [140/300], Train Loss: 0.006198
Validation Loss: 0.00608312
Epoch [141/300], Train Loss: 0.006115
Validation Loss: 0.00608460
Epoch [142/300], Train Loss: 0.006171
Validation Loss: 0.00608291
Epoch [143/300], Train Loss: 0.006279
Validation Loss: 0.00608164
Epoch [144/300], Train Loss: 0.006238
Validation Loss: 0.00607850
Epoch [145/300], Train Loss: 0.006190
Validation Loss: 0.00607815
Epoch [146/300], Train Loss: 0.006139
Validation Loss: 0.00607899
Epoch [147/300], Train Loss: 0.006305
Validation Loss: 0.00607958
Epoch [148/300], Train Loss: 0.006154
Validation Loss: 0.00607743
Epoch [149/300], Train Loss: 0.006346
Validation Loss: 0.00607623
Epoch [150/300], Train Loss: 0.006463
Validation Loss: 0.00607590
Epoch [151/300], Train Loss: 0.006235
Validation Loss: 0.00607753
Epoch [152/300], Train Loss: 0.006394
Validation Loss: 0.00607518
Epoch [153/300], Train Loss: 0.006112
Validation Loss: 0.00607428
Epoch [154/300], Train Loss: 0.006144
Validation Loss: 0.00607387
Epoch [155/300], Train Loss: 0.006310
Validation Loss: 0.00607866
Epoch [156/300], Train Loss: 0.006264
Validation Loss: 0.00607793
Epoch [157/300], Train Loss: 0.006328
Validation Loss: 0.00607274
Epoch [158/300], Train Loss: 0.006225
Validation Loss: 0.00607183
Epoch [159/300], Train Loss: 0.006336
Validation Loss: 0.00607119
Epoch [160/300], Train Loss: 0.006230
Validation Loss: 0.00607073
Epoch [161/300], Train Loss: 0.006278
Validation Loss: 0.00607357
Epoch [162/300], Train Loss: 0.006177
Validation Loss: 0.00607481
Epoch [163/300], Train Loss: 0.006272
Validation Loss: 0.00607430
Epoch [164/300], Train Loss: 0.006152
Validation Loss: 0.00607115
Epoch [165/300], Train Loss: 0.006122
Validation Loss: 0.00606963
Epoch [166/300], Train Loss: 0.006108
Validation Loss: 0.00606890
Epoch [167/300], Train Loss: 0.006154
Validation Loss: 0.00606874
Epoch [168/300], Train Loss: 0.006180
Validation Loss: 0.00606875
Epoch [169/300], Train Loss: 0.006326
Validation Loss: 0.00606822
Epoch [170/300], Train Loss: 0.006096
Validation Loss: 0.00606694
Epoch [171/300], Train Loss: 0.006257
Validation Loss: 0.00606710
Epoch [172/300], Train Loss: 0.006188
Validation Loss: 0.00606881
Epoch [173/300], Train Loss: 0.006105
Validation Loss: 0.00606800
Epoch [174/300], Train Loss: 0.006307
Validation Loss: 0.00606707
Epoch [175/300], Train Loss: 0.006336
Validation Loss: 0.00606503
Epoch [176/300], Train Loss: 0.006231
Validation Loss: 0.00606385
Epoch [177/300], Train Loss: 0.006093
Validation Loss: 0.00606397
Epoch [178/300], Train Loss: 0.006092
Validation Loss: 0.00606298
Epoch [179/300], Train Loss: 0.006196
Validation Loss: 0.00606417
Epoch [180/300], Train Loss: 0.006394
Validation Loss: 0.00606726
Epoch [181/300], Train Loss: 0.006211
Validation Loss: 0.00606514
Epoch [182/300], Train Loss: 0.006201
Validation Loss: 0.00606353
Epoch [183/300], Train Loss: 0.006361
Validation Loss: 0.00606275
Epoch [184/300], Train Loss: 0.006180
Validation Loss: 0.00606130
Epoch [185/300], Train Loss: 0.006091
Validation Loss: 0.00606024
Epoch [186/300], Train Loss: 0.006279
Validation Loss: 0.00605982
Epoch [187/300], Train Loss: 0.006265
Validation Loss: 0.00605947
Epoch [188/300], Train Loss: 0.006159
Validation Loss: 0.00605906
Epoch [189/300], Train Loss: 0.006242
Validation Loss: 0.00605869
Epoch [190/300], Train Loss: 0.006175
Validation Loss: 0.00605828
Epoch [191/300], Train Loss: 0.006315
Validation Loss: 0.00605796
Epoch [192/300], Train Loss: 0.006082
Validation Loss: 0.00605766
Epoch [193/300], Train Loss: 0.006252
Validation Loss: 0.00606170
Epoch [194/300], Train Loss: 0.006296
Validation Loss: 0.00606340
Epoch [195/300], Train Loss: 0.006192
Validation Loss: 0.00605950
Epoch [196/300], Train Loss: 0.006185
Validation Loss: 0.00605917
Epoch [197/300], Train Loss: 0.006198
Validation Loss: 0.00605780
Epoch [198/300], Train Loss: 0.006216
Validation Loss: 0.00605569
Epoch [199/300], Train Loss: 0.006203
Validation Loss: 0.00605534
Epoch [200/300], Train Loss: 0.006254
Validation Loss: 0.00605611
Epoch [201/300], Train Loss: 0.006450
Validation Loss: 0.00605556
Epoch [202/300], Train Loss: 0.006256
Validation Loss: 0.00605396
Epoch [203/300], Train Loss: 0.006163
Validation Loss: 0.00605375
Epoch [204/300], Train Loss: 0.006280
Validation Loss: 0.00605344
Epoch [205/300], Train Loss: 0.006099
Validation Loss: 0.00605392
Epoch [206/300], Train Loss: 0.006152
Validation Loss: 0.00605489
Epoch [207/300], Train Loss: 0.006129
Validation Loss: 0.00605443
Epoch [208/300], Train Loss: 0.006237
Validation Loss: 0.00605332
Epoch [209/300], Train Loss: 0.006177
Validation Loss: 0.00605219
Epoch [210/300], Train Loss: 0.006255
Validation Loss: 0.00605117
Epoch [211/300], Train Loss: 0.006222
Validation Loss: 0.00605078
Epoch [212/300], Train Loss: 0.006176
Validation Loss: 0.00605047
Epoch [213/300], Train Loss: 0.006322
Validation Loss: 0.00605017
Epoch [214/300], Train Loss: 0.006088
Validation Loss: 0.00604986
Epoch [215/300], Train Loss: 0.006144
Validation Loss: 0.00604950
Epoch [216/300], Train Loss: 0.006440
Validation Loss: 0.00604933
Epoch [217/300], Train Loss: 0.006134
Validation Loss: 0.00604955
Epoch [218/300], Train Loss: 0.006149
Validation Loss: 0.00604902
Epoch [219/300], Train Loss: 0.006164
Validation Loss: 0.00604941
Epoch [220/300], Train Loss: 0.006086
Validation Loss: 0.00604995
Epoch [221/300], Train Loss: 0.006327
Validation Loss: 0.00605133
Epoch [222/300], Train Loss: 0.006146
Validation Loss: 0.00604940
Epoch [223/300], Train Loss: 0.006184
Validation Loss: 0.00604776
Epoch [224/300], Train Loss: 0.006248
Validation Loss: 0.00604689
Epoch [225/300], Train Loss: 0.006169
Validation Loss: 0.00604706
Epoch [226/300], Train Loss: 0.006197
Validation Loss: 0.00604689
Epoch [227/300], Train Loss: 0.006105
Validation Loss: 0.00604625
Epoch [228/300], Train Loss: 0.006020
Validation Loss: 0.00604615
Epoch [229/300], Train Loss: 0.006195
Validation Loss: 0.00604725
Epoch [230/300], Train Loss: 0.006209
Validation Loss: 0.00604752
Epoch [231/300], Train Loss: 0.006092
Validation Loss: 0.00604640
Epoch [232/300], Train Loss: 0.006069
Validation Loss: 0.00604543
Epoch [233/300], Train Loss: 0.006262
Validation Loss: 0.00604506
Epoch [234/300], Train Loss: 0.006209
Validation Loss: 0.00604381
Epoch [235/300], Train Loss: 0.006201
Validation Loss: 0.00604353
Epoch [236/300], Train Loss: 0.006221
Validation Loss: 0.00604316
Epoch [237/300], Train Loss: 0.006080
Validation Loss: 0.00604286
Epoch [238/300], Train Loss: 0.006258
Validation Loss: 0.00604260
Epoch [239/300], Train Loss: 0.006389
Validation Loss: 0.00604240
Epoch [240/300], Train Loss: 0.006212
Validation Loss: 0.00604202
Epoch [241/300], Train Loss: 0.006172
Validation Loss: 0.00604174
Epoch [242/300], Train Loss: 0.006126
Validation Loss: 0.00604207
Epoch [243/300], Train Loss: 0.006201
Validation Loss: 0.00604226
Epoch [244/300], Train Loss: 0.006131
Validation Loss: 0.00604194
Epoch [245/300], Train Loss: 0.006251
Validation Loss: 0.00604216
Epoch [246/300], Train Loss: 0.006126
Validation Loss: 0.00604182
Epoch [247/300], Train Loss: 0.006084
Validation Loss: 0.00604061
Epoch [248/300], Train Loss: 0.006222
Validation Loss: 0.00603995
Epoch [249/300], Train Loss: 0.006135
Validation Loss: 0.00603948
Epoch [250/300], Train Loss: 0.006207
Validation Loss: 0.00603926
Epoch [251/300], Train Loss: 0.006214
Validation Loss: 0.00603921
Epoch [252/300], Train Loss: 0.006215
Validation Loss: 0.00603867
Epoch [253/300], Train Loss: 0.006173
Validation Loss: 0.00603855
Epoch [254/300], Train Loss: 0.006069
Validation Loss: 0.00603822
Epoch [255/300], Train Loss: 0.006252
Validation Loss: 0.00603800
Epoch [256/300], Train Loss: 0.006171
Validation Loss: 0.00603825
Epoch [257/300], Train Loss: 0.006110
Validation Loss: 0.00603850
Epoch [258/300], Train Loss: 0.006397
Validation Loss: 0.00603884
Epoch [259/300], Train Loss: 0.006111
Validation Loss: 0.00603776
Epoch [260/300], Train Loss: 0.006091
Validation Loss: 0.00603696
Epoch [261/300], Train Loss: 0.006098
Validation Loss: 0.00603661
Epoch [262/300], Train Loss: 0.006232
Validation Loss: 0.00603629
Epoch [263/300], Train Loss: 0.006212
Validation Loss: 0.00603587
Epoch [264/300], Train Loss: 0.006196
Validation Loss: 0.00603563
Epoch [265/300], Train Loss: 0.006212
Validation Loss: 0.00603538
Epoch [266/300], Train Loss: 0.006155
Validation Loss: 0.00603513
Epoch [267/300], Train Loss: 0.006127
Validation Loss: 0.00603497
Epoch [268/300], Train Loss: 0.006072
Validation Loss: 0.00603609
Epoch [269/300], Train Loss: 0.006091
Validation Loss: 0.00603702
Epoch [270/300], Train Loss: 0.006213
Validation Loss: 0.00603690
Epoch [271/300], Train Loss: 0.006071
Validation Loss: 0.00603726
Epoch [272/300], Train Loss: 0.006173
Validation Loss: 0.00603556
Epoch [273/300], Train Loss: 0.006118
Validation Loss: 0.00603387
Epoch [274/300], Train Loss: 0.006301
Validation Loss: 0.00603352
Epoch [275/300], Train Loss: 0.006114
Validation Loss: 0.00603301
Epoch [276/300], Train Loss: 0.006206
Validation Loss: 0.00603283
Epoch [277/300], Train Loss: 0.006165
Validation Loss: 0.00603256
Epoch [278/300], Train Loss: 0.006169
Validation Loss: 0.00603228
Epoch [279/300], Train Loss: 0.006169
Validation Loss: 0.00603227
Epoch [280/300], Train Loss: 0.006137
Validation Loss: 0.00603222
Epoch [281/300], Train Loss: 0.006209
Validation Loss: 0.00603226
Epoch [282/300], Train Loss: 0.006180
Validation Loss: 0.00603184
Epoch [283/300], Train Loss: 0.006058
Validation Loss: 0.00603119
Epoch [284/300], Train Loss: 0.006204
Validation Loss: 0.00603092
Epoch [285/300], Train Loss: 0.006153
Validation Loss: 0.00603071
Epoch [286/300], Train Loss: 0.006280
Validation Loss: 0.00603056
Epoch [287/300], Train Loss: 0.006149
Validation Loss: 0.00603043
Epoch [288/300], Train Loss: 0.006108
Validation Loss: 0.00603013
Epoch [289/300], Train Loss: 0.006272
Validation Loss: 0.00603040
Epoch [290/300], Train Loss: 0.006037
Validation Loss: 0.00603049
Epoch [291/300], Train Loss: 0.006023
Validation Loss: 0.00603119
Epoch [292/300], Train Loss: 0.006181
Validation Loss: 0.00603246
Epoch [293/300], Train Loss: 0.006377
Validation Loss: 0.00603121
Epoch [294/300], Train Loss: 0.006054
Validation Loss: 0.00602896
Epoch [295/300], Train Loss: 0.006165
Validation Loss: 0.00602853
Epoch [296/300], Train Loss: 0.006180
Validation Loss: 0.00602831
Epoch [297/300], Train Loss: 0.006227
Validation Loss: 0.00602810
Epoch [298/300], Train Loss: 0.006088
Validation Loss: 0.00602789
Epoch [299/300], Train Loss: 0.006032
Validation Loss: 0.00602769
Epoch [300/300], Train Loss: 0.006223
Validation Loss: 0.00602918

Evaluating model for: Router
Run 22/72 completed in 174.47 seconds with: {'MAE': np.float32(0.19598782), 'MSE': np.float32(0.0667136), 'RMSE': np.float32(0.25828975), 'SAE': np.float32(0.00037298765), 'NDE': np.float32(0.0129176285)}

Run 23/72: hidden=128, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Router
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.109532
Validation Loss: 0.10560207
Epoch [2/300], Train Loss: 0.104932
Validation Loss: 0.10085530
Epoch [3/300], Train Loss: 0.100596
Validation Loss: 0.09597840
Epoch [4/300], Train Loss: 0.095209
Validation Loss: 0.09108156
Epoch [5/300], Train Loss: 0.089283
Validation Loss: 0.08586910
Epoch [6/300], Train Loss: 0.084203
Validation Loss: 0.08007015
Epoch [7/300], Train Loss: 0.078610
Validation Loss: 0.07374481
Epoch [8/300], Train Loss: 0.071648
Validation Loss: 0.06628206
Epoch [9/300], Train Loss: 0.063393
Validation Loss: 0.05745691
Epoch [10/300], Train Loss: 0.053823
Validation Loss: 0.04615183
Epoch [11/300], Train Loss: 0.041267
Validation Loss: 0.03107302
Epoch [12/300], Train Loss: 0.024667
Validation Loss: 0.01323168
Epoch [13/300], Train Loss: 0.009282
Validation Loss: 0.00777304
Epoch [14/300], Train Loss: 0.011200
Validation Loss: 0.01300110
Epoch [15/300], Train Loss: 0.010560
Validation Loss: 0.00702323
Epoch [16/300], Train Loss: 0.006674
Validation Loss: 0.00655560
Epoch [17/300], Train Loss: 0.007195
Validation Loss: 0.00737548
Epoch [18/300], Train Loss: 0.007580
Validation Loss: 0.00708045
Epoch [19/300], Train Loss: 0.006990
Validation Loss: 0.00638573
Epoch [20/300], Train Loss: 0.006544
Validation Loss: 0.00629572
Epoch [21/300], Train Loss: 0.006481
Validation Loss: 0.00650169
Epoch [22/300], Train Loss: 0.006544
Validation Loss: 0.00642206
Epoch [23/300], Train Loss: 0.006561
Validation Loss: 0.00626552
Epoch [24/300], Train Loss: 0.006393
Validation Loss: 0.00623916
Epoch [25/300], Train Loss: 0.006385
Validation Loss: 0.00625520
Epoch [26/300], Train Loss: 0.006322
Validation Loss: 0.00624370
Epoch [27/300], Train Loss: 0.006422
Validation Loss: 0.00623327
Epoch [28/300], Train Loss: 0.006398
Validation Loss: 0.00624032
Epoch [29/300], Train Loss: 0.006514
Validation Loss: 0.00623847
Epoch [30/300], Train Loss: 0.006300
Validation Loss: 0.00623233
Epoch [31/300], Train Loss: 0.006300
Validation Loss: 0.00623136
Epoch [32/300], Train Loss: 0.006348
Validation Loss: 0.00623157
Epoch [33/300], Train Loss: 0.006513
Validation Loss: 0.00623581
Epoch [34/300], Train Loss: 0.006337
Validation Loss: 0.00622941
Epoch [35/300], Train Loss: 0.006361
Validation Loss: 0.00622474
Epoch [36/300], Train Loss: 0.006402
Validation Loss: 0.00622464
Epoch [37/300], Train Loss: 0.006337
Validation Loss: 0.00622312
Epoch [38/300], Train Loss: 0.006221
Validation Loss: 0.00622330
Epoch [39/300], Train Loss: 0.006327
Validation Loss: 0.00622831
Epoch [40/300], Train Loss: 0.006454
Validation Loss: 0.00622327
Epoch [41/300], Train Loss: 0.006396
Validation Loss: 0.00621745
Epoch [42/300], Train Loss: 0.006509
Validation Loss: 0.00621654
Epoch [43/300], Train Loss: 0.006465
Validation Loss: 0.00621545
Epoch [44/300], Train Loss: 0.006333
Validation Loss: 0.00621366
Epoch [45/300], Train Loss: 0.006323
Validation Loss: 0.00621388
Epoch [46/300], Train Loss: 0.006303
Validation Loss: 0.00621331
Epoch [47/300], Train Loss: 0.006396
Validation Loss: 0.00621513
Epoch [48/300], Train Loss: 0.006502
Validation Loss: 0.00621441
Epoch [49/300], Train Loss: 0.006399
Validation Loss: 0.00620969
Epoch [50/300], Train Loss: 0.006396
Validation Loss: 0.00620657
Epoch [51/300], Train Loss: 0.006369
Validation Loss: 0.00620529
Epoch [52/300], Train Loss: 0.006414
Validation Loss: 0.00620420
Epoch [53/300], Train Loss: 0.006378
Validation Loss: 0.00620299
Epoch [54/300], Train Loss: 0.006351
Validation Loss: 0.00620623
Epoch [55/300], Train Loss: 0.006365
Validation Loss: 0.00620327
Epoch [56/300], Train Loss: 0.006367
Validation Loss: 0.00619978
Epoch [57/300], Train Loss: 0.006445
Validation Loss: 0.00619838
Epoch [58/300], Train Loss: 0.006299
Validation Loss: 0.00619733
Epoch [59/300], Train Loss: 0.006352
Validation Loss: 0.00619695
Epoch [60/300], Train Loss: 0.006334
Validation Loss: 0.00619548
Epoch [61/300], Train Loss: 0.006276
Validation Loss: 0.00620598
Epoch [62/300], Train Loss: 0.006444
Validation Loss: 0.00621457
Epoch [63/300], Train Loss: 0.006215
Validation Loss: 0.00619544
Epoch [64/300], Train Loss: 0.006409
Validation Loss: 0.00619124
Epoch [65/300], Train Loss: 0.006263
Validation Loss: 0.00618954
Epoch [66/300], Train Loss: 0.006445
Validation Loss: 0.00619388
Epoch [67/300], Train Loss: 0.006271
Validation Loss: 0.00619450
Epoch [68/300], Train Loss: 0.006270
Validation Loss: 0.00618760
Epoch [69/300], Train Loss: 0.006304
Validation Loss: 0.00618536
Epoch [70/300], Train Loss: 0.006323
Validation Loss: 0.00618439
Epoch [71/300], Train Loss: 0.006367
Validation Loss: 0.00618326
Epoch [72/300], Train Loss: 0.006165
Validation Loss: 0.00618311
Epoch [73/300], Train Loss: 0.006220
Validation Loss: 0.00618845
Epoch [74/300], Train Loss: 0.006374
Validation Loss: 0.00618619
Epoch [75/300], Train Loss: 0.006217
Validation Loss: 0.00618166
Epoch [76/300], Train Loss: 0.006344
Validation Loss: 0.00617965
Epoch [77/300], Train Loss: 0.006331
Validation Loss: 0.00617791
Epoch [78/300], Train Loss: 0.006332
Validation Loss: 0.00617633
Epoch [79/300], Train Loss: 0.006218
Validation Loss: 0.00617616
Epoch [80/300], Train Loss: 0.006367
Validation Loss: 0.00617847
Epoch [81/300], Train Loss: 0.006205
Validation Loss: 0.00617460
Epoch [82/300], Train Loss: 0.006440
Validation Loss: 0.00617126
Epoch [83/300], Train Loss: 0.006332
Validation Loss: 0.00617023
Epoch [84/300], Train Loss: 0.006238
Validation Loss: 0.00617073
Epoch [85/300], Train Loss: 0.006282
Validation Loss: 0.00617238
Epoch [86/300], Train Loss: 0.006239
Validation Loss: 0.00617134
Epoch [87/300], Train Loss: 0.006298
Validation Loss: 0.00616884
Epoch [88/300], Train Loss: 0.006273
Validation Loss: 0.00616509
Epoch [89/300], Train Loss: 0.006294
Validation Loss: 0.00616461
Epoch [90/300], Train Loss: 0.006420
Validation Loss: 0.00616283
Epoch [91/300], Train Loss: 0.006357
Validation Loss: 0.00616334
Epoch [92/300], Train Loss: 0.006276
Validation Loss: 0.00617066
Epoch [93/300], Train Loss: 0.006335
Validation Loss: 0.00617488
Epoch [94/300], Train Loss: 0.006141
Validation Loss: 0.00616792
Epoch [95/300], Train Loss: 0.006278
Validation Loss: 0.00615960
Epoch [96/300], Train Loss: 0.006345
Validation Loss: 0.00615689
Epoch [97/300], Train Loss: 0.006233
Validation Loss: 0.00615583
Epoch [98/300], Train Loss: 0.006321
Validation Loss: 0.00615572
Epoch [99/300], Train Loss: 0.006295
Validation Loss: 0.00615748
Epoch [100/300], Train Loss: 0.006290
Validation Loss: 0.00615915
Epoch [101/300], Train Loss: 0.006230
Validation Loss: 0.00615987
Epoch [102/300], Train Loss: 0.006303
Validation Loss: 0.00615356
Epoch [103/300], Train Loss: 0.006267
Validation Loss: 0.00615050
Epoch [104/300], Train Loss: 0.006212
Validation Loss: 0.00614966
Epoch [105/300], Train Loss: 0.006291
Validation Loss: 0.00614875
Epoch [106/300], Train Loss: 0.006445
Validation Loss: 0.00614948
Epoch [107/300], Train Loss: 0.006245
Validation Loss: 0.00614854
Epoch [108/300], Train Loss: 0.006417
Validation Loss: 0.00614612
Epoch [109/300], Train Loss: 0.006473
Validation Loss: 0.00614541
Epoch [110/300], Train Loss: 0.006239
Validation Loss: 0.00614386
Epoch [111/300], Train Loss: 0.006217
Validation Loss: 0.00614420
Epoch [112/300], Train Loss: 0.006357
Validation Loss: 0.00614787
Epoch [113/300], Train Loss: 0.006350
Validation Loss: 0.00614419
Epoch [114/300], Train Loss: 0.006382
Validation Loss: 0.00613991
Epoch [115/300], Train Loss: 0.006326
Validation Loss: 0.00614030
Epoch [116/300], Train Loss: 0.006237
Validation Loss: 0.00613787
Epoch [117/300], Train Loss: 0.006257
Validation Loss: 0.00614076
Epoch [118/300], Train Loss: 0.006235
Validation Loss: 0.00613962
Epoch [119/300], Train Loss: 0.006225
Validation Loss: 0.00613673
Epoch [120/300], Train Loss: 0.006247
Validation Loss: 0.00613453
Epoch [121/300], Train Loss: 0.006181
Validation Loss: 0.00613394
Epoch [122/300], Train Loss: 0.006204
Validation Loss: 0.00613270
Epoch [123/300], Train Loss: 0.006269
Validation Loss: 0.00613378
Epoch [124/300], Train Loss: 0.006247
Validation Loss: 0.00613764
Epoch [125/300], Train Loss: 0.006327
Validation Loss: 0.00613669
Epoch [126/300], Train Loss: 0.006312
Validation Loss: 0.00613197
Epoch [127/300], Train Loss: 0.006246
Validation Loss: 0.00612868
Epoch [128/300], Train Loss: 0.006351
Validation Loss: 0.00612808
Epoch [129/300], Train Loss: 0.006169
Validation Loss: 0.00612727
Epoch [130/300], Train Loss: 0.006365
Validation Loss: 0.00612920
Epoch [131/300], Train Loss: 0.006209
Validation Loss: 0.00612994
Epoch [132/300], Train Loss: 0.006193
Validation Loss: 0.00612954
Epoch [133/300], Train Loss: 0.006193
Validation Loss: 0.00612482
Epoch [134/300], Train Loss: 0.006328
Validation Loss: 0.00612368
Epoch [135/300], Train Loss: 0.006143
Validation Loss: 0.00612239
Epoch [136/300], Train Loss: 0.006249
Validation Loss: 0.00612228
Epoch [137/300], Train Loss: 0.006388
Validation Loss: 0.00612053
Epoch [138/300], Train Loss: 0.006199
Validation Loss: 0.00612014
Epoch [139/300], Train Loss: 0.006192
Validation Loss: 0.00612001
Epoch [140/300], Train Loss: 0.006167
Validation Loss: 0.00612067
Epoch [141/300], Train Loss: 0.006080
Validation Loss: 0.00612043
Epoch [142/300], Train Loss: 0.006140
Validation Loss: 0.00611832
Epoch [143/300], Train Loss: 0.006238
Validation Loss: 0.00611727
Epoch [144/300], Train Loss: 0.006223
Validation Loss: 0.00611530
Epoch [145/300], Train Loss: 0.006159
Validation Loss: 0.00611479
Epoch [146/300], Train Loss: 0.006115
Validation Loss: 0.00611587
Epoch [147/300], Train Loss: 0.006277
Validation Loss: 0.00611597
Epoch [148/300], Train Loss: 0.006112
Validation Loss: 0.00611296
Epoch [149/300], Train Loss: 0.006323
Validation Loss: 0.00611193
Epoch [150/300], Train Loss: 0.006435
Validation Loss: 0.00611352
Epoch [151/300], Train Loss: 0.006205
Validation Loss: 0.00611529
Epoch [152/300], Train Loss: 0.006371
Validation Loss: 0.00611080
Epoch [153/300], Train Loss: 0.006086
Validation Loss: 0.00610954
Epoch [154/300], Train Loss: 0.006108
Validation Loss: 0.00610926
Epoch [155/300], Train Loss: 0.006295
Validation Loss: 0.00611443
Epoch [156/300], Train Loss: 0.006227
Validation Loss: 0.00611107
Epoch [157/300], Train Loss: 0.006297
Validation Loss: 0.00610662
Epoch [158/300], Train Loss: 0.006197
Validation Loss: 0.00610822
Epoch [159/300], Train Loss: 0.006314
Validation Loss: 0.00610535
Epoch [160/300], Train Loss: 0.006187
Validation Loss: 0.00610456
Epoch [161/300], Train Loss: 0.006249
Validation Loss: 0.00610888
Epoch [162/300], Train Loss: 0.006150
Validation Loss: 0.00610889
Epoch [163/300], Train Loss: 0.006254
Validation Loss: 0.00610585
Epoch [164/300], Train Loss: 0.006122
Validation Loss: 0.00610221
Epoch [165/300], Train Loss: 0.006095
Validation Loss: 0.00610123
Epoch [166/300], Train Loss: 0.006084
Validation Loss: 0.00610077
Epoch [167/300], Train Loss: 0.006127
Validation Loss: 0.00610099
Epoch [168/300], Train Loss: 0.006165
Validation Loss: 0.00610132
Epoch [169/300], Train Loss: 0.006301
Validation Loss: 0.00610035
Epoch [170/300], Train Loss: 0.006069
Validation Loss: 0.00609840
Epoch [171/300], Train Loss: 0.006222
Validation Loss: 0.00609795
Epoch [172/300], Train Loss: 0.006165
Validation Loss: 0.00609903
Epoch [173/300], Train Loss: 0.006061
Validation Loss: 0.00609845
Epoch [174/300], Train Loss: 0.006278
Validation Loss: 0.00609763
Epoch [175/300], Train Loss: 0.006319
Validation Loss: 0.00609561
Epoch [176/300], Train Loss: 0.006205
Validation Loss: 0.00609487
Epoch [177/300], Train Loss: 0.006058
Validation Loss: 0.00609591
Epoch [178/300], Train Loss: 0.006070
Validation Loss: 0.00609359
Epoch [179/300], Train Loss: 0.006155
Validation Loss: 0.00609475
Epoch [180/300], Train Loss: 0.006368
Validation Loss: 0.00609841
Epoch [181/300], Train Loss: 0.006193
Validation Loss: 0.00609438
Epoch [182/300], Train Loss: 0.006166
Validation Loss: 0.00609205
Epoch [183/300], Train Loss: 0.006345
Validation Loss: 0.00609117
Epoch [184/300], Train Loss: 0.006166
Validation Loss: 0.00609022
Epoch [185/300], Train Loss: 0.006048
Validation Loss: 0.00608967
Epoch [186/300], Train Loss: 0.006247
Validation Loss: 0.00608910
Epoch [187/300], Train Loss: 0.006227
Validation Loss: 0.00608854
Epoch [188/300], Train Loss: 0.006122
Validation Loss: 0.00608795
Epoch [189/300], Train Loss: 0.006213
Validation Loss: 0.00608741
Epoch [190/300], Train Loss: 0.006147
Validation Loss: 0.00608698
Epoch [191/300], Train Loss: 0.006287
Validation Loss: 0.00608667
Epoch [192/300], Train Loss: 0.006059
Validation Loss: 0.00608583
Epoch [193/300], Train Loss: 0.006223
Validation Loss: 0.00609042
Epoch [194/300], Train Loss: 0.006262
Validation Loss: 0.00609156
Epoch [195/300], Train Loss: 0.006170
Validation Loss: 0.00608612
Epoch [196/300], Train Loss: 0.006148
Validation Loss: 0.00608525
Epoch [197/300], Train Loss: 0.006166
Validation Loss: 0.00608412
Epoch [198/300], Train Loss: 0.006174
Validation Loss: 0.00608276
Epoch [199/300], Train Loss: 0.006150
Validation Loss: 0.00608245
Epoch [200/300], Train Loss: 0.006230
Validation Loss: 0.00608348
Epoch [201/300], Train Loss: 0.006420
Validation Loss: 0.00608269
Epoch [202/300], Train Loss: 0.006233
Validation Loss: 0.00608123
Epoch [203/300], Train Loss: 0.006126
Validation Loss: 0.00608104
Epoch [204/300], Train Loss: 0.006241
Validation Loss: 0.00607991
Epoch [205/300], Train Loss: 0.006062
Validation Loss: 0.00608044
Epoch [206/300], Train Loss: 0.006121
Validation Loss: 0.00608145
Epoch [207/300], Train Loss: 0.006093
Validation Loss: 0.00608019
Epoch [208/300], Train Loss: 0.006212
Validation Loss: 0.00607860
Epoch [209/300], Train Loss: 0.006133
Validation Loss: 0.00607758
Epoch [210/300], Train Loss: 0.006221
Validation Loss: 0.00607695
Epoch [211/300], Train Loss: 0.006209
Validation Loss: 0.00607656
Epoch [212/300], Train Loss: 0.006137
Validation Loss: 0.00607611
Epoch [213/300], Train Loss: 0.006304
Validation Loss: 0.00607570
Epoch [214/300], Train Loss: 0.006050
Validation Loss: 0.00607539
Epoch [215/300], Train Loss: 0.006107
Validation Loss: 0.00607483
Epoch [216/300], Train Loss: 0.006398
Validation Loss: 0.00607447
Epoch [217/300], Train Loss: 0.006088
Validation Loss: 0.00607445
Epoch [218/300], Train Loss: 0.006112
Validation Loss: 0.00607370
Epoch [219/300], Train Loss: 0.006150
Validation Loss: 0.00607377
Epoch [220/300], Train Loss: 0.006055
Validation Loss: 0.00607407
Epoch [221/300], Train Loss: 0.006272
Validation Loss: 0.00607537
Epoch [222/300], Train Loss: 0.006107
Validation Loss: 0.00607328
Epoch [223/300], Train Loss: 0.006151
Validation Loss: 0.00607174
Epoch [224/300], Train Loss: 0.006236
Validation Loss: 0.00607104
Epoch [225/300], Train Loss: 0.006138
Validation Loss: 0.00607104
Epoch [226/300], Train Loss: 0.006150
Validation Loss: 0.00607088
Epoch [227/300], Train Loss: 0.006067
Validation Loss: 0.00607020
Epoch [228/300], Train Loss: 0.005996
Validation Loss: 0.00607001
Epoch [229/300], Train Loss: 0.006170
Validation Loss: 0.00607119
Epoch [230/300], Train Loss: 0.006177
Validation Loss: 0.00607120
Epoch [231/300], Train Loss: 0.006045
Validation Loss: 0.00606981
Epoch [232/300], Train Loss: 0.006027
Validation Loss: 0.00606858
Epoch [233/300], Train Loss: 0.006231
Validation Loss: 0.00606814
Epoch [234/300], Train Loss: 0.006171
Validation Loss: 0.00606711
Epoch [235/300], Train Loss: 0.006150
Validation Loss: 0.00606700
Epoch [236/300], Train Loss: 0.006197
Validation Loss: 0.00606629
Epoch [237/300], Train Loss: 0.006055
Validation Loss: 0.00606584
Epoch [238/300], Train Loss: 0.006207
Validation Loss: 0.00606555
Epoch [239/300], Train Loss: 0.006347
Validation Loss: 0.00606530
Epoch [240/300], Train Loss: 0.006183
Validation Loss: 0.00606466
Epoch [241/300], Train Loss: 0.006129
Validation Loss: 0.00606421
Epoch [242/300], Train Loss: 0.006086
Validation Loss: 0.00606434
Epoch [243/300], Train Loss: 0.006157
Validation Loss: 0.00606427
Epoch [244/300], Train Loss: 0.006076
Validation Loss: 0.00606379
Epoch [245/300], Train Loss: 0.006223
Validation Loss: 0.00606394
Epoch [246/300], Train Loss: 0.006084
Validation Loss: 0.00606349
Epoch [247/300], Train Loss: 0.006044
Validation Loss: 0.00606224
Epoch [248/300], Train Loss: 0.006174
Validation Loss: 0.00606166
Epoch [249/300], Train Loss: 0.006114
Validation Loss: 0.00606142
Epoch [250/300], Train Loss: 0.006170
Validation Loss: 0.00606093
Epoch [251/300], Train Loss: 0.006201
Validation Loss: 0.00606085
Epoch [252/300], Train Loss: 0.006177
Validation Loss: 0.00606022
Epoch [253/300], Train Loss: 0.006141
Validation Loss: 0.00606013
Epoch [254/300], Train Loss: 0.006040
Validation Loss: 0.00605967
Epoch [255/300], Train Loss: 0.006225
Validation Loss: 0.00605925
Epoch [256/300], Train Loss: 0.006119
Validation Loss: 0.00605941
Epoch [257/300], Train Loss: 0.006077
Validation Loss: 0.00605949
Epoch [258/300], Train Loss: 0.006373
Validation Loss: 0.00605959
Epoch [259/300], Train Loss: 0.006069
Validation Loss: 0.00605825
Epoch [260/300], Train Loss: 0.006056
Validation Loss: 0.00605754
Epoch [261/300], Train Loss: 0.006067
Validation Loss: 0.00605719
Epoch [262/300], Train Loss: 0.006183
Validation Loss: 0.00605687
Epoch [263/300], Train Loss: 0.006174
Validation Loss: 0.00605649
Epoch [264/300], Train Loss: 0.006160
Validation Loss: 0.00605619
Epoch [265/300], Train Loss: 0.006174
Validation Loss: 0.00605587
Epoch [266/300], Train Loss: 0.006133
Validation Loss: 0.00605552
Epoch [267/300], Train Loss: 0.006095
Validation Loss: 0.00605531
Epoch [268/300], Train Loss: 0.006038
Validation Loss: 0.00605673
Epoch [269/300], Train Loss: 0.006054
Validation Loss: 0.00605767
Epoch [270/300], Train Loss: 0.006160
Validation Loss: 0.00605710
Epoch [271/300], Train Loss: 0.006038
Validation Loss: 0.00605699
Epoch [272/300], Train Loss: 0.006147
Validation Loss: 0.00605488
Epoch [273/300], Train Loss: 0.006079
Validation Loss: 0.00605344
Epoch [274/300], Train Loss: 0.006262
Validation Loss: 0.00605313
Epoch [275/300], Train Loss: 0.006074
Validation Loss: 0.00605285
Epoch [276/300], Train Loss: 0.006172
Validation Loss: 0.00605268
Epoch [277/300], Train Loss: 0.006135
Validation Loss: 0.00605221
Epoch [278/300], Train Loss: 0.006131
Validation Loss: 0.00605182
Epoch [279/300], Train Loss: 0.006132
Validation Loss: 0.00605177
Epoch [280/300], Train Loss: 0.006104
Validation Loss: 0.00605165
Epoch [281/300], Train Loss: 0.006165
Validation Loss: 0.00605159
Epoch [282/300], Train Loss: 0.006149
Validation Loss: 0.00605095
Epoch [283/300], Train Loss: 0.006020
Validation Loss: 0.00605028
Epoch [284/300], Train Loss: 0.006168
Validation Loss: 0.00605001
Epoch [285/300], Train Loss: 0.006129
Validation Loss: 0.00604973
Epoch [286/300], Train Loss: 0.006262
Validation Loss: 0.00604950
Epoch [287/300], Train Loss: 0.006116
Validation Loss: 0.00604927
Epoch [288/300], Train Loss: 0.006060
Validation Loss: 0.00604889
Epoch [289/300], Train Loss: 0.006254
Validation Loss: 0.00604906
Epoch [290/300], Train Loss: 0.005996
Validation Loss: 0.00604900
Epoch [291/300], Train Loss: 0.005988
Validation Loss: 0.00604965
Epoch [292/300], Train Loss: 0.006152
Validation Loss: 0.00605110
Epoch [293/300], Train Loss: 0.006355
Validation Loss: 0.00604957
Epoch [294/300], Train Loss: 0.006033
Validation Loss: 0.00604727
Epoch [295/300], Train Loss: 0.006129
Validation Loss: 0.00604699
Epoch [296/300], Train Loss: 0.006144
Validation Loss: 0.00604669
Epoch [297/300], Train Loss: 0.006199
Validation Loss: 0.00604646
Epoch [298/300], Train Loss: 0.006057
Validation Loss: 0.00604610
Epoch [299/300], Train Loss: 0.005993
Validation Loss: 0.00604587
Epoch [300/300], Train Loss: 0.006192
Validation Loss: 0.00604790

Evaluating model for: Router
Run 23/72 completed in 189.11 seconds with: {'MAE': np.float32(0.1955758), 'MSE': np.float32(0.06655902), 'RMSE': np.float32(0.25799033), 'SAE': np.float32(0.00040701043), 'NDE': np.float32(0.012902654)}

Run 24/72: hidden=128, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Router
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.066529
Validation Loss: 0.06324582
Epoch [2/300], Train Loss: 0.062214
Validation Loss: 0.05876834
Epoch [3/300], Train Loss: 0.058061
Validation Loss: 0.05418894
Epoch [4/300], Train Loss: 0.053048
Validation Loss: 0.04949327
Epoch [5/300], Train Loss: 0.047660
Validation Loss: 0.04446852
Epoch [6/300], Train Loss: 0.042790
Validation Loss: 0.03921841
Epoch [7/300], Train Loss: 0.037517
Validation Loss: 0.03333280
Epoch [8/300], Train Loss: 0.031200
Validation Loss: 0.02668985
Epoch [9/300], Train Loss: 0.024131
Validation Loss: 0.01928595
Epoch [10/300], Train Loss: 0.016467
Validation Loss: 0.01161310
Epoch [11/300], Train Loss: 0.009155
Validation Loss: 0.00618284
Epoch [12/300], Train Loss: 0.006312
Validation Loss: 0.00861173
Epoch [13/300], Train Loss: 0.008303
Validation Loss: 0.00752940
Epoch [14/300], Train Loss: 0.006405
Validation Loss: 0.00595877
Epoch [15/300], Train Loss: 0.005918
Validation Loss: 0.00625798
Epoch [16/300], Train Loss: 0.006268
Validation Loss: 0.00643604
Epoch [17/300], Train Loss: 0.006316
Validation Loss: 0.00620173
Epoch [18/300], Train Loss: 0.005987
Validation Loss: 0.00596827
Epoch [19/300], Train Loss: 0.005736
Validation Loss: 0.00596982
Epoch [20/300], Train Loss: 0.005904
Validation Loss: 0.00606339
Epoch [21/300], Train Loss: 0.005838
Validation Loss: 0.00601561
Epoch [22/300], Train Loss: 0.005772
Validation Loss: 0.00595025
Epoch [23/300], Train Loss: 0.005863
Validation Loss: 0.00593746
Epoch [24/300], Train Loss: 0.005781
Validation Loss: 0.00593797
Epoch [25/300], Train Loss: 0.005753
Validation Loss: 0.00593661
Epoch [26/300], Train Loss: 0.005685
Validation Loss: 0.00593686
Epoch [27/300], Train Loss: 0.005780
Validation Loss: 0.00593930
Epoch [28/300], Train Loss: 0.005787
Validation Loss: 0.00594019
Epoch [29/300], Train Loss: 0.005907
Validation Loss: 0.00593593
Epoch [30/300], Train Loss: 0.005693
Validation Loss: 0.00593439
Epoch [31/300], Train Loss: 0.005691
Validation Loss: 0.00593608
Epoch [32/300], Train Loss: 0.005737
Validation Loss: 0.00594057
Epoch [33/300], Train Loss: 0.005924
Validation Loss: 0.00594932
Epoch [34/300], Train Loss: 0.005735
Validation Loss: 0.00594115
Epoch [35/300], Train Loss: 0.005764
Validation Loss: 0.00593407
Epoch [36/300], Train Loss: 0.005799
Validation Loss: 0.00593351
Epoch [37/300], Train Loss: 0.005733
Validation Loss: 0.00593241
Epoch [38/300], Train Loss: 0.005607
Validation Loss: 0.00593331
Epoch [39/300], Train Loss: 0.005735
Validation Loss: 0.00593956
Epoch [40/300], Train Loss: 0.005869
Validation Loss: 0.00593733
Epoch [41/300], Train Loss: 0.005799
Validation Loss: 0.00592922
Epoch [42/300], Train Loss: 0.005941
Validation Loss: 0.00592885
Epoch [43/300], Train Loss: 0.005867
Validation Loss: 0.00592887
Epoch [44/300], Train Loss: 0.005738
Validation Loss: 0.00592792
Epoch [45/300], Train Loss: 0.005738
Validation Loss: 0.00592877
Epoch [46/300], Train Loss: 0.005694
Validation Loss: 0.00592957
Epoch [47/300], Train Loss: 0.005808
Validation Loss: 0.00593311
Epoch [48/300], Train Loss: 0.005930
Validation Loss: 0.00593393
Epoch [49/300], Train Loss: 0.005822
Validation Loss: 0.00592892
Epoch [50/300], Train Loss: 0.005820
Validation Loss: 0.00592536
Epoch [51/300], Train Loss: 0.005791
Validation Loss: 0.00592454
Epoch [52/300], Train Loss: 0.005824
Validation Loss: 0.00592426
Epoch [53/300], Train Loss: 0.005794
Validation Loss: 0.00592375
Epoch [54/300], Train Loss: 0.005792
Validation Loss: 0.00592838
Epoch [55/300], Train Loss: 0.005795
Validation Loss: 0.00592682
Epoch [56/300], Train Loss: 0.005800
Validation Loss: 0.00592353
Epoch [57/300], Train Loss: 0.005865
Validation Loss: 0.00592168
Epoch [58/300], Train Loss: 0.005722
Validation Loss: 0.00592133
Epoch [59/300], Train Loss: 0.005776
Validation Loss: 0.00592183
Epoch [60/300], Train Loss: 0.005771
Validation Loss: 0.00592034
Epoch [61/300], Train Loss: 0.005712
Validation Loss: 0.00592826
Epoch [62/300], Train Loss: 0.005881
Validation Loss: 0.00593905
Epoch [63/300], Train Loss: 0.005627
Validation Loss: 0.00592551
Epoch [64/300], Train Loss: 0.005834
Validation Loss: 0.00591825
Epoch [65/300], Train Loss: 0.005695
Validation Loss: 0.00591810
Epoch [66/300], Train Loss: 0.005887
Validation Loss: 0.00592205
Epoch [67/300], Train Loss: 0.005705
Validation Loss: 0.00592272
Epoch [68/300], Train Loss: 0.005695
Validation Loss: 0.00591761
Epoch [69/300], Train Loss: 0.005744
Validation Loss: 0.00591592
Epoch [70/300], Train Loss: 0.005772
Validation Loss: 0.00591532
Epoch [71/300], Train Loss: 0.005811
Validation Loss: 0.00591491
Epoch [72/300], Train Loss: 0.005597
Validation Loss: 0.00591506
Epoch [73/300], Train Loss: 0.005652
Validation Loss: 0.00591943
Epoch [74/300], Train Loss: 0.005807
Validation Loss: 0.00591932
Epoch [75/300], Train Loss: 0.005646
Validation Loss: 0.00591668
Epoch [76/300], Train Loss: 0.005791
Validation Loss: 0.00591522
Epoch [77/300], Train Loss: 0.005781
Validation Loss: 0.00591356
Epoch [78/300], Train Loss: 0.005795
Validation Loss: 0.00591210
Epoch [79/300], Train Loss: 0.005662
Validation Loss: 0.00591205
Epoch [80/300], Train Loss: 0.005823
Validation Loss: 0.00591424
Epoch [81/300], Train Loss: 0.005662
Validation Loss: 0.00591207
Epoch [82/300], Train Loss: 0.005874
Validation Loss: 0.00590921
Epoch [83/300], Train Loss: 0.005776
Validation Loss: 0.00590875
Epoch [84/300], Train Loss: 0.005680
Validation Loss: 0.00590986
Epoch [85/300], Train Loss: 0.005741
Validation Loss: 0.00591170
Epoch [86/300], Train Loss: 0.005688
Validation Loss: 0.00591179
Epoch [87/300], Train Loss: 0.005741
Validation Loss: 0.00591081
Epoch [88/300], Train Loss: 0.005734
Validation Loss: 0.00590694
Epoch [89/300], Train Loss: 0.005743
Validation Loss: 0.00590512
Epoch [90/300], Train Loss: 0.005897
Validation Loss: 0.00590448
Epoch [91/300], Train Loss: 0.005791
Validation Loss: 0.00590473
Epoch [92/300], Train Loss: 0.005750
Validation Loss: 0.00591059
Epoch [93/300], Train Loss: 0.005803
Validation Loss: 0.00591677
Epoch [94/300], Train Loss: 0.005584
Validation Loss: 0.00591348
Epoch [95/300], Train Loss: 0.005725
Validation Loss: 0.00590644
Epoch [96/300], Train Loss: 0.005798
Validation Loss: 0.00590234
Epoch [97/300], Train Loss: 0.005700
Validation Loss: 0.00590064
Epoch [98/300], Train Loss: 0.005785
Validation Loss: 0.00590065
Epoch [99/300], Train Loss: 0.005751
Validation Loss: 0.00590222
Epoch [100/300], Train Loss: 0.005737
Validation Loss: 0.00590571
Epoch [101/300], Train Loss: 0.005700
Validation Loss: 0.00590865
Epoch [102/300], Train Loss: 0.005776
Validation Loss: 0.00590287
Epoch [103/300], Train Loss: 0.005734
Validation Loss: 0.00589705
Epoch [104/300], Train Loss: 0.005668
Validation Loss: 0.00589663
Epoch [105/300], Train Loss: 0.005771
Validation Loss: 0.00589631
Epoch [106/300], Train Loss: 0.005930
Validation Loss: 0.00589716
Epoch [107/300], Train Loss: 0.005730
Validation Loss: 0.00589756
Epoch [108/300], Train Loss: 0.005905
Validation Loss: 0.00589595
Epoch [109/300], Train Loss: 0.005948
Validation Loss: 0.00589619
Epoch [110/300], Train Loss: 0.005703
Validation Loss: 0.00589457
Epoch [111/300], Train Loss: 0.005671
Validation Loss: 0.00589539
Epoch [112/300], Train Loss: 0.005832
Validation Loss: 0.00589976
Epoch [113/300], Train Loss: 0.005850
Validation Loss: 0.00589638
Epoch [114/300], Train Loss: 0.005846
Validation Loss: 0.00589053
Epoch [115/300], Train Loss: 0.005797
Validation Loss: 0.00589042
Epoch [116/300], Train Loss: 0.005700
Validation Loss: 0.00588953
Epoch [117/300], Train Loss: 0.005726
Validation Loss: 0.00589269
Epoch [118/300], Train Loss: 0.005705
Validation Loss: 0.00589277
Epoch [119/300], Train Loss: 0.005704
Validation Loss: 0.00589063
Epoch [120/300], Train Loss: 0.005725
Validation Loss: 0.00588834
Epoch [121/300], Train Loss: 0.005658
Validation Loss: 0.00588625
Epoch [122/300], Train Loss: 0.005668
Validation Loss: 0.00588568
Epoch [123/300], Train Loss: 0.005737
Validation Loss: 0.00588738
Epoch [124/300], Train Loss: 0.005732
Validation Loss: 0.00589133
Epoch [125/300], Train Loss: 0.005808
Validation Loss: 0.00589204
Epoch [126/300], Train Loss: 0.005783
Validation Loss: 0.00588831
Epoch [127/300], Train Loss: 0.005708
Validation Loss: 0.00588303
Epoch [128/300], Train Loss: 0.005847
Validation Loss: 0.00588224
Epoch [129/300], Train Loss: 0.005659
Validation Loss: 0.00588227
Epoch [130/300], Train Loss: 0.005850
Validation Loss: 0.00588410
Epoch [131/300], Train Loss: 0.005680
Validation Loss: 0.00588533
Epoch [132/300], Train Loss: 0.005670
Validation Loss: 0.00588629
Epoch [133/300], Train Loss: 0.005683
Validation Loss: 0.00588173
Epoch [134/300], Train Loss: 0.005856
Validation Loss: 0.00588047
Epoch [135/300], Train Loss: 0.005631
Validation Loss: 0.00587765
Epoch [136/300], Train Loss: 0.005737
Validation Loss: 0.00587725
Epoch [137/300], Train Loss: 0.005883
Validation Loss: 0.00587637
Epoch [138/300], Train Loss: 0.005679
Validation Loss: 0.00587627
Epoch [139/300], Train Loss: 0.005678
Validation Loss: 0.00587679
Epoch [140/300], Train Loss: 0.005653
Validation Loss: 0.00587822
Epoch [141/300], Train Loss: 0.005580
Validation Loss: 0.00587889
Epoch [142/300], Train Loss: 0.005628
Validation Loss: 0.00587640
Epoch [143/300], Train Loss: 0.005734
Validation Loss: 0.00587530
Epoch [144/300], Train Loss: 0.005702
Validation Loss: 0.00587209
Epoch [145/300], Train Loss: 0.005640
Validation Loss: 0.00587173
Epoch [146/300], Train Loss: 0.005599
Validation Loss: 0.00587295
Epoch [147/300], Train Loss: 0.005766
Validation Loss: 0.00587360
Epoch [148/300], Train Loss: 0.005590
Validation Loss: 0.00587049
Epoch [149/300], Train Loss: 0.005831
Validation Loss: 0.00586901
Epoch [150/300], Train Loss: 0.005944
Validation Loss: 0.00586876
Epoch [151/300], Train Loss: 0.005706
Validation Loss: 0.00587018
Epoch [152/300], Train Loss: 0.005878
Validation Loss: 0.00586730
Epoch [153/300], Train Loss: 0.005580
Validation Loss: 0.00586623
Epoch [154/300], Train Loss: 0.005589
Validation Loss: 0.00586661
Epoch [155/300], Train Loss: 0.005802
Validation Loss: 0.00587309
Epoch [156/300], Train Loss: 0.005733
Validation Loss: 0.00587038
Epoch [157/300], Train Loss: 0.005792
Validation Loss: 0.00586386
Epoch [158/300], Train Loss: 0.005677
Validation Loss: 0.00586346
Epoch [159/300], Train Loss: 0.005831
Validation Loss: 0.00586219
Epoch [160/300], Train Loss: 0.005696
Validation Loss: 0.00586150
Epoch [161/300], Train Loss: 0.005763
Validation Loss: 0.00586510
Epoch [162/300], Train Loss: 0.005641
Validation Loss: 0.00586687
Epoch [163/300], Train Loss: 0.005764
Validation Loss: 0.00586532
Epoch [164/300], Train Loss: 0.005612
Validation Loss: 0.00586114
Epoch [165/300], Train Loss: 0.005591
Validation Loss: 0.00585923
Epoch [166/300], Train Loss: 0.005575
Validation Loss: 0.00585842
Epoch [167/300], Train Loss: 0.005630
Validation Loss: 0.00585830
Epoch [168/300], Train Loss: 0.005659
Validation Loss: 0.00585804
Epoch [169/300], Train Loss: 0.005816
Validation Loss: 0.00585717
Epoch [170/300], Train Loss: 0.005559
Validation Loss: 0.00585544
Epoch [171/300], Train Loss: 0.005723
Validation Loss: 0.00585545
Epoch [172/300], Train Loss: 0.005650
Validation Loss: 0.00585720
Epoch [173/300], Train Loss: 0.005563
Validation Loss: 0.00585597
Epoch [174/300], Train Loss: 0.005781
Validation Loss: 0.00585457
Epoch [175/300], Train Loss: 0.005829
Validation Loss: 0.00585221
Epoch [176/300], Train Loss: 0.005704
Validation Loss: 0.00585089
Epoch [177/300], Train Loss: 0.005549
Validation Loss: 0.00585075
Epoch [178/300], Train Loss: 0.005560
Validation Loss: 0.00584950
Epoch [179/300], Train Loss: 0.005649
Validation Loss: 0.00585118
Epoch [180/300], Train Loss: 0.005875
Validation Loss: 0.00585465
Epoch [181/300], Train Loss: 0.005715
Validation Loss: 0.00585094
Epoch [182/300], Train Loss: 0.005653
Validation Loss: 0.00584853
Epoch [183/300], Train Loss: 0.005861
Validation Loss: 0.00584733
Epoch [184/300], Train Loss: 0.005656
Validation Loss: 0.00584589
Epoch [185/300], Train Loss: 0.005558
Validation Loss: 0.00584484
Epoch [186/300], Train Loss: 0.005759
Validation Loss: 0.00584424
Epoch [187/300], Train Loss: 0.005735
Validation Loss: 0.00584354
Epoch [188/300], Train Loss: 0.005629
Validation Loss: 0.00584285
Epoch [189/300], Train Loss: 0.005730
Validation Loss: 0.00584236
Epoch [190/300], Train Loss: 0.005647
Validation Loss: 0.00584151
Epoch [191/300], Train Loss: 0.005784
Validation Loss: 0.00584096
Epoch [192/300], Train Loss: 0.005549
Validation Loss: 0.00584045
Epoch [193/300], Train Loss: 0.005742
Validation Loss: 0.00584556
Epoch [194/300], Train Loss: 0.005780
Validation Loss: 0.00584665
Epoch [195/300], Train Loss: 0.005675
Validation Loss: 0.00584117
Epoch [196/300], Train Loss: 0.005665
Validation Loss: 0.00584037
Epoch [197/300], Train Loss: 0.005666
Validation Loss: 0.00583898
Epoch [198/300], Train Loss: 0.005684
Validation Loss: 0.00583674
Epoch [199/300], Train Loss: 0.005675
Validation Loss: 0.00583635
Epoch [200/300], Train Loss: 0.005751
Validation Loss: 0.00583740
Epoch [201/300], Train Loss: 0.005938
Validation Loss: 0.00583649
Epoch [202/300], Train Loss: 0.005741
Validation Loss: 0.00583413
Epoch [203/300], Train Loss: 0.005630
Validation Loss: 0.00583372
Epoch [204/300], Train Loss: 0.005757
Validation Loss: 0.00583314
Epoch [205/300], Train Loss: 0.005565
Validation Loss: 0.00583404
Epoch [206/300], Train Loss: 0.005634
Validation Loss: 0.00583540
Epoch [207/300], Train Loss: 0.005601
Validation Loss: 0.00583398
Epoch [208/300], Train Loss: 0.005729
Validation Loss: 0.00583185
Epoch [209/300], Train Loss: 0.005648
Validation Loss: 0.00583033
Epoch [210/300], Train Loss: 0.005730
Validation Loss: 0.00582925
Epoch [211/300], Train Loss: 0.005709
Validation Loss: 0.00582873
Epoch [212/300], Train Loss: 0.005643
Validation Loss: 0.00582820
Epoch [213/300], Train Loss: 0.005813
Validation Loss: 0.00582770
Epoch [214/300], Train Loss: 0.005556
Validation Loss: 0.00582715
Epoch [215/300], Train Loss: 0.005622
Validation Loss: 0.00582660
Epoch [216/300], Train Loss: 0.005904
Validation Loss: 0.00582618
Epoch [217/300], Train Loss: 0.005594
Validation Loss: 0.00582622
Epoch [218/300], Train Loss: 0.005625
Validation Loss: 0.00582548
Epoch [219/300], Train Loss: 0.005662
Validation Loss: 0.00582582
Epoch [220/300], Train Loss: 0.005567
Validation Loss: 0.00582617
Epoch [221/300], Train Loss: 0.005776
Validation Loss: 0.00582743
Epoch [222/300], Train Loss: 0.005617
Validation Loss: 0.00582508
Epoch [223/300], Train Loss: 0.005665
Validation Loss: 0.00582317
Epoch [224/300], Train Loss: 0.005751
Validation Loss: 0.00582222
Epoch [225/300], Train Loss: 0.005656
Validation Loss: 0.00582230
Epoch [226/300], Train Loss: 0.005676
Validation Loss: 0.00582209
Epoch [227/300], Train Loss: 0.005590
Validation Loss: 0.00582128
Epoch [228/300], Train Loss: 0.005492
Validation Loss: 0.00582113
Epoch [229/300], Train Loss: 0.005673
Validation Loss: 0.00582240
Epoch [230/300], Train Loss: 0.005679
Validation Loss: 0.00582242
Epoch [231/300], Train Loss: 0.005571
Validation Loss: 0.00582071
Epoch [232/300], Train Loss: 0.005551
Validation Loss: 0.00581922
Epoch [233/300], Train Loss: 0.005765
Validation Loss: 0.00581869
Epoch [234/300], Train Loss: 0.005690
Validation Loss: 0.00581735
Epoch [235/300], Train Loss: 0.005670
Validation Loss: 0.00581690
Epoch [236/300], Train Loss: 0.005713
Validation Loss: 0.00581629
Epoch [237/300], Train Loss: 0.005565
Validation Loss: 0.00581572
Epoch [238/300], Train Loss: 0.005737
Validation Loss: 0.00581542
Epoch [239/300], Train Loss: 0.005868
Validation Loss: 0.00581512
Epoch [240/300], Train Loss: 0.005697
Validation Loss: 0.00581440
Epoch [241/300], Train Loss: 0.005653
Validation Loss: 0.00581384
Epoch [242/300], Train Loss: 0.005603
Validation Loss: 0.00581410
Epoch [243/300], Train Loss: 0.005668
Validation Loss: 0.00581397
Epoch [244/300], Train Loss: 0.005594
Validation Loss: 0.00581334
Epoch [245/300], Train Loss: 0.005745
Validation Loss: 0.00581350
Epoch [246/300], Train Loss: 0.005610
Validation Loss: 0.00581304
Epoch [247/300], Train Loss: 0.005559
Validation Loss: 0.00581155
Epoch [248/300], Train Loss: 0.005705
Validation Loss: 0.00581073
Epoch [249/300], Train Loss: 0.005623
Validation Loss: 0.00581022
Epoch [250/300], Train Loss: 0.005692
Validation Loss: 0.00580985
Epoch [251/300], Train Loss: 0.005720
Validation Loss: 0.00580985
Epoch [252/300], Train Loss: 0.005703
Validation Loss: 0.00580898
Epoch [253/300], Train Loss: 0.005651
Validation Loss: 0.00580876
Epoch [254/300], Train Loss: 0.005551
Validation Loss: 0.00580831
Epoch [255/300], Train Loss: 0.005737
Validation Loss: 0.00580794
Epoch [256/300], Train Loss: 0.005645
Validation Loss: 0.00580821
Epoch [257/300], Train Loss: 0.005589
Validation Loss: 0.00580848
Epoch [258/300], Train Loss: 0.005911
Validation Loss: 0.00580880
Epoch [259/300], Train Loss: 0.005598
Validation Loss: 0.00580727
Epoch [260/300], Train Loss: 0.005588
Validation Loss: 0.00580619
Epoch [261/300], Train Loss: 0.005595
Validation Loss: 0.00580569
Epoch [262/300], Train Loss: 0.005720
Validation Loss: 0.00580529
Epoch [263/300], Train Loss: 0.005702
Validation Loss: 0.00580479
Epoch [264/300], Train Loss: 0.005683
Validation Loss: 0.00580448
Epoch [265/300], Train Loss: 0.005704
Validation Loss: 0.00580415
Epoch [266/300], Train Loss: 0.005651
Validation Loss: 0.00580379
Epoch [267/300], Train Loss: 0.005629
Validation Loss: 0.00580362
Epoch [268/300], Train Loss: 0.005562
Validation Loss: 0.00580538
Epoch [269/300], Train Loss: 0.005575
Validation Loss: 0.00580630
Epoch [270/300], Train Loss: 0.005689
Validation Loss: 0.00580551
Epoch [271/300], Train Loss: 0.005564
Validation Loss: 0.00580533
Epoch [272/300], Train Loss: 0.005669
Validation Loss: 0.00580321
Epoch [273/300], Train Loss: 0.005595
Validation Loss: 0.00580174
Epoch [274/300], Train Loss: 0.005785
Validation Loss: 0.00580145
Epoch [275/300], Train Loss: 0.005593
Validation Loss: 0.00580105
Epoch [276/300], Train Loss: 0.005702
Validation Loss: 0.00580073
Epoch [277/300], Train Loss: 0.005667
Validation Loss: 0.00580026
Epoch [278/300], Train Loss: 0.005652
Validation Loss: 0.00580000
Epoch [279/300], Train Loss: 0.005656
Validation Loss: 0.00580002
Epoch [280/300], Train Loss: 0.005632
Validation Loss: 0.00579981
Epoch [281/300], Train Loss: 0.005702
Validation Loss: 0.00579968
Epoch [282/300], Train Loss: 0.005682
Validation Loss: 0.00579903
Epoch [283/300], Train Loss: 0.005537
Validation Loss: 0.00579837
Epoch [284/300], Train Loss: 0.005704
Validation Loss: 0.00579812
Epoch [285/300], Train Loss: 0.005658
Validation Loss: 0.00579792
Epoch [286/300], Train Loss: 0.005804
Validation Loss: 0.00579775
Epoch [287/300], Train Loss: 0.005644
Validation Loss: 0.00579758
Epoch [288/300], Train Loss: 0.005583
Validation Loss: 0.00579715
Epoch [289/300], Train Loss: 0.005774
Validation Loss: 0.00579755
Epoch [290/300], Train Loss: 0.005522
Validation Loss: 0.00579753
Epoch [291/300], Train Loss: 0.005513
Validation Loss: 0.00579831
Epoch [292/300], Train Loss: 0.005683
Validation Loss: 0.00579970
Epoch [293/300], Train Loss: 0.005879
Validation Loss: 0.00579795
Epoch [294/300], Train Loss: 0.005545
Validation Loss: 0.00579553
Epoch [295/300], Train Loss: 0.005657
Validation Loss: 0.00579520
Epoch [296/300], Train Loss: 0.005685
Validation Loss: 0.00579489
Epoch [297/300], Train Loss: 0.005725
Validation Loss: 0.00579462
Epoch [298/300], Train Loss: 0.005584
Validation Loss: 0.00579430
Epoch [299/300], Train Loss: 0.005523
Validation Loss: 0.00579420
Epoch [300/300], Train Loss: 0.005735
Validation Loss: 0.00579651

Evaluating model for: Router
Run 24/72 completed in 204.04 seconds with: {'MAE': np.float32(0.1925198), 'MSE': np.float32(0.06278285), 'RMSE': np.float32(0.25056505), 'SAE': np.float32(0.0006078317), 'NDE': np.float32(0.012531299)}

Run 25/72: hidden=256, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Router
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.074197
Validation Loss: 0.01335930
Epoch [2/300], Train Loss: 0.010411
Validation Loss: 0.00904313
Epoch [3/300], Train Loss: 0.008744
Validation Loss: 0.00866500
Epoch [4/300], Train Loss: 0.008404
Validation Loss: 0.00835792
Epoch [5/300], Train Loss: 0.008090
Validation Loss: 0.00805770
Epoch [6/300], Train Loss: 0.007840
Validation Loss: 0.00781601
Epoch [7/300], Train Loss: 0.007541
Validation Loss: 0.00764527
Epoch [8/300], Train Loss: 0.007365
Validation Loss: 0.00750785
Epoch [9/300], Train Loss: 0.007236
Validation Loss: 0.00736090
Epoch [10/300], Train Loss: 0.007128
Validation Loss: 0.00723639
Epoch [11/300], Train Loss: 0.007056
Validation Loss: 0.00714129
Epoch [12/300], Train Loss: 0.006900
Validation Loss: 0.00705086
Epoch [13/300], Train Loss: 0.006837
Validation Loss: 0.00697431
Epoch [14/300], Train Loss: 0.006745
Validation Loss: 0.00691800
Epoch [15/300], Train Loss: 0.006664
Validation Loss: 0.00682917
Epoch [16/300], Train Loss: 0.006580
Validation Loss: 0.00677349
Epoch [17/300], Train Loss: 0.006542
Validation Loss: 0.00671065
Epoch [18/300], Train Loss: 0.006467
Validation Loss: 0.00665604
Epoch [19/300], Train Loss: 0.006445
Validation Loss: 0.00660387
Epoch [20/300], Train Loss: 0.006382
Validation Loss: 0.00655736
Epoch [21/300], Train Loss: 0.006338
Validation Loss: 0.00651049
Epoch [22/300], Train Loss: 0.006296
Validation Loss: 0.00647748
Epoch [23/300], Train Loss: 0.006276
Validation Loss: 0.00642339
Epoch [24/300], Train Loss: 0.006276
Validation Loss: 0.00638622
Epoch [25/300], Train Loss: 0.006141
Validation Loss: 0.00634565
Epoch [26/300], Train Loss: 0.006128
Validation Loss: 0.00634862
Epoch [27/300], Train Loss: 0.006071
Validation Loss: 0.00627692
Epoch [28/300], Train Loss: 0.006031
Validation Loss: 0.00624628
Epoch [29/300], Train Loss: 0.006030
Validation Loss: 0.00620506
Epoch [30/300], Train Loss: 0.005950
Validation Loss: 0.00618854
Epoch [31/300], Train Loss: 0.005976
Validation Loss: 0.00614964
Epoch [32/300], Train Loss: 0.005935
Validation Loss: 0.00612741
Epoch [33/300], Train Loss: 0.005898
Validation Loss: 0.00609556
Epoch [34/300], Train Loss: 0.005844
Validation Loss: 0.00608888
Epoch [35/300], Train Loss: 0.005834
Validation Loss: 0.00606407
Epoch [36/300], Train Loss: 0.005798
Validation Loss: 0.00602786
Epoch [37/300], Train Loss: 0.005773
Validation Loss: 0.00600947
Epoch [38/300], Train Loss: 0.005800
Validation Loss: 0.00603425
Epoch [39/300], Train Loss: 0.005762
Validation Loss: 0.00597588
Epoch [40/300], Train Loss: 0.005712
Validation Loss: 0.00596158
Epoch [41/300], Train Loss: 0.005732
Validation Loss: 0.00593235
Epoch [42/300], Train Loss: 0.005706
Validation Loss: 0.00593012
Epoch [43/300], Train Loss: 0.005692
Validation Loss: 0.00589843
Epoch [44/300], Train Loss: 0.005662
Validation Loss: 0.00588085
Epoch [45/300], Train Loss: 0.005663
Validation Loss: 0.00587145
Epoch [46/300], Train Loss: 0.005612
Validation Loss: 0.00584040
Epoch [47/300], Train Loss: 0.005615
Validation Loss: 0.00582335
Epoch [48/300], Train Loss: 0.005559
Validation Loss: 0.00581502
Epoch [49/300], Train Loss: 0.005560
Validation Loss: 0.00580285
Epoch [50/300], Train Loss: 0.005546
Validation Loss: 0.00581437
Epoch [51/300], Train Loss: 0.005535
Validation Loss: 0.00576919
Epoch [52/300], Train Loss: 0.005509
Validation Loss: 0.00574275
Epoch [53/300], Train Loss: 0.005519
Validation Loss: 0.00573536
Epoch [54/300], Train Loss: 0.005474
Validation Loss: 0.00571568
Epoch [55/300], Train Loss: 0.005451
Validation Loss: 0.00571407
Epoch [56/300], Train Loss: 0.005463
Validation Loss: 0.00577133
Epoch [57/300], Train Loss: 0.005495
Validation Loss: 0.00568448
Epoch [58/300], Train Loss: 0.005481
Validation Loss: 0.00566849
Epoch [59/300], Train Loss: 0.005422
Validation Loss: 0.00566588
Epoch [60/300], Train Loss: 0.005437
Validation Loss: 0.00566507
Epoch [61/300], Train Loss: 0.005427
Validation Loss: 0.00564839
Epoch [62/300], Train Loss: 0.005381
Validation Loss: 0.00563407
Epoch [63/300], Train Loss: 0.005405
Validation Loss: 0.00563748
Epoch [64/300], Train Loss: 0.005387
Validation Loss: 0.00561994
Epoch [65/300], Train Loss: 0.005380
Validation Loss: 0.00564644
Epoch [66/300], Train Loss: 0.005376
Validation Loss: 0.00560488
Epoch [67/300], Train Loss: 0.005350
Validation Loss: 0.00560574
Epoch [68/300], Train Loss: 0.005340
Validation Loss: 0.00558864
Epoch [69/300], Train Loss: 0.005338
Validation Loss: 0.00556945
Epoch [70/300], Train Loss: 0.005319
Validation Loss: 0.00555154
Epoch [71/300], Train Loss: 0.005299
Validation Loss: 0.00565378
Epoch [72/300], Train Loss: 0.005292
Validation Loss: 0.00552523
Epoch [73/300], Train Loss: 0.005282
Validation Loss: 0.00551042
Epoch [74/300], Train Loss: 0.005234
Validation Loss: 0.00546282
Epoch [75/300], Train Loss: 0.005253
Validation Loss: 0.00554422
Epoch [76/300], Train Loss: 0.005207
Validation Loss: 0.00544137
Epoch [77/300], Train Loss: 0.005227
Validation Loss: 0.00538444
Epoch [78/300], Train Loss: 0.005166
Validation Loss: 0.00533767
Epoch [79/300], Train Loss: 0.005131
Validation Loss: 0.00547495
Epoch [80/300], Train Loss: 0.005120
Validation Loss: 0.00530139
Epoch [81/300], Train Loss: 0.005121
Validation Loss: 0.00534412
Epoch [82/300], Train Loss: 0.005092
Validation Loss: 0.00686065
Epoch [83/300], Train Loss: 0.005354
Validation Loss: 0.00555787
Epoch [84/300], Train Loss: 0.005228
Validation Loss: 0.00546580
Epoch [85/300], Train Loss: 0.005170
Validation Loss: 0.00541199
Epoch [86/300], Train Loss: 0.005120
Validation Loss: 0.00532682
Epoch [87/300], Train Loss: 0.005027
Validation Loss: 0.00545323
Epoch [88/300], Train Loss: 0.004988
Validation Loss: 0.00519040
Epoch [89/300], Train Loss: 0.005004
Validation Loss: 0.00523188
Epoch [90/300], Train Loss: 0.004974
Validation Loss: 0.00526566
Epoch [91/300], Train Loss: 0.004974
Validation Loss: 0.00520761
Epoch [92/300], Train Loss: 0.004973
Validation Loss: 0.00516139
Epoch [93/300], Train Loss: 0.004913
Validation Loss: 0.00515018
Epoch [94/300], Train Loss: 0.004885
Validation Loss: 0.00516093
Epoch [95/300], Train Loss: 0.004886
Validation Loss: 0.00514298
Epoch [96/300], Train Loss: 0.004924
Validation Loss: 0.00513594
Epoch [97/300], Train Loss: 0.004887
Validation Loss: 0.00519674
Epoch [98/300], Train Loss: 0.004845
Validation Loss: 0.00510204
Epoch [99/300], Train Loss: 0.004844
Validation Loss: 0.00512789
Epoch [100/300], Train Loss: 0.004895
Validation Loss: 0.00510570
Epoch [101/300], Train Loss: 0.004930
Validation Loss: 0.00509810
Epoch [102/300], Train Loss: 0.004823
Validation Loss: 0.00506419
Epoch [103/300], Train Loss: 0.004863
Validation Loss: 0.00522632
Epoch [104/300], Train Loss: 0.004863
Validation Loss: 0.00505543
Epoch [105/300], Train Loss: 0.004802
Validation Loss: 0.00504244
Epoch [106/300], Train Loss: 0.004799
Validation Loss: 0.00504857
Epoch [107/300], Train Loss: 0.004788
Validation Loss: 0.00504343
Epoch [108/300], Train Loss: 0.004813
Validation Loss: 0.00504665
Epoch [109/300], Train Loss: 0.004855
Validation Loss: 0.00506653
Epoch [110/300], Train Loss: 0.004812
Validation Loss: 0.00500920
Epoch [111/300], Train Loss: 0.004797
Validation Loss: 0.00508435
Epoch [112/300], Train Loss: 0.004774
Validation Loss: 0.00503666
Epoch [113/300], Train Loss: 0.004774
Validation Loss: 0.00506314
Epoch [114/300], Train Loss: 0.004829
Validation Loss: 0.00499479
Epoch [115/300], Train Loss: 0.004796
Validation Loss: 0.00501720
Epoch [116/300], Train Loss: 0.004776
Validation Loss: 0.00497069
Epoch [117/300], Train Loss: 0.004746
Validation Loss: 0.00497384
Epoch [118/300], Train Loss: 0.004772
Validation Loss: 0.00495142
Epoch [119/300], Train Loss: 0.004724
Validation Loss: 0.00495846
Epoch [120/300], Train Loss: 0.004761
Validation Loss: 0.00500098
Epoch [121/300], Train Loss: 0.004774
Validation Loss: 0.00494256
Epoch [122/300], Train Loss: 0.004724
Validation Loss: 0.00494720
Epoch [123/300], Train Loss: 0.004710
Validation Loss: 0.00489836
Epoch [124/300], Train Loss: 0.004716
Validation Loss: 0.00496604
Epoch [125/300], Train Loss: 0.004696
Validation Loss: 0.00493146
Epoch [126/300], Train Loss: 0.004720
Validation Loss: 0.00506864
Epoch [127/300], Train Loss: 0.004697
Validation Loss: 0.00494264
Epoch [128/300], Train Loss: 0.004745
Validation Loss: 0.00490916
Epoch [129/300], Train Loss: 0.004690
Validation Loss: 0.00489447
Epoch [130/300], Train Loss: 0.004698
Validation Loss: 0.00506383
Epoch [131/300], Train Loss: 0.004734
Validation Loss: 0.00487123
Epoch [132/300], Train Loss: 0.004689
Validation Loss: 0.00488329
Epoch [133/300], Train Loss: 0.004671
Validation Loss: 0.00492043
Epoch [134/300], Train Loss: 0.004684
Validation Loss: 0.00514071
Epoch [135/300], Train Loss: 0.004740
Validation Loss: 0.00487111
Epoch [136/300], Train Loss: 0.004653
Validation Loss: 0.00486010
Epoch [137/300], Train Loss: 0.004653
Validation Loss: 0.00488123
Epoch [138/300], Train Loss: 0.004644
Validation Loss: 0.00484558
Epoch [139/300], Train Loss: 0.004656
Validation Loss: 0.00483070
Epoch [140/300], Train Loss: 0.004631
Validation Loss: 0.00483146
Epoch [141/300], Train Loss: 0.004639
Validation Loss: 0.00483811
Epoch [142/300], Train Loss: 0.004657
Validation Loss: 0.00516534
Epoch [143/300], Train Loss: 0.004763
Validation Loss: 0.00499619
Epoch [144/300], Train Loss: 0.004690
Validation Loss: 0.00486851
Epoch [145/300], Train Loss: 0.004655
Validation Loss: 0.00491843
Epoch [146/300], Train Loss: 0.004677
Validation Loss: 0.00483275
Epoch [147/300], Train Loss: 0.004618
Validation Loss: 0.00488967
Epoch [148/300], Train Loss: 0.004633
Validation Loss: 0.00482960
Epoch [149/300], Train Loss: 0.004610
Validation Loss: 0.00480213
Epoch [150/300], Train Loss: 0.004649
Validation Loss: 0.00485978
Epoch [151/300], Train Loss: 0.004633
Validation Loss: 0.00486556
Epoch [152/300], Train Loss: 0.004635
Validation Loss: 0.00479840
Epoch [153/300], Train Loss: 0.004641
Validation Loss: 0.00480909
Epoch [154/300], Train Loss: 0.004622
Validation Loss: 0.00484183
Epoch [155/300], Train Loss: 0.004614
Validation Loss: 0.00478250
Epoch [156/300], Train Loss: 0.004620
Validation Loss: 0.00480529
Epoch [157/300], Train Loss: 0.004612
Validation Loss: 0.00477500
Epoch [158/300], Train Loss: 0.004605
Validation Loss: 0.00479518
Epoch [159/300], Train Loss: 0.004671
Validation Loss: 0.00484571
Epoch [160/300], Train Loss: 0.004609
Validation Loss: 0.00476893
Epoch [161/300], Train Loss: 0.004585
Validation Loss: 0.00480074
Epoch [162/300], Train Loss: 0.004588
Validation Loss: 0.00479325
Epoch [163/300], Train Loss: 0.004616
Validation Loss: 0.00485367
Epoch [164/300], Train Loss: 0.004602
Validation Loss: 0.00478708
Epoch [165/300], Train Loss: 0.004585
Validation Loss: 0.00481086
Epoch [166/300], Train Loss: 0.004590
Validation Loss: 0.00476469
Epoch [167/300], Train Loss: 0.004581
Validation Loss: 0.00476566
Epoch [168/300], Train Loss: 0.004585
Validation Loss: 0.00477546
Epoch [169/300], Train Loss: 0.004591
Validation Loss: 0.00486151
Epoch [170/300], Train Loss: 0.004592
Validation Loss: 0.00485299
Epoch [171/300], Train Loss: 0.004598
Validation Loss: 0.00477211
Epoch [172/300], Train Loss: 0.004588
Validation Loss: 0.00476622
Epoch [173/300], Train Loss: 0.004586
Validation Loss: 0.00480258
Epoch [174/300], Train Loss: 0.004624
Validation Loss: 0.00475642
Epoch [175/300], Train Loss: 0.004568
Validation Loss: 0.00476531
Epoch [176/300], Train Loss: 0.004550
Validation Loss: 0.00475164
Epoch [177/300], Train Loss: 0.004560
Validation Loss: 0.00473502
Epoch [178/300], Train Loss: 0.004570
Validation Loss: 0.00474949
Epoch [179/300], Train Loss: 0.004559
Validation Loss: 0.00475747
Epoch [180/300], Train Loss: 0.004573
Validation Loss: 0.00477317
Epoch [181/300], Train Loss: 0.004566
Validation Loss: 0.00473038
Epoch [182/300], Train Loss: 0.004569
Validation Loss: 0.00474219
Epoch [183/300], Train Loss: 0.004566
Validation Loss: 0.00474336
Epoch [184/300], Train Loss: 0.004545
Validation Loss: 0.00480889
Epoch [185/300], Train Loss: 0.004598
Validation Loss: 0.00477096
Epoch [186/300], Train Loss: 0.004552
Validation Loss: 0.00486806
Epoch [187/300], Train Loss: 0.004550
Validation Loss: 0.00475885
Epoch [188/300], Train Loss: 0.004562
Validation Loss: 0.00474215
Epoch [189/300], Train Loss: 0.004535
Validation Loss: 0.00473759
Epoch [190/300], Train Loss: 0.004544
Validation Loss: 0.00473220
Epoch [191/300], Train Loss: 0.004553
Validation Loss: 0.00473411
Early stopping triggered

Evaluating model for: Router
Run 25/72 completed in 1220.78 seconds with: {'MAE': np.float32(0.18386994), 'MSE': np.float32(0.05698814), 'RMSE': np.float32(0.23872189), 'SAE': np.float32(0.000662814), 'NDE': np.float32(0.011931555)}

Run 26/72: hidden=256, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Router
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.037529
Validation Loss: 0.00763943
Epoch [2/300], Train Loss: 0.007359
Validation Loss: 0.00731959
Epoch [3/300], Train Loss: 0.006989
Validation Loss: 0.00720654
Epoch [4/300], Train Loss: 0.006852
Validation Loss: 0.00706672
Epoch [5/300], Train Loss: 0.006742
Validation Loss: 0.00694308
Epoch [6/300], Train Loss: 0.006661
Validation Loss: 0.00682153
Epoch [7/300], Train Loss: 0.006470
Validation Loss: 0.00673300
Epoch [8/300], Train Loss: 0.006346
Validation Loss: 0.00659851
Epoch [9/300], Train Loss: 0.006264
Validation Loss: 0.00650528
Epoch [10/300], Train Loss: 0.006191
Validation Loss: 0.00641525
Epoch [11/300], Train Loss: 0.006146
Validation Loss: 0.00635672
Epoch [12/300], Train Loss: 0.006032
Validation Loss: 0.00630039
Epoch [13/300], Train Loss: 0.006000
Validation Loss: 0.00626188
Epoch [14/300], Train Loss: 0.005948
Validation Loss: 0.00625805
Epoch [15/300], Train Loss: 0.005894
Validation Loss: 0.00617778
Epoch [16/300], Train Loss: 0.005837
Validation Loss: 0.00614234
Epoch [17/300], Train Loss: 0.005822
Validation Loss: 0.00610715
Epoch [18/300], Train Loss: 0.005771
Validation Loss: 0.00607572
Epoch [19/300], Train Loss: 0.005770
Validation Loss: 0.00604460
Epoch [20/300], Train Loss: 0.005736
Validation Loss: 0.00601621
Epoch [21/300], Train Loss: 0.005707
Validation Loss: 0.00598859
Epoch [22/300], Train Loss: 0.005678
Validation Loss: 0.00597425
Epoch [23/300], Train Loss: 0.005682
Validation Loss: 0.00593464
Epoch [24/300], Train Loss: 0.005696
Validation Loss: 0.00593195
Epoch [25/300], Train Loss: 0.005589
Validation Loss: 0.00588924
Epoch [26/300], Train Loss: 0.005585
Validation Loss: 0.00590475
Epoch [27/300], Train Loss: 0.005544
Validation Loss: 0.00585744
Epoch [28/300], Train Loss: 0.005516
Validation Loss: 0.00584420
Epoch [29/300], Train Loss: 0.005537
Validation Loss: 0.00580850
Epoch [30/300], Train Loss: 0.005468
Validation Loss: 0.00580202
Epoch [31/300], Train Loss: 0.005499
Validation Loss: 0.00578020
Epoch [32/300], Train Loss: 0.005474
Validation Loss: 0.00575978
Epoch [33/300], Train Loss: 0.005450
Validation Loss: 0.00573810
Epoch [34/300], Train Loss: 0.005405
Validation Loss: 0.00573755
Epoch [35/300], Train Loss: 0.005396
Validation Loss: 0.00571875
Epoch [36/300], Train Loss: 0.005371
Validation Loss: 0.00568860
Epoch [37/300], Train Loss: 0.005351
Validation Loss: 0.00567443
Epoch [38/300], Train Loss: 0.005381
Validation Loss: 0.00570625
Epoch [39/300], Train Loss: 0.005344
Validation Loss: 0.00562979
Epoch [40/300], Train Loss: 0.005303
Validation Loss: 0.00564366
Epoch [41/300], Train Loss: 0.005325
Validation Loss: 0.00559926
Epoch [42/300], Train Loss: 0.005308
Validation Loss: 0.00558772
Epoch [43/300], Train Loss: 0.005283
Validation Loss: 0.00560345
Epoch [44/300], Train Loss: 0.005257
Validation Loss: 0.00552635
Epoch [45/300], Train Loss: 0.005263
Validation Loss: 0.00551158
Epoch [46/300], Train Loss: 0.005189
Validation Loss: 0.00551073
Epoch [47/300], Train Loss: 0.005228
Validation Loss: 0.00551278
Epoch [48/300], Train Loss: 0.005172
Validation Loss: 0.00548099
Epoch [49/300], Train Loss: 0.005145
Validation Loss: 0.00546706
Epoch [50/300], Train Loss: 0.005135
Validation Loss: 0.00544836
Epoch [51/300], Train Loss: 0.005117
Validation Loss: 0.00538495
Epoch [52/300], Train Loss: 0.005110
Validation Loss: 0.00552613
Epoch [53/300], Train Loss: 0.005142
Validation Loss: 0.00542298
Epoch [54/300], Train Loss: 0.005076
Validation Loss: 0.00540478
Epoch [55/300], Train Loss: 0.005050
Validation Loss: 0.00538312
Epoch [56/300], Train Loss: 0.005076
Validation Loss: 0.00550641
Epoch [57/300], Train Loss: 0.005062
Validation Loss: 0.00536852
Epoch [58/300], Train Loss: 0.005059
Validation Loss: 0.00536358
Epoch [59/300], Train Loss: 0.005013
Validation Loss: 0.00532813
Epoch [60/300], Train Loss: 0.004992
Validation Loss: 0.00530368
Epoch [61/300], Train Loss: 0.004983
Validation Loss: 0.00527409
Epoch [62/300], Train Loss: 0.004948
Validation Loss: 0.00529664
Epoch [63/300], Train Loss: 0.004979
Validation Loss: 0.00525586
Epoch [64/300], Train Loss: 0.004943
Validation Loss: 0.00524589
Epoch [65/300], Train Loss: 0.004920
Validation Loss: 0.00527250
Epoch [66/300], Train Loss: 0.004899
Validation Loss: 0.00520103
Epoch [67/300], Train Loss: 0.004842
Validation Loss: 0.00516036
Epoch [68/300], Train Loss: 0.004842
Validation Loss: 0.00513729
Epoch [69/300], Train Loss: 0.004824
Validation Loss: 0.00517727
Epoch [70/300], Train Loss: 0.004820
Validation Loss: 0.00512083
Epoch [71/300], Train Loss: 0.004764
Validation Loss: 0.00511094
Epoch [72/300], Train Loss: 0.004788
Validation Loss: 0.00502260
Epoch [73/300], Train Loss: 0.004764
Validation Loss: 0.00503781
Epoch [74/300], Train Loss: 0.004701
Validation Loss: 0.00502353
Epoch [75/300], Train Loss: 0.004717
Validation Loss: 0.00500585
Epoch [76/300], Train Loss: 0.004663
Validation Loss: 0.00492980
Epoch [77/300], Train Loss: 0.004680
Validation Loss: 0.00492555
Epoch [78/300], Train Loss: 0.004684
Validation Loss: 0.00488654
Epoch [79/300], Train Loss: 0.004638
Validation Loss: 0.00494725
Epoch [80/300], Train Loss: 0.004620
Validation Loss: 0.00487142
Epoch [81/300], Train Loss: 0.004616
Validation Loss: 0.00486983
Epoch [82/300], Train Loss: 0.004619
Validation Loss: 0.00510244
Epoch [83/300], Train Loss: 0.004590
Validation Loss: 0.00486619
Epoch [84/300], Train Loss: 0.004604
Validation Loss: 0.00482551
Epoch [85/300], Train Loss: 0.004588
Validation Loss: 0.00480311
Epoch [86/300], Train Loss: 0.004555
Validation Loss: 0.00480402
Epoch [87/300], Train Loss: 0.004575
Validation Loss: 0.00482444
Epoch [88/300], Train Loss: 0.004544
Validation Loss: 0.00478332
Epoch [89/300], Train Loss: 0.004550
Validation Loss: 0.00486174
Epoch [90/300], Train Loss: 0.004540
Validation Loss: 0.00482650
Epoch [91/300], Train Loss: 0.004548
Validation Loss: 0.00485967
Epoch [92/300], Train Loss: 0.004550
Validation Loss: 0.00481545
Epoch [93/300], Train Loss: 0.004516
Validation Loss: 0.00475445
Epoch [94/300], Train Loss: 0.004515
Validation Loss: 0.00478064
Epoch [95/300], Train Loss: 0.004515
Validation Loss: 0.00477483
Epoch [96/300], Train Loss: 0.004543
Validation Loss: 0.00480434
Epoch [97/300], Train Loss: 0.004502
Validation Loss: 0.00472296
Epoch [98/300], Train Loss: 0.004506
Validation Loss: 0.00475951
Epoch [99/300], Train Loss: 0.004502
Validation Loss: 0.00478263
Epoch [100/300], Train Loss: 0.004534
Validation Loss: 0.00476971
Epoch [101/300], Train Loss: 0.004533
Validation Loss: 0.00478993
Epoch [102/300], Train Loss: 0.004499
Validation Loss: 0.00478279
Epoch [103/300], Train Loss: 0.004525
Validation Loss: 0.00482036
Epoch [104/300], Train Loss: 0.004535
Validation Loss: 0.00475053
Epoch [105/300], Train Loss: 0.004489
Validation Loss: 0.00476614
Epoch [106/300], Train Loss: 0.004496
Validation Loss: 0.00473722
Epoch [107/300], Train Loss: 0.004492
Validation Loss: 0.00472136
Epoch [108/300], Train Loss: 0.004478
Validation Loss: 0.00472890
Epoch [109/300], Train Loss: 0.004494
Validation Loss: 0.00475127
Epoch [110/300], Train Loss: 0.004495
Validation Loss: 0.00471733
Epoch [111/300], Train Loss: 0.004515
Validation Loss: 0.00473024
Epoch [112/300], Train Loss: 0.004476
Validation Loss: 0.00475857
Epoch [113/300], Train Loss: 0.004503
Validation Loss: 0.00471249
Epoch [114/300], Train Loss: 0.004504
Validation Loss: 0.00469988
Epoch [115/300], Train Loss: 0.004472
Validation Loss: 0.00473614
Epoch [116/300], Train Loss: 0.004484
Validation Loss: 0.00469988
Epoch [117/300], Train Loss: 0.004471
Validation Loss: 0.00470332
Epoch [118/300], Train Loss: 0.004490
Validation Loss: 0.00469931
Epoch [119/300], Train Loss: 0.004477
Validation Loss: 0.00468294
Epoch [120/300], Train Loss: 0.004478
Validation Loss: 0.00471534
Epoch [121/300], Train Loss: 0.004477
Validation Loss: 0.00468768
Epoch [122/300], Train Loss: 0.004472
Validation Loss: 0.00469065
Epoch [123/300], Train Loss: 0.004459
Validation Loss: 0.00468423
Epoch [124/300], Train Loss: 0.004463
Validation Loss: 0.00469397
Epoch [125/300], Train Loss: 0.004433
Validation Loss: 0.00468291
Epoch [126/300], Train Loss: 0.004460
Validation Loss: 0.00471455
Epoch [127/300], Train Loss: 0.004444
Validation Loss: 0.00471020
Epoch [128/300], Train Loss: 0.004484
Validation Loss: 0.00471823
Epoch [129/300], Train Loss: 0.004459
Validation Loss: 0.00466707
Epoch [130/300], Train Loss: 0.004454
Validation Loss: 0.00478497
Epoch [131/300], Train Loss: 0.004477
Validation Loss: 0.00466690
Epoch [132/300], Train Loss: 0.004456
Validation Loss: 0.00465861
Epoch [133/300], Train Loss: 0.004442
Validation Loss: 0.00466272
Epoch [134/300], Train Loss: 0.004453
Validation Loss: 0.00480708
Epoch [135/300], Train Loss: 0.004517
Validation Loss: 0.00467757
Epoch [136/300], Train Loss: 0.004425
Validation Loss: 0.00465036
Epoch [137/300], Train Loss: 0.004431
Validation Loss: 0.00466392
Epoch [138/300], Train Loss: 0.004420
Validation Loss: 0.00465043
Epoch [139/300], Train Loss: 0.004434
Validation Loss: 0.00464540
Epoch [140/300], Train Loss: 0.004431
Validation Loss: 0.00463750
Epoch [141/300], Train Loss: 0.004421
Validation Loss: 0.00463902
Epoch [142/300], Train Loss: 0.004445
Validation Loss: 0.00479572
Epoch [143/300], Train Loss: 0.004480
Validation Loss: 0.00472936
Epoch [144/300], Train Loss: 0.004506
Validation Loss: 0.00467401
Epoch [145/300], Train Loss: 0.004436
Validation Loss: 0.00466002
Epoch [146/300], Train Loss: 0.004419
Validation Loss: 0.00467357
Epoch [147/300], Train Loss: 0.004417
Validation Loss: 0.00468794
Epoch [148/300], Train Loss: 0.004434
Validation Loss: 0.00469595
Epoch [149/300], Train Loss: 0.004421
Validation Loss: 0.00462727
Epoch [150/300], Train Loss: 0.004438
Validation Loss: 0.00465934
Epoch [151/300], Train Loss: 0.004423
Validation Loss: 0.00465611
Epoch [152/300], Train Loss: 0.004431
Validation Loss: 0.00462060
Epoch [153/300], Train Loss: 0.004434
Validation Loss: 0.00461425
Epoch [154/300], Train Loss: 0.004413
Validation Loss: 0.00462859
Epoch [155/300], Train Loss: 0.004405
Validation Loss: 0.00461192
Epoch [156/300], Train Loss: 0.004392
Validation Loss: 0.00462246
Epoch [157/300], Train Loss: 0.004404
Validation Loss: 0.00461443
Epoch [158/300], Train Loss: 0.004405
Validation Loss: 0.00464540
Epoch [159/300], Train Loss: 0.004485
Validation Loss: 0.00464270
Epoch [160/300], Train Loss: 0.004384
Validation Loss: 0.00459417
Epoch [161/300], Train Loss: 0.004407
Validation Loss: 0.00463268
Epoch [162/300], Train Loss: 0.004388
Validation Loss: 0.00460537
Epoch [163/300], Train Loss: 0.004404
Validation Loss: 0.00467808
Epoch [164/300], Train Loss: 0.004399
Validation Loss: 0.00459290
Epoch [165/300], Train Loss: 0.004397
Validation Loss: 0.00462401
Epoch [166/300], Train Loss: 0.004396
Validation Loss: 0.00458217
Epoch [167/300], Train Loss: 0.004386
Validation Loss: 0.00458217
Epoch [168/300], Train Loss: 0.004391
Validation Loss: 0.00458007
Epoch [169/300], Train Loss: 0.004382
Validation Loss: 0.00460475
Epoch [170/300], Train Loss: 0.004391
Validation Loss: 0.00465009
Epoch [171/300], Train Loss: 0.004376
Validation Loss: 0.00457850
Epoch [172/300], Train Loss: 0.004375
Validation Loss: 0.00458667
Epoch [173/300], Train Loss: 0.004386
Validation Loss: 0.00461415
Epoch [174/300], Train Loss: 0.004404
Validation Loss: 0.00458940
Epoch [175/300], Train Loss: 0.004376
Validation Loss: 0.00455939
Epoch [176/300], Train Loss: 0.004370
Validation Loss: 0.00463711
Epoch [177/300], Train Loss: 0.004378
Validation Loss: 0.00457699
Epoch [178/300], Train Loss: 0.004377
Validation Loss: 0.00457088
Epoch [179/300], Train Loss: 0.004394
Validation Loss: 0.00457698
Epoch [180/300], Train Loss: 0.004392
Validation Loss: 0.00460294
Epoch [181/300], Train Loss: 0.004387
Validation Loss: 0.00456097
Epoch [182/300], Train Loss: 0.004375
Validation Loss: 0.00454385
Epoch [183/300], Train Loss: 0.004379
Validation Loss: 0.00454863
Epoch [184/300], Train Loss: 0.004370
Validation Loss: 0.00462968
Epoch [185/300], Train Loss: 0.004392
Validation Loss: 0.00456466
Epoch [186/300], Train Loss: 0.004358
Validation Loss: 0.00456958
Epoch [187/300], Train Loss: 0.004365
Validation Loss: 0.00454800
Epoch [188/300], Train Loss: 0.004358
Validation Loss: 0.00453535
Epoch [189/300], Train Loss: 0.004339
Validation Loss: 0.00454760
Epoch [190/300], Train Loss: 0.004349
Validation Loss: 0.00455417
Epoch [191/300], Train Loss: 0.004360
Validation Loss: 0.00454564
Epoch [192/300], Train Loss: 0.004350
Validation Loss: 0.00456006
Epoch [193/300], Train Loss: 0.004347
Validation Loss: 0.00461120
Epoch [194/300], Train Loss: 0.004348
Validation Loss: 0.00453629
Epoch [195/300], Train Loss: 0.004368
Validation Loss: 0.00452557
Epoch [196/300], Train Loss: 0.004331
Validation Loss: 0.00454967
Epoch [197/300], Train Loss: 0.004348
Validation Loss: 0.00452117
Epoch [198/300], Train Loss: 0.004341
Validation Loss: 0.00454661
Epoch [199/300], Train Loss: 0.004332
Validation Loss: 0.00451475
Epoch [200/300], Train Loss: 0.004344
Validation Loss: 0.00455407
Epoch [201/300], Train Loss: 0.004364
Validation Loss: 0.00454530
Epoch [202/300], Train Loss: 0.004341
Validation Loss: 0.00458334
Epoch [203/300], Train Loss: 0.004377
Validation Loss: 0.00452050
Epoch [204/300], Train Loss: 0.004346
Validation Loss: 0.00453341
Epoch [205/300], Train Loss: 0.004330
Validation Loss: 0.00456832
Epoch [206/300], Train Loss: 0.004330
Validation Loss: 0.00452698
Epoch [207/300], Train Loss: 0.004320
Validation Loss: 0.00450988
Epoch [208/300], Train Loss: 0.004356
Validation Loss: 0.00452480
Epoch [209/300], Train Loss: 0.004318
Validation Loss: 0.00454027
Epoch [210/300], Train Loss: 0.004319
Validation Loss: 0.00451252
Epoch [211/300], Train Loss: 0.004355
Validation Loss: 0.00452368
Epoch [212/300], Train Loss: 0.004342
Validation Loss: 0.00451415
Epoch [213/300], Train Loss: 0.004313
Validation Loss: 0.00450736
Epoch [214/300], Train Loss: 0.004320
Validation Loss: 0.00451416
Epoch [215/300], Train Loss: 0.004417
Validation Loss: 0.00449259
Epoch [216/300], Train Loss: 0.004309
Validation Loss: 0.00458104
Epoch [217/300], Train Loss: 0.004322
Validation Loss: 0.00448987
Epoch [218/300], Train Loss: 0.004329
Validation Loss: 0.00451041
Epoch [219/300], Train Loss: 0.004313
Validation Loss: 0.00449056
Epoch [220/300], Train Loss: 0.004310
Validation Loss: 0.00467641
Epoch [221/300], Train Loss: 0.004325
Validation Loss: 0.00447639
Epoch [222/300], Train Loss: 0.004324
Validation Loss: 0.00448355
Epoch [223/300], Train Loss: 0.004313
Validation Loss: 0.00448120
Epoch [224/300], Train Loss: 0.004291
Validation Loss: 0.00450985
Epoch [225/300], Train Loss: 0.004292
Validation Loss: 0.00448798
Epoch [226/300], Train Loss: 0.004288
Validation Loss: 0.00447004
Epoch [227/300], Train Loss: 0.004294
Validation Loss: 0.00447271
Epoch [228/300], Train Loss: 0.004300
Validation Loss: 0.00450668
Epoch [229/300], Train Loss: 0.004282
Validation Loss: 0.00447209
Epoch [230/300], Train Loss: 0.004275
Validation Loss: 0.00448701
Epoch [231/300], Train Loss: 0.004270
Validation Loss: 0.00446200
Epoch [232/300], Train Loss: 0.004271
Validation Loss: 0.00452775
Epoch [233/300], Train Loss: 0.004288
Validation Loss: 0.00447260
Epoch [234/300], Train Loss: 0.004324
Validation Loss: 0.00445498
Epoch [235/300], Train Loss: 0.004290
Validation Loss: 0.00445982
Epoch [236/300], Train Loss: 0.004288
Validation Loss: 0.00453397
Epoch [237/300], Train Loss: 0.004313
Validation Loss: 0.00451226
Epoch [238/300], Train Loss: 0.004278
Validation Loss: 0.00444713
Epoch [239/300], Train Loss: 0.004253
Validation Loss: 0.00443692
Epoch [240/300], Train Loss: 0.004253
Validation Loss: 0.00444201
Epoch [241/300], Train Loss: 0.004252
Validation Loss: 0.00443467
Epoch [242/300], Train Loss: 0.004244
Validation Loss: 0.00442399
Epoch [243/300], Train Loss: 0.004270
Validation Loss: 0.00443660
Epoch [244/300], Train Loss: 0.004253
Validation Loss: 0.00442411
Epoch [245/300], Train Loss: 0.004293
Validation Loss: 0.00447120
Epoch [246/300], Train Loss: 0.004277
Validation Loss: 0.00444334
Epoch [247/300], Train Loss: 0.004247
Validation Loss: 0.00442590
Epoch [248/300], Train Loss: 0.004265
Validation Loss: 0.00441382
Epoch [249/300], Train Loss: 0.004238
Validation Loss: 0.00443932
Epoch [250/300], Train Loss: 0.004256
Validation Loss: 0.00442449
Epoch [251/300], Train Loss: 0.004256
Validation Loss: 0.00440521
Epoch [252/300], Train Loss: 0.004262
Validation Loss: 0.00445847
Epoch [253/300], Train Loss: 0.004260
Validation Loss: 0.00439580
Epoch [254/300], Train Loss: 0.004225
Validation Loss: 0.00441326
Epoch [255/300], Train Loss: 0.004264
Validation Loss: 0.00444785
Epoch [256/300], Train Loss: 0.004261
Validation Loss: 0.00446061
Epoch [257/300], Train Loss: 0.004249
Validation Loss: 0.00444660
Epoch [258/300], Train Loss: 0.004262
Validation Loss: 0.00440192
Epoch [259/300], Train Loss: 0.004223
Validation Loss: 0.00441837
Epoch [260/300], Train Loss: 0.004220
Validation Loss: 0.00439421
Epoch [261/300], Train Loss: 0.004222
Validation Loss: 0.00443493
Epoch [262/300], Train Loss: 0.004229
Validation Loss: 0.00445394
Epoch [263/300], Train Loss: 0.004239
Validation Loss: 0.00442614
Epoch [264/300], Train Loss: 0.004237
Validation Loss: 0.00440482
Epoch [265/300], Train Loss: 0.004235
Validation Loss: 0.00441914
Epoch [266/300], Train Loss: 0.004206
Validation Loss: 0.00441198
Epoch [267/300], Train Loss: 0.004234
Validation Loss: 0.00443159
Epoch [268/300], Train Loss: 0.004245
Validation Loss: 0.00438104
Epoch [269/300], Train Loss: 0.004224
Validation Loss: 0.00436305
Epoch [270/300], Train Loss: 0.004202
Validation Loss: 0.00444814
Epoch [271/300], Train Loss: 0.004218
Validation Loss: 0.00440291
Epoch [272/300], Train Loss: 0.004226
Validation Loss: 0.00437856
Epoch [273/300], Train Loss: 0.004220
Validation Loss: 0.00437924
Epoch [274/300], Train Loss: 0.004243
Validation Loss: 0.00437630
Epoch [275/300], Train Loss: 0.004211
Validation Loss: 0.00437010
Epoch [276/300], Train Loss: 0.004207
Validation Loss: 0.00437965
Epoch [277/300], Train Loss: 0.004201
Validation Loss: 0.00439553
Epoch [278/300], Train Loss: 0.004205
Validation Loss: 0.00436852
Epoch [279/300], Train Loss: 0.004219
Validation Loss: 0.00438584
Early stopping triggered

Evaluating model for: Router
Run 26/72 completed in 1930.25 seconds with: {'MAE': np.float32(0.17920832), 'MSE': np.float32(0.053143587), 'RMSE': np.float32(0.23052894), 'SAE': np.float32(0.0005358451), 'NDE': np.float32(0.011522062)}

Run 27/72: hidden=256, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Router
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.040473
Validation Loss: 0.00827347
Epoch [2/300], Train Loss: 0.007710
Validation Loss: 0.00761148
Epoch [3/300], Train Loss: 0.007232
Validation Loss: 0.00745158
Epoch [4/300], Train Loss: 0.007066
Validation Loss: 0.00729380
Epoch [5/300], Train Loss: 0.006933
Validation Loss: 0.00715104
Epoch [6/300], Train Loss: 0.006845
Validation Loss: 0.00701293
Epoch [7/300], Train Loss: 0.006633
Validation Loss: 0.00690195
Epoch [8/300], Train Loss: 0.006508
Validation Loss: 0.00679854
Epoch [9/300], Train Loss: 0.006418
Validation Loss: 0.00668061
Epoch [10/300], Train Loss: 0.006330
Validation Loss: 0.00656963
Epoch [11/300], Train Loss: 0.006292
Validation Loss: 0.00649702
Epoch [12/300], Train Loss: 0.006148
Validation Loss: 0.00642370
Epoch [13/300], Train Loss: 0.006105
Validation Loss: 0.00639631
Epoch [14/300], Train Loss: 0.006063
Validation Loss: 0.00639802
Epoch [15/300], Train Loss: 0.005985
Validation Loss: 0.00627455
Epoch [16/300], Train Loss: 0.005930
Validation Loss: 0.00623357
Epoch [17/300], Train Loss: 0.005916
Validation Loss: 0.00619793
Epoch [18/300], Train Loss: 0.005858
Validation Loss: 0.00615611
Epoch [19/300], Train Loss: 0.005841
Validation Loss: 0.00612195
Epoch [20/300], Train Loss: 0.005808
Validation Loss: 0.00605956
Epoch [21/300], Train Loss: 0.005753
Validation Loss: 0.00604278
Epoch [22/300], Train Loss: 0.005729
Validation Loss: 0.00602111
Epoch [23/300], Train Loss: 0.005706
Validation Loss: 0.00592039
Epoch [24/300], Train Loss: 0.005739
Validation Loss: 0.00600544
Epoch [25/300], Train Loss: 0.005624
Validation Loss: 0.00591801
Epoch [26/300], Train Loss: 0.005563
Validation Loss: 0.00581950
Epoch [27/300], Train Loss: 0.005439
Validation Loss: 0.00584177
Epoch [28/300], Train Loss: 0.005341
Validation Loss: 0.00575522
Epoch [29/300], Train Loss: 0.005321
Validation Loss: 0.00554101
Epoch [30/300], Train Loss: 0.005229
Validation Loss: 0.00551464
Epoch [31/300], Train Loss: 0.005173
Validation Loss: 0.00543375
Epoch [32/300], Train Loss: 0.005127
Validation Loss: 0.00532745
Epoch [33/300], Train Loss: 0.005030
Validation Loss: 0.00523741
Epoch [34/300], Train Loss: 0.004987
Validation Loss: 0.00519692
Epoch [35/300], Train Loss: 0.004942
Validation Loss: 0.00522486
Epoch [36/300], Train Loss: 0.004875
Validation Loss: 0.00522459
Epoch [37/300], Train Loss: 0.004853
Validation Loss: 0.00506755
Epoch [38/300], Train Loss: 0.004841
Validation Loss: 0.00533944
Epoch [39/300], Train Loss: 0.004809
Validation Loss: 0.00500965
Epoch [40/300], Train Loss: 0.004781
Validation Loss: 0.00508452
Epoch [41/300], Train Loss: 0.004756
Validation Loss: 0.00498343
Epoch [42/300], Train Loss: 0.004720
Validation Loss: 0.00501628
Epoch [43/300], Train Loss: 0.004727
Validation Loss: 0.00495776
Epoch [44/300], Train Loss: 0.004724
Validation Loss: 0.00491279
Epoch [45/300], Train Loss: 0.004710
Validation Loss: 0.00487669
Epoch [46/300], Train Loss: 0.004706
Validation Loss: 0.00495174
Epoch [47/300], Train Loss: 0.004667
Validation Loss: 0.00486901
Epoch [48/300], Train Loss: 0.004639
Validation Loss: 0.00487897
Epoch [49/300], Train Loss: 0.004637
Validation Loss: 0.00489670
Epoch [50/300], Train Loss: 0.004632
Validation Loss: 0.00486056
Epoch [51/300], Train Loss: 0.004628
Validation Loss: 0.00481160
Epoch [52/300], Train Loss: 0.004598
Validation Loss: 0.00481363
Epoch [53/300], Train Loss: 0.004576
Validation Loss: 0.00482209
Epoch [54/300], Train Loss: 0.004570
Validation Loss: 0.00481790
Epoch [55/300], Train Loss: 0.004575
Validation Loss: 0.00481201
Epoch [56/300], Train Loss: 0.004593
Validation Loss: 0.00481979
Epoch [57/300], Train Loss: 0.004585
Validation Loss: 0.00483944
Epoch [58/300], Train Loss: 0.004579
Validation Loss: 0.00478068
Epoch [59/300], Train Loss: 0.004539
Validation Loss: 0.00477330
Epoch [60/300], Train Loss: 0.004548
Validation Loss: 0.00475940
Epoch [61/300], Train Loss: 0.004524
Validation Loss: 0.00475015
Epoch [62/300], Train Loss: 0.004516
Validation Loss: 0.00484529
Epoch [63/300], Train Loss: 0.004558
Validation Loss: 0.00475824
Epoch [64/300], Train Loss: 0.004532
Validation Loss: 0.00476302
Epoch [65/300], Train Loss: 0.004539
Validation Loss: 0.00475272
Epoch [66/300], Train Loss: 0.004537
Validation Loss: 0.00474855
Epoch [67/300], Train Loss: 0.004493
Validation Loss: 0.00474540
Epoch [68/300], Train Loss: 0.004507
Validation Loss: 0.00476902
Epoch [69/300], Train Loss: 0.004506
Validation Loss: 0.00472615
Epoch [70/300], Train Loss: 0.004528
Validation Loss: 0.00471881
Epoch [71/300], Train Loss: 0.004498
Validation Loss: 0.00485562
Epoch [72/300], Train Loss: 0.004537
Validation Loss: 0.00474333
Epoch [73/300], Train Loss: 0.004547
Validation Loss: 0.00472654
Epoch [74/300], Train Loss: 0.004483
Validation Loss: 0.00474745
Epoch [75/300], Train Loss: 0.004495
Validation Loss: 0.00472050
Epoch [76/300], Train Loss: 0.004495
Validation Loss: 0.00474487
Epoch [77/300], Train Loss: 0.004519
Validation Loss: 0.00471014
Epoch [78/300], Train Loss: 0.004496
Validation Loss: 0.00478645
Epoch [79/300], Train Loss: 0.004480
Validation Loss: 0.00471610
Epoch [80/300], Train Loss: 0.004479
Validation Loss: 0.00471807
Epoch [81/300], Train Loss: 0.004471
Validation Loss: 0.00471477
Epoch [82/300], Train Loss: 0.004507
Validation Loss: 0.00471131
Epoch [83/300], Train Loss: 0.004458
Validation Loss: 0.00472090
Epoch [84/300], Train Loss: 0.004467
Validation Loss: 0.00470706
Epoch [85/300], Train Loss: 0.004481
Validation Loss: 0.00470520
Epoch [86/300], Train Loss: 0.004466
Validation Loss: 0.00470754
Epoch [87/300], Train Loss: 0.004458
Validation Loss: 0.00469809
Epoch [88/300], Train Loss: 0.004469
Validation Loss: 0.00469628
Epoch [89/300], Train Loss: 0.004471
Validation Loss: 0.00471176
Epoch [90/300], Train Loss: 0.004464
Validation Loss: 0.00477544
Epoch [91/300], Train Loss: 0.004485
Validation Loss: 0.00471530
Epoch [92/300], Train Loss: 0.004473
Validation Loss: 0.00471037
Epoch [93/300], Train Loss: 0.004445
Validation Loss: 0.00467587
Epoch [94/300], Train Loss: 0.004443
Validation Loss: 0.00471621
Epoch [95/300], Train Loss: 0.004452
Validation Loss: 0.00476411
Epoch [96/300], Train Loss: 0.004516
Validation Loss: 0.00468950
Epoch [97/300], Train Loss: 0.004443
Validation Loss: 0.00468710
Epoch [98/300], Train Loss: 0.004444
Validation Loss: 0.00471145
Epoch [99/300], Train Loss: 0.004440
Validation Loss: 0.00466688
Epoch [100/300], Train Loss: 0.004461
Validation Loss: 0.00471410
Epoch [101/300], Train Loss: 0.004471
Validation Loss: 0.00472194
Epoch [102/300], Train Loss: 0.004441
Validation Loss: 0.00467795
Epoch [103/300], Train Loss: 0.004446
Validation Loss: 0.00469176
Epoch [104/300], Train Loss: 0.004492
Validation Loss: 0.00467518
Epoch [105/300], Train Loss: 0.004432
Validation Loss: 0.00467828
Epoch [106/300], Train Loss: 0.004433
Validation Loss: 0.00465822
Epoch [107/300], Train Loss: 0.004439
Validation Loss: 0.00467167
Epoch [108/300], Train Loss: 0.004448
Validation Loss: 0.00469387
Epoch [109/300], Train Loss: 0.004444
Validation Loss: 0.00466971
Epoch [110/300], Train Loss: 0.004447
Validation Loss: 0.00466303
Epoch [111/300], Train Loss: 0.004456
Validation Loss: 0.00470758
Epoch [112/300], Train Loss: 0.004419
Validation Loss: 0.00470431
Epoch [113/300], Train Loss: 0.004438
Validation Loss: 0.00466361
Epoch [114/300], Train Loss: 0.004444
Validation Loss: 0.00469563
Epoch [115/300], Train Loss: 0.004426
Validation Loss: 0.00466243
Epoch [116/300], Train Loss: 0.004427
Validation Loss: 0.00466690
Early stopping triggered

Evaluating model for: Router
Run 27/72 completed in 857.93 seconds with: {'MAE': np.float32(0.1843616), 'MSE': np.float32(0.055966582), 'RMSE': np.float32(0.23657258), 'SAE': np.float32(0.00028735897), 'NDE': np.float32(0.011824132)}

Run 28/72: hidden=256, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Router
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.056268
Validation Loss: 0.01217904
Epoch [2/300], Train Loss: 0.009375
Validation Loss: 0.00890036
Epoch [3/300], Train Loss: 0.008521
Validation Loss: 0.00856407
Epoch [4/300], Train Loss: 0.008209
Validation Loss: 0.00827038
Epoch [5/300], Train Loss: 0.007928
Validation Loss: 0.00797607
Epoch [6/300], Train Loss: 0.007704
Validation Loss: 0.00773064
Epoch [7/300], Train Loss: 0.007388
Validation Loss: 0.00752374
Epoch [8/300], Train Loss: 0.007194
Validation Loss: 0.00743625
Epoch [9/300], Train Loss: 0.007053
Validation Loss: 0.00721197
Epoch [10/300], Train Loss: 0.006935
Validation Loss: 0.00711064
Epoch [11/300], Train Loss: 0.006885
Validation Loss: 0.00700023
Epoch [12/300], Train Loss: 0.006702
Validation Loss: 0.00688417
Epoch [13/300], Train Loss: 0.006617
Validation Loss: 0.00684596
Epoch [14/300], Train Loss: 0.006542
Validation Loss: 0.00674037
Epoch [15/300], Train Loss: 0.006401
Validation Loss: 0.00660269
Epoch [16/300], Train Loss: 0.006313
Validation Loss: 0.00654488
Epoch [17/300], Train Loss: 0.006267
Validation Loss: 0.00647981
Epoch [18/300], Train Loss: 0.006193
Validation Loss: 0.00642013
Epoch [19/300], Train Loss: 0.006177
Validation Loss: 0.00636077
Epoch [20/300], Train Loss: 0.006130
Validation Loss: 0.00634681
Epoch [21/300], Train Loss: 0.006063
Validation Loss: 0.00627129
Epoch [22/300], Train Loss: 0.006018
Validation Loss: 0.00624457
Epoch [23/300], Train Loss: 0.006024
Validation Loss: 0.00620925
Epoch [24/300], Train Loss: 0.006017
Validation Loss: 0.00615396
Epoch [25/300], Train Loss: 0.005884
Validation Loss: 0.00611673
Epoch [26/300], Train Loss: 0.005859
Validation Loss: 0.00611206
Epoch [27/300], Train Loss: 0.005803
Validation Loss: 0.00605243
Epoch [28/300], Train Loss: 0.005756
Validation Loss: 0.00613577
Epoch [29/300], Train Loss: 0.005773
Validation Loss: 0.00598682
Epoch [30/300], Train Loss: 0.005701
Validation Loss: 0.00599801
Epoch [31/300], Train Loss: 0.005716
Validation Loss: 0.00593084
Epoch [32/300], Train Loss: 0.005671
Validation Loss: 0.00596639
Epoch [33/300], Train Loss: 0.005650
Validation Loss: 0.00589176
Epoch [34/300], Train Loss: 0.005618
Validation Loss: 0.00590056
Epoch [35/300], Train Loss: 0.005560
Validation Loss: 0.00580884
Epoch [36/300], Train Loss: 0.005509
Validation Loss: 0.00582987
Epoch [37/300], Train Loss: 0.005472
Validation Loss: 0.00589617
Epoch [38/300], Train Loss: 0.005532
Validation Loss: 0.00579528
Epoch [39/300], Train Loss: 0.005370
Validation Loss: 0.00559701
Epoch [40/300], Train Loss: 0.005434
Validation Loss: 0.00582927
Epoch [41/300], Train Loss: 0.005483
Validation Loss: 0.00571209
Epoch [42/300], Train Loss: 0.005350
Validation Loss: 0.00563123
Epoch [43/300], Train Loss: 0.005218
Validation Loss: 0.00539234
Epoch [44/300], Train Loss: 0.005117
Validation Loss: 0.00535213
Epoch [45/300], Train Loss: 0.005105
Validation Loss: 0.00529366
Epoch [46/300], Train Loss: 0.005012
Validation Loss: 0.00535295
Epoch [47/300], Train Loss: 0.004923
Validation Loss: 0.00512891
Epoch [48/300], Train Loss: 0.004869
Validation Loss: 0.00506287
Epoch [49/300], Train Loss: 0.004825
Validation Loss: 0.00505076
Epoch [50/300], Train Loss: 0.004777
Validation Loss: 0.00533575
Epoch [51/300], Train Loss: 0.004804
Validation Loss: 0.00497414
Epoch [52/300], Train Loss: 0.004750
Validation Loss: 0.00496461
Epoch [53/300], Train Loss: 0.004700
Validation Loss: 0.00492632
Epoch [54/300], Train Loss: 0.004692
Validation Loss: 0.00492784
Epoch [55/300], Train Loss: 0.004723
Validation Loss: 0.00490204
Epoch [56/300], Train Loss: 0.004715
Validation Loss: 0.00486828
Epoch [57/300], Train Loss: 0.004691
Validation Loss: 0.00488259
Epoch [58/300], Train Loss: 0.004670
Validation Loss: 0.00487322
Epoch [59/300], Train Loss: 0.004633
Validation Loss: 0.00484185
Epoch [60/300], Train Loss: 0.004644
Validation Loss: 0.00482695
Epoch [61/300], Train Loss: 0.004634
Validation Loss: 0.00481712
Epoch [62/300], Train Loss: 0.004600
Validation Loss: 0.00492544
Epoch [63/300], Train Loss: 0.004669
Validation Loss: 0.00483374
Epoch [64/300], Train Loss: 0.004654
Validation Loss: 0.00482882
Epoch [65/300], Train Loss: 0.004617
Validation Loss: 0.00480421
Epoch [66/300], Train Loss: 0.004604
Validation Loss: 0.00479238
Epoch [67/300], Train Loss: 0.004580
Validation Loss: 0.00479329
Epoch [68/300], Train Loss: 0.004594
Validation Loss: 0.00481432
Epoch [69/300], Train Loss: 0.004608
Validation Loss: 0.00479447
Epoch [70/300], Train Loss: 0.004661
Validation Loss: 0.00481263
Epoch [71/300], Train Loss: 0.004607
Validation Loss: 0.00493705
Epoch [72/300], Train Loss: 0.004638
Validation Loss: 0.00484727
Epoch [73/300], Train Loss: 0.004648
Validation Loss: 0.00478795
Epoch [74/300], Train Loss: 0.004563
Validation Loss: 0.00482186
Epoch [75/300], Train Loss: 0.004581
Validation Loss: 0.00477394
Epoch [76/300], Train Loss: 0.004555
Validation Loss: 0.00479244
Epoch [77/300], Train Loss: 0.004597
Validation Loss: 0.00477311
Epoch [78/300], Train Loss: 0.004598
Validation Loss: 0.00482679
Epoch [79/300], Train Loss: 0.004560
Validation Loss: 0.00478514
Epoch [80/300], Train Loss: 0.004569
Validation Loss: 0.00477708
Epoch [81/300], Train Loss: 0.004556
Validation Loss: 0.00475865
Epoch [82/300], Train Loss: 0.004588
Validation Loss: 0.00478239
Epoch [83/300], Train Loss: 0.004546
Validation Loss: 0.00476938
Epoch [84/300], Train Loss: 0.004544
Validation Loss: 0.00476968
Epoch [85/300], Train Loss: 0.004584
Validation Loss: 0.00475142
Epoch [86/300], Train Loss: 0.004537
Validation Loss: 0.00475046
Epoch [87/300], Train Loss: 0.004553
Validation Loss: 0.00475068
Epoch [88/300], Train Loss: 0.004538
Validation Loss: 0.00474687
Epoch [89/300], Train Loss: 0.004548
Validation Loss: 0.00478329
Epoch [90/300], Train Loss: 0.004534
Validation Loss: 0.00479682
Epoch [91/300], Train Loss: 0.004541
Validation Loss: 0.00479877
Epoch [92/300], Train Loss: 0.004556
Validation Loss: 0.00475462
Epoch [93/300], Train Loss: 0.004520
Validation Loss: 0.00474038
Epoch [94/300], Train Loss: 0.004523
Validation Loss: 0.00481249
Epoch [95/300], Train Loss: 0.004530
Validation Loss: 0.00477688
Epoch [96/300], Train Loss: 0.004593
Validation Loss: 0.00474450
Epoch [97/300], Train Loss: 0.004520
Validation Loss: 0.00473810
Epoch [98/300], Train Loss: 0.004516
Validation Loss: 0.00477454
Epoch [99/300], Train Loss: 0.004512
Validation Loss: 0.00473640
Epoch [100/300], Train Loss: 0.004540
Validation Loss: 0.00475210
Epoch [101/300], Train Loss: 0.004560
Validation Loss: 0.00474898
Epoch [102/300], Train Loss: 0.004520
Validation Loss: 0.00472547
Epoch [103/300], Train Loss: 0.004516
Validation Loss: 0.00478536
Epoch [104/300], Train Loss: 0.004557
Validation Loss: 0.00473600
Epoch [105/300], Train Loss: 0.004525
Validation Loss: 0.00473760
Epoch [106/300], Train Loss: 0.004510
Validation Loss: 0.00474561
Epoch [107/300], Train Loss: 0.004519
Validation Loss: 0.00473711
Epoch [108/300], Train Loss: 0.004513
Validation Loss: 0.00475664
Epoch [109/300], Train Loss: 0.004517
Validation Loss: 0.00473126
Epoch [110/300], Train Loss: 0.004534
Validation Loss: 0.00471790
Epoch [111/300], Train Loss: 0.004531
Validation Loss: 0.00478165
Epoch [112/300], Train Loss: 0.004514
Validation Loss: 0.00480012
Epoch [113/300], Train Loss: 0.004538
Validation Loss: 0.00477231
Epoch [114/300], Train Loss: 0.004545
Validation Loss: 0.00473358
Epoch [115/300], Train Loss: 0.004517
Validation Loss: 0.00475599
Epoch [116/300], Train Loss: 0.004521
Validation Loss: 0.00472965
Epoch [117/300], Train Loss: 0.004495
Validation Loss: 0.00471897
Epoch [118/300], Train Loss: 0.004510
Validation Loss: 0.00471605
Epoch [119/300], Train Loss: 0.004495
Validation Loss: 0.00470395
Epoch [120/300], Train Loss: 0.004498
Validation Loss: 0.00473858
Epoch [121/300], Train Loss: 0.004513
Validation Loss: 0.00471046
Epoch [122/300], Train Loss: 0.004491
Validation Loss: 0.00473265
Epoch [123/300], Train Loss: 0.004491
Validation Loss: 0.00470188
Epoch [124/300], Train Loss: 0.004490
Validation Loss: 0.00474806
Epoch [125/300], Train Loss: 0.004471
Validation Loss: 0.00477625
Epoch [126/300], Train Loss: 0.004509
Validation Loss: 0.00477240
Epoch [127/300], Train Loss: 0.004481
Validation Loss: 0.00478829
Epoch [128/300], Train Loss: 0.004541
Validation Loss: 0.00472323
Epoch [129/300], Train Loss: 0.004488
Validation Loss: 0.00470963
Epoch [130/300], Train Loss: 0.004488
Validation Loss: 0.00483544
Epoch [131/300], Train Loss: 0.004506
Validation Loss: 0.00468946
Epoch [132/300], Train Loss: 0.004487
Validation Loss: 0.00469553
Epoch [133/300], Train Loss: 0.004478
Validation Loss: 0.00470798
Epoch [134/300], Train Loss: 0.004499
Validation Loss: 0.00487522
Epoch [135/300], Train Loss: 0.004553
Validation Loss: 0.00470933
Epoch [136/300], Train Loss: 0.004472
Validation Loss: 0.00469076
Epoch [137/300], Train Loss: 0.004470
Validation Loss: 0.00471984
Epoch [138/300], Train Loss: 0.004462
Validation Loss: 0.00469493
Epoch [139/300], Train Loss: 0.004468
Validation Loss: 0.00469409
Epoch [140/300], Train Loss: 0.004464
Validation Loss: 0.00468784
Epoch [141/300], Train Loss: 0.004464
Validation Loss: 0.00472039
Epoch [142/300], Train Loss: 0.004476
Validation Loss: 0.00497526
Epoch [143/300], Train Loss: 0.004565
Validation Loss: 0.00475416
Epoch [144/300], Train Loss: 0.004562
Validation Loss: 0.00472632
Epoch [145/300], Train Loss: 0.004466
Validation Loss: 0.00469662
Epoch [146/300], Train Loss: 0.004478
Validation Loss: 0.00471101
Epoch [147/300], Train Loss: 0.004446
Validation Loss: 0.00476898
Epoch [148/300], Train Loss: 0.004475
Validation Loss: 0.00469375
Epoch [149/300], Train Loss: 0.004443
Validation Loss: 0.00467601
Epoch [150/300], Train Loss: 0.004488
Validation Loss: 0.00477263
Epoch [151/300], Train Loss: 0.004485
Validation Loss: 0.00471440
Epoch [152/300], Train Loss: 0.004464
Validation Loss: 0.00466975
Epoch [153/300], Train Loss: 0.004472
Validation Loss: 0.00470546
Epoch [154/300], Train Loss: 0.004448
Validation Loss: 0.00467306
Epoch [155/300], Train Loss: 0.004442
Validation Loss: 0.00468412
Epoch [156/300], Train Loss: 0.004452
Validation Loss: 0.00465799
Epoch [157/300], Train Loss: 0.004430
Validation Loss: 0.00465591
Epoch [158/300], Train Loss: 0.004453
Validation Loss: 0.00467900
Epoch [159/300], Train Loss: 0.004521
Validation Loss: 0.00480037
Epoch [160/300], Train Loss: 0.004457
Validation Loss: 0.00465610
Epoch [161/300], Train Loss: 0.004429
Validation Loss: 0.00469453
Epoch [162/300], Train Loss: 0.004419
Validation Loss: 0.00466679
Epoch [163/300], Train Loss: 0.004429
Validation Loss: 0.00468375
Epoch [164/300], Train Loss: 0.004426
Validation Loss: 0.00469633
Epoch [165/300], Train Loss: 0.004417
Validation Loss: 0.00463411
Epoch [166/300], Train Loss: 0.004414
Validation Loss: 0.00468909
Epoch [167/300], Train Loss: 0.004414
Validation Loss: 0.00461677
Epoch [168/300], Train Loss: 0.004410
Validation Loss: 0.00466455
Epoch [169/300], Train Loss: 0.004428
Validation Loss: 0.00472089
Epoch [170/300], Train Loss: 0.004415
Validation Loss: 0.00471622
Epoch [171/300], Train Loss: 0.004386
Validation Loss: 0.00459959
Epoch [172/300], Train Loss: 0.004388
Validation Loss: 0.00475960
Epoch [173/300], Train Loss: 0.004400
Validation Loss: 0.00475312
Epoch [174/300], Train Loss: 0.004444
Validation Loss: 0.00463436
Epoch [175/300], Train Loss: 0.004387
Validation Loss: 0.00457775
Epoch [176/300], Train Loss: 0.004343
Validation Loss: 0.00455487
Epoch [177/300], Train Loss: 0.004324
Validation Loss: 0.00454612
Epoch [178/300], Train Loss: 0.004358
Validation Loss: 0.00451906
Epoch [179/300], Train Loss: 0.004348
Validation Loss: 0.00452727
Epoch [180/300], Train Loss: 0.004350
Validation Loss: 0.00467369
Epoch [181/300], Train Loss: 0.004329
Validation Loss: 0.00449154
Epoch [182/300], Train Loss: 0.004325
Validation Loss: 0.00448106
Epoch [183/300], Train Loss: 0.004298
Validation Loss: 0.00448484
Epoch [184/300], Train Loss: 0.004294
Validation Loss: 0.00450477
Epoch [185/300], Train Loss: 0.004314
Validation Loss: 0.00451565
Epoch [186/300], Train Loss: 0.004271
Validation Loss: 0.00448405
Epoch [187/300], Train Loss: 0.004281
Validation Loss: 0.00446246
Epoch [188/300], Train Loss: 0.004291
Validation Loss: 0.00445453
Epoch [189/300], Train Loss: 0.004302
Validation Loss: 0.00477957
Epoch [190/300], Train Loss: 0.004430
Validation Loss: 0.00461384
Epoch [191/300], Train Loss: 0.004345
Validation Loss: 0.00451955
Epoch [192/300], Train Loss: 0.004257
Validation Loss: 0.00447128
Epoch [193/300], Train Loss: 0.004235
Validation Loss: 0.00447505
Epoch [194/300], Train Loss: 0.004231
Validation Loss: 0.00445125
Epoch [195/300], Train Loss: 0.004298
Validation Loss: 0.00449147
Epoch [196/300], Train Loss: 0.004253
Validation Loss: 0.00452609
Epoch [197/300], Train Loss: 0.004235
Validation Loss: 0.00448053
Epoch [198/300], Train Loss: 0.004201
Validation Loss: 0.00439424
Epoch [199/300], Train Loss: 0.004199
Validation Loss: 0.00441419
Epoch [200/300], Train Loss: 0.004217
Validation Loss: 0.00442930
Epoch [201/300], Train Loss: 0.004218
Validation Loss: 0.00438362
Epoch [202/300], Train Loss: 0.004231
Validation Loss: 0.00448418
Epoch [203/300], Train Loss: 0.004304
Validation Loss: 0.00442922
Epoch [204/300], Train Loss: 0.004233
Validation Loss: 0.00440562
Epoch [205/300], Train Loss: 0.004197
Validation Loss: 0.00441493
Epoch [206/300], Train Loss: 0.004215
Validation Loss: 0.00442590
Epoch [207/300], Train Loss: 0.004187
Validation Loss: 0.00440082
Epoch [208/300], Train Loss: 0.004242
Validation Loss: 0.00443019
Epoch [209/300], Train Loss: 0.004235
Validation Loss: 0.00436612
Epoch [210/300], Train Loss: 0.004190
Validation Loss: 0.00450480
Epoch [211/300], Train Loss: 0.004236
Validation Loss: 0.00436579
Epoch [212/300], Train Loss: 0.004234
Validation Loss: 0.00437092
Epoch [213/300], Train Loss: 0.004188
Validation Loss: 0.00435581
Epoch [214/300], Train Loss: 0.004193
Validation Loss: 0.00436221
Epoch [215/300], Train Loss: 0.004269
Validation Loss: 0.00436122
Epoch [216/300], Train Loss: 0.004176
Validation Loss: 0.00442120
Epoch [217/300], Train Loss: 0.004196
Validation Loss: 0.00436105
Epoch [218/300], Train Loss: 0.004201
Validation Loss: 0.00446698
Epoch [219/300], Train Loss: 0.004251
Validation Loss: 0.00436641
Epoch [220/300], Train Loss: 0.004196
Validation Loss: 0.00438447
Epoch [221/300], Train Loss: 0.004190
Validation Loss: 0.00435545
Epoch [222/300], Train Loss: 0.004160
Validation Loss: 0.00450149
Epoch [223/300], Train Loss: 0.004270
Validation Loss: 0.00435433
Epoch [224/300], Train Loss: 0.004170
Validation Loss: 0.00440082
Epoch [225/300], Train Loss: 0.004193
Validation Loss: 0.00436641
Epoch [226/300], Train Loss: 0.004172
Validation Loss: 0.00433995
Epoch [227/300], Train Loss: 0.004179
Validation Loss: 0.00432752
Epoch [228/300], Train Loss: 0.004225
Validation Loss: 0.00440160
Epoch [229/300], Train Loss: 0.004182
Validation Loss: 0.00450898
Epoch [230/300], Train Loss: 0.004173
Validation Loss: 0.00434417
Epoch [231/300], Train Loss: 0.004150
Validation Loss: 0.00435342
Epoch [232/300], Train Loss: 0.004158
Validation Loss: 0.00435816
Epoch [233/300], Train Loss: 0.004153
Validation Loss: 0.00432645
Epoch [234/300], Train Loss: 0.004189
Validation Loss: 0.00436854
Epoch [235/300], Train Loss: 0.004177
Validation Loss: 0.00433799
Epoch [236/300], Train Loss: 0.004188
Validation Loss: 0.00444989
Epoch [237/300], Train Loss: 0.004177
Validation Loss: 0.00446671
Epoch [238/300], Train Loss: 0.004237
Validation Loss: 0.00434590
Epoch [239/300], Train Loss: 0.004152
Validation Loss: 0.00434758
Epoch [240/300], Train Loss: 0.004146
Validation Loss: 0.00437897
Epoch [241/300], Train Loss: 0.004147
Validation Loss: 0.00433321
Epoch [242/300], Train Loss: 0.004141
Validation Loss: 0.00430985
Epoch [243/300], Train Loss: 0.004162
Validation Loss: 0.00447379
Epoch [244/300], Train Loss: 0.004192
Validation Loss: 0.00431061
Epoch [245/300], Train Loss: 0.004163
Validation Loss: 0.00432623
Epoch [246/300], Train Loss: 0.004196
Validation Loss: 0.00435652
Epoch [247/300], Train Loss: 0.004144
Validation Loss: 0.00434096
Epoch [248/300], Train Loss: 0.004148
Validation Loss: 0.00433272
Epoch [249/300], Train Loss: 0.004139
Validation Loss: 0.00431118
Epoch [250/300], Train Loss: 0.004145
Validation Loss: 0.00431994
Epoch [251/300], Train Loss: 0.004158
Validation Loss: 0.00431547
Epoch [252/300], Train Loss: 0.004146
Validation Loss: 0.00430229
Epoch [253/300], Train Loss: 0.004178
Validation Loss: 0.00432372
Epoch [254/300], Train Loss: 0.004119
Validation Loss: 0.00430566
Epoch [255/300], Train Loss: 0.004141
Validation Loss: 0.00446759
Epoch [256/300], Train Loss: 0.004170
Validation Loss: 0.00433342
Epoch [257/300], Train Loss: 0.004152
Validation Loss: 0.00433613
Epoch [258/300], Train Loss: 0.004136
Validation Loss: 0.00431488
Epoch [259/300], Train Loss: 0.004136
Validation Loss: 0.00447976
Epoch [260/300], Train Loss: 0.004141
Validation Loss: 0.00434571
Epoch [261/300], Train Loss: 0.004141
Validation Loss: 0.00430357
Epoch [262/300], Train Loss: 0.004115
Validation Loss: 0.00429913
Epoch [263/300], Train Loss: 0.004129
Validation Loss: 0.00430908
Epoch [264/300], Train Loss: 0.004127
Validation Loss: 0.00430379
Epoch [265/300], Train Loss: 0.004152
Validation Loss: 0.00432355
Epoch [266/300], Train Loss: 0.004114
Validation Loss: 0.00429108
Epoch [267/300], Train Loss: 0.004150
Validation Loss: 0.00435866
Epoch [268/300], Train Loss: 0.004138
Validation Loss: 0.00429599
Epoch [269/300], Train Loss: 0.004110
Validation Loss: 0.00431136
Epoch [270/300], Train Loss: 0.004116
Validation Loss: 0.00429274
Epoch [271/300], Train Loss: 0.004116
Validation Loss: 0.00429627
Epoch [272/300], Train Loss: 0.004141
Validation Loss: 0.00428084
Epoch [273/300], Train Loss: 0.004136
Validation Loss: 0.00429393
Epoch [274/300], Train Loss: 0.004138
Validation Loss: 0.00427963
Epoch [275/300], Train Loss: 0.004110
Validation Loss: 0.00431998
Epoch [276/300], Train Loss: 0.004172
Validation Loss: 0.00438178
Epoch [277/300], Train Loss: 0.004126
Validation Loss: 0.00438932
Epoch [278/300], Train Loss: 0.004142
Validation Loss: 0.00428034
Epoch [279/300], Train Loss: 0.004136
Validation Loss: 0.00429058
Epoch [280/300], Train Loss: 0.004110
Validation Loss: 0.00429058
Epoch [281/300], Train Loss: 0.004121
Validation Loss: 0.00427688
Epoch [282/300], Train Loss: 0.004147
Validation Loss: 0.00428677
Epoch [283/300], Train Loss: 0.004135
Validation Loss: 0.00443683
Epoch [284/300], Train Loss: 0.004131
Validation Loss: 0.00434729
Epoch [285/300], Train Loss: 0.004117
Validation Loss: 0.00432376
Epoch [286/300], Train Loss: 0.004109
Validation Loss: 0.00427188
Epoch [287/300], Train Loss: 0.004101
Validation Loss: 0.00431068
Epoch [288/300], Train Loss: 0.004108
Validation Loss: 0.00432115
Epoch [289/300], Train Loss: 0.004116
Validation Loss: 0.00426443
Epoch [290/300], Train Loss: 0.004124
Validation Loss: 0.00427351
Epoch [291/300], Train Loss: 0.004109
Validation Loss: 0.00425664
Epoch [292/300], Train Loss: 0.004086
Validation Loss: 0.00425311
Epoch [293/300], Train Loss: 0.004090
Validation Loss: 0.00426655
Epoch [294/300], Train Loss: 0.004109
Validation Loss: 0.00429312
Epoch [295/300], Train Loss: 0.004097
Validation Loss: 0.00424735
Epoch [296/300], Train Loss: 0.004094
Validation Loss: 0.00425139
Epoch [297/300], Train Loss: 0.004106
Validation Loss: 0.00430126
Epoch [298/300], Train Loss: 0.004102
Validation Loss: 0.00425547
Epoch [299/300], Train Loss: 0.004081
Validation Loss: 0.00427720
Epoch [300/300], Train Loss: 0.004101
Validation Loss: 0.00425429

Evaluating model for: Router
Run 28/72 completed in 2556.26 seconds with: {'MAE': np.float32(0.1734661), 'MSE': np.float32(0.05101286), 'RMSE': np.float32(0.22586027), 'SAE': np.float32(0.00030071166), 'NDE': np.float32(0.011288718)}

Run 29/72: hidden=256, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Router
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.068539
Validation Loss: 0.04519342
Epoch [2/300], Train Loss: 0.021119
Validation Loss: 0.01019579
Epoch [3/300], Train Loss: 0.008087
Validation Loss: 0.00763731
Epoch [4/300], Train Loss: 0.007449
Validation Loss: 0.00757010
Epoch [5/300], Train Loss: 0.007294
Validation Loss: 0.00744831
Epoch [6/300], Train Loss: 0.007196
Validation Loss: 0.00737000
Epoch [7/300], Train Loss: 0.007125
Validation Loss: 0.00730333
Epoch [8/300], Train Loss: 0.007040
Validation Loss: 0.00721699
Epoch [9/300], Train Loss: 0.006955
Validation Loss: 0.00714054
Epoch [10/300], Train Loss: 0.006888
Validation Loss: 0.00706551
Epoch [11/300], Train Loss: 0.006815
Validation Loss: 0.00699279
Epoch [12/300], Train Loss: 0.006756
Validation Loss: 0.00692558
Epoch [13/300], Train Loss: 0.006687
Validation Loss: 0.00686149
Epoch [14/300], Train Loss: 0.006594
Validation Loss: 0.00679812
Epoch [15/300], Train Loss: 0.006550
Validation Loss: 0.00674942
Epoch [16/300], Train Loss: 0.006496
Validation Loss: 0.00669308
Epoch [17/300], Train Loss: 0.006434
Validation Loss: 0.00665109
Epoch [18/300], Train Loss: 0.006388
Validation Loss: 0.00661686
Epoch [19/300], Train Loss: 0.006347
Validation Loss: 0.00657937
Epoch [20/300], Train Loss: 0.006325
Validation Loss: 0.00656686
Epoch [21/300], Train Loss: 0.006281
Validation Loss: 0.00653137
Epoch [22/300], Train Loss: 0.006289
Validation Loss: 0.00653322
Epoch [23/300], Train Loss: 0.006251
Validation Loss: 0.00645876
Epoch [24/300], Train Loss: 0.006205
Validation Loss: 0.00642720
Epoch [25/300], Train Loss: 0.006168
Validation Loss: 0.00640039
Epoch [26/300], Train Loss: 0.006154
Validation Loss: 0.00638052
Epoch [27/300], Train Loss: 0.006133
Validation Loss: 0.00635854
Epoch [28/300], Train Loss: 0.006127
Validation Loss: 0.00635420
Epoch [29/300], Train Loss: 0.006102
Validation Loss: 0.00634890
Epoch [30/300], Train Loss: 0.006068
Validation Loss: 0.00631909
Epoch [31/300], Train Loss: 0.006060
Validation Loss: 0.00627191
Epoch [32/300], Train Loss: 0.006027
Validation Loss: 0.00625521
Epoch [33/300], Train Loss: 0.006012
Validation Loss: 0.00624475
Epoch [34/300], Train Loss: 0.005992
Validation Loss: 0.00624328
Epoch [35/300], Train Loss: 0.005968
Validation Loss: 0.00621251
Epoch [36/300], Train Loss: 0.005955
Validation Loss: 0.00622522
Epoch [37/300], Train Loss: 0.005944
Validation Loss: 0.00620350
Epoch [38/300], Train Loss: 0.005955
Validation Loss: 0.00615958
Epoch [39/300], Train Loss: 0.005914
Validation Loss: 0.00615386
Epoch [40/300], Train Loss: 0.005875
Validation Loss: 0.00613678
Epoch [41/300], Train Loss: 0.005873
Validation Loss: 0.00612472
Epoch [42/300], Train Loss: 0.005848
Validation Loss: 0.00611231
Epoch [43/300], Train Loss: 0.005873
Validation Loss: 0.00608002
Epoch [44/300], Train Loss: 0.005827
Validation Loss: 0.00607378
Epoch [45/300], Train Loss: 0.005825
Validation Loss: 0.00605196
Epoch [46/300], Train Loss: 0.005815
Validation Loss: 0.00604243
Epoch [47/300], Train Loss: 0.005801
Validation Loss: 0.00602866
Epoch [48/300], Train Loss: 0.005788
Validation Loss: 0.00601712
Epoch [49/300], Train Loss: 0.005769
Validation Loss: 0.00603218
Epoch [50/300], Train Loss: 0.005758
Validation Loss: 0.00600688
Epoch [51/300], Train Loss: 0.005755
Validation Loss: 0.00599145
Epoch [52/300], Train Loss: 0.005737
Validation Loss: 0.00597746
Epoch [53/300], Train Loss: 0.005725
Validation Loss: 0.00596260
Epoch [54/300], Train Loss: 0.005710
Validation Loss: 0.00594959
Epoch [55/300], Train Loss: 0.005700
Validation Loss: 0.00594348
Epoch [56/300], Train Loss: 0.005710
Validation Loss: 0.00594273
Epoch [57/300], Train Loss: 0.005688
Validation Loss: 0.00593903
Epoch [58/300], Train Loss: 0.005659
Validation Loss: 0.00590892
Epoch [59/300], Train Loss: 0.005666
Validation Loss: 0.00593963
Epoch [60/300], Train Loss: 0.005661
Validation Loss: 0.00588979
Epoch [61/300], Train Loss: 0.005630
Validation Loss: 0.00588687
Epoch [62/300], Train Loss: 0.005635
Validation Loss: 0.00587338
Epoch [63/300], Train Loss: 0.005631
Validation Loss: 0.00588462
Epoch [64/300], Train Loss: 0.005653
Validation Loss: 0.00585901
Epoch [65/300], Train Loss: 0.005641
Validation Loss: 0.00585071
Epoch [66/300], Train Loss: 0.005612
Validation Loss: 0.00584218
Epoch [67/300], Train Loss: 0.005580
Validation Loss: 0.00583636
Epoch [68/300], Train Loss: 0.005592
Validation Loss: 0.00583239
Epoch [69/300], Train Loss: 0.005588
Validation Loss: 0.00585458
Epoch [70/300], Train Loss: 0.005590
Validation Loss: 0.00582595
Epoch [71/300], Train Loss: 0.005563
Validation Loss: 0.00581688
Epoch [72/300], Train Loss: 0.005588
Validation Loss: 0.00582797
Epoch [73/300], Train Loss: 0.005558
Validation Loss: 0.00579119
Epoch [74/300], Train Loss: 0.005527
Validation Loss: 0.00579898
Epoch [75/300], Train Loss: 0.005541
Validation Loss: 0.00577774
Epoch [76/300], Train Loss: 0.005526
Validation Loss: 0.00577226
Epoch [77/300], Train Loss: 0.005546
Validation Loss: 0.00579269
Epoch [78/300], Train Loss: 0.005553
Validation Loss: 0.00576128
Epoch [79/300], Train Loss: 0.005514
Validation Loss: 0.00576007
Epoch [80/300], Train Loss: 0.005525
Validation Loss: 0.00577274
Epoch [81/300], Train Loss: 0.005506
Validation Loss: 0.00575606
Epoch [82/300], Train Loss: 0.005514
Validation Loss: 0.00573782
Epoch [83/300], Train Loss: 0.005520
Validation Loss: 0.00573316
Epoch [84/300], Train Loss: 0.005470
Validation Loss: 0.00572925
Epoch [85/300], Train Loss: 0.005483
Validation Loss: 0.00572290
Epoch [86/300], Train Loss: 0.005481
Validation Loss: 0.00572244
Epoch [87/300], Train Loss: 0.005478
Validation Loss: 0.00572701
Epoch [88/300], Train Loss: 0.005470
Validation Loss: 0.00571348
Epoch [89/300], Train Loss: 0.005459
Validation Loss: 0.00570369
Epoch [90/300], Train Loss: 0.005479
Validation Loss: 0.00570223
Epoch [91/300], Train Loss: 0.005448
Validation Loss: 0.00569254
Epoch [92/300], Train Loss: 0.005454
Validation Loss: 0.00568918
Epoch [93/300], Train Loss: 0.005439
Validation Loss: 0.00569955
Epoch [94/300], Train Loss: 0.005439
Validation Loss: 0.00568924
Epoch [95/300], Train Loss: 0.005454
Validation Loss: 0.00569301
Epoch [96/300], Train Loss: 0.005444
Validation Loss: 0.00567167
Epoch [97/300], Train Loss: 0.005425
Validation Loss: 0.00566825
Epoch [98/300], Train Loss: 0.005427
Validation Loss: 0.00566517
Epoch [99/300], Train Loss: 0.005407
Validation Loss: 0.00565995
Epoch [100/300], Train Loss: 0.005415
Validation Loss: 0.00565600
Epoch [101/300], Train Loss: 0.005413
Validation Loss: 0.00567495
Epoch [102/300], Train Loss: 0.005406
Validation Loss: 0.00564880
Epoch [103/300], Train Loss: 0.005406
Validation Loss: 0.00564742
Epoch [104/300], Train Loss: 0.005400
Validation Loss: 0.00563994
Epoch [105/300], Train Loss: 0.005403
Validation Loss: 0.00563702
Epoch [106/300], Train Loss: 0.005394
Validation Loss: 0.00564014
Epoch [107/300], Train Loss: 0.005395
Validation Loss: 0.00562905
Epoch [108/300], Train Loss: 0.005378
Validation Loss: 0.00563017
Epoch [109/300], Train Loss: 0.005371
Validation Loss: 0.00562580
Epoch [110/300], Train Loss: 0.005376
Validation Loss: 0.00562450
Epoch [111/300], Train Loss: 0.005375
Validation Loss: 0.00562746
Epoch [112/300], Train Loss: 0.005384
Validation Loss: 0.00561337
Epoch [113/300], Train Loss: 0.005381
Validation Loss: 0.00560960
Epoch [114/300], Train Loss: 0.005372
Validation Loss: 0.00561214
Epoch [115/300], Train Loss: 0.005373
Validation Loss: 0.00563212
Epoch [116/300], Train Loss: 0.005355
Validation Loss: 0.00560894
Epoch [117/300], Train Loss: 0.005349
Validation Loss: 0.00559621
Epoch [118/300], Train Loss: 0.005349
Validation Loss: 0.00559295
Epoch [119/300], Train Loss: 0.005363
Validation Loss: 0.00559479
Epoch [120/300], Train Loss: 0.005354
Validation Loss: 0.00559157
Epoch [121/300], Train Loss: 0.005345
Validation Loss: 0.00558433
Epoch [122/300], Train Loss: 0.005340
Validation Loss: 0.00558635
Epoch [123/300], Train Loss: 0.005339
Validation Loss: 0.00557862
Epoch [124/300], Train Loss: 0.005325
Validation Loss: 0.00557948
Epoch [125/300], Train Loss: 0.005327
Validation Loss: 0.00557950
Epoch [126/300], Train Loss: 0.005326
Validation Loss: 0.00557221
Epoch [127/300], Train Loss: 0.005316
Validation Loss: 0.00557344
Epoch [128/300], Train Loss: 0.005330
Validation Loss: 0.00561924
Epoch [129/300], Train Loss: 0.005337
Validation Loss: 0.00558216
Epoch [130/300], Train Loss: 0.005343
Validation Loss: 0.00557413
Epoch [131/300], Train Loss: 0.005316
Validation Loss: 0.00558520
Epoch [132/300], Train Loss: 0.005337
Validation Loss: 0.00557485
Epoch [133/300], Train Loss: 0.005316
Validation Loss: 0.00557903
Epoch [134/300], Train Loss: 0.005320
Validation Loss: 0.00556655
Epoch [135/300], Train Loss: 0.005326
Validation Loss: 0.00554933
Epoch [136/300], Train Loss: 0.005299
Validation Loss: 0.00555070
Epoch [137/300], Train Loss: 0.005305
Validation Loss: 0.00554581
Epoch [138/300], Train Loss: 0.005296
Validation Loss: 0.00554522
Epoch [139/300], Train Loss: 0.005298
Validation Loss: 0.00554825
Epoch [140/300], Train Loss: 0.005294
Validation Loss: 0.00554055
Epoch [141/300], Train Loss: 0.005283
Validation Loss: 0.00553660
Epoch [142/300], Train Loss: 0.005295
Validation Loss: 0.00553737
Epoch [143/300], Train Loss: 0.005288
Validation Loss: 0.00553730
Epoch [144/300], Train Loss: 0.005297
Validation Loss: 0.00553776
Epoch [145/300], Train Loss: 0.005287
Validation Loss: 0.00553934
Epoch [146/300], Train Loss: 0.005297
Validation Loss: 0.00552672
Epoch [147/300], Train Loss: 0.005280
Validation Loss: 0.00552995
Epoch [148/300], Train Loss: 0.005281
Validation Loss: 0.00552289
Epoch [149/300], Train Loss: 0.005298
Validation Loss: 0.00553561
Epoch [150/300], Train Loss: 0.005265
Validation Loss: 0.00554170
Epoch [151/300], Train Loss: 0.005269
Validation Loss: 0.00551837
Epoch [152/300], Train Loss: 0.005285
Validation Loss: 0.00551598
Epoch [153/300], Train Loss: 0.005267
Validation Loss: 0.00551916
Epoch [154/300], Train Loss: 0.005274
Validation Loss: 0.00551638
Epoch [155/300], Train Loss: 0.005267
Validation Loss: 0.00551122
Epoch [156/300], Train Loss: 0.005262
Validation Loss: 0.00551260
Epoch [157/300], Train Loss: 0.005278
Validation Loss: 0.00550811
Epoch [158/300], Train Loss: 0.005270
Validation Loss: 0.00550716
Epoch [159/300], Train Loss: 0.005251
Validation Loss: 0.00550908
Epoch [160/300], Train Loss: 0.005274
Validation Loss: 0.00550367
Epoch [161/300], Train Loss: 0.005285
Validation Loss: 0.00550199
Epoch [162/300], Train Loss: 0.005275
Validation Loss: 0.00550179
Epoch [163/300], Train Loss: 0.005257
Validation Loss: 0.00550204
Epoch [164/300], Train Loss: 0.005248
Validation Loss: 0.00549966
Epoch [165/300], Train Loss: 0.005258
Validation Loss: 0.00550615
Epoch [166/300], Train Loss: 0.005279
Validation Loss: 0.00551064
Epoch [167/300], Train Loss: 0.005257
Validation Loss: 0.00550118
Epoch [168/300], Train Loss: 0.005255
Validation Loss: 0.00549289
Epoch [169/300], Train Loss: 0.005256
Validation Loss: 0.00550300
Epoch [170/300], Train Loss: 0.005262
Validation Loss: 0.00550842
Epoch [171/300], Train Loss: 0.005242
Validation Loss: 0.00548855
Epoch [172/300], Train Loss: 0.005249
Validation Loss: 0.00549029
Epoch [173/300], Train Loss: 0.005242
Validation Loss: 0.00548582
Epoch [174/300], Train Loss: 0.005246
Validation Loss: 0.00548758
Epoch [175/300], Train Loss: 0.005248
Validation Loss: 0.00548579
Epoch [176/300], Train Loss: 0.005247
Validation Loss: 0.00548550
Epoch [177/300], Train Loss: 0.005245
Validation Loss: 0.00548247
Epoch [178/300], Train Loss: 0.005241
Validation Loss: 0.00547996
Epoch [179/300], Train Loss: 0.005249
Validation Loss: 0.00547996
Epoch [180/300], Train Loss: 0.005230
Validation Loss: 0.00547688
Epoch [181/300], Train Loss: 0.005252
Validation Loss: 0.00547595
Epoch [182/300], Train Loss: 0.005233
Validation Loss: 0.00547560
Epoch [183/300], Train Loss: 0.005238
Validation Loss: 0.00547518
Epoch [184/300], Train Loss: 0.005229
Validation Loss: 0.00547782
Epoch [185/300], Train Loss: 0.005224
Validation Loss: 0.00549395
Epoch [186/300], Train Loss: 0.005229
Validation Loss: 0.00547408
Epoch [187/300], Train Loss: 0.005226
Validation Loss: 0.00546906
Epoch [188/300], Train Loss: 0.005218
Validation Loss: 0.00546818
Epoch [189/300], Train Loss: 0.005231
Validation Loss: 0.00546659
Epoch [190/300], Train Loss: 0.005230
Validation Loss: 0.00548193
Epoch [191/300], Train Loss: 0.005240
Validation Loss: 0.00546438
Epoch [192/300], Train Loss: 0.005227
Validation Loss: 0.00546533
Epoch [193/300], Train Loss: 0.005243
Validation Loss: 0.00547281
Epoch [194/300], Train Loss: 0.005231
Validation Loss: 0.00546200
Epoch [195/300], Train Loss: 0.005221
Validation Loss: 0.00546019
Epoch [196/300], Train Loss: 0.005227
Validation Loss: 0.00546298
Epoch [197/300], Train Loss: 0.005220
Validation Loss: 0.00545815
Epoch [198/300], Train Loss: 0.005215
Validation Loss: 0.00545763
Epoch [199/300], Train Loss: 0.005215
Validation Loss: 0.00545643
Epoch [200/300], Train Loss: 0.005210
Validation Loss: 0.00546418
Epoch [201/300], Train Loss: 0.005222
Validation Loss: 0.00545471
Epoch [202/300], Train Loss: 0.005229
Validation Loss: 0.00545386
Epoch [203/300], Train Loss: 0.005225
Validation Loss: 0.00545654
Epoch [204/300], Train Loss: 0.005207
Validation Loss: 0.00545665
Epoch [205/300], Train Loss: 0.005209
Validation Loss: 0.00546909
Epoch [206/300], Train Loss: 0.005206
Validation Loss: 0.00545929
Epoch [207/300], Train Loss: 0.005236
Validation Loss: 0.00545088
Epoch [208/300], Train Loss: 0.005202
Validation Loss: 0.00545474
Epoch [209/300], Train Loss: 0.005203
Validation Loss: 0.00544791
Epoch [210/300], Train Loss: 0.005210
Validation Loss: 0.00544588
Epoch [211/300], Train Loss: 0.005207
Validation Loss: 0.00546476
Epoch [212/300], Train Loss: 0.005216
Validation Loss: 0.00544402
Epoch [213/300], Train Loss: 0.005201
Validation Loss: 0.00545272
Epoch [214/300], Train Loss: 0.005205
Validation Loss: 0.00544368
Epoch [215/300], Train Loss: 0.005201
Validation Loss: 0.00545017
Epoch [216/300], Train Loss: 0.005204
Validation Loss: 0.00544067
Epoch [217/300], Train Loss: 0.005205
Validation Loss: 0.00544077
Epoch [218/300], Train Loss: 0.005196
Validation Loss: 0.00543797
Epoch [219/300], Train Loss: 0.005224
Validation Loss: 0.00543881
Epoch [220/300], Train Loss: 0.005202
Validation Loss: 0.00544956
Epoch [221/300], Train Loss: 0.005187
Validation Loss: 0.00544231
Epoch [222/300], Train Loss: 0.005216
Validation Loss: 0.00543375
Epoch [223/300], Train Loss: 0.005192
Validation Loss: 0.00543651
Epoch [224/300], Train Loss: 0.005199
Validation Loss: 0.00543717
Epoch [225/300], Train Loss: 0.005210
Validation Loss: 0.00544110
Epoch [226/300], Train Loss: 0.005195
Validation Loss: 0.00543479
Epoch [227/300], Train Loss: 0.005187
Validation Loss: 0.00543090
Epoch [228/300], Train Loss: 0.005201
Validation Loss: 0.00543017
Epoch [229/300], Train Loss: 0.005189
Validation Loss: 0.00542937
Epoch [230/300], Train Loss: 0.005188
Validation Loss: 0.00542441
Epoch [231/300], Train Loss: 0.005188
Validation Loss: 0.00542447
Epoch [232/300], Train Loss: 0.005191
Validation Loss: 0.00542326
Epoch [233/300], Train Loss: 0.005184
Validation Loss: 0.00542034
Epoch [234/300], Train Loss: 0.005190
Validation Loss: 0.00542040
Epoch [235/300], Train Loss: 0.005186
Validation Loss: 0.00542441
Epoch [236/300], Train Loss: 0.005174
Validation Loss: 0.00542085
Epoch [237/300], Train Loss: 0.005197
Validation Loss: 0.00541819
Epoch [238/300], Train Loss: 0.005186
Validation Loss: 0.00541381
Epoch [239/300], Train Loss: 0.005173
Validation Loss: 0.00541231
Epoch [240/300], Train Loss: 0.005201
Validation Loss: 0.00541310
Epoch [241/300], Train Loss: 0.005198
Validation Loss: 0.00540938
Epoch [242/300], Train Loss: 0.005164
Validation Loss: 0.00540714
Epoch [243/300], Train Loss: 0.005162
Validation Loss: 0.00541208
Epoch [244/300], Train Loss: 0.005177
Validation Loss: 0.00540569
Epoch [245/300], Train Loss: 0.005163
Validation Loss: 0.00540776
Epoch [246/300], Train Loss: 0.005177
Validation Loss: 0.00540225
Epoch [247/300], Train Loss: 0.005171
Validation Loss: 0.00539861
Epoch [248/300], Train Loss: 0.005168
Validation Loss: 0.00539589
Epoch [249/300], Train Loss: 0.005163
Validation Loss: 0.00539260
Epoch [250/300], Train Loss: 0.005158
Validation Loss: 0.00539438
Epoch [251/300], Train Loss: 0.005161
Validation Loss: 0.00539212
Epoch [252/300], Train Loss: 0.005180
Validation Loss: 0.00539044
Epoch [253/300], Train Loss: 0.005162
Validation Loss: 0.00538547
Epoch [254/300], Train Loss: 0.005149
Validation Loss: 0.00539049
Epoch [255/300], Train Loss: 0.005164
Validation Loss: 0.00538558
Epoch [256/300], Train Loss: 0.005143
Validation Loss: 0.00537588
Epoch [257/300], Train Loss: 0.005137
Validation Loss: 0.00537490
Epoch [258/300], Train Loss: 0.005139
Validation Loss: 0.00537167
Epoch [259/300], Train Loss: 0.005168
Validation Loss: 0.00540888
Epoch [260/300], Train Loss: 0.005163
Validation Loss: 0.00537536
Epoch [261/300], Train Loss: 0.005146
Validation Loss: 0.00537336
Epoch [262/300], Train Loss: 0.005134
Validation Loss: 0.00537234
Epoch [263/300], Train Loss: 0.005126
Validation Loss: 0.00535925
Epoch [264/300], Train Loss: 0.005123
Validation Loss: 0.00535860
Epoch [265/300], Train Loss: 0.005149
Validation Loss: 0.00534803
Epoch [266/300], Train Loss: 0.005123
Validation Loss: 0.00534424
Epoch [267/300], Train Loss: 0.005124
Validation Loss: 0.00534089
Epoch [268/300], Train Loss: 0.005133
Validation Loss: 0.00533540
Epoch [269/300], Train Loss: 0.005125
Validation Loss: 0.00533108
Epoch [270/300], Train Loss: 0.005102
Validation Loss: 0.00532120
Epoch [271/300], Train Loss: 0.005092
Validation Loss: 0.00532264
Epoch [272/300], Train Loss: 0.005097
Validation Loss: 0.00531867
Epoch [273/300], Train Loss: 0.005092
Validation Loss: 0.00531331
Epoch [274/300], Train Loss: 0.005085
Validation Loss: 0.00530497
Epoch [275/300], Train Loss: 0.005082
Validation Loss: 0.00530828
Epoch [276/300], Train Loss: 0.005080
Validation Loss: 0.00528779
Epoch [277/300], Train Loss: 0.005079
Validation Loss: 0.00527655
Epoch [278/300], Train Loss: 0.005081
Validation Loss: 0.00527973
Epoch [279/300], Train Loss: 0.005087
Validation Loss: 0.00529639
Epoch [280/300], Train Loss: 0.005085
Validation Loss: 0.00526564
Epoch [281/300], Train Loss: 0.005055
Validation Loss: 0.00530571
Epoch [282/300], Train Loss: 0.005072
Validation Loss: 0.00524052
Epoch [283/300], Train Loss: 0.005066
Validation Loss: 0.00525158
Epoch [284/300], Train Loss: 0.005055
Validation Loss: 0.00527664
Epoch [285/300], Train Loss: 0.005056
Validation Loss: 0.00523374
Epoch [286/300], Train Loss: 0.005028
Validation Loss: 0.00520359
Epoch [287/300], Train Loss: 0.005009
Validation Loss: 0.00519439
Epoch [288/300], Train Loss: 0.005007
Validation Loss: 0.00520488
Epoch [289/300], Train Loss: 0.004996
Validation Loss: 0.00518524
Epoch [290/300], Train Loss: 0.005015
Validation Loss: 0.00516747
Epoch [291/300], Train Loss: 0.004988
Validation Loss: 0.00514986
Epoch [292/300], Train Loss: 0.004998
Validation Loss: 0.00513803
Epoch [293/300], Train Loss: 0.004962
Validation Loss: 0.00512829
Epoch [294/300], Train Loss: 0.004935
Validation Loss: 0.00510646
Epoch [295/300], Train Loss: 0.004921
Validation Loss: 0.00509006
Epoch [296/300], Train Loss: 0.004912
Validation Loss: 0.00510055
Epoch [297/300], Train Loss: 0.004921
Validation Loss: 0.00507238
Epoch [298/300], Train Loss: 0.004889
Validation Loss: 0.00504816
Epoch [299/300], Train Loss: 0.004863
Validation Loss: 0.00505470
Epoch [300/300], Train Loss: 0.004880
Validation Loss: 0.00501344

Evaluating model for: Router
Run 29/72 completed in 956.38 seconds with: {'MAE': np.float32(0.19556093), 'MSE': np.float32(0.062574714), 'RMSE': np.float32(0.2501494), 'SAE': np.float32(6.8651396e-05), 'NDE': np.float32(0.012500456)}

Run 30/72: hidden=256, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Router
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.098477
Validation Loss: 0.07391546
Epoch [2/300], Train Loss: 0.036220
Validation Loss: 0.01031631
Epoch [3/300], Train Loss: 0.010220
Validation Loss: 0.00975931
Epoch [4/300], Train Loss: 0.009040
Validation Loss: 0.00898669
Epoch [5/300], Train Loss: 0.008758
Validation Loss: 0.00883566
Epoch [6/300], Train Loss: 0.008636
Validation Loss: 0.00869517
Epoch [7/300], Train Loss: 0.008494
Validation Loss: 0.00856880
Epoch [8/300], Train Loss: 0.008347
Validation Loss: 0.00840947
Epoch [9/300], Train Loss: 0.008192
Validation Loss: 0.00827076
Epoch [10/300], Train Loss: 0.008051
Validation Loss: 0.00811858
Epoch [11/300], Train Loss: 0.007909
Validation Loss: 0.00797065
Epoch [12/300], Train Loss: 0.007791
Validation Loss: 0.00785711
Epoch [13/300], Train Loss: 0.007649
Validation Loss: 0.00771350
Epoch [14/300], Train Loss: 0.007489
Validation Loss: 0.00760539
Epoch [15/300], Train Loss: 0.007401
Validation Loss: 0.00754705
Epoch [16/300], Train Loss: 0.007306
Validation Loss: 0.00741011
Epoch [17/300], Train Loss: 0.007209
Validation Loss: 0.00733549
Epoch [18/300], Train Loss: 0.007156
Validation Loss: 0.00727903
Epoch [19/300], Train Loss: 0.007080
Validation Loss: 0.00721060
Epoch [20/300], Train Loss: 0.007027
Validation Loss: 0.00720418
Epoch [21/300], Train Loss: 0.006965
Validation Loss: 0.00709737
Epoch [22/300], Train Loss: 0.006933
Validation Loss: 0.00705532
Epoch [23/300], Train Loss: 0.006870
Validation Loss: 0.00699858
Epoch [24/300], Train Loss: 0.006829
Validation Loss: 0.00694374
Epoch [25/300], Train Loss: 0.006754
Validation Loss: 0.00689782
Epoch [26/300], Train Loss: 0.006719
Validation Loss: 0.00686058
Epoch [27/300], Train Loss: 0.006694
Validation Loss: 0.00682738
Epoch [28/300], Train Loss: 0.006653
Validation Loss: 0.00678535
Epoch [29/300], Train Loss: 0.006596
Validation Loss: 0.00674490
Epoch [30/300], Train Loss: 0.006529
Validation Loss: 0.00669495
Epoch [31/300], Train Loss: 0.006517
Validation Loss: 0.00666058
Epoch [32/300], Train Loss: 0.006481
Validation Loss: 0.00662699
Epoch [33/300], Train Loss: 0.006450
Validation Loss: 0.00662788
Epoch [34/300], Train Loss: 0.006416
Validation Loss: 0.00656460
Epoch [35/300], Train Loss: 0.006379
Validation Loss: 0.00654303
Epoch [36/300], Train Loss: 0.006337
Validation Loss: 0.00654454
Epoch [37/300], Train Loss: 0.006320
Validation Loss: 0.00647582
Epoch [38/300], Train Loss: 0.006316
Validation Loss: 0.00646516
Epoch [39/300], Train Loss: 0.006273
Validation Loss: 0.00644598
Epoch [40/300], Train Loss: 0.006218
Validation Loss: 0.00641806
Epoch [41/300], Train Loss: 0.006199
Validation Loss: 0.00636649
Epoch [42/300], Train Loss: 0.006158
Validation Loss: 0.00634535
Epoch [43/300], Train Loss: 0.006171
Validation Loss: 0.00635088
Epoch [44/300], Train Loss: 0.006125
Validation Loss: 0.00628879
Epoch [45/300], Train Loss: 0.006103
Validation Loss: 0.00628028
Epoch [46/300], Train Loss: 0.006085
Validation Loss: 0.00624297
Epoch [47/300], Train Loss: 0.006069
Validation Loss: 0.00622337
Epoch [48/300], Train Loss: 0.006026
Validation Loss: 0.00624236
Epoch [49/300], Train Loss: 0.006036
Validation Loss: 0.00619241
Epoch [50/300], Train Loss: 0.006003
Validation Loss: 0.00618290
Epoch [51/300], Train Loss: 0.005979
Validation Loss: 0.00618355
Epoch [52/300], Train Loss: 0.005963
Validation Loss: 0.00613896
Epoch [53/300], Train Loss: 0.005954
Validation Loss: 0.00611438
Epoch [54/300], Train Loss: 0.005921
Validation Loss: 0.00610473
Epoch [55/300], Train Loss: 0.005919
Validation Loss: 0.00608068
Epoch [56/300], Train Loss: 0.005904
Validation Loss: 0.00606618
Epoch [57/300], Train Loss: 0.005885
Validation Loss: 0.00605410
Epoch [58/300], Train Loss: 0.005840
Validation Loss: 0.00603417
Epoch [59/300], Train Loss: 0.005845
Validation Loss: 0.00603158
Epoch [60/300], Train Loss: 0.005833
Validation Loss: 0.00600718
Epoch [61/300], Train Loss: 0.005797
Validation Loss: 0.00598895
Epoch [62/300], Train Loss: 0.005806
Validation Loss: 0.00597422
Epoch [63/300], Train Loss: 0.005779
Validation Loss: 0.00599387
Epoch [64/300], Train Loss: 0.005807
Validation Loss: 0.00599613
Epoch [65/300], Train Loss: 0.005790
Validation Loss: 0.00595364
Epoch [66/300], Train Loss: 0.005755
Validation Loss: 0.00593037
Epoch [67/300], Train Loss: 0.005741
Validation Loss: 0.00591511
Epoch [68/300], Train Loss: 0.005740
Validation Loss: 0.00593917
Epoch [69/300], Train Loss: 0.005717
Validation Loss: 0.00590507
Epoch [70/300], Train Loss: 0.005710
Validation Loss: 0.00589037
Epoch [71/300], Train Loss: 0.005693
Validation Loss: 0.00587266
Epoch [72/300], Train Loss: 0.005691
Validation Loss: 0.00585587
Epoch [73/300], Train Loss: 0.005668
Validation Loss: 0.00584532
Epoch [74/300], Train Loss: 0.005632
Validation Loss: 0.00584913
Epoch [75/300], Train Loss: 0.005634
Validation Loss: 0.00581943
Epoch [76/300], Train Loss: 0.005626
Validation Loss: 0.00580965
Epoch [77/300], Train Loss: 0.005639
Validation Loss: 0.00593915
Epoch [78/300], Train Loss: 0.005640
Validation Loss: 0.00579750
Epoch [79/300], Train Loss: 0.005599
Validation Loss: 0.00578740
Epoch [80/300], Train Loss: 0.005609
Validation Loss: 0.00577236
Epoch [81/300], Train Loss: 0.005565
Validation Loss: 0.00576693
Epoch [82/300], Train Loss: 0.005572
Validation Loss: 0.00581274
Epoch [83/300], Train Loss: 0.005574
Validation Loss: 0.00576621
Epoch [84/300], Train Loss: 0.005553
Validation Loss: 0.00573724
Epoch [85/300], Train Loss: 0.005554
Validation Loss: 0.00575957
Epoch [86/300], Train Loss: 0.005546
Validation Loss: 0.00571887
Epoch [87/300], Train Loss: 0.005526
Validation Loss: 0.00571025
Epoch [88/300], Train Loss: 0.005518
Validation Loss: 0.00570405
Epoch [89/300], Train Loss: 0.005514
Validation Loss: 0.00569510
Epoch [90/300], Train Loss: 0.005516
Validation Loss: 0.00568476
Epoch [91/300], Train Loss: 0.005493
Validation Loss: 0.00568310
Epoch [92/300], Train Loss: 0.005499
Validation Loss: 0.00568606
Epoch [93/300], Train Loss: 0.005475
Validation Loss: 0.00570147
Epoch [94/300], Train Loss: 0.005487
Validation Loss: 0.00575794
Epoch [95/300], Train Loss: 0.005501
Validation Loss: 0.00576517
Epoch [96/300], Train Loss: 0.005480
Validation Loss: 0.00564729
Epoch [97/300], Train Loss: 0.005450
Validation Loss: 0.00563770
Epoch [98/300], Train Loss: 0.005463
Validation Loss: 0.00563242
Epoch [99/300], Train Loss: 0.005430
Validation Loss: 0.00563156
Epoch [100/300], Train Loss: 0.005442
Validation Loss: 0.00561898
Epoch [101/300], Train Loss: 0.005424
Validation Loss: 0.00564433
Epoch [102/300], Train Loss: 0.005424
Validation Loss: 0.00560805
Epoch [103/300], Train Loss: 0.005424
Validation Loss: 0.00562375
Epoch [104/300], Train Loss: 0.005415
Validation Loss: 0.00559618
Epoch [105/300], Train Loss: 0.005414
Validation Loss: 0.00558919
Epoch [106/300], Train Loss: 0.005411
Validation Loss: 0.00559152
Epoch [107/300], Train Loss: 0.005408
Validation Loss: 0.00558763
Epoch [108/300], Train Loss: 0.005394
Validation Loss: 0.00557927
Epoch [109/300], Train Loss: 0.005381
Validation Loss: 0.00557469
Epoch [110/300], Train Loss: 0.005377
Validation Loss: 0.00557313
Epoch [111/300], Train Loss: 0.005383
Validation Loss: 0.00557440
Epoch [112/300], Train Loss: 0.005392
Validation Loss: 0.00556836
Epoch [113/300], Train Loss: 0.005382
Validation Loss: 0.00556003
Epoch [114/300], Train Loss: 0.005376
Validation Loss: 0.00554997
Epoch [115/300], Train Loss: 0.005362
Validation Loss: 0.00554500
Epoch [116/300], Train Loss: 0.005356
Validation Loss: 0.00554285
Epoch [117/300], Train Loss: 0.005345
Validation Loss: 0.00554643
Epoch [118/300], Train Loss: 0.005357
Validation Loss: 0.00553455
Epoch [119/300], Train Loss: 0.005355
Validation Loss: 0.00553984
Epoch [120/300], Train Loss: 0.005342
Validation Loss: 0.00552686
Epoch [121/300], Train Loss: 0.005339
Validation Loss: 0.00552452
Epoch [122/300], Train Loss: 0.005332
Validation Loss: 0.00553110
Epoch [123/300], Train Loss: 0.005338
Validation Loss: 0.00552298
Epoch [124/300], Train Loss: 0.005323
Validation Loss: 0.00551473
Epoch [125/300], Train Loss: 0.005317
Validation Loss: 0.00553085
Epoch [126/300], Train Loss: 0.005319
Validation Loss: 0.00551523
Epoch [127/300], Train Loss: 0.005312
Validation Loss: 0.00554080
Epoch [128/300], Train Loss: 0.005326
Validation Loss: 0.00557059
Epoch [129/300], Train Loss: 0.005316
Validation Loss: 0.00552206
Epoch [130/300], Train Loss: 0.005329
Validation Loss: 0.00550141
Epoch [131/300], Train Loss: 0.005309
Validation Loss: 0.00550846
Epoch [132/300], Train Loss: 0.005334
Validation Loss: 0.00550866
Epoch [133/300], Train Loss: 0.005310
Validation Loss: 0.00549412
Epoch [134/300], Train Loss: 0.005307
Validation Loss: 0.00555587
Epoch [135/300], Train Loss: 0.005327
Validation Loss: 0.00549872
Epoch [136/300], Train Loss: 0.005294
Validation Loss: 0.00549272
Epoch [137/300], Train Loss: 0.005310
Validation Loss: 0.00550921
Epoch [138/300], Train Loss: 0.005294
Validation Loss: 0.00549911
Epoch [139/300], Train Loss: 0.005289
Validation Loss: 0.00551783
Epoch [140/300], Train Loss: 0.005295
Validation Loss: 0.00550669
Epoch [141/300], Train Loss: 0.005278
Validation Loss: 0.00548496
Epoch [142/300], Train Loss: 0.005291
Validation Loss: 0.00548040
Epoch [143/300], Train Loss: 0.005275
Validation Loss: 0.00549445
Epoch [144/300], Train Loss: 0.005289
Validation Loss: 0.00549126
Epoch [145/300], Train Loss: 0.005288
Validation Loss: 0.00550478
Epoch [146/300], Train Loss: 0.005297
Validation Loss: 0.00547571
Epoch [147/300], Train Loss: 0.005283
Validation Loss: 0.00548652
Epoch [148/300], Train Loss: 0.005291
Validation Loss: 0.00547259
Epoch [149/300], Train Loss: 0.005310
Validation Loss: 0.00549626
Epoch [150/300], Train Loss: 0.005263
Validation Loss: 0.00551036
Epoch [151/300], Train Loss: 0.005278
Validation Loss: 0.00547067
Epoch [152/300], Train Loss: 0.005283
Validation Loss: 0.00546950
Epoch [153/300], Train Loss: 0.005271
Validation Loss: 0.00547116
Epoch [154/300], Train Loss: 0.005279
Validation Loss: 0.00547823
Epoch [155/300], Train Loss: 0.005276
Validation Loss: 0.00547923
Epoch [156/300], Train Loss: 0.005267
Validation Loss: 0.00548116
Epoch [157/300], Train Loss: 0.005285
Validation Loss: 0.00547492
Epoch [158/300], Train Loss: 0.005271
Validation Loss: 0.00546969
Epoch [159/300], Train Loss: 0.005260
Validation Loss: 0.00546592
Epoch [160/300], Train Loss: 0.005273
Validation Loss: 0.00546715
Epoch [161/300], Train Loss: 0.005298
Validation Loss: 0.00546479
Epoch [162/300], Train Loss: 0.005277
Validation Loss: 0.00546457
Epoch [163/300], Train Loss: 0.005274
Validation Loss: 0.00546395
Epoch [164/300], Train Loss: 0.005260
Validation Loss: 0.00546251
Epoch [165/300], Train Loss: 0.005271
Validation Loss: 0.00552204
Epoch [166/300], Train Loss: 0.005291
Validation Loss: 0.00546251
Epoch [167/300], Train Loss: 0.005273
Validation Loss: 0.00546225
Epoch [168/300], Train Loss: 0.005273
Validation Loss: 0.00546239
Epoch [169/300], Train Loss: 0.005271
Validation Loss: 0.00547939
Epoch [170/300], Train Loss: 0.005275
Validation Loss: 0.00546517
Epoch [171/300], Train Loss: 0.005261
Validation Loss: 0.00546086
Epoch [172/300], Train Loss: 0.005270
Validation Loss: 0.00546562
Epoch [173/300], Train Loss: 0.005257
Validation Loss: 0.00545898
Epoch [174/300], Train Loss: 0.005261
Validation Loss: 0.00546333
Epoch [175/300], Train Loss: 0.005271
Validation Loss: 0.00546346
Epoch [176/300], Train Loss: 0.005264
Validation Loss: 0.00547321
Epoch [177/300], Train Loss: 0.005270
Validation Loss: 0.00545808
Epoch [178/300], Train Loss: 0.005269
Validation Loss: 0.00546618
Epoch [179/300], Train Loss: 0.005276
Validation Loss: 0.00546045
Epoch [180/300], Train Loss: 0.005259
Validation Loss: 0.00545685
Epoch [181/300], Train Loss: 0.005274
Validation Loss: 0.00545867
Epoch [182/300], Train Loss: 0.005261
Validation Loss: 0.00545712
Epoch [183/300], Train Loss: 0.005267
Validation Loss: 0.00545626
Epoch [184/300], Train Loss: 0.005260
Validation Loss: 0.00546120
Epoch [185/300], Train Loss: 0.005247
Validation Loss: 0.00550446
Epoch [186/300], Train Loss: 0.005259
Validation Loss: 0.00547576
Epoch [187/300], Train Loss: 0.005264
Validation Loss: 0.00545449
Epoch [188/300], Train Loss: 0.005245
Validation Loss: 0.00545656
Epoch [189/300], Train Loss: 0.005260
Validation Loss: 0.00545307
Epoch [190/300], Train Loss: 0.005270
Validation Loss: 0.00547784
Epoch [191/300], Train Loss: 0.005272
Validation Loss: 0.00545536
Epoch [192/300], Train Loss: 0.005256
Validation Loss: 0.00545427
Epoch [193/300], Train Loss: 0.005271
Validation Loss: 0.00545378
Epoch [194/300], Train Loss: 0.005273
Validation Loss: 0.00545197
Epoch [195/300], Train Loss: 0.005261
Validation Loss: 0.00545352
Epoch [196/300], Train Loss: 0.005261
Validation Loss: 0.00545018
Epoch [197/300], Train Loss: 0.005261
Validation Loss: 0.00544901
Epoch [198/300], Train Loss: 0.005259
Validation Loss: 0.00545008
Epoch [199/300], Train Loss: 0.005243
Validation Loss: 0.00544721
Epoch [200/300], Train Loss: 0.005243
Validation Loss: 0.00545328
Epoch [201/300], Train Loss: 0.005255
Validation Loss: 0.00544738
Epoch [202/300], Train Loss: 0.005265
Validation Loss: 0.00544856
Epoch [203/300], Train Loss: 0.005262
Validation Loss: 0.00545538
Epoch [204/300], Train Loss: 0.005244
Validation Loss: 0.00545505
Epoch [205/300], Train Loss: 0.005241
Validation Loss: 0.00546702
Epoch [206/300], Train Loss: 0.005234
Validation Loss: 0.00544605
Epoch [207/300], Train Loss: 0.005265
Validation Loss: 0.00544113
Epoch [208/300], Train Loss: 0.005236
Validation Loss: 0.00544324
Epoch [209/300], Train Loss: 0.005232
Validation Loss: 0.00543881
Epoch [210/300], Train Loss: 0.005250
Validation Loss: 0.00543760
Epoch [211/300], Train Loss: 0.005238
Validation Loss: 0.00547238
Epoch [212/300], Train Loss: 0.005258
Validation Loss: 0.00544191
Epoch [213/300], Train Loss: 0.005233
Validation Loss: 0.00544934
Epoch [214/300], Train Loss: 0.005246
Validation Loss: 0.00543470
Epoch [215/300], Train Loss: 0.005231
Validation Loss: 0.00544098
Epoch [216/300], Train Loss: 0.005240
Validation Loss: 0.00543361
Epoch [217/300], Train Loss: 0.005241
Validation Loss: 0.00543373
Epoch [218/300], Train Loss: 0.005225
Validation Loss: 0.00542898
Epoch [219/300], Train Loss: 0.005251
Validation Loss: 0.00543041
Epoch [220/300], Train Loss: 0.005244
Validation Loss: 0.00544414
Epoch [221/300], Train Loss: 0.005228
Validation Loss: 0.00543140
Epoch [222/300], Train Loss: 0.005253
Validation Loss: 0.00542702
Epoch [223/300], Train Loss: 0.005233
Validation Loss: 0.00542704
Epoch [224/300], Train Loss: 0.005234
Validation Loss: 0.00543199
Epoch [225/300], Train Loss: 0.005250
Validation Loss: 0.00543565
Epoch [226/300], Train Loss: 0.005235
Validation Loss: 0.00543320
Epoch [227/300], Train Loss: 0.005227
Validation Loss: 0.00543244
Epoch [228/300], Train Loss: 0.005237
Validation Loss: 0.00543288
Epoch [229/300], Train Loss: 0.005231
Validation Loss: 0.00542761
Epoch [230/300], Train Loss: 0.005228
Validation Loss: 0.00542111
Epoch [231/300], Train Loss: 0.005232
Validation Loss: 0.00541925
Epoch [232/300], Train Loss: 0.005231
Validation Loss: 0.00541854
Epoch [233/300], Train Loss: 0.005226
Validation Loss: 0.00541794
Epoch [234/300], Train Loss: 0.005228
Validation Loss: 0.00541962
Epoch [235/300], Train Loss: 0.005230
Validation Loss: 0.00542967
Epoch [236/300], Train Loss: 0.005215
Validation Loss: 0.00541657
Epoch [237/300], Train Loss: 0.005241
Validation Loss: 0.00542390
Epoch [238/300], Train Loss: 0.005238
Validation Loss: 0.00541738
Epoch [239/300], Train Loss: 0.005220
Validation Loss: 0.00541422
Epoch [240/300], Train Loss: 0.005251
Validation Loss: 0.00542136
Epoch [241/300], Train Loss: 0.005252
Validation Loss: 0.00541633
Epoch [242/300], Train Loss: 0.005208
Validation Loss: 0.00541232
Epoch [243/300], Train Loss: 0.005224
Validation Loss: 0.00541561
Epoch [244/300], Train Loss: 0.005228
Validation Loss: 0.00541453
Epoch [245/300], Train Loss: 0.005212
Validation Loss: 0.00542072
Epoch [246/300], Train Loss: 0.005228
Validation Loss: 0.00541545
Epoch [247/300], Train Loss: 0.005226
Validation Loss: 0.00541166
Epoch [248/300], Train Loss: 0.005219
Validation Loss: 0.00540817
Epoch [249/300], Train Loss: 0.005222
Validation Loss: 0.00540820
Epoch [250/300], Train Loss: 0.005203
Validation Loss: 0.00541318
Epoch [251/300], Train Loss: 0.005214
Validation Loss: 0.00541414
Epoch [252/300], Train Loss: 0.005243
Validation Loss: 0.00540513
Epoch [253/300], Train Loss: 0.005224
Validation Loss: 0.00541686
Epoch [254/300], Train Loss: 0.005211
Validation Loss: 0.00542629
Epoch [255/300], Train Loss: 0.005224
Validation Loss: 0.00540196
Epoch [256/300], Train Loss: 0.005204
Validation Loss: 0.00540246
Epoch [257/300], Train Loss: 0.005207
Validation Loss: 0.00541073
Epoch [258/300], Train Loss: 0.005206
Validation Loss: 0.00540025
Epoch [259/300], Train Loss: 0.005232
Validation Loss: 0.00542712
Epoch [260/300], Train Loss: 0.005226
Validation Loss: 0.00540089
Epoch [261/300], Train Loss: 0.005217
Validation Loss: 0.00540009
Epoch [262/300], Train Loss: 0.005203
Validation Loss: 0.00539841
Epoch [263/300], Train Loss: 0.005204
Validation Loss: 0.00541433
Epoch [264/300], Train Loss: 0.005205
Validation Loss: 0.00540400
Epoch [265/300], Train Loss: 0.005224
Validation Loss: 0.00539581
Epoch [266/300], Train Loss: 0.005205
Validation Loss: 0.00539827
Epoch [267/300], Train Loss: 0.005204
Validation Loss: 0.00539666
Epoch [268/300], Train Loss: 0.005220
Validation Loss: 0.00539336
Epoch [269/300], Train Loss: 0.005209
Validation Loss: 0.00539552
Epoch [270/300], Train Loss: 0.005199
Validation Loss: 0.00539349
Epoch [271/300], Train Loss: 0.005192
Validation Loss: 0.00539124
Epoch [272/300], Train Loss: 0.005201
Validation Loss: 0.00539021
Epoch [273/300], Train Loss: 0.005193
Validation Loss: 0.00540034
Epoch [274/300], Train Loss: 0.005190
Validation Loss: 0.00538999
Epoch [275/300], Train Loss: 0.005197
Validation Loss: 0.00538786
Epoch [276/300], Train Loss: 0.005206
Validation Loss: 0.00538595
Epoch [277/300], Train Loss: 0.005210
Validation Loss: 0.00538515
Epoch [278/300], Train Loss: 0.005203
Validation Loss: 0.00538424
Epoch [279/300], Train Loss: 0.005196
Validation Loss: 0.00538252
Epoch [280/300], Train Loss: 0.005208
Validation Loss: 0.00538733
Epoch [281/300], Train Loss: 0.005187
Validation Loss: 0.00539262
Epoch [282/300], Train Loss: 0.005207
Validation Loss: 0.00539607
Epoch [283/300], Train Loss: 0.005212
Validation Loss: 0.00538370
Epoch [284/300], Train Loss: 0.005187
Validation Loss: 0.00538520
Epoch [285/300], Train Loss: 0.005208
Validation Loss: 0.00537745
Epoch [286/300], Train Loss: 0.005199
Validation Loss: 0.00537967
Epoch [287/300], Train Loss: 0.005209
Validation Loss: 0.00542821
Epoch [288/300], Train Loss: 0.005206
Validation Loss: 0.00540388
Epoch [289/300], Train Loss: 0.005187
Validation Loss: 0.00537365
Epoch [290/300], Train Loss: 0.005188
Validation Loss: 0.00537740
Epoch [291/300], Train Loss: 0.005188
Validation Loss: 0.00538294
Epoch [292/300], Train Loss: 0.005188
Validation Loss: 0.00537141
Epoch [293/300], Train Loss: 0.005186
Validation Loss: 0.00537588
Epoch [294/300], Train Loss: 0.005179
Validation Loss: 0.00536913
Epoch [295/300], Train Loss: 0.005176
Validation Loss: 0.00536816
Epoch [296/300], Train Loss: 0.005188
Validation Loss: 0.00536560
Epoch [297/300], Train Loss: 0.005185
Validation Loss: 0.00537506
Epoch [298/300], Train Loss: 0.005184
Validation Loss: 0.00536288
Epoch [299/300], Train Loss: 0.005183
Validation Loss: 0.00536290
Epoch [300/300], Train Loss: 0.005181
Validation Loss: 0.00536567

Evaluating model for: Router
Run 30/72 completed in 1052.87 seconds with: {'MAE': np.float32(0.20106515), 'MSE': np.float32(0.066870466), 'RMSE': np.float32(0.25859323), 'SAE': np.float32(3.4600933e-05), 'NDE': np.float32(0.012922413)}

Run 31/72: hidden=256, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Router
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.078269
Validation Loss: 0.05161784
Epoch [2/300], Train Loss: 0.022430
Validation Loss: 0.00908102
Epoch [3/300], Train Loss: 0.008889
Validation Loss: 0.00834544
Epoch [4/300], Train Loss: 0.007962
Validation Loss: 0.00810661
Epoch [5/300], Train Loss: 0.007819
Validation Loss: 0.00799022
Epoch [6/300], Train Loss: 0.007724
Validation Loss: 0.00788321
Epoch [7/300], Train Loss: 0.007627
Validation Loss: 0.00778619
Epoch [8/300], Train Loss: 0.007505
Validation Loss: 0.00765757
Epoch [9/300], Train Loss: 0.007382
Validation Loss: 0.00755531
Epoch [10/300], Train Loss: 0.007274
Validation Loss: 0.00743844
Epoch [11/300], Train Loss: 0.007177
Validation Loss: 0.00732966
Epoch [12/300], Train Loss: 0.007078
Validation Loss: 0.00723760
Epoch [13/300], Train Loss: 0.006988
Validation Loss: 0.00714468
Epoch [14/300], Train Loss: 0.006856
Validation Loss: 0.00704434
Epoch [15/300], Train Loss: 0.006776
Validation Loss: 0.00700864
Epoch [16/300], Train Loss: 0.006694
Validation Loss: 0.00688678
Epoch [17/300], Train Loss: 0.006621
Validation Loss: 0.00682235
Epoch [18/300], Train Loss: 0.006564
Validation Loss: 0.00677298
Epoch [19/300], Train Loss: 0.006499
Validation Loss: 0.00672358
Epoch [20/300], Train Loss: 0.006471
Validation Loss: 0.00673278
Epoch [21/300], Train Loss: 0.006412
Validation Loss: 0.00663786
Epoch [22/300], Train Loss: 0.006408
Validation Loss: 0.00660488
Epoch [23/300], Train Loss: 0.006357
Validation Loss: 0.00656561
Epoch [24/300], Train Loss: 0.006323
Validation Loss: 0.00652017
Epoch [25/300], Train Loss: 0.006259
Validation Loss: 0.00648500
Epoch [26/300], Train Loss: 0.006240
Validation Loss: 0.00645535
Epoch [27/300], Train Loss: 0.006224
Validation Loss: 0.00643982
Epoch [28/300], Train Loss: 0.006198
Validation Loss: 0.00640438
Epoch [29/300], Train Loss: 0.006156
Validation Loss: 0.00637271
Epoch [30/300], Train Loss: 0.006100
Validation Loss: 0.00633204
Epoch [31/300], Train Loss: 0.006090
Validation Loss: 0.00630551
Epoch [32/300], Train Loss: 0.006064
Validation Loss: 0.00628094
Epoch [33/300], Train Loss: 0.006044
Validation Loss: 0.00629259
Epoch [34/300], Train Loss: 0.006030
Validation Loss: 0.00624002
Epoch [35/300], Train Loss: 0.006000
Validation Loss: 0.00622580
Epoch [36/300], Train Loss: 0.005966
Validation Loss: 0.00623883
Epoch [37/300], Train Loss: 0.005957
Validation Loss: 0.00618034
Epoch [38/300], Train Loss: 0.005968
Validation Loss: 0.00617974
Epoch [39/300], Train Loss: 0.005931
Validation Loss: 0.00616680
Epoch [40/300], Train Loss: 0.005875
Validation Loss: 0.00615259
Epoch [41/300], Train Loss: 0.005883
Validation Loss: 0.00610733
Epoch [42/300], Train Loss: 0.005852
Validation Loss: 0.00609697
Epoch [43/300], Train Loss: 0.005868
Validation Loss: 0.00610687
Epoch [44/300], Train Loss: 0.005830
Validation Loss: 0.00605593
Epoch [45/300], Train Loss: 0.005819
Validation Loss: 0.00605469
Epoch [46/300], Train Loss: 0.005815
Validation Loss: 0.00602533
Epoch [47/300], Train Loss: 0.005801
Validation Loss: 0.00601256
Epoch [48/300], Train Loss: 0.005772
Validation Loss: 0.00603196
Epoch [49/300], Train Loss: 0.005773
Validation Loss: 0.00600334
Epoch [50/300], Train Loss: 0.005747
Validation Loss: 0.00598827
Epoch [51/300], Train Loss: 0.005745
Validation Loss: 0.00599522
Epoch [52/300], Train Loss: 0.005720
Validation Loss: 0.00595490
Epoch [53/300], Train Loss: 0.005719
Validation Loss: 0.00593873
Epoch [54/300], Train Loss: 0.005701
Validation Loss: 0.00593174
Epoch [55/300], Train Loss: 0.005695
Validation Loss: 0.00591633
Epoch [56/300], Train Loss: 0.005699
Validation Loss: 0.00591400
Epoch [57/300], Train Loss: 0.005672
Validation Loss: 0.00589958
Epoch [58/300], Train Loss: 0.005640
Validation Loss: 0.00588199
Epoch [59/300], Train Loss: 0.005647
Validation Loss: 0.00588890
Epoch [60/300], Train Loss: 0.005640
Validation Loss: 0.00586717
Epoch [61/300], Train Loss: 0.005597
Validation Loss: 0.00585001
Epoch [62/300], Train Loss: 0.005613
Validation Loss: 0.00583931
Epoch [63/300], Train Loss: 0.005597
Validation Loss: 0.00585668
Epoch [64/300], Train Loss: 0.005633
Validation Loss: 0.00586554
Epoch [65/300], Train Loss: 0.005618
Validation Loss: 0.00583641
Epoch [66/300], Train Loss: 0.005580
Validation Loss: 0.00580651
Epoch [67/300], Train Loss: 0.005579
Validation Loss: 0.00579378
Epoch [68/300], Train Loss: 0.005569
Validation Loss: 0.00582325
Epoch [69/300], Train Loss: 0.005555
Validation Loss: 0.00579612
Epoch [70/300], Train Loss: 0.005552
Validation Loss: 0.00577076
Epoch [71/300], Train Loss: 0.005541
Validation Loss: 0.00575970
Epoch [72/300], Train Loss: 0.005534
Validation Loss: 0.00574206
Epoch [73/300], Train Loss: 0.005516
Validation Loss: 0.00572845
Epoch [74/300], Train Loss: 0.005479
Validation Loss: 0.00573945
Epoch [75/300], Train Loss: 0.005486
Validation Loss: 0.00569779
Epoch [76/300], Train Loss: 0.005469
Validation Loss: 0.00568509
Epoch [77/300], Train Loss: 0.005474
Validation Loss: 0.00577076
Epoch [78/300], Train Loss: 0.005501
Validation Loss: 0.00572262
Epoch [79/300], Train Loss: 0.005473
Validation Loss: 0.00569691
Epoch [80/300], Train Loss: 0.005475
Validation Loss: 0.00567304
Epoch [81/300], Train Loss: 0.005432
Validation Loss: 0.00566009
Epoch [82/300], Train Loss: 0.005417
Validation Loss: 0.00571607
Epoch [83/300], Train Loss: 0.005439
Validation Loss: 0.00564234
Epoch [84/300], Train Loss: 0.005392
Validation Loss: 0.00562301
Epoch [85/300], Train Loss: 0.005419
Validation Loss: 0.00567785
Epoch [86/300], Train Loss: 0.005398
Validation Loss: 0.00560920
Epoch [87/300], Train Loss: 0.005356
Validation Loss: 0.00558391
Epoch [88/300], Train Loss: 0.005350
Validation Loss: 0.00551316
Epoch [89/300], Train Loss: 0.005347
Validation Loss: 0.00548821
Epoch [90/300], Train Loss: 0.005340
Validation Loss: 0.00562777
Epoch [91/300], Train Loss: 0.005375
Validation Loss: 0.00554252
Epoch [92/300], Train Loss: 0.005296
Validation Loss: 0.00544913
Epoch [93/300], Train Loss: 0.005231
Validation Loss: 0.00543244
Epoch [94/300], Train Loss: 0.005213
Validation Loss: 0.00534913
Epoch [95/300], Train Loss: 0.005188
Validation Loss: 0.00533943
Epoch [96/300], Train Loss: 0.005169
Validation Loss: 0.00527586
Epoch [97/300], Train Loss: 0.005168
Validation Loss: 0.00529774
Epoch [98/300], Train Loss: 0.005157
Validation Loss: 0.00529084
Epoch [99/300], Train Loss: 0.005158
Validation Loss: 0.00523195
Epoch [100/300], Train Loss: 0.005121
Validation Loss: 0.00520149
Epoch [101/300], Train Loss: 0.005167
Validation Loss: 0.00542857
Epoch [102/300], Train Loss: 0.005106
Validation Loss: 0.00525314
Epoch [103/300], Train Loss: 0.005103
Validation Loss: 0.00522992
Epoch [104/300], Train Loss: 0.005044
Validation Loss: 0.00514920
Epoch [105/300], Train Loss: 0.005045
Validation Loss: 0.00514286
Epoch [106/300], Train Loss: 0.005094
Validation Loss: 0.00524340
Epoch [107/300], Train Loss: 0.005073
Validation Loss: 0.00512208
Epoch [108/300], Train Loss: 0.005000
Validation Loss: 0.00512838
Epoch [109/300], Train Loss: 0.005008
Validation Loss: 0.00506923
Epoch [110/300], Train Loss: 0.004999
Validation Loss: 0.00505819
Epoch [111/300], Train Loss: 0.004974
Validation Loss: 0.00505908
Epoch [112/300], Train Loss: 0.004960
Validation Loss: 0.00504969
Epoch [113/300], Train Loss: 0.004956
Validation Loss: 0.00500503
Epoch [114/300], Train Loss: 0.004972
Validation Loss: 0.00508476
Epoch [115/300], Train Loss: 0.004961
Validation Loss: 0.00496672
Epoch [116/300], Train Loss: 0.004926
Validation Loss: 0.00494503
Epoch [117/300], Train Loss: 0.004927
Validation Loss: 0.00494321
Epoch [118/300], Train Loss: 0.004938
Validation Loss: 0.00495745
Epoch [119/300], Train Loss: 0.004906
Validation Loss: 0.00492713
Epoch [120/300], Train Loss: 0.004867
Validation Loss: 0.00492697
Epoch [121/300], Train Loss: 0.004860
Validation Loss: 0.00487835
Epoch [122/300], Train Loss: 0.004842
Validation Loss: 0.00487211
Epoch [123/300], Train Loss: 0.004820
Validation Loss: 0.00487169
Epoch [124/300], Train Loss: 0.004813
Validation Loss: 0.00486564
Epoch [125/300], Train Loss: 0.004801
Validation Loss: 0.00502251
Epoch [126/300], Train Loss: 0.004839
Validation Loss: 0.00484232
Epoch [127/300], Train Loss: 0.004768
Validation Loss: 0.00478497
Epoch [128/300], Train Loss: 0.004759
Validation Loss: 0.00476996
Epoch [129/300], Train Loss: 0.004751
Validation Loss: 0.00477062
Epoch [130/300], Train Loss: 0.004740
Validation Loss: 0.00474263
Epoch [131/300], Train Loss: 0.004760
Validation Loss: 0.00473018
Epoch [132/300], Train Loss: 0.004722
Validation Loss: 0.00475359
Epoch [133/300], Train Loss: 0.004724
Validation Loss: 0.00477419
Epoch [134/300], Train Loss: 0.004717
Validation Loss: 0.00475266
Epoch [135/300], Train Loss: 0.004739
Validation Loss: 0.00472361
Epoch [136/300], Train Loss: 0.004698
Validation Loss: 0.00469038
Epoch [137/300], Train Loss: 0.004710
Validation Loss: 0.00474238
Epoch [138/300], Train Loss: 0.004683
Validation Loss: 0.00470579
Epoch [139/300], Train Loss: 0.004673
Validation Loss: 0.00470561
Epoch [140/300], Train Loss: 0.004694
Validation Loss: 0.00468202
Epoch [141/300], Train Loss: 0.004698
Validation Loss: 0.00489767
Epoch [142/300], Train Loss: 0.004695
Validation Loss: 0.00470895
Epoch [143/300], Train Loss: 0.004655
Validation Loss: 0.00467012
Epoch [144/300], Train Loss: 0.004673
Validation Loss: 0.00470686
Epoch [145/300], Train Loss: 0.004653
Validation Loss: 0.00470500
Epoch [146/300], Train Loss: 0.004676
Validation Loss: 0.00468216
Epoch [147/300], Train Loss: 0.004673
Validation Loss: 0.00469850
Epoch [148/300], Train Loss: 0.004649
Validation Loss: 0.00468739
Epoch [149/300], Train Loss: 0.004651
Validation Loss: 0.00466308
Epoch [150/300], Train Loss: 0.004711
Validation Loss: 0.00474828
Epoch [151/300], Train Loss: 0.004665
Validation Loss: 0.00466561
Epoch [152/300], Train Loss: 0.004637
Validation Loss: 0.00464352
Epoch [153/300], Train Loss: 0.004630
Validation Loss: 0.00464308
Epoch [154/300], Train Loss: 0.004642
Validation Loss: 0.00464190
Epoch [155/300], Train Loss: 0.004624
Validation Loss: 0.00464435
Epoch [156/300], Train Loss: 0.004636
Validation Loss: 0.00468217
Epoch [157/300], Train Loss: 0.004645
Validation Loss: 0.00464985
Epoch [158/300], Train Loss: 0.004638
Validation Loss: 0.00465192
Epoch [159/300], Train Loss: 0.004604
Validation Loss: 0.00465044
Epoch [160/300], Train Loss: 0.004634
Validation Loss: 0.00474458
Epoch [161/300], Train Loss: 0.004624
Validation Loss: 0.00463291
Epoch [162/300], Train Loss: 0.004613
Validation Loss: 0.00464650
Epoch [163/300], Train Loss: 0.004616
Validation Loss: 0.00463860
Epoch [164/300], Train Loss: 0.004619
Validation Loss: 0.00463424
Epoch [165/300], Train Loss: 0.004599
Validation Loss: 0.00464649
Epoch [166/300], Train Loss: 0.004617
Validation Loss: 0.00462568
Epoch [167/300], Train Loss: 0.004602
Validation Loss: 0.00466436
Epoch [168/300], Train Loss: 0.004601
Validation Loss: 0.00465084
Epoch [169/300], Train Loss: 0.004608
Validation Loss: 0.00471642
Epoch [170/300], Train Loss: 0.004687
Validation Loss: 0.00463275
Epoch [171/300], Train Loss: 0.004602
Validation Loss: 0.00461129
Epoch [172/300], Train Loss: 0.004624
Validation Loss: 0.00463222
Epoch [173/300], Train Loss: 0.004597
Validation Loss: 0.00464221
Epoch [174/300], Train Loss: 0.004597
Validation Loss: 0.00463411
Epoch [175/300], Train Loss: 0.004644
Validation Loss: 0.00464415
Epoch [176/300], Train Loss: 0.004629
Validation Loss: 0.00468013
Epoch [177/300], Train Loss: 0.004622
Validation Loss: 0.00461438
Epoch [178/300], Train Loss: 0.004621
Validation Loss: 0.00469291
Epoch [179/300], Train Loss: 0.004598
Validation Loss: 0.00460620
Epoch [180/300], Train Loss: 0.004579
Validation Loss: 0.00462095
Epoch [181/300], Train Loss: 0.004598
Validation Loss: 0.00463833
Epoch [182/300], Train Loss: 0.004579
Validation Loss: 0.00462860
Epoch [183/300], Train Loss: 0.004598
Validation Loss: 0.00461783
Epoch [184/300], Train Loss: 0.004584
Validation Loss: 0.00462947
Epoch [185/300], Train Loss: 0.004579
Validation Loss: 0.00460319
Epoch [186/300], Train Loss: 0.004577
Validation Loss: 0.00460888
Epoch [187/300], Train Loss: 0.004597
Validation Loss: 0.00462104
Epoch [188/300], Train Loss: 0.004616
Validation Loss: 0.00459588
Epoch [189/300], Train Loss: 0.004571
Validation Loss: 0.00463928
Epoch [190/300], Train Loss: 0.004618
Validation Loss: 0.00465525
Epoch [191/300], Train Loss: 0.004607
Validation Loss: 0.00462850
Epoch [192/300], Train Loss: 0.004583
Validation Loss: 0.00460523
Epoch [193/300], Train Loss: 0.004580
Validation Loss: 0.00458859
Epoch [194/300], Train Loss: 0.004585
Validation Loss: 0.00463630
Epoch [195/300], Train Loss: 0.004598
Validation Loss: 0.00463924
Epoch [196/300], Train Loss: 0.004571
Validation Loss: 0.00459282
Epoch [197/300], Train Loss: 0.004568
Validation Loss: 0.00462095
Epoch [198/300], Train Loss: 0.004562
Validation Loss: 0.00458564
Epoch [199/300], Train Loss: 0.004559
Validation Loss: 0.00464360
Epoch [200/300], Train Loss: 0.004568
Validation Loss: 0.00459010
Epoch [201/300], Train Loss: 0.004573
Validation Loss: 0.00459071
Epoch [202/300], Train Loss: 0.004569
Validation Loss: 0.00461351
Epoch [203/300], Train Loss: 0.004567
Validation Loss: 0.00458842
Epoch [204/300], Train Loss: 0.004589
Validation Loss: 0.00462715
Epoch [205/300], Train Loss: 0.004568
Validation Loss: 0.00475209
Epoch [206/300], Train Loss: 0.004586
Validation Loss: 0.00458039
Epoch [207/300], Train Loss: 0.004595
Validation Loss: 0.00457637
Epoch [208/300], Train Loss: 0.004543
Validation Loss: 0.00458251
Epoch [209/300], Train Loss: 0.004543
Validation Loss: 0.00458372
Epoch [210/300], Train Loss: 0.004551
Validation Loss: 0.00458329
Epoch [211/300], Train Loss: 0.004552
Validation Loss: 0.00461265
Epoch [212/300], Train Loss: 0.004566
Validation Loss: 0.00457908
Epoch [213/300], Train Loss: 0.004553
Validation Loss: 0.00459653
Epoch [214/300], Train Loss: 0.004541
Validation Loss: 0.00458854
Epoch [215/300], Train Loss: 0.004544
Validation Loss: 0.00461077
Epoch [216/300], Train Loss: 0.004558
Validation Loss: 0.00457842
Epoch [217/300], Train Loss: 0.004560
Validation Loss: 0.00458393
Early stopping triggered

Evaluating model for: Router
Run 31/72 completed in 808.00 seconds with: {'MAE': np.float32(0.19000751), 'MSE': np.float32(0.059240907), 'RMSE': np.float32(0.24339455), 'SAE': np.float32(2.705164e-05), 'NDE': np.float32(0.012162905)}

Run 32/72: hidden=256, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Router
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.099226
Validation Loss: 0.06951234
Epoch [2/300], Train Loss: 0.029489
Validation Loss: 0.01162960
Epoch [3/300], Train Loss: 0.010279
Validation Loss: 0.00914031
Epoch [4/300], Train Loss: 0.008980
Validation Loss: 0.00894972
Epoch [5/300], Train Loss: 0.008724
Validation Loss: 0.00878286
Epoch [6/300], Train Loss: 0.008561
Validation Loss: 0.00862013
Epoch [7/300], Train Loss: 0.008402
Validation Loss: 0.00847189
Epoch [8/300], Train Loss: 0.008246
Validation Loss: 0.00830646
Epoch [9/300], Train Loss: 0.008080
Validation Loss: 0.00815122
Epoch [10/300], Train Loss: 0.007927
Validation Loss: 0.00799164
Epoch [11/300], Train Loss: 0.007775
Validation Loss: 0.00783658
Epoch [12/300], Train Loss: 0.007657
Validation Loss: 0.00772466
Epoch [13/300], Train Loss: 0.007518
Validation Loss: 0.00759363
Epoch [14/300], Train Loss: 0.007372
Validation Loss: 0.00749154
Epoch [15/300], Train Loss: 0.007324
Validation Loss: 0.00752394
Epoch [16/300], Train Loss: 0.007221
Validation Loss: 0.00733913
Epoch [17/300], Train Loss: 0.007134
Validation Loss: 0.00728235
Epoch [18/300], Train Loss: 0.007081
Validation Loss: 0.00724717
Epoch [19/300], Train Loss: 0.007023
Validation Loss: 0.00717666
Epoch [20/300], Train Loss: 0.006972
Validation Loss: 0.00716797
Epoch [21/300], Train Loss: 0.006908
Validation Loss: 0.00707173
Epoch [22/300], Train Loss: 0.006896
Validation Loss: 0.00702058
Epoch [23/300], Train Loss: 0.006829
Validation Loss: 0.00697935
Epoch [24/300], Train Loss: 0.006800
Validation Loss: 0.00693194
Epoch [25/300], Train Loss: 0.006728
Validation Loss: 0.00689067
Epoch [26/300], Train Loss: 0.006688
Validation Loss: 0.00684972
Epoch [27/300], Train Loss: 0.006661
Validation Loss: 0.00682010
Epoch [28/300], Train Loss: 0.006639
Validation Loss: 0.00679166
Epoch [29/300], Train Loss: 0.006585
Validation Loss: 0.00673863
Epoch [30/300], Train Loss: 0.006508
Validation Loss: 0.00669871
Epoch [31/300], Train Loss: 0.006501
Validation Loss: 0.00666129
Epoch [32/300], Train Loss: 0.006461
Validation Loss: 0.00662195
Epoch [33/300], Train Loss: 0.006426
Validation Loss: 0.00660092
Epoch [34/300], Train Loss: 0.006393
Validation Loss: 0.00655764
Epoch [35/300], Train Loss: 0.006356
Validation Loss: 0.00651906
Epoch [36/300], Train Loss: 0.006323
Validation Loss: 0.00653894
Epoch [37/300], Train Loss: 0.006291
Validation Loss: 0.00646222
Epoch [38/300], Train Loss: 0.006320
Validation Loss: 0.00649398
Epoch [39/300], Train Loss: 0.006271
Validation Loss: 0.00647398
Epoch [40/300], Train Loss: 0.006212
Validation Loss: 0.00642342
Epoch [41/300], Train Loss: 0.006193
Validation Loss: 0.00637210
Epoch [42/300], Train Loss: 0.006163
Validation Loss: 0.00634789
Epoch [43/300], Train Loss: 0.006170
Validation Loss: 0.00636321
Epoch [44/300], Train Loss: 0.006130
Validation Loss: 0.00630538
Epoch [45/300], Train Loss: 0.006112
Validation Loss: 0.00630262
Epoch [46/300], Train Loss: 0.006090
Validation Loss: 0.00627677
Epoch [47/300], Train Loss: 0.006102
Validation Loss: 0.00627521
Epoch [48/300], Train Loss: 0.006044
Validation Loss: 0.00628753
Epoch [49/300], Train Loss: 0.006051
Validation Loss: 0.00621757
Epoch [50/300], Train Loss: 0.006046
Validation Loss: 0.00627338
Epoch [51/300], Train Loss: 0.006007
Validation Loss: 0.00621184
Epoch [52/300], Train Loss: 0.005998
Validation Loss: 0.00617017
Epoch [53/300], Train Loss: 0.005987
Validation Loss: 0.00615317
Epoch [54/300], Train Loss: 0.005945
Validation Loss: 0.00614698
Epoch [55/300], Train Loss: 0.005955
Validation Loss: 0.00613102
Epoch [56/300], Train Loss: 0.005939
Validation Loss: 0.00610848
Epoch [57/300], Train Loss: 0.005911
Validation Loss: 0.00612194
Epoch [58/300], Train Loss: 0.005885
Validation Loss: 0.00608179
Epoch [59/300], Train Loss: 0.005869
Validation Loss: 0.00606431
Epoch [60/300], Train Loss: 0.005882
Validation Loss: 0.00604691
Epoch [61/300], Train Loss: 0.005827
Validation Loss: 0.00603281
Epoch [62/300], Train Loss: 0.005838
Validation Loss: 0.00602411
Epoch [63/300], Train Loss: 0.005818
Validation Loss: 0.00601401
Epoch [64/300], Train Loss: 0.005827
Validation Loss: 0.00606777
Epoch [65/300], Train Loss: 0.005809
Validation Loss: 0.00598172
Epoch [66/300], Train Loss: 0.005775
Validation Loss: 0.00596928
Epoch [67/300], Train Loss: 0.005760
Validation Loss: 0.00600795
Epoch [68/300], Train Loss: 0.005770
Validation Loss: 0.00596149
Epoch [69/300], Train Loss: 0.005732
Validation Loss: 0.00592959
Epoch [70/300], Train Loss: 0.005727
Validation Loss: 0.00591465
Epoch [71/300], Train Loss: 0.005711
Validation Loss: 0.00589653
Epoch [72/300], Train Loss: 0.005718
Validation Loss: 0.00588928
Epoch [73/300], Train Loss: 0.005706
Validation Loss: 0.00587257
Epoch [74/300], Train Loss: 0.005648
Validation Loss: 0.00591828
Epoch [75/300], Train Loss: 0.005657
Validation Loss: 0.00584180
Epoch [76/300], Train Loss: 0.005620
Validation Loss: 0.00584613
Epoch [77/300], Train Loss: 0.005635
Validation Loss: 0.00587324
Epoch [78/300], Train Loss: 0.005646
Validation Loss: 0.00581414
Epoch [79/300], Train Loss: 0.005594
Validation Loss: 0.00578183
Epoch [80/300], Train Loss: 0.005590
Validation Loss: 0.00580332
Epoch [81/300], Train Loss: 0.005548
Validation Loss: 0.00580375
Epoch [82/300], Train Loss: 0.005537
Validation Loss: 0.00583833
Epoch [83/300], Train Loss: 0.005544
Validation Loss: 0.00571271
Epoch [84/300], Train Loss: 0.005510
Validation Loss: 0.00574791
Epoch [85/300], Train Loss: 0.005496
Validation Loss: 0.00577809
Epoch [86/300], Train Loss: 0.005527
Validation Loss: 0.00568584
Epoch [87/300], Train Loss: 0.005470
Validation Loss: 0.00565908
Epoch [88/300], Train Loss: 0.005438
Validation Loss: 0.00563101
Epoch [89/300], Train Loss: 0.005439
Validation Loss: 0.00566104
Epoch [90/300], Train Loss: 0.005422
Validation Loss: 0.00558497
Epoch [91/300], Train Loss: 0.005369
Validation Loss: 0.00558903
Epoch [92/300], Train Loss: 0.005405
Validation Loss: 0.00556842
Epoch [93/300], Train Loss: 0.005361
Validation Loss: 0.00559581
Epoch [94/300], Train Loss: 0.005433
Validation Loss: 0.00565967
Epoch [95/300], Train Loss: 0.005383
Validation Loss: 0.00564357
Epoch [96/300], Train Loss: 0.005364
Validation Loss: 0.00548490
Epoch [97/300], Train Loss: 0.005287
Validation Loss: 0.00546041
Epoch [98/300], Train Loss: 0.005279
Validation Loss: 0.00553434
Epoch [99/300], Train Loss: 0.005243
Validation Loss: 0.00543043
Epoch [100/300], Train Loss: 0.005243
Validation Loss: 0.00542002
Epoch [101/300], Train Loss: 0.005289
Validation Loss: 0.00554163
Epoch [102/300], Train Loss: 0.005216
Validation Loss: 0.00539434
Epoch [103/300], Train Loss: 0.005196
Validation Loss: 0.00533014
Epoch [104/300], Train Loss: 0.005139
Validation Loss: 0.00530110
Epoch [105/300], Train Loss: 0.005135
Validation Loss: 0.00527187
Epoch [106/300], Train Loss: 0.005139
Validation Loss: 0.00537495
Epoch [107/300], Train Loss: 0.005152
Validation Loss: 0.00524522
Epoch [108/300], Train Loss: 0.005086
Validation Loss: 0.00523585
Epoch [109/300], Train Loss: 0.005103
Validation Loss: 0.00519174
Epoch [110/300], Train Loss: 0.005070
Validation Loss: 0.00518523
Epoch [111/300], Train Loss: 0.005044
Validation Loss: 0.00517389
Epoch [112/300], Train Loss: 0.005024
Validation Loss: 0.00513523
Epoch [113/300], Train Loss: 0.005020
Validation Loss: 0.00512545
Epoch [114/300], Train Loss: 0.005078
Validation Loss: 0.00520353
Epoch [115/300], Train Loss: 0.005012
Validation Loss: 0.00505515
Epoch [116/300], Train Loss: 0.005008
Validation Loss: 0.00502575
Epoch [117/300], Train Loss: 0.005014
Validation Loss: 0.00502956
Epoch [118/300], Train Loss: 0.004970
Validation Loss: 0.00499993
Epoch [119/300], Train Loss: 0.004945
Validation Loss: 0.00499315
Epoch [120/300], Train Loss: 0.004939
Validation Loss: 0.00502037
Epoch [121/300], Train Loss: 0.004922
Validation Loss: 0.00494346
Epoch [122/300], Train Loss: 0.004892
Validation Loss: 0.00493571
Epoch [123/300], Train Loss: 0.004894
Validation Loss: 0.00492129
Epoch [124/300], Train Loss: 0.004857
Validation Loss: 0.00492812
Epoch [125/300], Train Loss: 0.004869
Validation Loss: 0.00515940
Epoch [126/300], Train Loss: 0.004881
Validation Loss: 0.00488794
Epoch [127/300], Train Loss: 0.004823
Validation Loss: 0.00485128
Epoch [128/300], Train Loss: 0.004817
Validation Loss: 0.00483791
Epoch [129/300], Train Loss: 0.004811
Validation Loss: 0.00483256
Epoch [130/300], Train Loss: 0.004798
Validation Loss: 0.00481580
Epoch [131/300], Train Loss: 0.004808
Validation Loss: 0.00479944
Epoch [132/300], Train Loss: 0.004789
Validation Loss: 0.00481048
Epoch [133/300], Train Loss: 0.004807
Validation Loss: 0.00483084
Epoch [134/300], Train Loss: 0.004805
Validation Loss: 0.00483745
Epoch [135/300], Train Loss: 0.004807
Validation Loss: 0.00483812
Epoch [136/300], Train Loss: 0.004747
Validation Loss: 0.00475403
Epoch [137/300], Train Loss: 0.004756
Validation Loss: 0.00479656
Epoch [138/300], Train Loss: 0.004746
Validation Loss: 0.00477525
Epoch [139/300], Train Loss: 0.004736
Validation Loss: 0.00475611
Epoch [140/300], Train Loss: 0.004738
Validation Loss: 0.00472607
Epoch [141/300], Train Loss: 0.004739
Validation Loss: 0.00487278
Epoch [142/300], Train Loss: 0.004735
Validation Loss: 0.00484039
Epoch [143/300], Train Loss: 0.004727
Validation Loss: 0.00470627
Epoch [144/300], Train Loss: 0.004707
Validation Loss: 0.00473257
Epoch [145/300], Train Loss: 0.004696
Validation Loss: 0.00472551
Epoch [146/300], Train Loss: 0.004733
Validation Loss: 0.00473805
Epoch [147/300], Train Loss: 0.004718
Validation Loss: 0.00475345
Epoch [148/300], Train Loss: 0.004708
Validation Loss: 0.00470502
Epoch [149/300], Train Loss: 0.004698
Validation Loss: 0.00472358
Epoch [150/300], Train Loss: 0.004778
Validation Loss: 0.00476703
Epoch [151/300], Train Loss: 0.004709
Validation Loss: 0.00468758
Epoch [152/300], Train Loss: 0.004675
Validation Loss: 0.00465799
Epoch [153/300], Train Loss: 0.004666
Validation Loss: 0.00465730
Epoch [154/300], Train Loss: 0.004676
Validation Loss: 0.00466590
Epoch [155/300], Train Loss: 0.004664
Validation Loss: 0.00465144
Epoch [156/300], Train Loss: 0.004666
Validation Loss: 0.00468250
Epoch [157/300], Train Loss: 0.004668
Validation Loss: 0.00465128
Epoch [158/300], Train Loss: 0.004666
Validation Loss: 0.00465953
Epoch [159/300], Train Loss: 0.004644
Validation Loss: 0.00465224
Epoch [160/300], Train Loss: 0.004661
Validation Loss: 0.00473776
Epoch [161/300], Train Loss: 0.004656
Validation Loss: 0.00463223
Epoch [162/300], Train Loss: 0.004644
Validation Loss: 0.00464346
Epoch [163/300], Train Loss: 0.004634
Validation Loss: 0.00463630
Epoch [164/300], Train Loss: 0.004646
Validation Loss: 0.00463030
Epoch [165/300], Train Loss: 0.004623
Validation Loss: 0.00463129
Epoch [166/300], Train Loss: 0.004645
Validation Loss: 0.00461999
Epoch [167/300], Train Loss: 0.004623
Validation Loss: 0.00465932
Epoch [168/300], Train Loss: 0.004618
Validation Loss: 0.00464456
Epoch [169/300], Train Loss: 0.004615
Validation Loss: 0.00470574
Epoch [170/300], Train Loss: 0.004681
Validation Loss: 0.00461369
Epoch [171/300], Train Loss: 0.004647
Validation Loss: 0.00459753
Epoch [172/300], Train Loss: 0.004636
Validation Loss: 0.00461682
Epoch [173/300], Train Loss: 0.004606
Validation Loss: 0.00462862
Epoch [174/300], Train Loss: 0.004614
Validation Loss: 0.00460852
Epoch [175/300], Train Loss: 0.004649
Validation Loss: 0.00461233
Epoch [176/300], Train Loss: 0.004641
Validation Loss: 0.00468674
Epoch [177/300], Train Loss: 0.004638
Validation Loss: 0.00460372
Epoch [178/300], Train Loss: 0.004642
Validation Loss: 0.00467062
Epoch [179/300], Train Loss: 0.004613
Validation Loss: 0.00458341
Epoch [180/300], Train Loss: 0.004599
Validation Loss: 0.00459448
Epoch [181/300], Train Loss: 0.004601
Validation Loss: 0.00460034
Epoch [182/300], Train Loss: 0.004590
Validation Loss: 0.00460948
Epoch [183/300], Train Loss: 0.004609
Validation Loss: 0.00459441
Epoch [184/300], Train Loss: 0.004590
Validation Loss: 0.00460505
Epoch [185/300], Train Loss: 0.004589
Validation Loss: 0.00458148
Epoch [186/300], Train Loss: 0.004590
Validation Loss: 0.00458901
Epoch [187/300], Train Loss: 0.004623
Validation Loss: 0.00460888
Epoch [188/300], Train Loss: 0.004635
Validation Loss: 0.00457019
Epoch [189/300], Train Loss: 0.004587
Validation Loss: 0.00464067
Epoch [190/300], Train Loss: 0.004632
Validation Loss: 0.00464547
Epoch [191/300], Train Loss: 0.004621
Validation Loss: 0.00460710
Epoch [192/300], Train Loss: 0.004593
Validation Loss: 0.00458271
Epoch [193/300], Train Loss: 0.004582
Validation Loss: 0.00455943
Epoch [194/300], Train Loss: 0.004588
Validation Loss: 0.00460304
Epoch [195/300], Train Loss: 0.004596
Validation Loss: 0.00463157
Epoch [196/300], Train Loss: 0.004585
Validation Loss: 0.00455841
Epoch [197/300], Train Loss: 0.004573
Validation Loss: 0.00458701
Epoch [198/300], Train Loss: 0.004567
Validation Loss: 0.00455502
Epoch [199/300], Train Loss: 0.004562
Validation Loss: 0.00461838
Epoch [200/300], Train Loss: 0.004575
Validation Loss: 0.00455682
Epoch [201/300], Train Loss: 0.004580
Validation Loss: 0.00455969
Epoch [202/300], Train Loss: 0.004561
Validation Loss: 0.00457519
Epoch [203/300], Train Loss: 0.004567
Validation Loss: 0.00455550
Epoch [204/300], Train Loss: 0.004593
Validation Loss: 0.00459966
Epoch [205/300], Train Loss: 0.004569
Validation Loss: 0.00469740
Epoch [206/300], Train Loss: 0.004586
Validation Loss: 0.00454456
Epoch [207/300], Train Loss: 0.004616
Validation Loss: 0.00454485
Epoch [208/300], Train Loss: 0.004550
Validation Loss: 0.00454858
Epoch [209/300], Train Loss: 0.004547
Validation Loss: 0.00454584
Epoch [210/300], Train Loss: 0.004555
Validation Loss: 0.00455557
Epoch [211/300], Train Loss: 0.004564
Validation Loss: 0.00457685
Epoch [212/300], Train Loss: 0.004569
Validation Loss: 0.00454460
Epoch [213/300], Train Loss: 0.004554
Validation Loss: 0.00455506
Epoch [214/300], Train Loss: 0.004542
Validation Loss: 0.00455343
Epoch [215/300], Train Loss: 0.004549
Validation Loss: 0.00458313
Epoch [216/300], Train Loss: 0.004574
Validation Loss: 0.00454329
Epoch [217/300], Train Loss: 0.004564
Validation Loss: 0.00455459
Epoch [218/300], Train Loss: 0.004551
Validation Loss: 0.00455726
Epoch [219/300], Train Loss: 0.004565
Validation Loss: 0.00457933
Epoch [220/300], Train Loss: 0.004574
Validation Loss: 0.00459614
Epoch [221/300], Train Loss: 0.004548
Validation Loss: 0.00456369
Epoch [222/300], Train Loss: 0.004569
Validation Loss: 0.00460634
Epoch [223/300], Train Loss: 0.004548
Validation Loss: 0.00453992
Epoch [224/300], Train Loss: 0.004547
Validation Loss: 0.00453263
Epoch [225/300], Train Loss: 0.004550
Validation Loss: 0.00453729
Epoch [226/300], Train Loss: 0.004537
Validation Loss: 0.00453388
Epoch [227/300], Train Loss: 0.004551
Validation Loss: 0.00468672
Epoch [228/300], Train Loss: 0.004586
Validation Loss: 0.00454167
Epoch [229/300], Train Loss: 0.004557
Validation Loss: 0.00457811
Epoch [230/300], Train Loss: 0.004540
Validation Loss: 0.00458543
Epoch [231/300], Train Loss: 0.004553
Validation Loss: 0.00454206
Epoch [232/300], Train Loss: 0.004535
Validation Loss: 0.00455910
Epoch [233/300], Train Loss: 0.004546
Validation Loss: 0.00453836
Epoch [234/300], Train Loss: 0.004558
Validation Loss: 0.00456825
Early stopping triggered

Evaluating model for: Router
Run 32/72 completed in 1011.21 seconds with: {'MAE': np.float32(0.19032528), 'MSE': np.float32(0.05883899), 'RMSE': np.float32(0.2425675), 'SAE': np.float32(0.00038139665), 'NDE': np.float32(0.012121575)}

Run 33/72: hidden=256, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Router
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.098079
Validation Loss: 0.08414278
Epoch [2/300], Train Loss: 0.064695
Validation Loss: 0.04427078
Epoch [3/300], Train Loss: 0.020457
Validation Loss: 0.01225182
Epoch [4/300], Train Loss: 0.008672
Validation Loss: 0.00808597
Epoch [5/300], Train Loss: 0.006985
Validation Loss: 0.00624766
Epoch [6/300], Train Loss: 0.006630
Validation Loss: 0.00627753
Epoch [7/300], Train Loss: 0.006487
Validation Loss: 0.00602365
Epoch [8/300], Train Loss: 0.006426
Validation Loss: 0.00612719
Epoch [9/300], Train Loss: 0.006421
Validation Loss: 0.00600125
Epoch [10/300], Train Loss: 0.006381
Validation Loss: 0.00605239
Epoch [11/300], Train Loss: 0.006358
Validation Loss: 0.00598937
Epoch [12/300], Train Loss: 0.006339
Validation Loss: 0.00599880
Epoch [13/300], Train Loss: 0.006325
Validation Loss: 0.00597335
Epoch [14/300], Train Loss: 0.006321
Validation Loss: 0.00597248
Epoch [15/300], Train Loss: 0.006283
Validation Loss: 0.00594975
Epoch [16/300], Train Loss: 0.006281
Validation Loss: 0.00596675
Epoch [17/300], Train Loss: 0.006304
Validation Loss: 0.00593175
Epoch [18/300], Train Loss: 0.006247
Validation Loss: 0.00592407
Epoch [19/300], Train Loss: 0.006257
Validation Loss: 0.00591511
Epoch [20/300], Train Loss: 0.006254
Validation Loss: 0.00591005
Epoch [21/300], Train Loss: 0.006203
Validation Loss: 0.00590350
Epoch [22/300], Train Loss: 0.006188
Validation Loss: 0.00597788
Epoch [23/300], Train Loss: 0.006198
Validation Loss: 0.00586448
Epoch [24/300], Train Loss: 0.006172
Validation Loss: 0.00586882
Epoch [25/300], Train Loss: 0.006149
Validation Loss: 0.00590839
Epoch [26/300], Train Loss: 0.006159
Validation Loss: 0.00586131
Epoch [27/300], Train Loss: 0.006134
Validation Loss: 0.00586163
Epoch [28/300], Train Loss: 0.006087
Validation Loss: 0.00584382
Epoch [29/300], Train Loss: 0.006111
Validation Loss: 0.00583580
Epoch [30/300], Train Loss: 0.006117
Validation Loss: 0.00583365
Epoch [31/300], Train Loss: 0.006093
Validation Loss: 0.00586078
Epoch [32/300], Train Loss: 0.006056
Validation Loss: 0.00578937
Epoch [33/300], Train Loss: 0.006059
Validation Loss: 0.00579671
Epoch [34/300], Train Loss: 0.006054
Validation Loss: 0.00590649
Epoch [35/300], Train Loss: 0.006079
Validation Loss: 0.00580161
Epoch [36/300], Train Loss: 0.006031
Validation Loss: 0.00578400
Epoch [37/300], Train Loss: 0.006092
Validation Loss: 0.00577361
Epoch [38/300], Train Loss: 0.006031
Validation Loss: 0.00575117
Epoch [39/300], Train Loss: 0.006017
Validation Loss: 0.00575199
Epoch [40/300], Train Loss: 0.006028
Validation Loss: 0.00577780
Epoch [41/300], Train Loss: 0.006019
Validation Loss: 0.00574405
Epoch [42/300], Train Loss: 0.005995
Validation Loss: 0.00574785
Epoch [43/300], Train Loss: 0.005995
Validation Loss: 0.00573997
Epoch [44/300], Train Loss: 0.006011
Validation Loss: 0.00570782
Epoch [45/300], Train Loss: 0.005971
Validation Loss: 0.00572540
Epoch [46/300], Train Loss: 0.005948
Validation Loss: 0.00571778
Epoch [47/300], Train Loss: 0.005927
Validation Loss: 0.00572758
Epoch [48/300], Train Loss: 0.005935
Validation Loss: 0.00575843
Epoch [49/300], Train Loss: 0.005913
Validation Loss: 0.00567610
Epoch [50/300], Train Loss: 0.005918
Validation Loss: 0.00567718
Epoch [51/300], Train Loss: 0.005909
Validation Loss: 0.00580358
Epoch [52/300], Train Loss: 0.005931
Validation Loss: 0.00565185
Epoch [53/300], Train Loss: 0.005925
Validation Loss: 0.00567447
Epoch [54/300], Train Loss: 0.005907
Validation Loss: 0.00574398
Epoch [55/300], Train Loss: 0.005928
Validation Loss: 0.00567457
Epoch [56/300], Train Loss: 0.005879
Validation Loss: 0.00563401
Epoch [57/300], Train Loss: 0.005904
Validation Loss: 0.00563705
Epoch [58/300], Train Loss: 0.005927
Validation Loss: 0.00563244
Epoch [59/300], Train Loss: 0.005878
Validation Loss: 0.00568442
Epoch [60/300], Train Loss: 0.005868
Validation Loss: 0.00561802
Epoch [61/300], Train Loss: 0.005858
Validation Loss: 0.00564505
Epoch [62/300], Train Loss: 0.005861
Validation Loss: 0.00563590
Epoch [63/300], Train Loss: 0.005839
Validation Loss: 0.00564257
Epoch [64/300], Train Loss: 0.005837
Validation Loss: 0.00561089
Epoch [65/300], Train Loss: 0.005841
Validation Loss: 0.00559604
Epoch [66/300], Train Loss: 0.005825
Validation Loss: 0.00557732
Epoch [67/300], Train Loss: 0.005865
Validation Loss: 0.00571659
Epoch [68/300], Train Loss: 0.005852
Validation Loss: 0.00559108
Epoch [69/300], Train Loss: 0.005861
Validation Loss: 0.00557956
Epoch [70/300], Train Loss: 0.005829
Validation Loss: 0.00558065
Epoch [71/300], Train Loss: 0.005826
Validation Loss: 0.00569131
Epoch [72/300], Train Loss: 0.005797
Validation Loss: 0.00557515
Epoch [73/300], Train Loss: 0.005808
Validation Loss: 0.00557807
Epoch [74/300], Train Loss: 0.005831
Validation Loss: 0.00557086
Epoch [75/300], Train Loss: 0.005810
Validation Loss: 0.00556983
Epoch [76/300], Train Loss: 0.005794
Validation Loss: 0.00558131
Epoch [77/300], Train Loss: 0.005784
Validation Loss: 0.00558449
Epoch [78/300], Train Loss: 0.005794
Validation Loss: 0.00564152
Epoch [79/300], Train Loss: 0.005787
Validation Loss: 0.00556934
Epoch [80/300], Train Loss: 0.005778
Validation Loss: 0.00554106
Epoch [81/300], Train Loss: 0.005799
Validation Loss: 0.00564388
Epoch [82/300], Train Loss: 0.005804
Validation Loss: 0.00560467
Epoch [83/300], Train Loss: 0.005790
Validation Loss: 0.00551819
Epoch [84/300], Train Loss: 0.005776
Validation Loss: 0.00555450
Epoch [85/300], Train Loss: 0.005782
Validation Loss: 0.00557016
Epoch [86/300], Train Loss: 0.005775
Validation Loss: 0.00558502
Epoch [87/300], Train Loss: 0.005782
Validation Loss: 0.00555096
Epoch [88/300], Train Loss: 0.005757
Validation Loss: 0.00552446
Epoch [89/300], Train Loss: 0.005747
Validation Loss: 0.00555033
Epoch [90/300], Train Loss: 0.005786
Validation Loss: 0.00552325
Epoch [91/300], Train Loss: 0.005757
Validation Loss: 0.00552595
Epoch [92/300], Train Loss: 0.005771
Validation Loss: 0.00551258
Epoch [93/300], Train Loss: 0.005830
Validation Loss: 0.00549875
Epoch [94/300], Train Loss: 0.005768
Validation Loss: 0.00551499
Epoch [95/300], Train Loss: 0.005754
Validation Loss: 0.00551249
Epoch [96/300], Train Loss: 0.005753
Validation Loss: 0.00554878
Epoch [97/300], Train Loss: 0.005739
Validation Loss: 0.00551319
Epoch [98/300], Train Loss: 0.005717
Validation Loss: 0.00549291
Epoch [99/300], Train Loss: 0.005715
Validation Loss: 0.00553774
Epoch [100/300], Train Loss: 0.005738
Validation Loss: 0.00548385
Epoch [101/300], Train Loss: 0.005716
Validation Loss: 0.00556346
Epoch [102/300], Train Loss: 0.005718
Validation Loss: 0.00549699
Epoch [103/300], Train Loss: 0.005707
Validation Loss: 0.00554771
Epoch [104/300], Train Loss: 0.005721
Validation Loss: 0.00548599
Epoch [105/300], Train Loss: 0.005724
Validation Loss: 0.00549674
Epoch [106/300], Train Loss: 0.005704
Validation Loss: 0.00547189
Epoch [107/300], Train Loss: 0.005723
Validation Loss: 0.00548528
Epoch [108/300], Train Loss: 0.005711
Validation Loss: 0.00549905
Epoch [109/300], Train Loss: 0.005697
Validation Loss: 0.00548299
Epoch [110/300], Train Loss: 0.005703
Validation Loss: 0.00550597
Epoch [111/300], Train Loss: 0.005679
Validation Loss: 0.00546614
Epoch [112/300], Train Loss: 0.005702
Validation Loss: 0.00548583
Epoch [113/300], Train Loss: 0.005700
Validation Loss: 0.00546329
Epoch [114/300], Train Loss: 0.005692
Validation Loss: 0.00548972
Epoch [115/300], Train Loss: 0.005680
Validation Loss: 0.00549869
Epoch [116/300], Train Loss: 0.005665
Validation Loss: 0.00547183
Epoch [117/300], Train Loss: 0.005675
Validation Loss: 0.00549657
Epoch [118/300], Train Loss: 0.005691
Validation Loss: 0.00545617
Epoch [119/300], Train Loss: 0.005677
Validation Loss: 0.00547459
Epoch [120/300], Train Loss: 0.005665
Validation Loss: 0.00545028
Epoch [121/300], Train Loss: 0.005668
Validation Loss: 0.00548849
Epoch [122/300], Train Loss: 0.005669
Validation Loss: 0.00548636
Epoch [123/300], Train Loss: 0.005688
Validation Loss: 0.00543001
Epoch [124/300], Train Loss: 0.005682
Validation Loss: 0.00554976
Epoch [125/300], Train Loss: 0.005682
Validation Loss: 0.00550880
Epoch [126/300], Train Loss: 0.005757
Validation Loss: 0.00542201
Epoch [127/300], Train Loss: 0.005675
Validation Loss: 0.00548494
Epoch [128/300], Train Loss: 0.005688
Validation Loss: 0.00544375
Epoch [129/300], Train Loss: 0.005653
Validation Loss: 0.00542579
Epoch [130/300], Train Loss: 0.005686
Validation Loss: 0.00548045
Epoch [131/300], Train Loss: 0.005674
Validation Loss: 0.00544036
Epoch [132/300], Train Loss: 0.005676
Validation Loss: 0.00546090
Epoch [133/300], Train Loss: 0.005649
Validation Loss: 0.00543508
Epoch [134/300], Train Loss: 0.005652
Validation Loss: 0.00542770
Epoch [135/300], Train Loss: 0.005645
Validation Loss: 0.00547312
Epoch [136/300], Train Loss: 0.005643
Validation Loss: 0.00542054
Epoch [137/300], Train Loss: 0.005656
Validation Loss: 0.00548981
Epoch [138/300], Train Loss: 0.005628
Validation Loss: 0.00541288
Epoch [139/300], Train Loss: 0.005656
Validation Loss: 0.00548734
Epoch [140/300], Train Loss: 0.005669
Validation Loss: 0.00540053
Epoch [141/300], Train Loss: 0.005654
Validation Loss: 0.00544725
Epoch [142/300], Train Loss: 0.005633
Validation Loss: 0.00543813
Epoch [143/300], Train Loss: 0.005636
Validation Loss: 0.00540044
Epoch [144/300], Train Loss: 0.005643
Validation Loss: 0.00547642
Epoch [145/300], Train Loss: 0.005621
Validation Loss: 0.00542680
Epoch [146/300], Train Loss: 0.005638
Validation Loss: 0.00541625
Epoch [147/300], Train Loss: 0.005626
Validation Loss: 0.00541728
Epoch [148/300], Train Loss: 0.005624
Validation Loss: 0.00543079
Epoch [149/300], Train Loss: 0.005622
Validation Loss: 0.00542693
Epoch [150/300], Train Loss: 0.005634
Validation Loss: 0.00541581
Epoch [151/300], Train Loss: 0.005611
Validation Loss: 0.00546022
Epoch [152/300], Train Loss: 0.005620
Validation Loss: 0.00539317
Epoch [153/300], Train Loss: 0.005611
Validation Loss: 0.00544826
Epoch [154/300], Train Loss: 0.005624
Validation Loss: 0.00541012
Epoch [155/300], Train Loss: 0.005595
Validation Loss: 0.00540985
Epoch [156/300], Train Loss: 0.005618
Validation Loss: 0.00541432
Epoch [157/300], Train Loss: 0.005620
Validation Loss: 0.00543494
Epoch [158/300], Train Loss: 0.005602
Validation Loss: 0.00539552
Epoch [159/300], Train Loss: 0.005648
Validation Loss: 0.00540040
Epoch [160/300], Train Loss: 0.005605
Validation Loss: 0.00543159
Epoch [161/300], Train Loss: 0.005611
Validation Loss: 0.00541898
Epoch [162/300], Train Loss: 0.005596
Validation Loss: 0.00540970
Early stopping triggered

Evaluating model for: Router
Run 33/72 completed in 454.88 seconds with: {'MAE': np.float32(0.20027633), 'MSE': np.float32(0.069850974), 'RMSE': np.float32(0.26429334), 'SAE': np.float32(0.000316488), 'NDE': np.float32(0.013217191)}

Run 34/72: hidden=256, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Router
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.089387
Validation Loss: 0.07387442
Epoch [2/300], Train Loss: 0.051534
Validation Loss: 0.02496155
Epoch [3/300], Train Loss: 0.011659
Validation Loss: 0.00613025
Epoch [4/300], Train Loss: 0.007377
Validation Loss: 0.00629243
Epoch [5/300], Train Loss: 0.006530
Validation Loss: 0.00606320
Epoch [6/300], Train Loss: 0.006364
Validation Loss: 0.00604806
Epoch [7/300], Train Loss: 0.006306
Validation Loss: 0.00605566
Epoch [8/300], Train Loss: 0.006275
Validation Loss: 0.00607288
Epoch [9/300], Train Loss: 0.006274
Validation Loss: 0.00601236
Epoch [10/300], Train Loss: 0.006257
Validation Loss: 0.00604961
Epoch [11/300], Train Loss: 0.006242
Validation Loss: 0.00600278
Epoch [12/300], Train Loss: 0.006236
Validation Loss: 0.00600882
Epoch [13/300], Train Loss: 0.006242
Validation Loss: 0.00598847
Epoch [14/300], Train Loss: 0.006227
Validation Loss: 0.00598369
Epoch [15/300], Train Loss: 0.006203
Validation Loss: 0.00596738
Epoch [16/300], Train Loss: 0.006210
Validation Loss: 0.00596660
Epoch [17/300], Train Loss: 0.006238
Validation Loss: 0.00594700
Epoch [18/300], Train Loss: 0.006187
Validation Loss: 0.00592953
Epoch [19/300], Train Loss: 0.006193
Validation Loss: 0.00592325
Epoch [20/300], Train Loss: 0.006191
Validation Loss: 0.00591448
Epoch [21/300], Train Loss: 0.006144
Validation Loss: 0.00590604
Epoch [22/300], Train Loss: 0.006135
Validation Loss: 0.00599468
Epoch [23/300], Train Loss: 0.006152
Validation Loss: 0.00586734
Epoch [24/300], Train Loss: 0.006125
Validation Loss: 0.00586710
Epoch [25/300], Train Loss: 0.006098
Validation Loss: 0.00590742
Epoch [26/300], Train Loss: 0.006106
Validation Loss: 0.00586420
Epoch [27/300], Train Loss: 0.006097
Validation Loss: 0.00586149
Epoch [28/300], Train Loss: 0.006039
Validation Loss: 0.00584095
Epoch [29/300], Train Loss: 0.006062
Validation Loss: 0.00583277
Epoch [30/300], Train Loss: 0.006071
Validation Loss: 0.00582893
Epoch [31/300], Train Loss: 0.006045
Validation Loss: 0.00585471
Epoch [32/300], Train Loss: 0.006010
Validation Loss: 0.00578088
Epoch [33/300], Train Loss: 0.006015
Validation Loss: 0.00578671
Epoch [34/300], Train Loss: 0.006013
Validation Loss: 0.00589947
Epoch [35/300], Train Loss: 0.006033
Validation Loss: 0.00579510
Epoch [36/300], Train Loss: 0.005994
Validation Loss: 0.00577183
Epoch [37/300], Train Loss: 0.006054
Validation Loss: 0.00575943
Epoch [38/300], Train Loss: 0.005991
Validation Loss: 0.00573882
Epoch [39/300], Train Loss: 0.005973
Validation Loss: 0.00573789
Epoch [40/300], Train Loss: 0.005987
Validation Loss: 0.00576635
Epoch [41/300], Train Loss: 0.005975
Validation Loss: 0.00573107
Epoch [42/300], Train Loss: 0.005953
Validation Loss: 0.00572818
Epoch [43/300], Train Loss: 0.005951
Validation Loss: 0.00571888
Epoch [44/300], Train Loss: 0.005972
Validation Loss: 0.00569076
Epoch [45/300], Train Loss: 0.005929
Validation Loss: 0.00570816
Epoch [46/300], Train Loss: 0.005906
Validation Loss: 0.00570746
Epoch [47/300], Train Loss: 0.005883
Validation Loss: 0.00571171
Epoch [48/300], Train Loss: 0.005889
Validation Loss: 0.00574479
Epoch [49/300], Train Loss: 0.005870
Validation Loss: 0.00565849
Epoch [50/300], Train Loss: 0.005873
Validation Loss: 0.00565474
Epoch [51/300], Train Loss: 0.005858
Validation Loss: 0.00578468
Epoch [52/300], Train Loss: 0.005879
Validation Loss: 0.00563642
Epoch [53/300], Train Loss: 0.005880
Validation Loss: 0.00565026
Epoch [54/300], Train Loss: 0.005867
Validation Loss: 0.00573314
Epoch [55/300], Train Loss: 0.005890
Validation Loss: 0.00566467
Epoch [56/300], Train Loss: 0.005824
Validation Loss: 0.00560989
Epoch [57/300], Train Loss: 0.005861
Validation Loss: 0.00560788
Epoch [58/300], Train Loss: 0.005874
Validation Loss: 0.00559967
Epoch [59/300], Train Loss: 0.005829
Validation Loss: 0.00565004
Epoch [60/300], Train Loss: 0.005826
Validation Loss: 0.00559013
Epoch [61/300], Train Loss: 0.005812
Validation Loss: 0.00561482
Epoch [62/300], Train Loss: 0.005809
Validation Loss: 0.00562164
Epoch [63/300], Train Loss: 0.005793
Validation Loss: 0.00561616
Epoch [64/300], Train Loss: 0.005783
Validation Loss: 0.00558043
Epoch [65/300], Train Loss: 0.005790
Validation Loss: 0.00556177
Epoch [66/300], Train Loss: 0.005774
Validation Loss: 0.00555384
Epoch [67/300], Train Loss: 0.005818
Validation Loss: 0.00564864
Epoch [68/300], Train Loss: 0.005797
Validation Loss: 0.00557586
Epoch [69/300], Train Loss: 0.005809
Validation Loss: 0.00554880
Epoch [70/300], Train Loss: 0.005781
Validation Loss: 0.00554023
Epoch [71/300], Train Loss: 0.005770
Validation Loss: 0.00563031
Epoch [72/300], Train Loss: 0.005739
Validation Loss: 0.00556243
Epoch [73/300], Train Loss: 0.005760
Validation Loss: 0.00556151
Epoch [74/300], Train Loss: 0.005787
Validation Loss: 0.00554329
Epoch [75/300], Train Loss: 0.005766
Validation Loss: 0.00553426
Epoch [76/300], Train Loss: 0.005740
Validation Loss: 0.00554206
Epoch [77/300], Train Loss: 0.005736
Validation Loss: 0.00554431
Epoch [78/300], Train Loss: 0.005752
Validation Loss: 0.00561369
Epoch [79/300], Train Loss: 0.005731
Validation Loss: 0.00557048
Epoch [80/300], Train Loss: 0.005733
Validation Loss: 0.00550974
Epoch [81/300], Train Loss: 0.005745
Validation Loss: 0.00559592
Epoch [82/300], Train Loss: 0.005746
Validation Loss: 0.00562243
Epoch [83/300], Train Loss: 0.005749
Validation Loss: 0.00548978
Epoch [84/300], Train Loss: 0.005725
Validation Loss: 0.00549982
Epoch [85/300], Train Loss: 0.005731
Validation Loss: 0.00551399
Epoch [86/300], Train Loss: 0.005730
Validation Loss: 0.00557617
Epoch [87/300], Train Loss: 0.005734
Validation Loss: 0.00557622
Epoch [88/300], Train Loss: 0.005710
Validation Loss: 0.00550143
Epoch [89/300], Train Loss: 0.005694
Validation Loss: 0.00551708
Epoch [90/300], Train Loss: 0.005748
Validation Loss: 0.00550090
Epoch [91/300], Train Loss: 0.005712
Validation Loss: 0.00549024
Epoch [92/300], Train Loss: 0.005729
Validation Loss: 0.00548296
Epoch [93/300], Train Loss: 0.005786
Validation Loss: 0.00546441
Epoch [94/300], Train Loss: 0.005727
Validation Loss: 0.00547500
Epoch [95/300], Train Loss: 0.005700
Validation Loss: 0.00547402
Epoch [96/300], Train Loss: 0.005705
Validation Loss: 0.00552607
Epoch [97/300], Train Loss: 0.005685
Validation Loss: 0.00551057
Epoch [98/300], Train Loss: 0.005674
Validation Loss: 0.00546481
Epoch [99/300], Train Loss: 0.005668
Validation Loss: 0.00549368
Epoch [100/300], Train Loss: 0.005689
Validation Loss: 0.00545150
Epoch [101/300], Train Loss: 0.005674
Validation Loss: 0.00552619
Epoch [102/300], Train Loss: 0.005670
Validation Loss: 0.00549282
Epoch [103/300], Train Loss: 0.005665
Validation Loss: 0.00555162
Epoch [104/300], Train Loss: 0.005681
Validation Loss: 0.00547219
Epoch [105/300], Train Loss: 0.005677
Validation Loss: 0.00545470
Epoch [106/300], Train Loss: 0.005660
Validation Loss: 0.00544220
Epoch [107/300], Train Loss: 0.005679
Validation Loss: 0.00545035
Epoch [108/300], Train Loss: 0.005668
Validation Loss: 0.00546042
Epoch [109/300], Train Loss: 0.005654
Validation Loss: 0.00546926
Epoch [110/300], Train Loss: 0.005660
Validation Loss: 0.00550470
Epoch [111/300], Train Loss: 0.005634
Validation Loss: 0.00543992
Epoch [112/300], Train Loss: 0.005656
Validation Loss: 0.00544165
Epoch [113/300], Train Loss: 0.005655
Validation Loss: 0.00542799
Epoch [114/300], Train Loss: 0.005655
Validation Loss: 0.00545256
Epoch [115/300], Train Loss: 0.005632
Validation Loss: 0.00549644
Epoch [116/300], Train Loss: 0.005625
Validation Loss: 0.00545754
Epoch [117/300], Train Loss: 0.005634
Validation Loss: 0.00547802
Epoch [118/300], Train Loss: 0.005651
Validation Loss: 0.00544419
Epoch [119/300], Train Loss: 0.005629
Validation Loss: 0.00543959
Epoch [120/300], Train Loss: 0.005626
Validation Loss: 0.00541832
Epoch [121/300], Train Loss: 0.005625
Validation Loss: 0.00544760
Epoch [122/300], Train Loss: 0.005620
Validation Loss: 0.00549763
Epoch [123/300], Train Loss: 0.005643
Validation Loss: 0.00540724
Epoch [124/300], Train Loss: 0.005636
Validation Loss: 0.00548909
Epoch [125/300], Train Loss: 0.005623
Validation Loss: 0.00557497
Epoch [126/300], Train Loss: 0.005716
Validation Loss: 0.00540161
Epoch [127/300], Train Loss: 0.005627
Validation Loss: 0.00540977
Epoch [128/300], Train Loss: 0.005642
Validation Loss: 0.00544206
Epoch [129/300], Train Loss: 0.005604
Validation Loss: 0.00539725
Epoch [130/300], Train Loss: 0.005643
Validation Loss: 0.00543789
Epoch [131/300], Train Loss: 0.005636
Validation Loss: 0.00542154
Epoch [132/300], Train Loss: 0.005633
Validation Loss: 0.00543413
Epoch [133/300], Train Loss: 0.005604
Validation Loss: 0.00540896
Epoch [134/300], Train Loss: 0.005605
Validation Loss: 0.00539849
Epoch [135/300], Train Loss: 0.005601
Validation Loss: 0.00544715
Epoch [136/300], Train Loss: 0.005594
Validation Loss: 0.00539611
Epoch [137/300], Train Loss: 0.005608
Validation Loss: 0.00546403
Epoch [138/300], Train Loss: 0.005583
Validation Loss: 0.00539070
Epoch [139/300], Train Loss: 0.005610
Validation Loss: 0.00545493
Epoch [140/300], Train Loss: 0.005626
Validation Loss: 0.00537660
Epoch [141/300], Train Loss: 0.005608
Validation Loss: 0.00539448
Epoch [142/300], Train Loss: 0.005596
Validation Loss: 0.00542467
Epoch [143/300], Train Loss: 0.005587
Validation Loss: 0.00537415
Epoch [144/300], Train Loss: 0.005596
Validation Loss: 0.00542839
Epoch [145/300], Train Loss: 0.005577
Validation Loss: 0.00543816
Epoch [146/300], Train Loss: 0.005595
Validation Loss: 0.00538766
Epoch [147/300], Train Loss: 0.005585
Validation Loss: 0.00537541
Epoch [148/300], Train Loss: 0.005589
Validation Loss: 0.00540581
Epoch [149/300], Train Loss: 0.005574
Validation Loss: 0.00541130
Epoch [150/300], Train Loss: 0.005586
Validation Loss: 0.00538307
Epoch [151/300], Train Loss: 0.005568
Validation Loss: 0.00544936
Epoch [152/300], Train Loss: 0.005571
Validation Loss: 0.00537000
Epoch [153/300], Train Loss: 0.005561
Validation Loss: 0.00540413
Epoch [154/300], Train Loss: 0.005580
Validation Loss: 0.00539575
Epoch [155/300], Train Loss: 0.005552
Validation Loss: 0.00538026
Epoch [156/300], Train Loss: 0.005576
Validation Loss: 0.00538547
Epoch [157/300], Train Loss: 0.005574
Validation Loss: 0.00541889
Epoch [158/300], Train Loss: 0.005554
Validation Loss: 0.00536625
Epoch [159/300], Train Loss: 0.005605
Validation Loss: 0.00536577
Epoch [160/300], Train Loss: 0.005567
Validation Loss: 0.00539960
Epoch [161/300], Train Loss: 0.005571
Validation Loss: 0.00541684
Epoch [162/300], Train Loss: 0.005551
Validation Loss: 0.00538991
Epoch [163/300], Train Loss: 0.005557
Validation Loss: 0.00535200
Epoch [164/300], Train Loss: 0.005568
Validation Loss: 0.00548963
Epoch [165/300], Train Loss: 0.005596
Validation Loss: 0.00539375
Epoch [166/300], Train Loss: 0.005612
Validation Loss: 0.00534423
Epoch [167/300], Train Loss: 0.005555
Validation Loss: 0.00540182
Epoch [168/300], Train Loss: 0.005551
Validation Loss: 0.00544025
Epoch [169/300], Train Loss: 0.005566
Validation Loss: 0.00534674
Epoch [170/300], Train Loss: 0.005570
Validation Loss: 0.00535880
Epoch [171/300], Train Loss: 0.005559
Validation Loss: 0.00536517
Epoch [172/300], Train Loss: 0.005559
Validation Loss: 0.00533783
Epoch [173/300], Train Loss: 0.005546
Validation Loss: 0.00543385
Epoch [174/300], Train Loss: 0.005570
Validation Loss: 0.00535070
Epoch [175/300], Train Loss: 0.005546
Validation Loss: 0.00536734
Epoch [176/300], Train Loss: 0.005559
Validation Loss: 0.00535894
Epoch [177/300], Train Loss: 0.005556
Validation Loss: 0.00536558
Epoch [178/300], Train Loss: 0.005547
Validation Loss: 0.00534168
Epoch [179/300], Train Loss: 0.005575
Validation Loss: 0.00543070
Epoch [180/300], Train Loss: 0.005576
Validation Loss: 0.00536736
Epoch [181/300], Train Loss: 0.005530
Validation Loss: 0.00535434
Epoch [182/300], Train Loss: 0.005531
Validation Loss: 0.00537460
Early stopping triggered

Evaluating model for: Router
Run 34/72 completed in 615.99 seconds with: {'MAE': np.float32(0.19874571), 'MSE': np.float32(0.06920776), 'RMSE': np.float32(0.26307368), 'SAE': np.float32(0.00021587781), 'NDE': np.float32(0.013156197)}

Run 35/72: hidden=256, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Router
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.094458
Validation Loss: 0.07649009
Epoch [2/300], Train Loss: 0.048590
Validation Loss: 0.01255650
Epoch [3/300], Train Loss: 0.009897
Validation Loss: 0.00889258
Epoch [4/300], Train Loss: 0.007637
Validation Loss: 0.00650765
Epoch [5/300], Train Loss: 0.006819
Validation Loss: 0.00655116
Epoch [6/300], Train Loss: 0.006538
Validation Loss: 0.00621074
Epoch [7/300], Train Loss: 0.006494
Validation Loss: 0.00623644
Epoch [8/300], Train Loss: 0.006453
Validation Loss: 0.00627993
Epoch [9/300], Train Loss: 0.006450
Validation Loss: 0.00618164
Epoch [10/300], Train Loss: 0.006427
Validation Loss: 0.00622130
Epoch [11/300], Train Loss: 0.006406
Validation Loss: 0.00617877
Epoch [12/300], Train Loss: 0.006392
Validation Loss: 0.00617229
Epoch [13/300], Train Loss: 0.006396
Validation Loss: 0.00615718
Epoch [14/300], Train Loss: 0.006382
Validation Loss: 0.00615001
Epoch [15/300], Train Loss: 0.006367
Validation Loss: 0.00613250
Epoch [16/300], Train Loss: 0.006370
Validation Loss: 0.00612767
Epoch [17/300], Train Loss: 0.006389
Validation Loss: 0.00611174
Epoch [18/300], Train Loss: 0.006337
Validation Loss: 0.00609127
Epoch [19/300], Train Loss: 0.006348
Validation Loss: 0.00608161
Epoch [20/300], Train Loss: 0.006353
Validation Loss: 0.00607195
Epoch [21/300], Train Loss: 0.006302
Validation Loss: 0.00606035
Epoch [22/300], Train Loss: 0.006286
Validation Loss: 0.00615866
Epoch [23/300], Train Loss: 0.006308
Validation Loss: 0.00602559
Epoch [24/300], Train Loss: 0.006271
Validation Loss: 0.00601503
Epoch [25/300], Train Loss: 0.006247
Validation Loss: 0.00605233
Epoch [26/300], Train Loss: 0.006256
Validation Loss: 0.00601993
Epoch [27/300], Train Loss: 0.006238
Validation Loss: 0.00600955
Epoch [28/300], Train Loss: 0.006183
Validation Loss: 0.00597867
Epoch [29/300], Train Loss: 0.006216
Validation Loss: 0.00596994
Epoch [30/300], Train Loss: 0.006214
Validation Loss: 0.00596545
Epoch [31/300], Train Loss: 0.006186
Validation Loss: 0.00599233
Epoch [32/300], Train Loss: 0.006152
Validation Loss: 0.00591785
Epoch [33/300], Train Loss: 0.006154
Validation Loss: 0.00591359
Epoch [34/300], Train Loss: 0.006143
Validation Loss: 0.00601026
Epoch [35/300], Train Loss: 0.006161
Validation Loss: 0.00593881
Epoch [36/300], Train Loss: 0.006124
Validation Loss: 0.00590127
Epoch [37/300], Train Loss: 0.006180
Validation Loss: 0.00587368
Epoch [38/300], Train Loss: 0.006118
Validation Loss: 0.00585397
Epoch [39/300], Train Loss: 0.006104
Validation Loss: 0.00584748
Epoch [40/300], Train Loss: 0.006117
Validation Loss: 0.00587729
Epoch [41/300], Train Loss: 0.006095
Validation Loss: 0.00584851
Epoch [42/300], Train Loss: 0.006066
Validation Loss: 0.00582803
Epoch [43/300], Train Loss: 0.006074
Validation Loss: 0.00580877
Epoch [44/300], Train Loss: 0.006101
Validation Loss: 0.00578340
Epoch [45/300], Train Loss: 0.006046
Validation Loss: 0.00579244
Epoch [46/300], Train Loss: 0.006015
Validation Loss: 0.00581442
Epoch [47/300], Train Loss: 0.005994
Validation Loss: 0.00581720
Epoch [48/300], Train Loss: 0.006002
Validation Loss: 0.00584501
Epoch [49/300], Train Loss: 0.005970
Validation Loss: 0.00574851
Epoch [50/300], Train Loss: 0.005980
Validation Loss: 0.00573388
Epoch [51/300], Train Loss: 0.005961
Validation Loss: 0.00585597
Epoch [52/300], Train Loss: 0.005976
Validation Loss: 0.00572616
Epoch [53/300], Train Loss: 0.005968
Validation Loss: 0.00573140
Epoch [54/300], Train Loss: 0.005961
Validation Loss: 0.00584454
Epoch [55/300], Train Loss: 0.005988
Validation Loss: 0.00576394
Epoch [56/300], Train Loss: 0.005914
Validation Loss: 0.00568555
Epoch [57/300], Train Loss: 0.005949
Validation Loss: 0.00567730
Epoch [58/300], Train Loss: 0.005955
Validation Loss: 0.00565967
Epoch [59/300], Train Loss: 0.005917
Validation Loss: 0.00569951
Epoch [60/300], Train Loss: 0.005915
Validation Loss: 0.00563815
Epoch [61/300], Train Loss: 0.005905
Validation Loss: 0.00564665
Epoch [62/300], Train Loss: 0.005888
Validation Loss: 0.00567063
Epoch [63/300], Train Loss: 0.005877
Validation Loss: 0.00566269
Epoch [64/300], Train Loss: 0.005866
Validation Loss: 0.00563161
Epoch [65/300], Train Loss: 0.005881
Validation Loss: 0.00561174
Epoch [66/300], Train Loss: 0.005875
Validation Loss: 0.00561877
Epoch [67/300], Train Loss: 0.005883
Validation Loss: 0.00563784
Epoch [68/300], Train Loss: 0.005888
Validation Loss: 0.00561294
Epoch [69/300], Train Loss: 0.005890
Validation Loss: 0.00559998
Epoch [70/300], Train Loss: 0.005866
Validation Loss: 0.00559446
Epoch [71/300], Train Loss: 0.005843
Validation Loss: 0.00565205
Epoch [72/300], Train Loss: 0.005819
Validation Loss: 0.00561938
Epoch [73/300], Train Loss: 0.005832
Validation Loss: 0.00564284
Epoch [74/300], Train Loss: 0.005863
Validation Loss: 0.00564525
Epoch [75/300], Train Loss: 0.005857
Validation Loss: 0.00563199
Epoch [76/300], Train Loss: 0.005826
Validation Loss: 0.00561740
Epoch [77/300], Train Loss: 0.005803
Validation Loss: 0.00559454
Epoch [78/300], Train Loss: 0.005820
Validation Loss: 0.00563974
Epoch [79/300], Train Loss: 0.005805
Validation Loss: 0.00563830
Epoch [80/300], Train Loss: 0.005801
Validation Loss: 0.00557465
Epoch [81/300], Train Loss: 0.005818
Validation Loss: 0.00564390
Epoch [82/300], Train Loss: 0.005813
Validation Loss: 0.00572250
Epoch [83/300], Train Loss: 0.005815
Validation Loss: 0.00555244
Epoch [84/300], Train Loss: 0.005794
Validation Loss: 0.00555870
Epoch [85/300], Train Loss: 0.005797
Validation Loss: 0.00554678
Epoch [86/300], Train Loss: 0.005798
Validation Loss: 0.00560120
Epoch [87/300], Train Loss: 0.005790
Validation Loss: 0.00566419
Epoch [88/300], Train Loss: 0.005793
Validation Loss: 0.00558356
Epoch [89/300], Train Loss: 0.005766
Validation Loss: 0.00561795
Epoch [90/300], Train Loss: 0.005821
Validation Loss: 0.00560111
Epoch [91/300], Train Loss: 0.005793
Validation Loss: 0.00555183
Epoch [92/300], Train Loss: 0.005807
Validation Loss: 0.00553330
Epoch [93/300], Train Loss: 0.005859
Validation Loss: 0.00550985
Epoch [94/300], Train Loss: 0.005816
Validation Loss: 0.00551249
Epoch [95/300], Train Loss: 0.005775
Validation Loss: 0.00550637
Epoch [96/300], Train Loss: 0.005769
Validation Loss: 0.00554954
Epoch [97/300], Train Loss: 0.005751
Validation Loss: 0.00557081
Epoch [98/300], Train Loss: 0.005736
Validation Loss: 0.00551958
Epoch [99/300], Train Loss: 0.005725
Validation Loss: 0.00553447
Epoch [100/300], Train Loss: 0.005756
Validation Loss: 0.00549028
Epoch [101/300], Train Loss: 0.005736
Validation Loss: 0.00554548
Epoch [102/300], Train Loss: 0.005734
Validation Loss: 0.00553798
Epoch [103/300], Train Loss: 0.005733
Validation Loss: 0.00562341
Epoch [104/300], Train Loss: 0.005744
Validation Loss: 0.00553675
Epoch [105/300], Train Loss: 0.005742
Validation Loss: 0.00549740
Epoch [106/300], Train Loss: 0.005724
Validation Loss: 0.00548001
Epoch [107/300], Train Loss: 0.005747
Validation Loss: 0.00548329
Epoch [108/300], Train Loss: 0.005727
Validation Loss: 0.00548628
Epoch [109/300], Train Loss: 0.005715
Validation Loss: 0.00550426
Epoch [110/300], Train Loss: 0.005718
Validation Loss: 0.00556518
Epoch [111/300], Train Loss: 0.005700
Validation Loss: 0.00549013
Epoch [112/300], Train Loss: 0.005715
Validation Loss: 0.00547738
Epoch [113/300], Train Loss: 0.005712
Validation Loss: 0.00545727
Epoch [114/300], Train Loss: 0.005716
Validation Loss: 0.00546928
Epoch [115/300], Train Loss: 0.005698
Validation Loss: 0.00553174
Epoch [116/300], Train Loss: 0.005682
Validation Loss: 0.00550659
Epoch [117/300], Train Loss: 0.005689
Validation Loss: 0.00553148
Epoch [118/300], Train Loss: 0.005716
Validation Loss: 0.00549837
Epoch [119/300], Train Loss: 0.005690
Validation Loss: 0.00547302
Epoch [120/300], Train Loss: 0.005687
Validation Loss: 0.00544722
Epoch [121/300], Train Loss: 0.005676
Validation Loss: 0.00546247
Epoch [122/300], Train Loss: 0.005676
Validation Loss: 0.00553686
Epoch [123/300], Train Loss: 0.005696
Validation Loss: 0.00544847
Epoch [124/300], Train Loss: 0.005689
Validation Loss: 0.00550528
Epoch [125/300], Train Loss: 0.005672
Validation Loss: 0.00564463
Epoch [126/300], Train Loss: 0.005770
Validation Loss: 0.00542696
Epoch [127/300], Train Loss: 0.005673
Validation Loss: 0.00542439
Epoch [128/300], Train Loss: 0.005704
Validation Loss: 0.00545336
Epoch [129/300], Train Loss: 0.005658
Validation Loss: 0.00542474
Epoch [130/300], Train Loss: 0.005699
Validation Loss: 0.00545622
Epoch [131/300], Train Loss: 0.005683
Validation Loss: 0.00544387
Epoch [132/300], Train Loss: 0.005688
Validation Loss: 0.00545530
Epoch [133/300], Train Loss: 0.005656
Validation Loss: 0.00543154
Epoch [134/300], Train Loss: 0.005656
Validation Loss: 0.00541915
Epoch [135/300], Train Loss: 0.005652
Validation Loss: 0.00546894
Epoch [136/300], Train Loss: 0.005646
Validation Loss: 0.00541702
Epoch [137/300], Train Loss: 0.005656
Validation Loss: 0.00548263
Epoch [138/300], Train Loss: 0.005634
Validation Loss: 0.00541304
Epoch [139/300], Train Loss: 0.005655
Validation Loss: 0.00546923
Epoch [140/300], Train Loss: 0.005670
Validation Loss: 0.00539534
Epoch [141/300], Train Loss: 0.005652
Validation Loss: 0.00540323
Epoch [142/300], Train Loss: 0.005639
Validation Loss: 0.00543496
Epoch [143/300], Train Loss: 0.005631
Validation Loss: 0.00538933
Epoch [144/300], Train Loss: 0.005644
Validation Loss: 0.00542656
Epoch [145/300], Train Loss: 0.005621
Validation Loss: 0.00546914
Epoch [146/300], Train Loss: 0.005641
Validation Loss: 0.00540912
Epoch [147/300], Train Loss: 0.005622
Validation Loss: 0.00538200
Epoch [148/300], Train Loss: 0.005627
Validation Loss: 0.00539832
Epoch [149/300], Train Loss: 0.005614
Validation Loss: 0.00542607
Epoch [150/300], Train Loss: 0.005632
Validation Loss: 0.00539432
Epoch [151/300], Train Loss: 0.005609
Validation Loss: 0.00546207
Epoch [152/300], Train Loss: 0.005611
Validation Loss: 0.00538115
Epoch [153/300], Train Loss: 0.005597
Validation Loss: 0.00539666
Epoch [154/300], Train Loss: 0.005612
Validation Loss: 0.00539955
Epoch [155/300], Train Loss: 0.005588
Validation Loss: 0.00538228
Epoch [156/300], Train Loss: 0.005615
Validation Loss: 0.00538243
Epoch [157/300], Train Loss: 0.005605
Validation Loss: 0.00541692
Epoch [158/300], Train Loss: 0.005593
Validation Loss: 0.00536181
Epoch [159/300], Train Loss: 0.005631
Validation Loss: 0.00535239
Epoch [160/300], Train Loss: 0.005596
Validation Loss: 0.00536755
Epoch [161/300], Train Loss: 0.005605
Validation Loss: 0.00541258
Epoch [162/300], Train Loss: 0.005579
Validation Loss: 0.00540737
Epoch [163/300], Train Loss: 0.005586
Validation Loss: 0.00533927
Epoch [164/300], Train Loss: 0.005586
Validation Loss: 0.00544303
Epoch [165/300], Train Loss: 0.005597
Validation Loss: 0.00542885
Epoch [166/300], Train Loss: 0.005629
Validation Loss: 0.00531974
Epoch [167/300], Train Loss: 0.005572
Validation Loss: 0.00533504
Epoch [168/300], Train Loss: 0.005555
Validation Loss: 0.00546319
Epoch [169/300], Train Loss: 0.005574
Validation Loss: 0.00533532
Epoch [170/300], Train Loss: 0.005574
Validation Loss: 0.00529714
Epoch [171/300], Train Loss: 0.005569
Validation Loss: 0.00529415
Epoch [172/300], Train Loss: 0.005572
Validation Loss: 0.00529392
Epoch [173/300], Train Loss: 0.005542
Validation Loss: 0.00534233
Epoch [174/300], Train Loss: 0.005563
Validation Loss: 0.00528142
Epoch [175/300], Train Loss: 0.005560
Validation Loss: 0.00529273
Epoch [176/300], Train Loss: 0.005577
Validation Loss: 0.00533152
Epoch [177/300], Train Loss: 0.005545
Validation Loss: 0.00535032
Epoch [178/300], Train Loss: 0.005532
Validation Loss: 0.00529018
Epoch [179/300], Train Loss: 0.005557
Validation Loss: 0.00537683
Epoch [180/300], Train Loss: 0.005551
Validation Loss: 0.00533948
Epoch [181/300], Train Loss: 0.005510
Validation Loss: 0.00526742
Epoch [182/300], Train Loss: 0.005493
Validation Loss: 0.00527704
Epoch [183/300], Train Loss: 0.005612
Validation Loss: 0.00545507
Epoch [184/300], Train Loss: 0.005557
Validation Loss: 0.00532220
Epoch [185/300], Train Loss: 0.005517
Validation Loss: 0.00532820
Epoch [186/300], Train Loss: 0.005532
Validation Loss: 0.00539713
Epoch [187/300], Train Loss: 0.005530
Validation Loss: 0.00529559
Epoch [188/300], Train Loss: 0.005538
Validation Loss: 0.00536554
Epoch [189/300], Train Loss: 0.005537
Validation Loss: 0.00534855
Epoch [190/300], Train Loss: 0.005507
Validation Loss: 0.00530704
Epoch [191/300], Train Loss: 0.005513
Validation Loss: 0.00527617
Early stopping triggered

Evaluating model for: Router
Run 35/72 completed in 721.55 seconds with: {'MAE': np.float32(0.20042412), 'MSE': np.float32(0.06856254), 'RMSE': np.float32(0.2618445), 'SAE': np.float32(0.0008358693), 'NDE': np.float32(0.013094727)}

Run 36/72: hidden=256, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Router
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.060650
Validation Loss: 0.04846561
Epoch [2/300], Train Loss: 0.029891
Validation Loss: 0.00766477
Epoch [3/300], Train Loss: 0.007908
Validation Loss: 0.00766374
Epoch [4/300], Train Loss: 0.006608
Validation Loss: 0.00601883
Epoch [5/300], Train Loss: 0.006206
Validation Loss: 0.00606985
Epoch [6/300], Train Loss: 0.006035
Validation Loss: 0.00584676
Epoch [7/300], Train Loss: 0.006015
Validation Loss: 0.00587017
Epoch [8/300], Train Loss: 0.005981
Validation Loss: 0.00592147
Epoch [9/300], Train Loss: 0.005983
Validation Loss: 0.00582720
Epoch [10/300], Train Loss: 0.005964
Validation Loss: 0.00587263
Epoch [11/300], Train Loss: 0.005957
Validation Loss: 0.00582806
Epoch [12/300], Train Loss: 0.005942
Validation Loss: 0.00582958
Epoch [13/300], Train Loss: 0.005948
Validation Loss: 0.00581680
Epoch [14/300], Train Loss: 0.005938
Validation Loss: 0.00580755
Epoch [15/300], Train Loss: 0.005926
Validation Loss: 0.00579693
Epoch [16/300], Train Loss: 0.005939
Validation Loss: 0.00579111
Epoch [17/300], Train Loss: 0.005962
Validation Loss: 0.00577784
Epoch [18/300], Train Loss: 0.005905
Validation Loss: 0.00576133
Epoch [19/300], Train Loss: 0.005922
Validation Loss: 0.00575174
Epoch [20/300], Train Loss: 0.005929
Validation Loss: 0.00574230
Epoch [21/300], Train Loss: 0.005880
Validation Loss: 0.00573324
Epoch [22/300], Train Loss: 0.005867
Validation Loss: 0.00583932
Epoch [23/300], Train Loss: 0.005893
Validation Loss: 0.00569988
Epoch [24/300], Train Loss: 0.005868
Validation Loss: 0.00568725
Epoch [25/300], Train Loss: 0.005841
Validation Loss: 0.00572424
Epoch [26/300], Train Loss: 0.005851
Validation Loss: 0.00569598
Epoch [27/300], Train Loss: 0.005843
Validation Loss: 0.00568329
Epoch [28/300], Train Loss: 0.005786
Validation Loss: 0.00564426
Epoch [29/300], Train Loss: 0.005806
Validation Loss: 0.00562504
Epoch [30/300], Train Loss: 0.005818
Validation Loss: 0.00561404
Epoch [31/300], Train Loss: 0.005792
Validation Loss: 0.00564944
Epoch [32/300], Train Loss: 0.005752
Validation Loss: 0.00557341
Epoch [33/300], Train Loss: 0.005757
Validation Loss: 0.00556713
Epoch [34/300], Train Loss: 0.005747
Validation Loss: 0.00565677
Epoch [35/300], Train Loss: 0.005772
Validation Loss: 0.00561216
Epoch [36/300], Train Loss: 0.005737
Validation Loss: 0.00558369
Epoch [37/300], Train Loss: 0.005798
Validation Loss: 0.00554411
Epoch [38/300], Train Loss: 0.005738
Validation Loss: 0.00551901
Epoch [39/300], Train Loss: 0.005725
Validation Loss: 0.00551157
Epoch [40/300], Train Loss: 0.005740
Validation Loss: 0.00555141
Epoch [41/300], Train Loss: 0.005728
Validation Loss: 0.00554478
Epoch [42/300], Train Loss: 0.005698
Validation Loss: 0.00550712
Epoch [43/300], Train Loss: 0.005707
Validation Loss: 0.00548444
Epoch [44/300], Train Loss: 0.005750
Validation Loss: 0.00547261
Epoch [45/300], Train Loss: 0.005703
Validation Loss: 0.00547603
Epoch [46/300], Train Loss: 0.005667
Validation Loss: 0.00551051
Epoch [47/300], Train Loss: 0.005645
Validation Loss: 0.00551819
Epoch [48/300], Train Loss: 0.005665
Validation Loss: 0.00554971
Epoch [49/300], Train Loss: 0.005632
Validation Loss: 0.00545637
Epoch [50/300], Train Loss: 0.005635
Validation Loss: 0.00544183
Epoch [51/300], Train Loss: 0.005623
Validation Loss: 0.00556033
Epoch [52/300], Train Loss: 0.005644
Validation Loss: 0.00544343
Epoch [53/300], Train Loss: 0.005644
Validation Loss: 0.00545385
Epoch [54/300], Train Loss: 0.005636
Validation Loss: 0.00556341
Epoch [55/300], Train Loss: 0.005666
Validation Loss: 0.00548418
Epoch [56/300], Train Loss: 0.005600
Validation Loss: 0.00540946
Epoch [57/300], Train Loss: 0.005627
Validation Loss: 0.00540673
Epoch [58/300], Train Loss: 0.005645
Validation Loss: 0.00539481
Epoch [59/300], Train Loss: 0.005605
Validation Loss: 0.00542878
Epoch [60/300], Train Loss: 0.005605
Validation Loss: 0.00537540
Epoch [61/300], Train Loss: 0.005589
Validation Loss: 0.00538303
Epoch [62/300], Train Loss: 0.005585
Validation Loss: 0.00540182
Epoch [63/300], Train Loss: 0.005570
Validation Loss: 0.00538979
Epoch [64/300], Train Loss: 0.005564
Validation Loss: 0.00535482
Epoch [65/300], Train Loss: 0.005576
Validation Loss: 0.00536676
Epoch [66/300], Train Loss: 0.005586
Validation Loss: 0.00538648
Epoch [67/300], Train Loss: 0.005589
Validation Loss: 0.00538919
Epoch [68/300], Train Loss: 0.005592
Validation Loss: 0.00542990
Epoch [69/300], Train Loss: 0.005625
Validation Loss: 0.00541580
Epoch [70/300], Train Loss: 0.005598
Validation Loss: 0.00540910
Epoch [71/300], Train Loss: 0.005578
Validation Loss: 0.00550900
Epoch [72/300], Train Loss: 0.005544
Validation Loss: 0.00541214
Epoch [73/300], Train Loss: 0.005559
Validation Loss: 0.00539857
Epoch [74/300], Train Loss: 0.005581
Validation Loss: 0.00537485
Early stopping triggered

Evaluating model for: Router
Run 36/72 completed in 353.30 seconds with: {'MAE': np.float32(0.20070574), 'MSE': np.float32(0.0695676), 'RMSE': np.float32(0.2637567), 'SAE': np.float32(0.00043191493), 'NDE': np.float32(0.013190355)}

Run 37/72: hidden=256, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Router
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.098339
Validation Loss: 0.08951347
Epoch [2/300], Train Loss: 0.084496
Validation Loss: 0.07564880
Epoch [3/300], Train Loss: 0.070116
Validation Loss: 0.06016914
Epoch [4/300], Train Loss: 0.053326
Validation Loss: 0.04129399
Epoch [5/300], Train Loss: 0.032041
Validation Loss: 0.01691299
Epoch [6/300], Train Loss: 0.010294
Validation Loss: 0.01003677
Epoch [7/300], Train Loss: 0.009923
Validation Loss: 0.00550684
Epoch [8/300], Train Loss: 0.006993
Validation Loss: 0.00690300
Epoch [9/300], Train Loss: 0.007289
Validation Loss: 0.00565821
Epoch [10/300], Train Loss: 0.006383
Validation Loss: 0.00567401
Epoch [11/300], Train Loss: 0.006497
Validation Loss: 0.00543978
Epoch [12/300], Train Loss: 0.006277
Validation Loss: 0.00549221
Epoch [13/300], Train Loss: 0.006308
Validation Loss: 0.00541326
Epoch [14/300], Train Loss: 0.006267
Validation Loss: 0.00541437
Epoch [15/300], Train Loss: 0.006257
Validation Loss: 0.00539170
Epoch [16/300], Train Loss: 0.006238
Validation Loss: 0.00539299
Epoch [17/300], Train Loss: 0.006242
Validation Loss: 0.00538408
Epoch [18/300], Train Loss: 0.006226
Validation Loss: 0.00538006
Epoch [19/300], Train Loss: 0.006237
Validation Loss: 0.00537629
Epoch [20/300], Train Loss: 0.006220
Validation Loss: 0.00537562
Epoch [21/300], Train Loss: 0.006218
Validation Loss: 0.00536860
Epoch [22/300], Train Loss: 0.006206
Validation Loss: 0.00536532
Epoch [23/300], Train Loss: 0.006209
Validation Loss: 0.00536074
Epoch [24/300], Train Loss: 0.006214
Validation Loss: 0.00535678
Epoch [25/300], Train Loss: 0.006194
Validation Loss: 0.00536013
Epoch [26/300], Train Loss: 0.006199
Validation Loss: 0.00534921
Epoch [27/300], Train Loss: 0.006185
Validation Loss: 0.00534532
Epoch [28/300], Train Loss: 0.006211
Validation Loss: 0.00534101
Epoch [29/300], Train Loss: 0.006203
Validation Loss: 0.00533676
Epoch [30/300], Train Loss: 0.006179
Validation Loss: 0.00533861
Epoch [31/300], Train Loss: 0.006188
Validation Loss: 0.00532897
Epoch [32/300], Train Loss: 0.006183
Validation Loss: 0.00532550
Epoch [33/300], Train Loss: 0.006175
Validation Loss: 0.00532244
Epoch [34/300], Train Loss: 0.006159
Validation Loss: 0.00532061
Epoch [35/300], Train Loss: 0.006152
Validation Loss: 0.00531621
Epoch [36/300], Train Loss: 0.006176
Validation Loss: 0.00531192
Epoch [37/300], Train Loss: 0.006169
Validation Loss: 0.00530875
Epoch [38/300], Train Loss: 0.006151
Validation Loss: 0.00530193
Epoch [39/300], Train Loss: 0.006127
Validation Loss: 0.00529681
Epoch [40/300], Train Loss: 0.006153
Validation Loss: 0.00529156
Epoch [41/300], Train Loss: 0.006152
Validation Loss: 0.00528912
Epoch [42/300], Train Loss: 0.006122
Validation Loss: 0.00528204
Epoch [43/300], Train Loss: 0.006140
Validation Loss: 0.00527689
Epoch [44/300], Train Loss: 0.006127
Validation Loss: 0.00527367
Epoch [45/300], Train Loss: 0.006100
Validation Loss: 0.00526868
Epoch [46/300], Train Loss: 0.006117
Validation Loss: 0.00526457
Epoch [47/300], Train Loss: 0.006087
Validation Loss: 0.00526038
Epoch [48/300], Train Loss: 0.006115
Validation Loss: 0.00525568
Epoch [49/300], Train Loss: 0.006112
Validation Loss: 0.00525147
Epoch [50/300], Train Loss: 0.006099
Validation Loss: 0.00524715
Epoch [51/300], Train Loss: 0.006090
Validation Loss: 0.00524312
Epoch [52/300], Train Loss: 0.006088
Validation Loss: 0.00523976
Epoch [53/300], Train Loss: 0.006084
Validation Loss: 0.00523507
Epoch [54/300], Train Loss: 0.006081
Validation Loss: 0.00523135
Epoch [55/300], Train Loss: 0.006073
Validation Loss: 0.00522946
Epoch [56/300], Train Loss: 0.006083
Validation Loss: 0.00522459
Epoch [57/300], Train Loss: 0.006057
Validation Loss: 0.00522199
Epoch [58/300], Train Loss: 0.006060
Validation Loss: 0.00521704
Epoch [59/300], Train Loss: 0.006055
Validation Loss: 0.00521443
Epoch [60/300], Train Loss: 0.006043
Validation Loss: 0.00520805
Epoch [61/300], Train Loss: 0.006028
Validation Loss: 0.00520734
Epoch [62/300], Train Loss: 0.006032
Validation Loss: 0.00520104
Epoch [63/300], Train Loss: 0.006041
Validation Loss: 0.00519743
Epoch [64/300], Train Loss: 0.006020
Validation Loss: 0.00519724
Epoch [65/300], Train Loss: 0.006033
Validation Loss: 0.00519083
Epoch [66/300], Train Loss: 0.006033
Validation Loss: 0.00518774
Epoch [67/300], Train Loss: 0.006022
Validation Loss: 0.00518418
Epoch [68/300], Train Loss: 0.006039
Validation Loss: 0.00518094
Epoch [69/300], Train Loss: 0.006013
Validation Loss: 0.00517878
Epoch [70/300], Train Loss: 0.006026
Validation Loss: 0.00517395
Epoch [71/300], Train Loss: 0.006014
Validation Loss: 0.00517109
Epoch [72/300], Train Loss: 0.005987
Validation Loss: 0.00516845
Epoch [73/300], Train Loss: 0.005990
Validation Loss: 0.00516412
Epoch [74/300], Train Loss: 0.006001
Validation Loss: 0.00516166
Epoch [75/300], Train Loss: 0.005973
Validation Loss: 0.00515974
Epoch [76/300], Train Loss: 0.005983
Validation Loss: 0.00515430
Epoch [77/300], Train Loss: 0.005995
Validation Loss: 0.00515274
Epoch [78/300], Train Loss: 0.005981
Validation Loss: 0.00515799
Epoch [79/300], Train Loss: 0.005986
Validation Loss: 0.00514701
Epoch [80/300], Train Loss: 0.005971
Validation Loss: 0.00514259
Epoch [81/300], Train Loss: 0.005993
Validation Loss: 0.00514235
Epoch [82/300], Train Loss: 0.005971
Validation Loss: 0.00513700
Epoch [83/300], Train Loss: 0.005956
Validation Loss: 0.00513338
Epoch [84/300], Train Loss: 0.005977
Validation Loss: 0.00513038
Epoch [85/300], Train Loss: 0.005958
Validation Loss: 0.00513054
Epoch [86/300], Train Loss: 0.005981
Validation Loss: 0.00512599
Epoch [87/300], Train Loss: 0.005964
Validation Loss: 0.00512242
Epoch [88/300], Train Loss: 0.005952
Validation Loss: 0.00512038
Epoch [89/300], Train Loss: 0.005947
Validation Loss: 0.00511581
Epoch [90/300], Train Loss: 0.005968
Validation Loss: 0.00511720
Epoch [91/300], Train Loss: 0.005959
Validation Loss: 0.00511080
Epoch [92/300], Train Loss: 0.005944
Validation Loss: 0.00510809
Epoch [93/300], Train Loss: 0.005961
Validation Loss: 0.00510500
Epoch [94/300], Train Loss: 0.005941
Validation Loss: 0.00510407
Epoch [95/300], Train Loss: 0.005929
Validation Loss: 0.00510037
Epoch [96/300], Train Loss: 0.005935
Validation Loss: 0.00509988
Epoch [97/300], Train Loss: 0.005932
Validation Loss: 0.00509733
Epoch [98/300], Train Loss: 0.005916
Validation Loss: 0.00509196
Epoch [99/300], Train Loss: 0.005907
Validation Loss: 0.00508986
Epoch [100/300], Train Loss: 0.005902
Validation Loss: 0.00508716
Epoch [101/300], Train Loss: 0.005924
Validation Loss: 0.00508930
Epoch [102/300], Train Loss: 0.005917
Validation Loss: 0.00508208
Epoch [103/300], Train Loss: 0.005900
Validation Loss: 0.00507913
Epoch [104/300], Train Loss: 0.005904
Validation Loss: 0.00507882
Epoch [105/300], Train Loss: 0.005904
Validation Loss: 0.00507400
Epoch [106/300], Train Loss: 0.005920
Validation Loss: 0.00507177
Epoch [107/300], Train Loss: 0.005896
Validation Loss: 0.00507443
Epoch [108/300], Train Loss: 0.005876
Validation Loss: 0.00506783
Epoch [109/300], Train Loss: 0.005896
Validation Loss: 0.00506637
Epoch [110/300], Train Loss: 0.005881
Validation Loss: 0.00506279
Epoch [111/300], Train Loss: 0.005883
Validation Loss: 0.00506439
Epoch [112/300], Train Loss: 0.005884
Validation Loss: 0.00505914
Epoch [113/300], Train Loss: 0.005870
Validation Loss: 0.00505589
Epoch [114/300], Train Loss: 0.005879
Validation Loss: 0.00505365
Epoch [115/300], Train Loss: 0.005890
Validation Loss: 0.00505421
Epoch [116/300], Train Loss: 0.005876
Validation Loss: 0.00504984
Epoch [117/300], Train Loss: 0.005857
Validation Loss: 0.00504709
Epoch [118/300], Train Loss: 0.005861
Validation Loss: 0.00504504
Epoch [119/300], Train Loss: 0.005866
Validation Loss: 0.00504261
Epoch [120/300], Train Loss: 0.005874
Validation Loss: 0.00504116
Epoch [121/300], Train Loss: 0.005862
Validation Loss: 0.00503856
Epoch [122/300], Train Loss: 0.005858
Validation Loss: 0.00503739
Epoch [123/300], Train Loss: 0.005867
Validation Loss: 0.00503453
Epoch [124/300], Train Loss: 0.005865
Validation Loss: 0.00503257
Epoch [125/300], Train Loss: 0.005851
Validation Loss: 0.00503501
Epoch [126/300], Train Loss: 0.005851
Validation Loss: 0.00502875
Epoch [127/300], Train Loss: 0.005850
Validation Loss: 0.00502722
Epoch [128/300], Train Loss: 0.005852
Validation Loss: 0.00502584
Epoch [129/300], Train Loss: 0.005847
Validation Loss: 0.00502309
Epoch [130/300], Train Loss: 0.005840
Validation Loss: 0.00502245
Epoch [131/300], Train Loss: 0.005835
Validation Loss: 0.00502032
Epoch [132/300], Train Loss: 0.005840
Validation Loss: 0.00501776
Epoch [133/300], Train Loss: 0.005851
Validation Loss: 0.00501551
Epoch [134/300], Train Loss: 0.005824
Validation Loss: 0.00501413
Epoch [135/300], Train Loss: 0.005839
Validation Loss: 0.00501233
Epoch [136/300], Train Loss: 0.005832
Validation Loss: 0.00501092
Epoch [137/300], Train Loss: 0.005821
Validation Loss: 0.00501081
Epoch [138/300], Train Loss: 0.005836
Validation Loss: 0.00500722
Epoch [139/300], Train Loss: 0.005832
Validation Loss: 0.00500867
Epoch [140/300], Train Loss: 0.005834
Validation Loss: 0.00500533
Epoch [141/300], Train Loss: 0.005833
Validation Loss: 0.00500328
Epoch [142/300], Train Loss: 0.005819
Validation Loss: 0.00500058
Epoch [143/300], Train Loss: 0.005832
Validation Loss: 0.00500052
Epoch [144/300], Train Loss: 0.005805
Validation Loss: 0.00499725
Epoch [145/300], Train Loss: 0.005815
Validation Loss: 0.00499581
Epoch [146/300], Train Loss: 0.005817
Validation Loss: 0.00499426
Epoch [147/300], Train Loss: 0.005824
Validation Loss: 0.00499403
Epoch [148/300], Train Loss: 0.005810
Validation Loss: 0.00499112
Epoch [149/300], Train Loss: 0.005811
Validation Loss: 0.00498930
Epoch [150/300], Train Loss: 0.005801
Validation Loss: 0.00498845
Epoch [151/300], Train Loss: 0.005803
Validation Loss: 0.00498729
Epoch [152/300], Train Loss: 0.005802
Validation Loss: 0.00498591
Epoch [153/300], Train Loss: 0.005812
Validation Loss: 0.00498425
Epoch [154/300], Train Loss: 0.005793
Validation Loss: 0.00498228
Epoch [155/300], Train Loss: 0.005803
Validation Loss: 0.00498207
Epoch [156/300], Train Loss: 0.005808
Validation Loss: 0.00497991
Epoch [157/300], Train Loss: 0.005795
Validation Loss: 0.00497972
Epoch [158/300], Train Loss: 0.005792
Validation Loss: 0.00497681
Epoch [159/300], Train Loss: 0.005795
Validation Loss: 0.00497618
Epoch [160/300], Train Loss: 0.005812
Validation Loss: 0.00497521
Epoch [161/300], Train Loss: 0.005818
Validation Loss: 0.00497770
Epoch [162/300], Train Loss: 0.005788
Validation Loss: 0.00497151
Epoch [163/300], Train Loss: 0.005786
Validation Loss: 0.00497081
Epoch [164/300], Train Loss: 0.005788
Validation Loss: 0.00496990
Epoch [165/300], Train Loss: 0.005785
Validation Loss: 0.00497144
Epoch [166/300], Train Loss: 0.005774
Validation Loss: 0.00496687
Epoch [167/300], Train Loss: 0.005781
Validation Loss: 0.00496557
Epoch [168/300], Train Loss: 0.005771
Validation Loss: 0.00496414
Epoch [169/300], Train Loss: 0.005792
Validation Loss: 0.00496300
Epoch [170/300], Train Loss: 0.005770
Validation Loss: 0.00496200
Epoch [171/300], Train Loss: 0.005779
Validation Loss: 0.00496227
Epoch [172/300], Train Loss: 0.005774
Validation Loss: 0.00496064
Epoch [173/300], Train Loss: 0.005784
Validation Loss: 0.00495858
Epoch [174/300], Train Loss: 0.005778
Validation Loss: 0.00495726
Epoch [175/300], Train Loss: 0.005771
Validation Loss: 0.00495648
Epoch [176/300], Train Loss: 0.005784
Validation Loss: 0.00495512
Epoch [177/300], Train Loss: 0.005767
Validation Loss: 0.00495608
Epoch [178/300], Train Loss: 0.005755
Validation Loss: 0.00495288
Epoch [179/300], Train Loss: 0.005758
Validation Loss: 0.00495176
Epoch [180/300], Train Loss: 0.005758
Validation Loss: 0.00495177
Epoch [181/300], Train Loss: 0.005764
Validation Loss: 0.00494978
Epoch [182/300], Train Loss: 0.005780
Validation Loss: 0.00494896
Epoch [183/300], Train Loss: 0.005755
Validation Loss: 0.00495022
Epoch [184/300], Train Loss: 0.005751
Validation Loss: 0.00494727
Epoch [185/300], Train Loss: 0.005768
Validation Loss: 0.00494591
Epoch [186/300], Train Loss: 0.005763
Validation Loss: 0.00494607
Epoch [187/300], Train Loss: 0.005752
Validation Loss: 0.00494470
Epoch [188/300], Train Loss: 0.005754
Validation Loss: 0.00494296
Epoch [189/300], Train Loss: 0.005757
Validation Loss: 0.00494257
Epoch [190/300], Train Loss: 0.005786
Validation Loss: 0.00494190
Epoch [191/300], Train Loss: 0.005759
Validation Loss: 0.00494218
Epoch [192/300], Train Loss: 0.005744
Validation Loss: 0.00494161
Epoch [193/300], Train Loss: 0.005733
Validation Loss: 0.00493826
Epoch [194/300], Train Loss: 0.005774
Validation Loss: 0.00493733
Epoch [195/300], Train Loss: 0.005744
Validation Loss: 0.00493645
Epoch [196/300], Train Loss: 0.005737
Validation Loss: 0.00493632
Epoch [197/300], Train Loss: 0.005756
Validation Loss: 0.00493480
Epoch [198/300], Train Loss: 0.005746
Validation Loss: 0.00493548
Epoch [199/300], Train Loss: 0.005739
Validation Loss: 0.00493318
Epoch [200/300], Train Loss: 0.005751
Validation Loss: 0.00493257
Epoch [201/300], Train Loss: 0.005732
Validation Loss: 0.00493248
Epoch [202/300], Train Loss: 0.005731
Validation Loss: 0.00493070
Epoch [203/300], Train Loss: 0.005736
Validation Loss: 0.00493010
Epoch [204/300], Train Loss: 0.005756
Validation Loss: 0.00492901
Epoch [205/300], Train Loss: 0.005743
Validation Loss: 0.00492816
Epoch [206/300], Train Loss: 0.005745
Validation Loss: 0.00492736
Epoch [207/300], Train Loss: 0.005738
Validation Loss: 0.00492654
Epoch [208/300], Train Loss: 0.005727
Validation Loss: 0.00492832
Epoch [209/300], Train Loss: 0.005747
Validation Loss: 0.00492495
Epoch [210/300], Train Loss: 0.005731
Validation Loss: 0.00492415
Epoch [211/300], Train Loss: 0.005722
Validation Loss: 0.00492420
Epoch [212/300], Train Loss: 0.005721
Validation Loss: 0.00492278
Epoch [213/300], Train Loss: 0.005746
Validation Loss: 0.00492205
Epoch [214/300], Train Loss: 0.005724
Validation Loss: 0.00492213
Epoch [215/300], Train Loss: 0.005723
Validation Loss: 0.00492137
Epoch [216/300], Train Loss: 0.005726
Validation Loss: 0.00492026
Epoch [217/300], Train Loss: 0.005708
Validation Loss: 0.00491921
Epoch [218/300], Train Loss: 0.005749
Validation Loss: 0.00491910
Epoch [219/300], Train Loss: 0.005729
Validation Loss: 0.00491794
Epoch [220/300], Train Loss: 0.005725
Validation Loss: 0.00491757
Epoch [221/300], Train Loss: 0.005720
Validation Loss: 0.00491640
Epoch [222/300], Train Loss: 0.005725
Validation Loss: 0.00491570
Epoch [223/300], Train Loss: 0.005722
Validation Loss: 0.00491611
Epoch [224/300], Train Loss: 0.005725
Validation Loss: 0.00491428
Epoch [225/300], Train Loss: 0.005715
Validation Loss: 0.00491359
Epoch [226/300], Train Loss: 0.005735
Validation Loss: 0.00491296
Epoch [227/300], Train Loss: 0.005724
Validation Loss: 0.00491489
Epoch [228/300], Train Loss: 0.005709
Validation Loss: 0.00491225
Epoch [229/300], Train Loss: 0.005710
Validation Loss: 0.00491115
Epoch [230/300], Train Loss: 0.005724
Validation Loss: 0.00491058
Epoch [231/300], Train Loss: 0.005713
Validation Loss: 0.00491046
Epoch [232/300], Train Loss: 0.005728
Validation Loss: 0.00490994
Epoch [233/300], Train Loss: 0.005728
Validation Loss: 0.00491030
Epoch [234/300], Train Loss: 0.005730
Validation Loss: 0.00490821
Epoch [235/300], Train Loss: 0.005717
Validation Loss: 0.00490779
Epoch [236/300], Train Loss: 0.005737
Validation Loss: 0.00490884
Epoch [237/300], Train Loss: 0.005716
Validation Loss: 0.00490624
Epoch [238/300], Train Loss: 0.005708
Validation Loss: 0.00490558
Epoch [239/300], Train Loss: 0.005708
Validation Loss: 0.00490553
Epoch [240/300], Train Loss: 0.005708
Validation Loss: 0.00490431
Epoch [241/300], Train Loss: 0.005710
Validation Loss: 0.00490376
Epoch [242/300], Train Loss: 0.005708
Validation Loss: 0.00490333
Epoch [243/300], Train Loss: 0.005721
Validation Loss: 0.00490356
Epoch [244/300], Train Loss: 0.005697
Validation Loss: 0.00490271
Epoch [245/300], Train Loss: 0.005710
Validation Loss: 0.00490338
Epoch [246/300], Train Loss: 0.005720
Validation Loss: 0.00490103
Epoch [247/300], Train Loss: 0.005717
Validation Loss: 0.00490220
Epoch [248/300], Train Loss: 0.005699
Validation Loss: 0.00490056
Epoch [249/300], Train Loss: 0.005709
Validation Loss: 0.00489993
Epoch [250/300], Train Loss: 0.005712
Validation Loss: 0.00489987
Epoch [251/300], Train Loss: 0.005694
Validation Loss: 0.00489930
Epoch [252/300], Train Loss: 0.005708
Validation Loss: 0.00489793
Epoch [253/300], Train Loss: 0.005718
Validation Loss: 0.00489732
Epoch [254/300], Train Loss: 0.005698
Validation Loss: 0.00489697
Epoch [255/300], Train Loss: 0.005689
Validation Loss: 0.00489844
Epoch [256/300], Train Loss: 0.005702
Validation Loss: 0.00489568
Epoch [257/300], Train Loss: 0.005703
Validation Loss: 0.00489563
Epoch [258/300], Train Loss: 0.005694
Validation Loss: 0.00489471
Epoch [259/300], Train Loss: 0.005706
Validation Loss: 0.00489475
Epoch [260/300], Train Loss: 0.005706
Validation Loss: 0.00489558
Epoch [261/300], Train Loss: 0.005692
Validation Loss: 0.00489327
Epoch [262/300], Train Loss: 0.005693
Validation Loss: 0.00489312
Epoch [263/300], Train Loss: 0.005693
Validation Loss: 0.00489240
Epoch [264/300], Train Loss: 0.005703
Validation Loss: 0.00489291
Epoch [265/300], Train Loss: 0.005696
Validation Loss: 0.00489133
Epoch [266/300], Train Loss: 0.005713
Validation Loss: 0.00489145
Epoch [267/300], Train Loss: 0.005707
Validation Loss: 0.00489043
Epoch [268/300], Train Loss: 0.005706
Validation Loss: 0.00489003
Epoch [269/300], Train Loss: 0.005701
Validation Loss: 0.00489301
Epoch [270/300], Train Loss: 0.005698
Validation Loss: 0.00488980
Epoch [271/300], Train Loss: 0.005720
Validation Loss: 0.00488957
Epoch [272/300], Train Loss: 0.005686
Validation Loss: 0.00488953
Epoch [273/300], Train Loss: 0.005707
Validation Loss: 0.00488764
Epoch [274/300], Train Loss: 0.005693
Validation Loss: 0.00488761
Epoch [275/300], Train Loss: 0.005699
Validation Loss: 0.00488711
Epoch [276/300], Train Loss: 0.005680
Validation Loss: 0.00488644
Epoch [277/300], Train Loss: 0.005691
Validation Loss: 0.00488706
Epoch [278/300], Train Loss: 0.005704
Validation Loss: 0.00488621
Epoch [279/300], Train Loss: 0.005692
Validation Loss: 0.00488602
Epoch [280/300], Train Loss: 0.005716
Validation Loss: 0.00488469
Epoch [281/300], Train Loss: 0.005687
Validation Loss: 0.00488433
Epoch [282/300], Train Loss: 0.005690
Validation Loss: 0.00488379
Epoch [283/300], Train Loss: 0.005687
Validation Loss: 0.00488380
Epoch [284/300], Train Loss: 0.005673
Validation Loss: 0.00488306
Epoch [285/300], Train Loss: 0.005678
Validation Loss: 0.00488286
Epoch [286/300], Train Loss: 0.005703
Validation Loss: 0.00488323
Epoch [287/300], Train Loss: 0.005693
Validation Loss: 0.00488175
Epoch [288/300], Train Loss: 0.005671
Validation Loss: 0.00488213
Epoch [289/300], Train Loss: 0.005674
Validation Loss: 0.00488104
Epoch [290/300], Train Loss: 0.005671
Validation Loss: 0.00488066
Epoch [291/300], Train Loss: 0.005681
Validation Loss: 0.00488027
Epoch [292/300], Train Loss: 0.005676
Validation Loss: 0.00488034
Epoch [293/300], Train Loss: 0.005685
Validation Loss: 0.00487957
Epoch [294/300], Train Loss: 0.005683
Validation Loss: 0.00487922
Epoch [295/300], Train Loss: 0.005679
Validation Loss: 0.00487875
Epoch [296/300], Train Loss: 0.005694
Validation Loss: 0.00487882
Epoch [297/300], Train Loss: 0.005677
Validation Loss: 0.00487794
Epoch [298/300], Train Loss: 0.005703
Validation Loss: 0.00487777
Epoch [299/300], Train Loss: 0.005681
Validation Loss: 0.00487756
Epoch [300/300], Train Loss: 0.005686
Validation Loss: 0.00487678

Evaluating model for: Router
Run 37/72 completed in 435.25 seconds with: {'MAE': np.float32(0.21148422), 'MSE': np.float32(0.07685243), 'RMSE': np.float32(0.27722272), 'SAE': np.float32(0.0007800151), 'NDE': np.float32(0.013865943)}

Run 38/72: hidden=256, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Router
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.112459
Validation Loss: 0.10229670
Epoch [2/300], Train Loss: 0.096356
Validation Loss: 0.08600455
Epoch [3/300], Train Loss: 0.078926
Validation Loss: 0.06670305
Epoch [4/300], Train Loss: 0.057220
Validation Loss: 0.04051108
Epoch [5/300], Train Loss: 0.026109
Validation Loss: 0.00648407
Epoch [6/300], Train Loss: 0.011473
Validation Loss: 0.00739267
Epoch [7/300], Train Loss: 0.007523
Validation Loss: 0.00784430
Epoch [8/300], Train Loss: 0.008357
Validation Loss: 0.00620335
Epoch [9/300], Train Loss: 0.006706
Validation Loss: 0.00613026
Epoch [10/300], Train Loss: 0.006933
Validation Loss: 0.00565278
Epoch [11/300], Train Loss: 0.006588
Validation Loss: 0.00578823
Epoch [12/300], Train Loss: 0.006597
Validation Loss: 0.00562465
Epoch [13/300], Train Loss: 0.006536
Validation Loss: 0.00564515
Epoch [14/300], Train Loss: 0.006523
Validation Loss: 0.00561558
Epoch [15/300], Train Loss: 0.006531
Validation Loss: 0.00561978
Epoch [16/300], Train Loss: 0.006501
Validation Loss: 0.00560584
Epoch [17/300], Train Loss: 0.006512
Validation Loss: 0.00559848
Epoch [18/300], Train Loss: 0.006492
Validation Loss: 0.00559838
Epoch [19/300], Train Loss: 0.006504
Validation Loss: 0.00558926
Epoch [20/300], Train Loss: 0.006480
Validation Loss: 0.00558475
Epoch [21/300], Train Loss: 0.006469
Validation Loss: 0.00557922
Epoch [22/300], Train Loss: 0.006455
Validation Loss: 0.00557511
Epoch [23/300], Train Loss: 0.006464
Validation Loss: 0.00556924
Epoch [24/300], Train Loss: 0.006474
Validation Loss: 0.00556362
Epoch [25/300], Train Loss: 0.006443
Validation Loss: 0.00556829
Epoch [26/300], Train Loss: 0.006438
Validation Loss: 0.00555363
Epoch [27/300], Train Loss: 0.006446
Validation Loss: 0.00554811
Epoch [28/300], Train Loss: 0.006455
Validation Loss: 0.00554351
Epoch [29/300], Train Loss: 0.006451
Validation Loss: 0.00553731
Epoch [30/300], Train Loss: 0.006426
Validation Loss: 0.00553941
Epoch [31/300], Train Loss: 0.006433
Validation Loss: 0.00552806
Epoch [32/300], Train Loss: 0.006424
Validation Loss: 0.00552223
Epoch [33/300], Train Loss: 0.006425
Validation Loss: 0.00551913
Epoch [34/300], Train Loss: 0.006403
Validation Loss: 0.00551397
Epoch [35/300], Train Loss: 0.006402
Validation Loss: 0.00551108
Epoch [36/300], Train Loss: 0.006414
Validation Loss: 0.00550884
Epoch [37/300], Train Loss: 0.006412
Validation Loss: 0.00549788
Epoch [38/300], Train Loss: 0.006380
Validation Loss: 0.00549478
Epoch [39/300], Train Loss: 0.006364
Validation Loss: 0.00548740
Epoch [40/300], Train Loss: 0.006393
Validation Loss: 0.00548259
Epoch [41/300], Train Loss: 0.006383
Validation Loss: 0.00547843
Epoch [42/300], Train Loss: 0.006361
Validation Loss: 0.00547268
Epoch [43/300], Train Loss: 0.006374
Validation Loss: 0.00546741
Epoch [44/300], Train Loss: 0.006373
Validation Loss: 0.00546267
Epoch [45/300], Train Loss: 0.006343
Validation Loss: 0.00545748
Epoch [46/300], Train Loss: 0.006358
Validation Loss: 0.00545332
Epoch [47/300], Train Loss: 0.006325
Validation Loss: 0.00544992
Epoch [48/300], Train Loss: 0.006347
Validation Loss: 0.00544293
Epoch [49/300], Train Loss: 0.006347
Validation Loss: 0.00543868
Epoch [50/300], Train Loss: 0.006331
Validation Loss: 0.00543360
Epoch [51/300], Train Loss: 0.006319
Validation Loss: 0.00542891
Epoch [52/300], Train Loss: 0.006326
Validation Loss: 0.00542538
Epoch [53/300], Train Loss: 0.006318
Validation Loss: 0.00541939
Epoch [54/300], Train Loss: 0.006312
Validation Loss: 0.00541523
Epoch [55/300], Train Loss: 0.006305
Validation Loss: 0.00541156
Epoch [56/300], Train Loss: 0.006315
Validation Loss: 0.00540785
Epoch [57/300], Train Loss: 0.006286
Validation Loss: 0.00540698
Epoch [58/300], Train Loss: 0.006289
Validation Loss: 0.00539554
Epoch [59/300], Train Loss: 0.006289
Validation Loss: 0.00539321
Epoch [60/300], Train Loss: 0.006265
Validation Loss: 0.00538828
Epoch [61/300], Train Loss: 0.006258
Validation Loss: 0.00538240
Epoch [62/300], Train Loss: 0.006261
Validation Loss: 0.00537773
Epoch [63/300], Train Loss: 0.006259
Validation Loss: 0.00537441
Epoch [64/300], Train Loss: 0.006249
Validation Loss: 0.00537039
Epoch [65/300], Train Loss: 0.006255
Validation Loss: 0.00536504
Epoch [66/300], Train Loss: 0.006259
Validation Loss: 0.00536117
Epoch [67/300], Train Loss: 0.006237
Validation Loss: 0.00535662
Epoch [68/300], Train Loss: 0.006256
Validation Loss: 0.00535107
Epoch [69/300], Train Loss: 0.006232
Validation Loss: 0.00534959
Epoch [70/300], Train Loss: 0.006245
Validation Loss: 0.00534235
Epoch [71/300], Train Loss: 0.006229
Validation Loss: 0.00533829
Epoch [72/300], Train Loss: 0.006190
Validation Loss: 0.00533465
Epoch [73/300], Train Loss: 0.006205
Validation Loss: 0.00532867
Epoch [74/300], Train Loss: 0.006220
Validation Loss: 0.00532442
Epoch [75/300], Train Loss: 0.006191
Validation Loss: 0.00532275
Epoch [76/300], Train Loss: 0.006185
Validation Loss: 0.00531717
Epoch [77/300], Train Loss: 0.006205
Validation Loss: 0.00531170
Epoch [78/300], Train Loss: 0.006203
Validation Loss: 0.00531736
Epoch [79/300], Train Loss: 0.006200
Validation Loss: 0.00531012
Epoch [80/300], Train Loss: 0.006166
Validation Loss: 0.00530743
Epoch [81/300], Train Loss: 0.006205
Validation Loss: 0.00529656
Epoch [82/300], Train Loss: 0.006174
Validation Loss: 0.00529220
Epoch [83/300], Train Loss: 0.006159
Validation Loss: 0.00528835
Epoch [84/300], Train Loss: 0.006187
Validation Loss: 0.00528408
Epoch [85/300], Train Loss: 0.006160
Validation Loss: 0.00528223
Epoch [86/300], Train Loss: 0.006182
Validation Loss: 0.00527918
Epoch [87/300], Train Loss: 0.006160
Validation Loss: 0.00527858
Epoch [88/300], Train Loss: 0.006151
Validation Loss: 0.00526835
Epoch [89/300], Train Loss: 0.006141
Validation Loss: 0.00526451
Epoch [90/300], Train Loss: 0.006173
Validation Loss: 0.00526797
Epoch [91/300], Train Loss: 0.006145
Validation Loss: 0.00526252
Epoch [92/300], Train Loss: 0.006141
Validation Loss: 0.00525868
Epoch [93/300], Train Loss: 0.006153
Validation Loss: 0.00525058
Epoch [94/300], Train Loss: 0.006137
Validation Loss: 0.00524936
Epoch [95/300], Train Loss: 0.006121
Validation Loss: 0.00524343
Epoch [96/300], Train Loss: 0.006122
Validation Loss: 0.00524290
Epoch [97/300], Train Loss: 0.006131
Validation Loss: 0.00524640
Epoch [98/300], Train Loss: 0.006105
Validation Loss: 0.00523584
Epoch [99/300], Train Loss: 0.006095
Validation Loss: 0.00523331
Epoch [100/300], Train Loss: 0.006094
Validation Loss: 0.00522737
Epoch [101/300], Train Loss: 0.006108
Validation Loss: 0.00523094
Epoch [102/300], Train Loss: 0.006105
Validation Loss: 0.00522451
Epoch [103/300], Train Loss: 0.006091
Validation Loss: 0.00521899
Epoch [104/300], Train Loss: 0.006093
Validation Loss: 0.00521375
Epoch [105/300], Train Loss: 0.006085
Validation Loss: 0.00521044
Epoch [106/300], Train Loss: 0.006087
Validation Loss: 0.00520883
Epoch [107/300], Train Loss: 0.006083
Validation Loss: 0.00520676
Epoch [108/300], Train Loss: 0.006058
Validation Loss: 0.00520231
Epoch [109/300], Train Loss: 0.006073
Validation Loss: 0.00519929
Epoch [110/300], Train Loss: 0.006062
Validation Loss: 0.00519680
Epoch [111/300], Train Loss: 0.006059
Validation Loss: 0.00519459
Epoch [112/300], Train Loss: 0.006061
Validation Loss: 0.00519311
Epoch [113/300], Train Loss: 0.006049
Validation Loss: 0.00518992
Epoch [114/300], Train Loss: 0.006057
Validation Loss: 0.00518645
Epoch [115/300], Train Loss: 0.006060
Validation Loss: 0.00518765
Epoch [116/300], Train Loss: 0.006051
Validation Loss: 0.00518451
Epoch [117/300], Train Loss: 0.006026
Validation Loss: 0.00518048
Epoch [118/300], Train Loss: 0.006047
Validation Loss: 0.00517524
Epoch [119/300], Train Loss: 0.006036
Validation Loss: 0.00517277
Epoch [120/300], Train Loss: 0.006033
Validation Loss: 0.00517084
Epoch [121/300], Train Loss: 0.006040
Validation Loss: 0.00516849
Epoch [122/300], Train Loss: 0.006026
Validation Loss: 0.00516879
Epoch [123/300], Train Loss: 0.006034
Validation Loss: 0.00516433
Epoch [124/300], Train Loss: 0.006032
Validation Loss: 0.00516154
Epoch [125/300], Train Loss: 0.006026
Validation Loss: 0.00516233
Epoch [126/300], Train Loss: 0.006015
Validation Loss: 0.00515823
Epoch [127/300], Train Loss: 0.006017
Validation Loss: 0.00515561
Epoch [128/300], Train Loss: 0.006021
Validation Loss: 0.00515251
Epoch [129/300], Train Loss: 0.006019
Validation Loss: 0.00515040
Epoch [130/300], Train Loss: 0.006010
Validation Loss: 0.00515058
Epoch [131/300], Train Loss: 0.006006
Validation Loss: 0.00515059
Epoch [132/300], Train Loss: 0.006008
Validation Loss: 0.00514892
Epoch [133/300], Train Loss: 0.006023
Validation Loss: 0.00514375
Epoch [134/300], Train Loss: 0.005980
Validation Loss: 0.00514189
Epoch [135/300], Train Loss: 0.006012
Validation Loss: 0.00513825
Epoch [136/300], Train Loss: 0.006003
Validation Loss: 0.00513813
Epoch [137/300], Train Loss: 0.005978
Validation Loss: 0.00514067
Epoch [138/300], Train Loss: 0.006011
Validation Loss: 0.00513772
Epoch [139/300], Train Loss: 0.006011
Validation Loss: 0.00514029
Epoch [140/300], Train Loss: 0.005997
Validation Loss: 0.00513890
Epoch [141/300], Train Loss: 0.005994
Validation Loss: 0.00513731
Epoch [142/300], Train Loss: 0.005994
Validation Loss: 0.00512604
Epoch [143/300], Train Loss: 0.005993
Validation Loss: 0.00512678
Epoch [144/300], Train Loss: 0.005979
Validation Loss: 0.00512405
Epoch [145/300], Train Loss: 0.005981
Validation Loss: 0.00512079
Epoch [146/300], Train Loss: 0.005979
Validation Loss: 0.00512084
Epoch [147/300], Train Loss: 0.005979
Validation Loss: 0.00511768
Epoch [148/300], Train Loss: 0.005978
Validation Loss: 0.00511654
Epoch [149/300], Train Loss: 0.005971
Validation Loss: 0.00511434
Epoch [150/300], Train Loss: 0.005962
Validation Loss: 0.00511260
Epoch [151/300], Train Loss: 0.005968
Validation Loss: 0.00511219
Epoch [152/300], Train Loss: 0.005962
Validation Loss: 0.00511487
Epoch [153/300], Train Loss: 0.005966
Validation Loss: 0.00510838
Epoch [154/300], Train Loss: 0.005961
Validation Loss: 0.00510659
Epoch [155/300], Train Loss: 0.005971
Validation Loss: 0.00510772
Epoch [156/300], Train Loss: 0.005972
Validation Loss: 0.00510726
Epoch [157/300], Train Loss: 0.005957
Validation Loss: 0.00510919
Epoch [158/300], Train Loss: 0.005954
Validation Loss: 0.00510164
Epoch [159/300], Train Loss: 0.005962
Validation Loss: 0.00510076
Epoch [160/300], Train Loss: 0.005970
Validation Loss: 0.00509903
Epoch [161/300], Train Loss: 0.005976
Validation Loss: 0.00510552
Epoch [162/300], Train Loss: 0.005951
Validation Loss: 0.00509717
Epoch [163/300], Train Loss: 0.005939
Validation Loss: 0.00509417
Epoch [164/300], Train Loss: 0.005957
Validation Loss: 0.00509417
Epoch [165/300], Train Loss: 0.005933
Validation Loss: 0.00509165
Epoch [166/300], Train Loss: 0.005941
Validation Loss: 0.00509026
Epoch [167/300], Train Loss: 0.005942
Validation Loss: 0.00508870
Epoch [168/300], Train Loss: 0.005936
Validation Loss: 0.00508798
Epoch [169/300], Train Loss: 0.005952
Validation Loss: 0.00508626
Epoch [170/300], Train Loss: 0.005930
Validation Loss: 0.00508529
Epoch [171/300], Train Loss: 0.005941
Validation Loss: 0.00508610
Epoch [172/300], Train Loss: 0.005932
Validation Loss: 0.00508596
Epoch [173/300], Train Loss: 0.005945
Validation Loss: 0.00508172
Epoch [174/300], Train Loss: 0.005935
Validation Loss: 0.00508075
Epoch [175/300], Train Loss: 0.005928
Validation Loss: 0.00507973
Epoch [176/300], Train Loss: 0.005947
Validation Loss: 0.00507790
Epoch [177/300], Train Loss: 0.005929
Validation Loss: 0.00508058
Epoch [178/300], Train Loss: 0.005913
Validation Loss: 0.00507553
Epoch [179/300], Train Loss: 0.005904
Validation Loss: 0.00507445
Epoch [180/300], Train Loss: 0.005921
Validation Loss: 0.00507493
Epoch [181/300], Train Loss: 0.005921
Validation Loss: 0.00507207
Epoch [182/300], Train Loss: 0.005932
Validation Loss: 0.00507104
Epoch [183/300], Train Loss: 0.005917
Validation Loss: 0.00507492
Epoch [184/300], Train Loss: 0.005910
Validation Loss: 0.00506889
Epoch [185/300], Train Loss: 0.005920
Validation Loss: 0.00506785
Epoch [186/300], Train Loss: 0.005926
Validation Loss: 0.00506864
Epoch [187/300], Train Loss: 0.005913
Validation Loss: 0.00506938
Epoch [188/300], Train Loss: 0.005913
Validation Loss: 0.00506582
Epoch [189/300], Train Loss: 0.005911
Validation Loss: 0.00506375
Epoch [190/300], Train Loss: 0.005941
Validation Loss: 0.00506443
Epoch [191/300], Train Loss: 0.005915
Validation Loss: 0.00507149
Epoch [192/300], Train Loss: 0.005906
Validation Loss: 0.00506108
Epoch [193/300], Train Loss: 0.005894
Validation Loss: 0.00505973
Epoch [194/300], Train Loss: 0.005928
Validation Loss: 0.00505901
Epoch [195/300], Train Loss: 0.005904
Validation Loss: 0.00505743
Epoch [196/300], Train Loss: 0.005889
Validation Loss: 0.00505678
Epoch [197/300], Train Loss: 0.005900
Validation Loss: 0.00505552
Epoch [198/300], Train Loss: 0.005900
Validation Loss: 0.00505917
Epoch [199/300], Train Loss: 0.005893
Validation Loss: 0.00505397
Epoch [200/300], Train Loss: 0.005910
Validation Loss: 0.00505295
Epoch [201/300], Train Loss: 0.005879
Validation Loss: 0.00505261
Epoch [202/300], Train Loss: 0.005877
Validation Loss: 0.00505172
Epoch [203/300], Train Loss: 0.005887
Validation Loss: 0.00504992
Epoch [204/300], Train Loss: 0.005905
Validation Loss: 0.00504900
Epoch [205/300], Train Loss: 0.005891
Validation Loss: 0.00504839
Epoch [206/300], Train Loss: 0.005902
Validation Loss: 0.00504718
Epoch [207/300], Train Loss: 0.005896
Validation Loss: 0.00504625
Epoch [208/300], Train Loss: 0.005882
Validation Loss: 0.00504942
Epoch [209/300], Train Loss: 0.005905
Validation Loss: 0.00504484
Epoch [210/300], Train Loss: 0.005876
Validation Loss: 0.00504410
Epoch [211/300], Train Loss: 0.005876
Validation Loss: 0.00504454
Epoch [212/300], Train Loss: 0.005865
Validation Loss: 0.00504220
Epoch [213/300], Train Loss: 0.005893
Validation Loss: 0.00504127
Epoch [214/300], Train Loss: 0.005883
Validation Loss: 0.00504198
Epoch [215/300], Train Loss: 0.005881
Validation Loss: 0.00503958
Epoch [216/300], Train Loss: 0.005885
Validation Loss: 0.00503921
Epoch [217/300], Train Loss: 0.005857
Validation Loss: 0.00503862
Epoch [218/300], Train Loss: 0.005904
Validation Loss: 0.00503729
Epoch [219/300], Train Loss: 0.005880
Validation Loss: 0.00503617
Epoch [220/300], Train Loss: 0.005881
Validation Loss: 0.00503633
Epoch [221/300], Train Loss: 0.005867
Validation Loss: 0.00503466
Epoch [222/300], Train Loss: 0.005874
Validation Loss: 0.00503376
Epoch [223/300], Train Loss: 0.005866
Validation Loss: 0.00503455
Epoch [224/300], Train Loss: 0.005887
Validation Loss: 0.00503234
Epoch [225/300], Train Loss: 0.005872
Validation Loss: 0.00503138
Epoch [226/300], Train Loss: 0.005877
Validation Loss: 0.00503067
Epoch [227/300], Train Loss: 0.005866
Validation Loss: 0.00503263
Epoch [228/300], Train Loss: 0.005863
Validation Loss: 0.00502910
Epoch [229/300], Train Loss: 0.005860
Validation Loss: 0.00502843
Epoch [230/300], Train Loss: 0.005860
Validation Loss: 0.00502770
Epoch [231/300], Train Loss: 0.005861
Validation Loss: 0.00502781
Epoch [232/300], Train Loss: 0.005872
Validation Loss: 0.00502620
Epoch [233/300], Train Loss: 0.005879
Validation Loss: 0.00502870
Epoch [234/300], Train Loss: 0.005876
Validation Loss: 0.00502766
Epoch [235/300], Train Loss: 0.005875
Validation Loss: 0.00502406
Epoch [236/300], Train Loss: 0.005882
Validation Loss: 0.00502442
Epoch [237/300], Train Loss: 0.005873
Validation Loss: 0.00502278
Epoch [238/300], Train Loss: 0.005851
Validation Loss: 0.00502193
Epoch [239/300], Train Loss: 0.005856
Validation Loss: 0.00502185
Epoch [240/300], Train Loss: 0.005858
Validation Loss: 0.00502052
Epoch [241/300], Train Loss: 0.005856
Validation Loss: 0.00501972
Epoch [242/300], Train Loss: 0.005855
Validation Loss: 0.00501966
Epoch [243/300], Train Loss: 0.005861
Validation Loss: 0.00501863
Epoch [244/300], Train Loss: 0.005849
Validation Loss: 0.00501771
Epoch [245/300], Train Loss: 0.005861
Validation Loss: 0.00501904
Epoch [246/300], Train Loss: 0.005858
Validation Loss: 0.00501741
Epoch [247/300], Train Loss: 0.005863
Validation Loss: 0.00501770
Epoch [248/300], Train Loss: 0.005843
Validation Loss: 0.00501505
Epoch [249/300], Train Loss: 0.005857
Validation Loss: 0.00501540
Epoch [250/300], Train Loss: 0.005856
Validation Loss: 0.00501473
Epoch [251/300], Train Loss: 0.005841
Validation Loss: 0.00501627
Epoch [252/300], Train Loss: 0.005852
Validation Loss: 0.00501242
Epoch [253/300], Train Loss: 0.005870
Validation Loss: 0.00501202
Epoch [254/300], Train Loss: 0.005843
Validation Loss: 0.00501259
Epoch [255/300], Train Loss: 0.005843
Validation Loss: 0.00501311
Epoch [256/300], Train Loss: 0.005839
Validation Loss: 0.00501021
Epoch [257/300], Train Loss: 0.005845
Validation Loss: 0.00500945
Epoch [258/300], Train Loss: 0.005840
Validation Loss: 0.00500897
Epoch [259/300], Train Loss: 0.005851
Validation Loss: 0.00500888
Epoch [260/300], Train Loss: 0.005855
Validation Loss: 0.00500878
Epoch [261/300], Train Loss: 0.005834
Validation Loss: 0.00500711
Epoch [262/300], Train Loss: 0.005834
Validation Loss: 0.00500629
Epoch [263/300], Train Loss: 0.005832
Validation Loss: 0.00500650
Epoch [264/300], Train Loss: 0.005844
Validation Loss: 0.00500574
Epoch [265/300], Train Loss: 0.005846
Validation Loss: 0.00500490
Epoch [266/300], Train Loss: 0.005856
Validation Loss: 0.00500677
Epoch [267/300], Train Loss: 0.005852
Validation Loss: 0.00500362
Epoch [268/300], Train Loss: 0.005850
Validation Loss: 0.00500298
Epoch [269/300], Train Loss: 0.005844
Validation Loss: 0.00501040
Epoch [270/300], Train Loss: 0.005841
Validation Loss: 0.00500175
Epoch [271/300], Train Loss: 0.005861
Validation Loss: 0.00500349
Epoch [272/300], Train Loss: 0.005832
Validation Loss: 0.00500669
Epoch [273/300], Train Loss: 0.005849
Validation Loss: 0.00500007
Epoch [274/300], Train Loss: 0.005832
Validation Loss: 0.00499961
Epoch [275/300], Train Loss: 0.005843
Validation Loss: 0.00499965
Epoch [276/300], Train Loss: 0.005825
Validation Loss: 0.00499864
Epoch [277/300], Train Loss: 0.005835
Validation Loss: 0.00499971
Epoch [278/300], Train Loss: 0.005845
Validation Loss: 0.00500037
Epoch [279/300], Train Loss: 0.005834
Validation Loss: 0.00499788
Epoch [280/300], Train Loss: 0.005857
Validation Loss: 0.00499710
Epoch [281/300], Train Loss: 0.005833
Validation Loss: 0.00499630
Epoch [282/300], Train Loss: 0.005835
Validation Loss: 0.00499522
Epoch [283/300], Train Loss: 0.005835
Validation Loss: 0.00499536
Epoch [284/300], Train Loss: 0.005816
Validation Loss: 0.00499408
Epoch [285/300], Train Loss: 0.005826
Validation Loss: 0.00499404
Epoch [286/300], Train Loss: 0.005834
Validation Loss: 0.00499473
Epoch [287/300], Train Loss: 0.005833
Validation Loss: 0.00499308
Epoch [288/300], Train Loss: 0.005812
Validation Loss: 0.00499354
Epoch [289/300], Train Loss: 0.005812
Validation Loss: 0.00499160
Epoch [290/300], Train Loss: 0.005806
Validation Loss: 0.00499114
Epoch [291/300], Train Loss: 0.005822
Validation Loss: 0.00499071
Epoch [292/300], Train Loss: 0.005820
Validation Loss: 0.00499145
Epoch [293/300], Train Loss: 0.005830
Validation Loss: 0.00498966
Epoch [294/300], Train Loss: 0.005812
Validation Loss: 0.00498946
Epoch [295/300], Train Loss: 0.005811
Validation Loss: 0.00498940
Epoch [296/300], Train Loss: 0.005829
Validation Loss: 0.00498909
Epoch [297/300], Train Loss: 0.005822
Validation Loss: 0.00498775
Epoch [298/300], Train Loss: 0.005841
Validation Loss: 0.00498738
Epoch [299/300], Train Loss: 0.005827
Validation Loss: 0.00498863
Epoch [300/300], Train Loss: 0.005821
Validation Loss: 0.00498621

Evaluating model for: Router
Run 38/72 completed in 503.33 seconds with: {'MAE': np.float32(0.212633), 'MSE': np.float32(0.07825109), 'RMSE': np.float32(0.27973396), 'SAE': np.float32(0.0007568041), 'NDE': np.float32(0.013991549)}

Run 39/72: hidden=256, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Router
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.069276
Validation Loss: 0.06054189
Epoch [2/300], Train Loss: 0.055306
Validation Loss: 0.04608381
Epoch [3/300], Train Loss: 0.039946
Validation Loss: 0.02886654
Epoch [4/300], Train Loss: 0.020273
Validation Loss: 0.00698026
Epoch [5/300], Train Loss: 0.008915
Validation Loss: 0.00750494
Epoch [6/300], Train Loss: 0.006794
Validation Loss: 0.00634344
Epoch [7/300], Train Loss: 0.007210
Validation Loss: 0.00577713
Epoch [8/300], Train Loss: 0.006157
Validation Loss: 0.00538035
Epoch [9/300], Train Loss: 0.006227
Validation Loss: 0.00526119
Epoch [10/300], Train Loss: 0.006005
Validation Loss: 0.00525901
Epoch [11/300], Train Loss: 0.006062
Validation Loss: 0.00519197
Epoch [12/300], Train Loss: 0.005999
Validation Loss: 0.00519398
Epoch [13/300], Train Loss: 0.005993
Validation Loss: 0.00517819
Epoch [14/300], Train Loss: 0.006005
Validation Loss: 0.00517700
Epoch [15/300], Train Loss: 0.005989
Validation Loss: 0.00517211
Epoch [16/300], Train Loss: 0.005980
Validation Loss: 0.00517006
Epoch [17/300], Train Loss: 0.005991
Validation Loss: 0.00516617
Epoch [18/300], Train Loss: 0.005970
Validation Loss: 0.00516473
Epoch [19/300], Train Loss: 0.006000
Validation Loss: 0.00516164
Epoch [20/300], Train Loss: 0.005962
Validation Loss: 0.00515897
Epoch [21/300], Train Loss: 0.005972
Validation Loss: 0.00515458
Epoch [22/300], Train Loss: 0.005956
Validation Loss: 0.00515129
Epoch [23/300], Train Loss: 0.005965
Validation Loss: 0.00514809
Epoch [24/300], Train Loss: 0.005965
Validation Loss: 0.00514466
Epoch [25/300], Train Loss: 0.005943
Validation Loss: 0.00514997
Epoch [26/300], Train Loss: 0.005941
Validation Loss: 0.00513901
Epoch [27/300], Train Loss: 0.005942
Validation Loss: 0.00513541
Epoch [28/300], Train Loss: 0.005958
Validation Loss: 0.00513197
Epoch [29/300], Train Loss: 0.005958
Validation Loss: 0.00512861
Epoch [30/300], Train Loss: 0.005933
Validation Loss: 0.00513231
Epoch [31/300], Train Loss: 0.005937
Validation Loss: 0.00512444
Epoch [32/300], Train Loss: 0.005940
Validation Loss: 0.00511891
Epoch [33/300], Train Loss: 0.005933
Validation Loss: 0.00511681
Epoch [34/300], Train Loss: 0.005916
Validation Loss: 0.00511362
Epoch [35/300], Train Loss: 0.005918
Validation Loss: 0.00511404
Epoch [36/300], Train Loss: 0.005929
Validation Loss: 0.00511233
Epoch [37/300], Train Loss: 0.005932
Validation Loss: 0.00510357
Epoch [38/300], Train Loss: 0.005914
Validation Loss: 0.00510323
Epoch [39/300], Train Loss: 0.005887
Validation Loss: 0.00509709
Epoch [40/300], Train Loss: 0.005920
Validation Loss: 0.00509393
Epoch [41/300], Train Loss: 0.005908
Validation Loss: 0.00509154
Epoch [42/300], Train Loss: 0.005891
Validation Loss: 0.00508849
Epoch [43/300], Train Loss: 0.005903
Validation Loss: 0.00508452
Epoch [44/300], Train Loss: 0.005900
Validation Loss: 0.00508156
Epoch [45/300], Train Loss: 0.005873
Validation Loss: 0.00507824
Epoch [46/300], Train Loss: 0.005892
Validation Loss: 0.00507635
Epoch [47/300], Train Loss: 0.005864
Validation Loss: 0.00507391
Epoch [48/300], Train Loss: 0.005885
Validation Loss: 0.00506912
Epoch [49/300], Train Loss: 0.005893
Validation Loss: 0.00506641
Epoch [50/300], Train Loss: 0.005871
Validation Loss: 0.00506327
Epoch [51/300], Train Loss: 0.005865
Validation Loss: 0.00506027
Epoch [52/300], Train Loss: 0.005858
Validation Loss: 0.00505793
Epoch [53/300], Train Loss: 0.005869
Validation Loss: 0.00505435
Epoch [54/300], Train Loss: 0.005859
Validation Loss: 0.00505169
Epoch [55/300], Train Loss: 0.005850
Validation Loss: 0.00504955
Epoch [56/300], Train Loss: 0.005867
Validation Loss: 0.00504854
Epoch [57/300], Train Loss: 0.005842
Validation Loss: 0.00504801
Epoch [58/300], Train Loss: 0.005841
Validation Loss: 0.00503928
Epoch [59/300], Train Loss: 0.005845
Validation Loss: 0.00503916
Epoch [60/300], Train Loss: 0.005819
Validation Loss: 0.00503491
Epoch [61/300], Train Loss: 0.005812
Validation Loss: 0.00503114
Epoch [62/300], Train Loss: 0.005819
Validation Loss: 0.00502885
Epoch [63/300], Train Loss: 0.005827
Validation Loss: 0.00502612
Epoch [64/300], Train Loss: 0.005815
Validation Loss: 0.00502379
Epoch [65/300], Train Loss: 0.005824
Validation Loss: 0.00502083
Epoch [66/300], Train Loss: 0.005825
Validation Loss: 0.00501777
Epoch [67/300], Train Loss: 0.005811
Validation Loss: 0.00501544
Epoch [68/300], Train Loss: 0.005826
Validation Loss: 0.00501162
Epoch [69/300], Train Loss: 0.005806
Validation Loss: 0.00501098
Epoch [70/300], Train Loss: 0.005822
Validation Loss: 0.00500604
Epoch [71/300], Train Loss: 0.005810
Validation Loss: 0.00500343
Epoch [72/300], Train Loss: 0.005782
Validation Loss: 0.00500099
Epoch [73/300], Train Loss: 0.005786
Validation Loss: 0.00499731
Epoch [74/300], Train Loss: 0.005802
Validation Loss: 0.00499488
Epoch [75/300], Train Loss: 0.005772
Validation Loss: 0.00499421
Epoch [76/300], Train Loss: 0.005780
Validation Loss: 0.00499070
Epoch [77/300], Train Loss: 0.005784
Validation Loss: 0.00498694
Epoch [78/300], Train Loss: 0.005798
Validation Loss: 0.00499365
Epoch [79/300], Train Loss: 0.005794
Validation Loss: 0.00498787
Epoch [80/300], Train Loss: 0.005765
Validation Loss: 0.00498508
Epoch [81/300], Train Loss: 0.005794
Validation Loss: 0.00497765
Epoch [82/300], Train Loss: 0.005766
Validation Loss: 0.00497452
Epoch [83/300], Train Loss: 0.005762
Validation Loss: 0.00497222
Epoch [84/300], Train Loss: 0.005779
Validation Loss: 0.00496965
Epoch [85/300], Train Loss: 0.005763
Validation Loss: 0.00496871
Epoch [86/300], Train Loss: 0.005785
Validation Loss: 0.00496798
Epoch [87/300], Train Loss: 0.005765
Validation Loss: 0.00496717
Epoch [88/300], Train Loss: 0.005758
Validation Loss: 0.00495959
Epoch [89/300], Train Loss: 0.005756
Validation Loss: 0.00495714
Epoch [90/300], Train Loss: 0.005782
Validation Loss: 0.00496075
Epoch [91/300], Train Loss: 0.005764
Validation Loss: 0.00495763
Epoch [92/300], Train Loss: 0.005751
Validation Loss: 0.00495321
Epoch [93/300], Train Loss: 0.005762
Validation Loss: 0.00494785
Epoch [94/300], Train Loss: 0.005751
Validation Loss: 0.00494734
Epoch [95/300], Train Loss: 0.005740
Validation Loss: 0.00494272
Epoch [96/300], Train Loss: 0.005733
Validation Loss: 0.00494367
Epoch [97/300], Train Loss: 0.005745
Validation Loss: 0.00494649
Epoch [98/300], Train Loss: 0.005722
Validation Loss: 0.00493890
Epoch [99/300], Train Loss: 0.005721
Validation Loss: 0.00493683
Epoch [100/300], Train Loss: 0.005717
Validation Loss: 0.00493238
Epoch [101/300], Train Loss: 0.005735
Validation Loss: 0.00493589
Epoch [102/300], Train Loss: 0.005724
Validation Loss: 0.00493099
Epoch [103/300], Train Loss: 0.005709
Validation Loss: 0.00492620
Epoch [104/300], Train Loss: 0.005719
Validation Loss: 0.00492274
Epoch [105/300], Train Loss: 0.005714
Validation Loss: 0.00492039
Epoch [106/300], Train Loss: 0.005726
Validation Loss: 0.00491932
Epoch [107/300], Train Loss: 0.005712
Validation Loss: 0.00491818
Epoch [108/300], Train Loss: 0.005692
Validation Loss: 0.00491473
Epoch [109/300], Train Loss: 0.005702
Validation Loss: 0.00491277
Epoch [110/300], Train Loss: 0.005705
Validation Loss: 0.00491095
Epoch [111/300], Train Loss: 0.005694
Validation Loss: 0.00490983
Epoch [112/300], Train Loss: 0.005698
Validation Loss: 0.00490927
Epoch [113/300], Train Loss: 0.005684
Validation Loss: 0.00490642
Epoch [114/300], Train Loss: 0.005698
Validation Loss: 0.00490407
Epoch [115/300], Train Loss: 0.005704
Validation Loss: 0.00490548
Epoch [116/300], Train Loss: 0.005687
Validation Loss: 0.00490378
Epoch [117/300], Train Loss: 0.005673
Validation Loss: 0.00490017
Epoch [118/300], Train Loss: 0.005682
Validation Loss: 0.00489594
Epoch [119/300], Train Loss: 0.005688
Validation Loss: 0.00489408
Epoch [120/300], Train Loss: 0.005695
Validation Loss: 0.00489306
Epoch [121/300], Train Loss: 0.005686
Validation Loss: 0.00489121
Epoch [122/300], Train Loss: 0.005667
Validation Loss: 0.00489199
Epoch [123/300], Train Loss: 0.005687
Validation Loss: 0.00488810
Epoch [124/300], Train Loss: 0.005682
Validation Loss: 0.00488590
Epoch [125/300], Train Loss: 0.005669
Validation Loss: 0.00488848
Epoch [126/300], Train Loss: 0.005667
Validation Loss: 0.00488438
Epoch [127/300], Train Loss: 0.005673
Validation Loss: 0.00488191
Epoch [128/300], Train Loss: 0.005670
Validation Loss: 0.00487956
Epoch [129/300], Train Loss: 0.005670
Validation Loss: 0.00487804
Epoch [130/300], Train Loss: 0.005665
Validation Loss: 0.00487925
Epoch [131/300], Train Loss: 0.005653
Validation Loss: 0.00487937
Epoch [132/300], Train Loss: 0.005666
Validation Loss: 0.00487741
Epoch [133/300], Train Loss: 0.005676
Validation Loss: 0.00487316
Epoch [134/300], Train Loss: 0.005638
Validation Loss: 0.00487204
Epoch [135/300], Train Loss: 0.005664
Validation Loss: 0.00486928
Epoch [136/300], Train Loss: 0.005658
Validation Loss: 0.00486951
Epoch [137/300], Train Loss: 0.005641
Validation Loss: 0.00487312
Epoch [138/300], Train Loss: 0.005682
Validation Loss: 0.00486984
Epoch [139/300], Train Loss: 0.005680
Validation Loss: 0.00487413
Epoch [140/300], Train Loss: 0.005654
Validation Loss: 0.00487248
Epoch [141/300], Train Loss: 0.005659
Validation Loss: 0.00487213
Epoch [142/300], Train Loss: 0.005655
Validation Loss: 0.00486056
Epoch [143/300], Train Loss: 0.005658
Validation Loss: 0.00486176
Epoch [144/300], Train Loss: 0.005645
Validation Loss: 0.00485925
Epoch [145/300], Train Loss: 0.005644
Validation Loss: 0.00485679
Epoch [146/300], Train Loss: 0.005644
Validation Loss: 0.00485723
Epoch [147/300], Train Loss: 0.005653
Validation Loss: 0.00485471
Epoch [148/300], Train Loss: 0.005627
Validation Loss: 0.00485389
Epoch [149/300], Train Loss: 0.005632
Validation Loss: 0.00485222
Epoch [150/300], Train Loss: 0.005625
Validation Loss: 0.00485096
Epoch [151/300], Train Loss: 0.005641
Validation Loss: 0.00485097
Epoch [152/300], Train Loss: 0.005629
Validation Loss: 0.00485353
Epoch [153/300], Train Loss: 0.005638
Validation Loss: 0.00484803
Epoch [154/300], Train Loss: 0.005625
Validation Loss: 0.00484682
Epoch [155/300], Train Loss: 0.005634
Validation Loss: 0.00484817
Epoch [156/300], Train Loss: 0.005649
Validation Loss: 0.00484764
Epoch [157/300], Train Loss: 0.005628
Validation Loss: 0.00485043
Epoch [158/300], Train Loss: 0.005633
Validation Loss: 0.00484367
Epoch [159/300], Train Loss: 0.005636
Validation Loss: 0.00484371
Epoch [160/300], Train Loss: 0.005645
Validation Loss: 0.00484189
Epoch [161/300], Train Loss: 0.005652
Validation Loss: 0.00484901
Epoch [162/300], Train Loss: 0.005625
Validation Loss: 0.00484049
Epoch [163/300], Train Loss: 0.005617
Validation Loss: 0.00483832
Epoch [164/300], Train Loss: 0.005632
Validation Loss: 0.00483855
Epoch [165/300], Train Loss: 0.005614
Validation Loss: 0.00483641
Epoch [166/300], Train Loss: 0.005618
Validation Loss: 0.00483545
Epoch [167/300], Train Loss: 0.005621
Validation Loss: 0.00483433
Epoch [168/300], Train Loss: 0.005610
Validation Loss: 0.00483400
Epoch [169/300], Train Loss: 0.005631
Validation Loss: 0.00483265
Epoch [170/300], Train Loss: 0.005609
Validation Loss: 0.00483207
Epoch [171/300], Train Loss: 0.005623
Validation Loss: 0.00483325
Epoch [172/300], Train Loss: 0.005615
Validation Loss: 0.00483411
Epoch [173/300], Train Loss: 0.005621
Validation Loss: 0.00482972
Epoch [174/300], Train Loss: 0.005617
Validation Loss: 0.00482927
Epoch [175/300], Train Loss: 0.005611
Validation Loss: 0.00482846
Epoch [176/300], Train Loss: 0.005622
Validation Loss: 0.00482702
Epoch [177/300], Train Loss: 0.005611
Validation Loss: 0.00482980
Epoch [178/300], Train Loss: 0.005604
Validation Loss: 0.00482536
Epoch [179/300], Train Loss: 0.005600
Validation Loss: 0.00482468
Epoch [180/300], Train Loss: 0.005605
Validation Loss: 0.00482557
Epoch [181/300], Train Loss: 0.005604
Validation Loss: 0.00482307
Epoch [182/300], Train Loss: 0.005624
Validation Loss: 0.00482241
Epoch [183/300], Train Loss: 0.005601
Validation Loss: 0.00482652
Epoch [184/300], Train Loss: 0.005593
Validation Loss: 0.00482097
Epoch [185/300], Train Loss: 0.005609
Validation Loss: 0.00482036
Epoch [186/300], Train Loss: 0.005606
Validation Loss: 0.00482141
Epoch [187/300], Train Loss: 0.005607
Validation Loss: 0.00482356
Epoch [188/300], Train Loss: 0.005605
Validation Loss: 0.00481944
Epoch [189/300], Train Loss: 0.005609
Validation Loss: 0.00481771
Epoch [190/300], Train Loss: 0.005633
Validation Loss: 0.00481879
Epoch [191/300], Train Loss: 0.005610
Validation Loss: 0.00482722
Epoch [192/300], Train Loss: 0.005599
Validation Loss: 0.00481574
Epoch [193/300], Train Loss: 0.005586
Validation Loss: 0.00481502
Epoch [194/300], Train Loss: 0.005621
Validation Loss: 0.00481503
Epoch [195/300], Train Loss: 0.005596
Validation Loss: 0.00481352
Epoch [196/300], Train Loss: 0.005588
Validation Loss: 0.00481339
Epoch [197/300], Train Loss: 0.005597
Validation Loss: 0.00481232
Epoch [198/300], Train Loss: 0.005591
Validation Loss: 0.00481626
Epoch [199/300], Train Loss: 0.005591
Validation Loss: 0.00481153
Epoch [200/300], Train Loss: 0.005599
Validation Loss: 0.00481089
Epoch [201/300], Train Loss: 0.005577
Validation Loss: 0.00481083
Epoch [202/300], Train Loss: 0.005580
Validation Loss: 0.00481041
Epoch [203/300], Train Loss: 0.005586
Validation Loss: 0.00480881
Epoch [204/300], Train Loss: 0.005608
Validation Loss: 0.00480822
Epoch [205/300], Train Loss: 0.005590
Validation Loss: 0.00480789
Epoch [206/300], Train Loss: 0.005597
Validation Loss: 0.00480709
Epoch [207/300], Train Loss: 0.005595
Validation Loss: 0.00480650
Epoch [208/300], Train Loss: 0.005588
Validation Loss: 0.00481030
Epoch [209/300], Train Loss: 0.005600
Validation Loss: 0.00480583
Epoch [210/300], Train Loss: 0.005574
Validation Loss: 0.00480529
Epoch [211/300], Train Loss: 0.005577
Validation Loss: 0.00480632
Epoch [212/300], Train Loss: 0.005578
Validation Loss: 0.00480404
Epoch [213/300], Train Loss: 0.005593
Validation Loss: 0.00480343
Epoch [214/300], Train Loss: 0.005581
Validation Loss: 0.00480446
Epoch [215/300], Train Loss: 0.005582
Validation Loss: 0.00480240
Epoch [216/300], Train Loss: 0.005582
Validation Loss: 0.00480218
Epoch [217/300], Train Loss: 0.005562
Validation Loss: 0.00480216
Epoch [218/300], Train Loss: 0.005601
Validation Loss: 0.00480093
Epoch [219/300], Train Loss: 0.005575
Validation Loss: 0.00480019
Epoch [220/300], Train Loss: 0.005587
Validation Loss: 0.00480102
Epoch [221/300], Train Loss: 0.005579
Validation Loss: 0.00479929
Epoch [222/300], Train Loss: 0.005581
Validation Loss: 0.00479875
Epoch [223/300], Train Loss: 0.005573
Validation Loss: 0.00479994
Epoch [224/300], Train Loss: 0.005586
Validation Loss: 0.00479797
Epoch [225/300], Train Loss: 0.005579
Validation Loss: 0.00479737
Epoch [226/300], Train Loss: 0.005592
Validation Loss: 0.00479688
Epoch [227/300], Train Loss: 0.005572
Validation Loss: 0.00479891
Epoch [228/300], Train Loss: 0.005563
Validation Loss: 0.00479583
Epoch [229/300], Train Loss: 0.005566
Validation Loss: 0.00479538
Epoch [230/300], Train Loss: 0.005577
Validation Loss: 0.00479503
Epoch [231/300], Train Loss: 0.005575
Validation Loss: 0.00479556
Epoch [232/300], Train Loss: 0.005582
Validation Loss: 0.00479403
Epoch [233/300], Train Loss: 0.005592
Validation Loss: 0.00479680
Epoch [234/300], Train Loss: 0.005586
Validation Loss: 0.00479657
Epoch [235/300], Train Loss: 0.005579
Validation Loss: 0.00479273
Epoch [236/300], Train Loss: 0.005590
Validation Loss: 0.00479364
Epoch [237/300], Train Loss: 0.005581
Validation Loss: 0.00479205
Epoch [238/300], Train Loss: 0.005564
Validation Loss: 0.00479152
Epoch [239/300], Train Loss: 0.005569
Validation Loss: 0.00479210
Epoch [240/300], Train Loss: 0.005572
Validation Loss: 0.00479065
Epoch [241/300], Train Loss: 0.005569
Validation Loss: 0.00479017
Epoch [242/300], Train Loss: 0.005566
Validation Loss: 0.00479033
Epoch [243/300], Train Loss: 0.005577
Validation Loss: 0.00478959
Epoch [244/300], Train Loss: 0.005563
Validation Loss: 0.00478892
Epoch [245/300], Train Loss: 0.005567
Validation Loss: 0.00479059
Epoch [246/300], Train Loss: 0.005569
Validation Loss: 0.00478927
Epoch [247/300], Train Loss: 0.005581
Validation Loss: 0.00478936
Epoch [248/300], Train Loss: 0.005555
Validation Loss: 0.00478727
Epoch [249/300], Train Loss: 0.005566
Validation Loss: 0.00478804
Epoch [250/300], Train Loss: 0.005574
Validation Loss: 0.00478775
Epoch [251/300], Train Loss: 0.005557
Validation Loss: 0.00478923
Epoch [252/300], Train Loss: 0.005568
Validation Loss: 0.00478568
Epoch [253/300], Train Loss: 0.005575
Validation Loss: 0.00478566
Epoch [254/300], Train Loss: 0.005552
Validation Loss: 0.00478655
Epoch [255/300], Train Loss: 0.005559
Validation Loss: 0.00478698
Epoch [256/300], Train Loss: 0.005554
Validation Loss: 0.00478465
Epoch [257/300], Train Loss: 0.005562
Validation Loss: 0.00478391
Epoch [258/300], Train Loss: 0.005559
Validation Loss: 0.00478370
Epoch [259/300], Train Loss: 0.005564
Validation Loss: 0.00478359
Epoch [260/300], Train Loss: 0.005573
Validation Loss: 0.00478384
Epoch [261/300], Train Loss: 0.005558
Validation Loss: 0.00478270
Epoch [262/300], Train Loss: 0.005556
Validation Loss: 0.00478200
Epoch [263/300], Train Loss: 0.005547
Validation Loss: 0.00478234
Epoch [264/300], Train Loss: 0.005569
Validation Loss: 0.00478169
Epoch [265/300], Train Loss: 0.005559
Validation Loss: 0.00478136
Epoch [266/300], Train Loss: 0.005581
Validation Loss: 0.00478339
Epoch [267/300], Train Loss: 0.005568
Validation Loss: 0.00478059
Epoch [268/300], Train Loss: 0.005575
Validation Loss: 0.00478003
Epoch [269/300], Train Loss: 0.005564
Validation Loss: 0.00478822
Epoch [270/300], Train Loss: 0.005558
Validation Loss: 0.00477921
Epoch [271/300], Train Loss: 0.005580
Validation Loss: 0.00478150
Epoch [272/300], Train Loss: 0.005554
Validation Loss: 0.00478511
Epoch [273/300], Train Loss: 0.005576
Validation Loss: 0.00477832
Epoch [274/300], Train Loss: 0.005556
Validation Loss: 0.00477805
Epoch [275/300], Train Loss: 0.005562
Validation Loss: 0.00477813
Epoch [276/300], Train Loss: 0.005546
Validation Loss: 0.00477740
Epoch [277/300], Train Loss: 0.005559
Validation Loss: 0.00477893
Epoch [278/300], Train Loss: 0.005565
Validation Loss: 0.00477991
Epoch [279/300], Train Loss: 0.005563
Validation Loss: 0.00477726
Epoch [280/300], Train Loss: 0.005578
Validation Loss: 0.00477701
Epoch [281/300], Train Loss: 0.005553
Validation Loss: 0.00477616
Epoch [282/300], Train Loss: 0.005553
Validation Loss: 0.00477536
Epoch [283/300], Train Loss: 0.005557
Validation Loss: 0.00477570
Epoch [284/300], Train Loss: 0.005538
Validation Loss: 0.00477475
Epoch [285/300], Train Loss: 0.005548
Validation Loss: 0.00477493
Epoch [286/300], Train Loss: 0.005558
Validation Loss: 0.00477610
Epoch [287/300], Train Loss: 0.005559
Validation Loss: 0.00477434
Epoch [288/300], Train Loss: 0.005535
Validation Loss: 0.00477493
Epoch [289/300], Train Loss: 0.005542
Validation Loss: 0.00477333
Epoch [290/300], Train Loss: 0.005537
Validation Loss: 0.00477306
Epoch [291/300], Train Loss: 0.005545
Validation Loss: 0.00477276
Epoch [292/300], Train Loss: 0.005551
Validation Loss: 0.00477380
Epoch [293/300], Train Loss: 0.005555
Validation Loss: 0.00477213
Epoch [294/300], Train Loss: 0.005550
Validation Loss: 0.00477223
Epoch [295/300], Train Loss: 0.005535
Validation Loss: 0.00477227
Epoch [296/300], Train Loss: 0.005556
Validation Loss: 0.00477218
Epoch [297/300], Train Loss: 0.005548
Validation Loss: 0.00477112
Epoch [298/300], Train Loss: 0.005568
Validation Loss: 0.00477095
Epoch [299/300], Train Loss: 0.005551
Validation Loss: 0.00477232
Epoch [300/300], Train Loss: 0.005551
Validation Loss: 0.00477012

Evaluating model for: Router
Run 39/72 completed in 573.55 seconds with: {'MAE': np.float32(0.2105917), 'MSE': np.float32(0.07570635), 'RMSE': np.float32(0.27514786), 'SAE': np.float32(0.00086212193), 'NDE': np.float32(0.013762164)}

Run 40/72: hidden=256, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Router
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.099592
Validation Loss: 0.09024861
Epoch [2/300], Train Loss: 0.084832
Validation Loss: 0.07529975
Epoch [3/300], Train Loss: 0.068723
Validation Loss: 0.05638363
Epoch [4/300], Train Loss: 0.044956
Validation Loss: 0.02297634
Epoch [5/300], Train Loss: 0.014457
Validation Loss: 0.01385941
Epoch [6/300], Train Loss: 0.009056
Validation Loss: 0.00799884
Epoch [7/300], Train Loss: 0.008980
Validation Loss: 0.00655925
Epoch [8/300], Train Loss: 0.006888
Validation Loss: 0.00640084
Epoch [9/300], Train Loss: 0.007056
Validation Loss: 0.00568675
Epoch [10/300], Train Loss: 0.006657
Validation Loss: 0.00584700
Epoch [11/300], Train Loss: 0.006666
Validation Loss: 0.00567980
Epoch [12/300], Train Loss: 0.006592
Validation Loss: 0.00566729
Epoch [13/300], Train Loss: 0.006557
Validation Loss: 0.00566321
Epoch [14/300], Train Loss: 0.006563
Validation Loss: 0.00563996
Epoch [15/300], Train Loss: 0.006542
Validation Loss: 0.00563139
Epoch [16/300], Train Loss: 0.006535
Validation Loss: 0.00562422
Epoch [17/300], Train Loss: 0.006529
Validation Loss: 0.00561693
Epoch [18/300], Train Loss: 0.006515
Validation Loss: 0.00560984
Epoch [19/300], Train Loss: 0.006523
Validation Loss: 0.00560459
Epoch [20/300], Train Loss: 0.006489
Validation Loss: 0.00559788
Epoch [21/300], Train Loss: 0.006494
Validation Loss: 0.00559115
Epoch [22/300], Train Loss: 0.006473
Validation Loss: 0.00558090
Epoch [23/300], Train Loss: 0.006473
Validation Loss: 0.00557392
Epoch [24/300], Train Loss: 0.006474
Validation Loss: 0.00556567
Epoch [25/300], Train Loss: 0.006450
Validation Loss: 0.00556655
Epoch [26/300], Train Loss: 0.006437
Validation Loss: 0.00555428
Epoch [27/300], Train Loss: 0.006429
Validation Loss: 0.00554280
Epoch [28/300], Train Loss: 0.006442
Validation Loss: 0.00553497
Epoch [29/300], Train Loss: 0.006448
Validation Loss: 0.00552826
Epoch [30/300], Train Loss: 0.006426
Validation Loss: 0.00552831
Epoch [31/300], Train Loss: 0.006407
Validation Loss: 0.00551908
Epoch [32/300], Train Loss: 0.006414
Validation Loss: 0.00550493
Epoch [33/300], Train Loss: 0.006388
Validation Loss: 0.00549836
Epoch [34/300], Train Loss: 0.006370
Validation Loss: 0.00549083
Epoch [35/300], Train Loss: 0.006365
Validation Loss: 0.00548786
Epoch [36/300], Train Loss: 0.006380
Validation Loss: 0.00548294
Epoch [37/300], Train Loss: 0.006370
Validation Loss: 0.00546955
Epoch [38/300], Train Loss: 0.006351
Validation Loss: 0.00546485
Epoch [39/300], Train Loss: 0.006327
Validation Loss: 0.00545442
Epoch [40/300], Train Loss: 0.006357
Validation Loss: 0.00544721
Epoch [41/300], Train Loss: 0.006341
Validation Loss: 0.00543994
Epoch [42/300], Train Loss: 0.006316
Validation Loss: 0.00543441
Epoch [43/300], Train Loss: 0.006324
Validation Loss: 0.00542518
Epoch [44/300], Train Loss: 0.006313
Validation Loss: 0.00541717
Epoch [45/300], Train Loss: 0.006281
Validation Loss: 0.00540979
Epoch [46/300], Train Loss: 0.006295
Validation Loss: 0.00540422
Epoch [47/300], Train Loss: 0.006261
Validation Loss: 0.00539745
Epoch [48/300], Train Loss: 0.006286
Validation Loss: 0.00538912
Epoch [49/300], Train Loss: 0.006288
Validation Loss: 0.00538215
Epoch [50/300], Train Loss: 0.006261
Validation Loss: 0.00537551
Epoch [51/300], Train Loss: 0.006249
Validation Loss: 0.00536774
Epoch [52/300], Train Loss: 0.006247
Validation Loss: 0.00536098
Epoch [53/300], Train Loss: 0.006239
Validation Loss: 0.00535435
Epoch [54/300], Train Loss: 0.006228
Validation Loss: 0.00534755
Epoch [55/300], Train Loss: 0.006224
Validation Loss: 0.00533927
Epoch [56/300], Train Loss: 0.006234
Validation Loss: 0.00533566
Epoch [57/300], Train Loss: 0.006199
Validation Loss: 0.00533298
Epoch [58/300], Train Loss: 0.006194
Validation Loss: 0.00532213
Epoch [59/300], Train Loss: 0.006192
Validation Loss: 0.00531076
Epoch [60/300], Train Loss: 0.006172
Validation Loss: 0.00530398
Epoch [61/300], Train Loss: 0.006155
Validation Loss: 0.00529691
Epoch [62/300], Train Loss: 0.006149
Validation Loss: 0.00529064
Epoch [63/300], Train Loss: 0.006165
Validation Loss: 0.00528511
Epoch [64/300], Train Loss: 0.006141
Validation Loss: 0.00527734
Epoch [65/300], Train Loss: 0.006148
Validation Loss: 0.00527125
Epoch [66/300], Train Loss: 0.006154
Validation Loss: 0.00526423
Epoch [67/300], Train Loss: 0.006125
Validation Loss: 0.00526181
Epoch [68/300], Train Loss: 0.006141
Validation Loss: 0.00525113
Epoch [69/300], Train Loss: 0.006108
Validation Loss: 0.00524659
Epoch [70/300], Train Loss: 0.006130
Validation Loss: 0.00523926
Epoch [71/300], Train Loss: 0.006117
Validation Loss: 0.00523249
Epoch [72/300], Train Loss: 0.006083
Validation Loss: 0.00522594
Epoch [73/300], Train Loss: 0.006082
Validation Loss: 0.00522002
Epoch [74/300], Train Loss: 0.006100
Validation Loss: 0.00521382
Epoch [75/300], Train Loss: 0.006057
Validation Loss: 0.00520776
Epoch [76/300], Train Loss: 0.006064
Validation Loss: 0.00520446
Epoch [77/300], Train Loss: 0.006073
Validation Loss: 0.00519827
Epoch [78/300], Train Loss: 0.006080
Validation Loss: 0.00519313
Epoch [79/300], Train Loss: 0.006090
Validation Loss: 0.00518859
Epoch [80/300], Train Loss: 0.006041
Validation Loss: 0.00519331
Epoch [81/300], Train Loss: 0.006071
Validation Loss: 0.00517928
Epoch [82/300], Train Loss: 0.006037
Validation Loss: 0.00517663
Epoch [83/300], Train Loss: 0.006031
Validation Loss: 0.00516920
Epoch [84/300], Train Loss: 0.006044
Validation Loss: 0.00516475
Epoch [85/300], Train Loss: 0.006032
Validation Loss: 0.00516028
Epoch [86/300], Train Loss: 0.006050
Validation Loss: 0.00515824
Epoch [87/300], Train Loss: 0.006022
Validation Loss: 0.00516056
Epoch [88/300], Train Loss: 0.006016
Validation Loss: 0.00514802
Epoch [89/300], Train Loss: 0.006004
Validation Loss: 0.00514736
Epoch [90/300], Train Loss: 0.006041
Validation Loss: 0.00513916
Epoch [91/300], Train Loss: 0.006018
Validation Loss: 0.00513736
Epoch [92/300], Train Loss: 0.006016
Validation Loss: 0.00513716
Epoch [93/300], Train Loss: 0.006029
Validation Loss: 0.00512947
Epoch [94/300], Train Loss: 0.005996
Validation Loss: 0.00513337
Epoch [95/300], Train Loss: 0.005985
Validation Loss: 0.00512586
Epoch [96/300], Train Loss: 0.005983
Validation Loss: 0.00511744
Epoch [97/300], Train Loss: 0.005995
Validation Loss: 0.00512266
Epoch [98/300], Train Loss: 0.005969
Validation Loss: 0.00511554
Epoch [99/300], Train Loss: 0.005968
Validation Loss: 0.00511605
Epoch [100/300], Train Loss: 0.005967
Validation Loss: 0.00510790
Epoch [101/300], Train Loss: 0.005981
Validation Loss: 0.00511522
Epoch [102/300], Train Loss: 0.005957
Validation Loss: 0.00510763
Epoch [103/300], Train Loss: 0.005952
Validation Loss: 0.00510215
Epoch [104/300], Train Loss: 0.005960
Validation Loss: 0.00509253
Epoch [105/300], Train Loss: 0.005957
Validation Loss: 0.00508994
Epoch [106/300], Train Loss: 0.005957
Validation Loss: 0.00508710
Epoch [107/300], Train Loss: 0.005944
Validation Loss: 0.00508350
Epoch [108/300], Train Loss: 0.005926
Validation Loss: 0.00508217
Epoch [109/300], Train Loss: 0.005935
Validation Loss: 0.00507847
Epoch [110/300], Train Loss: 0.005929
Validation Loss: 0.00507597
Epoch [111/300], Train Loss: 0.005920
Validation Loss: 0.00507288
Epoch [112/300], Train Loss: 0.005918
Validation Loss: 0.00507259
Epoch [113/300], Train Loss: 0.005918
Validation Loss: 0.00506919
Epoch [114/300], Train Loss: 0.005917
Validation Loss: 0.00506570
Epoch [115/300], Train Loss: 0.005929
Validation Loss: 0.00506660
Epoch [116/300], Train Loss: 0.005920
Validation Loss: 0.00506615
Epoch [117/300], Train Loss: 0.005902
Validation Loss: 0.00506267
Epoch [118/300], Train Loss: 0.005895
Validation Loss: 0.00505598
Epoch [119/300], Train Loss: 0.005901
Validation Loss: 0.00505358
Epoch [120/300], Train Loss: 0.005904
Validation Loss: 0.00504944
Epoch [121/300], Train Loss: 0.005900
Validation Loss: 0.00504758
Epoch [122/300], Train Loss: 0.005891
Validation Loss: 0.00504893
Epoch [123/300], Train Loss: 0.005901
Validation Loss: 0.00504543
Epoch [124/300], Train Loss: 0.005894
Validation Loss: 0.00504218
Epoch [125/300], Train Loss: 0.005876
Validation Loss: 0.00503985
Epoch [126/300], Train Loss: 0.005878
Validation Loss: 0.00503695
Epoch [127/300], Train Loss: 0.005879
Validation Loss: 0.00503577
Epoch [128/300], Train Loss: 0.005882
Validation Loss: 0.00503247
Epoch [129/300], Train Loss: 0.005874
Validation Loss: 0.00503019
Epoch [130/300], Train Loss: 0.005881
Validation Loss: 0.00502852
Epoch [131/300], Train Loss: 0.005857
Validation Loss: 0.00502893
Epoch [132/300], Train Loss: 0.005876
Validation Loss: 0.00502989
Epoch [133/300], Train Loss: 0.005884
Validation Loss: 0.00502528
Epoch [134/300], Train Loss: 0.005836
Validation Loss: 0.00502334
Epoch [135/300], Train Loss: 0.005867
Validation Loss: 0.00501699
Epoch [136/300], Train Loss: 0.005853
Validation Loss: 0.00501559
Epoch [137/300], Train Loss: 0.005849
Validation Loss: 0.00501949
Epoch [138/300], Train Loss: 0.005872
Validation Loss: 0.00501848
Epoch [139/300], Train Loss: 0.005870
Validation Loss: 0.00502286
Epoch [140/300], Train Loss: 0.005860
Validation Loss: 0.00502495
Epoch [141/300], Train Loss: 0.005856
Validation Loss: 0.00502510
Epoch [142/300], Train Loss: 0.005845
Validation Loss: 0.00500581
Epoch [143/300], Train Loss: 0.005848
Validation Loss: 0.00500662
Epoch [144/300], Train Loss: 0.005827
Validation Loss: 0.00500360
Epoch [145/300], Train Loss: 0.005832
Validation Loss: 0.00499793
Epoch [146/300], Train Loss: 0.005835
Validation Loss: 0.00499782
Epoch [147/300], Train Loss: 0.005829
Validation Loss: 0.00499402
Epoch [148/300], Train Loss: 0.005822
Validation Loss: 0.00499360
Epoch [149/300], Train Loss: 0.005821
Validation Loss: 0.00499011
Epoch [150/300], Train Loss: 0.005813
Validation Loss: 0.00498827
Epoch [151/300], Train Loss: 0.005818
Validation Loss: 0.00498789
Epoch [152/300], Train Loss: 0.005810
Validation Loss: 0.00499016
Epoch [153/300], Train Loss: 0.005822
Validation Loss: 0.00498514
Epoch [154/300], Train Loss: 0.005804
Validation Loss: 0.00498225
Epoch [155/300], Train Loss: 0.005817
Validation Loss: 0.00497972
Epoch [156/300], Train Loss: 0.005825
Validation Loss: 0.00498027
Epoch [157/300], Train Loss: 0.005807
Validation Loss: 0.00498423
Epoch [158/300], Train Loss: 0.005802
Validation Loss: 0.00497833
Epoch [159/300], Train Loss: 0.005810
Validation Loss: 0.00497695
Epoch [160/300], Train Loss: 0.005819
Validation Loss: 0.00497346
Epoch [161/300], Train Loss: 0.005825
Validation Loss: 0.00498002
Epoch [162/300], Train Loss: 0.005785
Validation Loss: 0.00497075
Epoch [163/300], Train Loss: 0.005785
Validation Loss: 0.00496614
Epoch [164/300], Train Loss: 0.005804
Validation Loss: 0.00496269
Epoch [165/300], Train Loss: 0.005773
Validation Loss: 0.00496003
Epoch [166/300], Train Loss: 0.005780
Validation Loss: 0.00495821
Epoch [167/300], Train Loss: 0.005778
Validation Loss: 0.00495708
Epoch [168/300], Train Loss: 0.005775
Validation Loss: 0.00495494
Epoch [169/300], Train Loss: 0.005792
Validation Loss: 0.00495183
Epoch [170/300], Train Loss: 0.005766
Validation Loss: 0.00494973
Epoch [171/300], Train Loss: 0.005771
Validation Loss: 0.00494832
Epoch [172/300], Train Loss: 0.005769
Validation Loss: 0.00494987
Epoch [173/300], Train Loss: 0.005773
Validation Loss: 0.00494505
Epoch [174/300], Train Loss: 0.005759
Validation Loss: 0.00494326
Epoch [175/300], Train Loss: 0.005747
Validation Loss: 0.00493500
Epoch [176/300], Train Loss: 0.005756
Validation Loss: 0.00493924
Epoch [177/300], Train Loss: 0.005734
Validation Loss: 0.00492538
Epoch [178/300], Train Loss: 0.005750
Validation Loss: 0.00492839
Epoch [179/300], Train Loss: 0.005732
Validation Loss: 0.00492339
Epoch [180/300], Train Loss: 0.005727
Validation Loss: 0.00491402
Epoch [181/300], Train Loss: 0.005699
Validation Loss: 0.00491901
Epoch [182/300], Train Loss: 0.005735
Validation Loss: 0.00492736
Epoch [183/300], Train Loss: 0.005709
Validation Loss: 0.00491942
Epoch [184/300], Train Loss: 0.005691
Validation Loss: 0.00489067
Epoch [185/300], Train Loss: 0.005697
Validation Loss: 0.00489126
Epoch [186/300], Train Loss: 0.005681
Validation Loss: 0.00488474
Epoch [187/300], Train Loss: 0.005688
Validation Loss: 0.00486760
Epoch [188/300], Train Loss: 0.005678
Validation Loss: 0.00488877
Epoch [189/300], Train Loss: 0.005694
Validation Loss: 0.00486198
Epoch [190/300], Train Loss: 0.005685
Validation Loss: 0.00485615
Epoch [191/300], Train Loss: 0.005702
Validation Loss: 0.00485896
Epoch [192/300], Train Loss: 0.005661
Validation Loss: 0.00484719
Epoch [193/300], Train Loss: 0.005662
Validation Loss: 0.00485777
Epoch [194/300], Train Loss: 0.005685
Validation Loss: 0.00489009
Epoch [195/300], Train Loss: 0.005687
Validation Loss: 0.00487583
Epoch [196/300], Train Loss: 0.005675
Validation Loss: 0.00483961
Epoch [197/300], Train Loss: 0.005691
Validation Loss: 0.00484327
Epoch [198/300], Train Loss: 0.005659
Validation Loss: 0.00485413
Epoch [199/300], Train Loss: 0.005674
Validation Loss: 0.00488174
Epoch [200/300], Train Loss: 0.005674
Validation Loss: 0.00484819
Epoch [201/300], Train Loss: 0.005622
Validation Loss: 0.00482993
Epoch [202/300], Train Loss: 0.005618
Validation Loss: 0.00483441
Epoch [203/300], Train Loss: 0.005624
Validation Loss: 0.00482003
Epoch [204/300], Train Loss: 0.005643
Validation Loss: 0.00484436
Epoch [205/300], Train Loss: 0.005635
Validation Loss: 0.00482592
Epoch [206/300], Train Loss: 0.005640
Validation Loss: 0.00481537
Epoch [207/300], Train Loss: 0.005620
Validation Loss: 0.00480714
Epoch [208/300], Train Loss: 0.005617
Validation Loss: 0.00484714
Epoch [209/300], Train Loss: 0.005628
Validation Loss: 0.00480266
Epoch [210/300], Train Loss: 0.005599
Validation Loss: 0.00485539
Epoch [211/300], Train Loss: 0.005598
Validation Loss: 0.00479670
Epoch [212/300], Train Loss: 0.005591
Validation Loss: 0.00479182
Epoch [213/300], Train Loss: 0.005614
Validation Loss: 0.00480166
Epoch [214/300], Train Loss: 0.005589
Validation Loss: 0.00478764
Epoch [215/300], Train Loss: 0.005599
Validation Loss: 0.00478616
Epoch [216/300], Train Loss: 0.005592
Validation Loss: 0.00479094
Epoch [217/300], Train Loss: 0.005580
Validation Loss: 0.00477761
Epoch [218/300], Train Loss: 0.005606
Validation Loss: 0.00478863
Epoch [219/300], Train Loss: 0.005587
Validation Loss: 0.00478537
Epoch [220/300], Train Loss: 0.005587
Validation Loss: 0.00476964
Epoch [221/300], Train Loss: 0.005576
Validation Loss: 0.00477029
Epoch [222/300], Train Loss: 0.005584
Validation Loss: 0.00476502
Epoch [223/300], Train Loss: 0.005582
Validation Loss: 0.00479777
Epoch [224/300], Train Loss: 0.005581
Validation Loss: 0.00475991
Epoch [225/300], Train Loss: 0.005574
Validation Loss: 0.00481768
Epoch [226/300], Train Loss: 0.005603
Validation Loss: 0.00478128
Epoch [227/300], Train Loss: 0.005570
Validation Loss: 0.00481318
Epoch [228/300], Train Loss: 0.005560
Validation Loss: 0.00475734
Epoch [229/300], Train Loss: 0.005583
Validation Loss: 0.00477668
Epoch [230/300], Train Loss: 0.005565
Validation Loss: 0.00475177
Epoch [231/300], Train Loss: 0.005564
Validation Loss: 0.00477815
Epoch [232/300], Train Loss: 0.005568
Validation Loss: 0.00474626
Epoch [233/300], Train Loss: 0.005571
Validation Loss: 0.00475434
Epoch [234/300], Train Loss: 0.005571
Validation Loss: 0.00474435
Epoch [235/300], Train Loss: 0.005561
Validation Loss: 0.00473518
Epoch [236/300], Train Loss: 0.005575
Validation Loss: 0.00473992
Epoch [237/300], Train Loss: 0.005552
Validation Loss: 0.00473132
Epoch [238/300], Train Loss: 0.005543
Validation Loss: 0.00475785
Epoch [239/300], Train Loss: 0.005553
Validation Loss: 0.00474651
Epoch [240/300], Train Loss: 0.005555
Validation Loss: 0.00481061
Epoch [241/300], Train Loss: 0.005541
Validation Loss: 0.00472563
Epoch [242/300], Train Loss: 0.005537
Validation Loss: 0.00472817
Epoch [243/300], Train Loss: 0.005556
Validation Loss: 0.00472121
Epoch [244/300], Train Loss: 0.005528
Validation Loss: 0.00471849
Epoch [245/300], Train Loss: 0.005537
Validation Loss: 0.00471882
Epoch [246/300], Train Loss: 0.005520
Validation Loss: 0.00474841
Epoch [247/300], Train Loss: 0.005550
Validation Loss: 0.00471528
Epoch [248/300], Train Loss: 0.005532
Validation Loss: 0.00475031
Epoch [249/300], Train Loss: 0.005520
Validation Loss: 0.00470796
Epoch [250/300], Train Loss: 0.005512
Validation Loss: 0.00470862
Epoch [251/300], Train Loss: 0.005515
Validation Loss: 0.00472840
Epoch [252/300], Train Loss: 0.005521
Validation Loss: 0.00470922
Epoch [253/300], Train Loss: 0.005520
Validation Loss: 0.00470826
Epoch [254/300], Train Loss: 0.005510
Validation Loss: 0.00470120
Epoch [255/300], Train Loss: 0.005502
Validation Loss: 0.00469509
Epoch [256/300], Train Loss: 0.005495
Validation Loss: 0.00470072
Epoch [257/300], Train Loss: 0.005497
Validation Loss: 0.00469301
Epoch [258/300], Train Loss: 0.005489
Validation Loss: 0.00470940
Epoch [259/300], Train Loss: 0.005502
Validation Loss: 0.00469892
Epoch [260/300], Train Loss: 0.005500
Validation Loss: 0.00468687
Epoch [261/300], Train Loss: 0.005491
Validation Loss: 0.00468654
Epoch [262/300], Train Loss: 0.005489
Validation Loss: 0.00468357
Epoch [263/300], Train Loss: 0.005478
Validation Loss: 0.00470504
Epoch [264/300], Train Loss: 0.005490
Validation Loss: 0.00468077
Epoch [265/300], Train Loss: 0.005485
Validation Loss: 0.00468347
Epoch [266/300], Train Loss: 0.005492
Validation Loss: 0.00468631
Epoch [267/300], Train Loss: 0.005506
Validation Loss: 0.00467741
Epoch [268/300], Train Loss: 0.005471
Validation Loss: 0.00475118
Epoch [269/300], Train Loss: 0.005478
Validation Loss: 0.00467100
Epoch [270/300], Train Loss: 0.005475
Validation Loss: 0.00466866
Epoch [271/300], Train Loss: 0.005477
Validation Loss: 0.00469030
Epoch [272/300], Train Loss: 0.005459
Validation Loss: 0.00466621
Epoch [273/300], Train Loss: 0.005517
Validation Loss: 0.00467485
Epoch [274/300], Train Loss: 0.005476
Validation Loss: 0.00470952
Epoch [275/300], Train Loss: 0.005473
Validation Loss: 0.00466362
Epoch [276/300], Train Loss: 0.005461
Validation Loss: 0.00466604
Epoch [277/300], Train Loss: 0.005464
Validation Loss: 0.00466157
Epoch [278/300], Train Loss: 0.005474
Validation Loss: 0.00469212
Epoch [279/300], Train Loss: 0.005461
Validation Loss: 0.00465807
Epoch [280/300], Train Loss: 0.005471
Validation Loss: 0.00465645
Epoch [281/300], Train Loss: 0.005448
Validation Loss: 0.00466391
Epoch [282/300], Train Loss: 0.005448
Validation Loss: 0.00465267
Epoch [283/300], Train Loss: 0.005449
Validation Loss: 0.00466621
Epoch [284/300], Train Loss: 0.005426
Validation Loss: 0.00465043
Epoch [285/300], Train Loss: 0.005452
Validation Loss: 0.00465438
Epoch [286/300], Train Loss: 0.005453
Validation Loss: 0.00464996
Epoch [287/300], Train Loss: 0.005441
Validation Loss: 0.00466451
Epoch [288/300], Train Loss: 0.005430
Validation Loss: 0.00464247
Epoch [289/300], Train Loss: 0.005426
Validation Loss: 0.00464792
Epoch [290/300], Train Loss: 0.005427
Validation Loss: 0.00464999
Epoch [291/300], Train Loss: 0.005428
Validation Loss: 0.00464106
Epoch [292/300], Train Loss: 0.005422
Validation Loss: 0.00465917
Epoch [293/300], Train Loss: 0.005435
Validation Loss: 0.00464573
Epoch [294/300], Train Loss: 0.005432
Validation Loss: 0.00463942
Epoch [295/300], Train Loss: 0.005417
Validation Loss: 0.00467572
Epoch [296/300], Train Loss: 0.005433
Validation Loss: 0.00463375
Epoch [297/300], Train Loss: 0.005430
Validation Loss: 0.00463834
Epoch [298/300], Train Loss: 0.005428
Validation Loss: 0.00465633
Epoch [299/300], Train Loss: 0.005415
Validation Loss: 0.00463427
Epoch [300/300], Train Loss: 0.005423
Validation Loss: 0.00463419

Evaluating model for: Router
Run 40/72 completed in 731.18 seconds with: {'MAE': np.float32(0.21192509), 'MSE': np.float32(0.07525161), 'RMSE': np.float32(0.27432027), 'SAE': np.float32(0.0010624942), 'NDE': np.float32(0.01372077)}

Run 41/72: hidden=256, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Router
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.088050
Validation Loss: 0.07880005
Epoch [2/300], Train Loss: 0.071686
Validation Loss: 0.06268948
Epoch [3/300], Train Loss: 0.055745
Validation Loss: 0.04646308
Epoch [4/300], Train Loss: 0.038424
Validation Loss: 0.02681863
Epoch [5/300], Train Loss: 0.017426
Validation Loss: 0.00656478
Epoch [6/300], Train Loss: 0.008273
Validation Loss: 0.00872862
Epoch [7/300], Train Loss: 0.007113
Validation Loss: 0.00556417
Epoch [8/300], Train Loss: 0.006534
Validation Loss: 0.00628636
Epoch [9/300], Train Loss: 0.006263
Validation Loss: 0.00521543
Epoch [10/300], Train Loss: 0.005829
Validation Loss: 0.00527925
Epoch [11/300], Train Loss: 0.005905
Validation Loss: 0.00515165
Epoch [12/300], Train Loss: 0.005765
Validation Loss: 0.00522909
Epoch [13/300], Train Loss: 0.005787
Validation Loss: 0.00516192
Epoch [14/300], Train Loss: 0.005770
Validation Loss: 0.00514397
Epoch [15/300], Train Loss: 0.005737
Validation Loss: 0.00514833
Epoch [16/300], Train Loss: 0.005767
Validation Loss: 0.00516485
Epoch [17/300], Train Loss: 0.005717
Validation Loss: 0.00515111
Epoch [18/300], Train Loss: 0.005732
Validation Loss: 0.00513989
Epoch [19/300], Train Loss: 0.005733
Validation Loss: 0.00514439
Epoch [20/300], Train Loss: 0.005764
Validation Loss: 0.00514574
Epoch [21/300], Train Loss: 0.005770
Validation Loss: 0.00514037
Epoch [22/300], Train Loss: 0.005750
Validation Loss: 0.00514400
Epoch [23/300], Train Loss: 0.005736
Validation Loss: 0.00513802
Epoch [24/300], Train Loss: 0.005751
Validation Loss: 0.00513298
Epoch [25/300], Train Loss: 0.005724
Validation Loss: 0.00514562
Epoch [26/300], Train Loss: 0.005735
Validation Loss: 0.00513691
Epoch [27/300], Train Loss: 0.005701
Validation Loss: 0.00512916
Epoch [28/300], Train Loss: 0.005693
Validation Loss: 0.00513666
Epoch [29/300], Train Loss: 0.005704
Validation Loss: 0.00513318
Epoch [30/300], Train Loss: 0.005682
Validation Loss: 0.00512804
Epoch [31/300], Train Loss: 0.005696
Validation Loss: 0.00512791
Epoch [32/300], Train Loss: 0.005712
Validation Loss: 0.00513164
Epoch [33/300], Train Loss: 0.005699
Validation Loss: 0.00513402
Epoch [34/300], Train Loss: 0.005693
Validation Loss: 0.00512096
Epoch [35/300], Train Loss: 0.005687
Validation Loss: 0.00512079
Epoch [36/300], Train Loss: 0.005663
Validation Loss: 0.00513104
Epoch [37/300], Train Loss: 0.005677
Validation Loss: 0.00511897
Epoch [38/300], Train Loss: 0.005685
Validation Loss: 0.00511603
Epoch [39/300], Train Loss: 0.005703
Validation Loss: 0.00512838
Epoch [40/300], Train Loss: 0.005724
Validation Loss: 0.00512053
Epoch [41/300], Train Loss: 0.005688
Validation Loss: 0.00511812
Epoch [42/300], Train Loss: 0.005690
Validation Loss: 0.00511669
Epoch [43/300], Train Loss: 0.005668
Validation Loss: 0.00511204
Epoch [44/300], Train Loss: 0.005682
Validation Loss: 0.00511281
Epoch [45/300], Train Loss: 0.005670
Validation Loss: 0.00512623
Epoch [46/300], Train Loss: 0.005670
Validation Loss: 0.00511029
Epoch [47/300], Train Loss: 0.005686
Validation Loss: 0.00510847
Epoch [48/300], Train Loss: 0.005652
Validation Loss: 0.00512017
Epoch [49/300], Train Loss: 0.005649
Validation Loss: 0.00510522
Epoch [50/300], Train Loss: 0.005670
Validation Loss: 0.00510912
Epoch [51/300], Train Loss: 0.005690
Validation Loss: 0.00511121
Epoch [52/300], Train Loss: 0.005639
Validation Loss: 0.00511267
Epoch [53/300], Train Loss: 0.005653
Validation Loss: 0.00510638
Epoch [54/300], Train Loss: 0.005649
Validation Loss: 0.00510198
Epoch [55/300], Train Loss: 0.005666
Validation Loss: 0.00511473
Epoch [56/300], Train Loss: 0.005669
Validation Loss: 0.00510678
Epoch [57/300], Train Loss: 0.005641
Validation Loss: 0.00510204
Epoch [58/300], Train Loss: 0.005675
Validation Loss: 0.00510542
Epoch [59/300], Train Loss: 0.005640
Validation Loss: 0.00509934
Epoch [60/300], Train Loss: 0.005660
Validation Loss: 0.00510523
Epoch [61/300], Train Loss: 0.005670
Validation Loss: 0.00510204
Epoch [62/300], Train Loss: 0.005647
Validation Loss: 0.00510459
Epoch [63/300], Train Loss: 0.005655
Validation Loss: 0.00509825
Epoch [64/300], Train Loss: 0.005646
Validation Loss: 0.00509997
Epoch [65/300], Train Loss: 0.005667
Validation Loss: 0.00509800
Epoch [66/300], Train Loss: 0.005655
Validation Loss: 0.00509813
Epoch [67/300], Train Loss: 0.005663
Validation Loss: 0.00509767
Epoch [68/300], Train Loss: 0.005663
Validation Loss: 0.00510751
Epoch [69/300], Train Loss: 0.005671
Validation Loss: 0.00509155
Epoch [70/300], Train Loss: 0.005694
Validation Loss: 0.00509159
Epoch [71/300], Train Loss: 0.005656
Validation Loss: 0.00511771
Epoch [72/300], Train Loss: 0.005673
Validation Loss: 0.00509338
Epoch [73/300], Train Loss: 0.005650
Validation Loss: 0.00508963
Epoch [74/300], Train Loss: 0.005618
Validation Loss: 0.00509769
Epoch [75/300], Train Loss: 0.005681
Validation Loss: 0.00509612
Epoch [76/300], Train Loss: 0.005604
Validation Loss: 0.00508681
Epoch [77/300], Train Loss: 0.005662
Validation Loss: 0.00509023
Epoch [78/300], Train Loss: 0.005612
Validation Loss: 0.00508772
Epoch [79/300], Train Loss: 0.005673
Validation Loss: 0.00509636
Epoch [80/300], Train Loss: 0.005634
Validation Loss: 0.00508416
Epoch [81/300], Train Loss: 0.005652
Validation Loss: 0.00508661
Epoch [82/300], Train Loss: 0.005639
Validation Loss: 0.00509241
Epoch [83/300], Train Loss: 0.005636
Validation Loss: 0.00508409
Epoch [84/300], Train Loss: 0.005602
Validation Loss: 0.00508230
Epoch [85/300], Train Loss: 0.005659
Validation Loss: 0.00508451
Epoch [86/300], Train Loss: 0.005628
Validation Loss: 0.00509145
Epoch [87/300], Train Loss: 0.005606
Validation Loss: 0.00507788
Epoch [88/300], Train Loss: 0.005655
Validation Loss: 0.00507974
Epoch [89/300], Train Loss: 0.005638
Validation Loss: 0.00510370
Epoch [90/300], Train Loss: 0.005620
Validation Loss: 0.00508030
Epoch [91/300], Train Loss: 0.005598
Validation Loss: 0.00507501
Epoch [92/300], Train Loss: 0.005622
Validation Loss: 0.00509465
Epoch [93/300], Train Loss: 0.005595
Validation Loss: 0.00507970
Epoch [94/300], Train Loss: 0.005627
Validation Loss: 0.00507307
Epoch [95/300], Train Loss: 0.005595
Validation Loss: 0.00508723
Epoch [96/300], Train Loss: 0.005667
Validation Loss: 0.00507957
Epoch [97/300], Train Loss: 0.005623
Validation Loss: 0.00507221
Epoch [98/300], Train Loss: 0.005606
Validation Loss: 0.00507652
Epoch [99/300], Train Loss: 0.005618
Validation Loss: 0.00507403
Epoch [100/300], Train Loss: 0.005586
Validation Loss: 0.00507486
Epoch [101/300], Train Loss: 0.005618
Validation Loss: 0.00507064
Epoch [102/300], Train Loss: 0.005605
Validation Loss: 0.00507290
Epoch [103/300], Train Loss: 0.005607
Validation Loss: 0.00507504
Epoch [104/300], Train Loss: 0.005625
Validation Loss: 0.00506618
Epoch [105/300], Train Loss: 0.005597
Validation Loss: 0.00507255
Epoch [106/300], Train Loss: 0.005621
Validation Loss: 0.00507265
Epoch [107/300], Train Loss: 0.005597
Validation Loss: 0.00506668
Epoch [108/300], Train Loss: 0.005619
Validation Loss: 0.00507090
Epoch [109/300], Train Loss: 0.005593
Validation Loss: 0.00506456
Epoch [110/300], Train Loss: 0.005603
Validation Loss: 0.00506668
Epoch [111/300], Train Loss: 0.005618
Validation Loss: 0.00506567
Epoch [112/300], Train Loss: 0.005595
Validation Loss: 0.00507242
Epoch [113/300], Train Loss: 0.005612
Validation Loss: 0.00506358
Epoch [114/300], Train Loss: 0.005636
Validation Loss: 0.00505980
Epoch [115/300], Train Loss: 0.005589
Validation Loss: 0.00507496
Epoch [116/300], Train Loss: 0.005593
Validation Loss: 0.00506388
Epoch [117/300], Train Loss: 0.005583
Validation Loss: 0.00505729
Epoch [118/300], Train Loss: 0.005602
Validation Loss: 0.00507000
Epoch [119/300], Train Loss: 0.005589
Validation Loss: 0.00506007
Epoch [120/300], Train Loss: 0.005609
Validation Loss: 0.00505472
Epoch [121/300], Train Loss: 0.005614
Validation Loss: 0.00506964
Epoch [122/300], Train Loss: 0.005604
Validation Loss: 0.00506348
Epoch [123/300], Train Loss: 0.005587
Validation Loss: 0.00505563
Epoch [124/300], Train Loss: 0.005583
Validation Loss: 0.00505535
Epoch [125/300], Train Loss: 0.005583
Validation Loss: 0.00506391
Epoch [126/300], Train Loss: 0.005575
Validation Loss: 0.00505706
Epoch [127/300], Train Loss: 0.005598
Validation Loss: 0.00505049
Epoch [128/300], Train Loss: 0.005625
Validation Loss: 0.00506080
Epoch [129/300], Train Loss: 0.005576
Validation Loss: 0.00505743
Epoch [130/300], Train Loss: 0.005587
Validation Loss: 0.00504997
Epoch [131/300], Train Loss: 0.005596
Validation Loss: 0.00505283
Epoch [132/300], Train Loss: 0.005579
Validation Loss: 0.00505640
Epoch [133/300], Train Loss: 0.005574
Validation Loss: 0.00505319
Epoch [134/300], Train Loss: 0.005575
Validation Loss: 0.00504808
Epoch [135/300], Train Loss: 0.005571
Validation Loss: 0.00504751
Epoch [136/300], Train Loss: 0.005554
Validation Loss: 0.00505174
Epoch [137/300], Train Loss: 0.005586
Validation Loss: 0.00504899
Epoch [138/300], Train Loss: 0.005573
Validation Loss: 0.00505813
Epoch [139/300], Train Loss: 0.005578
Validation Loss: 0.00504409
Epoch [140/300], Train Loss: 0.005571
Validation Loss: 0.00504775
Epoch [141/300], Train Loss: 0.005571
Validation Loss: 0.00505110
Epoch [142/300], Train Loss: 0.005595
Validation Loss: 0.00504363
Epoch [143/300], Train Loss: 0.005567
Validation Loss: 0.00505168
Epoch [144/300], Train Loss: 0.005542
Validation Loss: 0.00504324
Epoch [145/300], Train Loss: 0.005559
Validation Loss: 0.00504756
Epoch [146/300], Train Loss: 0.005570
Validation Loss: 0.00504730
Epoch [147/300], Train Loss: 0.005574
Validation Loss: 0.00503997
Epoch [148/300], Train Loss: 0.005595
Validation Loss: 0.00504127
Epoch [149/300], Train Loss: 0.005576
Validation Loss: 0.00505300
Epoch [150/300], Train Loss: 0.005558
Validation Loss: 0.00504081
Epoch [151/300], Train Loss: 0.005560
Validation Loss: 0.00503844
Epoch [152/300], Train Loss: 0.005574
Validation Loss: 0.00504376
Epoch [153/300], Train Loss: 0.005548
Validation Loss: 0.00504226
Epoch [154/300], Train Loss: 0.005537
Validation Loss: 0.00503890
Epoch [155/300], Train Loss: 0.005578
Validation Loss: 0.00503954
Epoch [156/300], Train Loss: 0.005589
Validation Loss: 0.00503903
Epoch [157/300], Train Loss: 0.005574
Validation Loss: 0.00504007
Epoch [158/300], Train Loss: 0.005545
Validation Loss: 0.00503835
Epoch [159/300], Train Loss: 0.005551
Validation Loss: 0.00503642
Epoch [160/300], Train Loss: 0.005567
Validation Loss: 0.00503672
Epoch [161/300], Train Loss: 0.005567
Validation Loss: 0.00503972
Epoch [162/300], Train Loss: 0.005543
Validation Loss: 0.00503937
Epoch [163/300], Train Loss: 0.005580
Validation Loss: 0.00503184
Epoch [164/300], Train Loss: 0.005597
Validation Loss: 0.00504201
Epoch [165/300], Train Loss: 0.005568
Validation Loss: 0.00503013
Epoch [166/300], Train Loss: 0.005567
Validation Loss: 0.00504237
Epoch [167/300], Train Loss: 0.005553
Validation Loss: 0.00503508
Epoch [168/300], Train Loss: 0.005546
Validation Loss: 0.00503212
Epoch [169/300], Train Loss: 0.005524
Validation Loss: 0.00502902
Epoch [170/300], Train Loss: 0.005578
Validation Loss: 0.00503328
Epoch [171/300], Train Loss: 0.005551
Validation Loss: 0.00503305
Epoch [172/300], Train Loss: 0.005582
Validation Loss: 0.00503042
Epoch [173/300], Train Loss: 0.005541
Validation Loss: 0.00503565
Epoch [174/300], Train Loss: 0.005567
Validation Loss: 0.00502781
Epoch [175/300], Train Loss: 0.005566
Validation Loss: 0.00503607
Epoch [176/300], Train Loss: 0.005570
Validation Loss: 0.00502765
Epoch [177/300], Train Loss: 0.005559
Validation Loss: 0.00502958
Epoch [178/300], Train Loss: 0.005571
Validation Loss: 0.00503025
Epoch [179/300], Train Loss: 0.005588
Validation Loss: 0.00502904
Epoch [180/300], Train Loss: 0.005540
Validation Loss: 0.00502824
Epoch [181/300], Train Loss: 0.005565
Validation Loss: 0.00502723
Epoch [182/300], Train Loss: 0.005545
Validation Loss: 0.00502621
Epoch [183/300], Train Loss: 0.005534
Validation Loss: 0.00502661
Epoch [184/300], Train Loss: 0.005543
Validation Loss: 0.00503206
Epoch [185/300], Train Loss: 0.005561
Validation Loss: 0.00502472
Epoch [186/300], Train Loss: 0.005589
Validation Loss: 0.00502216
Epoch [187/300], Train Loss: 0.005559
Validation Loss: 0.00503078
Epoch [188/300], Train Loss: 0.005520
Validation Loss: 0.00502760
Epoch [189/300], Train Loss: 0.005582
Validation Loss: 0.00502071
Epoch [190/300], Train Loss: 0.005510
Validation Loss: 0.00502109
Epoch [191/300], Train Loss: 0.005542
Validation Loss: 0.00502595
Epoch [192/300], Train Loss: 0.005527
Validation Loss: 0.00502385
Epoch [193/300], Train Loss: 0.005562
Validation Loss: 0.00502346
Epoch [194/300], Train Loss: 0.005517
Validation Loss: 0.00502291
Epoch [195/300], Train Loss: 0.005538
Validation Loss: 0.00502151
Epoch [196/300], Train Loss: 0.005578
Validation Loss: 0.00502725
Epoch [197/300], Train Loss: 0.005574
Validation Loss: 0.00501841
Epoch [198/300], Train Loss: 0.005542
Validation Loss: 0.00501899
Epoch [199/300], Train Loss: 0.005524
Validation Loss: 0.00502478
Epoch [200/300], Train Loss: 0.005571
Validation Loss: 0.00501921
Epoch [201/300], Train Loss: 0.005542
Validation Loss: 0.00501816
Epoch [202/300], Train Loss: 0.005524
Validation Loss: 0.00502422
Epoch [203/300], Train Loss: 0.005535
Validation Loss: 0.00501512
Epoch [204/300], Train Loss: 0.005533
Validation Loss: 0.00501647
Epoch [205/300], Train Loss: 0.005560
Validation Loss: 0.00502301
Epoch [206/300], Train Loss: 0.005540
Validation Loss: 0.00502577
Epoch [207/300], Train Loss: 0.005544
Validation Loss: 0.00501357
Epoch [208/300], Train Loss: 0.005623
Validation Loss: 0.00501210
Epoch [209/300], Train Loss: 0.005543
Validation Loss: 0.00503263
Epoch [210/300], Train Loss: 0.005527
Validation Loss: 0.00501980
Epoch [211/300], Train Loss: 0.005561
Validation Loss: 0.00501115
Epoch [212/300], Train Loss: 0.005545
Validation Loss: 0.00501299
Epoch [213/300], Train Loss: 0.005537
Validation Loss: 0.00501997
Epoch [214/300], Train Loss: 0.005510
Validation Loss: 0.00501472
Epoch [215/300], Train Loss: 0.005525
Validation Loss: 0.00501296
Epoch [216/300], Train Loss: 0.005584
Validation Loss: 0.00501108
Epoch [217/300], Train Loss: 0.005551
Validation Loss: 0.00502110
Epoch [218/300], Train Loss: 0.005544
Validation Loss: 0.00501278
Epoch [219/300], Train Loss: 0.005542
Validation Loss: 0.00501102
Epoch [220/300], Train Loss: 0.005546
Validation Loss: 0.00502061
Epoch [221/300], Train Loss: 0.005541
Validation Loss: 0.00501068
Epoch [222/300], Train Loss: 0.005536
Validation Loss: 0.00501048
Epoch [223/300], Train Loss: 0.005521
Validation Loss: 0.00501021
Epoch [224/300], Train Loss: 0.005540
Validation Loss: 0.00501502
Epoch [225/300], Train Loss: 0.005531
Validation Loss: 0.00501016
Epoch [226/300], Train Loss: 0.005536
Validation Loss: 0.00501045
Epoch [227/300], Train Loss: 0.005528
Validation Loss: 0.00500813
Epoch [228/300], Train Loss: 0.005535
Validation Loss: 0.00500814
Epoch [229/300], Train Loss: 0.005518
Validation Loss: 0.00502095
Epoch [230/300], Train Loss: 0.005522
Validation Loss: 0.00501182
Epoch [231/300], Train Loss: 0.005541
Validation Loss: 0.00500417
Epoch [232/300], Train Loss: 0.005547
Validation Loss: 0.00500878
Epoch [233/300], Train Loss: 0.005527
Validation Loss: 0.00501868
Epoch [234/300], Train Loss: 0.005545
Validation Loss: 0.00500848
Epoch [235/300], Train Loss: 0.005512
Validation Loss: 0.00500389
Epoch [236/300], Train Loss: 0.005540
Validation Loss: 0.00501119
Epoch [237/300], Train Loss: 0.005513
Validation Loss: 0.00500748
Epoch [238/300], Train Loss: 0.005570
Validation Loss: 0.00500284
Epoch [239/300], Train Loss: 0.005573
Validation Loss: 0.00500664
Epoch [240/300], Train Loss: 0.005513
Validation Loss: 0.00501609
Epoch [241/300], Train Loss: 0.005507
Validation Loss: 0.00500570
Epoch [242/300], Train Loss: 0.005513
Validation Loss: 0.00500313
Epoch [243/300], Train Loss: 0.005546
Validation Loss: 0.00500381
Epoch [244/300], Train Loss: 0.005499
Validation Loss: 0.00500379
Epoch [245/300], Train Loss: 0.005530
Validation Loss: 0.00500641
Epoch [246/300], Train Loss: 0.005540
Validation Loss: 0.00500321
Epoch [247/300], Train Loss: 0.005533
Validation Loss: 0.00500836
Epoch [248/300], Train Loss: 0.005515
Validation Loss: 0.00500240
Epoch [249/300], Train Loss: 0.005532
Validation Loss: 0.00500349
Epoch [250/300], Train Loss: 0.005528
Validation Loss: 0.00500363
Epoch [251/300], Train Loss: 0.005522
Validation Loss: 0.00500145
Epoch [252/300], Train Loss: 0.005490
Validation Loss: 0.00500315
Epoch [253/300], Train Loss: 0.005522
Validation Loss: 0.00500364
Epoch [254/300], Train Loss: 0.005497
Validation Loss: 0.00500375
Epoch [255/300], Train Loss: 0.005557
Validation Loss: 0.00500448
Epoch [256/300], Train Loss: 0.005497
Validation Loss: 0.00500210
Epoch [257/300], Train Loss: 0.005551
Validation Loss: 0.00499953
Epoch [258/300], Train Loss: 0.005512
Validation Loss: 0.00500292
Epoch [259/300], Train Loss: 0.005522
Validation Loss: 0.00500278
Epoch [260/300], Train Loss: 0.005516
Validation Loss: 0.00500199
Epoch [261/300], Train Loss: 0.005497
Validation Loss: 0.00500067
Epoch [262/300], Train Loss: 0.005510
Validation Loss: 0.00500123
Epoch [263/300], Train Loss: 0.005545
Validation Loss: 0.00499872
Epoch [264/300], Train Loss: 0.005520
Validation Loss: 0.00500144
Epoch [265/300], Train Loss: 0.005523
Validation Loss: 0.00499872
Epoch [266/300], Train Loss: 0.005512
Validation Loss: 0.00499738
Epoch [267/300], Train Loss: 0.005539
Validation Loss: 0.00500532
Epoch [268/300], Train Loss: 0.005505
Validation Loss: 0.00499868
Epoch [269/300], Train Loss: 0.005535
Validation Loss: 0.00499598
Epoch [270/300], Train Loss: 0.005498
Validation Loss: 0.00499854
Epoch [271/300], Train Loss: 0.005484
Validation Loss: 0.00499796
Epoch [272/300], Train Loss: 0.005514
Validation Loss: 0.00499641
Epoch [273/300], Train Loss: 0.005508
Validation Loss: 0.00499897
Epoch [274/300], Train Loss: 0.005504
Validation Loss: 0.00499424
Epoch [275/300], Train Loss: 0.005509
Validation Loss: 0.00499496
Epoch [276/300], Train Loss: 0.005486
Validation Loss: 0.00499697
Epoch [277/300], Train Loss: 0.005506
Validation Loss: 0.00499751
Epoch [278/300], Train Loss: 0.005499
Validation Loss: 0.00499753
Epoch [279/300], Train Loss: 0.005478
Validation Loss: 0.00499378
Epoch [280/300], Train Loss: 0.005505
Validation Loss: 0.00499372
Epoch [281/300], Train Loss: 0.005508
Validation Loss: 0.00499844
Epoch [282/300], Train Loss: 0.005517
Validation Loss: 0.00499345
Epoch [283/300], Train Loss: 0.005509
Validation Loss: 0.00499389
Epoch [284/300], Train Loss: 0.005542
Validation Loss: 0.00499589
Epoch [285/300], Train Loss: 0.005503
Validation Loss: 0.00499756
Epoch [286/300], Train Loss: 0.005507
Validation Loss: 0.00499326
Epoch [287/300], Train Loss: 0.005526
Validation Loss: 0.00499125
Epoch [288/300], Train Loss: 0.005495
Validation Loss: 0.00499577
Epoch [289/300], Train Loss: 0.005512
Validation Loss: 0.00499537
Epoch [290/300], Train Loss: 0.005530
Validation Loss: 0.00499299
Epoch [291/300], Train Loss: 0.005505
Validation Loss: 0.00499302
Epoch [292/300], Train Loss: 0.005489
Validation Loss: 0.00499615
Epoch [293/300], Train Loss: 0.005504
Validation Loss: 0.00499250
Epoch [294/300], Train Loss: 0.005511
Validation Loss: 0.00499639
Epoch [295/300], Train Loss: 0.005497
Validation Loss: 0.00498961
Epoch [296/300], Train Loss: 0.005525
Validation Loss: 0.00498825
Epoch [297/300], Train Loss: 0.005492
Validation Loss: 0.00499388
Epoch [298/300], Train Loss: 0.005505
Validation Loss: 0.00499768
Epoch [299/300], Train Loss: 0.005487
Validation Loss: 0.00499261
Epoch [300/300], Train Loss: 0.005504
Validation Loss: 0.00498958

Evaluating model for: Router
Run 41/72 completed in 545.88 seconds with: {'MAE': np.float32(0.20765953), 'MSE': np.float32(0.077595115), 'RMSE': np.float32(0.278559), 'SAE': np.float32(0.0001320564), 'NDE': np.float32(0.0139248)}

Run 42/72: hidden=256, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Router
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.112888
Validation Loss: 0.10293312
Epoch [2/300], Train Loss: 0.095097
Validation Loss: 0.08491768
Epoch [3/300], Train Loss: 0.075983
Validation Loss: 0.06333531
Epoch [4/300], Train Loss: 0.051138
Validation Loss: 0.03262713
Epoch [5/300], Train Loss: 0.017388
Validation Loss: 0.00717545
Epoch [6/300], Train Loss: 0.011326
Validation Loss: 0.00545856
Epoch [7/300], Train Loss: 0.007037
Validation Loss: 0.00793109
Epoch [8/300], Train Loss: 0.007569
Validation Loss: 0.00567580
Epoch [9/300], Train Loss: 0.006120
Validation Loss: 0.00567121
Epoch [10/300], Train Loss: 0.006239
Validation Loss: 0.00529663
Epoch [11/300], Train Loss: 0.006058
Validation Loss: 0.00550575
Epoch [12/300], Train Loss: 0.005985
Validation Loss: 0.00529387
Epoch [13/300], Train Loss: 0.005982
Validation Loss: 0.00529643
Epoch [14/300], Train Loss: 0.005955
Validation Loss: 0.00531826
Epoch [15/300], Train Loss: 0.005920
Validation Loss: 0.00530557
Epoch [16/300], Train Loss: 0.005954
Validation Loss: 0.00528773
Epoch [17/300], Train Loss: 0.005899
Validation Loss: 0.00528907
Epoch [18/300], Train Loss: 0.005916
Validation Loss: 0.00529011
Epoch [19/300], Train Loss: 0.005914
Validation Loss: 0.00528939
Epoch [20/300], Train Loss: 0.005945
Validation Loss: 0.00528425
Epoch [21/300], Train Loss: 0.005954
Validation Loss: 0.00528485
Epoch [22/300], Train Loss: 0.005936
Validation Loss: 0.00529166
Epoch [23/300], Train Loss: 0.005918
Validation Loss: 0.00527938
Epoch [24/300], Train Loss: 0.005933
Validation Loss: 0.00527797
Epoch [25/300], Train Loss: 0.005909
Validation Loss: 0.00529438
Epoch [26/300], Train Loss: 0.005917
Validation Loss: 0.00527672
Epoch [27/300], Train Loss: 0.005888
Validation Loss: 0.00527379
Epoch [28/300], Train Loss: 0.005882
Validation Loss: 0.00528637
Epoch [29/300], Train Loss: 0.005888
Validation Loss: 0.00527341
Epoch [30/300], Train Loss: 0.005871
Validation Loss: 0.00527238
Epoch [31/300], Train Loss: 0.005881
Validation Loss: 0.00527503
Epoch [32/300], Train Loss: 0.005900
Validation Loss: 0.00527369
Epoch [33/300], Train Loss: 0.005880
Validation Loss: 0.00527530
Epoch [34/300], Train Loss: 0.005880
Validation Loss: 0.00526493
Epoch [35/300], Train Loss: 0.005883
Validation Loss: 0.00526627
Epoch [36/300], Train Loss: 0.005848
Validation Loss: 0.00527316
Epoch [37/300], Train Loss: 0.005865
Validation Loss: 0.00526031
Epoch [38/300], Train Loss: 0.005868
Validation Loss: 0.00526073
Epoch [39/300], Train Loss: 0.005893
Validation Loss: 0.00527260
Epoch [40/300], Train Loss: 0.005911
Validation Loss: 0.00525965
Epoch [41/300], Train Loss: 0.005882
Validation Loss: 0.00526201
Epoch [42/300], Train Loss: 0.005876
Validation Loss: 0.00525830
Epoch [43/300], Train Loss: 0.005858
Validation Loss: 0.00525263
Epoch [44/300], Train Loss: 0.005869
Validation Loss: 0.00525675
Epoch [45/300], Train Loss: 0.005864
Validation Loss: 0.00526633
Epoch [46/300], Train Loss: 0.005857
Validation Loss: 0.00524875
Epoch [47/300], Train Loss: 0.005867
Validation Loss: 0.00525088
Epoch [48/300], Train Loss: 0.005844
Validation Loss: 0.00526015
Epoch [49/300], Train Loss: 0.005836
Validation Loss: 0.00524463
Epoch [50/300], Train Loss: 0.005859
Validation Loss: 0.00525305
Epoch [51/300], Train Loss: 0.005879
Validation Loss: 0.00524875
Epoch [52/300], Train Loss: 0.005819
Validation Loss: 0.00524809
Epoch [53/300], Train Loss: 0.005840
Validation Loss: 0.00524477
Epoch [54/300], Train Loss: 0.005833
Validation Loss: 0.00523998
Epoch [55/300], Train Loss: 0.005848
Validation Loss: 0.00525270
Epoch [56/300], Train Loss: 0.005849
Validation Loss: 0.00524165
Epoch [57/300], Train Loss: 0.005822
Validation Loss: 0.00523884
Epoch [58/300], Train Loss: 0.005854
Validation Loss: 0.00524079
Epoch [59/300], Train Loss: 0.005823
Validation Loss: 0.00523390
Epoch [60/300], Train Loss: 0.005842
Validation Loss: 0.00524308
Epoch [61/300], Train Loss: 0.005855
Validation Loss: 0.00523500
Epoch [62/300], Train Loss: 0.005832
Validation Loss: 0.00523886
Epoch [63/300], Train Loss: 0.005838
Validation Loss: 0.00523248
Epoch [64/300], Train Loss: 0.005827
Validation Loss: 0.00523385
Epoch [65/300], Train Loss: 0.005846
Validation Loss: 0.00522959
Epoch [66/300], Train Loss: 0.005834
Validation Loss: 0.00523081
Epoch [67/300], Train Loss: 0.005849
Validation Loss: 0.00523080
Epoch [68/300], Train Loss: 0.005841
Validation Loss: 0.00523725
Epoch [69/300], Train Loss: 0.005848
Validation Loss: 0.00522174
Epoch [70/300], Train Loss: 0.005870
Validation Loss: 0.00522497
Epoch [71/300], Train Loss: 0.005838
Validation Loss: 0.00524873
Epoch [72/300], Train Loss: 0.005850
Validation Loss: 0.00521926
Epoch [73/300], Train Loss: 0.005826
Validation Loss: 0.00522219
Epoch [74/300], Train Loss: 0.005794
Validation Loss: 0.00522800
Epoch [75/300], Train Loss: 0.005859
Validation Loss: 0.00521957
Epoch [76/300], Train Loss: 0.005787
Validation Loss: 0.00521498
Epoch [77/300], Train Loss: 0.005835
Validation Loss: 0.00522030
Epoch [78/300], Train Loss: 0.005791
Validation Loss: 0.00521296
Epoch [79/300], Train Loss: 0.005854
Validation Loss: 0.00522389
Epoch [80/300], Train Loss: 0.005800
Validation Loss: 0.00520922
Epoch [81/300], Train Loss: 0.005824
Validation Loss: 0.00521438
Epoch [82/300], Train Loss: 0.005813
Validation Loss: 0.00521636
Epoch [83/300], Train Loss: 0.005809
Validation Loss: 0.00520669
Epoch [84/300], Train Loss: 0.005778
Validation Loss: 0.00520844
Epoch [85/300], Train Loss: 0.005824
Validation Loss: 0.00521001
Epoch [86/300], Train Loss: 0.005794
Validation Loss: 0.00521096
Epoch [87/300], Train Loss: 0.005777
Validation Loss: 0.00520016
Epoch [88/300], Train Loss: 0.005827
Validation Loss: 0.00520901
Epoch [89/300], Train Loss: 0.005808
Validation Loss: 0.00522305
Epoch [90/300], Train Loss: 0.005783
Validation Loss: 0.00519752
Epoch [91/300], Train Loss: 0.005768
Validation Loss: 0.00519729
Epoch [92/300], Train Loss: 0.005800
Validation Loss: 0.00522341
Epoch [93/300], Train Loss: 0.005764
Validation Loss: 0.00519474
Epoch [94/300], Train Loss: 0.005801
Validation Loss: 0.00519350
Epoch [95/300], Train Loss: 0.005763
Validation Loss: 0.00521562
Epoch [96/300], Train Loss: 0.005829
Validation Loss: 0.00519235
Epoch [97/300], Train Loss: 0.005788
Validation Loss: 0.00519121
Epoch [98/300], Train Loss: 0.005767
Validation Loss: 0.00520010
Epoch [99/300], Train Loss: 0.005786
Validation Loss: 0.00518879
Epoch [100/300], Train Loss: 0.005749
Validation Loss: 0.00519282
Epoch [101/300], Train Loss: 0.005782
Validation Loss: 0.00518845
Epoch [102/300], Train Loss: 0.005770
Validation Loss: 0.00518949
Epoch [103/300], Train Loss: 0.005771
Validation Loss: 0.00518961
Epoch [104/300], Train Loss: 0.005795
Validation Loss: 0.00518174
Epoch [105/300], Train Loss: 0.005760
Validation Loss: 0.00519261
Epoch [106/300], Train Loss: 0.005783
Validation Loss: 0.00518422
Epoch [107/300], Train Loss: 0.005759
Validation Loss: 0.00518100
Epoch [108/300], Train Loss: 0.005784
Validation Loss: 0.00518972
Epoch [109/300], Train Loss: 0.005760
Validation Loss: 0.00517739
Epoch [110/300], Train Loss: 0.005762
Validation Loss: 0.00518125
Epoch [111/300], Train Loss: 0.005772
Validation Loss: 0.00518005
Epoch [112/300], Train Loss: 0.005758
Validation Loss: 0.00518686
Epoch [113/300], Train Loss: 0.005773
Validation Loss: 0.00517423
Epoch [114/300], Train Loss: 0.005791
Validation Loss: 0.00517301
Epoch [115/300], Train Loss: 0.005746
Validation Loss: 0.00519355
Epoch [116/300], Train Loss: 0.005751
Validation Loss: 0.00517064
Epoch [117/300], Train Loss: 0.005739
Validation Loss: 0.00516951
Epoch [118/300], Train Loss: 0.005766
Validation Loss: 0.00518688
Epoch [119/300], Train Loss: 0.005743
Validation Loss: 0.00516678
Epoch [120/300], Train Loss: 0.005767
Validation Loss: 0.00516571
Epoch [121/300], Train Loss: 0.005772
Validation Loss: 0.00519114
Epoch [122/300], Train Loss: 0.005766
Validation Loss: 0.00516641
Epoch [123/300], Train Loss: 0.005739
Validation Loss: 0.00516585
Epoch [124/300], Train Loss: 0.005733
Validation Loss: 0.00516889
Epoch [125/300], Train Loss: 0.005738
Validation Loss: 0.00517065
Epoch [126/300], Train Loss: 0.005728
Validation Loss: 0.00516240
Epoch [127/300], Train Loss: 0.005755
Validation Loss: 0.00515938
Epoch [128/300], Train Loss: 0.005781
Validation Loss: 0.00517546
Epoch [129/300], Train Loss: 0.005734
Validation Loss: 0.00515933
Epoch [130/300], Train Loss: 0.005737
Validation Loss: 0.00515768
Epoch [131/300], Train Loss: 0.005745
Validation Loss: 0.00516431
Epoch [132/300], Train Loss: 0.005729
Validation Loss: 0.00515939
Epoch [133/300], Train Loss: 0.005722
Validation Loss: 0.00515761
Epoch [134/300], Train Loss: 0.005725
Validation Loss: 0.00515428
Epoch [135/300], Train Loss: 0.005716
Validation Loss: 0.00515357
Epoch [136/300], Train Loss: 0.005704
Validation Loss: 0.00515850
Epoch [137/300], Train Loss: 0.005743
Validation Loss: 0.00515308
Epoch [138/300], Train Loss: 0.005729
Validation Loss: 0.00516447
Epoch [139/300], Train Loss: 0.005725
Validation Loss: 0.00514758
Epoch [140/300], Train Loss: 0.005721
Validation Loss: 0.00515584
Epoch [141/300], Train Loss: 0.005719
Validation Loss: 0.00515360
Epoch [142/300], Train Loss: 0.005745
Validation Loss: 0.00514606
Epoch [143/300], Train Loss: 0.005716
Validation Loss: 0.00516135
Epoch [144/300], Train Loss: 0.005694
Validation Loss: 0.00514442
Epoch [145/300], Train Loss: 0.005704
Validation Loss: 0.00515140
Epoch [146/300], Train Loss: 0.005719
Validation Loss: 0.00514693
Epoch [147/300], Train Loss: 0.005722
Validation Loss: 0.00514088
Epoch [148/300], Train Loss: 0.005740
Validation Loss: 0.00514629
Epoch [149/300], Train Loss: 0.005725
Validation Loss: 0.00515395
Epoch [150/300], Train Loss: 0.005696
Validation Loss: 0.00513840
Epoch [151/300], Train Loss: 0.005705
Validation Loss: 0.00514100
Epoch [152/300], Train Loss: 0.005719
Validation Loss: 0.00514713
Epoch [153/300], Train Loss: 0.005688
Validation Loss: 0.00513806
Epoch [154/300], Train Loss: 0.005683
Validation Loss: 0.00513876
Epoch [155/300], Train Loss: 0.005718
Validation Loss: 0.00514039
Epoch [156/300], Train Loss: 0.005731
Validation Loss: 0.00513523
Epoch [157/300], Train Loss: 0.005718
Validation Loss: 0.00513758
Epoch [158/300], Train Loss: 0.005695
Validation Loss: 0.00513733
Epoch [159/300], Train Loss: 0.005694
Validation Loss: 0.00513370
Epoch [160/300], Train Loss: 0.005706
Validation Loss: 0.00513380
Epoch [161/300], Train Loss: 0.005704
Validation Loss: 0.00513727
Epoch [162/300], Train Loss: 0.005685
Validation Loss: 0.00513450
Epoch [163/300], Train Loss: 0.005719
Validation Loss: 0.00512778
Epoch [164/300], Train Loss: 0.005751
Validation Loss: 0.00514162
Epoch [165/300], Train Loss: 0.005712
Validation Loss: 0.00512637
Epoch [166/300], Train Loss: 0.005712
Validation Loss: 0.00514930
Epoch [167/300], Train Loss: 0.005687
Validation Loss: 0.00512697
Epoch [168/300], Train Loss: 0.005688
Validation Loss: 0.00512548
Epoch [169/300], Train Loss: 0.005674
Validation Loss: 0.00512480
Epoch [170/300], Train Loss: 0.005719
Validation Loss: 0.00512946
Epoch [171/300], Train Loss: 0.005691
Validation Loss: 0.00512481
Epoch [172/300], Train Loss: 0.005718
Validation Loss: 0.00512479
Epoch [173/300], Train Loss: 0.005682
Validation Loss: 0.00513115
Epoch [174/300], Train Loss: 0.005702
Validation Loss: 0.00511957
Epoch [175/300], Train Loss: 0.005702
Validation Loss: 0.00513298
Epoch [176/300], Train Loss: 0.005705
Validation Loss: 0.00511854
Epoch [177/300], Train Loss: 0.005690
Validation Loss: 0.00512421
Epoch [178/300], Train Loss: 0.005708
Validation Loss: 0.00512331
Epoch [179/300], Train Loss: 0.005727
Validation Loss: 0.00511829
Epoch [180/300], Train Loss: 0.005668
Validation Loss: 0.00511969
Epoch [181/300], Train Loss: 0.005697
Validation Loss: 0.00511895
Epoch [182/300], Train Loss: 0.005677
Validation Loss: 0.00511684
Epoch [183/300], Train Loss: 0.005664
Validation Loss: 0.00511752
Epoch [184/300], Train Loss: 0.005678
Validation Loss: 0.00512314
Epoch [185/300], Train Loss: 0.005689
Validation Loss: 0.00511279
Epoch [186/300], Train Loss: 0.005724
Validation Loss: 0.00511273
Epoch [187/300], Train Loss: 0.005692
Validation Loss: 0.00512633
Epoch [188/300], Train Loss: 0.005656
Validation Loss: 0.00511204
Epoch [189/300], Train Loss: 0.005723
Validation Loss: 0.00510909
Epoch [190/300], Train Loss: 0.005643
Validation Loss: 0.00511357
Epoch [191/300], Train Loss: 0.005674
Validation Loss: 0.00511377
Epoch [192/300], Train Loss: 0.005655
Validation Loss: 0.00510921
Epoch [193/300], Train Loss: 0.005689
Validation Loss: 0.00511383
Epoch [194/300], Train Loss: 0.005647
Validation Loss: 0.00511156
Epoch [195/300], Train Loss: 0.005667
Validation Loss: 0.00510821
Epoch [196/300], Train Loss: 0.005710
Validation Loss: 0.00511476
Epoch [197/300], Train Loss: 0.005706
Validation Loss: 0.00510390
Epoch [198/300], Train Loss: 0.005673
Validation Loss: 0.00510844
Epoch [199/300], Train Loss: 0.005653
Validation Loss: 0.00511369
Epoch [200/300], Train Loss: 0.005697
Validation Loss: 0.00510281
Epoch [201/300], Train Loss: 0.005670
Validation Loss: 0.00510508
Epoch [202/300], Train Loss: 0.005650
Validation Loss: 0.00511267
Epoch [203/300], Train Loss: 0.005669
Validation Loss: 0.00509891
Epoch [204/300], Train Loss: 0.005653
Validation Loss: 0.00510473
Epoch [205/300], Train Loss: 0.005682
Validation Loss: 0.00511060
Epoch [206/300], Train Loss: 0.005667
Validation Loss: 0.00510444
Epoch [207/300], Train Loss: 0.005672
Validation Loss: 0.00509623
Epoch [208/300], Train Loss: 0.005751
Validation Loss: 0.00509652
Epoch [209/300], Train Loss: 0.005676
Validation Loss: 0.00513038
Epoch [210/300], Train Loss: 0.005652
Validation Loss: 0.00509482
Epoch [211/300], Train Loss: 0.005687
Validation Loss: 0.00509373
Epoch [212/300], Train Loss: 0.005671
Validation Loss: 0.00510440
Epoch [213/300], Train Loss: 0.005658
Validation Loss: 0.00510150
Epoch [214/300], Train Loss: 0.005630
Validation Loss: 0.00509290
Epoch [215/300], Train Loss: 0.005653
Validation Loss: 0.00509762
Epoch [216/300], Train Loss: 0.005704
Validation Loss: 0.00509463
Epoch [217/300], Train Loss: 0.005677
Validation Loss: 0.00510298
Epoch [218/300], Train Loss: 0.005673
Validation Loss: 0.00509110
Epoch [219/300], Train Loss: 0.005661
Validation Loss: 0.00509493
Epoch [220/300], Train Loss: 0.005668
Validation Loss: 0.00510886
Epoch [221/300], Train Loss: 0.005661
Validation Loss: 0.00508852
Epoch [222/300], Train Loss: 0.005661
Validation Loss: 0.00509181
Epoch [223/300], Train Loss: 0.005643
Validation Loss: 0.00509408
Epoch [224/300], Train Loss: 0.005663
Validation Loss: 0.00509545
Epoch [225/300], Train Loss: 0.005652
Validation Loss: 0.00508720
Epoch [226/300], Train Loss: 0.005651
Validation Loss: 0.00509132
Epoch [227/300], Train Loss: 0.005648
Validation Loss: 0.00508909
Epoch [228/300], Train Loss: 0.005656
Validation Loss: 0.00508805
Epoch [229/300], Train Loss: 0.005637
Validation Loss: 0.00510463
Epoch [230/300], Train Loss: 0.005642
Validation Loss: 0.00508635
Epoch [231/300], Train Loss: 0.005663
Validation Loss: 0.00508360
Epoch [232/300], Train Loss: 0.005664
Validation Loss: 0.00509947
Epoch [233/300], Train Loss: 0.005654
Validation Loss: 0.00509787
Epoch [234/300], Train Loss: 0.005653
Validation Loss: 0.00508213
Epoch [235/300], Train Loss: 0.005634
Validation Loss: 0.00508259
Epoch [236/300], Train Loss: 0.005664
Validation Loss: 0.00509914
Epoch [237/300], Train Loss: 0.005633
Validation Loss: 0.00508269
Epoch [238/300], Train Loss: 0.005692
Validation Loss: 0.00508008
Epoch [239/300], Train Loss: 0.005686
Validation Loss: 0.00509162
Epoch [240/300], Train Loss: 0.005631
Validation Loss: 0.00509434
Epoch [241/300], Train Loss: 0.005622
Validation Loss: 0.00507874
Epoch [242/300], Train Loss: 0.005632
Validation Loss: 0.00508073
Epoch [243/300], Train Loss: 0.005660
Validation Loss: 0.00508419
Epoch [244/300], Train Loss: 0.005612
Validation Loss: 0.00507994
Epoch [245/300], Train Loss: 0.005643
Validation Loss: 0.00508199
Epoch [246/300], Train Loss: 0.005654
Validation Loss: 0.00507854
Epoch [247/300], Train Loss: 0.005651
Validation Loss: 0.00508834
Epoch [248/300], Train Loss: 0.005631
Validation Loss: 0.00507714
Epoch [249/300], Train Loss: 0.005645
Validation Loss: 0.00507946
Epoch [250/300], Train Loss: 0.005648
Validation Loss: 0.00508012
Epoch [251/300], Train Loss: 0.005633
Validation Loss: 0.00507669
Epoch [252/300], Train Loss: 0.005608
Validation Loss: 0.00507947
Epoch [253/300], Train Loss: 0.005640
Validation Loss: 0.00507917
Epoch [254/300], Train Loss: 0.005614
Validation Loss: 0.00507856
Epoch [255/300], Train Loss: 0.005671
Validation Loss: 0.00507952
Epoch [256/300], Train Loss: 0.005614
Validation Loss: 0.00507555
Epoch [257/300], Train Loss: 0.005671
Validation Loss: 0.00507385
Epoch [258/300], Train Loss: 0.005626
Validation Loss: 0.00508167
Epoch [259/300], Train Loss: 0.005636
Validation Loss: 0.00507681
Epoch [260/300], Train Loss: 0.005633
Validation Loss: 0.00507475
Epoch [261/300], Train Loss: 0.005610
Validation Loss: 0.00507463
Epoch [262/300], Train Loss: 0.005625
Validation Loss: 0.00507582
Epoch [263/300], Train Loss: 0.005656
Validation Loss: 0.00507149
Epoch [264/300], Train Loss: 0.005626
Validation Loss: 0.00507589
Epoch [265/300], Train Loss: 0.005633
Validation Loss: 0.00507167
Epoch [266/300], Train Loss: 0.005629
Validation Loss: 0.00507091
Epoch [267/300], Train Loss: 0.005651
Validation Loss: 0.00508166
Epoch [268/300], Train Loss: 0.005613
Validation Loss: 0.00506937
Epoch [269/300], Train Loss: 0.005650
Validation Loss: 0.00506880
Epoch [270/300], Train Loss: 0.005612
Validation Loss: 0.00507428
Epoch [271/300], Train Loss: 0.005593
Validation Loss: 0.00506998
Epoch [272/300], Train Loss: 0.005624
Validation Loss: 0.00506762
Epoch [273/300], Train Loss: 0.005625
Validation Loss: 0.00507271
Epoch [274/300], Train Loss: 0.005609
Validation Loss: 0.00506580
Epoch [275/300], Train Loss: 0.005622
Validation Loss: 0.00506813
Epoch [276/300], Train Loss: 0.005589
Validation Loss: 0.00507009
Epoch [277/300], Train Loss: 0.005616
Validation Loss: 0.00506845
Epoch [278/300], Train Loss: 0.005609
Validation Loss: 0.00506866
Epoch [279/300], Train Loss: 0.005589
Validation Loss: 0.00506497
Epoch [280/300], Train Loss: 0.005613
Validation Loss: 0.00506589
Epoch [281/300], Train Loss: 0.005619
Validation Loss: 0.00507197
Epoch [282/300], Train Loss: 0.005627
Validation Loss: 0.00506310
Epoch [283/300], Train Loss: 0.005616
Validation Loss: 0.00506563
Epoch [284/300], Train Loss: 0.005647
Validation Loss: 0.00506937
Epoch [285/300], Train Loss: 0.005610
Validation Loss: 0.00506807
Epoch [286/300], Train Loss: 0.005617
Validation Loss: 0.00506210
Epoch [287/300], Train Loss: 0.005628
Validation Loss: 0.00506206
Epoch [288/300], Train Loss: 0.005602
Validation Loss: 0.00507143
Epoch [289/300], Train Loss: 0.005618
Validation Loss: 0.00506546
Epoch [290/300], Train Loss: 0.005633
Validation Loss: 0.00506158
Epoch [291/300], Train Loss: 0.005616
Validation Loss: 0.00506345
Epoch [292/300], Train Loss: 0.005593
Validation Loss: 0.00506881
Epoch [293/300], Train Loss: 0.005612
Validation Loss: 0.00506154
Epoch [294/300], Train Loss: 0.005616
Validation Loss: 0.00506715
Epoch [295/300], Train Loss: 0.005608
Validation Loss: 0.00505818
Epoch [296/300], Train Loss: 0.005637
Validation Loss: 0.00505803
Epoch [297/300], Train Loss: 0.005596
Validation Loss: 0.00506955
Epoch [298/300], Train Loss: 0.005609
Validation Loss: 0.00506751
Epoch [299/300], Train Loss: 0.005594
Validation Loss: 0.00505829
Epoch [300/300], Train Loss: 0.005607
Validation Loss: 0.00505820

Evaluating model for: Router
Run 42/72 completed in 720.20 seconds with: {'MAE': np.float32(0.20870852), 'MSE': np.float32(0.07862973), 'RMSE': np.float32(0.28040993), 'SAE': np.float32(0.00012337703), 'NDE': np.float32(0.014017326)}

Run 43/72: hidden=256, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Router
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.092837
Validation Loss: 0.08405767
Epoch [2/300], Train Loss: 0.076747
Validation Loss: 0.06670270
Epoch [3/300], Train Loss: 0.057305
Validation Loss: 0.04288036
Epoch [4/300], Train Loss: 0.028618
Validation Loss: 0.00876459
Epoch [5/300], Train Loss: 0.009903
Validation Loss: 0.00852616
Epoch [6/300], Train Loss: 0.006938
Validation Loss: 0.00724737
Epoch [7/300], Train Loss: 0.007664
Validation Loss: 0.00608332
Epoch [8/300], Train Loss: 0.006183
Validation Loss: 0.00573745
Epoch [9/300], Train Loss: 0.006243
Validation Loss: 0.00533698
Epoch [10/300], Train Loss: 0.005939
Validation Loss: 0.00550469
Epoch [11/300], Train Loss: 0.005976
Validation Loss: 0.00532652
Epoch [12/300], Train Loss: 0.005901
Validation Loss: 0.00534748
Epoch [13/300], Train Loss: 0.005908
Validation Loss: 0.00534074
Epoch [14/300], Train Loss: 0.005918
Validation Loss: 0.00533187
Epoch [15/300], Train Loss: 0.005867
Validation Loss: 0.00531799
Epoch [16/300], Train Loss: 0.005920
Validation Loss: 0.00531997
Epoch [17/300], Train Loss: 0.005852
Validation Loss: 0.00531629
Epoch [18/300], Train Loss: 0.005866
Validation Loss: 0.00530940
Epoch [19/300], Train Loss: 0.005870
Validation Loss: 0.00531173
Epoch [20/300], Train Loss: 0.005903
Validation Loss: 0.00530650
Epoch [21/300], Train Loss: 0.005922
Validation Loss: 0.00530325
Epoch [22/300], Train Loss: 0.005898
Validation Loss: 0.00530851
Epoch [23/300], Train Loss: 0.005870
Validation Loss: 0.00529695
Epoch [24/300], Train Loss: 0.005888
Validation Loss: 0.00529610
Epoch [25/300], Train Loss: 0.005865
Validation Loss: 0.00530331
Epoch [26/300], Train Loss: 0.005871
Validation Loss: 0.00528913
Epoch [27/300], Train Loss: 0.005840
Validation Loss: 0.00528764
Epoch [28/300], Train Loss: 0.005827
Validation Loss: 0.00529477
Epoch [29/300], Train Loss: 0.005845
Validation Loss: 0.00528111
Epoch [30/300], Train Loss: 0.005820
Validation Loss: 0.00528421
Epoch [31/300], Train Loss: 0.005833
Validation Loss: 0.00528046
Epoch [32/300], Train Loss: 0.005853
Validation Loss: 0.00527486
Epoch [33/300], Train Loss: 0.005836
Validation Loss: 0.00528010
Epoch [34/300], Train Loss: 0.005835
Validation Loss: 0.00526838
Epoch [35/300], Train Loss: 0.005833
Validation Loss: 0.00526772
Epoch [36/300], Train Loss: 0.005796
Validation Loss: 0.00527310
Epoch [37/300], Train Loss: 0.005818
Validation Loss: 0.00526049
Epoch [38/300], Train Loss: 0.005824
Validation Loss: 0.00525975
Epoch [39/300], Train Loss: 0.005846
Validation Loss: 0.00526402
Epoch [40/300], Train Loss: 0.005857
Validation Loss: 0.00525329
Epoch [41/300], Train Loss: 0.005832
Validation Loss: 0.00525698
Epoch [42/300], Train Loss: 0.005825
Validation Loss: 0.00524754
Epoch [43/300], Train Loss: 0.005804
Validation Loss: 0.00524356
Epoch [44/300], Train Loss: 0.005818
Validation Loss: 0.00524807
Epoch [45/300], Train Loss: 0.005811
Validation Loss: 0.00524442
Epoch [46/300], Train Loss: 0.005804
Validation Loss: 0.00523495
Epoch [47/300], Train Loss: 0.005815
Validation Loss: 0.00523871
Epoch [48/300], Train Loss: 0.005785
Validation Loss: 0.00523513
Epoch [49/300], Train Loss: 0.005774
Validation Loss: 0.00522817
Epoch [50/300], Train Loss: 0.005801
Validation Loss: 0.00523870
Epoch [51/300], Train Loss: 0.005823
Validation Loss: 0.00522272
Epoch [52/300], Train Loss: 0.005762
Validation Loss: 0.00522734
Epoch [53/300], Train Loss: 0.005792
Validation Loss: 0.00521984
Epoch [54/300], Train Loss: 0.005776
Validation Loss: 0.00521492
Epoch [55/300], Train Loss: 0.005799
Validation Loss: 0.00522607
Epoch [56/300], Train Loss: 0.005793
Validation Loss: 0.00521098
Epoch [57/300], Train Loss: 0.005757
Validation Loss: 0.00521110
Epoch [58/300], Train Loss: 0.005797
Validation Loss: 0.00520767
Epoch [59/300], Train Loss: 0.005763
Validation Loss: 0.00520192
Epoch [60/300], Train Loss: 0.005779
Validation Loss: 0.00521182
Epoch [61/300], Train Loss: 0.005796
Validation Loss: 0.00519754
Epoch [62/300], Train Loss: 0.005770
Validation Loss: 0.00520589
Epoch [63/300], Train Loss: 0.005774
Validation Loss: 0.00519527
Epoch [64/300], Train Loss: 0.005763
Validation Loss: 0.00519435
Epoch [65/300], Train Loss: 0.005785
Validation Loss: 0.00518957
Epoch [66/300], Train Loss: 0.005765
Validation Loss: 0.00519154
Epoch [67/300], Train Loss: 0.005781
Validation Loss: 0.00519008
Epoch [68/300], Train Loss: 0.005781
Validation Loss: 0.00518946
Epoch [69/300], Train Loss: 0.005785
Validation Loss: 0.00517910
Epoch [70/300], Train Loss: 0.005803
Validation Loss: 0.00518549
Epoch [71/300], Train Loss: 0.005777
Validation Loss: 0.00519377
Epoch [72/300], Train Loss: 0.005785
Validation Loss: 0.00517279
Epoch [73/300], Train Loss: 0.005751
Validation Loss: 0.00518247
Epoch [74/300], Train Loss: 0.005734
Validation Loss: 0.00517258
Epoch [75/300], Train Loss: 0.005784
Validation Loss: 0.00516888
Epoch [76/300], Train Loss: 0.005712
Validation Loss: 0.00516663
Epoch [77/300], Train Loss: 0.005763
Validation Loss: 0.00516851
Epoch [78/300], Train Loss: 0.005725
Validation Loss: 0.00516120
Epoch [79/300], Train Loss: 0.005785
Validation Loss: 0.00517351
Epoch [80/300], Train Loss: 0.005742
Validation Loss: 0.00515633
Epoch [81/300], Train Loss: 0.005757
Validation Loss: 0.00516783
Epoch [82/300], Train Loss: 0.005739
Validation Loss: 0.00515732
Epoch [83/300], Train Loss: 0.005734
Validation Loss: 0.00515265
Epoch [84/300], Train Loss: 0.005705
Validation Loss: 0.00515717
Epoch [85/300], Train Loss: 0.005759
Validation Loss: 0.00515403
Epoch [86/300], Train Loss: 0.005728
Validation Loss: 0.00515197
Epoch [87/300], Train Loss: 0.005709
Validation Loss: 0.00514488
Epoch [88/300], Train Loss: 0.005742
Validation Loss: 0.00516410
Epoch [89/300], Train Loss: 0.005749
Validation Loss: 0.00515285
Epoch [90/300], Train Loss: 0.005707
Validation Loss: 0.00514083
Epoch [91/300], Train Loss: 0.005685
Validation Loss: 0.00514449
Epoch [92/300], Train Loss: 0.005725
Validation Loss: 0.00515736
Epoch [93/300], Train Loss: 0.005684
Validation Loss: 0.00513670
Epoch [94/300], Train Loss: 0.005720
Validation Loss: 0.00513950
Epoch [95/300], Train Loss: 0.005689
Validation Loss: 0.00515000
Epoch [96/300], Train Loss: 0.005759
Validation Loss: 0.00513236
Epoch [97/300], Train Loss: 0.005715
Validation Loss: 0.00513723
Epoch [98/300], Train Loss: 0.005694
Validation Loss: 0.00513595
Epoch [99/300], Train Loss: 0.005710
Validation Loss: 0.00512896
Epoch [100/300], Train Loss: 0.005680
Validation Loss: 0.00513502
Epoch [101/300], Train Loss: 0.005707
Validation Loss: 0.00512631
Epoch [102/300], Train Loss: 0.005700
Validation Loss: 0.00513272
Epoch [103/300], Train Loss: 0.005696
Validation Loss: 0.00512547
Epoch [104/300], Train Loss: 0.005718
Validation Loss: 0.00512114
Epoch [105/300], Train Loss: 0.005691
Validation Loss: 0.00513454
Epoch [106/300], Train Loss: 0.005714
Validation Loss: 0.00511864
Epoch [107/300], Train Loss: 0.005687
Validation Loss: 0.00512263
Epoch [108/300], Train Loss: 0.005711
Validation Loss: 0.00512663
Epoch [109/300], Train Loss: 0.005682
Validation Loss: 0.00511510
Epoch [110/300], Train Loss: 0.005689
Validation Loss: 0.00512270
Epoch [111/300], Train Loss: 0.005699
Validation Loss: 0.00511625
Epoch [112/300], Train Loss: 0.005679
Validation Loss: 0.00512417
Epoch [113/300], Train Loss: 0.005694
Validation Loss: 0.00511074
Epoch [114/300], Train Loss: 0.005720
Validation Loss: 0.00511268
Epoch [115/300], Train Loss: 0.005672
Validation Loss: 0.00512798
Epoch [116/300], Train Loss: 0.005677
Validation Loss: 0.00510619
Epoch [117/300], Train Loss: 0.005657
Validation Loss: 0.00511089
Epoch [118/300], Train Loss: 0.005693
Validation Loss: 0.00511396
Epoch [119/300], Train Loss: 0.005669
Validation Loss: 0.00510280
Epoch [120/300], Train Loss: 0.005678
Validation Loss: 0.00510626
Epoch [121/300], Train Loss: 0.005700
Validation Loss: 0.00511939
Epoch [122/300], Train Loss: 0.005690
Validation Loss: 0.00510034
Epoch [123/300], Train Loss: 0.005661
Validation Loss: 0.00510662
Epoch [124/300], Train Loss: 0.005657
Validation Loss: 0.00510207
Epoch [125/300], Train Loss: 0.005659
Validation Loss: 0.00510335
Epoch [126/300], Train Loss: 0.005649
Validation Loss: 0.00509784
Epoch [127/300], Train Loss: 0.005673
Validation Loss: 0.00509599
Epoch [128/300], Train Loss: 0.005700
Validation Loss: 0.00510883
Epoch [129/300], Train Loss: 0.005649
Validation Loss: 0.00509274
Epoch [130/300], Train Loss: 0.005663
Validation Loss: 0.00509617
Epoch [131/300], Train Loss: 0.005668
Validation Loss: 0.00509731
Epoch [132/300], Train Loss: 0.005651
Validation Loss: 0.00509205
Epoch [133/300], Train Loss: 0.005646
Validation Loss: 0.00509320
Epoch [134/300], Train Loss: 0.005643
Validation Loss: 0.00508773
Epoch [135/300], Train Loss: 0.005642
Validation Loss: 0.00508906
Epoch [136/300], Train Loss: 0.005628
Validation Loss: 0.00509445
Epoch [137/300], Train Loss: 0.005663
Validation Loss: 0.00508620
Epoch [138/300], Train Loss: 0.005652
Validation Loss: 0.00509949
Epoch [139/300], Train Loss: 0.005643
Validation Loss: 0.00508271
Epoch [140/300], Train Loss: 0.005644
Validation Loss: 0.00509540
Epoch [141/300], Train Loss: 0.005635
Validation Loss: 0.00508373
Epoch [142/300], Train Loss: 0.005670
Validation Loss: 0.00508152
Epoch [143/300], Train Loss: 0.005637
Validation Loss: 0.00509958
Epoch [144/300], Train Loss: 0.005628
Validation Loss: 0.00507790
Epoch [145/300], Train Loss: 0.005632
Validation Loss: 0.00509055
Epoch [146/300], Train Loss: 0.005637
Validation Loss: 0.00507747
Epoch [147/300], Train Loss: 0.005642
Validation Loss: 0.00507569
Epoch [148/300], Train Loss: 0.005663
Validation Loss: 0.00508421
Epoch [149/300], Train Loss: 0.005641
Validation Loss: 0.00508155
Epoch [150/300], Train Loss: 0.005619
Validation Loss: 0.00507251
Epoch [151/300], Train Loss: 0.005626
Validation Loss: 0.00508036
Epoch [152/300], Train Loss: 0.005639
Validation Loss: 0.00507708
Epoch [153/300], Train Loss: 0.005608
Validation Loss: 0.00507080
Epoch [154/300], Train Loss: 0.005603
Validation Loss: 0.00507513
Epoch [155/300], Train Loss: 0.005646
Validation Loss: 0.00507219
Epoch [156/300], Train Loss: 0.005655
Validation Loss: 0.00506815
Epoch [157/300], Train Loss: 0.005635
Validation Loss: 0.00507206
Epoch [158/300], Train Loss: 0.005609
Validation Loss: 0.00506974
Epoch [159/300], Train Loss: 0.005612
Validation Loss: 0.00506702
Epoch [160/300], Train Loss: 0.005628
Validation Loss: 0.00506755
Epoch [161/300], Train Loss: 0.005628
Validation Loss: 0.00506947
Epoch [162/300], Train Loss: 0.005609
Validation Loss: 0.00506638
Epoch [163/300], Train Loss: 0.005636
Validation Loss: 0.00506128
Epoch [164/300], Train Loss: 0.005678
Validation Loss: 0.00507284
Epoch [165/300], Train Loss: 0.005643
Validation Loss: 0.00506094
Epoch [166/300], Train Loss: 0.005639
Validation Loss: 0.00509601
Epoch [167/300], Train Loss: 0.005612
Validation Loss: 0.00505795
Epoch [168/300], Train Loss: 0.005612
Validation Loss: 0.00506076
Epoch [169/300], Train Loss: 0.005588
Validation Loss: 0.00505943
Epoch [170/300], Train Loss: 0.005633
Validation Loss: 0.00505959
Epoch [171/300], Train Loss: 0.005615
Validation Loss: 0.00505763
Epoch [172/300], Train Loss: 0.005635
Validation Loss: 0.00505882
Epoch [173/300], Train Loss: 0.005604
Validation Loss: 0.00506075
Epoch [174/300], Train Loss: 0.005636
Validation Loss: 0.00505254
Epoch [175/300], Train Loss: 0.005629
Validation Loss: 0.00507001
Epoch [176/300], Train Loss: 0.005637
Validation Loss: 0.00505098
Epoch [177/300], Train Loss: 0.005615
Validation Loss: 0.00506021
Epoch [178/300], Train Loss: 0.005626
Validation Loss: 0.00505570
Epoch [179/300], Train Loss: 0.005641
Validation Loss: 0.00504939
Epoch [180/300], Train Loss: 0.005594
Validation Loss: 0.00505459
Epoch [181/300], Train Loss: 0.005619
Validation Loss: 0.00505100
Epoch [182/300], Train Loss: 0.005602
Validation Loss: 0.00504895
Epoch [183/300], Train Loss: 0.005586
Validation Loss: 0.00505132
Epoch [184/300], Train Loss: 0.005597
Validation Loss: 0.00505422
Epoch [185/300], Train Loss: 0.005612
Validation Loss: 0.00504458
Epoch [186/300], Train Loss: 0.005642
Validation Loss: 0.00504715
Epoch [187/300], Train Loss: 0.005617
Validation Loss: 0.00505836
Epoch [188/300], Train Loss: 0.005576
Validation Loss: 0.00504237
Epoch [189/300], Train Loss: 0.005642
Validation Loss: 0.00504314
Epoch [190/300], Train Loss: 0.005561
Validation Loss: 0.00504682
Epoch [191/300], Train Loss: 0.005591
Validation Loss: 0.00504302
Epoch [192/300], Train Loss: 0.005579
Validation Loss: 0.00504230
Epoch [193/300], Train Loss: 0.005610
Validation Loss: 0.00504800
Epoch [194/300], Train Loss: 0.005571
Validation Loss: 0.00504177
Epoch [195/300], Train Loss: 0.005588
Validation Loss: 0.00504105
Epoch [196/300], Train Loss: 0.005637
Validation Loss: 0.00504673
Epoch [197/300], Train Loss: 0.005625
Validation Loss: 0.00503639
Epoch [198/300], Train Loss: 0.005588
Validation Loss: 0.00504288
Epoch [199/300], Train Loss: 0.005574
Validation Loss: 0.00504586
Epoch [200/300], Train Loss: 0.005622
Validation Loss: 0.00503482
Epoch [201/300], Train Loss: 0.005592
Validation Loss: 0.00503994
Epoch [202/300], Train Loss: 0.005580
Validation Loss: 0.00504216
Epoch [203/300], Train Loss: 0.005589
Validation Loss: 0.00503318
Epoch [204/300], Train Loss: 0.005577
Validation Loss: 0.00504352
Epoch [205/300], Train Loss: 0.005608
Validation Loss: 0.00503960
Epoch [206/300], Train Loss: 0.005583
Validation Loss: 0.00503385
Epoch [207/300], Train Loss: 0.005598
Validation Loss: 0.00503046
Epoch [208/300], Train Loss: 0.005667
Validation Loss: 0.00503156
Epoch [209/300], Train Loss: 0.005602
Validation Loss: 0.00505797
Epoch [210/300], Train Loss: 0.005570
Validation Loss: 0.00502907
Epoch [211/300], Train Loss: 0.005610
Validation Loss: 0.00502873
Epoch [212/300], Train Loss: 0.005593
Validation Loss: 0.00503915
Epoch [213/300], Train Loss: 0.005583
Validation Loss: 0.00502978
Epoch [214/300], Train Loss: 0.005556
Validation Loss: 0.00502695
Epoch [215/300], Train Loss: 0.005582
Validation Loss: 0.00503399
Epoch [216/300], Train Loss: 0.005628
Validation Loss: 0.00502654
Epoch [217/300], Train Loss: 0.005600
Validation Loss: 0.00503555
Epoch [218/300], Train Loss: 0.005596
Validation Loss: 0.00502474
Epoch [219/300], Train Loss: 0.005579
Validation Loss: 0.00502956
Epoch [220/300], Train Loss: 0.005598
Validation Loss: 0.00503898
Epoch [221/300], Train Loss: 0.005589
Validation Loss: 0.00502237
Epoch [222/300], Train Loss: 0.005584
Validation Loss: 0.00502871
Epoch [223/300], Train Loss: 0.005563
Validation Loss: 0.00502614
Epoch [224/300], Train Loss: 0.005581
Validation Loss: 0.00502570
Epoch [225/300], Train Loss: 0.005570
Validation Loss: 0.00502054
Epoch [226/300], Train Loss: 0.005584
Validation Loss: 0.00502604
Epoch [227/300], Train Loss: 0.005568
Validation Loss: 0.00502162
Epoch [228/300], Train Loss: 0.005579
Validation Loss: 0.00502140
Epoch [229/300], Train Loss: 0.005566
Validation Loss: 0.00503805
Epoch [230/300], Train Loss: 0.005559
Validation Loss: 0.00501817
Epoch [231/300], Train Loss: 0.005589
Validation Loss: 0.00501783
Epoch [232/300], Train Loss: 0.005587
Validation Loss: 0.00503854
Epoch [233/300], Train Loss: 0.005577
Validation Loss: 0.00502375
Epoch [234/300], Train Loss: 0.005584
Validation Loss: 0.00501626
Epoch [235/300], Train Loss: 0.005558
Validation Loss: 0.00501897
Epoch [236/300], Train Loss: 0.005585
Validation Loss: 0.00503076
Epoch [237/300], Train Loss: 0.005559
Validation Loss: 0.00501477
Epoch [238/300], Train Loss: 0.005616
Validation Loss: 0.00501514
Epoch [239/300], Train Loss: 0.005605
Validation Loss: 0.00502854
Epoch [240/300], Train Loss: 0.005554
Validation Loss: 0.00502031
Epoch [241/300], Train Loss: 0.005547
Validation Loss: 0.00501296
Epoch [242/300], Train Loss: 0.005558
Validation Loss: 0.00501815
Epoch [243/300], Train Loss: 0.005588
Validation Loss: 0.00501759
Epoch [244/300], Train Loss: 0.005541
Validation Loss: 0.00501272
Epoch [245/300], Train Loss: 0.005563
Validation Loss: 0.00501644
Epoch [246/300], Train Loss: 0.005578
Validation Loss: 0.00501340
Epoch [247/300], Train Loss: 0.005573
Validation Loss: 0.00502106
Epoch [248/300], Train Loss: 0.005560
Validation Loss: 0.00501073
Epoch [249/300], Train Loss: 0.005574
Validation Loss: 0.00501521
Epoch [250/300], Train Loss: 0.005569
Validation Loss: 0.00501348
Epoch [251/300], Train Loss: 0.005562
Validation Loss: 0.00501005
Epoch [252/300], Train Loss: 0.005531
Validation Loss: 0.00501528
Epoch [253/300], Train Loss: 0.005562
Validation Loss: 0.00501238
Epoch [254/300], Train Loss: 0.005537
Validation Loss: 0.00501185
Epoch [255/300], Train Loss: 0.005592
Validation Loss: 0.00501322
Epoch [256/300], Train Loss: 0.005536
Validation Loss: 0.00500924
Epoch [257/300], Train Loss: 0.005592
Validation Loss: 0.00500815
Epoch [258/300], Train Loss: 0.005550
Validation Loss: 0.00501645
Epoch [259/300], Train Loss: 0.005566
Validation Loss: 0.00501002
Epoch [260/300], Train Loss: 0.005557
Validation Loss: 0.00500820
Epoch [261/300], Train Loss: 0.005537
Validation Loss: 0.00500878
Epoch [262/300], Train Loss: 0.005551
Validation Loss: 0.00500921
Epoch [263/300], Train Loss: 0.005584
Validation Loss: 0.00500531
Epoch [264/300], Train Loss: 0.005561
Validation Loss: 0.00501114
Epoch [265/300], Train Loss: 0.005563
Validation Loss: 0.00500530
Epoch [266/300], Train Loss: 0.005549
Validation Loss: 0.00500496
Epoch [267/300], Train Loss: 0.005582
Validation Loss: 0.00501550
Epoch [268/300], Train Loss: 0.005542
Validation Loss: 0.00500266
Epoch [269/300], Train Loss: 0.005578
Validation Loss: 0.00500390
Epoch [270/300], Train Loss: 0.005536
Validation Loss: 0.00500956
Epoch [271/300], Train Loss: 0.005526
Validation Loss: 0.00500283
Epoch [272/300], Train Loss: 0.005550
Validation Loss: 0.00500206
Epoch [273/300], Train Loss: 0.005550
Validation Loss: 0.00500755
Epoch [274/300], Train Loss: 0.005541
Validation Loss: 0.00500012
Epoch [275/300], Train Loss: 0.005552
Validation Loss: 0.00500287
Epoch [276/300], Train Loss: 0.005521
Validation Loss: 0.00500499
Epoch [277/300], Train Loss: 0.005544
Validation Loss: 0.00500173
Epoch [278/300], Train Loss: 0.005535
Validation Loss: 0.00500246
Epoch [279/300], Train Loss: 0.005515
Validation Loss: 0.00499957
Epoch [280/300], Train Loss: 0.005539
Validation Loss: 0.00500106
Epoch [281/300], Train Loss: 0.005539
Validation Loss: 0.00500557
Epoch [282/300], Train Loss: 0.005549
Validation Loss: 0.00499767
Epoch [283/300], Train Loss: 0.005544
Validation Loss: 0.00500167
Epoch [284/300], Train Loss: 0.005573
Validation Loss: 0.00500445
Epoch [285/300], Train Loss: 0.005538
Validation Loss: 0.00500032
Epoch [286/300], Train Loss: 0.005543
Validation Loss: 0.00499668
Epoch [287/300], Train Loss: 0.005559
Validation Loss: 0.00499836
Epoch [288/300], Train Loss: 0.005529
Validation Loss: 0.00500649
Epoch [289/300], Train Loss: 0.005544
Validation Loss: 0.00499818
Epoch [290/300], Train Loss: 0.005565
Validation Loss: 0.00499600
Epoch [291/300], Train Loss: 0.005539
Validation Loss: 0.00499948
Epoch [292/300], Train Loss: 0.005523
Validation Loss: 0.00500330
Epoch [293/300], Train Loss: 0.005546
Validation Loss: 0.00499500
Epoch [294/300], Train Loss: 0.005553
Validation Loss: 0.00500165
Epoch [295/300], Train Loss: 0.005532
Validation Loss: 0.00499306
Epoch [296/300], Train Loss: 0.005559
Validation Loss: 0.00499336
Epoch [297/300], Train Loss: 0.005523
Validation Loss: 0.00500532
Epoch [298/300], Train Loss: 0.005544
Validation Loss: 0.00499953
Epoch [299/300], Train Loss: 0.005519
Validation Loss: 0.00499268
Epoch [300/300], Train Loss: 0.005543
Validation Loss: 0.00499386

Evaluating model for: Router
Run 43/72 completed in 882.31 seconds with: {'MAE': np.float32(0.20817636), 'MSE': np.float32(0.0778921), 'RMSE': np.float32(0.27909157), 'SAE': np.float32(0.00017764345), 'NDE': np.float32(0.013951421)}

Run 44/72: hidden=256, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Router
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.063113
Validation Loss: 0.05694180
Epoch [2/300], Train Loss: 0.052217
Validation Loss: 0.04578323
Epoch [3/300], Train Loss: 0.039923
Validation Loss: 0.03089205
Epoch [4/300], Train Loss: 0.021370
Validation Loss: 0.00711796
Epoch [5/300], Train Loss: 0.008362
Validation Loss: 0.00586082
Epoch [6/300], Train Loss: 0.006345
Validation Loss: 0.00674350
Epoch [7/300], Train Loss: 0.006646
Validation Loss: 0.00530646
Epoch [8/300], Train Loss: 0.005964
Validation Loss: 0.00553434
Epoch [9/300], Train Loss: 0.005856
Validation Loss: 0.00528906
Epoch [10/300], Train Loss: 0.005808
Validation Loss: 0.00527276
Epoch [11/300], Train Loss: 0.005734
Validation Loss: 0.00522884
Epoch [12/300], Train Loss: 0.005723
Validation Loss: 0.00520730
Epoch [13/300], Train Loss: 0.005726
Validation Loss: 0.00522756
Epoch [14/300], Train Loss: 0.005741
Validation Loss: 0.00520409
Epoch [15/300], Train Loss: 0.005693
Validation Loss: 0.00520224
Epoch [16/300], Train Loss: 0.005751
Validation Loss: 0.00521140
Epoch [17/300], Train Loss: 0.005684
Validation Loss: 0.00519945
Epoch [18/300], Train Loss: 0.005700
Validation Loss: 0.00519750
Epoch [19/300], Train Loss: 0.005706
Validation Loss: 0.00520296
Epoch [20/300], Train Loss: 0.005727
Validation Loss: 0.00519435
Epoch [21/300], Train Loss: 0.005757
Validation Loss: 0.00519345
Epoch [22/300], Train Loss: 0.005732
Validation Loss: 0.00520091
Epoch [23/300], Train Loss: 0.005710
Validation Loss: 0.00518966
Epoch [24/300], Train Loss: 0.005731
Validation Loss: 0.00518999
Epoch [25/300], Train Loss: 0.005697
Validation Loss: 0.00519426
Epoch [26/300], Train Loss: 0.005707
Validation Loss: 0.00518300
Epoch [27/300], Train Loss: 0.005677
Validation Loss: 0.00518301
Epoch [28/300], Train Loss: 0.005663
Validation Loss: 0.00518776
Epoch [29/300], Train Loss: 0.005674
Validation Loss: 0.00517714
Epoch [30/300], Train Loss: 0.005658
Validation Loss: 0.00518320
Epoch [31/300], Train Loss: 0.005669
Validation Loss: 0.00517497
Epoch [32/300], Train Loss: 0.005690
Validation Loss: 0.00517142
Epoch [33/300], Train Loss: 0.005671
Validation Loss: 0.00517857
Epoch [34/300], Train Loss: 0.005666
Validation Loss: 0.00516657
Epoch [35/300], Train Loss: 0.005665
Validation Loss: 0.00516632
Epoch [36/300], Train Loss: 0.005628
Validation Loss: 0.00517015
Epoch [37/300], Train Loss: 0.005651
Validation Loss: 0.00516069
Epoch [38/300], Train Loss: 0.005664
Validation Loss: 0.00515939
Epoch [39/300], Train Loss: 0.005684
Validation Loss: 0.00516066
Epoch [40/300], Train Loss: 0.005686
Validation Loss: 0.00515323
Epoch [41/300], Train Loss: 0.005671
Validation Loss: 0.00515633
Epoch [42/300], Train Loss: 0.005661
Validation Loss: 0.00514720
Epoch [43/300], Train Loss: 0.005649
Validation Loss: 0.00514439
Epoch [44/300], Train Loss: 0.005654
Validation Loss: 0.00514719
Epoch [45/300], Train Loss: 0.005643
Validation Loss: 0.00514164
Epoch [46/300], Train Loss: 0.005634
Validation Loss: 0.00513559
Epoch [47/300], Train Loss: 0.005657
Validation Loss: 0.00513875
Epoch [48/300], Train Loss: 0.005614
Validation Loss: 0.00513179
Epoch [49/300], Train Loss: 0.005622
Validation Loss: 0.00512790
Epoch [50/300], Train Loss: 0.005635
Validation Loss: 0.00513708
Epoch [51/300], Train Loss: 0.005664
Validation Loss: 0.00512150
Epoch [52/300], Train Loss: 0.005601
Validation Loss: 0.00512819
Epoch [53/300], Train Loss: 0.005624
Validation Loss: 0.00511588
Epoch [54/300], Train Loss: 0.005612
Validation Loss: 0.00511273
Epoch [55/300], Train Loss: 0.005633
Validation Loss: 0.00512113
Epoch [56/300], Train Loss: 0.005629
Validation Loss: 0.00510596
Epoch [57/300], Train Loss: 0.005593
Validation Loss: 0.00510816
Epoch [58/300], Train Loss: 0.005628
Validation Loss: 0.00509968
Epoch [59/300], Train Loss: 0.005604
Validation Loss: 0.00509699
Epoch [60/300], Train Loss: 0.005614
Validation Loss: 0.00510252
Epoch [61/300], Train Loss: 0.005629
Validation Loss: 0.00509007
Epoch [62/300], Train Loss: 0.005607
Validation Loss: 0.00510176
Epoch [63/300], Train Loss: 0.005611
Validation Loss: 0.00508539
Epoch [64/300], Train Loss: 0.005597
Validation Loss: 0.00508812
Epoch [65/300], Train Loss: 0.005620
Validation Loss: 0.00508000
Epoch [66/300], Train Loss: 0.005608
Validation Loss: 0.00508369
Epoch [67/300], Train Loss: 0.005615
Validation Loss: 0.00508177
Epoch [68/300], Train Loss: 0.005618
Validation Loss: 0.00507781
Epoch [69/300], Train Loss: 0.005622
Validation Loss: 0.00507077
Epoch [70/300], Train Loss: 0.005637
Validation Loss: 0.00507923
Epoch [71/300], Train Loss: 0.005617
Validation Loss: 0.00507958
Epoch [72/300], Train Loss: 0.005615
Validation Loss: 0.00506525
Epoch [73/300], Train Loss: 0.005587
Validation Loss: 0.00507492
Epoch [74/300], Train Loss: 0.005570
Validation Loss: 0.00506283
Epoch [75/300], Train Loss: 0.005626
Validation Loss: 0.00506161
Epoch [76/300], Train Loss: 0.005551
Validation Loss: 0.00505826
Epoch [77/300], Train Loss: 0.005601
Validation Loss: 0.00506212
Epoch [78/300], Train Loss: 0.005563
Validation Loss: 0.00505435
Epoch [79/300], Train Loss: 0.005626
Validation Loss: 0.00506671
Epoch [80/300], Train Loss: 0.005571
Validation Loss: 0.00504999
Epoch [81/300], Train Loss: 0.005594
Validation Loss: 0.00506694
Epoch [82/300], Train Loss: 0.005583
Validation Loss: 0.00504944
Epoch [83/300], Train Loss: 0.005580
Validation Loss: 0.00504895
Epoch [84/300], Train Loss: 0.005541
Validation Loss: 0.00505167
Epoch [85/300], Train Loss: 0.005599
Validation Loss: 0.00505051
Epoch [86/300], Train Loss: 0.005568
Validation Loss: 0.00504687
Epoch [87/300], Train Loss: 0.005545
Validation Loss: 0.00504071
Epoch [88/300], Train Loss: 0.005577
Validation Loss: 0.00506717
Epoch [89/300], Train Loss: 0.005587
Validation Loss: 0.00504459
Epoch [90/300], Train Loss: 0.005547
Validation Loss: 0.00503833
Epoch [91/300], Train Loss: 0.005528
Validation Loss: 0.00504213
Epoch [92/300], Train Loss: 0.005566
Validation Loss: 0.00505228
Epoch [93/300], Train Loss: 0.005529
Validation Loss: 0.00503408
Epoch [94/300], Train Loss: 0.005559
Validation Loss: 0.00503895
Epoch [95/300], Train Loss: 0.005532
Validation Loss: 0.00504503
Epoch [96/300], Train Loss: 0.005590
Validation Loss: 0.00502991
Epoch [97/300], Train Loss: 0.005554
Validation Loss: 0.00503607
Epoch [98/300], Train Loss: 0.005532
Validation Loss: 0.00503213
Epoch [99/300], Train Loss: 0.005551
Validation Loss: 0.00502704
Epoch [100/300], Train Loss: 0.005521
Validation Loss: 0.00503229
Epoch [101/300], Train Loss: 0.005553
Validation Loss: 0.00502395
Epoch [102/300], Train Loss: 0.005542
Validation Loss: 0.00503186
Epoch [103/300], Train Loss: 0.005535
Validation Loss: 0.00502204
Epoch [104/300], Train Loss: 0.005560
Validation Loss: 0.00501952
Epoch [105/300], Train Loss: 0.005533
Validation Loss: 0.00503020
Epoch [106/300], Train Loss: 0.005549
Validation Loss: 0.00501613
Epoch [107/300], Train Loss: 0.005531
Validation Loss: 0.00502321
Epoch [108/300], Train Loss: 0.005550
Validation Loss: 0.00502102
Epoch [109/300], Train Loss: 0.005525
Validation Loss: 0.00501319
Epoch [110/300], Train Loss: 0.005533
Validation Loss: 0.00502062
Epoch [111/300], Train Loss: 0.005544
Validation Loss: 0.00501443
Epoch [112/300], Train Loss: 0.005521
Validation Loss: 0.00502352
Epoch [113/300], Train Loss: 0.005538
Validation Loss: 0.00500839
Epoch [114/300], Train Loss: 0.005557
Validation Loss: 0.00501326
Epoch [115/300], Train Loss: 0.005515
Validation Loss: 0.00502291
Epoch [116/300], Train Loss: 0.005516
Validation Loss: 0.00500336
Epoch [117/300], Train Loss: 0.005502
Validation Loss: 0.00501124
Epoch [118/300], Train Loss: 0.005539
Validation Loss: 0.00500722
Epoch [119/300], Train Loss: 0.005511
Validation Loss: 0.00500019
Epoch [120/300], Train Loss: 0.005523
Validation Loss: 0.00500481
Epoch [121/300], Train Loss: 0.005540
Validation Loss: 0.00501365
Epoch [122/300], Train Loss: 0.005527
Validation Loss: 0.00499740
Epoch [123/300], Train Loss: 0.005509
Validation Loss: 0.00500457
Epoch [124/300], Train Loss: 0.005511
Validation Loss: 0.00499762
Epoch [125/300], Train Loss: 0.005508
Validation Loss: 0.00500102
Epoch [126/300], Train Loss: 0.005499
Validation Loss: 0.00499312
Epoch [127/300], Train Loss: 0.005525
Validation Loss: 0.00499306
Epoch [128/300], Train Loss: 0.005545
Validation Loss: 0.00500473
Epoch [129/300], Train Loss: 0.005492
Validation Loss: 0.00498839
Epoch [130/300], Train Loss: 0.005504
Validation Loss: 0.00499438
Epoch [131/300], Train Loss: 0.005508
Validation Loss: 0.00499079
Epoch [132/300], Train Loss: 0.005500
Validation Loss: 0.00498742
Epoch [133/300], Train Loss: 0.005493
Validation Loss: 0.00498761
Epoch [134/300], Train Loss: 0.005490
Validation Loss: 0.00498131
Epoch [135/300], Train Loss: 0.005485
Validation Loss: 0.00498398
Epoch [136/300], Train Loss: 0.005471
Validation Loss: 0.00498817
Epoch [137/300], Train Loss: 0.005508
Validation Loss: 0.00497899
Epoch [138/300], Train Loss: 0.005499
Validation Loss: 0.00499411
Epoch [139/300], Train Loss: 0.005491
Validation Loss: 0.00497557
Epoch [140/300], Train Loss: 0.005492
Validation Loss: 0.00499132
Epoch [141/300], Train Loss: 0.005481
Validation Loss: 0.00497330
Epoch [142/300], Train Loss: 0.005521
Validation Loss: 0.00497545
Epoch [143/300], Train Loss: 0.005482
Validation Loss: 0.00499012
Epoch [144/300], Train Loss: 0.005474
Validation Loss: 0.00496900
Epoch [145/300], Train Loss: 0.005476
Validation Loss: 0.00498436
Epoch [146/300], Train Loss: 0.005480
Validation Loss: 0.00496729
Epoch [147/300], Train Loss: 0.005491
Validation Loss: 0.00496669
Epoch [148/300], Train Loss: 0.005503
Validation Loss: 0.00497291
Epoch [149/300], Train Loss: 0.005484
Validation Loss: 0.00496760
Epoch [150/300], Train Loss: 0.005466
Validation Loss: 0.00495898
Epoch [151/300], Train Loss: 0.005465
Validation Loss: 0.00496683
Epoch [152/300], Train Loss: 0.005472
Validation Loss: 0.00495906
Epoch [153/300], Train Loss: 0.005451
Validation Loss: 0.00495384
Epoch [154/300], Train Loss: 0.005440
Validation Loss: 0.00495944
Epoch [155/300], Train Loss: 0.005479
Validation Loss: 0.00495340
Epoch [156/300], Train Loss: 0.005493
Validation Loss: 0.00494978
Epoch [157/300], Train Loss: 0.005479
Validation Loss: 0.00495126
Epoch [158/300], Train Loss: 0.005447
Validation Loss: 0.00494998
Epoch [159/300], Train Loss: 0.005455
Validation Loss: 0.00494717
Epoch [160/300], Train Loss: 0.005466
Validation Loss: 0.00494509
Epoch [161/300], Train Loss: 0.005463
Validation Loss: 0.00494654
Epoch [162/300], Train Loss: 0.005436
Validation Loss: 0.00494188
Epoch [163/300], Train Loss: 0.005474
Validation Loss: 0.00493571
Epoch [164/300], Train Loss: 0.005515
Validation Loss: 0.00493965
Epoch [165/300], Train Loss: 0.005487
Validation Loss: 0.00493622
Epoch [166/300], Train Loss: 0.005488
Validation Loss: 0.00497911
Epoch [167/300], Train Loss: 0.005447
Validation Loss: 0.00494108
Epoch [168/300], Train Loss: 0.005456
Validation Loss: 0.00494425
Epoch [169/300], Train Loss: 0.005416
Validation Loss: 0.00492693
Epoch [170/300], Train Loss: 0.005463
Validation Loss: 0.00492425
Epoch [171/300], Train Loss: 0.005440
Validation Loss: 0.00492519
Epoch [172/300], Train Loss: 0.005459
Validation Loss: 0.00492554
Epoch [173/300], Train Loss: 0.005429
Validation Loss: 0.00492364
Epoch [174/300], Train Loss: 0.005475
Validation Loss: 0.00494068
Epoch [175/300], Train Loss: 0.005468
Validation Loss: 0.00496474
Epoch [176/300], Train Loss: 0.005460
Validation Loss: 0.00493388
Epoch [177/300], Train Loss: 0.005439
Validation Loss: 0.00493291
Epoch [178/300], Train Loss: 0.005462
Validation Loss: 0.00492053
Epoch [179/300], Train Loss: 0.005464
Validation Loss: 0.00492088
Epoch [180/300], Train Loss: 0.005408
Validation Loss: 0.00491354
Epoch [181/300], Train Loss: 0.005425
Validation Loss: 0.00490183
Epoch [182/300], Train Loss: 0.005421
Validation Loss: 0.00491086
Epoch [183/300], Train Loss: 0.005413
Validation Loss: 0.00489953
Epoch [184/300], Train Loss: 0.005416
Validation Loss: 0.00492237
Epoch [185/300], Train Loss: 0.005429
Validation Loss: 0.00491490
Epoch [186/300], Train Loss: 0.005438
Validation Loss: 0.00487541
Epoch [187/300], Train Loss: 0.005428
Validation Loss: 0.00489359
Epoch [188/300], Train Loss: 0.005386
Validation Loss: 0.00491708
Epoch [189/300], Train Loss: 0.005448
Validation Loss: 0.00492080
Epoch [190/300], Train Loss: 0.005374
Validation Loss: 0.00486209
Epoch [191/300], Train Loss: 0.005430
Validation Loss: 0.00489567
Epoch [192/300], Train Loss: 0.005414
Validation Loss: 0.00493847
Epoch [193/300], Train Loss: 0.005448
Validation Loss: 0.00495698
Epoch [194/300], Train Loss: 0.005398
Validation Loss: 0.00491791
Epoch [195/300], Train Loss: 0.005401
Validation Loss: 0.00489584
Epoch [196/300], Train Loss: 0.005445
Validation Loss: 0.00487285
Epoch [197/300], Train Loss: 0.005418
Validation Loss: 0.00482755
Epoch [198/300], Train Loss: 0.005386
Validation Loss: 0.00482700
Epoch [199/300], Train Loss: 0.005364
Validation Loss: 0.00483942
Epoch [200/300], Train Loss: 0.005413
Validation Loss: 0.00486133
Epoch [201/300], Train Loss: 0.005375
Validation Loss: 0.00482291
Epoch [202/300], Train Loss: 0.005345
Validation Loss: 0.00485698
Epoch [203/300], Train Loss: 0.005354
Validation Loss: 0.00481628
Epoch [204/300], Train Loss: 0.005339
Validation Loss: 0.00480844
Epoch [205/300], Train Loss: 0.005352
Validation Loss: 0.00480783
Epoch [206/300], Train Loss: 0.005348
Validation Loss: 0.00478686
Epoch [207/300], Train Loss: 0.005341
Validation Loss: 0.00479661
Epoch [208/300], Train Loss: 0.005384
Validation Loss: 0.00481898
Epoch [209/300], Train Loss: 0.005381
Validation Loss: 0.00492884
Epoch [210/300], Train Loss: 0.005400
Validation Loss: 0.00493158
Epoch [211/300], Train Loss: 0.005424
Validation Loss: 0.00489659
Epoch [212/300], Train Loss: 0.005376
Validation Loss: 0.00477845
Epoch [213/300], Train Loss: 0.005329
Validation Loss: 0.00475094
Epoch [214/300], Train Loss: 0.005340
Validation Loss: 0.00474120
Epoch [215/300], Train Loss: 0.005394
Validation Loss: 0.00491496
Epoch [216/300], Train Loss: 0.005452
Validation Loss: 0.00493184
Epoch [217/300], Train Loss: 0.005428
Validation Loss: 0.00491173
Epoch [218/300], Train Loss: 0.005397
Validation Loss: 0.00485328
Epoch [219/300], Train Loss: 0.005327
Validation Loss: 0.00477927
Epoch [220/300], Train Loss: 0.005327
Validation Loss: 0.00479446
Epoch [221/300], Train Loss: 0.005346
Validation Loss: 0.00474965
Epoch [222/300], Train Loss: 0.005322
Validation Loss: 0.00480435
Epoch [223/300], Train Loss: 0.005299
Validation Loss: 0.00474781
Epoch [224/300], Train Loss: 0.005310
Validation Loss: 0.00477172
Early stopping triggered

Evaluating model for: Router
Run 44/72 completed in 897.33 seconds with: {'MAE': np.float32(0.20639513), 'MSE': np.float32(0.07477827), 'RMSE': np.float32(0.27345616), 'SAE': np.float32(0.000393898), 'NDE': np.float32(0.013669716)}

Run 45/72: hidden=256, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Router
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.109652
Validation Loss: 0.10374216
Epoch [2/300], Train Loss: 0.101832
Validation Loss: 0.09586794
Epoch [3/300], Train Loss: 0.094357
Validation Loss: 0.08790960
Epoch [4/300], Train Loss: 0.085684
Validation Loss: 0.07938332
Epoch [5/300], Train Loss: 0.076095
Validation Loss: 0.07016283
Epoch [6/300], Train Loss: 0.066669
Validation Loss: 0.05953082
Epoch [7/300], Train Loss: 0.055572
Validation Loss: 0.04699147
Epoch [8/300], Train Loss: 0.041964
Validation Loss: 0.03178076
Epoch [9/300], Train Loss: 0.025641
Validation Loss: 0.01427637
Epoch [10/300], Train Loss: 0.009814
Validation Loss: 0.00776732
Epoch [11/300], Train Loss: 0.011120
Validation Loss: 0.01136664
Epoch [12/300], Train Loss: 0.008551
Validation Loss: 0.00617331
Epoch [13/300], Train Loss: 0.006620
Validation Loss: 0.00739502
Epoch [14/300], Train Loss: 0.007655
Validation Loss: 0.00759113
Epoch [15/300], Train Loss: 0.007261
Validation Loss: 0.00655419
Epoch [16/300], Train Loss: 0.006290
Validation Loss: 0.00609763
Epoch [17/300], Train Loss: 0.006333
Validation Loss: 0.00640730
Epoch [18/300], Train Loss: 0.006427
Validation Loss: 0.00633478
Epoch [19/300], Train Loss: 0.006132
Validation Loss: 0.00609155
Epoch [20/300], Train Loss: 0.006126
Validation Loss: 0.00609369
Epoch [21/300], Train Loss: 0.006143
Validation Loss: 0.00612996
Epoch [22/300], Train Loss: 0.006134
Validation Loss: 0.00607624
Epoch [23/300], Train Loss: 0.006123
Validation Loss: 0.00605741
Epoch [24/300], Train Loss: 0.006059
Validation Loss: 0.00609607
Epoch [25/300], Train Loss: 0.005989
Validation Loss: 0.00606960
Epoch [26/300], Train Loss: 0.005910
Validation Loss: 0.00604150
Epoch [27/300], Train Loss: 0.006055
Validation Loss: 0.00604056
Epoch [28/300], Train Loss: 0.005993
Validation Loss: 0.00603703
Epoch [29/300], Train Loss: 0.006081
Validation Loss: 0.00603132
Epoch [30/300], Train Loss: 0.005916
Validation Loss: 0.00602873
Epoch [31/300], Train Loss: 0.005935
Validation Loss: 0.00603431
Epoch [32/300], Train Loss: 0.005956
Validation Loss: 0.00603352
Epoch [33/300], Train Loss: 0.006097
Validation Loss: 0.00603020
Epoch [34/300], Train Loss: 0.005969
Validation Loss: 0.00601798
Epoch [35/300], Train Loss: 0.005968
Validation Loss: 0.00601523
Epoch [36/300], Train Loss: 0.005998
Validation Loss: 0.00601352
Epoch [37/300], Train Loss: 0.005937
Validation Loss: 0.00601264
Epoch [38/300], Train Loss: 0.005810
Validation Loss: 0.00601348
Epoch [39/300], Train Loss: 0.005905
Validation Loss: 0.00601891
Epoch [40/300], Train Loss: 0.006020
Validation Loss: 0.00600803
Epoch [41/300], Train Loss: 0.005989
Validation Loss: 0.00600703
Epoch [42/300], Train Loss: 0.006073
Validation Loss: 0.00600496
Epoch [43/300], Train Loss: 0.006023
Validation Loss: 0.00600049
Epoch [44/300], Train Loss: 0.005935
Validation Loss: 0.00599946
Epoch [45/300], Train Loss: 0.005891
Validation Loss: 0.00599945
Epoch [46/300], Train Loss: 0.005889
Validation Loss: 0.00599696
Epoch [47/300], Train Loss: 0.005940
Validation Loss: 0.00599724
Epoch [48/300], Train Loss: 0.006064
Validation Loss: 0.00599631
Epoch [49/300], Train Loss: 0.005945
Validation Loss: 0.00599242
Epoch [50/300], Train Loss: 0.005951
Validation Loss: 0.00599001
Epoch [51/300], Train Loss: 0.005935
Validation Loss: 0.00598896
Epoch [52/300], Train Loss: 0.005980
Validation Loss: 0.00598817
Epoch [53/300], Train Loss: 0.005974
Validation Loss: 0.00598693
Epoch [54/300], Train Loss: 0.005896
Validation Loss: 0.00599008
Epoch [55/300], Train Loss: 0.005948
Validation Loss: 0.00598713
Epoch [56/300], Train Loss: 0.005935
Validation Loss: 0.00598405
Epoch [57/300], Train Loss: 0.006009
Validation Loss: 0.00598337
Epoch [58/300], Train Loss: 0.005869
Validation Loss: 0.00598228
Epoch [59/300], Train Loss: 0.005908
Validation Loss: 0.00598220
Epoch [60/300], Train Loss: 0.005904
Validation Loss: 0.00598208
Epoch [61/300], Train Loss: 0.005847
Validation Loss: 0.00599697
Epoch [62/300], Train Loss: 0.005983
Validation Loss: 0.00600119
Epoch [63/300], Train Loss: 0.005785
Validation Loss: 0.00597878
Epoch [64/300], Train Loss: 0.006007
Validation Loss: 0.00598306
Epoch [65/300], Train Loss: 0.005845
Validation Loss: 0.00597697
Epoch [66/300], Train Loss: 0.006005
Validation Loss: 0.00598417
Epoch [67/300], Train Loss: 0.005846
Validation Loss: 0.00598312
Epoch [68/300], Train Loss: 0.005865
Validation Loss: 0.00597502
Epoch [69/300], Train Loss: 0.005876
Validation Loss: 0.00597590
Epoch [70/300], Train Loss: 0.005887
Validation Loss: 0.00597462
Epoch [71/300], Train Loss: 0.005948
Validation Loss: 0.00597370
Epoch [72/300], Train Loss: 0.005738
Validation Loss: 0.00597531
Epoch [73/300], Train Loss: 0.005815
Validation Loss: 0.00598083
Epoch [74/300], Train Loss: 0.005932
Validation Loss: 0.00597402
Epoch [75/300], Train Loss: 0.005796
Validation Loss: 0.00597129
Epoch [76/300], Train Loss: 0.005907
Validation Loss: 0.00597112
Epoch [77/300], Train Loss: 0.005886
Validation Loss: 0.00597141
Epoch [78/300], Train Loss: 0.005924
Validation Loss: 0.00597116
Epoch [79/300], Train Loss: 0.005791
Validation Loss: 0.00597160
Epoch [80/300], Train Loss: 0.005928
Validation Loss: 0.00597294
Epoch [81/300], Train Loss: 0.005783
Validation Loss: 0.00596900
Epoch [82/300], Train Loss: 0.006012
Validation Loss: 0.00596893
Epoch [83/300], Train Loss: 0.005901
Validation Loss: 0.00596774
Epoch [84/300], Train Loss: 0.005802
Validation Loss: 0.00596892
Epoch [85/300], Train Loss: 0.005843
Validation Loss: 0.00597124
Epoch [86/300], Train Loss: 0.005808
Validation Loss: 0.00596906
Epoch [87/300], Train Loss: 0.005892
Validation Loss: 0.00596762
Epoch [88/300], Train Loss: 0.005847
Validation Loss: 0.00596561
Epoch [89/300], Train Loss: 0.005872
Validation Loss: 0.00596642
Epoch [90/300], Train Loss: 0.005964
Validation Loss: 0.00596478
Epoch [91/300], Train Loss: 0.005942
Validation Loss: 0.00596773
Epoch [92/300], Train Loss: 0.005871
Validation Loss: 0.00597515
Epoch [93/300], Train Loss: 0.005919
Validation Loss: 0.00597483
Epoch [94/300], Train Loss: 0.005712
Validation Loss: 0.00596674
Epoch [95/300], Train Loss: 0.005843
Validation Loss: 0.00596278
Epoch [96/300], Train Loss: 0.005915
Validation Loss: 0.00596229
Epoch [97/300], Train Loss: 0.005812
Validation Loss: 0.00596182
Epoch [98/300], Train Loss: 0.005905
Validation Loss: 0.00596312
Epoch [99/300], Train Loss: 0.005866
Validation Loss: 0.00596548
Epoch [100/300], Train Loss: 0.005865
Validation Loss: 0.00596611
Epoch [101/300], Train Loss: 0.005823
Validation Loss: 0.00596555
Epoch [102/300], Train Loss: 0.005902
Validation Loss: 0.00596014
Epoch [103/300], Train Loss: 0.005836
Validation Loss: 0.00596134
Epoch [104/300], Train Loss: 0.005799
Validation Loss: 0.00595907
Epoch [105/300], Train Loss: 0.005868
Validation Loss: 0.00596088
Epoch [106/300], Train Loss: 0.006022
Validation Loss: 0.00596154
Epoch [107/300], Train Loss: 0.005819
Validation Loss: 0.00595850
Epoch [108/300], Train Loss: 0.006001
Validation Loss: 0.00595686
Epoch [109/300], Train Loss: 0.006085
Validation Loss: 0.00595660
Epoch [110/300], Train Loss: 0.005819
Validation Loss: 0.00595622
Epoch [111/300], Train Loss: 0.005788
Validation Loss: 0.00595851
Epoch [112/300], Train Loss: 0.005937
Validation Loss: 0.00596392
Epoch [113/300], Train Loss: 0.005940
Validation Loss: 0.00595716
Epoch [114/300], Train Loss: 0.005984
Validation Loss: 0.00595606
Epoch [115/300], Train Loss: 0.005931
Validation Loss: 0.00595628
Epoch [116/300], Train Loss: 0.005816
Validation Loss: 0.00595375
Epoch [117/300], Train Loss: 0.005854
Validation Loss: 0.00596108
Epoch [118/300], Train Loss: 0.005845
Validation Loss: 0.00595630
Epoch [119/300], Train Loss: 0.005806
Validation Loss: 0.00595207
Epoch [120/300], Train Loss: 0.005838
Validation Loss: 0.00595119
Epoch [121/300], Train Loss: 0.005790
Validation Loss: 0.00595246
Epoch [122/300], Train Loss: 0.005777
Validation Loss: 0.00595042
Epoch [123/300], Train Loss: 0.005862
Validation Loss: 0.00595492
Epoch [124/300], Train Loss: 0.005844
Validation Loss: 0.00596111
Epoch [125/300], Train Loss: 0.005924
Validation Loss: 0.00595667
Epoch [126/300], Train Loss: 0.005911
Validation Loss: 0.00594993
Epoch [127/300], Train Loss: 0.005848
Validation Loss: 0.00594999
Epoch [128/300], Train Loss: 0.005947
Validation Loss: 0.00594874
Epoch [129/300], Train Loss: 0.005770
Validation Loss: 0.00594901
Epoch [130/300], Train Loss: 0.005979
Validation Loss: 0.00595434
Epoch [131/300], Train Loss: 0.005815
Validation Loss: 0.00595389
Epoch [132/300], Train Loss: 0.005801
Validation Loss: 0.00595022
Epoch [133/300], Train Loss: 0.005785
Validation Loss: 0.00594622
Epoch [134/300], Train Loss: 0.005945
Validation Loss: 0.00594608
Epoch [135/300], Train Loss: 0.005747
Validation Loss: 0.00594525
Epoch [136/300], Train Loss: 0.005836
Validation Loss: 0.00594486
Epoch [137/300], Train Loss: 0.005976
Validation Loss: 0.00594437
Epoch [138/300], Train Loss: 0.005804
Validation Loss: 0.00594440
Epoch [139/300], Train Loss: 0.005797
Validation Loss: 0.00594384
Epoch [140/300], Train Loss: 0.005769
Validation Loss: 0.00594471
Epoch [141/300], Train Loss: 0.005702
Validation Loss: 0.00594561
Epoch [142/300], Train Loss: 0.005746
Validation Loss: 0.00594382
Epoch [143/300], Train Loss: 0.005853
Validation Loss: 0.00594314
Epoch [144/300], Train Loss: 0.005813
Validation Loss: 0.00594086
Epoch [145/300], Train Loss: 0.005774
Validation Loss: 0.00594098
Epoch [146/300], Train Loss: 0.005729
Validation Loss: 0.00594350
Epoch [147/300], Train Loss: 0.005885
Validation Loss: 0.00594377
Epoch [148/300], Train Loss: 0.005721
Validation Loss: 0.00593976
Epoch [149/300], Train Loss: 0.005934
Validation Loss: 0.00593921
Epoch [150/300], Train Loss: 0.006044
Validation Loss: 0.00594168
Epoch [151/300], Train Loss: 0.005818
Validation Loss: 0.00594265
Epoch [152/300], Train Loss: 0.005977
Validation Loss: 0.00593801
Epoch [153/300], Train Loss: 0.005686
Validation Loss: 0.00593751
Epoch [154/300], Train Loss: 0.005718
Validation Loss: 0.00593891
Epoch [155/300], Train Loss: 0.005917
Validation Loss: 0.00594476
Epoch [156/300], Train Loss: 0.005839
Validation Loss: 0.00593919
Epoch [157/300], Train Loss: 0.005901
Validation Loss: 0.00593637
Epoch [158/300], Train Loss: 0.005811
Validation Loss: 0.00593841
Epoch [159/300], Train Loss: 0.005928
Validation Loss: 0.00593506
Epoch [160/300], Train Loss: 0.005805
Validation Loss: 0.00593549
Epoch [161/300], Train Loss: 0.005874
Validation Loss: 0.00594391
Epoch [162/300], Train Loss: 0.005763
Validation Loss: 0.00594017
Epoch [163/300], Train Loss: 0.005862
Validation Loss: 0.00593539
Epoch [164/300], Train Loss: 0.005738
Validation Loss: 0.00593267
Epoch [165/300], Train Loss: 0.005712
Validation Loss: 0.00593229
Epoch [166/300], Train Loss: 0.005703
Validation Loss: 0.00593286
Epoch [167/300], Train Loss: 0.005735
Validation Loss: 0.00593416
Epoch [168/300], Train Loss: 0.005765
Validation Loss: 0.00593412
Epoch [169/300], Train Loss: 0.005920
Validation Loss: 0.00593216
Epoch [170/300], Train Loss: 0.005691
Validation Loss: 0.00593023
Epoch [171/300], Train Loss: 0.005847
Validation Loss: 0.00593038
Epoch [172/300], Train Loss: 0.005783
Validation Loss: 0.00593330
Epoch [173/300], Train Loss: 0.005690
Validation Loss: 0.00593230
Epoch [174/300], Train Loss: 0.005898
Validation Loss: 0.00593081
Epoch [175/300], Train Loss: 0.005929
Validation Loss: 0.00592855
Epoch [176/300], Train Loss: 0.005809
Validation Loss: 0.00592803
Epoch [177/300], Train Loss: 0.005673
Validation Loss: 0.00592882
Epoch [178/300], Train Loss: 0.005684
Validation Loss: 0.00592731
Epoch [179/300], Train Loss: 0.005770
Validation Loss: 0.00593156
Epoch [180/300], Train Loss: 0.005996
Validation Loss: 0.00593528
Epoch [181/300], Train Loss: 0.005804
Validation Loss: 0.00592865
Epoch [182/300], Train Loss: 0.005787
Validation Loss: 0.00592608
Epoch [183/300], Train Loss: 0.005955
Validation Loss: 0.00592567
Epoch [184/300], Train Loss: 0.005787
Validation Loss: 0.00592503
Epoch [185/300], Train Loss: 0.005675
Validation Loss: 0.00592442
Epoch [186/300], Train Loss: 0.005864
Validation Loss: 0.00592410
Epoch [187/300], Train Loss: 0.005855
Validation Loss: 0.00592371
Epoch [188/300], Train Loss: 0.005746
Validation Loss: 0.00592332
Epoch [189/300], Train Loss: 0.005849
Validation Loss: 0.00592312
Epoch [190/300], Train Loss: 0.005780
Validation Loss: 0.00592265
Epoch [191/300], Train Loss: 0.005911
Validation Loss: 0.00592252
Epoch [192/300], Train Loss: 0.005669
Validation Loss: 0.00592229
Epoch [193/300], Train Loss: 0.005856
Validation Loss: 0.00593023
Epoch [194/300], Train Loss: 0.005891
Validation Loss: 0.00593036
Epoch [195/300], Train Loss: 0.005791
Validation Loss: 0.00592270
Epoch [196/300], Train Loss: 0.005767
Validation Loss: 0.00592211
Epoch [197/300], Train Loss: 0.005794
Validation Loss: 0.00592146
Epoch [198/300], Train Loss: 0.005810
Validation Loss: 0.00592002
Epoch [199/300], Train Loss: 0.005788
Validation Loss: 0.00592016
Epoch [200/300], Train Loss: 0.005854
Validation Loss: 0.00592233
Epoch [201/300], Train Loss: 0.006061
Validation Loss: 0.00592097
Epoch [202/300], Train Loss: 0.005860
Validation Loss: 0.00591909
Epoch [203/300], Train Loss: 0.005760
Validation Loss: 0.00591891
Epoch [204/300], Train Loss: 0.005889
Validation Loss: 0.00591854
Epoch [205/300], Train Loss: 0.005685
Validation Loss: 0.00592028
Epoch [206/300], Train Loss: 0.005750
Validation Loss: 0.00592157
Epoch [207/300], Train Loss: 0.005723
Validation Loss: 0.00591959
Epoch [208/300], Train Loss: 0.005845
Validation Loss: 0.00591762
Epoch [209/300], Train Loss: 0.005763
Validation Loss: 0.00591647
Epoch [210/300], Train Loss: 0.005861
Validation Loss: 0.00591583
Epoch [211/300], Train Loss: 0.005828
Validation Loss: 0.00591562
Epoch [212/300], Train Loss: 0.005768
Validation Loss: 0.00591554
Epoch [213/300], Train Loss: 0.005935
Validation Loss: 0.00591539
Epoch [214/300], Train Loss: 0.005685
Validation Loss: 0.00591472
Epoch [215/300], Train Loss: 0.005744
Validation Loss: 0.00591448
Epoch [216/300], Train Loss: 0.006034
Validation Loss: 0.00591452
Epoch [217/300], Train Loss: 0.005737
Validation Loss: 0.00591505
Epoch [218/300], Train Loss: 0.005735
Validation Loss: 0.00591421
Epoch [219/300], Train Loss: 0.005775
Validation Loss: 0.00591480
Epoch [220/300], Train Loss: 0.005683
Validation Loss: 0.00591557
Epoch [221/300], Train Loss: 0.005910
Validation Loss: 0.00591750
Epoch [222/300], Train Loss: 0.005748
Validation Loss: 0.00591447
Epoch [223/300], Train Loss: 0.005802
Validation Loss: 0.00591278
Epoch [224/300], Train Loss: 0.005858
Validation Loss: 0.00591227
Epoch [225/300], Train Loss: 0.005777
Validation Loss: 0.00591330
Epoch [226/300], Train Loss: 0.005803
Validation Loss: 0.00591353
Epoch [227/300], Train Loss: 0.005700
Validation Loss: 0.00591235
Epoch [228/300], Train Loss: 0.005618
Validation Loss: 0.00591223
Epoch [229/300], Train Loss: 0.005800
Validation Loss: 0.00591413
Epoch [230/300], Train Loss: 0.005803
Validation Loss: 0.00591411
Epoch [231/300], Train Loss: 0.005689
Validation Loss: 0.00591207
Epoch [232/300], Train Loss: 0.005669
Validation Loss: 0.00591092
Epoch [233/300], Train Loss: 0.005861
Validation Loss: 0.00591087
Epoch [234/300], Train Loss: 0.005805
Validation Loss: 0.00590943
Epoch [235/300], Train Loss: 0.005790
Validation Loss: 0.00590909
Epoch [236/300], Train Loss: 0.005819
Validation Loss: 0.00590880
Epoch [237/300], Train Loss: 0.005683
Validation Loss: 0.00590848
Epoch [238/300], Train Loss: 0.005854
Validation Loss: 0.00590865
Epoch [239/300], Train Loss: 0.005985
Validation Loss: 0.00590836
Epoch [240/300], Train Loss: 0.005812
Validation Loss: 0.00590760
Epoch [241/300], Train Loss: 0.005770
Validation Loss: 0.00590721
Epoch [242/300], Train Loss: 0.005722
Validation Loss: 0.00590794
Epoch [243/300], Train Loss: 0.005809
Validation Loss: 0.00590849
Epoch [244/300], Train Loss: 0.005724
Validation Loss: 0.00590800
Epoch [245/300], Train Loss: 0.005865
Validation Loss: 0.00590841
Epoch [246/300], Train Loss: 0.005722
Validation Loss: 0.00590785
Epoch [247/300], Train Loss: 0.005683
Validation Loss: 0.00590605
Epoch [248/300], Train Loss: 0.005830
Validation Loss: 0.00590536
Epoch [249/300], Train Loss: 0.005740
Validation Loss: 0.00590500
Epoch [250/300], Train Loss: 0.005817
Validation Loss: 0.00590493
Epoch [251/300], Train Loss: 0.005823
Validation Loss: 0.00590546
Epoch [252/300], Train Loss: 0.005826
Validation Loss: 0.00590430
Epoch [253/300], Train Loss: 0.005788
Validation Loss: 0.00590404
Epoch [254/300], Train Loss: 0.005674
Validation Loss: 0.00590377
Epoch [255/300], Train Loss: 0.005866
Validation Loss: 0.00590411
Epoch [256/300], Train Loss: 0.005778
Validation Loss: 0.00590502
Epoch [257/300], Train Loss: 0.005710
Validation Loss: 0.00590544
Epoch [258/300], Train Loss: 0.006015
Validation Loss: 0.00590574
Epoch [259/300], Train Loss: 0.005718
Validation Loss: 0.00590365
Epoch [260/300], Train Loss: 0.005701
Validation Loss: 0.00590257
Epoch [261/300], Train Loss: 0.005707
Validation Loss: 0.00590229
Epoch [262/300], Train Loss: 0.005839
Validation Loss: 0.00590211
Epoch [263/300], Train Loss: 0.005821
Validation Loss: 0.00590158
Epoch [264/300], Train Loss: 0.005805
Validation Loss: 0.00590149
Epoch [265/300], Train Loss: 0.005821
Validation Loss: 0.00590127
Epoch [266/300], Train Loss: 0.005778
Validation Loss: 0.00590098
Epoch [267/300], Train Loss: 0.005731
Validation Loss: 0.00590118
Epoch [268/300], Train Loss: 0.005684
Validation Loss: 0.00590413
Epoch [269/300], Train Loss: 0.005705
Validation Loss: 0.00590538
Epoch [270/300], Train Loss: 0.005810
Validation Loss: 0.00590404
Epoch [271/300], Train Loss: 0.005676
Validation Loss: 0.00590374
Epoch [272/300], Train Loss: 0.005779
Validation Loss: 0.00590109
Epoch [273/300], Train Loss: 0.005716
Validation Loss: 0.00589947
Epoch [274/300], Train Loss: 0.005903
Validation Loss: 0.00589937
Epoch [275/300], Train Loss: 0.005708
Validation Loss: 0.00589897
Epoch [276/300], Train Loss: 0.005818
Validation Loss: 0.00589863
Epoch [277/300], Train Loss: 0.005780
Validation Loss: 0.00589840
Epoch [278/300], Train Loss: 0.005772
Validation Loss: 0.00589859
Epoch [279/300], Train Loss: 0.005779
Validation Loss: 0.00589904
Epoch [280/300], Train Loss: 0.005751
Validation Loss: 0.00589870
Epoch [281/300], Train Loss: 0.005817
Validation Loss: 0.00589840
Epoch [282/300], Train Loss: 0.005800
Validation Loss: 0.00589764
Epoch [283/300], Train Loss: 0.005670
Validation Loss: 0.00589694
Epoch [284/300], Train Loss: 0.005817
Validation Loss: 0.00589676
Epoch [285/300], Train Loss: 0.005768
Validation Loss: 0.00589675
Epoch [286/300], Train Loss: 0.005906
Validation Loss: 0.00589691
Epoch [287/300], Train Loss: 0.005771
Validation Loss: 0.00589701
Epoch [288/300], Train Loss: 0.005708
Validation Loss: 0.00589645
Epoch [289/300], Train Loss: 0.005897
Validation Loss: 0.00589718
Epoch [290/300], Train Loss: 0.005640
Validation Loss: 0.00589728
Epoch [291/300], Train Loss: 0.005628
Validation Loss: 0.00589837
Epoch [292/300], Train Loss: 0.005796
Validation Loss: 0.00590027
Epoch [293/300], Train Loss: 0.005992
Validation Loss: 0.00589782
Epoch [294/300], Train Loss: 0.005669
Validation Loss: 0.00589475
Epoch [295/300], Train Loss: 0.005779
Validation Loss: 0.00589446
Epoch [296/300], Train Loss: 0.005796
Validation Loss: 0.00589423
Epoch [297/300], Train Loss: 0.005837
Validation Loss: 0.00589400
Epoch [298/300], Train Loss: 0.005698
Validation Loss: 0.00589381
Epoch [299/300], Train Loss: 0.005640
Validation Loss: 0.00589432
Epoch [300/300], Train Loss: 0.005840
Validation Loss: 0.00589860

Evaluating model for: Router
Run 45/72 completed in 290.29 seconds with: {'MAE': np.float32(0.19509119), 'MSE': np.float32(0.065053515), 'RMSE': np.float32(0.2550559), 'SAE': np.float32(0.0005783874), 'NDE': np.float32(0.012755897)}

Run 46/72: hidden=256, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Router
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.107176
Validation Loss: 0.10050249
Epoch [2/300], Train Loss: 0.098224
Validation Loss: 0.09160745
Epoch [3/300], Train Loss: 0.089683
Validation Loss: 0.08255682
Epoch [4/300], Train Loss: 0.079889
Validation Loss: 0.07290867
Epoch [5/300], Train Loss: 0.069031
Validation Loss: 0.06209136
Epoch [6/300], Train Loss: 0.057777
Validation Loss: 0.04895966
Epoch [7/300], Train Loss: 0.043326
Validation Loss: 0.03192888
Epoch [8/300], Train Loss: 0.024641
Validation Loss: 0.01186980
Epoch [9/300], Train Loss: 0.009066
Validation Loss: 0.01204358
Epoch [10/300], Train Loss: 0.012747
Validation Loss: 0.00889989
Epoch [11/300], Train Loss: 0.006974
Validation Loss: 0.00651540
Epoch [12/300], Train Loss: 0.007171
Validation Loss: 0.00809080
Epoch [13/300], Train Loss: 0.007994
Validation Loss: 0.00741325
Epoch [14/300], Train Loss: 0.006763
Validation Loss: 0.00620194
Epoch [15/300], Train Loss: 0.006145
Validation Loss: 0.00643284
Epoch [16/300], Train Loss: 0.006271
Validation Loss: 0.00654983
Epoch [17/300], Train Loss: 0.006351
Validation Loss: 0.00618898
Epoch [18/300], Train Loss: 0.006061
Validation Loss: 0.00614815
Epoch [19/300], Train Loss: 0.006036
Validation Loss: 0.00621661
Epoch [20/300], Train Loss: 0.006138
Validation Loss: 0.00614186
Epoch [21/300], Train Loss: 0.006000
Validation Loss: 0.00611533
Epoch [22/300], Train Loss: 0.005973
Validation Loss: 0.00614847
Epoch [23/300], Train Loss: 0.006101
Validation Loss: 0.00614520
Epoch [24/300], Train Loss: 0.006030
Validation Loss: 0.00612025
Epoch [25/300], Train Loss: 0.005967
Validation Loss: 0.00610861
Epoch [26/300], Train Loss: 0.005900
Validation Loss: 0.00611057
Epoch [27/300], Train Loss: 0.006022
Validation Loss: 0.00610607
Epoch [28/300], Train Loss: 0.006010
Validation Loss: 0.00610618
Epoch [29/300], Train Loss: 0.006118
Validation Loss: 0.00610456
Epoch [30/300], Train Loss: 0.005912
Validation Loss: 0.00610244
Epoch [31/300], Train Loss: 0.005910
Validation Loss: 0.00610471
Epoch [32/300], Train Loss: 0.005957
Validation Loss: 0.00610721
Epoch [33/300], Train Loss: 0.006133
Validation Loss: 0.00611146
Epoch [34/300], Train Loss: 0.005947
Validation Loss: 0.00609828
Epoch [35/300], Train Loss: 0.005980
Validation Loss: 0.00609577
Epoch [36/300], Train Loss: 0.006011
Validation Loss: 0.00609567
Epoch [37/300], Train Loss: 0.005961
Validation Loss: 0.00609611
Epoch [38/300], Train Loss: 0.005831
Validation Loss: 0.00609749
Epoch [39/300], Train Loss: 0.005948
Validation Loss: 0.00610265
Epoch [40/300], Train Loss: 0.006073
Validation Loss: 0.00609146
Epoch [41/300], Train Loss: 0.006012
Validation Loss: 0.00609575
Epoch [42/300], Train Loss: 0.006144
Validation Loss: 0.00608918
Epoch [43/300], Train Loss: 0.006073
Validation Loss: 0.00608563
Epoch [44/300], Train Loss: 0.005943
Validation Loss: 0.00608785
Epoch [45/300], Train Loss: 0.005955
Validation Loss: 0.00608553
Epoch [46/300], Train Loss: 0.005915
Validation Loss: 0.00608217
Epoch [47/300], Train Loss: 0.006008
Validation Loss: 0.00608286
Epoch [48/300], Train Loss: 0.006135
Validation Loss: 0.00608337
Epoch [49/300], Train Loss: 0.006021
Validation Loss: 0.00607896
Epoch [50/300], Train Loss: 0.006023
Validation Loss: 0.00607677
Epoch [51/300], Train Loss: 0.005998
Validation Loss: 0.00607563
Epoch [52/300], Train Loss: 0.006027
Validation Loss: 0.00607432
Epoch [53/300], Train Loss: 0.006006
Validation Loss: 0.00607331
Epoch [54/300], Train Loss: 0.005979
Validation Loss: 0.00607813
Epoch [55/300], Train Loss: 0.005993
Validation Loss: 0.00607117
Epoch [56/300], Train Loss: 0.005994
Validation Loss: 0.00606946
Epoch [57/300], Train Loss: 0.006072
Validation Loss: 0.00606908
Epoch [58/300], Train Loss: 0.005925
Validation Loss: 0.00606672
Epoch [59/300], Train Loss: 0.005974
Validation Loss: 0.00606592
Epoch [60/300], Train Loss: 0.005958
Validation Loss: 0.00606632
Epoch [61/300], Train Loss: 0.005912
Validation Loss: 0.00607941
Epoch [62/300], Train Loss: 0.006075
Validation Loss: 0.00607841
Epoch [63/300], Train Loss: 0.005824
Validation Loss: 0.00606074
Epoch [64/300], Train Loss: 0.006065
Validation Loss: 0.00606751
Epoch [65/300], Train Loss: 0.005893
Validation Loss: 0.00605912
Epoch [66/300], Train Loss: 0.006072
Validation Loss: 0.00607795
Epoch [67/300], Train Loss: 0.005911
Validation Loss: 0.00606463
Epoch [68/300], Train Loss: 0.005889
Validation Loss: 0.00605649
Epoch [69/300], Train Loss: 0.005933
Validation Loss: 0.00605868
Epoch [70/300], Train Loss: 0.005958
Validation Loss: 0.00605295
Epoch [71/300], Train Loss: 0.006003
Validation Loss: 0.00605333
Epoch [72/300], Train Loss: 0.005782
Validation Loss: 0.00605320
Epoch [73/300], Train Loss: 0.005855
Validation Loss: 0.00605512
Epoch [74/300], Train Loss: 0.005989
Validation Loss: 0.00604862
Epoch [75/300], Train Loss: 0.005843
Validation Loss: 0.00604675
Epoch [76/300], Train Loss: 0.005980
Validation Loss: 0.00604626
Epoch [77/300], Train Loss: 0.005953
Validation Loss: 0.00604638
Epoch [78/300], Train Loss: 0.005977
Validation Loss: 0.00604464
Epoch [79/300], Train Loss: 0.005847
Validation Loss: 0.00604378
Epoch [80/300], Train Loss: 0.005994
Validation Loss: 0.00604448
Epoch [81/300], Train Loss: 0.005848
Validation Loss: 0.00604035
Epoch [82/300], Train Loss: 0.006071
Validation Loss: 0.00604079
Epoch [83/300], Train Loss: 0.005959
Validation Loss: 0.00603809
Epoch [84/300], Train Loss: 0.005873
Validation Loss: 0.00604079
Epoch [85/300], Train Loss: 0.005916
Validation Loss: 0.00604123
Epoch [86/300], Train Loss: 0.005874
Validation Loss: 0.00603613
Epoch [87/300], Train Loss: 0.005932
Validation Loss: 0.00603397
Epoch [88/300], Train Loss: 0.005910
Validation Loss: 0.00603279
Epoch [89/300], Train Loss: 0.005933
Validation Loss: 0.00603318
Epoch [90/300], Train Loss: 0.006055
Validation Loss: 0.00603062
Epoch [91/300], Train Loss: 0.005990
Validation Loss: 0.00603324
Epoch [92/300], Train Loss: 0.005929
Validation Loss: 0.00603873
Epoch [93/300], Train Loss: 0.005977
Validation Loss: 0.00603534
Epoch [94/300], Train Loss: 0.005770
Validation Loss: 0.00602804
Epoch [95/300], Train Loss: 0.005903
Validation Loss: 0.00602542
Epoch [96/300], Train Loss: 0.005984
Validation Loss: 0.00602445
Epoch [97/300], Train Loss: 0.005874
Validation Loss: 0.00602362
Epoch [98/300], Train Loss: 0.005960
Validation Loss: 0.00602504
Epoch [99/300], Train Loss: 0.005936
Validation Loss: 0.00602523
Epoch [100/300], Train Loss: 0.005931
Validation Loss: 0.00602377
Epoch [101/300], Train Loss: 0.005872
Validation Loss: 0.00602329
Epoch [102/300], Train Loss: 0.005954
Validation Loss: 0.00601868
Epoch [103/300], Train Loss: 0.005910
Validation Loss: 0.00601995
Epoch [104/300], Train Loss: 0.005847
Validation Loss: 0.00601661
Epoch [105/300], Train Loss: 0.005938
Validation Loss: 0.00601886
Epoch [106/300], Train Loss: 0.006100
Validation Loss: 0.00601767
Epoch [107/300], Train Loss: 0.005881
Validation Loss: 0.00601370
Epoch [108/300], Train Loss: 0.006063
Validation Loss: 0.00601260
Epoch [109/300], Train Loss: 0.006132
Validation Loss: 0.00601166
Epoch [110/300], Train Loss: 0.005858
Validation Loss: 0.00601113
Epoch [111/300], Train Loss: 0.005843
Validation Loss: 0.00601375
Epoch [112/300], Train Loss: 0.005997
Validation Loss: 0.00601843
Epoch [113/300], Train Loss: 0.006005
Validation Loss: 0.00600886
Epoch [114/300], Train Loss: 0.006031
Validation Loss: 0.00601242
Epoch [115/300], Train Loss: 0.005977
Validation Loss: 0.00600967
Epoch [116/300], Train Loss: 0.005881
Validation Loss: 0.00600693
Epoch [117/300], Train Loss: 0.005905
Validation Loss: 0.00601588
Epoch [118/300], Train Loss: 0.005883
Validation Loss: 0.00600557
Epoch [119/300], Train Loss: 0.005871
Validation Loss: 0.00600188
Epoch [120/300], Train Loss: 0.005890
Validation Loss: 0.00600139
Epoch [121/300], Train Loss: 0.005836
Validation Loss: 0.00600192
Epoch [122/300], Train Loss: 0.005834
Validation Loss: 0.00599933
Epoch [123/300], Train Loss: 0.005911
Validation Loss: 0.00600721
Epoch [124/300], Train Loss: 0.005906
Validation Loss: 0.00600849
Epoch [125/300], Train Loss: 0.005970
Validation Loss: 0.00599976
Epoch [126/300], Train Loss: 0.005951
Validation Loss: 0.00599587
Epoch [127/300], Train Loss: 0.005886
Validation Loss: 0.00599795
Epoch [128/300], Train Loss: 0.006001
Validation Loss: 0.00599432
Epoch [129/300], Train Loss: 0.005823
Validation Loss: 0.00599755
Epoch [130/300], Train Loss: 0.006020
Validation Loss: 0.00600036
Epoch [131/300], Train Loss: 0.005857
Validation Loss: 0.00599495
Epoch [132/300], Train Loss: 0.005838
Validation Loss: 0.00599210
Epoch [133/300], Train Loss: 0.005852
Validation Loss: 0.00599018
Epoch [134/300], Train Loss: 0.006001
Validation Loss: 0.00599006
Epoch [135/300], Train Loss: 0.005783
Validation Loss: 0.00598847
Epoch [136/300], Train Loss: 0.005888
Validation Loss: 0.00598793
Epoch [137/300], Train Loss: 0.006036
Validation Loss: 0.00598695
Epoch [138/300], Train Loss: 0.005849
Validation Loss: 0.00598655
Epoch [139/300], Train Loss: 0.005846
Validation Loss: 0.00598569
Epoch [140/300], Train Loss: 0.005817
Validation Loss: 0.00598585
Epoch [141/300], Train Loss: 0.005743
Validation Loss: 0.00598590
Epoch [142/300], Train Loss: 0.005795
Validation Loss: 0.00598388
Epoch [143/300], Train Loss: 0.005895
Validation Loss: 0.00598327
Epoch [144/300], Train Loss: 0.005879
Validation Loss: 0.00598132
Epoch [145/300], Train Loss: 0.005808
Validation Loss: 0.00598104
Epoch [146/300], Train Loss: 0.005773
Validation Loss: 0.00598371
Epoch [147/300], Train Loss: 0.005938
Validation Loss: 0.00598217
Epoch [148/300], Train Loss: 0.005765
Validation Loss: 0.00597838
Epoch [149/300], Train Loss: 0.005985
Validation Loss: 0.00597818
Epoch [150/300], Train Loss: 0.006097
Validation Loss: 0.00598090
Epoch [151/300], Train Loss: 0.005867
Validation Loss: 0.00598021
Epoch [152/300], Train Loss: 0.006036
Validation Loss: 0.00597550
Epoch [153/300], Train Loss: 0.005733
Validation Loss: 0.00597480
Epoch [154/300], Train Loss: 0.005763
Validation Loss: 0.00597566
Epoch [155/300], Train Loss: 0.005957
Validation Loss: 0.00598063
Epoch [156/300], Train Loss: 0.005885
Validation Loss: 0.00597402
Epoch [157/300], Train Loss: 0.005945
Validation Loss: 0.00597461
Epoch [158/300], Train Loss: 0.005854
Validation Loss: 0.00597627
Epoch [159/300], Train Loss: 0.005977
Validation Loss: 0.00597101
Epoch [160/300], Train Loss: 0.005831
Validation Loss: 0.00597154
Epoch [161/300], Train Loss: 0.005917
Validation Loss: 0.00598001
Epoch [162/300], Train Loss: 0.005804
Validation Loss: 0.00597258
Epoch [163/300], Train Loss: 0.005906
Validation Loss: 0.00596810
Epoch [164/300], Train Loss: 0.005781
Validation Loss: 0.00596706
Epoch [165/300], Train Loss: 0.005749
Validation Loss: 0.00596638
Epoch [166/300], Train Loss: 0.005740
Validation Loss: 0.00596755
Epoch [167/300], Train Loss: 0.005790
Validation Loss: 0.00596891
Epoch [168/300], Train Loss: 0.005808
Validation Loss: 0.00596703
Epoch [169/300], Train Loss: 0.005967
Validation Loss: 0.00596416
Epoch [170/300], Train Loss: 0.005728
Validation Loss: 0.00596323
Epoch [171/300], Train Loss: 0.005879
Validation Loss: 0.00596265
Epoch [172/300], Train Loss: 0.005822
Validation Loss: 0.00596653
Epoch [173/300], Train Loss: 0.005728
Validation Loss: 0.00596496
Epoch [174/300], Train Loss: 0.005940
Validation Loss: 0.00596225
Epoch [175/300], Train Loss: 0.005972
Validation Loss: 0.00595999
Epoch [176/300], Train Loss: 0.005857
Validation Loss: 0.00596026
Epoch [177/300], Train Loss: 0.005720
Validation Loss: 0.00596133
Epoch [178/300], Train Loss: 0.005722
Validation Loss: 0.00595846
Epoch [179/300], Train Loss: 0.005808
Validation Loss: 0.00596475
Epoch [180/300], Train Loss: 0.006040
Validation Loss: 0.00596684
Epoch [181/300], Train Loss: 0.005855
Validation Loss: 0.00595718
Epoch [182/300], Train Loss: 0.005822
Validation Loss: 0.00595571
Epoch [183/300], Train Loss: 0.006000
Validation Loss: 0.00595508
Epoch [184/300], Train Loss: 0.005816
Validation Loss: 0.00595458
Epoch [185/300], Train Loss: 0.005715
Validation Loss: 0.00595392
Epoch [186/300], Train Loss: 0.005905
Validation Loss: 0.00595349
Epoch [187/300], Train Loss: 0.005880
Validation Loss: 0.00595272
Epoch [188/300], Train Loss: 0.005787
Validation Loss: 0.00595215
Epoch [189/300], Train Loss: 0.005877
Validation Loss: 0.00595151
Epoch [190/300], Train Loss: 0.005811
Validation Loss: 0.00595143
Epoch [191/300], Train Loss: 0.005940
Validation Loss: 0.00595089
Epoch [192/300], Train Loss: 0.005705
Validation Loss: 0.00595040
Epoch [193/300], Train Loss: 0.005894
Validation Loss: 0.00596098
Epoch [194/300], Train Loss: 0.005929
Validation Loss: 0.00595734
Epoch [195/300], Train Loss: 0.005836
Validation Loss: 0.00594837
Epoch [196/300], Train Loss: 0.005818
Validation Loss: 0.00594784
Epoch [197/300], Train Loss: 0.005825
Validation Loss: 0.00594766
Epoch [198/300], Train Loss: 0.005837
Validation Loss: 0.00594667
Epoch [199/300], Train Loss: 0.005825
Validation Loss: 0.00594706
Epoch [200/300], Train Loss: 0.005893
Validation Loss: 0.00594975
Epoch [201/300], Train Loss: 0.006089
Validation Loss: 0.00594678
Epoch [202/300], Train Loss: 0.005890
Validation Loss: 0.00594692
Epoch [203/300], Train Loss: 0.005798
Validation Loss: 0.00594599
Epoch [204/300], Train Loss: 0.005912
Validation Loss: 0.00594443
Epoch [205/300], Train Loss: 0.005711
Validation Loss: 0.00594709
Epoch [206/300], Train Loss: 0.005786
Validation Loss: 0.00594750
Epoch [207/300], Train Loss: 0.005759
Validation Loss: 0.00594342
Epoch [208/300], Train Loss: 0.005879
Validation Loss: 0.00594154
Epoch [209/300], Train Loss: 0.005801
Validation Loss: 0.00594100
Epoch [210/300], Train Loss: 0.005888
Validation Loss: 0.00594047
Epoch [211/300], Train Loss: 0.005862
Validation Loss: 0.00594010
Epoch [212/300], Train Loss: 0.005795
Validation Loss: 0.00593996
Epoch [213/300], Train Loss: 0.005970
Validation Loss: 0.00593936
Epoch [214/300], Train Loss: 0.005711
Validation Loss: 0.00593893
Epoch [215/300], Train Loss: 0.005781
Validation Loss: 0.00593827
Epoch [216/300], Train Loss: 0.006049
Validation Loss: 0.00593787
Epoch [217/300], Train Loss: 0.005769
Validation Loss: 0.00593827
Epoch [218/300], Train Loss: 0.005772
Validation Loss: 0.00593713
Epoch [219/300], Train Loss: 0.005806
Validation Loss: 0.00593751
Epoch [220/300], Train Loss: 0.005714
Validation Loss: 0.00593805
Epoch [221/300], Train Loss: 0.005939
Validation Loss: 0.00593971
Epoch [222/300], Train Loss: 0.005781
Validation Loss: 0.00593605
Epoch [223/300], Train Loss: 0.005822
Validation Loss: 0.00593468
Epoch [224/300], Train Loss: 0.005898
Validation Loss: 0.00593426
Epoch [225/300], Train Loss: 0.005806
Validation Loss: 0.00593502
Epoch [226/300], Train Loss: 0.005827
Validation Loss: 0.00593527
Epoch [227/300], Train Loss: 0.005743
Validation Loss: 0.00593372
Epoch [228/300], Train Loss: 0.005650
Validation Loss: 0.00593325
Epoch [229/300], Train Loss: 0.005835
Validation Loss: 0.00593485
Epoch [230/300], Train Loss: 0.005830
Validation Loss: 0.00593467
Epoch [231/300], Train Loss: 0.005711
Validation Loss: 0.00593253
Epoch [232/300], Train Loss: 0.005700
Validation Loss: 0.00593136
Epoch [233/300], Train Loss: 0.005892
Validation Loss: 0.00593121
Epoch [234/300], Train Loss: 0.005838
Validation Loss: 0.00593012
Epoch [235/300], Train Loss: 0.005823
Validation Loss: 0.00593004
Epoch [236/300], Train Loss: 0.005850
Validation Loss: 0.00592923
Epoch [237/300], Train Loss: 0.005712
Validation Loss: 0.00592882
Epoch [238/300], Train Loss: 0.005878
Validation Loss: 0.00592894
Epoch [239/300], Train Loss: 0.006016
Validation Loss: 0.00592842
Epoch [240/300], Train Loss: 0.005835
Validation Loss: 0.00592745
Epoch [241/300], Train Loss: 0.005798
Validation Loss: 0.00592701
Epoch [242/300], Train Loss: 0.005750
Validation Loss: 0.00592745
Epoch [243/300], Train Loss: 0.005824
Validation Loss: 0.00592793
Epoch [244/300], Train Loss: 0.005742
Validation Loss: 0.00592722
Epoch [245/300], Train Loss: 0.005887
Validation Loss: 0.00592740
Epoch [246/300], Train Loss: 0.005751
Validation Loss: 0.00592646
Epoch [247/300], Train Loss: 0.005717
Validation Loss: 0.00592482
Epoch [248/300], Train Loss: 0.005858
Validation Loss: 0.00592435
Epoch [249/300], Train Loss: 0.005782
Validation Loss: 0.00592419
Epoch [250/300], Train Loss: 0.005846
Validation Loss: 0.00592378
Epoch [251/300], Train Loss: 0.005857
Validation Loss: 0.00592438
Epoch [252/300], Train Loss: 0.005849
Validation Loss: 0.00592285
Epoch [253/300], Train Loss: 0.005805
Validation Loss: 0.00592309
Epoch [254/300], Train Loss: 0.005704
Validation Loss: 0.00592236
Epoch [255/300], Train Loss: 0.005886
Validation Loss: 0.00592235
Epoch [256/300], Train Loss: 0.005800
Validation Loss: 0.00592339
Epoch [257/300], Train Loss: 0.005746
Validation Loss: 0.00592331
Epoch [258/300], Train Loss: 0.006045
Validation Loss: 0.00592280
Epoch [259/300], Train Loss: 0.005741
Validation Loss: 0.00592060
Epoch [260/300], Train Loss: 0.005724
Validation Loss: 0.00592006
Epoch [261/300], Train Loss: 0.005742
Validation Loss: 0.00591968
Epoch [262/300], Train Loss: 0.005858
Validation Loss: 0.00591949
Epoch [263/300], Train Loss: 0.005848
Validation Loss: 0.00591898
Epoch [264/300], Train Loss: 0.005830
Validation Loss: 0.00591879
Epoch [265/300], Train Loss: 0.005846
Validation Loss: 0.00591841
Epoch [266/300], Train Loss: 0.005800
Validation Loss: 0.00591798
Epoch [267/300], Train Loss: 0.005761
Validation Loss: 0.00591792
Epoch [268/300], Train Loss: 0.005708
Validation Loss: 0.00592086
Epoch [269/300], Train Loss: 0.005721
Validation Loss: 0.00592152
Epoch [270/300], Train Loss: 0.005829
Validation Loss: 0.00591952
Epoch [271/300], Train Loss: 0.005699
Validation Loss: 0.00591898
Epoch [272/300], Train Loss: 0.005817
Validation Loss: 0.00591657
Epoch [273/300], Train Loss: 0.005735
Validation Loss: 0.00591571
Epoch [274/300], Train Loss: 0.005930
Validation Loss: 0.00591540
Epoch [275/300], Train Loss: 0.005733
Validation Loss: 0.00591506
Epoch [276/300], Train Loss: 0.005844
Validation Loss: 0.00591471
Epoch [277/300], Train Loss: 0.005801
Validation Loss: 0.00591438
Epoch [278/300], Train Loss: 0.005798
Validation Loss: 0.00591443
Epoch [279/300], Train Loss: 0.005804
Validation Loss: 0.00591467
Epoch [280/300], Train Loss: 0.005775
Validation Loss: 0.00591409
Epoch [281/300], Train Loss: 0.005843
Validation Loss: 0.00591370
Epoch [282/300], Train Loss: 0.005831
Validation Loss: 0.00591290
Epoch [283/300], Train Loss: 0.005690
Validation Loss: 0.00591247
Epoch [284/300], Train Loss: 0.005840
Validation Loss: 0.00591211
Epoch [285/300], Train Loss: 0.005796
Validation Loss: 0.00591193
Epoch [286/300], Train Loss: 0.005931
Validation Loss: 0.00591207
Epoch [287/300], Train Loss: 0.005784
Validation Loss: 0.00591199
Epoch [288/300], Train Loss: 0.005722
Validation Loss: 0.00591117
Epoch [289/300], Train Loss: 0.005916
Validation Loss: 0.00591165
Epoch [290/300], Train Loss: 0.005668
Validation Loss: 0.00591145
Epoch [291/300], Train Loss: 0.005650
Validation Loss: 0.00591241
Epoch [292/300], Train Loss: 0.005818
Validation Loss: 0.00591437
Epoch [293/300], Train Loss: 0.006011
Validation Loss: 0.00591147
Epoch [294/300], Train Loss: 0.005687
Validation Loss: 0.00590935
Epoch [295/300], Train Loss: 0.005798
Validation Loss: 0.00590930
Epoch [296/300], Train Loss: 0.005827
Validation Loss: 0.00590863
Epoch [297/300], Train Loss: 0.005871
Validation Loss: 0.00590830
Epoch [298/300], Train Loss: 0.005722
Validation Loss: 0.00590805
Epoch [299/300], Train Loss: 0.005661
Validation Loss: 0.00590863
Epoch [300/300], Train Loss: 0.005871
Validation Loss: 0.00591332

Evaluating model for: Router
Run 46/72 completed in 386.61 seconds with: {'MAE': np.float32(0.19473399), 'MSE': np.float32(0.064969726), 'RMSE': np.float32(0.2548916), 'SAE': np.float32(0.0006370392), 'NDE': np.float32(0.012747678)}

Run 47/72: hidden=256, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Router
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.111795
Validation Loss: 0.10532690
Epoch [2/300], Train Loss: 0.103076
Validation Loss: 0.09641780
Epoch [3/300], Train Loss: 0.094523
Validation Loss: 0.08725834
Epoch [4/300], Train Loss: 0.084575
Validation Loss: 0.07740166
Epoch [5/300], Train Loss: 0.073597
Validation Loss: 0.06662447
Epoch [6/300], Train Loss: 0.062297
Validation Loss: 0.05338834
Epoch [7/300], Train Loss: 0.047535
Validation Loss: 0.03492056
Epoch [8/300], Train Loss: 0.026199
Validation Loss: 0.01052093
Epoch [9/300], Train Loss: 0.010466
Validation Loss: 0.01639041
Epoch [10/300], Train Loss: 0.012091
Validation Loss: 0.00653814
Epoch [11/300], Train Loss: 0.006646
Validation Loss: 0.00802560
Epoch [12/300], Train Loss: 0.008487
Validation Loss: 0.00848141
Epoch [13/300], Train Loss: 0.007839
Validation Loss: 0.00665904
Epoch [14/300], Train Loss: 0.006270
Validation Loss: 0.00642633
Epoch [15/300], Train Loss: 0.006651
Validation Loss: 0.00691734
Epoch [16/300], Train Loss: 0.006420
Validation Loss: 0.00629481
Epoch [17/300], Train Loss: 0.006172
Validation Loss: 0.00622601
Epoch [18/300], Train Loss: 0.006219
Validation Loss: 0.00632472
Epoch [19/300], Train Loss: 0.006166
Validation Loss: 0.00621763
Epoch [20/300], Train Loss: 0.006169
Validation Loss: 0.00619959
Epoch [21/300], Train Loss: 0.006071
Validation Loss: 0.00623620
Epoch [22/300], Train Loss: 0.006065
Validation Loss: 0.00620044
Epoch [23/300], Train Loss: 0.006179
Validation Loss: 0.00617839
Epoch [24/300], Train Loss: 0.006080
Validation Loss: 0.00617680
Epoch [25/300], Train Loss: 0.006059
Validation Loss: 0.00617566
Epoch [26/300], Train Loss: 0.005990
Validation Loss: 0.00617593
Epoch [27/300], Train Loss: 0.006085
Validation Loss: 0.00617524
Epoch [28/300], Train Loss: 0.006083
Validation Loss: 0.00617367
Epoch [29/300], Train Loss: 0.006196
Validation Loss: 0.00617110
Epoch [30/300], Train Loss: 0.006003
Validation Loss: 0.00616993
Epoch [31/300], Train Loss: 0.005989
Validation Loss: 0.00617762
Epoch [32/300], Train Loss: 0.006033
Validation Loss: 0.00618581
Epoch [33/300], Train Loss: 0.006228
Validation Loss: 0.00618652
Epoch [34/300], Train Loss: 0.006033
Validation Loss: 0.00616608
Epoch [35/300], Train Loss: 0.006064
Validation Loss: 0.00616559
Epoch [36/300], Train Loss: 0.006105
Validation Loss: 0.00616569
Epoch [37/300], Train Loss: 0.006027
Validation Loss: 0.00616917
Epoch [38/300], Train Loss: 0.005908
Validation Loss: 0.00617010
Epoch [39/300], Train Loss: 0.006022
Validation Loss: 0.00617229
Epoch [40/300], Train Loss: 0.006147
Validation Loss: 0.00615988
Epoch [41/300], Train Loss: 0.006096
Validation Loss: 0.00616679
Epoch [42/300], Train Loss: 0.006240
Validation Loss: 0.00615702
Epoch [43/300], Train Loss: 0.006155
Validation Loss: 0.00615582
Epoch [44/300], Train Loss: 0.006031
Validation Loss: 0.00616006
Epoch [45/300], Train Loss: 0.006024
Validation Loss: 0.00615471
Epoch [46/300], Train Loss: 0.005992
Validation Loss: 0.00615196
Epoch [47/300], Train Loss: 0.006094
Validation Loss: 0.00615453
Epoch [48/300], Train Loss: 0.006207
Validation Loss: 0.00615773
Epoch [49/300], Train Loss: 0.006097
Validation Loss: 0.00615042
Epoch [50/300], Train Loss: 0.006097
Validation Loss: 0.00614735
Epoch [51/300], Train Loss: 0.006079
Validation Loss: 0.00614644
Epoch [52/300], Train Loss: 0.006115
Validation Loss: 0.00614502
Epoch [53/300], Train Loss: 0.006080
Validation Loss: 0.00614528
Epoch [54/300], Train Loss: 0.006068
Validation Loss: 0.00615262
Epoch [55/300], Train Loss: 0.006064
Validation Loss: 0.00614181
Epoch [56/300], Train Loss: 0.006061
Validation Loss: 0.00614110
Epoch [57/300], Train Loss: 0.006146
Validation Loss: 0.00614002
Epoch [58/300], Train Loss: 0.005998
Validation Loss: 0.00613753
Epoch [59/300], Train Loss: 0.006053
Validation Loss: 0.00613638
Epoch [60/300], Train Loss: 0.006025
Validation Loss: 0.00613854
Epoch [61/300], Train Loss: 0.005980
Validation Loss: 0.00615270
Epoch [62/300], Train Loss: 0.006159
Validation Loss: 0.00614929
Epoch [63/300], Train Loss: 0.005893
Validation Loss: 0.00613227
Epoch [64/300], Train Loss: 0.006139
Validation Loss: 0.00613839
Epoch [65/300], Train Loss: 0.005967
Validation Loss: 0.00613406
Epoch [66/300], Train Loss: 0.006169
Validation Loss: 0.00616175
Epoch [67/300], Train Loss: 0.005991
Validation Loss: 0.00613431
Epoch [68/300], Train Loss: 0.005966
Validation Loss: 0.00613150
Epoch [69/300], Train Loss: 0.006020
Validation Loss: 0.00613039
Epoch [70/300], Train Loss: 0.006032
Validation Loss: 0.00612386
Epoch [71/300], Train Loss: 0.006083
Validation Loss: 0.00612908
Epoch [72/300], Train Loss: 0.005853
Validation Loss: 0.00612491
Epoch [73/300], Train Loss: 0.005925
Validation Loss: 0.00612446
Epoch [74/300], Train Loss: 0.006070
Validation Loss: 0.00611969
Epoch [75/300], Train Loss: 0.005921
Validation Loss: 0.00611838
Epoch [76/300], Train Loss: 0.006057
Validation Loss: 0.00611962
Epoch [77/300], Train Loss: 0.006040
Validation Loss: 0.00611906
Epoch [78/300], Train Loss: 0.006060
Validation Loss: 0.00611561
Epoch [79/300], Train Loss: 0.005921
Validation Loss: 0.00611480
Epoch [80/300], Train Loss: 0.006084
Validation Loss: 0.00611723
Epoch [81/300], Train Loss: 0.005919
Validation Loss: 0.00611197
Epoch [82/300], Train Loss: 0.006131
Validation Loss: 0.00611189
Epoch [83/300], Train Loss: 0.006035
Validation Loss: 0.00610967
Epoch [84/300], Train Loss: 0.005948
Validation Loss: 0.00611567
Epoch [85/300], Train Loss: 0.006000
Validation Loss: 0.00611441
Epoch [86/300], Train Loss: 0.005954
Validation Loss: 0.00610727
Epoch [87/300], Train Loss: 0.006005
Validation Loss: 0.00610525
Epoch [88/300], Train Loss: 0.005983
Validation Loss: 0.00610385
Epoch [89/300], Train Loss: 0.005996
Validation Loss: 0.00610329
Epoch [90/300], Train Loss: 0.006131
Validation Loss: 0.00610260
Epoch [91/300], Train Loss: 0.006048
Validation Loss: 0.00610629
Epoch [92/300], Train Loss: 0.005996
Validation Loss: 0.00611226
Epoch [93/300], Train Loss: 0.006055
Validation Loss: 0.00610756
Epoch [94/300], Train Loss: 0.005836
Validation Loss: 0.00609902
Epoch [95/300], Train Loss: 0.005970
Validation Loss: 0.00609631
Epoch [96/300], Train Loss: 0.006043
Validation Loss: 0.00609558
Epoch [97/300], Train Loss: 0.005943
Validation Loss: 0.00609521
Epoch [98/300], Train Loss: 0.006040
Validation Loss: 0.00609760
Epoch [99/300], Train Loss: 0.005996
Validation Loss: 0.00609690
Epoch [100/300], Train Loss: 0.005994
Validation Loss: 0.00609555
Epoch [101/300], Train Loss: 0.005940
Validation Loss: 0.00609564
Epoch [102/300], Train Loss: 0.006017
Validation Loss: 0.00608942
Epoch [103/300], Train Loss: 0.005979
Validation Loss: 0.00608919
Epoch [104/300], Train Loss: 0.005924
Validation Loss: 0.00608634
Epoch [105/300], Train Loss: 0.006011
Validation Loss: 0.00609304
Epoch [106/300], Train Loss: 0.006167
Validation Loss: 0.00608919
Epoch [107/300], Train Loss: 0.005954
Validation Loss: 0.00608350
Epoch [108/300], Train Loss: 0.006149
Validation Loss: 0.00608236
Epoch [109/300], Train Loss: 0.006198
Validation Loss: 0.00608217
Epoch [110/300], Train Loss: 0.005935
Validation Loss: 0.00608237
Epoch [111/300], Train Loss: 0.005910
Validation Loss: 0.00608583
Epoch [112/300], Train Loss: 0.006081
Validation Loss: 0.00609018
Epoch [113/300], Train Loss: 0.006079
Validation Loss: 0.00607791
Epoch [114/300], Train Loss: 0.006094
Validation Loss: 0.00608240
Epoch [115/300], Train Loss: 0.006049
Validation Loss: 0.00607667
Epoch [116/300], Train Loss: 0.005946
Validation Loss: 0.00608142
Epoch [117/300], Train Loss: 0.005980
Validation Loss: 0.00609027
Epoch [118/300], Train Loss: 0.005954
Validation Loss: 0.00607310
Epoch [119/300], Train Loss: 0.005934
Validation Loss: 0.00607097
Epoch [120/300], Train Loss: 0.005949
Validation Loss: 0.00606942
Epoch [121/300], Train Loss: 0.005904
Validation Loss: 0.00606854
Epoch [122/300], Train Loss: 0.005894
Validation Loss: 0.00606971
Epoch [123/300], Train Loss: 0.005973
Validation Loss: 0.00608022
Epoch [124/300], Train Loss: 0.005972
Validation Loss: 0.00607572
Epoch [125/300], Train Loss: 0.006034
Validation Loss: 0.00606636
Epoch [126/300], Train Loss: 0.006015
Validation Loss: 0.00606352
Epoch [127/300], Train Loss: 0.005956
Validation Loss: 0.00606374
Epoch [128/300], Train Loss: 0.006062
Validation Loss: 0.00606229
Epoch [129/300], Train Loss: 0.005888
Validation Loss: 0.00606972
Epoch [130/300], Train Loss: 0.006080
Validation Loss: 0.00606853
Epoch [131/300], Train Loss: 0.005915
Validation Loss: 0.00606053
Epoch [132/300], Train Loss: 0.005908
Validation Loss: 0.00605860
Epoch [133/300], Train Loss: 0.005916
Validation Loss: 0.00605666
Epoch [134/300], Train Loss: 0.006078
Validation Loss: 0.00605833
Epoch [135/300], Train Loss: 0.005857
Validation Loss: 0.00605452
Epoch [136/300], Train Loss: 0.005955
Validation Loss: 0.00605380
Epoch [137/300], Train Loss: 0.006106
Validation Loss: 0.00605322
Epoch [138/300], Train Loss: 0.005907
Validation Loss: 0.00605354
Epoch [139/300], Train Loss: 0.005904
Validation Loss: 0.00605241
Epoch [140/300], Train Loss: 0.005878
Validation Loss: 0.00605255
Epoch [141/300], Train Loss: 0.005812
Validation Loss: 0.00605240
Epoch [142/300], Train Loss: 0.005862
Validation Loss: 0.00604942
Epoch [143/300], Train Loss: 0.005956
Validation Loss: 0.00604906
Epoch [144/300], Train Loss: 0.005932
Validation Loss: 0.00604604
Epoch [145/300], Train Loss: 0.005863
Validation Loss: 0.00604656
Epoch [146/300], Train Loss: 0.005833
Validation Loss: 0.00605094
Epoch [147/300], Train Loss: 0.005984
Validation Loss: 0.00604781
Epoch [148/300], Train Loss: 0.005815
Validation Loss: 0.00604243
Epoch [149/300], Train Loss: 0.006046
Validation Loss: 0.00604177
Epoch [150/300], Train Loss: 0.006164
Validation Loss: 0.00604342
Epoch [151/300], Train Loss: 0.005931
Validation Loss: 0.00604195
Epoch [152/300], Train Loss: 0.006108
Validation Loss: 0.00603967
Epoch [153/300], Train Loss: 0.005782
Validation Loss: 0.00603828
Epoch [154/300], Train Loss: 0.005804
Validation Loss: 0.00603977
Epoch [155/300], Train Loss: 0.006030
Validation Loss: 0.00604617
Epoch [156/300], Train Loss: 0.005940
Validation Loss: 0.00603663
Epoch [157/300], Train Loss: 0.006014
Validation Loss: 0.00603808
Epoch [158/300], Train Loss: 0.005917
Validation Loss: 0.00603730
Epoch [159/300], Train Loss: 0.006049
Validation Loss: 0.00603622
Epoch [160/300], Train Loss: 0.005901
Validation Loss: 0.00603646
Epoch [161/300], Train Loss: 0.005980
Validation Loss: 0.00604514
Epoch [162/300], Train Loss: 0.005858
Validation Loss: 0.00603334
Epoch [163/300], Train Loss: 0.005969
Validation Loss: 0.00602924
Epoch [164/300], Train Loss: 0.005832
Validation Loss: 0.00602815
Epoch [165/300], Train Loss: 0.005797
Validation Loss: 0.00602933
Epoch [166/300], Train Loss: 0.005794
Validation Loss: 0.00603222
Epoch [167/300], Train Loss: 0.005854
Validation Loss: 0.00603145
Epoch [168/300], Train Loss: 0.005873
Validation Loss: 0.00602698
Epoch [169/300], Train Loss: 0.006035
Validation Loss: 0.00602429
Epoch [170/300], Train Loss: 0.005788
Validation Loss: 0.00602332
Epoch [171/300], Train Loss: 0.005938
Validation Loss: 0.00602449
Epoch [172/300], Train Loss: 0.005874
Validation Loss: 0.00603208
Epoch [173/300], Train Loss: 0.005771
Validation Loss: 0.00602593
Epoch [174/300], Train Loss: 0.005997
Validation Loss: 0.00602118
Epoch [175/300], Train Loss: 0.006029
Validation Loss: 0.00601949
Epoch [176/300], Train Loss: 0.005908
Validation Loss: 0.00601897
Epoch [177/300], Train Loss: 0.005770
Validation Loss: 0.00601864
Epoch [178/300], Train Loss: 0.005766
Validation Loss: 0.00601983
Epoch [179/300], Train Loss: 0.005859
Validation Loss: 0.00602776
Epoch [180/300], Train Loss: 0.006082
Validation Loss: 0.00602493
Epoch [181/300], Train Loss: 0.005908
Validation Loss: 0.00601475
Epoch [182/300], Train Loss: 0.005880
Validation Loss: 0.00601411
Epoch [183/300], Train Loss: 0.006062
Validation Loss: 0.00601369
Epoch [184/300], Train Loss: 0.005869
Validation Loss: 0.00601394
Epoch [185/300], Train Loss: 0.005757
Validation Loss: 0.00601224
Epoch [186/300], Train Loss: 0.005972
Validation Loss: 0.00601129
Epoch [187/300], Train Loss: 0.005951
Validation Loss: 0.00601023
Epoch [188/300], Train Loss: 0.005838
Validation Loss: 0.00600951
Epoch [189/300], Train Loss: 0.005936
Validation Loss: 0.00600891
Epoch [190/300], Train Loss: 0.005862
Validation Loss: 0.00600806
Epoch [191/300], Train Loss: 0.005979
Validation Loss: 0.00600738
Epoch [192/300], Train Loss: 0.005752
Validation Loss: 0.00600830
Epoch [193/300], Train Loss: 0.005942
Validation Loss: 0.00602364
Epoch [194/300], Train Loss: 0.005988
Validation Loss: 0.00601417
Epoch [195/300], Train Loss: 0.005891
Validation Loss: 0.00600433
Epoch [196/300], Train Loss: 0.005864
Validation Loss: 0.00600382
Epoch [197/300], Train Loss: 0.005878
Validation Loss: 0.00600458
Epoch [198/300], Train Loss: 0.005889
Validation Loss: 0.00600314
Epoch [199/300], Train Loss: 0.005880
Validation Loss: 0.00600436
Epoch [200/300], Train Loss: 0.005949
Validation Loss: 0.00600745
Epoch [201/300], Train Loss: 0.006138
Validation Loss: 0.00600176
Epoch [202/300], Train Loss: 0.005948
Validation Loss: 0.00600467
Epoch [203/300], Train Loss: 0.005843
Validation Loss: 0.00600090
Epoch [204/300], Train Loss: 0.005960
Validation Loss: 0.00600264
Epoch [205/300], Train Loss: 0.005767
Validation Loss: 0.00600756
Epoch [206/300], Train Loss: 0.005841
Validation Loss: 0.00600413
Epoch [207/300], Train Loss: 0.005810
Validation Loss: 0.00599708
Epoch [208/300], Train Loss: 0.005929
Validation Loss: 0.00599579
Epoch [209/300], Train Loss: 0.005857
Validation Loss: 0.00599507
Epoch [210/300], Train Loss: 0.005926
Validation Loss: 0.00599458
Epoch [211/300], Train Loss: 0.005908
Validation Loss: 0.00599463
Epoch [212/300], Train Loss: 0.005843
Validation Loss: 0.00599403
Epoch [213/300], Train Loss: 0.006010
Validation Loss: 0.00599278
Epoch [214/300], Train Loss: 0.005762
Validation Loss: 0.00599267
Epoch [215/300], Train Loss: 0.005823
Validation Loss: 0.00599150
Epoch [216/300], Train Loss: 0.006106
Validation Loss: 0.00599129
Epoch [217/300], Train Loss: 0.005806
Validation Loss: 0.00599234
Epoch [218/300], Train Loss: 0.005822
Validation Loss: 0.00599019
Epoch [219/300], Train Loss: 0.005846
Validation Loss: 0.00599058
Epoch [220/300], Train Loss: 0.005764
Validation Loss: 0.00599103
Epoch [221/300], Train Loss: 0.005990
Validation Loss: 0.00599292
Epoch [222/300], Train Loss: 0.005829
Validation Loss: 0.00598825
Epoch [223/300], Train Loss: 0.005865
Validation Loss: 0.00598671
Epoch [224/300], Train Loss: 0.005951
Validation Loss: 0.00598610
Epoch [225/300], Train Loss: 0.005849
Validation Loss: 0.00598794
Epoch [226/300], Train Loss: 0.005881
Validation Loss: 0.00598783
Epoch [227/300], Train Loss: 0.005781
Validation Loss: 0.00598510
Epoch [228/300], Train Loss: 0.005694
Validation Loss: 0.00598437
Epoch [229/300], Train Loss: 0.005875
Validation Loss: 0.00598637
Epoch [230/300], Train Loss: 0.005869
Validation Loss: 0.00598610
Epoch [231/300], Train Loss: 0.005762
Validation Loss: 0.00598349
Epoch [232/300], Train Loss: 0.005749
Validation Loss: 0.00598215
Epoch [233/300], Train Loss: 0.005947
Validation Loss: 0.00598221
Epoch [234/300], Train Loss: 0.005889
Validation Loss: 0.00598066
Epoch [235/300], Train Loss: 0.005869
Validation Loss: 0.00598042
Epoch [236/300], Train Loss: 0.005906
Validation Loss: 0.00597971
Epoch [237/300], Train Loss: 0.005760
Validation Loss: 0.00597925
Epoch [238/300], Train Loss: 0.005934
Validation Loss: 0.00597936
Epoch [239/300], Train Loss: 0.006074
Validation Loss: 0.00597852
Epoch [240/300], Train Loss: 0.005890
Validation Loss: 0.00597734
Epoch [241/300], Train Loss: 0.005853
Validation Loss: 0.00597682
Epoch [242/300], Train Loss: 0.005797
Validation Loss: 0.00597792
Epoch [243/300], Train Loss: 0.005867
Validation Loss: 0.00597854
Epoch [244/300], Train Loss: 0.005781
Validation Loss: 0.00597709
Epoch [245/300], Train Loss: 0.005933
Validation Loss: 0.00597704
Epoch [246/300], Train Loss: 0.005801
Validation Loss: 0.00597577
Epoch [247/300], Train Loss: 0.005760
Validation Loss: 0.00597399
Epoch [248/300], Train Loss: 0.005901
Validation Loss: 0.00597350
Epoch [249/300], Train Loss: 0.005816
Validation Loss: 0.00597316
Epoch [250/300], Train Loss: 0.005878
Validation Loss: 0.00597335
Epoch [251/300], Train Loss: 0.005918
Validation Loss: 0.00597450
Epoch [252/300], Train Loss: 0.005894
Validation Loss: 0.00597164
Epoch [253/300], Train Loss: 0.005847
Validation Loss: 0.00597239
Epoch [254/300], Train Loss: 0.005750
Validation Loss: 0.00597103
Epoch [255/300], Train Loss: 0.005932
Validation Loss: 0.00597156
Epoch [256/300], Train Loss: 0.005832
Validation Loss: 0.00597343
Epoch [257/300], Train Loss: 0.005787
Validation Loss: 0.00597259
Epoch [258/300], Train Loss: 0.006098
Validation Loss: 0.00597122
Epoch [259/300], Train Loss: 0.005783
Validation Loss: 0.00596863
Epoch [260/300], Train Loss: 0.005782
Validation Loss: 0.00596824
Epoch [261/300], Train Loss: 0.005782
Validation Loss: 0.00596774
Epoch [262/300], Train Loss: 0.005912
Validation Loss: 0.00596786
Epoch [263/300], Train Loss: 0.005889
Validation Loss: 0.00596700
Epoch [264/300], Train Loss: 0.005866
Validation Loss: 0.00596683
Epoch [265/300], Train Loss: 0.005881
Validation Loss: 0.00596621
Epoch [266/300], Train Loss: 0.005843
Validation Loss: 0.00596560
Epoch [267/300], Train Loss: 0.005797
Validation Loss: 0.00596556
Epoch [268/300], Train Loss: 0.005753
Validation Loss: 0.00597006
Epoch [269/300], Train Loss: 0.005763
Validation Loss: 0.00597016
Epoch [270/300], Train Loss: 0.005870
Validation Loss: 0.00596676
Epoch [271/300], Train Loss: 0.005747
Validation Loss: 0.00596595
Epoch [272/300], Train Loss: 0.005858
Validation Loss: 0.00596353
Epoch [273/300], Train Loss: 0.005788
Validation Loss: 0.00596297
Epoch [274/300], Train Loss: 0.005977
Validation Loss: 0.00596259
Epoch [275/300], Train Loss: 0.005786
Validation Loss: 0.00596218
Epoch [276/300], Train Loss: 0.005888
Validation Loss: 0.00596169
Epoch [277/300], Train Loss: 0.005844
Validation Loss: 0.00596145
Epoch [278/300], Train Loss: 0.005840
Validation Loss: 0.00596163
Epoch [279/300], Train Loss: 0.005835
Validation Loss: 0.00596171
Epoch [280/300], Train Loss: 0.005821
Validation Loss: 0.00596079
Epoch [281/300], Train Loss: 0.005887
Validation Loss: 0.00596030
Epoch [282/300], Train Loss: 0.005864
Validation Loss: 0.00595940
Epoch [283/300], Train Loss: 0.005728
Validation Loss: 0.00595900
Epoch [284/300], Train Loss: 0.005881
Validation Loss: 0.00595853
Epoch [285/300], Train Loss: 0.005831
Validation Loss: 0.00595867
Epoch [286/300], Train Loss: 0.005985
Validation Loss: 0.00595893
Epoch [287/300], Train Loss: 0.005827
Validation Loss: 0.00595849
Epoch [288/300], Train Loss: 0.005765
Validation Loss: 0.00595731
Epoch [289/300], Train Loss: 0.005960
Validation Loss: 0.00595795
Epoch [290/300], Train Loss: 0.005711
Validation Loss: 0.00595780
Epoch [291/300], Train Loss: 0.005695
Validation Loss: 0.00595935
Epoch [292/300], Train Loss: 0.005875
Validation Loss: 0.00596188
Epoch [293/300], Train Loss: 0.006064
Validation Loss: 0.00595734
Epoch [294/300], Train Loss: 0.005736
Validation Loss: 0.00595569
Epoch [295/300], Train Loss: 0.005839
Validation Loss: 0.00595539
Epoch [296/300], Train Loss: 0.005864
Validation Loss: 0.00595433
Epoch [297/300], Train Loss: 0.005901
Validation Loss: 0.00595417
Epoch [298/300], Train Loss: 0.005769
Validation Loss: 0.00595415
Epoch [299/300], Train Loss: 0.005695
Validation Loss: 0.00595514
Epoch [300/300], Train Loss: 0.005910
Validation Loss: 0.00596063

Evaluating model for: Router
Run 47/72 completed in 468.65 seconds with: {'MAE': np.float32(0.19539905), 'MSE': np.float32(0.06531536), 'RMSE': np.float32(0.25556868), 'SAE': np.float32(0.0007171625), 'NDE': np.float32(0.012781542)}

Run 48/72: hidden=256, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Router
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.091680
Validation Loss: 0.08574338
Epoch [2/300], Train Loss: 0.083476
Validation Loss: 0.07725416
Epoch [3/300], Train Loss: 0.075203
Validation Loss: 0.06835032
Epoch [4/300], Train Loss: 0.065405
Validation Loss: 0.05823019
Epoch [5/300], Train Loss: 0.053998
Validation Loss: 0.04624794
Epoch [6/300], Train Loss: 0.040799
Validation Loss: 0.03001014
Epoch [7/300], Train Loss: 0.022362
Validation Loss: 0.00941978
Epoch [8/300], Train Loss: 0.009118
Validation Loss: 0.01536070
Epoch [9/300], Train Loss: 0.011213
Validation Loss: 0.00629433
Epoch [10/300], Train Loss: 0.006477
Validation Loss: 0.00789194
Epoch [11/300], Train Loss: 0.008235
Validation Loss: 0.00828519
Epoch [12/300], Train Loss: 0.007586
Validation Loss: 0.00663056
Epoch [13/300], Train Loss: 0.006131
Validation Loss: 0.00623452
Epoch [14/300], Train Loss: 0.006328
Validation Loss: 0.00684467
Epoch [15/300], Train Loss: 0.006465
Validation Loss: 0.00621451
Epoch [16/300], Train Loss: 0.005915
Validation Loss: 0.00612812
Epoch [17/300], Train Loss: 0.006085
Validation Loss: 0.00620857
Epoch [18/300], Train Loss: 0.006064
Validation Loss: 0.00611902
Epoch [19/300], Train Loss: 0.005870
Validation Loss: 0.00609107
Epoch [20/300], Train Loss: 0.006006
Validation Loss: 0.00614769
Epoch [21/300], Train Loss: 0.005925
Validation Loss: 0.00609993
Epoch [22/300], Train Loss: 0.005888
Validation Loss: 0.00607856
Epoch [23/300], Train Loss: 0.006009
Validation Loss: 0.00607870
Epoch [24/300], Train Loss: 0.005931
Validation Loss: 0.00607997
Epoch [25/300], Train Loss: 0.005887
Validation Loss: 0.00608296
Epoch [26/300], Train Loss: 0.005816
Validation Loss: 0.00607899
Epoch [27/300], Train Loss: 0.005918
Validation Loss: 0.00607370
Epoch [28/300], Train Loss: 0.005918
Validation Loss: 0.00607254
Epoch [29/300], Train Loss: 0.006040
Validation Loss: 0.00607170
Epoch [30/300], Train Loss: 0.005829
Validation Loss: 0.00607139
Epoch [31/300], Train Loss: 0.005821
Validation Loss: 0.00608250
Epoch [32/300], Train Loss: 0.005866
Validation Loss: 0.00608688
Epoch [33/300], Train Loss: 0.006064
Validation Loss: 0.00608418
Epoch [34/300], Train Loss: 0.005867
Validation Loss: 0.00606683
Epoch [35/300], Train Loss: 0.005906
Validation Loss: 0.00606642
Epoch [36/300], Train Loss: 0.005937
Validation Loss: 0.00606771
Epoch [37/300], Train Loss: 0.005864
Validation Loss: 0.00607132
Epoch [38/300], Train Loss: 0.005739
Validation Loss: 0.00607129
Epoch [39/300], Train Loss: 0.005867
Validation Loss: 0.00607317
Epoch [40/300], Train Loss: 0.005984
Validation Loss: 0.00606163
Epoch [41/300], Train Loss: 0.005934
Validation Loss: 0.00606724
Epoch [42/300], Train Loss: 0.006080
Validation Loss: 0.00605875
Epoch [43/300], Train Loss: 0.006001
Validation Loss: 0.00605770
Epoch [44/300], Train Loss: 0.005861
Validation Loss: 0.00606204
Epoch [45/300], Train Loss: 0.005858
Validation Loss: 0.00605732
Epoch [46/300], Train Loss: 0.005836
Validation Loss: 0.00605433
Epoch [47/300], Train Loss: 0.005938
Validation Loss: 0.00605708
Epoch [48/300], Train Loss: 0.006052
Validation Loss: 0.00605991
Epoch [49/300], Train Loss: 0.005942
Validation Loss: 0.00605291
Epoch [50/300], Train Loss: 0.005943
Validation Loss: 0.00604984
Epoch [51/300], Train Loss: 0.005916
Validation Loss: 0.00604891
Epoch [52/300], Train Loss: 0.005948
Validation Loss: 0.00604759
Epoch [53/300], Train Loss: 0.005910
Validation Loss: 0.00604861
Epoch [54/300], Train Loss: 0.005905
Validation Loss: 0.00605687
Epoch [55/300], Train Loss: 0.005908
Validation Loss: 0.00604521
Epoch [56/300], Train Loss: 0.005902
Validation Loss: 0.00604379
Epoch [57/300], Train Loss: 0.005982
Validation Loss: 0.00604304
Epoch [58/300], Train Loss: 0.005842
Validation Loss: 0.00604087
Epoch [59/300], Train Loss: 0.005889
Validation Loss: 0.00603981
Epoch [60/300], Train Loss: 0.005872
Validation Loss: 0.00604246
Epoch [61/300], Train Loss: 0.005816
Validation Loss: 0.00605817
Epoch [62/300], Train Loss: 0.005995
Validation Loss: 0.00605484
Epoch [63/300], Train Loss: 0.005737
Validation Loss: 0.00603574
Epoch [64/300], Train Loss: 0.005971
Validation Loss: 0.00604188
Epoch [65/300], Train Loss: 0.005808
Validation Loss: 0.00603719
Epoch [66/300], Train Loss: 0.006008
Validation Loss: 0.00606525
Epoch [67/300], Train Loss: 0.005834
Validation Loss: 0.00603975
Epoch [68/300], Train Loss: 0.005814
Validation Loss: 0.00603411
Epoch [69/300], Train Loss: 0.005858
Validation Loss: 0.00603431
Epoch [70/300], Train Loss: 0.005880
Validation Loss: 0.00602792
Epoch [71/300], Train Loss: 0.005923
Validation Loss: 0.00603283
Epoch [72/300], Train Loss: 0.005701
Validation Loss: 0.00602960
Epoch [73/300], Train Loss: 0.005771
Validation Loss: 0.00602960
Epoch [74/300], Train Loss: 0.005912
Validation Loss: 0.00602412
Epoch [75/300], Train Loss: 0.005769
Validation Loss: 0.00602260
Epoch [76/300], Train Loss: 0.005898
Validation Loss: 0.00602353
Epoch [77/300], Train Loss: 0.005870
Validation Loss: 0.00602334
Epoch [78/300], Train Loss: 0.005895
Validation Loss: 0.00602024
Epoch [79/300], Train Loss: 0.005757
Validation Loss: 0.00601950
Epoch [80/300], Train Loss: 0.005931
Validation Loss: 0.00602177
Epoch [81/300], Train Loss: 0.005758
Validation Loss: 0.00601641
Epoch [82/300], Train Loss: 0.005983
Validation Loss: 0.00601617
Epoch [83/300], Train Loss: 0.005874
Validation Loss: 0.00601405
Epoch [84/300], Train Loss: 0.005784
Validation Loss: 0.00601938
Epoch [85/300], Train Loss: 0.005836
Validation Loss: 0.00601842
Epoch [86/300], Train Loss: 0.005791
Validation Loss: 0.00601161
Epoch [87/300], Train Loss: 0.005849
Validation Loss: 0.00600961
Epoch [88/300], Train Loss: 0.005838
Validation Loss: 0.00600819
Epoch [89/300], Train Loss: 0.005851
Validation Loss: 0.00600769
Epoch [90/300], Train Loss: 0.005983
Validation Loss: 0.00600677
Epoch [91/300], Train Loss: 0.005895
Validation Loss: 0.00601029
Epoch [92/300], Train Loss: 0.005839
Validation Loss: 0.00601645
Epoch [93/300], Train Loss: 0.005898
Validation Loss: 0.00601182
Epoch [94/300], Train Loss: 0.005679
Validation Loss: 0.00600329
Epoch [95/300], Train Loss: 0.005813
Validation Loss: 0.00600063
Epoch [96/300], Train Loss: 0.005899
Validation Loss: 0.00599985
Epoch [97/300], Train Loss: 0.005796
Validation Loss: 0.00599936
Epoch [98/300], Train Loss: 0.005876
Validation Loss: 0.00600152
Epoch [99/300], Train Loss: 0.005839
Validation Loss: 0.00600102
Epoch [100/300], Train Loss: 0.005835
Validation Loss: 0.00599974
Epoch [101/300], Train Loss: 0.005795
Validation Loss: 0.00599933
Epoch [102/300], Train Loss: 0.005856
Validation Loss: 0.00599336
Epoch [103/300], Train Loss: 0.005819
Validation Loss: 0.00599372
Epoch [104/300], Train Loss: 0.005760
Validation Loss: 0.00599048
Epoch [105/300], Train Loss: 0.005853
Validation Loss: 0.00599674
Epoch [106/300], Train Loss: 0.006012
Validation Loss: 0.00599300
Epoch [107/300], Train Loss: 0.005805
Validation Loss: 0.00598738
Epoch [108/300], Train Loss: 0.005994
Validation Loss: 0.00598636
Epoch [109/300], Train Loss: 0.006050
Validation Loss: 0.00598565
Epoch [110/300], Train Loss: 0.005781
Validation Loss: 0.00598563
Epoch [111/300], Train Loss: 0.005752
Validation Loss: 0.00598913
Epoch [112/300], Train Loss: 0.005925
Validation Loss: 0.00599327
Epoch [113/300], Train Loss: 0.005934
Validation Loss: 0.00598108
Epoch [114/300], Train Loss: 0.005940
Validation Loss: 0.00598622
Epoch [115/300], Train Loss: 0.005892
Validation Loss: 0.00598000
Epoch [116/300], Train Loss: 0.005794
Validation Loss: 0.00598426
Epoch [117/300], Train Loss: 0.005820
Validation Loss: 0.00599285
Epoch [118/300], Train Loss: 0.005802
Validation Loss: 0.00597582
Epoch [119/300], Train Loss: 0.005774
Validation Loss: 0.00597406
Epoch [120/300], Train Loss: 0.005801
Validation Loss: 0.00597231
Epoch [121/300], Train Loss: 0.005742
Validation Loss: 0.00597139
Epoch [122/300], Train Loss: 0.005744
Validation Loss: 0.00597183
Epoch [123/300], Train Loss: 0.005822
Validation Loss: 0.00598162
Epoch [124/300], Train Loss: 0.005818
Validation Loss: 0.00597791
Epoch [125/300], Train Loss: 0.005878
Validation Loss: 0.00596883
Epoch [126/300], Train Loss: 0.005859
Validation Loss: 0.00596592
Epoch [127/300], Train Loss: 0.005796
Validation Loss: 0.00596646
Epoch [128/300], Train Loss: 0.005914
Validation Loss: 0.00596426
Epoch [129/300], Train Loss: 0.005734
Validation Loss: 0.00597091
Epoch [130/300], Train Loss: 0.005931
Validation Loss: 0.00597050
Epoch [131/300], Train Loss: 0.005758
Validation Loss: 0.00596274
Epoch [132/300], Train Loss: 0.005756
Validation Loss: 0.00596051
Epoch [133/300], Train Loss: 0.005757
Validation Loss: 0.00595867
Epoch [134/300], Train Loss: 0.005928
Validation Loss: 0.00595990
Epoch [135/300], Train Loss: 0.005706
Validation Loss: 0.00595639
Epoch [136/300], Train Loss: 0.005804
Validation Loss: 0.00595548
Epoch [137/300], Train Loss: 0.005948
Validation Loss: 0.00595474
Epoch [138/300], Train Loss: 0.005765
Validation Loss: 0.00595441
Epoch [139/300], Train Loss: 0.005758
Validation Loss: 0.00595315
Epoch [140/300], Train Loss: 0.005730
Validation Loss: 0.00595340
Epoch [141/300], Train Loss: 0.005648
Validation Loss: 0.00595354
Epoch [142/300], Train Loss: 0.005698
Validation Loss: 0.00595039
Epoch [143/300], Train Loss: 0.005802
Validation Loss: 0.00594969
Epoch [144/300], Train Loss: 0.005783
Validation Loss: 0.00594693
Epoch [145/300], Train Loss: 0.005722
Validation Loss: 0.00594713
Epoch [146/300], Train Loss: 0.005679
Validation Loss: 0.00595146
Epoch [147/300], Train Loss: 0.005840
Validation Loss: 0.00594840
Epoch [148/300], Train Loss: 0.005670
Validation Loss: 0.00594338
Epoch [149/300], Train Loss: 0.005880
Validation Loss: 0.00594293
Epoch [150/300], Train Loss: 0.006008
Validation Loss: 0.00594472
Epoch [151/300], Train Loss: 0.005769
Validation Loss: 0.00594306
Epoch [152/300], Train Loss: 0.005956
Validation Loss: 0.00594032
Epoch [153/300], Train Loss: 0.005642
Validation Loss: 0.00593891
Epoch [154/300], Train Loss: 0.005660
Validation Loss: 0.00593975
Epoch [155/300], Train Loss: 0.005873
Validation Loss: 0.00594529
Epoch [156/300], Train Loss: 0.005793
Validation Loss: 0.00593698
Epoch [157/300], Train Loss: 0.005853
Validation Loss: 0.00593875
Epoch [158/300], Train Loss: 0.005758
Validation Loss: 0.00593795
Epoch [159/300], Train Loss: 0.005901
Validation Loss: 0.00593612
Epoch [160/300], Train Loss: 0.005750
Validation Loss: 0.00593596
Epoch [161/300], Train Loss: 0.005827
Validation Loss: 0.00594358
Epoch [162/300], Train Loss: 0.005717
Validation Loss: 0.00593291
Epoch [163/300], Train Loss: 0.005825
Validation Loss: 0.00592939
Epoch [164/300], Train Loss: 0.005680
Validation Loss: 0.00592834
Epoch [165/300], Train Loss: 0.005658
Validation Loss: 0.00592885
Epoch [166/300], Train Loss: 0.005647
Validation Loss: 0.00593127
Epoch [167/300], Train Loss: 0.005702
Validation Loss: 0.00593055
Epoch [168/300], Train Loss: 0.005723
Validation Loss: 0.00592676
Epoch [169/300], Train Loss: 0.005879
Validation Loss: 0.00592430
Epoch [170/300], Train Loss: 0.005636
Validation Loss: 0.00592340
Epoch [171/300], Train Loss: 0.005782
Validation Loss: 0.00592399
Epoch [172/300], Train Loss: 0.005724
Validation Loss: 0.00593057
Epoch [173/300], Train Loss: 0.005631
Validation Loss: 0.00592474
Epoch [174/300], Train Loss: 0.005851
Validation Loss: 0.00592081
Epoch [175/300], Train Loss: 0.005878
Validation Loss: 0.00591978
Epoch [176/300], Train Loss: 0.005773
Validation Loss: 0.00591933
Epoch [177/300], Train Loss: 0.005619
Validation Loss: 0.00591893
Epoch [178/300], Train Loss: 0.005622
Validation Loss: 0.00591965
Epoch [179/300], Train Loss: 0.005716
Validation Loss: 0.00592733
Epoch [180/300], Train Loss: 0.005944
Validation Loss: 0.00592406
Epoch [181/300], Train Loss: 0.005763
Validation Loss: 0.00591490
Epoch [182/300], Train Loss: 0.005738
Validation Loss: 0.00591447
Epoch [183/300], Train Loss: 0.005910
Validation Loss: 0.00591375
Epoch [184/300], Train Loss: 0.005741
Validation Loss: 0.00591397
Epoch [185/300], Train Loss: 0.005610
Validation Loss: 0.00591224
Epoch [186/300], Train Loss: 0.005818
Validation Loss: 0.00591132
Epoch [187/300], Train Loss: 0.005797
Validation Loss: 0.00591058
Epoch [188/300], Train Loss: 0.005693
Validation Loss: 0.00590988
Epoch [189/300], Train Loss: 0.005796
Validation Loss: 0.00590910
Epoch [190/300], Train Loss: 0.005711
Validation Loss: 0.00590857
Epoch [191/300], Train Loss: 0.005842
Validation Loss: 0.00590808
Epoch [192/300], Train Loss: 0.005602
Validation Loss: 0.00590842
Epoch [193/300], Train Loss: 0.005810
Validation Loss: 0.00592248
Epoch [194/300], Train Loss: 0.005839
Validation Loss: 0.00591380
Epoch [195/300], Train Loss: 0.005746
Validation Loss: 0.00590528
Epoch [196/300], Train Loss: 0.005718
Validation Loss: 0.00590475
Epoch [197/300], Train Loss: 0.005740
Validation Loss: 0.00590542
Epoch [198/300], Train Loss: 0.005741
Validation Loss: 0.00590409
Epoch [199/300], Train Loss: 0.005732
Validation Loss: 0.00590501
Epoch [200/300], Train Loss: 0.005808
Validation Loss: 0.00590778
Epoch [201/300], Train Loss: 0.005999
Validation Loss: 0.00590294
Epoch [202/300], Train Loss: 0.005811
Validation Loss: 0.00590644
Epoch [203/300], Train Loss: 0.005716
Validation Loss: 0.00590308
Epoch [204/300], Train Loss: 0.005827
Validation Loss: 0.00590341
Epoch [205/300], Train Loss: 0.005628
Validation Loss: 0.00590753
Epoch [206/300], Train Loss: 0.005690
Validation Loss: 0.00590444
Epoch [207/300], Train Loss: 0.005664
Validation Loss: 0.00589897
Epoch [208/300], Train Loss: 0.005784
Validation Loss: 0.00589807
Epoch [209/300], Train Loss: 0.005716
Validation Loss: 0.00589742
Epoch [210/300], Train Loss: 0.005799
Validation Loss: 0.00589690
Epoch [211/300], Train Loss: 0.005775
Validation Loss: 0.00589697
Epoch [212/300], Train Loss: 0.005708
Validation Loss: 0.00589660
Epoch [213/300], Train Loss: 0.005885
Validation Loss: 0.00589567
Epoch [214/300], Train Loss: 0.005629
Validation Loss: 0.00589580
Epoch [215/300], Train Loss: 0.005692
Validation Loss: 0.00589476
Epoch [216/300], Train Loss: 0.005967
Validation Loss: 0.00589465
Epoch [217/300], Train Loss: 0.005671
Validation Loss: 0.00589559
Epoch [218/300], Train Loss: 0.005691
Validation Loss: 0.00589378
Epoch [219/300], Train Loss: 0.005715
Validation Loss: 0.00589416
Epoch [220/300], Train Loss: 0.005623
Validation Loss: 0.00589491
Epoch [221/300], Train Loss: 0.005846
Validation Loss: 0.00589727
Epoch [222/300], Train Loss: 0.005687
Validation Loss: 0.00589278
Epoch [223/300], Train Loss: 0.005723
Validation Loss: 0.00589157
Epoch [224/300], Train Loss: 0.005806
Validation Loss: 0.00589122
Epoch [225/300], Train Loss: 0.005707
Validation Loss: 0.00589323
Epoch [226/300], Train Loss: 0.005731
Validation Loss: 0.00589345
Epoch [227/300], Train Loss: 0.005647
Validation Loss: 0.00589069
Epoch [228/300], Train Loss: 0.005552
Validation Loss: 0.00589003
Epoch [229/300], Train Loss: 0.005743
Validation Loss: 0.00589212
Epoch [230/300], Train Loss: 0.005737
Validation Loss: 0.00589198
Epoch [231/300], Train Loss: 0.005630
Validation Loss: 0.00588946
Epoch [232/300], Train Loss: 0.005602
Validation Loss: 0.00588832
Epoch [233/300], Train Loss: 0.005802
Validation Loss: 0.00588839
Epoch [234/300], Train Loss: 0.005743
Validation Loss: 0.00588723
Epoch [235/300], Train Loss: 0.005737
Validation Loss: 0.00588703
Epoch [236/300], Train Loss: 0.005758
Validation Loss: 0.00588644
Epoch [237/300], Train Loss: 0.005620
Validation Loss: 0.00588604
Epoch [238/300], Train Loss: 0.005794
Validation Loss: 0.00588615
Epoch [239/300], Train Loss: 0.005929
Validation Loss: 0.00588527
Epoch [240/300], Train Loss: 0.005746
Validation Loss: 0.00588430
Epoch [241/300], Train Loss: 0.005712
Validation Loss: 0.00588391
Epoch [242/300], Train Loss: 0.005668
Validation Loss: 0.00588470
Epoch [243/300], Train Loss: 0.005738
Validation Loss: 0.00588556
Epoch [244/300], Train Loss: 0.005656
Validation Loss: 0.00588438
Epoch [245/300], Train Loss: 0.005797
Validation Loss: 0.00588452
Epoch [246/300], Train Loss: 0.005667
Validation Loss: 0.00588339
Epoch [247/300], Train Loss: 0.005620
Validation Loss: 0.00588171
Epoch [248/300], Train Loss: 0.005760
Validation Loss: 0.00588138
Epoch [249/300], Train Loss: 0.005682
Validation Loss: 0.00588117
Epoch [250/300], Train Loss: 0.005747
Validation Loss: 0.00588131
Epoch [251/300], Train Loss: 0.005775
Validation Loss: 0.00588240
Epoch [252/300], Train Loss: 0.005763
Validation Loss: 0.00588000
Epoch [253/300], Train Loss: 0.005717
Validation Loss: 0.00588079
Epoch [254/300], Train Loss: 0.005606
Validation Loss: 0.00587967
Epoch [255/300], Train Loss: 0.005793
Validation Loss: 0.00588025
Epoch [256/300], Train Loss: 0.005708
Validation Loss: 0.00588205
Epoch [257/300], Train Loss: 0.005644
Validation Loss: 0.00588123
Epoch [258/300], Train Loss: 0.005956
Validation Loss: 0.00588008
Epoch [259/300], Train Loss: 0.005647
Validation Loss: 0.00587786
Epoch [260/300], Train Loss: 0.005633
Validation Loss: 0.00587758
Epoch [261/300], Train Loss: 0.005644
Validation Loss: 0.00587710
Epoch [262/300], Train Loss: 0.005763
Validation Loss: 0.00587725
Epoch [263/300], Train Loss: 0.005749
Validation Loss: 0.00587651
Epoch [264/300], Train Loss: 0.005729
Validation Loss: 0.00587643
Epoch [265/300], Train Loss: 0.005745
Validation Loss: 0.00587602
Epoch [266/300], Train Loss: 0.005710
Validation Loss: 0.00587555
Epoch [267/300], Train Loss: 0.005664
Validation Loss: 0.00587562
Epoch [268/300], Train Loss: 0.005614
Validation Loss: 0.00587972
Epoch [269/300], Train Loss: 0.005626
Validation Loss: 0.00588002
Epoch [270/300], Train Loss: 0.005735
Validation Loss: 0.00587698
Epoch [271/300], Train Loss: 0.005609
Validation Loss: 0.00587632
Epoch [272/300], Train Loss: 0.005721
Validation Loss: 0.00587423
Epoch [273/300], Train Loss: 0.005646
Validation Loss: 0.00587380
Epoch [274/300], Train Loss: 0.005841
Validation Loss: 0.00587350
Epoch [275/300], Train Loss: 0.005648
Validation Loss: 0.00587318
Epoch [276/300], Train Loss: 0.005757
Validation Loss: 0.00587274
Epoch [277/300], Train Loss: 0.005717
Validation Loss: 0.00587248
Epoch [278/300], Train Loss: 0.005705
Validation Loss: 0.00587263
Epoch [279/300], Train Loss: 0.005712
Validation Loss: 0.00587273
Epoch [280/300], Train Loss: 0.005682
Validation Loss: 0.00587182
Epoch [281/300], Train Loss: 0.005756
Validation Loss: 0.00587140
Epoch [282/300], Train Loss: 0.005725
Validation Loss: 0.00587080
Epoch [283/300], Train Loss: 0.005597
Validation Loss: 0.00587064
Epoch [284/300], Train Loss: 0.005752
Validation Loss: 0.00587027
Epoch [285/300], Train Loss: 0.005696
Validation Loss: 0.00587049
Epoch [286/300], Train Loss: 0.005847
Validation Loss: 0.00587090
Epoch [287/300], Train Loss: 0.005692
Validation Loss: 0.00587057
Epoch [288/300], Train Loss: 0.005631
Validation Loss: 0.00586940
Epoch [289/300], Train Loss: 0.005821
Validation Loss: 0.00587003
Epoch [290/300], Train Loss: 0.005566
Validation Loss: 0.00586992
Epoch [291/300], Train Loss: 0.005559
Validation Loss: 0.00587135
Epoch [292/300], Train Loss: 0.005729
Validation Loss: 0.00587385
Epoch [293/300], Train Loss: 0.005924
Validation Loss: 0.00586995
Epoch [294/300], Train Loss: 0.005597
Validation Loss: 0.00586827
Epoch [295/300], Train Loss: 0.005713
Validation Loss: 0.00586805
Epoch [296/300], Train Loss: 0.005734
Validation Loss: 0.00586714
Epoch [297/300], Train Loss: 0.005774
Validation Loss: 0.00586695
Epoch [298/300], Train Loss: 0.005637
Validation Loss: 0.00586691
Epoch [299/300], Train Loss: 0.005567
Validation Loss: 0.00586791
Epoch [300/300], Train Loss: 0.005797
Validation Loss: 0.00587354

Evaluating model for: Router
Run 48/72 completed in 656.36 seconds with: {'MAE': np.float32(0.19494681), 'MSE': np.float32(0.06442944), 'RMSE': np.float32(0.25382954), 'SAE': np.float32(0.0007456595), 'NDE': np.float32(0.012694562)}

Run 49/72: hidden=512, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Router
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.030678
Validation Loss: 0.00788492
Epoch [2/300], Train Loss: 0.007119
Validation Loss: 0.00726690
Epoch [3/300], Train Loss: 0.006866
Validation Loss: 0.00712120
Epoch [4/300], Train Loss: 0.006705
Validation Loss: 0.00696404
Epoch [5/300], Train Loss: 0.006563
Validation Loss: 0.00681636
Epoch [6/300], Train Loss: 0.006474
Validation Loss: 0.00669425
Epoch [7/300], Train Loss: 0.006280
Validation Loss: 0.00660683
Epoch [8/300], Train Loss: 0.006179
Validation Loss: 0.00653319
Epoch [9/300], Train Loss: 0.006112
Validation Loss: 0.00642266
Epoch [10/300], Train Loss: 0.006041
Validation Loss: 0.00634892
Epoch [11/300], Train Loss: 0.006014
Validation Loss: 0.00629546
Epoch [12/300], Train Loss: 0.005901
Validation Loss: 0.00624145
Epoch [13/300], Train Loss: 0.005870
Validation Loss: 0.00620068
Epoch [14/300], Train Loss: 0.005823
Validation Loss: 0.00620071
Epoch [15/300], Train Loss: 0.005757
Validation Loss: 0.00611034
Epoch [16/300], Train Loss: 0.005709
Validation Loss: 0.00606974
Epoch [17/300], Train Loss: 0.005696
Validation Loss: 0.00603625
Epoch [18/300], Train Loss: 0.005641
Validation Loss: 0.00600187
Epoch [19/300], Train Loss: 0.005642
Validation Loss: 0.00597297
Epoch [20/300], Train Loss: 0.005614
Validation Loss: 0.00594032
Epoch [21/300], Train Loss: 0.005579
Validation Loss: 0.00591318
Epoch [22/300], Train Loss: 0.005549
Validation Loss: 0.00590000
Epoch [23/300], Train Loss: 0.005563
Validation Loss: 0.00586277
Epoch [24/300], Train Loss: 0.005577
Validation Loss: 0.00588603
Epoch [25/300], Train Loss: 0.005472
Validation Loss: 0.00582248
Epoch [26/300], Train Loss: 0.005471
Validation Loss: 0.00584168
Epoch [27/300], Train Loss: 0.005426
Validation Loss: 0.00579521
Epoch [28/300], Train Loss: 0.005403
Validation Loss: 0.00582544
Epoch [29/300], Train Loss: 0.005427
Validation Loss: 0.00574864
Epoch [30/300], Train Loss: 0.005360
Validation Loss: 0.00573759
Epoch [31/300], Train Loss: 0.005393
Validation Loss: 0.00572748
Epoch [32/300], Train Loss: 0.005372
Validation Loss: 0.00571222
Epoch [33/300], Train Loss: 0.005352
Validation Loss: 0.00568394
Epoch [34/300], Train Loss: 0.005312
Validation Loss: 0.00568136
Epoch [35/300], Train Loss: 0.005299
Validation Loss: 0.00566437
Epoch [36/300], Train Loss: 0.005274
Validation Loss: 0.00564170
Epoch [37/300], Train Loss: 0.005258
Validation Loss: 0.00563216
Epoch [38/300], Train Loss: 0.005292
Validation Loss: 0.00565845
Epoch [39/300], Train Loss: 0.005254
Validation Loss: 0.00561909
Epoch [40/300], Train Loss: 0.005220
Validation Loss: 0.00561663
Epoch [41/300], Train Loss: 0.005246
Validation Loss: 0.00558842
Epoch [42/300], Train Loss: 0.005240
Validation Loss: 0.00556839
Epoch [43/300], Train Loss: 0.005225
Validation Loss: 0.00558299
Epoch [44/300], Train Loss: 0.005192
Validation Loss: 0.00552735
Epoch [45/300], Train Loss: 0.005219
Validation Loss: 0.00554045
Epoch [46/300], Train Loss: 0.005148
Validation Loss: 0.00551712
Epoch [47/300], Train Loss: 0.005157
Validation Loss: 0.00547034
Epoch [48/300], Train Loss: 0.005099
Validation Loss: 0.00542957
Epoch [49/300], Train Loss: 0.005061
Validation Loss: 0.00542983
Epoch [50/300], Train Loss: 0.005047
Validation Loss: 0.00550770
Epoch [51/300], Train Loss: 0.005127
Validation Loss: 0.00538086
Epoch [52/300], Train Loss: 0.004970
Validation Loss: 0.00523220
Epoch [53/300], Train Loss: 0.004920
Validation Loss: 0.00516798
Epoch [54/300], Train Loss: 0.005006
Validation Loss: 0.00526131
Epoch [55/300], Train Loss: 0.004892
Validation Loss: 0.00514776
Epoch [56/300], Train Loss: 0.004888
Validation Loss: 0.00516374
Epoch [57/300], Train Loss: 0.004773
Validation Loss: 0.00516415
Epoch [58/300], Train Loss: 0.004784
Validation Loss: 0.00508104
Epoch [59/300], Train Loss: 0.004832
Validation Loss: 0.00503209
Epoch [60/300], Train Loss: 0.004793
Validation Loss: 0.00502811
Epoch [61/300], Train Loss: 0.004683
Validation Loss: 0.00520261
Epoch [62/300], Train Loss: 0.004700
Validation Loss: 0.00511402
Epoch [63/300], Train Loss: 0.004696
Validation Loss: 0.00502747
Epoch [64/300], Train Loss: 0.004643
Validation Loss: 0.00538067
Epoch [65/300], Train Loss: 0.004681
Validation Loss: 0.00487886
Epoch [66/300], Train Loss: 0.004619
Validation Loss: 0.00486959
Epoch [67/300], Train Loss: 0.004602
Validation Loss: 0.00494057
Epoch [68/300], Train Loss: 0.004604
Validation Loss: 0.00488793
Epoch [69/300], Train Loss: 0.004617
Validation Loss: 0.00496418
Epoch [70/300], Train Loss: 0.004688
Validation Loss: 0.00487598
Epoch [71/300], Train Loss: 0.004601
Validation Loss: 0.00507408
Epoch [72/300], Train Loss: 0.004666
Validation Loss: 0.00484697
Epoch [73/300], Train Loss: 0.004601
Validation Loss: 0.00481177
Epoch [74/300], Train Loss: 0.004534
Validation Loss: 0.00481216
Epoch [75/300], Train Loss: 0.004557
Validation Loss: 0.00480128
Epoch [76/300], Train Loss: 0.004529
Validation Loss: 0.00479685
Epoch [77/300], Train Loss: 0.004553
Validation Loss: 0.00479004
Epoch [78/300], Train Loss: 0.004586
Validation Loss: 0.00478483
Epoch [79/300], Train Loss: 0.004536
Validation Loss: 0.00487514
Epoch [80/300], Train Loss: 0.004530
Validation Loss: 0.00477335
Epoch [81/300], Train Loss: 0.004503
Validation Loss: 0.00476908
Epoch [82/300], Train Loss: 0.004549
Validation Loss: 0.00501235
Epoch [83/300], Train Loss: 0.004525
Validation Loss: 0.00478242
Epoch [84/300], Train Loss: 0.004503
Validation Loss: 0.00479606
Epoch [85/300], Train Loss: 0.004556
Validation Loss: 0.00475919
Epoch [86/300], Train Loss: 0.004484
Validation Loss: 0.00475577
Epoch [87/300], Train Loss: 0.004533
Validation Loss: 0.00476322
Epoch [88/300], Train Loss: 0.004492
Validation Loss: 0.00475048
Epoch [89/300], Train Loss: 0.004494
Validation Loss: 0.00478028
Epoch [90/300], Train Loss: 0.004476
Validation Loss: 0.00475508
Epoch [91/300], Train Loss: 0.004486
Validation Loss: 0.00475239
Epoch [92/300], Train Loss: 0.004490
Validation Loss: 0.00478515
Epoch [93/300], Train Loss: 0.004459
Validation Loss: 0.00474751
Epoch [94/300], Train Loss: 0.004489
Validation Loss: 0.00485186
Epoch [95/300], Train Loss: 0.004475
Validation Loss: 0.00477222
Epoch [96/300], Train Loss: 0.004554
Validation Loss: 0.00472570
Epoch [97/300], Train Loss: 0.004458
Validation Loss: 0.00471191
Epoch [98/300], Train Loss: 0.004458
Validation Loss: 0.00475380
Epoch [99/300], Train Loss: 0.004452
Validation Loss: 0.00481545
Epoch [100/300], Train Loss: 0.004473
Validation Loss: 0.00471147
Epoch [101/300], Train Loss: 0.004488
Validation Loss: 0.00479932
Epoch [102/300], Train Loss: 0.004453
Validation Loss: 0.00471154
Epoch [103/300], Train Loss: 0.004432
Validation Loss: 0.00475299
Epoch [104/300], Train Loss: 0.004493
Validation Loss: 0.00472609
Epoch [105/300], Train Loss: 0.004439
Validation Loss: 0.00475136
Epoch [106/300], Train Loss: 0.004446
Validation Loss: 0.00468207
Epoch [107/300], Train Loss: 0.004449
Validation Loss: 0.00468570
Epoch [108/300], Train Loss: 0.004438
Validation Loss: 0.00470712
Epoch [109/300], Train Loss: 0.004431
Validation Loss: 0.00471075
Epoch [110/300], Train Loss: 0.004468
Validation Loss: 0.00468292
Epoch [111/300], Train Loss: 0.004436
Validation Loss: 0.00465968
Epoch [112/300], Train Loss: 0.004408
Validation Loss: 0.00468649
Epoch [113/300], Train Loss: 0.004442
Validation Loss: 0.00477055
Epoch [114/300], Train Loss: 0.004464
Validation Loss: 0.00468152
Epoch [115/300], Train Loss: 0.004425
Validation Loss: 0.00466980
Epoch [116/300], Train Loss: 0.004449
Validation Loss: 0.00467123
Epoch [117/300], Train Loss: 0.004433
Validation Loss: 0.00467718
Epoch [118/300], Train Loss: 0.004414
Validation Loss: 0.00474678
Epoch [119/300], Train Loss: 0.004414
Validation Loss: 0.00465113
Epoch [120/300], Train Loss: 0.004406
Validation Loss: 0.00463446
Epoch [121/300], Train Loss: 0.004393
Validation Loss: 0.00470997
Epoch [122/300], Train Loss: 0.004432
Validation Loss: 0.00466771
Epoch [123/300], Train Loss: 0.004395
Validation Loss: 0.00463172
Epoch [124/300], Train Loss: 0.004394
Validation Loss: 0.00468272
Epoch [125/300], Train Loss: 0.004365
Validation Loss: 0.00467703
Epoch [126/300], Train Loss: 0.004394
Validation Loss: 0.00463596
Epoch [127/300], Train Loss: 0.004390
Validation Loss: 0.00472042
Epoch [128/300], Train Loss: 0.004495
Validation Loss: 0.00470621
Epoch [129/300], Train Loss: 0.004408
Validation Loss: 0.00461899
Epoch [130/300], Train Loss: 0.004386
Validation Loss: 0.00469563
Epoch [131/300], Train Loss: 0.004398
Validation Loss: 0.00461498
Epoch [132/300], Train Loss: 0.004384
Validation Loss: 0.00460820
Epoch [133/300], Train Loss: 0.004402
Validation Loss: 0.00463155
Epoch [134/300], Train Loss: 0.004383
Validation Loss: 0.00473301
Epoch [135/300], Train Loss: 0.004430
Validation Loss: 0.00464043
Epoch [136/300], Train Loss: 0.004359
Validation Loss: 0.00465914
Epoch [137/300], Train Loss: 0.004365
Validation Loss: 0.00465662
Epoch [138/300], Train Loss: 0.004363
Validation Loss: 0.00461700
Epoch [139/300], Train Loss: 0.004366
Validation Loss: 0.00464044
Epoch [140/300], Train Loss: 0.004357
Validation Loss: 0.00458166
Epoch [141/300], Train Loss: 0.004373
Validation Loss: 0.00460115
Epoch [142/300], Train Loss: 0.004364
Validation Loss: 0.00486061
Epoch [143/300], Train Loss: 0.004406
Validation Loss: 0.00483787
Epoch [144/300], Train Loss: 0.004501
Validation Loss: 0.00463380
Epoch [145/300], Train Loss: 0.004359
Validation Loss: 0.00465640
Epoch [146/300], Train Loss: 0.004392
Validation Loss: 0.00465252
Epoch [147/300], Train Loss: 0.004342
Validation Loss: 0.00468215
Epoch [148/300], Train Loss: 0.004365
Validation Loss: 0.00462740
Epoch [149/300], Train Loss: 0.004343
Validation Loss: 0.00459968
Epoch [150/300], Train Loss: 0.004401
Validation Loss: 0.00467901
Early stopping triggered

Evaluating model for: Router
Run 49/72 completed in 1102.34 seconds with: {'MAE': np.float32(0.18587527), 'MSE': np.float32(0.056284547), 'RMSE': np.float32(0.23724364), 'SAE': np.float32(0.0011522803), 'NDE': np.float32(0.011857673)}

Run 50/72: hidden=512, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Router
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.027874
Validation Loss: 0.00798082
Epoch [2/300], Train Loss: 0.007231
Validation Loss: 0.00739280
Epoch [3/300], Train Loss: 0.006953
Validation Loss: 0.00721176
Epoch [4/300], Train Loss: 0.006773
Validation Loss: 0.00704274
Epoch [5/300], Train Loss: 0.006615
Validation Loss: 0.00686815
Epoch [6/300], Train Loss: 0.006525
Validation Loss: 0.00672387
Epoch [7/300], Train Loss: 0.006315
Validation Loss: 0.00660305
Epoch [8/300], Train Loss: 0.006197
Validation Loss: 0.00653526
Epoch [9/300], Train Loss: 0.006110
Validation Loss: 0.00642541
Epoch [10/300], Train Loss: 0.006048
Validation Loss: 0.00636846
Epoch [11/300], Train Loss: 0.006033
Validation Loss: 0.00628012
Epoch [12/300], Train Loss: 0.005897
Validation Loss: 0.00621946
Epoch [13/300], Train Loss: 0.005858
Validation Loss: 0.00623393
Epoch [14/300], Train Loss: 0.005814
Validation Loss: 0.00613144
Epoch [15/300], Train Loss: 0.005728
Validation Loss: 0.00605917
Epoch [16/300], Train Loss: 0.005678
Validation Loss: 0.00602707
Epoch [17/300], Train Loss: 0.005651
Validation Loss: 0.00598548
Epoch [18/300], Train Loss: 0.005603
Validation Loss: 0.00595063
Epoch [19/300], Train Loss: 0.005605
Validation Loss: 0.00591036
Epoch [20/300], Train Loss: 0.005587
Validation Loss: 0.00590629
Epoch [21/300], Train Loss: 0.005535
Validation Loss: 0.00585344
Epoch [22/300], Train Loss: 0.005509
Validation Loss: 0.00584180
Epoch [23/300], Train Loss: 0.005531
Validation Loss: 0.00582382
Epoch [24/300], Train Loss: 0.005536
Validation Loss: 0.00578229
Epoch [25/300], Train Loss: 0.005426
Validation Loss: 0.00575953
Epoch [26/300], Train Loss: 0.005415
Validation Loss: 0.00576659
Epoch [27/300], Train Loss: 0.005369
Validation Loss: 0.00571693
Epoch [28/300], Train Loss: 0.005336
Validation Loss: 0.00581373
Epoch [29/300], Train Loss: 0.005361
Validation Loss: 0.00567958
Epoch [30/300], Train Loss: 0.005303
Validation Loss: 0.00569294
Epoch [31/300], Train Loss: 0.005335
Validation Loss: 0.00564543
Epoch [32/300], Train Loss: 0.005308
Validation Loss: 0.00568403
Epoch [33/300], Train Loss: 0.005305
Validation Loss: 0.00562703
Epoch [34/300], Train Loss: 0.005256
Validation Loss: 0.00566202
Epoch [35/300], Train Loss: 0.005253
Validation Loss: 0.00560440
Epoch [36/300], Train Loss: 0.005224
Validation Loss: 0.00559669
Epoch [37/300], Train Loss: 0.005212
Validation Loss: 0.00558824
Epoch [38/300], Train Loss: 0.005260
Validation Loss: 0.00559823
Epoch [39/300], Train Loss: 0.005221
Validation Loss: 0.00559067
Epoch [40/300], Train Loss: 0.005209
Validation Loss: 0.00560095
Epoch [41/300], Train Loss: 0.005228
Validation Loss: 0.00557574
Epoch [42/300], Train Loss: 0.005227
Validation Loss: 0.00559160
Epoch [43/300], Train Loss: 0.005240
Validation Loss: 0.00555919
Epoch [44/300], Train Loss: 0.005201
Validation Loss: 0.00550078
Epoch [45/300], Train Loss: 0.005232
Validation Loss: 0.00553629
Epoch [46/300], Train Loss: 0.005156
Validation Loss: 0.00552551
Epoch [47/300], Train Loss: 0.005188
Validation Loss: 0.00550298
Epoch [48/300], Train Loss: 0.005126
Validation Loss: 0.00550773
Epoch [49/300], Train Loss: 0.005101
Validation Loss: 0.00543272
Epoch [50/300], Train Loss: 0.005048
Validation Loss: 0.00546549
Epoch [51/300], Train Loss: 0.005069
Validation Loss: 0.00537212
Epoch [52/300], Train Loss: 0.005012
Validation Loss: 0.00532065
Epoch [53/300], Train Loss: 0.004953
Validation Loss: 0.00569104
Epoch [54/300], Train Loss: 0.004978
Validation Loss: 0.00523157
Epoch [55/300], Train Loss: 0.004829
Validation Loss: 0.00510971
Epoch [56/300], Train Loss: 0.004918
Validation Loss: 0.00543092
Epoch [57/300], Train Loss: 0.004789
Validation Loss: 0.00515627
Epoch [58/300], Train Loss: 0.004772
Validation Loss: 0.00513552
Epoch [59/300], Train Loss: 0.004787
Validation Loss: 0.00508488
Epoch [60/300], Train Loss: 0.004667
Validation Loss: 0.00502445
Epoch [61/300], Train Loss: 0.004620
Validation Loss: 0.00499851
Epoch [62/300], Train Loss: 0.004583
Validation Loss: 0.00480487
Epoch [63/300], Train Loss: 0.004609
Validation Loss: 0.00486013
Epoch [64/300], Train Loss: 0.004617
Validation Loss: 0.00487476
Epoch [65/300], Train Loss: 0.004621
Validation Loss: 0.00484551
Epoch [66/300], Train Loss: 0.004567
Validation Loss: 0.00486387
Epoch [67/300], Train Loss: 0.004552
Validation Loss: 0.00483810
Epoch [68/300], Train Loss: 0.004535
Validation Loss: 0.00483702
Epoch [69/300], Train Loss: 0.004537
Validation Loss: 0.00482196
Epoch [70/300], Train Loss: 0.004510
Validation Loss: 0.00486547
Epoch [71/300], Train Loss: 0.004519
Validation Loss: 0.00478044
Epoch [72/300], Train Loss: 0.004496
Validation Loss: 0.00478186
Epoch [73/300], Train Loss: 0.004524
Validation Loss: 0.00474668
Epoch [74/300], Train Loss: 0.004495
Validation Loss: 0.00480224
Epoch [75/300], Train Loss: 0.004529
Validation Loss: 0.00480289
Epoch [76/300], Train Loss: 0.004503
Validation Loss: 0.00476458
Epoch [77/300], Train Loss: 0.004516
Validation Loss: 0.00477493
Epoch [78/300], Train Loss: 0.004539
Validation Loss: 0.00480527
Epoch [79/300], Train Loss: 0.004501
Validation Loss: 0.00488592
Epoch [80/300], Train Loss: 0.004527
Validation Loss: 0.00474421
Epoch [81/300], Train Loss: 0.004469
Validation Loss: 0.00481940
Epoch [82/300], Train Loss: 0.004474
Validation Loss: 0.00475582
Epoch [83/300], Train Loss: 0.004461
Validation Loss: 0.00474879
Epoch [84/300], Train Loss: 0.004538
Validation Loss: 0.00476837
Epoch [85/300], Train Loss: 0.004541
Validation Loss: 0.00474251
Epoch [86/300], Train Loss: 0.004457
Validation Loss: 0.00473726
Epoch [87/300], Train Loss: 0.004492
Validation Loss: 0.00472568
Epoch [88/300], Train Loss: 0.004447
Validation Loss: 0.00473731
Epoch [89/300], Train Loss: 0.004474
Validation Loss: 0.00484341
Epoch [90/300], Train Loss: 0.004460
Validation Loss: 0.00480578
Epoch [91/300], Train Loss: 0.004476
Validation Loss: 0.00474479
Epoch [92/300], Train Loss: 0.004479
Validation Loss: 0.00486270
Epoch [93/300], Train Loss: 0.004446
Validation Loss: 0.00476331
Epoch [94/300], Train Loss: 0.004467
Validation Loss: 0.00478154
Epoch [95/300], Train Loss: 0.004459
Validation Loss: 0.00480456
Epoch [96/300], Train Loss: 0.004561
Validation Loss: 0.00477682
Epoch [97/300], Train Loss: 0.004429
Validation Loss: 0.00470863
Epoch [98/300], Train Loss: 0.004432
Validation Loss: 0.00470669
Epoch [99/300], Train Loss: 0.004425
Validation Loss: 0.00477354
Epoch [100/300], Train Loss: 0.004469
Validation Loss: 0.00469072
Epoch [101/300], Train Loss: 0.004487
Validation Loss: 0.00488035
Epoch [102/300], Train Loss: 0.004447
Validation Loss: 0.00470003
Epoch [103/300], Train Loss: 0.004408
Validation Loss: 0.00477018
Epoch [104/300], Train Loss: 0.004475
Validation Loss: 0.00475446
Epoch [105/300], Train Loss: 0.004408
Validation Loss: 0.00470239
Epoch [106/300], Train Loss: 0.004424
Validation Loss: 0.00468288
Epoch [107/300], Train Loss: 0.004437
Validation Loss: 0.00468741
Epoch [108/300], Train Loss: 0.004426
Validation Loss: 0.00471732
Epoch [109/300], Train Loss: 0.004426
Validation Loss: 0.00471961
Epoch [110/300], Train Loss: 0.004448
Validation Loss: 0.00468539
Epoch [111/300], Train Loss: 0.004416
Validation Loss: 0.00466660
Epoch [112/300], Train Loss: 0.004398
Validation Loss: 0.00467318
Epoch [113/300], Train Loss: 0.004430
Validation Loss: 0.00476877
Epoch [114/300], Train Loss: 0.004461
Validation Loss: 0.00469298
Epoch [115/300], Train Loss: 0.004417
Validation Loss: 0.00466895
Epoch [116/300], Train Loss: 0.004430
Validation Loss: 0.00469776
Epoch [117/300], Train Loss: 0.004433
Validation Loss: 0.00467321
Epoch [118/300], Train Loss: 0.004406
Validation Loss: 0.00471668
Epoch [119/300], Train Loss: 0.004409
Validation Loss: 0.00466524
Epoch [120/300], Train Loss: 0.004399
Validation Loss: 0.00465712
Epoch [121/300], Train Loss: 0.004393
Validation Loss: 0.00473251
Epoch [122/300], Train Loss: 0.004442
Validation Loss: 0.00468117
Epoch [123/300], Train Loss: 0.004399
Validation Loss: 0.00464783
Epoch [124/300], Train Loss: 0.004401
Validation Loss: 0.00469882
Epoch [125/300], Train Loss: 0.004367
Validation Loss: 0.00469772
Epoch [126/300], Train Loss: 0.004403
Validation Loss: 0.00464411
Epoch [127/300], Train Loss: 0.004401
Validation Loss: 0.00475855
Epoch [128/300], Train Loss: 0.004492
Validation Loss: 0.00474115
Epoch [129/300], Train Loss: 0.004411
Validation Loss: 0.00465506
Epoch [130/300], Train Loss: 0.004397
Validation Loss: 0.00471011
Epoch [131/300], Train Loss: 0.004397
Validation Loss: 0.00464891
Epoch [132/300], Train Loss: 0.004408
Validation Loss: 0.00464590
Epoch [133/300], Train Loss: 0.004405
Validation Loss: 0.00464827
Epoch [134/300], Train Loss: 0.004389
Validation Loss: 0.00476362
Epoch [135/300], Train Loss: 0.004456
Validation Loss: 0.00466677
Epoch [136/300], Train Loss: 0.004378
Validation Loss: 0.00466183
Early stopping triggered

Evaluating model for: Router
Run 50/72 completed in 1110.21 seconds with: {'MAE': np.float32(0.18529424), 'MSE': np.float32(0.056075472), 'RMSE': np.float32(0.23680261), 'SAE': np.float32(0.00053126254), 'NDE': np.float32(0.011835628)}

Run 51/72: hidden=512, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Router
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.033395
Validation Loss: 0.00891545
Epoch [2/300], Train Loss: 0.007696
Validation Loss: 0.00779444
Epoch [3/300], Train Loss: 0.007336
Validation Loss: 0.00752888
Epoch [4/300], Train Loss: 0.007083
Validation Loss: 0.00729529
Epoch [5/300], Train Loss: 0.006863
Validation Loss: 0.00706724
Epoch [6/300], Train Loss: 0.006732
Validation Loss: 0.00691609
Epoch [7/300], Train Loss: 0.006492
Validation Loss: 0.00674681
Epoch [8/300], Train Loss: 0.006346
Validation Loss: 0.00664820
Epoch [9/300], Train Loss: 0.006260
Validation Loss: 0.00653148
Epoch [10/300], Train Loss: 0.006181
Validation Loss: 0.00647239
Epoch [11/300], Train Loss: 0.006151
Validation Loss: 0.00634415
Epoch [12/300], Train Loss: 0.006004
Validation Loss: 0.00628030
Epoch [13/300], Train Loss: 0.005954
Validation Loss: 0.00631783
Epoch [14/300], Train Loss: 0.005878
Validation Loss: 0.00614187
Epoch [15/300], Train Loss: 0.005793
Validation Loss: 0.00609117
Epoch [16/300], Train Loss: 0.005734
Validation Loss: 0.00605692
Epoch [17/300], Train Loss: 0.005704
Validation Loss: 0.00600035
Epoch [18/300], Train Loss: 0.005654
Validation Loss: 0.00597052
Epoch [19/300], Train Loss: 0.005663
Validation Loss: 0.00592662
Epoch [20/300], Train Loss: 0.005647
Validation Loss: 0.00596060
Epoch [21/300], Train Loss: 0.005583
Validation Loss: 0.00586868
Epoch [22/300], Train Loss: 0.005558
Validation Loss: 0.00587354
Epoch [23/300], Train Loss: 0.005581
Validation Loss: 0.00582191
Epoch [24/300], Train Loss: 0.005558
Validation Loss: 0.00580468
Epoch [25/300], Train Loss: 0.005458
Validation Loss: 0.00577273
Epoch [26/300], Train Loss: 0.005449
Validation Loss: 0.00577074
Epoch [27/300], Train Loss: 0.005402
Validation Loss: 0.00572512
Epoch [28/300], Train Loss: 0.005361
Validation Loss: 0.00581564
Epoch [29/300], Train Loss: 0.005387
Validation Loss: 0.00569075
Epoch [30/300], Train Loss: 0.005334
Validation Loss: 0.00571453
Epoch [31/300], Train Loss: 0.005369
Validation Loss: 0.00566919
Epoch [32/300], Train Loss: 0.005329
Validation Loss: 0.00570392
Epoch [33/300], Train Loss: 0.005309
Validation Loss: 0.00561947
Epoch [34/300], Train Loss: 0.005253
Validation Loss: 0.00562941
Epoch [35/300], Train Loss: 0.005282
Validation Loss: 0.00565380
Epoch [36/300], Train Loss: 0.005262
Validation Loss: 0.00562136
Epoch [37/300], Train Loss: 0.005229
Validation Loss: 0.00559831
Epoch [38/300], Train Loss: 0.005275
Validation Loss: 0.00558995
Epoch [39/300], Train Loss: 0.005221
Validation Loss: 0.00556085
Epoch [40/300], Train Loss: 0.005202
Validation Loss: 0.00553857
Epoch [41/300], Train Loss: 0.005161
Validation Loss: 0.00546031
Epoch [42/300], Train Loss: 0.005122
Validation Loss: 0.00547759
Epoch [43/300], Train Loss: 0.005333
Validation Loss: 0.00565152
Epoch [44/300], Train Loss: 0.005190
Validation Loss: 0.00551255
Epoch [45/300], Train Loss: 0.005180
Validation Loss: 0.00542601
Epoch [46/300], Train Loss: 0.005039
Validation Loss: 0.00535251
Epoch [47/300], Train Loss: 0.004994
Validation Loss: 0.00524037
Epoch [48/300], Train Loss: 0.004850
Validation Loss: 0.00525043
Epoch [49/300], Train Loss: 0.004870
Validation Loss: 0.00515777
Epoch [50/300], Train Loss: 0.004774
Validation Loss: 0.00540693
Epoch [51/300], Train Loss: 0.004791
Validation Loss: 0.00501843
Epoch [52/300], Train Loss: 0.004731
Validation Loss: 0.00503041
Epoch [53/300], Train Loss: 0.004683
Validation Loss: 0.00497619
Epoch [54/300], Train Loss: 0.004677
Validation Loss: 0.00506515
Epoch [55/300], Train Loss: 0.004733
Validation Loss: 0.00492798
Epoch [56/300], Train Loss: 0.004671
Validation Loss: 0.00506495
Epoch [57/300], Train Loss: 0.004674
Validation Loss: 0.00490893
Epoch [58/300], Train Loss: 0.004638
Validation Loss: 0.00490013
Epoch [59/300], Train Loss: 0.004592
Validation Loss: 0.00485829
Epoch [60/300], Train Loss: 0.004593
Validation Loss: 0.00485619
Epoch [61/300], Train Loss: 0.004594
Validation Loss: 0.00483978
Epoch [62/300], Train Loss: 0.004551
Validation Loss: 0.00490258
Epoch [63/300], Train Loss: 0.004585
Validation Loss: 0.00492401
Epoch [64/300], Train Loss: 0.004551
Validation Loss: 0.00505093
Epoch [65/300], Train Loss: 0.004587
Validation Loss: 0.00486799
Epoch [66/300], Train Loss: 0.004542
Validation Loss: 0.00481317
Epoch [67/300], Train Loss: 0.004519
Validation Loss: 0.00478881
Epoch [68/300], Train Loss: 0.004533
Validation Loss: 0.00483632
Epoch [69/300], Train Loss: 0.004550
Validation Loss: 0.00492578
Epoch [70/300], Train Loss: 0.004602
Validation Loss: 0.00484667
Epoch [71/300], Train Loss: 0.004580
Validation Loss: 0.00496747
Epoch [72/300], Train Loss: 0.004561
Validation Loss: 0.00481128
Epoch [73/300], Train Loss: 0.004522
Validation Loss: 0.00475542
Epoch [74/300], Train Loss: 0.004505
Validation Loss: 0.00480660
Epoch [75/300], Train Loss: 0.004516
Validation Loss: 0.00479312
Epoch [76/300], Train Loss: 0.004493
Validation Loss: 0.00477924
Epoch [77/300], Train Loss: 0.004529
Validation Loss: 0.00477426
Epoch [78/300], Train Loss: 0.004544
Validation Loss: 0.00476824
Epoch [79/300], Train Loss: 0.004491
Validation Loss: 0.00484189
Epoch [80/300], Train Loss: 0.004494
Validation Loss: 0.00473710
Epoch [81/300], Train Loss: 0.004484
Validation Loss: 0.00473302
Epoch [82/300], Train Loss: 0.004520
Validation Loss: 0.00494788
Epoch [83/300], Train Loss: 0.004488
Validation Loss: 0.00478789
Epoch [84/300], Train Loss: 0.004502
Validation Loss: 0.00473807
Epoch [85/300], Train Loss: 0.004500
Validation Loss: 0.00474497
Epoch [86/300], Train Loss: 0.004467
Validation Loss: 0.00474474
Epoch [87/300], Train Loss: 0.004497
Validation Loss: 0.00474991
Epoch [88/300], Train Loss: 0.004460
Validation Loss: 0.00471375
Epoch [89/300], Train Loss: 0.004473
Validation Loss: 0.00481486
Epoch [90/300], Train Loss: 0.004461
Validation Loss: 0.00479727
Epoch [91/300], Train Loss: 0.004474
Validation Loss: 0.00478246
Epoch [92/300], Train Loss: 0.004471
Validation Loss: 0.00476421
Epoch [93/300], Train Loss: 0.004447
Validation Loss: 0.00470961
Epoch [94/300], Train Loss: 0.004454
Validation Loss: 0.00477454
Epoch [95/300], Train Loss: 0.004457
Validation Loss: 0.00475652
Epoch [96/300], Train Loss: 0.004514
Validation Loss: 0.00477401
Epoch [97/300], Train Loss: 0.004444
Validation Loss: 0.00470189
Epoch [98/300], Train Loss: 0.004442
Validation Loss: 0.00476518
Epoch [99/300], Train Loss: 0.004444
Validation Loss: 0.00475560
Epoch [100/300], Train Loss: 0.004468
Validation Loss: 0.00472509
Epoch [101/300], Train Loss: 0.004480
Validation Loss: 0.00476104
Epoch [102/300], Train Loss: 0.004443
Validation Loss: 0.00472284
Epoch [103/300], Train Loss: 0.004441
Validation Loss: 0.00475138
Epoch [104/300], Train Loss: 0.004483
Validation Loss: 0.00472595
Epoch [105/300], Train Loss: 0.004439
Validation Loss: 0.00477329
Epoch [106/300], Train Loss: 0.004447
Validation Loss: 0.00471788
Epoch [107/300], Train Loss: 0.004456
Validation Loss: 0.00471321
Early stopping triggered

Evaluating model for: Router
Run 51/72 completed in 960.48 seconds with: {'MAE': np.float32(0.18513873), 'MSE': np.float32(0.056578357), 'RMSE': np.float32(0.23786205), 'SAE': np.float32(0.00028941323), 'NDE': np.float32(0.011888579)}

Run 52/72: hidden=512, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Router
Dataset length: 6585 windows

Epoch [1/300], Train Loss: 0.027529
Validation Loss: 0.00811161
Epoch [2/300], Train Loss: 0.007220
Validation Loss: 0.00742610
Epoch [3/300], Train Loss: 0.006956
Validation Loss: 0.00720936
Epoch [4/300], Train Loss: 0.006745
Validation Loss: 0.00702304
Epoch [5/300], Train Loss: 0.006576
Validation Loss: 0.00684041
Epoch [6/300], Train Loss: 0.006502
Validation Loss: 0.00670680
Epoch [7/300], Train Loss: 0.006288
Validation Loss: 0.00657161
Epoch [8/300], Train Loss: 0.006139
Validation Loss: 0.00643489
Epoch [9/300], Train Loss: 0.006058
Validation Loss: 0.00635838
Epoch [10/300], Train Loss: 0.005986
Validation Loss: 0.00630004
Epoch [11/300], Train Loss: 0.005963
Validation Loss: 0.00619134
Epoch [12/300], Train Loss: 0.005826
Validation Loss: 0.00617747
Epoch [13/300], Train Loss: 0.005793
Validation Loss: 0.00617278
Epoch [14/300], Train Loss: 0.005703
Validation Loss: 0.00600005
Epoch [15/300], Train Loss: 0.005624
Validation Loss: 0.00593675
Epoch [16/300], Train Loss: 0.005558
Validation Loss: 0.00593496
Epoch [17/300], Train Loss: 0.005505
Validation Loss: 0.00580416
Epoch [18/300], Train Loss: 0.005476
Validation Loss: 0.00579907
Epoch [19/300], Train Loss: 0.005431
Validation Loss: 0.00570598
Epoch [20/300], Train Loss: 0.005424
Validation Loss: 0.00571009
Epoch [21/300], Train Loss: 0.005288
Validation Loss: 0.00562496
Epoch [22/300], Train Loss: 0.005210
Validation Loss: 0.00548136
Epoch [23/300], Train Loss: 0.005191
Validation Loss: 0.00553175
Epoch [24/300], Train Loss: 0.005177
Validation Loss: 0.00553887
Epoch [25/300], Train Loss: 0.005088
Validation Loss: 0.00529614
Epoch [26/300], Train Loss: 0.004983
Validation Loss: 0.00524076
Epoch [27/300], Train Loss: 0.004918
Validation Loss: 0.00516441
Epoch [28/300], Train Loss: 0.004801
Validation Loss: 0.00527053
Epoch [29/300], Train Loss: 0.004806
Validation Loss: 0.00495253
Epoch [30/300], Train Loss: 0.004737
Validation Loss: 0.00499878
Epoch [31/300], Train Loss: 0.004729
Validation Loss: 0.00498204
Epoch [32/300], Train Loss: 0.004652
Validation Loss: 0.00503165
Epoch [33/300], Train Loss: 0.004642
Validation Loss: 0.00483448
Epoch [34/300], Train Loss: 0.004645
Validation Loss: 0.00489022
Epoch [35/300], Train Loss: 0.004592
Validation Loss: 0.00492291
Epoch [36/300], Train Loss: 0.004565
Validation Loss: 0.00487491
Epoch [37/300], Train Loss: 0.004540
Validation Loss: 0.00482683
Epoch [38/300], Train Loss: 0.004561
Validation Loss: 0.00496798
Epoch [39/300], Train Loss: 0.004544
Validation Loss: 0.00480316
Epoch [40/300], Train Loss: 0.004549
Validation Loss: 0.00491280
Epoch [41/300], Train Loss: 0.004530
Validation Loss: 0.00476752
Epoch [42/300], Train Loss: 0.004516
Validation Loss: 0.00479449
Epoch [43/300], Train Loss: 0.004528
Validation Loss: 0.00481022
Epoch [44/300], Train Loss: 0.004539
Validation Loss: 0.00476837
Epoch [45/300], Train Loss: 0.004563
Validation Loss: 0.00476423
Epoch [46/300], Train Loss: 0.004600
Validation Loss: 0.00502667
Epoch [47/300], Train Loss: 0.004531
Validation Loss: 0.00478362
Epoch [48/300], Train Loss: 0.004486
Validation Loss: 0.00474139
Epoch [49/300], Train Loss: 0.004500
Validation Loss: 0.00478706
Epoch [50/300], Train Loss: 0.004482
Validation Loss: 0.00477353
Epoch [51/300], Train Loss: 0.004495
Validation Loss: 0.00472414
Epoch [52/300], Train Loss: 0.004496
Validation Loss: 0.00478212
Epoch [53/300], Train Loss: 0.004468
Validation Loss: 0.00476005
Epoch [54/300], Train Loss: 0.004465
Validation Loss: 0.00478075
Epoch [55/300], Train Loss: 0.004474
Validation Loss: 0.00475364
Epoch [56/300], Train Loss: 0.004494
Validation Loss: 0.00474748
Epoch [57/300], Train Loss: 0.004507
Validation Loss: 0.00479439
Epoch [58/300], Train Loss: 0.004499
Validation Loss: 0.00476159
Epoch [59/300], Train Loss: 0.004472
Validation Loss: 0.00472534
Epoch [60/300], Train Loss: 0.004481
Validation Loss: 0.00472271
Epoch [61/300], Train Loss: 0.004460
Validation Loss: 0.00471858
Epoch [62/300], Train Loss: 0.004450
Validation Loss: 0.00483150
Epoch [63/300], Train Loss: 0.004499
Validation Loss: 0.00473555
Epoch [64/300], Train Loss: 0.004474
Validation Loss: 0.00473012
Epoch [65/300], Train Loss: 0.004484
Validation Loss: 0.00478621
Epoch [66/300], Train Loss: 0.004496
Validation Loss: 0.00473754
Epoch [67/300], Train Loss: 0.004443
Validation Loss: 0.00476047
Epoch [68/300], Train Loss: 0.004458
Validation Loss: 0.00475835
Epoch [69/300], Train Loss: 0.004459
Validation Loss: 0.00469475
Epoch [70/300], Train Loss: 0.004479
Validation Loss: 0.00472905
Epoch [71/300], Train Loss: 0.004464
Validation Loss: 0.00483484
Epoch [72/300], Train Loss: 0.004461
Validation Loss: 0.00474902
Epoch [73/300], Train Loss: 0.004476
Validation Loss: 0.00472454
Epoch [74/300], Train Loss: 0.004432
Validation Loss: 0.00471532
Epoch [75/300], Train Loss: 0.004438
Validation Loss: 0.00472518
Epoch [76/300], Train Loss: 0.004433
Validation Loss: 0.00470883
Epoch [77/300], Train Loss: 0.004470
Validation Loss: 0.00469719
Epoch [78/300], Train Loss: 0.004470
Validation Loss: 0.00480644
Epoch [79/300], Train Loss: 0.004439
Validation Loss: 0.00469504
Early stopping triggered

Evaluating model for: Router
Run 52/72 completed in 838.41 seconds with: {'MAE': np.float32(0.18336825), 'MSE': np.float32(0.056859303), 'RMSE': np.float32(0.23845188), 'SAE': np.float32(0.0008613659), 'NDE': np.float32(0.01191806)}

Run 53/72: hidden=512, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Router
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.049626
Validation Loss: 0.01381342
Epoch [2/300], Train Loss: 0.009160
Validation Loss: 0.00781256
Epoch [3/300], Train Loss: 0.007019
Validation Loss: 0.00720771
Epoch [4/300], Train Loss: 0.006801
Validation Loss: 0.00701544
Epoch [5/300], Train Loss: 0.006675
Validation Loss: 0.00693481
Epoch [6/300], Train Loss: 0.006604
Validation Loss: 0.00686644
Epoch [7/300], Train Loss: 0.006536
Validation Loss: 0.00680911
Epoch [8/300], Train Loss: 0.006468
Validation Loss: 0.00673272
Epoch [9/300], Train Loss: 0.006393
Validation Loss: 0.00666605
Epoch [10/300], Train Loss: 0.006332
Validation Loss: 0.00660134
Epoch [11/300], Train Loss: 0.006284
Validation Loss: 0.00653805
Epoch [12/300], Train Loss: 0.006243
Validation Loss: 0.00650678
Epoch [13/300], Train Loss: 0.006183
Validation Loss: 0.00643448
Epoch [14/300], Train Loss: 0.006106
Validation Loss: 0.00640043
Epoch [15/300], Train Loss: 0.006083
Validation Loss: 0.00641434
Epoch [16/300], Train Loss: 0.006041
Validation Loss: 0.00631668
Epoch [17/300], Train Loss: 0.005997
Validation Loss: 0.00628122
Epoch [18/300], Train Loss: 0.005972
Validation Loss: 0.00626306
Epoch [19/300], Train Loss: 0.005942
Validation Loss: 0.00622919
Epoch [20/300], Train Loss: 0.005922
Validation Loss: 0.00626653
Epoch [21/300], Train Loss: 0.005889
Validation Loss: 0.00617665
Epoch [22/300], Train Loss: 0.005892
Validation Loss: 0.00616761
Epoch [23/300], Train Loss: 0.005859
Validation Loss: 0.00613283
Epoch [24/300], Train Loss: 0.005845
Validation Loss: 0.00610499
Epoch [25/300], Train Loss: 0.005796
Validation Loss: 0.00608268
Epoch [26/300], Train Loss: 0.005785
Validation Loss: 0.00607014
Epoch [27/300], Train Loss: 0.005786
Validation Loss: 0.00605826
Epoch [28/300], Train Loss: 0.005774
Validation Loss: 0.00603661
Epoch [29/300], Train Loss: 0.005742
Validation Loss: 0.00601741
Epoch [30/300], Train Loss: 0.005699
Validation Loss: 0.00598870
Epoch [31/300], Train Loss: 0.005703
Validation Loss: 0.00597325
Epoch [32/300], Train Loss: 0.005686
Validation Loss: 0.00595735
Epoch [33/300], Train Loss: 0.005673
Validation Loss: 0.00597356
Epoch [34/300], Train Loss: 0.005664
Validation Loss: 0.00592877
Epoch [35/300], Train Loss: 0.005637
Validation Loss: 0.00593093
Epoch [36/300], Train Loss: 0.005608
Validation Loss: 0.00594726
Epoch [37/300], Train Loss: 0.005610
Validation Loss: 0.00589434
Epoch [38/300], Train Loss: 0.005626
Validation Loss: 0.00588846
Epoch [39/300], Train Loss: 0.005598
Validation Loss: 0.00588185
Epoch [40/300], Train Loss: 0.005559
Validation Loss: 0.00588144
Epoch [41/300], Train Loss: 0.005560
Validation Loss: 0.00584278
Epoch [42/300], Train Loss: 0.005536
Validation Loss: 0.00583756
Epoch [43/300], Train Loss: 0.005564
Validation Loss: 0.00583699
Epoch [44/300], Train Loss: 0.005529
Validation Loss: 0.00580812
Epoch [45/300], Train Loss: 0.005526
Validation Loss: 0.00580944
Epoch [46/300], Train Loss: 0.005525
Validation Loss: 0.00578622
Epoch [47/300], Train Loss: 0.005503
Validation Loss: 0.00577509
Epoch [48/300], Train Loss: 0.005488
Validation Loss: 0.00579010
Epoch [49/300], Train Loss: 0.005499
Validation Loss: 0.00579190
Epoch [50/300], Train Loss: 0.005475
Validation Loss: 0.00576210
Epoch [51/300], Train Loss: 0.005472
Validation Loss: 0.00576803
Epoch [52/300], Train Loss: 0.005461
Validation Loss: 0.00573721
Epoch [53/300], Train Loss: 0.005454
Validation Loss: 0.00572413
Epoch [54/300], Train Loss: 0.005441
Validation Loss: 0.00571705
Epoch [55/300], Train Loss: 0.005440
Validation Loss: 0.00570764
Epoch [56/300], Train Loss: 0.005447
Validation Loss: 0.00571820
Epoch [57/300], Train Loss: 0.005421
Validation Loss: 0.00570357
Epoch [58/300], Train Loss: 0.005397
Validation Loss: 0.00568687
Epoch [59/300], Train Loss: 0.005410
Validation Loss: 0.00569999
Epoch [60/300], Train Loss: 0.005405
Validation Loss: 0.00567982
Epoch [61/300], Train Loss: 0.005380
Validation Loss: 0.00566458
Epoch [62/300], Train Loss: 0.005383
Validation Loss: 0.00565718
Epoch [63/300], Train Loss: 0.005378
Validation Loss: 0.00568288
Epoch [64/300], Train Loss: 0.005411
Validation Loss: 0.00566025
Epoch [65/300], Train Loss: 0.005401
Validation Loss: 0.00567040
Epoch [66/300], Train Loss: 0.005379
Validation Loss: 0.00563367
Epoch [67/300], Train Loss: 0.005358
Validation Loss: 0.00562811
Epoch [68/300], Train Loss: 0.005364
Validation Loss: 0.00564419
Epoch [69/300], Train Loss: 0.005355
Validation Loss: 0.00565689
Epoch [70/300], Train Loss: 0.005356
Validation Loss: 0.00561135
Epoch [71/300], Train Loss: 0.005340
Validation Loss: 0.00562964
Epoch [72/300], Train Loss: 0.005354
Validation Loss: 0.00561424
Epoch [73/300], Train Loss: 0.005335
Validation Loss: 0.00559924
Epoch [74/300], Train Loss: 0.005302
Validation Loss: 0.00561616
Epoch [75/300], Train Loss: 0.005312
Validation Loss: 0.00558344
Epoch [76/300], Train Loss: 0.005298
Validation Loss: 0.00557774
Epoch [77/300], Train Loss: 0.005320
Validation Loss: 0.00566807
Epoch [78/300], Train Loss: 0.005335
Validation Loss: 0.00558431
Epoch [79/300], Train Loss: 0.005296
Validation Loss: 0.00556913
Epoch [80/300], Train Loss: 0.005310
Validation Loss: 0.00556380
Epoch [81/300], Train Loss: 0.005283
Validation Loss: 0.00555411
Epoch [82/300], Train Loss: 0.005292
Validation Loss: 0.00558886
Epoch [83/300], Train Loss: 0.005301
Validation Loss: 0.00556925
Epoch [84/300], Train Loss: 0.005267
Validation Loss: 0.00554787
Epoch [85/300], Train Loss: 0.005276
Validation Loss: 0.00554657
Epoch [86/300], Train Loss: 0.005273
Validation Loss: 0.00553196
Epoch [87/300], Train Loss: 0.005261
Validation Loss: 0.00552689
Epoch [88/300], Train Loss: 0.005259
Validation Loss: 0.00552179
Epoch [89/300], Train Loss: 0.005246
Validation Loss: 0.00551566
Epoch [90/300], Train Loss: 0.005267
Validation Loss: 0.00551004
Epoch [91/300], Train Loss: 0.005232
Validation Loss: 0.00550757
Epoch [92/300], Train Loss: 0.005245
Validation Loss: 0.00551093
Epoch [93/300], Train Loss: 0.005226
Validation Loss: 0.00553862
Epoch [94/300], Train Loss: 0.005251
Validation Loss: 0.00554449
Epoch [95/300], Train Loss: 0.005257
Validation Loss: 0.00559344
Epoch [96/300], Train Loss: 0.005247
Validation Loss: 0.00549071
Epoch [97/300], Train Loss: 0.005205
Validation Loss: 0.00547517
Epoch [98/300], Train Loss: 0.005219
Validation Loss: 0.00547338
Epoch [99/300], Train Loss: 0.005193
Validation Loss: 0.00547091
Epoch [100/300], Train Loss: 0.005209
Validation Loss: 0.00545863
Epoch [101/300], Train Loss: 0.005195
Validation Loss: 0.00548493
Epoch [102/300], Train Loss: 0.005185
Validation Loss: 0.00544395
Epoch [103/300], Train Loss: 0.005199
Validation Loss: 0.00545594
Epoch [104/300], Train Loss: 0.005192
Validation Loss: 0.00545916
Epoch [105/300], Train Loss: 0.005191
Validation Loss: 0.00541985
Epoch [106/300], Train Loss: 0.005185
Validation Loss: 0.00541898
Epoch [107/300], Train Loss: 0.005182
Validation Loss: 0.00541792
Epoch [108/300], Train Loss: 0.005156
Validation Loss: 0.00539732
Epoch [109/300], Train Loss: 0.005146
Validation Loss: 0.00538406
Epoch [110/300], Train Loss: 0.005132
Validation Loss: 0.00537758
Epoch [111/300], Train Loss: 0.005136
Validation Loss: 0.00540812
Epoch [112/300], Train Loss: 0.005130
Validation Loss: 0.00533961
Epoch [113/300], Train Loss: 0.005119
Validation Loss: 0.00535112
Epoch [114/300], Train Loss: 0.005154
Validation Loss: 0.00536634
Epoch [115/300], Train Loss: 0.005101
Validation Loss: 0.00530571
Epoch [116/300], Train Loss: 0.005105
Validation Loss: 0.00531667
Epoch [117/300], Train Loss: 0.005097
Validation Loss: 0.00526905
Epoch [118/300], Train Loss: 0.005107
Validation Loss: 0.00532500
Epoch [119/300], Train Loss: 0.005072
Validation Loss: 0.00521043
Epoch [120/300], Train Loss: 0.005013
Validation Loss: 0.00522753
Epoch [121/300], Train Loss: 0.005001
Validation Loss: 0.00519180
Epoch [122/300], Train Loss: 0.005039
Validation Loss: 0.00509910
Epoch [123/300], Train Loss: 0.005001
Validation Loss: 0.00513736
Epoch [124/300], Train Loss: 0.004935
Validation Loss: 0.00516289
Epoch [125/300], Train Loss: 0.004912
Validation Loss: 0.00514427
Epoch [126/300], Train Loss: 0.004943
Validation Loss: 0.00507457
Epoch [127/300], Train Loss: 0.004901
Validation Loss: 0.00498766
Epoch [128/300], Train Loss: 0.004858
Validation Loss: 0.00495405
Epoch [129/300], Train Loss: 0.004901
Validation Loss: 0.00499884
Epoch [130/300], Train Loss: 0.004848
Validation Loss: 0.00494164
Epoch [131/300], Train Loss: 0.004903
Validation Loss: 0.00500850
Epoch [132/300], Train Loss: 0.004902
Validation Loss: 0.00498127
Epoch [133/300], Train Loss: 0.004927
Validation Loss: 0.00496837
Epoch [134/300], Train Loss: 0.004844
Validation Loss: 0.00499044
Epoch [135/300], Train Loss: 0.004824
Validation Loss: 0.00494077
Epoch [136/300], Train Loss: 0.004779
Validation Loss: 0.00491177
Epoch [137/300], Train Loss: 0.004816
Validation Loss: 0.00507951
Epoch [138/300], Train Loss: 0.004792
Validation Loss: 0.00490544
Epoch [139/300], Train Loss: 0.004756
Validation Loss: 0.00487406
Epoch [140/300], Train Loss: 0.004780
Validation Loss: 0.00487511
Epoch [141/300], Train Loss: 0.004744
Validation Loss: 0.00488795
Epoch [142/300], Train Loss: 0.004834
Validation Loss: 0.00505717
Epoch [143/300], Train Loss: 0.004756
Validation Loss: 0.00479934
Epoch [144/300], Train Loss: 0.004732
Validation Loss: 0.00479807
Epoch [145/300], Train Loss: 0.004710
Validation Loss: 0.00481856
Epoch [146/300], Train Loss: 0.004712
Validation Loss: 0.00478394
Epoch [147/300], Train Loss: 0.004673
Validation Loss: 0.00481938
Epoch [148/300], Train Loss: 0.004682
Validation Loss: 0.00475486
Epoch [149/300], Train Loss: 0.004661
Validation Loss: 0.00477495
Epoch [150/300], Train Loss: 0.004643
Validation Loss: 0.00480024
Epoch [151/300], Train Loss: 0.004639
Validation Loss: 0.00469694
Epoch [152/300], Train Loss: 0.004641
Validation Loss: 0.00471417
Epoch [153/300], Train Loss: 0.004661
Validation Loss: 0.00477843
Epoch [154/300], Train Loss: 0.004606
Validation Loss: 0.00477280
Epoch [155/300], Train Loss: 0.004663
Validation Loss: 0.00478634
Epoch [156/300], Train Loss: 0.004631
Validation Loss: 0.00466655
Epoch [157/300], Train Loss: 0.004643
Validation Loss: 0.00466676
Epoch [158/300], Train Loss: 0.004589
Validation Loss: 0.00466420
Epoch [159/300], Train Loss: 0.004555
Validation Loss: 0.00466071
Epoch [160/300], Train Loss: 0.004580
Validation Loss: 0.00465868
Epoch [161/300], Train Loss: 0.004579
Validation Loss: 0.00465146
Epoch [162/300], Train Loss: 0.004574
Validation Loss: 0.00471007
Epoch [163/300], Train Loss: 0.004633
Validation Loss: 0.00482865
Epoch [164/300], Train Loss: 0.004632
Validation Loss: 0.00464533
Epoch [165/300], Train Loss: 0.004603
Validation Loss: 0.00465053
Epoch [166/300], Train Loss: 0.004544
Validation Loss: 0.00462380
Epoch [167/300], Train Loss: 0.004531
Validation Loss: 0.00461436
Epoch [168/300], Train Loss: 0.004530
Validation Loss: 0.00464835
Epoch [169/300], Train Loss: 0.004533
Validation Loss: 0.00460736
Epoch [170/300], Train Loss: 0.004534
Validation Loss: 0.00488550
Epoch [171/300], Train Loss: 0.004555
Validation Loss: 0.00459482
Epoch [172/300], Train Loss: 0.004536
Validation Loss: 0.00467620
Epoch [173/300], Train Loss: 0.004533
Validation Loss: 0.00467364
Epoch [174/300], Train Loss: 0.004535
Validation Loss: 0.00468825
Epoch [175/300], Train Loss: 0.004550
Validation Loss: 0.00480731
Epoch [176/300], Train Loss: 0.004567
Validation Loss: 0.00482600
Epoch [177/300], Train Loss: 0.004589
Validation Loss: 0.00461260
Epoch [178/300], Train Loss: 0.004500
Validation Loss: 0.00459681
Epoch [179/300], Train Loss: 0.004521
Validation Loss: 0.00462967
Epoch [180/300], Train Loss: 0.004519
Validation Loss: 0.00460072
Epoch [181/300], Train Loss: 0.004517
Validation Loss: 0.00463095
Early stopping triggered

Evaluating model for: Router
Run 53/72 completed in 664.11 seconds with: {'MAE': np.float32(0.18977512), 'MSE': np.float32(0.059838228), 'RMSE': np.float32(0.24461854), 'SAE': np.float32(0.0009368203), 'NDE': np.float32(0.01222407)}

Run 54/72: hidden=512, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Router
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.053785
Validation Loss: 0.00914788
Epoch [2/300], Train Loss: 0.009716
Validation Loss: 0.00773264
Epoch [3/300], Train Loss: 0.007438
Validation Loss: 0.00743598
Epoch [4/300], Train Loss: 0.007120
Validation Loss: 0.00734709
Epoch [5/300], Train Loss: 0.006970
Validation Loss: 0.00725244
Epoch [6/300], Train Loss: 0.006899
Validation Loss: 0.00716165
Epoch [7/300], Train Loss: 0.006811
Validation Loss: 0.00707534
Epoch [8/300], Train Loss: 0.006717
Validation Loss: 0.00699669
Epoch [9/300], Train Loss: 0.006629
Validation Loss: 0.00689897
Epoch [10/300], Train Loss: 0.006542
Validation Loss: 0.00681281
Epoch [11/300], Train Loss: 0.006479
Validation Loss: 0.00672910
Epoch [12/300], Train Loss: 0.006426
Validation Loss: 0.00666855
Epoch [13/300], Train Loss: 0.006333
Validation Loss: 0.00659864
Epoch [14/300], Train Loss: 0.006250
Validation Loss: 0.00653904
Epoch [15/300], Train Loss: 0.006238
Validation Loss: 0.00662143
Epoch [16/300], Train Loss: 0.006172
Validation Loss: 0.00644614
Epoch [17/300], Train Loss: 0.006113
Validation Loss: 0.00641161
Epoch [18/300], Train Loss: 0.006093
Validation Loss: 0.00642120
Epoch [19/300], Train Loss: 0.006073
Validation Loss: 0.00634746
Epoch [20/300], Train Loss: 0.006042
Validation Loss: 0.00633965
Epoch [21/300], Train Loss: 0.005982
Validation Loss: 0.00630029
Epoch [22/300], Train Loss: 0.005990
Validation Loss: 0.00625205
Epoch [23/300], Train Loss: 0.005946
Validation Loss: 0.00622524
Epoch [24/300], Train Loss: 0.005947
Validation Loss: 0.00622729
Epoch [25/300], Train Loss: 0.005901
Validation Loss: 0.00618736
Epoch [26/300], Train Loss: 0.005863
Validation Loss: 0.00614755
Epoch [27/300], Train Loss: 0.005860
Validation Loss: 0.00612659
Epoch [28/300], Train Loss: 0.005862
Validation Loss: 0.00616657
Epoch [29/300], Train Loss: 0.005821
Validation Loss: 0.00608087
Epoch [30/300], Train Loss: 0.005753
Validation Loss: 0.00606213
Epoch [31/300], Train Loss: 0.005763
Validation Loss: 0.00604525
Epoch [32/300], Train Loss: 0.005739
Validation Loss: 0.00602102
Epoch [33/300], Train Loss: 0.005722
Validation Loss: 0.00600869
Epoch [34/300], Train Loss: 0.005703
Validation Loss: 0.00598759
Epoch [35/300], Train Loss: 0.005678
Validation Loss: 0.00596902
Epoch [36/300], Train Loss: 0.005659
Validation Loss: 0.00600290
Epoch [37/300], Train Loss: 0.005648
Validation Loss: 0.00593400
Epoch [38/300], Train Loss: 0.005689
Validation Loss: 0.00597305
Epoch [39/300], Train Loss: 0.005649
Validation Loss: 0.00595631
Epoch [40/300], Train Loss: 0.005598
Validation Loss: 0.00592434
Epoch [41/300], Train Loss: 0.005593
Validation Loss: 0.00587569
Epoch [42/300], Train Loss: 0.005565
Validation Loss: 0.00586146
Epoch [43/300], Train Loss: 0.005578
Validation Loss: 0.00589089
Epoch [44/300], Train Loss: 0.005549
Validation Loss: 0.00583263
Epoch [45/300], Train Loss: 0.005539
Validation Loss: 0.00583176
Epoch [46/300], Train Loss: 0.005539
Validation Loss: 0.00581576
Epoch [47/300], Train Loss: 0.005543
Validation Loss: 0.00581435
Epoch [48/300], Train Loss: 0.005495
Validation Loss: 0.00583218
Epoch [49/300], Train Loss: 0.005508
Validation Loss: 0.00577255
Epoch [50/300], Train Loss: 0.005501
Validation Loss: 0.00582629
Epoch [51/300], Train Loss: 0.005482
Validation Loss: 0.00577572
Epoch [52/300], Train Loss: 0.005472
Validation Loss: 0.00574301
Epoch [53/300], Train Loss: 0.005464
Validation Loss: 0.00573099
Epoch [54/300], Train Loss: 0.005444
Validation Loss: 0.00572949
Epoch [55/300], Train Loss: 0.005450
Validation Loss: 0.00571829
Epoch [56/300], Train Loss: 0.005436
Validation Loss: 0.00570177
Epoch [57/300], Train Loss: 0.005422
Validation Loss: 0.00571361
Epoch [58/300], Train Loss: 0.005399
Validation Loss: 0.00568637
Epoch [59/300], Train Loss: 0.005396
Validation Loss: 0.00567643
Epoch [60/300], Train Loss: 0.005412
Validation Loss: 0.00566326
Epoch [61/300], Train Loss: 0.005366
Validation Loss: 0.00565460
Epoch [62/300], Train Loss: 0.005370
Validation Loss: 0.00564877
Epoch [63/300], Train Loss: 0.005364
Validation Loss: 0.00565311
Epoch [64/300], Train Loss: 0.005388
Validation Loss: 0.00570396
Epoch [65/300], Train Loss: 0.005368
Validation Loss: 0.00562387
Epoch [66/300], Train Loss: 0.005346
Validation Loss: 0.00562027
Epoch [67/300], Train Loss: 0.005341
Validation Loss: 0.00564053
Epoch [68/300], Train Loss: 0.005349
Validation Loss: 0.00562800
Epoch [69/300], Train Loss: 0.005318
Validation Loss: 0.00559765
Epoch [70/300], Train Loss: 0.005316
Validation Loss: 0.00559835
Epoch [71/300], Train Loss: 0.005311
Validation Loss: 0.00557775
Epoch [72/300], Train Loss: 0.005316
Validation Loss: 0.00557038
Epoch [73/300], Train Loss: 0.005307
Validation Loss: 0.00556361
Epoch [74/300], Train Loss: 0.005270
Validation Loss: 0.00559447
Epoch [75/300], Train Loss: 0.005285
Validation Loss: 0.00555017
Epoch [76/300], Train Loss: 0.005270
Validation Loss: 0.00555409
Epoch [77/300], Train Loss: 0.005298
Validation Loss: 0.00565558
Epoch [78/300], Train Loss: 0.005276
Validation Loss: 0.00553527
Epoch [79/300], Train Loss: 0.005265
Validation Loss: 0.00552966
Epoch [80/300], Train Loss: 0.005261
Validation Loss: 0.00553957
Epoch [81/300], Train Loss: 0.005241
Validation Loss: 0.00552465
Epoch [82/300], Train Loss: 0.005237
Validation Loss: 0.00559729
Epoch [83/300], Train Loss: 0.005251
Validation Loss: 0.00551412
Epoch [84/300], Train Loss: 0.005234
Validation Loss: 0.00551393
Epoch [85/300], Train Loss: 0.005240
Validation Loss: 0.00556144
Epoch [86/300], Train Loss: 0.005252
Validation Loss: 0.00550060
Epoch [87/300], Train Loss: 0.005226
Validation Loss: 0.00549473
Epoch [88/300], Train Loss: 0.005223
Validation Loss: 0.00549960
Epoch [89/300], Train Loss: 0.005213
Validation Loss: 0.00549242
Epoch [90/300], Train Loss: 0.005235
Validation Loss: 0.00548995
Epoch [91/300], Train Loss: 0.005215
Validation Loss: 0.00550417
Epoch [92/300], Train Loss: 0.005222
Validation Loss: 0.00548443
Epoch [93/300], Train Loss: 0.005192
Validation Loss: 0.00549797
Epoch [94/300], Train Loss: 0.005217
Validation Loss: 0.00563543
Epoch [95/300], Train Loss: 0.005235
Validation Loss: 0.00552822
Epoch [96/300], Train Loss: 0.005210
Validation Loss: 0.00547172
Epoch [97/300], Train Loss: 0.005196
Validation Loss: 0.00546822
Epoch [98/300], Train Loss: 0.005213
Validation Loss: 0.00547629
Epoch [99/300], Train Loss: 0.005187
Validation Loss: 0.00547226
Epoch [100/300], Train Loss: 0.005211
Validation Loss: 0.00548113
Epoch [101/300], Train Loss: 0.005204
Validation Loss: 0.00549341
Epoch [102/300], Train Loss: 0.005193
Validation Loss: 0.00545854
Epoch [103/300], Train Loss: 0.005203
Validation Loss: 0.00546417
Epoch [104/300], Train Loss: 0.005196
Validation Loss: 0.00546387
Epoch [105/300], Train Loss: 0.005201
Validation Loss: 0.00545716
Epoch [106/300], Train Loss: 0.005198
Validation Loss: 0.00545688
Epoch [107/300], Train Loss: 0.005204
Validation Loss: 0.00545985
Epoch [108/300], Train Loss: 0.005183
Validation Loss: 0.00545683
Epoch [109/300], Train Loss: 0.005179
Validation Loss: 0.00544570
Epoch [110/300], Train Loss: 0.005169
Validation Loss: 0.00545076
Epoch [111/300], Train Loss: 0.005180
Validation Loss: 0.00545654
Epoch [112/300], Train Loss: 0.005189
Validation Loss: 0.00545306
Epoch [113/300], Train Loss: 0.005187
Validation Loss: 0.00544531
Epoch [114/300], Train Loss: 0.005181
Validation Loss: 0.00543105
Epoch [115/300], Train Loss: 0.005166
Validation Loss: 0.00543494
Epoch [116/300], Train Loss: 0.005167
Validation Loss: 0.00542170
Epoch [117/300], Train Loss: 0.005153
Validation Loss: 0.00542188
Epoch [118/300], Train Loss: 0.005175
Validation Loss: 0.00541211
Epoch [119/300], Train Loss: 0.005167
Validation Loss: 0.00541096
Epoch [120/300], Train Loss: 0.005149
Validation Loss: 0.00540711
Epoch [121/300], Train Loss: 0.005141
Validation Loss: 0.00539609
Epoch [122/300], Train Loss: 0.005137
Validation Loss: 0.00541400
Epoch [123/300], Train Loss: 0.005139
Validation Loss: 0.00548470
Epoch [124/300], Train Loss: 0.005161
Validation Loss: 0.00539783
Epoch [125/300], Train Loss: 0.005122
Validation Loss: 0.00543898
Epoch [126/300], Train Loss: 0.005121
Validation Loss: 0.00536649
Epoch [127/300], Train Loss: 0.005119
Validation Loss: 0.00544320
Epoch [128/300], Train Loss: 0.005138
Validation Loss: 0.00540771
Epoch [129/300], Train Loss: 0.005101
Validation Loss: 0.00537133
Epoch [130/300], Train Loss: 0.005109
Validation Loss: 0.00534294
Epoch [131/300], Train Loss: 0.005108
Validation Loss: 0.00538774
Epoch [132/300], Train Loss: 0.005111
Validation Loss: 0.00544272
Epoch [133/300], Train Loss: 0.005137
Validation Loss: 0.00539434
Epoch [134/300], Train Loss: 0.005111
Validation Loss: 0.00540880
Epoch [135/300], Train Loss: 0.005086
Validation Loss: 0.00533991
Epoch [136/300], Train Loss: 0.005057
Validation Loss: 0.00528700
Epoch [137/300], Train Loss: 0.005056
Validation Loss: 0.00528696
Epoch [138/300], Train Loss: 0.005036
Validation Loss: 0.00528739
Epoch [139/300], Train Loss: 0.005018
Validation Loss: 0.00525659
Epoch [140/300], Train Loss: 0.005024
Validation Loss: 0.00522313
Epoch [141/300], Train Loss: 0.005001
Validation Loss: 0.00520087
Epoch [142/300], Train Loss: 0.004997
Validation Loss: 0.00525821
Epoch [143/300], Train Loss: 0.005006
Validation Loss: 0.00517169
Epoch [144/300], Train Loss: 0.004983
Validation Loss: 0.00518632
Epoch [145/300], Train Loss: 0.004928
Validation Loss: 0.00511142
Epoch [146/300], Train Loss: 0.004924
Validation Loss: 0.00509988
Epoch [147/300], Train Loss: 0.004880
Validation Loss: 0.00506259
Epoch [148/300], Train Loss: 0.004871
Validation Loss: 0.00502707
Epoch [149/300], Train Loss: 0.004858
Validation Loss: 0.00501132
Epoch [150/300], Train Loss: 0.004829
Validation Loss: 0.00498585
Epoch [151/300], Train Loss: 0.004810
Validation Loss: 0.00499795
Epoch [152/300], Train Loss: 0.004837
Validation Loss: 0.00499616
Epoch [153/300], Train Loss: 0.004786
Validation Loss: 0.00488649
Epoch [154/300], Train Loss: 0.004804
Validation Loss: 0.00490144
Epoch [155/300], Train Loss: 0.004743
Validation Loss: 0.00496493
Epoch [156/300], Train Loss: 0.004819
Validation Loss: 0.00499539
Epoch [157/300], Train Loss: 0.004780
Validation Loss: 0.00482192
Epoch [158/300], Train Loss: 0.004729
Validation Loss: 0.00480391
Epoch [159/300], Train Loss: 0.004706
Validation Loss: 0.00475547
Epoch [160/300], Train Loss: 0.004671
Validation Loss: 0.00475896
Epoch [161/300], Train Loss: 0.004669
Validation Loss: 0.00471963
Epoch [162/300], Train Loss: 0.004649
Validation Loss: 0.00473397
Epoch [163/300], Train Loss: 0.004665
Validation Loss: 0.00470295
Epoch [164/300], Train Loss: 0.004626
Validation Loss: 0.00468196
Epoch [165/300], Train Loss: 0.004608
Validation Loss: 0.00468206
Epoch [166/300], Train Loss: 0.004614
Validation Loss: 0.00465206
Epoch [167/300], Train Loss: 0.004590
Validation Loss: 0.00463227
Epoch [168/300], Train Loss: 0.004585
Validation Loss: 0.00463915
Epoch [169/300], Train Loss: 0.004577
Validation Loss: 0.00466398
Epoch [170/300], Train Loss: 0.004578
Validation Loss: 0.00475410
Epoch [171/300], Train Loss: 0.004600
Validation Loss: 0.00461222
Epoch [172/300], Train Loss: 0.004635
Validation Loss: 0.00469170
Epoch [173/300], Train Loss: 0.004584
Validation Loss: 0.00472387
Epoch [174/300], Train Loss: 0.004575
Validation Loss: 0.00464223
Epoch [175/300], Train Loss: 0.004594
Validation Loss: 0.00470794
Epoch [176/300], Train Loss: 0.004681
Validation Loss: 0.00470489
Epoch [177/300], Train Loss: 0.004696
Validation Loss: 0.00475536
Epoch [178/300], Train Loss: 0.004624
Validation Loss: 0.00459951
Epoch [179/300], Train Loss: 0.004561
Validation Loss: 0.00458639
Epoch [180/300], Train Loss: 0.004543
Validation Loss: 0.00459783
Epoch [181/300], Train Loss: 0.004553
Validation Loss: 0.00460647
Epoch [182/300], Train Loss: 0.004542
Validation Loss: 0.00459743
Epoch [183/300], Train Loss: 0.004539
Validation Loss: 0.00459486
Epoch [184/300], Train Loss: 0.004548
Validation Loss: 0.00462746
Epoch [185/300], Train Loss: 0.004526
Validation Loss: 0.00458002
Epoch [186/300], Train Loss: 0.004528
Validation Loss: 0.00463374
Epoch [187/300], Train Loss: 0.004540
Validation Loss: 0.00457946
Epoch [188/300], Train Loss: 0.004551
Validation Loss: 0.00461280
Epoch [189/300], Train Loss: 0.004531
Validation Loss: 0.00456687
Epoch [190/300], Train Loss: 0.004534
Validation Loss: 0.00456884
Epoch [191/300], Train Loss: 0.004522
Validation Loss: 0.00460035
Epoch [192/300], Train Loss: 0.004551
Validation Loss: 0.00460821
Epoch [193/300], Train Loss: 0.004546
Validation Loss: 0.00457249
Epoch [194/300], Train Loss: 0.004581
Validation Loss: 0.00460287
Epoch [195/300], Train Loss: 0.004542
Validation Loss: 0.00471655
Epoch [196/300], Train Loss: 0.004546
Validation Loss: 0.00459059
Epoch [197/300], Train Loss: 0.004531
Validation Loss: 0.00456741
Epoch [198/300], Train Loss: 0.004516
Validation Loss: 0.00456389
Epoch [199/300], Train Loss: 0.004513
Validation Loss: 0.00463289
Epoch [200/300], Train Loss: 0.004517
Validation Loss: 0.00455972
Epoch [201/300], Train Loss: 0.004525
Validation Loss: 0.00456099
Epoch [202/300], Train Loss: 0.004515
Validation Loss: 0.00456381
Epoch [203/300], Train Loss: 0.004508
Validation Loss: 0.00454951
Epoch [204/300], Train Loss: 0.004532
Validation Loss: 0.00457264
Epoch [205/300], Train Loss: 0.004515
Validation Loss: 0.00479214
Epoch [206/300], Train Loss: 0.004552
Validation Loss: 0.00458939
Epoch [207/300], Train Loss: 0.004580
Validation Loss: 0.00456450
Epoch [208/300], Train Loss: 0.004495
Validation Loss: 0.00455509
Epoch [209/300], Train Loss: 0.004502
Validation Loss: 0.00454527
Epoch [210/300], Train Loss: 0.004501
Validation Loss: 0.00455147
Epoch [211/300], Train Loss: 0.004505
Validation Loss: 0.00456888
Epoch [212/300], Train Loss: 0.004514
Validation Loss: 0.00454690
Epoch [213/300], Train Loss: 0.004494
Validation Loss: 0.00455318
Epoch [214/300], Train Loss: 0.004489
Validation Loss: 0.00455431
Epoch [215/300], Train Loss: 0.004492
Validation Loss: 0.00459450
Epoch [216/300], Train Loss: 0.004503
Validation Loss: 0.00453653
Epoch [217/300], Train Loss: 0.004504
Validation Loss: 0.00454512
Epoch [218/300], Train Loss: 0.004508
Validation Loss: 0.00454631
Epoch [219/300], Train Loss: 0.004504
Validation Loss: 0.00456552
Epoch [220/300], Train Loss: 0.004512
Validation Loss: 0.00455662
Epoch [221/300], Train Loss: 0.004499
Validation Loss: 0.00456850
Epoch [222/300], Train Loss: 0.004528
Validation Loss: 0.00461486
Epoch [223/300], Train Loss: 0.004488
Validation Loss: 0.00455868
Epoch [224/300], Train Loss: 0.004487
Validation Loss: 0.00453568
Epoch [225/300], Train Loss: 0.004503
Validation Loss: 0.00454084
Epoch [226/300], Train Loss: 0.004485
Validation Loss: 0.00453613
Epoch [227/300], Train Loss: 0.004502
Validation Loss: 0.00474186
Epoch [228/300], Train Loss: 0.004540
Validation Loss: 0.00454544
Epoch [229/300], Train Loss: 0.004488
Validation Loss: 0.00455051
Epoch [230/300], Train Loss: 0.004489
Validation Loss: 0.00464858
Epoch [231/300], Train Loss: 0.004514
Validation Loss: 0.00454839
Epoch [232/300], Train Loss: 0.004473
Validation Loss: 0.00454274
Epoch [233/300], Train Loss: 0.004485
Validation Loss: 0.00453242
Epoch [234/300], Train Loss: 0.004499
Validation Loss: 0.00459188
Epoch [235/300], Train Loss: 0.004489
Validation Loss: 0.00454404
Epoch [236/300], Train Loss: 0.004483
Validation Loss: 0.00456433
Epoch [237/300], Train Loss: 0.004518
Validation Loss: 0.00453011
Epoch [238/300], Train Loss: 0.004486
Validation Loss: 0.00453102
Epoch [239/300], Train Loss: 0.004491
Validation Loss: 0.00463705
Epoch [240/300], Train Loss: 0.004542
Validation Loss: 0.00452916
Epoch [241/300], Train Loss: 0.004501
Validation Loss: 0.00453798
Epoch [242/300], Train Loss: 0.004492
Validation Loss: 0.00457995
Epoch [243/300], Train Loss: 0.004471
Validation Loss: 0.00452521
Epoch [244/300], Train Loss: 0.004472
Validation Loss: 0.00454076
Epoch [245/300], Train Loss: 0.004480
Validation Loss: 0.00455088
Epoch [246/300], Train Loss: 0.004473
Validation Loss: 0.00457966
Epoch [247/300], Train Loss: 0.004481
Validation Loss: 0.00454061
Epoch [248/300], Train Loss: 0.004490
Validation Loss: 0.00458656
Epoch [249/300], Train Loss: 0.004526
Validation Loss: 0.00454298
Epoch [250/300], Train Loss: 0.004494
Validation Loss: 0.00454865
Epoch [251/300], Train Loss: 0.004499
Validation Loss: 0.00458318
Epoch [252/300], Train Loss: 0.004502
Validation Loss: 0.00467015
Epoch [253/300], Train Loss: 0.004513
Validation Loss: 0.00457465
Early stopping triggered

Evaluating model for: Router
Run 54/72 completed in 1023.76 seconds with: {'MAE': np.float32(0.19103217), 'MSE': np.float32(0.058668498), 'RMSE': np.float32(0.24221581), 'SAE': np.float32(0.0007525703), 'NDE': np.float32(0.012104)}

Run 55/72: hidden=512, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Router
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.048309
Validation Loss: 0.01676725
Epoch [2/300], Train Loss: 0.009091
Validation Loss: 0.00843682
Epoch [3/300], Train Loss: 0.007401
Validation Loss: 0.00750521
Epoch [4/300], Train Loss: 0.007092
Validation Loss: 0.00732998
Epoch [5/300], Train Loss: 0.006959
Validation Loss: 0.00721684
Epoch [6/300], Train Loss: 0.006861
Validation Loss: 0.00711380
Epoch [7/300], Train Loss: 0.006761
Validation Loss: 0.00700608
Epoch [8/300], Train Loss: 0.006649
Validation Loss: 0.00693177
Epoch [9/300], Train Loss: 0.006562
Validation Loss: 0.00683424
Epoch [10/300], Train Loss: 0.006468
Validation Loss: 0.00672830
Epoch [11/300], Train Loss: 0.006404
Validation Loss: 0.00664458
Epoch [12/300], Train Loss: 0.006371
Validation Loss: 0.00660133
Epoch [13/300], Train Loss: 0.006273
Validation Loss: 0.00652288
Epoch [14/300], Train Loss: 0.006190
Validation Loss: 0.00646716
Epoch [15/300], Train Loss: 0.006193
Validation Loss: 0.00652020
Epoch [16/300], Train Loss: 0.006132
Validation Loss: 0.00637952
Epoch [17/300], Train Loss: 0.006061
Validation Loss: 0.00634688
Epoch [18/300], Train Loss: 0.006027
Validation Loss: 0.00635964
Epoch [19/300], Train Loss: 0.006011
Validation Loss: 0.00626101
Epoch [20/300], Train Loss: 0.005980
Validation Loss: 0.00623164
Epoch [21/300], Train Loss: 0.005918
Validation Loss: 0.00623783
Epoch [22/300], Train Loss: 0.005917
Validation Loss: 0.00618146
Epoch [23/300], Train Loss: 0.005875
Validation Loss: 0.00615009
Epoch [24/300], Train Loss: 0.005879
Validation Loss: 0.00617064
Epoch [25/300], Train Loss: 0.005845
Validation Loss: 0.00609180
Epoch [26/300], Train Loss: 0.005805
Validation Loss: 0.00606749
Epoch [27/300], Train Loss: 0.005791
Validation Loss: 0.00607583
Epoch [28/300], Train Loss: 0.005803
Validation Loss: 0.00611825
Epoch [29/300], Train Loss: 0.005754
Validation Loss: 0.00599969
Epoch [30/300], Train Loss: 0.005701
Validation Loss: 0.00597654
Epoch [31/300], Train Loss: 0.005703
Validation Loss: 0.00596800
Epoch [32/300], Train Loss: 0.005677
Validation Loss: 0.00593810
Epoch [33/300], Train Loss: 0.005654
Validation Loss: 0.00591993
Epoch [34/300], Train Loss: 0.005629
Validation Loss: 0.00590653
Epoch [35/300], Train Loss: 0.005609
Validation Loss: 0.00588983
Epoch [36/300], Train Loss: 0.005594
Validation Loss: 0.00589125
Epoch [37/300], Train Loss: 0.005573
Validation Loss: 0.00584790
Epoch [38/300], Train Loss: 0.005649
Validation Loss: 0.00594017
Epoch [39/300], Train Loss: 0.005597
Validation Loss: 0.00584740
Epoch [40/300], Train Loss: 0.005544
Validation Loss: 0.00588189
Epoch [41/300], Train Loss: 0.005540
Validation Loss: 0.00578818
Epoch [42/300], Train Loss: 0.005500
Validation Loss: 0.00576122
Epoch [43/300], Train Loss: 0.005510
Validation Loss: 0.00577640
Epoch [44/300], Train Loss: 0.005481
Validation Loss: 0.00572659
Epoch [45/300], Train Loss: 0.005473
Validation Loss: 0.00569843
Epoch [46/300], Train Loss: 0.005434
Validation Loss: 0.00570488
Epoch [47/300], Train Loss: 0.005445
Validation Loss: 0.00570853
Epoch [48/300], Train Loss: 0.005433
Validation Loss: 0.00578012
Epoch [49/300], Train Loss: 0.005440
Validation Loss: 0.00566814
Epoch [50/300], Train Loss: 0.005423
Validation Loss: 0.00574903
Epoch [51/300], Train Loss: 0.005408
Validation Loss: 0.00563606
Epoch [52/300], Train Loss: 0.005404
Validation Loss: 0.00568304
Epoch [53/300], Train Loss: 0.005396
Validation Loss: 0.00565914
Epoch [54/300], Train Loss: 0.005373
Validation Loss: 0.00563779
Epoch [55/300], Train Loss: 0.005377
Validation Loss: 0.00561542
Epoch [56/300], Train Loss: 0.005365
Validation Loss: 0.00559642
Epoch [57/300], Train Loss: 0.005343
Validation Loss: 0.00560608
Epoch [58/300], Train Loss: 0.005304
Validation Loss: 0.00555385
Epoch [59/300], Train Loss: 0.005300
Validation Loss: 0.00552878
Epoch [60/300], Train Loss: 0.005316
Validation Loss: 0.00550625
Epoch [61/300], Train Loss: 0.005241
Validation Loss: 0.00546224
Epoch [62/300], Train Loss: 0.005233
Validation Loss: 0.00547480
Epoch [63/300], Train Loss: 0.005211
Validation Loss: 0.00542744
Epoch [64/300], Train Loss: 0.005192
Validation Loss: 0.00543996
Epoch [65/300], Train Loss: 0.005229
Validation Loss: 0.00538593
Epoch [66/300], Train Loss: 0.005140
Validation Loss: 0.00650082
Epoch [67/300], Train Loss: 0.005410
Validation Loss: 0.00562299
Epoch [68/300], Train Loss: 0.005340
Validation Loss: 0.00560988
Epoch [69/300], Train Loss: 0.005280
Validation Loss: 0.00553714
Epoch [70/300], Train Loss: 0.005256
Validation Loss: 0.00552122
Epoch [71/300], Train Loss: 0.005241
Validation Loss: 0.00549651
Epoch [72/300], Train Loss: 0.005252
Validation Loss: 0.00548476
Epoch [73/300], Train Loss: 0.005242
Validation Loss: 0.00546444
Epoch [74/300], Train Loss: 0.005190
Validation Loss: 0.00549525
Epoch [75/300], Train Loss: 0.005195
Validation Loss: 0.00542959
Early stopping triggered

Evaluating model for: Router
Run 55/72 completed in 334.24 seconds with: {'MAE': np.float32(0.19988017), 'MSE': np.float32(0.06762391), 'RMSE': np.float32(0.26004598), 'SAE': np.float32(0.0005090269), 'NDE': np.float32(0.012995009)}

Run 56/72: hidden=512, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Router
Dataset length: 3299 windows

Epoch [1/300], Train Loss: 0.058330
Validation Loss: 0.01151839
Epoch [2/300], Train Loss: 0.009550
Validation Loss: 0.00848459
Epoch [3/300], Train Loss: 0.007975
Validation Loss: 0.00804847
Epoch [4/300], Train Loss: 0.007676
Validation Loss: 0.00789542
Epoch [5/300], Train Loss: 0.007506
Validation Loss: 0.00775540
Epoch [6/300], Train Loss: 0.007382
Validation Loss: 0.00761865
Epoch [7/300], Train Loss: 0.007231
Validation Loss: 0.00747230
Epoch [8/300], Train Loss: 0.007094
Validation Loss: 0.00735968
Epoch [9/300], Train Loss: 0.006968
Validation Loss: 0.00723852
Epoch [10/300], Train Loss: 0.006853
Validation Loss: 0.00709748
Epoch [11/300], Train Loss: 0.006770
Validation Loss: 0.00701436
Epoch [12/300], Train Loss: 0.006753
Validation Loss: 0.00697649
Epoch [13/300], Train Loss: 0.006631
Validation Loss: 0.00688442
Epoch [14/300], Train Loss: 0.006521
Validation Loss: 0.00680058
Epoch [15/300], Train Loss: 0.006511
Validation Loss: 0.00679020
Epoch [16/300], Train Loss: 0.006451
Validation Loss: 0.00667901
Epoch [17/300], Train Loss: 0.006348
Validation Loss: 0.00660675
Epoch [18/300], Train Loss: 0.006298
Validation Loss: 0.00661183
Epoch [19/300], Train Loss: 0.006265
Validation Loss: 0.00652922
Epoch [20/300], Train Loss: 0.006219
Validation Loss: 0.00646482
Epoch [21/300], Train Loss: 0.006148
Validation Loss: 0.00645354
Epoch [22/300], Train Loss: 0.006142
Validation Loss: 0.00638664
Epoch [23/300], Train Loss: 0.006089
Validation Loss: 0.00633925
Epoch [24/300], Train Loss: 0.006082
Validation Loss: 0.00632397
Epoch [25/300], Train Loss: 0.006037
Validation Loss: 0.00627494
Epoch [26/300], Train Loss: 0.005999
Validation Loss: 0.00623314
Epoch [27/300], Train Loss: 0.005952
Validation Loss: 0.00625363
Epoch [28/300], Train Loss: 0.005958
Validation Loss: 0.00619557
Epoch [29/300], Train Loss: 0.005891
Validation Loss: 0.00610441
Epoch [30/300], Train Loss: 0.005854
Validation Loss: 0.00612535
Epoch [31/300], Train Loss: 0.005849
Validation Loss: 0.00608383
Epoch [32/300], Train Loss: 0.005808
Validation Loss: 0.00603179
Epoch [33/300], Train Loss: 0.005768
Validation Loss: 0.00600485
Epoch [34/300], Train Loss: 0.005726
Validation Loss: 0.00595469
Epoch [35/300], Train Loss: 0.005709
Validation Loss: 0.00591518
Epoch [36/300], Train Loss: 0.005661
Validation Loss: 0.00590603
Epoch [37/300], Train Loss: 0.005633
Validation Loss: 0.00584843
Epoch [38/300], Train Loss: 0.005752
Validation Loss: 0.00588822
Epoch [39/300], Train Loss: 0.005655
Validation Loss: 0.00580993
Epoch [40/300], Train Loss: 0.005551
Validation Loss: 0.00574908
Epoch [41/300], Train Loss: 0.005536
Validation Loss: 0.00581523
Epoch [42/300], Train Loss: 0.005490
Validation Loss: 0.00564569
Epoch [43/300], Train Loss: 0.005468
Validation Loss: 0.00566077
Epoch [44/300], Train Loss: 0.005397
Validation Loss: 0.00548058
Epoch [45/300], Train Loss: 0.005355
Validation Loss: 0.00542152
Epoch [46/300], Train Loss: 0.005277
Validation Loss: 0.00545698
Epoch [47/300], Train Loss: 0.005367
Validation Loss: 0.00532632
Epoch [48/300], Train Loss: 0.005171
Validation Loss: 0.00535076
Epoch [49/300], Train Loss: 0.005193
Validation Loss: 0.00553854
Epoch [50/300], Train Loss: 0.005167
Validation Loss: 0.00523552
Epoch [51/300], Train Loss: 0.005133
Validation Loss: 0.00521510
Epoch [52/300], Train Loss: 0.005076
Validation Loss: 0.00522208
Epoch [53/300], Train Loss: 0.005047
Validation Loss: 0.00525041
Epoch [54/300], Train Loss: 0.004976
Validation Loss: 0.00510958
Epoch [55/300], Train Loss: 0.004938
Validation Loss: 0.00500968
Epoch [56/300], Train Loss: 0.004945
Validation Loss: 0.00509162
Epoch [57/300], Train Loss: 0.004980
Validation Loss: 0.00492681
Epoch [58/300], Train Loss: 0.004928
Validation Loss: 0.00503770
Epoch [59/300], Train Loss: 0.004945
Validation Loss: 0.00491588
Epoch [60/300], Train Loss: 0.004855
Validation Loss: 0.00493965
Epoch [61/300], Train Loss: 0.004827
Validation Loss: 0.00488906
Epoch [62/300], Train Loss: 0.004862
Validation Loss: 0.00499703
Epoch [63/300], Train Loss: 0.004797
Validation Loss: 0.00502118
Epoch [64/300], Train Loss: 0.004810
Validation Loss: 0.00481803
Epoch [65/300], Train Loss: 0.004915
Validation Loss: 0.00513859
Epoch [66/300], Train Loss: 0.004796
Validation Loss: 0.00521440
Epoch [67/300], Train Loss: 0.004827
Validation Loss: 0.00476838
Epoch [68/300], Train Loss: 0.004867
Validation Loss: 0.00510074
Epoch [69/300], Train Loss: 0.004748
Validation Loss: 0.00474845
Epoch [70/300], Train Loss: 0.004721
Validation Loss: 0.00473414
Epoch [71/300], Train Loss: 0.004684
Validation Loss: 0.00474247
Epoch [72/300], Train Loss: 0.004696
Validation Loss: 0.00473258
Epoch [73/300], Train Loss: 0.004712
Validation Loss: 0.00493066
Epoch [74/300], Train Loss: 0.004702
Validation Loss: 0.00472732
Epoch [75/300], Train Loss: 0.004676
Validation Loss: 0.00473278
Epoch [76/300], Train Loss: 0.004633
Validation Loss: 0.00466869
Epoch [77/300], Train Loss: 0.004626
Validation Loss: 0.00481042
Epoch [78/300], Train Loss: 0.004717
Validation Loss: 0.00467155
Epoch [79/300], Train Loss: 0.004615
Validation Loss: 0.00465808
Epoch [80/300], Train Loss: 0.004622
Validation Loss: 0.00465456
Epoch [81/300], Train Loss: 0.004615
Validation Loss: 0.00468101
Epoch [82/300], Train Loss: 0.004590
Validation Loss: 0.00467328
Epoch [83/300], Train Loss: 0.004580
Validation Loss: 0.00463161
Epoch [84/300], Train Loss: 0.004571
Validation Loss: 0.00465979
Epoch [85/300], Train Loss: 0.004601
Validation Loss: 0.00463041
Epoch [86/300], Train Loss: 0.004606
Validation Loss: 0.00462192
Epoch [87/300], Train Loss: 0.004552
Validation Loss: 0.00462474
Epoch [88/300], Train Loss: 0.004556
Validation Loss: 0.00461863
Epoch [89/300], Train Loss: 0.004586
Validation Loss: 0.00461621
Epoch [90/300], Train Loss: 0.004573
Validation Loss: 0.00458468
Epoch [91/300], Train Loss: 0.004548
Validation Loss: 0.00463236
Epoch [92/300], Train Loss: 0.004574
Validation Loss: 0.00473119
Epoch [93/300], Train Loss: 0.004554
Validation Loss: 0.00458969
Epoch [94/300], Train Loss: 0.004539
Validation Loss: 0.00459524
Epoch [95/300], Train Loss: 0.004536
Validation Loss: 0.00463960
Epoch [96/300], Train Loss: 0.004538
Validation Loss: 0.00458825
Epoch [97/300], Train Loss: 0.004586
Validation Loss: 0.00462997
Epoch [98/300], Train Loss: 0.004530
Validation Loss: 0.00459783
Epoch [99/300], Train Loss: 0.004538
Validation Loss: 0.00457987
Epoch [100/300], Train Loss: 0.004559
Validation Loss: 0.00459892
Epoch [101/300], Train Loss: 0.004527
Validation Loss: 0.00464156
Epoch [102/300], Train Loss: 0.004535
Validation Loss: 0.00461523
Epoch [103/300], Train Loss: 0.004543
Validation Loss: 0.00467790
Epoch [104/300], Train Loss: 0.004517
Validation Loss: 0.00457913
Epoch [105/300], Train Loss: 0.004506
Validation Loss: 0.00466760
Epoch [106/300], Train Loss: 0.004573
Validation Loss: 0.00462599
Epoch [107/300], Train Loss: 0.004586
Validation Loss: 0.00456696
Epoch [108/300], Train Loss: 0.004531
Validation Loss: 0.00460282
Epoch [109/300], Train Loss: 0.004521
Validation Loss: 0.00469804
Epoch [110/300], Train Loss: 0.004533
Validation Loss: 0.00465084
Epoch [111/300], Train Loss: 0.004520
Validation Loss: 0.00456658
Epoch [112/300], Train Loss: 0.004501
Validation Loss: 0.00456678
Epoch [113/300], Train Loss: 0.004512
Validation Loss: 0.00460777
Epoch [114/300], Train Loss: 0.004548
Validation Loss: 0.00455700
Epoch [115/300], Train Loss: 0.004592
Validation Loss: 0.00459339
Epoch [116/300], Train Loss: 0.004495
Validation Loss: 0.00455378
Epoch [117/300], Train Loss: 0.004507
Validation Loss: 0.00462928
Epoch [118/300], Train Loss: 0.004523
Validation Loss: 0.00473888
Epoch [119/300], Train Loss: 0.004512
Validation Loss: 0.00462536
Epoch [120/300], Train Loss: 0.004486
Validation Loss: 0.00460910
Epoch [121/300], Train Loss: 0.004481
Validation Loss: 0.00454249
Epoch [122/300], Train Loss: 0.004503
Validation Loss: 0.00465996
Epoch [123/300], Train Loss: 0.004519
Validation Loss: 0.00457498
Epoch [124/300], Train Loss: 0.004479
Validation Loss: 0.00458175
Epoch [125/300], Train Loss: 0.004475
Validation Loss: 0.00464992
Epoch [126/300], Train Loss: 0.004537
Validation Loss: 0.00456084
Epoch [127/300], Train Loss: 0.004524
Validation Loss: 0.00457490
Epoch [128/300], Train Loss: 0.004484
Validation Loss: 0.00453303
Epoch [129/300], Train Loss: 0.004461
Validation Loss: 0.00455398
Epoch [130/300], Train Loss: 0.004471
Validation Loss: 0.00452970
Epoch [131/300], Train Loss: 0.004516
Validation Loss: 0.00453314
Epoch [132/300], Train Loss: 0.004476
Validation Loss: 0.00458179
Epoch [133/300], Train Loss: 0.004474
Validation Loss: 0.00458628
Epoch [134/300], Train Loss: 0.004487
Validation Loss: 0.00460311
Epoch [135/300], Train Loss: 0.004492
Validation Loss: 0.00452619
Epoch [136/300], Train Loss: 0.004470
Validation Loss: 0.00454292
Epoch [137/300], Train Loss: 0.004480
Validation Loss: 0.00456887
Epoch [138/300], Train Loss: 0.004461
Validation Loss: 0.00455179
Epoch [139/300], Train Loss: 0.004457
Validation Loss: 0.00454172
Epoch [140/300], Train Loss: 0.004473
Validation Loss: 0.00455487
Epoch [141/300], Train Loss: 0.004511
Validation Loss: 0.00473170
Epoch [142/300], Train Loss: 0.004499
Validation Loss: 0.00460857
Epoch [143/300], Train Loss: 0.004465
Validation Loss: 0.00452562
Epoch [144/300], Train Loss: 0.004475
Validation Loss: 0.00453927
Epoch [145/300], Train Loss: 0.004449
Validation Loss: 0.00459637
Epoch [146/300], Train Loss: 0.004488
Validation Loss: 0.00452898
Epoch [147/300], Train Loss: 0.004456
Validation Loss: 0.00453876
Epoch [148/300], Train Loss: 0.004448
Validation Loss: 0.00452486
Epoch [149/300], Train Loss: 0.004451
Validation Loss: 0.00451037
Epoch [150/300], Train Loss: 0.004505
Validation Loss: 0.00459438
Epoch [151/300], Train Loss: 0.004469
Validation Loss: 0.00451384
Epoch [152/300], Train Loss: 0.004442
Validation Loss: 0.00451338
Epoch [153/300], Train Loss: 0.004454
Validation Loss: 0.00451407
Epoch [154/300], Train Loss: 0.004466
Validation Loss: 0.00450980
Epoch [155/300], Train Loss: 0.004436
Validation Loss: 0.00451763
Epoch [156/300], Train Loss: 0.004457
Validation Loss: 0.00454349
Epoch [157/300], Train Loss: 0.004466
Validation Loss: 0.00450765
Epoch [158/300], Train Loss: 0.004448
Validation Loss: 0.00452780
Epoch [159/300], Train Loss: 0.004437
Validation Loss: 0.00451795
Epoch [160/300], Train Loss: 0.004460
Validation Loss: 0.00456896
Epoch [161/300], Train Loss: 0.004436
Validation Loss: 0.00450251
Epoch [162/300], Train Loss: 0.004448
Validation Loss: 0.00455751
Epoch [163/300], Train Loss: 0.004438
Validation Loss: 0.00450670
Epoch [164/300], Train Loss: 0.004436
Validation Loss: 0.00452775
Epoch [165/300], Train Loss: 0.004426
Validation Loss: 0.00453557
Epoch [166/300], Train Loss: 0.004455
Validation Loss: 0.00450826
Epoch [167/300], Train Loss: 0.004422
Validation Loss: 0.00453354
Epoch [168/300], Train Loss: 0.004424
Validation Loss: 0.00451319
Epoch [169/300], Train Loss: 0.004438
Validation Loss: 0.00479250
Epoch [170/300], Train Loss: 0.004557
Validation Loss: 0.00463181
Epoch [171/300], Train Loss: 0.004532
Validation Loss: 0.00449539
Epoch [172/300], Train Loss: 0.004447
Validation Loss: 0.00449856
Epoch [173/300], Train Loss: 0.004424
Validation Loss: 0.00458400
Epoch [174/300], Train Loss: 0.004436
Validation Loss: 0.00457070
Epoch [175/300], Train Loss: 0.004487
Validation Loss: 0.00457344
Epoch [176/300], Train Loss: 0.004482
Validation Loss: 0.00461306
Epoch [177/300], Train Loss: 0.004444
Validation Loss: 0.00452726
Epoch [178/300], Train Loss: 0.004422
Validation Loss: 0.00449402
Epoch [179/300], Train Loss: 0.004451
Validation Loss: 0.00453799
Epoch [180/300], Train Loss: 0.004428
Validation Loss: 0.00449523
Epoch [181/300], Train Loss: 0.004416
Validation Loss: 0.00448953
Epoch [182/300], Train Loss: 0.004418
Validation Loss: 0.00449865
Epoch [183/300], Train Loss: 0.004429
Validation Loss: 0.00450366
Epoch [184/300], Train Loss: 0.004434
Validation Loss: 0.00455386
Epoch [185/300], Train Loss: 0.004415
Validation Loss: 0.00450179
Epoch [186/300], Train Loss: 0.004408
Validation Loss: 0.00459506
Epoch [187/300], Train Loss: 0.004447
Validation Loss: 0.00451666
Epoch [188/300], Train Loss: 0.004449
Validation Loss: 0.00453378
Epoch [189/300], Train Loss: 0.004419
Validation Loss: 0.00448759
Epoch [190/300], Train Loss: 0.004443
Validation Loss: 0.00449687
Epoch [191/300], Train Loss: 0.004407
Validation Loss: 0.00453519
Epoch [192/300], Train Loss: 0.004439
Validation Loss: 0.00454241
Epoch [193/300], Train Loss: 0.004441
Validation Loss: 0.00450410
Epoch [194/300], Train Loss: 0.004490
Validation Loss: 0.00451919
Epoch [195/300], Train Loss: 0.004434
Validation Loss: 0.00462792
Epoch [196/300], Train Loss: 0.004439
Validation Loss: 0.00447620
Epoch [197/300], Train Loss: 0.004417
Validation Loss: 0.00447898
Epoch [198/300], Train Loss: 0.004397
Validation Loss: 0.00447429
Epoch [199/300], Train Loss: 0.004395
Validation Loss: 0.00459509
Epoch [200/300], Train Loss: 0.004408
Validation Loss: 0.00449091
Epoch [201/300], Train Loss: 0.004417
Validation Loss: 0.00447615
Epoch [202/300], Train Loss: 0.004406
Validation Loss: 0.00447791
Epoch [203/300], Train Loss: 0.004400
Validation Loss: 0.00446913
Epoch [204/300], Train Loss: 0.004454
Validation Loss: 0.00448352
Epoch [205/300], Train Loss: 0.004404
Validation Loss: 0.00467939
Epoch [206/300], Train Loss: 0.004416
Validation Loss: 0.00457249
Epoch [207/300], Train Loss: 0.004467
Validation Loss: 0.00453898
Epoch [208/300], Train Loss: 0.004396
Validation Loss: 0.00449122
Epoch [209/300], Train Loss: 0.004394
Validation Loss: 0.00446263
Epoch [210/300], Train Loss: 0.004407
Validation Loss: 0.00447481
Epoch [211/300], Train Loss: 0.004392
Validation Loss: 0.00449340
Epoch [212/300], Train Loss: 0.004390
Validation Loss: 0.00452111
Epoch [213/300], Train Loss: 0.004402
Validation Loss: 0.00449708
Epoch [214/300], Train Loss: 0.004381
Validation Loss: 0.00447206
Epoch [215/300], Train Loss: 0.004377
Validation Loss: 0.00448972
Epoch [216/300], Train Loss: 0.004407
Validation Loss: 0.00448633
Epoch [217/300], Train Loss: 0.004404
Validation Loss: 0.00449650
Epoch [218/300], Train Loss: 0.004446
Validation Loss: 0.00447517
Epoch [219/300], Train Loss: 0.004393
Validation Loss: 0.00446500
Early stopping triggered

Evaluating model for: Router
Run 56/72 completed in 1154.41 seconds with: {'MAE': np.float32(0.18607113), 'MSE': np.float32(0.0576718), 'RMSE': np.float32(0.24014954), 'SAE': np.float32(0.00052090135), 'NDE': np.float32(0.012000744)}

Run 57/72: hidden=512, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Router
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.067387
Validation Loss: 0.04473112
Epoch [2/300], Train Loss: 0.020047
Validation Loss: 0.00698957
Epoch [3/300], Train Loss: 0.007342
Validation Loss: 0.00628554
Epoch [4/300], Train Loss: 0.006187
Validation Loss: 0.00587232
Epoch [5/300], Train Loss: 0.006052
Validation Loss: 0.00578261
Epoch [6/300], Train Loss: 0.005986
Validation Loss: 0.00585571
Epoch [7/300], Train Loss: 0.005949
Validation Loss: 0.00577440
Epoch [8/300], Train Loss: 0.005918
Validation Loss: 0.00585924
Epoch [9/300], Train Loss: 0.005927
Validation Loss: 0.00576545
Epoch [10/300], Train Loss: 0.005909
Validation Loss: 0.00577739
Epoch [11/300], Train Loss: 0.005897
Validation Loss: 0.00576629
Epoch [12/300], Train Loss: 0.005890
Validation Loss: 0.00575819
Epoch [13/300], Train Loss: 0.005888
Validation Loss: 0.00573924
Epoch [14/300], Train Loss: 0.005887
Validation Loss: 0.00573837
Epoch [15/300], Train Loss: 0.005867
Validation Loss: 0.00572759
Epoch [16/300], Train Loss: 0.005872
Validation Loss: 0.00571770
Epoch [17/300], Train Loss: 0.005898
Validation Loss: 0.00571686
Epoch [18/300], Train Loss: 0.005840
Validation Loss: 0.00568787
Epoch [19/300], Train Loss: 0.005862
Validation Loss: 0.00567784
Epoch [20/300], Train Loss: 0.005865
Validation Loss: 0.00567589
Epoch [21/300], Train Loss: 0.005815
Validation Loss: 0.00566382
Epoch [22/300], Train Loss: 0.005806
Validation Loss: 0.00578800
Epoch [23/300], Train Loss: 0.005817
Validation Loss: 0.00565754
Epoch [24/300], Train Loss: 0.005797
Validation Loss: 0.00562989
Epoch [25/300], Train Loss: 0.005777
Validation Loss: 0.00565301
Epoch [26/300], Train Loss: 0.005784
Validation Loss: 0.00564892
Epoch [27/300], Train Loss: 0.005772
Validation Loss: 0.00565521
Epoch [28/300], Train Loss: 0.005721
Validation Loss: 0.00561354
Epoch [29/300], Train Loss: 0.005747
Validation Loss: 0.00559169
Epoch [30/300], Train Loss: 0.005762
Validation Loss: 0.00558450
Epoch [31/300], Train Loss: 0.005743
Validation Loss: 0.00562755
Epoch [32/300], Train Loss: 0.005701
Validation Loss: 0.00556442
Epoch [33/300], Train Loss: 0.005706
Validation Loss: 0.00555929
Epoch [34/300], Train Loss: 0.005698
Validation Loss: 0.00564796
Epoch [35/300], Train Loss: 0.005721
Validation Loss: 0.00560676
Epoch [36/300], Train Loss: 0.005687
Validation Loss: 0.00557717
Epoch [37/300], Train Loss: 0.005748
Validation Loss: 0.00553760
Epoch [38/300], Train Loss: 0.005691
Validation Loss: 0.00551756
Epoch [39/300], Train Loss: 0.005675
Validation Loss: 0.00551027
Epoch [40/300], Train Loss: 0.005693
Validation Loss: 0.00554656
Epoch [41/300], Train Loss: 0.005682
Validation Loss: 0.00554317
Epoch [42/300], Train Loss: 0.005653
Validation Loss: 0.00550880
Epoch [43/300], Train Loss: 0.005657
Validation Loss: 0.00548927
Epoch [44/300], Train Loss: 0.005703
Validation Loss: 0.00547692
Epoch [45/300], Train Loss: 0.005660
Validation Loss: 0.00547670
Epoch [46/300], Train Loss: 0.005623
Validation Loss: 0.00551277
Epoch [47/300], Train Loss: 0.005603
Validation Loss: 0.00552638
Epoch [48/300], Train Loss: 0.005622
Validation Loss: 0.00555948
Epoch [49/300], Train Loss: 0.005596
Validation Loss: 0.00546834
Epoch [50/300], Train Loss: 0.005592
Validation Loss: 0.00545649
Epoch [51/300], Train Loss: 0.005583
Validation Loss: 0.00558539
Epoch [52/300], Train Loss: 0.005611
Validation Loss: 0.00545814
Epoch [53/300], Train Loss: 0.005608
Validation Loss: 0.00546946
Epoch [54/300], Train Loss: 0.005601
Validation Loss: 0.00557159
Epoch [55/300], Train Loss: 0.005628
Validation Loss: 0.00549559
Epoch [56/300], Train Loss: 0.005567
Validation Loss: 0.00543351
Epoch [57/300], Train Loss: 0.005598
Validation Loss: 0.00542917
Epoch [58/300], Train Loss: 0.005617
Validation Loss: 0.00541753
Epoch [59/300], Train Loss: 0.005577
Validation Loss: 0.00545890
Epoch [60/300], Train Loss: 0.005576
Validation Loss: 0.00540716
Epoch [61/300], Train Loss: 0.005566
Validation Loss: 0.00542788
Epoch [62/300], Train Loss: 0.005558
Validation Loss: 0.00544811
Epoch [63/300], Train Loss: 0.005549
Validation Loss: 0.00544626
Epoch [64/300], Train Loss: 0.005544
Validation Loss: 0.00541316
Epoch [65/300], Train Loss: 0.005548
Validation Loss: 0.00539112
Epoch [66/300], Train Loss: 0.005543
Validation Loss: 0.00539293
Epoch [67/300], Train Loss: 0.005572
Validation Loss: 0.00543901
Epoch [68/300], Train Loss: 0.005570
Validation Loss: 0.00540241
Epoch [69/300], Train Loss: 0.005574
Validation Loss: 0.00538786
Epoch [70/300], Train Loss: 0.005546
Validation Loss: 0.00538239
Epoch [71/300], Train Loss: 0.005540
Validation Loss: 0.00545892
Epoch [72/300], Train Loss: 0.005512
Validation Loss: 0.00540978
Epoch [73/300], Train Loss: 0.005527
Validation Loss: 0.00542126
Epoch [74/300], Train Loss: 0.005558
Validation Loss: 0.00540945
Epoch [75/300], Train Loss: 0.005550
Validation Loss: 0.00539751
Epoch [76/300], Train Loss: 0.005519
Validation Loss: 0.00539226
Epoch [77/300], Train Loss: 0.005509
Validation Loss: 0.00538839
Epoch [78/300], Train Loss: 0.005527
Validation Loss: 0.00545065
Epoch [79/300], Train Loss: 0.005509
Validation Loss: 0.00543665
Epoch [80/300], Train Loss: 0.005506
Validation Loss: 0.00536991
Epoch [81/300], Train Loss: 0.005524
Validation Loss: 0.00544053
Epoch [82/300], Train Loss: 0.005529
Validation Loss: 0.00549902
Epoch [83/300], Train Loss: 0.005528
Validation Loss: 0.00534775
Epoch [84/300], Train Loss: 0.005506
Validation Loss: 0.00535439
Epoch [85/300], Train Loss: 0.005515
Validation Loss: 0.00535779
Epoch [86/300], Train Loss: 0.005514
Validation Loss: 0.00542147
Epoch [87/300], Train Loss: 0.005513
Validation Loss: 0.00545637
Epoch [88/300], Train Loss: 0.005509
Validation Loss: 0.00537473
Epoch [89/300], Train Loss: 0.005488
Validation Loss: 0.00539704
Epoch [90/300], Train Loss: 0.005541
Validation Loss: 0.00537686
Epoch [91/300], Train Loss: 0.005506
Validation Loss: 0.00534909
Epoch [92/300], Train Loss: 0.005528
Validation Loss: 0.00534033
Epoch [93/300], Train Loss: 0.005578
Validation Loss: 0.00532280
Epoch [94/300], Train Loss: 0.005528
Validation Loss: 0.00532912
Epoch [95/300], Train Loss: 0.005496
Validation Loss: 0.00532794
Epoch [96/300], Train Loss: 0.005498
Validation Loss: 0.00537532
Epoch [97/300], Train Loss: 0.005481
Validation Loss: 0.00538105
Epoch [98/300], Train Loss: 0.005468
Validation Loss: 0.00532968
Epoch [99/300], Train Loss: 0.005458
Validation Loss: 0.00535064
Epoch [100/300], Train Loss: 0.005486
Validation Loss: 0.00531066
Epoch [101/300], Train Loss: 0.005473
Validation Loss: 0.00537944
Epoch [102/300], Train Loss: 0.005472
Validation Loss: 0.00535988
Epoch [103/300], Train Loss: 0.005467
Validation Loss: 0.00542664
Epoch [104/300], Train Loss: 0.005478
Validation Loss: 0.00534469
Epoch [105/300], Train Loss: 0.005475
Validation Loss: 0.00531909
Epoch [106/300], Train Loss: 0.005463
Validation Loss: 0.00530525
Epoch [107/300], Train Loss: 0.005482
Validation Loss: 0.00531213
Epoch [108/300], Train Loss: 0.005465
Validation Loss: 0.00531974
Epoch [109/300], Train Loss: 0.005453
Validation Loss: 0.00533503
Epoch [110/300], Train Loss: 0.005460
Validation Loss: 0.00538048
Epoch [111/300], Train Loss: 0.005442
Validation Loss: 0.00531059
Epoch [112/300], Train Loss: 0.005462
Validation Loss: 0.00530726
Epoch [113/300], Train Loss: 0.005456
Validation Loss: 0.00529122
Epoch [114/300], Train Loss: 0.005459
Validation Loss: 0.00531146
Epoch [115/300], Train Loss: 0.005441
Validation Loss: 0.00536703
Epoch [116/300], Train Loss: 0.005429
Validation Loss: 0.00533189
Epoch [117/300], Train Loss: 0.005438
Validation Loss: 0.00535003
Epoch [118/300], Train Loss: 0.005462
Validation Loss: 0.00531957
Epoch [119/300], Train Loss: 0.005439
Validation Loss: 0.00530466
Epoch [120/300], Train Loss: 0.005436
Validation Loss: 0.00528501
Epoch [121/300], Train Loss: 0.005427
Validation Loss: 0.00530658
Epoch [122/300], Train Loss: 0.005430
Validation Loss: 0.00537053
Epoch [123/300], Train Loss: 0.005451
Validation Loss: 0.00528039
Epoch [124/300], Train Loss: 0.005440
Validation Loss: 0.00534503
Epoch [125/300], Train Loss: 0.005428
Validation Loss: 0.00546377
Epoch [126/300], Train Loss: 0.005522
Validation Loss: 0.00526927
Epoch [127/300], Train Loss: 0.005436
Validation Loss: 0.00527120
Epoch [128/300], Train Loss: 0.005457
Validation Loss: 0.00530376
Epoch [129/300], Train Loss: 0.005412
Validation Loss: 0.00526809
Epoch [130/300], Train Loss: 0.005455
Validation Loss: 0.00530169
Epoch [131/300], Train Loss: 0.005443
Validation Loss: 0.00529099
Epoch [132/300], Train Loss: 0.005446
Validation Loss: 0.00530057
Epoch [133/300], Train Loss: 0.005420
Validation Loss: 0.00527955
Epoch [134/300], Train Loss: 0.005416
Validation Loss: 0.00526681
Epoch [135/300], Train Loss: 0.005409
Validation Loss: 0.00531606
Epoch [136/300], Train Loss: 0.005409
Validation Loss: 0.00526594
Epoch [137/300], Train Loss: 0.005416
Validation Loss: 0.00533192
Epoch [138/300], Train Loss: 0.005394
Validation Loss: 0.00526377
Epoch [139/300], Train Loss: 0.005423
Validation Loss: 0.00531776
Epoch [140/300], Train Loss: 0.005438
Validation Loss: 0.00524723
Epoch [141/300], Train Loss: 0.005421
Validation Loss: 0.00525983
Epoch [142/300], Train Loss: 0.005406
Validation Loss: 0.00529119
Epoch [143/300], Train Loss: 0.005398
Validation Loss: 0.00524380
Epoch [144/300], Train Loss: 0.005410
Validation Loss: 0.00528823
Epoch [145/300], Train Loss: 0.005392
Validation Loss: 0.00531633
Epoch [146/300], Train Loss: 0.005413
Validation Loss: 0.00525919
Epoch [147/300], Train Loss: 0.005396
Validation Loss: 0.00524214
Epoch [148/300], Train Loss: 0.005408
Validation Loss: 0.00526721
Epoch [149/300], Train Loss: 0.005388
Validation Loss: 0.00528402
Epoch [150/300], Train Loss: 0.005401
Validation Loss: 0.00525393
Epoch [151/300], Train Loss: 0.005386
Validation Loss: 0.00531770
Epoch [152/300], Train Loss: 0.005388
Validation Loss: 0.00524363
Epoch [153/300], Train Loss: 0.005376
Validation Loss: 0.00526490
Epoch [154/300], Train Loss: 0.005391
Validation Loss: 0.00526297
Epoch [155/300], Train Loss: 0.005366
Validation Loss: 0.00525177
Epoch [156/300], Train Loss: 0.005391
Validation Loss: 0.00525171
Epoch [157/300], Train Loss: 0.005390
Validation Loss: 0.00528883
Early stopping triggered

Evaluating model for: Router
Run 57/72 completed in 567.61 seconds with: {'MAE': np.float32(0.19735576), 'MSE': np.float32(0.06772865), 'RMSE': np.float32(0.2602473), 'SAE': np.float32(2.7402939e-05), 'NDE': np.float32(0.013014849)}

Run 58/72: hidden=512, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Router
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.073148
Validation Loss: 0.03847453
Epoch [2/300], Train Loss: 0.015052
Validation Loss: 0.00795099
Epoch [3/300], Train Loss: 0.007773
Validation Loss: 0.00642815
Epoch [4/300], Train Loss: 0.006555
Validation Loss: 0.00644003
Epoch [5/300], Train Loss: 0.006245
Validation Loss: 0.00601740
Epoch [6/300], Train Loss: 0.006166
Validation Loss: 0.00601250
Epoch [7/300], Train Loss: 0.006142
Validation Loss: 0.00601663
Epoch [8/300], Train Loss: 0.006110
Validation Loss: 0.00608400
Epoch [9/300], Train Loss: 0.006111
Validation Loss: 0.00597795
Epoch [10/300], Train Loss: 0.006087
Validation Loss: 0.00597259
Epoch [11/300], Train Loss: 0.006078
Validation Loss: 0.00596180
Epoch [12/300], Train Loss: 0.006063
Validation Loss: 0.00595371
Epoch [13/300], Train Loss: 0.006060
Validation Loss: 0.00592668
Epoch [14/300], Train Loss: 0.006055
Validation Loss: 0.00591369
Epoch [15/300], Train Loss: 0.006029
Validation Loss: 0.00590676
Epoch [16/300], Train Loss: 0.006034
Validation Loss: 0.00588124
Epoch [17/300], Train Loss: 0.006060
Validation Loss: 0.00587896
Epoch [18/300], Train Loss: 0.005997
Validation Loss: 0.00585109
Epoch [19/300], Train Loss: 0.006016
Validation Loss: 0.00582991
Epoch [20/300], Train Loss: 0.006019
Validation Loss: 0.00581775
Epoch [21/300], Train Loss: 0.005965
Validation Loss: 0.00580104
Epoch [22/300], Train Loss: 0.005950
Validation Loss: 0.00589865
Epoch [23/300], Train Loss: 0.005941
Validation Loss: 0.00582444
Epoch [24/300], Train Loss: 0.005929
Validation Loss: 0.00577923
Epoch [25/300], Train Loss: 0.005911
Validation Loss: 0.00578931
Epoch [26/300], Train Loss: 0.005910
Validation Loss: 0.00577846
Epoch [27/300], Train Loss: 0.005902
Validation Loss: 0.00582733
Epoch [28/300], Train Loss: 0.005859
Validation Loss: 0.00575552
Epoch [29/300], Train Loss: 0.005869
Validation Loss: 0.00569223
Epoch [30/300], Train Loss: 0.005877
Validation Loss: 0.00568023
Epoch [31/300], Train Loss: 0.005857
Validation Loss: 0.00567346
Epoch [32/300], Train Loss: 0.005823
Validation Loss: 0.00565692
Epoch [33/300], Train Loss: 0.005832
Validation Loss: 0.00565031
Epoch [34/300], Train Loss: 0.005796
Validation Loss: 0.00568960
Epoch [35/300], Train Loss: 0.005826
Validation Loss: 0.00566818
Epoch [36/300], Train Loss: 0.005789
Validation Loss: 0.00565551
Epoch [37/300], Train Loss: 0.005862
Validation Loss: 0.00561067
Epoch [38/300], Train Loss: 0.005795
Validation Loss: 0.00560352
Epoch [39/300], Train Loss: 0.005788
Validation Loss: 0.00560296
Epoch [40/300], Train Loss: 0.005787
Validation Loss: 0.00570033
Epoch [41/300], Train Loss: 0.005799
Validation Loss: 0.00574655
Epoch [42/300], Train Loss: 0.005777
Validation Loss: 0.00558839
Epoch [43/300], Train Loss: 0.005760
Validation Loss: 0.00555450
Epoch [44/300], Train Loss: 0.005828
Validation Loss: 0.00559411
Epoch [45/300], Train Loss: 0.005783
Validation Loss: 0.00554297
Epoch [46/300], Train Loss: 0.005757
Validation Loss: 0.00557890
Epoch [47/300], Train Loss: 0.005691
Validation Loss: 0.00559310
Epoch [48/300], Train Loss: 0.005720
Validation Loss: 0.00560009
Epoch [49/300], Train Loss: 0.005697
Validation Loss: 0.00552269
Epoch [50/300], Train Loss: 0.005687
Validation Loss: 0.00551566
Epoch [51/300], Train Loss: 0.005671
Validation Loss: 0.00560739
Epoch [52/300], Train Loss: 0.005695
Validation Loss: 0.00551999
Epoch [53/300], Train Loss: 0.005693
Validation Loss: 0.00553117
Epoch [54/300], Train Loss: 0.005692
Validation Loss: 0.00568716
Epoch [55/300], Train Loss: 0.005731
Validation Loss: 0.00555502
Epoch [56/300], Train Loss: 0.005656
Validation Loss: 0.00548918
Epoch [57/300], Train Loss: 0.005692
Validation Loss: 0.00549774
Epoch [58/300], Train Loss: 0.005695
Validation Loss: 0.00548767
Epoch [59/300], Train Loss: 0.005662
Validation Loss: 0.00553230
Epoch [60/300], Train Loss: 0.005658
Validation Loss: 0.00546702
Epoch [61/300], Train Loss: 0.005654
Validation Loss: 0.00546456
Epoch [62/300], Train Loss: 0.005645
Validation Loss: 0.00549027
Epoch [63/300], Train Loss: 0.005621
Validation Loss: 0.00547479
Epoch [64/300], Train Loss: 0.005626
Validation Loss: 0.00545422
Epoch [65/300], Train Loss: 0.005642
Validation Loss: 0.00544752
Epoch [66/300], Train Loss: 0.005652
Validation Loss: 0.00545342
Epoch [67/300], Train Loss: 0.005640
Validation Loss: 0.00546821
Epoch [68/300], Train Loss: 0.005655
Validation Loss: 0.00545058
Epoch [69/300], Train Loss: 0.005651
Validation Loss: 0.00543958
Epoch [70/300], Train Loss: 0.005629
Validation Loss: 0.00543995
Epoch [71/300], Train Loss: 0.005610
Validation Loss: 0.00548561
Epoch [72/300], Train Loss: 0.005590
Validation Loss: 0.00546556
Epoch [73/300], Train Loss: 0.005599
Validation Loss: 0.00550052
Epoch [74/300], Train Loss: 0.005626
Validation Loss: 0.00552157
Epoch [75/300], Train Loss: 0.005629
Validation Loss: 0.00551871
Epoch [76/300], Train Loss: 0.005604
Validation Loss: 0.00550216
Epoch [77/300], Train Loss: 0.005584
Validation Loss: 0.00544644
Epoch [78/300], Train Loss: 0.005597
Validation Loss: 0.00546503
Epoch [79/300], Train Loss: 0.005579
Validation Loss: 0.00546992
Early stopping triggered

Evaluating model for: Router
Run 58/72 completed in 376.59 seconds with: {'MAE': np.float32(0.19930656), 'MSE': np.float32(0.070137374), 'RMSE': np.float32(0.2648346), 'SAE': np.float32(7.2092036e-05), 'NDE': np.float32(0.01324426)}

Run 59/72: hidden=512, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Router
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.072840
Validation Loss: 0.03667570
Epoch [2/300], Train Loss: 0.014106
Validation Loss: 0.01040688
Epoch [3/300], Train Loss: 0.007912
Validation Loss: 0.00676780
Epoch [4/300], Train Loss: 0.006521
Validation Loss: 0.00615760
Epoch [5/300], Train Loss: 0.006240
Validation Loss: 0.00613538
Epoch [6/300], Train Loss: 0.006161
Validation Loss: 0.00600807
Epoch [7/300], Train Loss: 0.006145
Validation Loss: 0.00599955
Epoch [8/300], Train Loss: 0.006109
Validation Loss: 0.00610783
Epoch [9/300], Train Loss: 0.006099
Validation Loss: 0.00599898
Epoch [10/300], Train Loss: 0.006083
Validation Loss: 0.00597321
Epoch [11/300], Train Loss: 0.006071
Validation Loss: 0.00595989
Epoch [12/300], Train Loss: 0.006058
Validation Loss: 0.00595230
Epoch [13/300], Train Loss: 0.006053
Validation Loss: 0.00592767
Epoch [14/300], Train Loss: 0.006051
Validation Loss: 0.00591402
Epoch [15/300], Train Loss: 0.006019
Validation Loss: 0.00590934
Epoch [16/300], Train Loss: 0.006025
Validation Loss: 0.00587975
Epoch [17/300], Train Loss: 0.006051
Validation Loss: 0.00587732
Epoch [18/300], Train Loss: 0.005987
Validation Loss: 0.00584892
Epoch [19/300], Train Loss: 0.006005
Validation Loss: 0.00582824
Epoch [20/300], Train Loss: 0.006008
Validation Loss: 0.00581480
Epoch [21/300], Train Loss: 0.005949
Validation Loss: 0.00580295
Epoch [22/300], Train Loss: 0.005937
Validation Loss: 0.00587023
Epoch [23/300], Train Loss: 0.005926
Validation Loss: 0.00581910
Epoch [24/300], Train Loss: 0.005916
Validation Loss: 0.00578367
Epoch [25/300], Train Loss: 0.005896
Validation Loss: 0.00579970
Epoch [26/300], Train Loss: 0.005891
Validation Loss: 0.00578631
Epoch [27/300], Train Loss: 0.005892
Validation Loss: 0.00584886
Epoch [28/300], Train Loss: 0.005842
Validation Loss: 0.00576587
Epoch [29/300], Train Loss: 0.005862
Validation Loss: 0.00568863
Epoch [30/300], Train Loss: 0.005868
Validation Loss: 0.00567890
Epoch [31/300], Train Loss: 0.005839
Validation Loss: 0.00566615
Epoch [32/300], Train Loss: 0.005808
Validation Loss: 0.00565249
Epoch [33/300], Train Loss: 0.005821
Validation Loss: 0.00564779
Epoch [34/300], Train Loss: 0.005776
Validation Loss: 0.00568421
Epoch [35/300], Train Loss: 0.005804
Validation Loss: 0.00565710
Epoch [36/300], Train Loss: 0.005767
Validation Loss: 0.00564269
Epoch [37/300], Train Loss: 0.005847
Validation Loss: 0.00560012
Epoch [38/300], Train Loss: 0.005778
Validation Loss: 0.00559686
Epoch [39/300], Train Loss: 0.005773
Validation Loss: 0.00559933
Epoch [40/300], Train Loss: 0.005767
Validation Loss: 0.00570527
Epoch [41/300], Train Loss: 0.005779
Validation Loss: 0.00574795
Epoch [42/300], Train Loss: 0.005767
Validation Loss: 0.00556604
Epoch [43/300], Train Loss: 0.005747
Validation Loss: 0.00554003
Epoch [44/300], Train Loss: 0.005814
Validation Loss: 0.00558184
Epoch [45/300], Train Loss: 0.005765
Validation Loss: 0.00552554
Epoch [46/300], Train Loss: 0.005744
Validation Loss: 0.00557586
Epoch [47/300], Train Loss: 0.005673
Validation Loss: 0.00558272
Epoch [48/300], Train Loss: 0.005700
Validation Loss: 0.00557772
Epoch [49/300], Train Loss: 0.005674
Validation Loss: 0.00550192
Epoch [50/300], Train Loss: 0.005661
Validation Loss: 0.00549516
Epoch [51/300], Train Loss: 0.005647
Validation Loss: 0.00558502
Epoch [52/300], Train Loss: 0.005672
Validation Loss: 0.00549907
Epoch [53/300], Train Loss: 0.005670
Validation Loss: 0.00551013
Epoch [54/300], Train Loss: 0.005673
Validation Loss: 0.00567184
Epoch [55/300], Train Loss: 0.005709
Validation Loss: 0.00553060
Epoch [56/300], Train Loss: 0.005633
Validation Loss: 0.00546446
Epoch [57/300], Train Loss: 0.005664
Validation Loss: 0.00547348
Epoch [58/300], Train Loss: 0.005670
Validation Loss: 0.00546370
Epoch [59/300], Train Loss: 0.005634
Validation Loss: 0.00550825
Epoch [60/300], Train Loss: 0.005633
Validation Loss: 0.00544139
Epoch [61/300], Train Loss: 0.005628
Validation Loss: 0.00543659
Epoch [62/300], Train Loss: 0.005616
Validation Loss: 0.00546251
Epoch [63/300], Train Loss: 0.005590
Validation Loss: 0.00544586
Epoch [64/300], Train Loss: 0.005600
Validation Loss: 0.00542464
Epoch [65/300], Train Loss: 0.005612
Validation Loss: 0.00541854
Epoch [66/300], Train Loss: 0.005619
Validation Loss: 0.00542297
Epoch [67/300], Train Loss: 0.005603
Validation Loss: 0.00543982
Epoch [68/300], Train Loss: 0.005616
Validation Loss: 0.00541985
Epoch [69/300], Train Loss: 0.005616
Validation Loss: 0.00540756
Epoch [70/300], Train Loss: 0.005597
Validation Loss: 0.00540698
Epoch [71/300], Train Loss: 0.005572
Validation Loss: 0.00544882
Epoch [72/300], Train Loss: 0.005554
Validation Loss: 0.00542805
Epoch [73/300], Train Loss: 0.005565
Validation Loss: 0.00546411
Epoch [74/300], Train Loss: 0.005588
Validation Loss: 0.00548756
Epoch [75/300], Train Loss: 0.005594
Validation Loss: 0.00548298
Epoch [76/300], Train Loss: 0.005567
Validation Loss: 0.00546238
Epoch [77/300], Train Loss: 0.005544
Validation Loss: 0.00540821
Epoch [78/300], Train Loss: 0.005558
Validation Loss: 0.00542363
Epoch [79/300], Train Loss: 0.005541
Validation Loss: 0.00542752
Epoch [80/300], Train Loss: 0.005535
Validation Loss: 0.00537478
Epoch [81/300], Train Loss: 0.005555
Validation Loss: 0.00542084
Epoch [82/300], Train Loss: 0.005543
Validation Loss: 0.00552136
Epoch [83/300], Train Loss: 0.005550
Validation Loss: 0.00535952
Epoch [84/300], Train Loss: 0.005524
Validation Loss: 0.00537151
Epoch [85/300], Train Loss: 0.005521
Validation Loss: 0.00534498
Epoch [86/300], Train Loss: 0.005527
Validation Loss: 0.00538701
Epoch [87/300], Train Loss: 0.005520
Validation Loss: 0.00547269
Epoch [88/300], Train Loss: 0.005524
Validation Loss: 0.00538707
Epoch [89/300], Train Loss: 0.005488
Validation Loss: 0.00545170
Epoch [90/300], Train Loss: 0.005547
Validation Loss: 0.00548189
Epoch [91/300], Train Loss: 0.005535
Validation Loss: 0.00541109
Epoch [92/300], Train Loss: 0.005528
Validation Loss: 0.00538736
Epoch [93/300], Train Loss: 0.005595
Validation Loss: 0.00532322
Epoch [94/300], Train Loss: 0.005565
Validation Loss: 0.00533283
Epoch [95/300], Train Loss: 0.005521
Validation Loss: 0.00530174
Epoch [96/300], Train Loss: 0.005502
Validation Loss: 0.00532862
Epoch [97/300], Train Loss: 0.005480
Validation Loss: 0.00536526
Epoch [98/300], Train Loss: 0.005470
Validation Loss: 0.00532159
Epoch [99/300], Train Loss: 0.005454
Validation Loss: 0.00532990
Epoch [100/300], Train Loss: 0.005478
Validation Loss: 0.00528108
Epoch [101/300], Train Loss: 0.005458
Validation Loss: 0.00529620
Epoch [102/300], Train Loss: 0.005461
Validation Loss: 0.00529491
Epoch [103/300], Train Loss: 0.005454
Validation Loss: 0.00537611
Epoch [104/300], Train Loss: 0.005464
Validation Loss: 0.00532835
Epoch [105/300], Train Loss: 0.005478
Validation Loss: 0.00527204
Epoch [106/300], Train Loss: 0.005451
Validation Loss: 0.00526735
Epoch [107/300], Train Loss: 0.005474
Validation Loss: 0.00527305
Epoch [108/300], Train Loss: 0.005439
Validation Loss: 0.00525011
Epoch [109/300], Train Loss: 0.005436
Validation Loss: 0.00525239
Epoch [110/300], Train Loss: 0.005439
Validation Loss: 0.00536772
Epoch [111/300], Train Loss: 0.005421
Validation Loss: 0.00529918
Epoch [112/300], Train Loss: 0.005425
Validation Loss: 0.00526393
Epoch [113/300], Train Loss: 0.005414
Validation Loss: 0.00517287
Epoch [114/300], Train Loss: 0.005446
Validation Loss: 0.00528714
Epoch [115/300], Train Loss: 0.005427
Validation Loss: 0.00533177
Epoch [116/300], Train Loss: 0.005414
Validation Loss: 0.00531847
Epoch [117/300], Train Loss: 0.005418
Validation Loss: 0.00537903
Epoch [118/300], Train Loss: 0.005442
Validation Loss: 0.00540077
Epoch [119/300], Train Loss: 0.005425
Validation Loss: 0.00533440
Epoch [120/300], Train Loss: 0.005417
Validation Loss: 0.00527486
Epoch [121/300], Train Loss: 0.005390
Validation Loss: 0.00524746
Epoch [122/300], Train Loss: 0.005399
Validation Loss: 0.00531102
Epoch [123/300], Train Loss: 0.005411
Validation Loss: 0.00527282
Early stopping triggered

Evaluating model for: Router
Run 59/72 completed in 691.71 seconds with: {'MAE': np.float32(0.19790347), 'MSE': np.float32(0.0680122), 'RMSE': np.float32(0.26079148), 'SAE': np.float32(0.000286297), 'NDE': np.float32(0.013042066)}

Run 60/72: hidden=512, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Router
Dataset length: 2169 windows

Epoch [1/300], Train Loss: 0.065859
Validation Loss: 0.02099650
Epoch [2/300], Train Loss: 0.010973
Validation Loss: 0.01034522
Epoch [3/300], Train Loss: 0.007367
Validation Loss: 0.00615446
Epoch [4/300], Train Loss: 0.006378
Validation Loss: 0.00607284
Epoch [5/300], Train Loss: 0.006278
Validation Loss: 0.00619247
Epoch [6/300], Train Loss: 0.006173
Validation Loss: 0.00606057
Epoch [7/300], Train Loss: 0.006158
Validation Loss: 0.00602956
Epoch [8/300], Train Loss: 0.006116
Validation Loss: 0.00611709
Epoch [9/300], Train Loss: 0.006111
Validation Loss: 0.00603260
Epoch [10/300], Train Loss: 0.006094
Validation Loss: 0.00600492
Epoch [11/300], Train Loss: 0.006081
Validation Loss: 0.00598617
Epoch [12/300], Train Loss: 0.006069
Validation Loss: 0.00597633
Epoch [13/300], Train Loss: 0.006066
Validation Loss: 0.00595323
Epoch [14/300], Train Loss: 0.006057
Validation Loss: 0.00593706
Epoch [15/300], Train Loss: 0.006027
Validation Loss: 0.00593291
Epoch [16/300], Train Loss: 0.006037
Validation Loss: 0.00590270
Epoch [17/300], Train Loss: 0.006065
Validation Loss: 0.00589885
Epoch [18/300], Train Loss: 0.005996
Validation Loss: 0.00587553
Epoch [19/300], Train Loss: 0.006015
Validation Loss: 0.00585342
Epoch [20/300], Train Loss: 0.006018
Validation Loss: 0.00583790
Epoch [21/300], Train Loss: 0.005953
Validation Loss: 0.00582891
Epoch [22/300], Train Loss: 0.005942
Validation Loss: 0.00586900
Epoch [23/300], Train Loss: 0.005933
Validation Loss: 0.00582706
Epoch [24/300], Train Loss: 0.005917
Validation Loss: 0.00579730
Epoch [25/300], Train Loss: 0.005893
Validation Loss: 0.00581429
Epoch [26/300], Train Loss: 0.005883
Validation Loss: 0.00578877
Epoch [27/300], Train Loss: 0.005882
Validation Loss: 0.00587243
Epoch [28/300], Train Loss: 0.005826
Validation Loss: 0.00570716
Epoch [29/300], Train Loss: 0.005865
Validation Loss: 0.00564577
Epoch [30/300], Train Loss: 0.005856
Validation Loss: 0.00563002
Epoch [31/300], Train Loss: 0.005814
Validation Loss: 0.00561642
Epoch [32/300], Train Loss: 0.005785
Validation Loss: 0.00560635
Epoch [33/300], Train Loss: 0.005797
Validation Loss: 0.00565938
Epoch [34/300], Train Loss: 0.005775
Validation Loss: 0.00566239
Epoch [35/300], Train Loss: 0.005785
Validation Loss: 0.00559715
Epoch [36/300], Train Loss: 0.005736
Validation Loss: 0.00558052
Epoch [37/300], Train Loss: 0.005827
Validation Loss: 0.00555187
Epoch [38/300], Train Loss: 0.005754
Validation Loss: 0.00558933
Epoch [39/300], Train Loss: 0.005766
Validation Loss: 0.00559066
Epoch [40/300], Train Loss: 0.005733
Validation Loss: 0.00568309
Epoch [41/300], Train Loss: 0.005745
Validation Loss: 0.00569856
Epoch [42/300], Train Loss: 0.005750
Validation Loss: 0.00549897
Epoch [43/300], Train Loss: 0.005733
Validation Loss: 0.00550837
Epoch [44/300], Train Loss: 0.005789
Validation Loss: 0.00552348
Epoch [45/300], Train Loss: 0.005737
Validation Loss: 0.00549664
Epoch [46/300], Train Loss: 0.005733
Validation Loss: 0.00559106
Epoch [47/300], Train Loss: 0.005653
Validation Loss: 0.00555934
Epoch [48/300], Train Loss: 0.005678
Validation Loss: 0.00550343
Epoch [49/300], Train Loss: 0.005654
Validation Loss: 0.00543872
Epoch [50/300], Train Loss: 0.005634
Validation Loss: 0.00542160
Epoch [51/300], Train Loss: 0.005599
Validation Loss: 0.00547605
Epoch [52/300], Train Loss: 0.005629
Validation Loss: 0.00544524
Epoch [53/300], Train Loss: 0.005630
Validation Loss: 0.00540320
Epoch [54/300], Train Loss: 0.005720
Validation Loss: 0.00560033
Epoch [55/300], Train Loss: 0.005705
Validation Loss: 0.00559929
Epoch [56/300], Train Loss: 0.005637
Validation Loss: 0.00552790
Epoch [57/300], Train Loss: 0.005675
Validation Loss: 0.00552950
Epoch [58/300], Train Loss: 0.005677
Validation Loss: 0.00550428
Epoch [59/300], Train Loss: 0.005634
Validation Loss: 0.00554153
Epoch [60/300], Train Loss: 0.005631
Validation Loss: 0.00546294
Epoch [61/300], Train Loss: 0.005619
Validation Loss: 0.00544991
Epoch [62/300], Train Loss: 0.005606
Validation Loss: 0.00546867
Epoch [63/300], Train Loss: 0.005580
Validation Loss: 0.00544446
Early stopping triggered

Evaluating model for: Router
Run 60/72 completed in 446.22 seconds with: {'MAE': np.float32(0.20136371), 'MSE': np.float32(0.070551045), 'RMSE': np.float32(0.26561448), 'SAE': np.float32(0.0005856582), 'NDE': np.float32(0.013283261)}

Run 61/72: hidden=512, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Router
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.081671
Validation Loss: 0.06788395
Epoch [2/300], Train Loss: 0.058793
Validation Loss: 0.04377871
Epoch [3/300], Train Loss: 0.031481
Validation Loss: 0.01178054
Epoch [4/300], Train Loss: 0.011010
Validation Loss: 0.00807592
Epoch [5/300], Train Loss: 0.007178
Validation Loss: 0.00742566
Epoch [6/300], Train Loss: 0.007866
Validation Loss: 0.00588375
Epoch [7/300], Train Loss: 0.006273
Validation Loss: 0.00582650
Epoch [8/300], Train Loss: 0.006378
Validation Loss: 0.00529200
Epoch [9/300], Train Loss: 0.006126
Validation Loss: 0.00542940
Epoch [10/300], Train Loss: 0.006061
Validation Loss: 0.00528457
Epoch [11/300], Train Loss: 0.006067
Validation Loss: 0.00528710
Epoch [12/300], Train Loss: 0.006010
Validation Loss: 0.00529041
Epoch [13/300], Train Loss: 0.006009
Validation Loss: 0.00526194
Epoch [14/300], Train Loss: 0.006021
Validation Loss: 0.00526280
Epoch [15/300], Train Loss: 0.006009
Validation Loss: 0.00526050
Epoch [16/300], Train Loss: 0.005998
Validation Loss: 0.00524840
Epoch [17/300], Train Loss: 0.006006
Validation Loss: 0.00524430
Epoch [18/300], Train Loss: 0.005980
Validation Loss: 0.00524271
Epoch [19/300], Train Loss: 0.006003
Validation Loss: 0.00523624
Epoch [20/300], Train Loss: 0.005967
Validation Loss: 0.00523347
Epoch [21/300], Train Loss: 0.005976
Validation Loss: 0.00522762
Epoch [22/300], Train Loss: 0.005959
Validation Loss: 0.00522399
Epoch [23/300], Train Loss: 0.005964
Validation Loss: 0.00521887
Epoch [24/300], Train Loss: 0.005973
Validation Loss: 0.00521363
Epoch [25/300], Train Loss: 0.005946
Validation Loss: 0.00522008
Epoch [26/300], Train Loss: 0.005942
Validation Loss: 0.00520712
Epoch [27/300], Train Loss: 0.005943
Validation Loss: 0.00519960
Epoch [28/300], Train Loss: 0.005958
Validation Loss: 0.00519542
Epoch [29/300], Train Loss: 0.005960
Validation Loss: 0.00519065
Epoch [30/300], Train Loss: 0.005930
Validation Loss: 0.00519474
Epoch [31/300], Train Loss: 0.005932
Validation Loss: 0.00518495
Epoch [32/300], Train Loss: 0.005940
Validation Loss: 0.00517676
Epoch [33/300], Train Loss: 0.005924
Validation Loss: 0.00517411
Epoch [34/300], Train Loss: 0.005911
Validation Loss: 0.00516832
Epoch [35/300], Train Loss: 0.005912
Validation Loss: 0.00516596
Epoch [36/300], Train Loss: 0.005922
Validation Loss: 0.00516869
Epoch [37/300], Train Loss: 0.005919
Validation Loss: 0.00515558
Epoch [38/300], Train Loss: 0.005905
Validation Loss: 0.00515145
Epoch [39/300], Train Loss: 0.005876
Validation Loss: 0.00514591
Epoch [40/300], Train Loss: 0.005912
Validation Loss: 0.00514124
Epoch [41/300], Train Loss: 0.005895
Validation Loss: 0.00513785
Epoch [42/300], Train Loss: 0.005876
Validation Loss: 0.00513357
Epoch [43/300], Train Loss: 0.005893
Validation Loss: 0.00512873
Epoch [44/300], Train Loss: 0.005883
Validation Loss: 0.00512281
Epoch [45/300], Train Loss: 0.005854
Validation Loss: 0.00511865
Epoch [46/300], Train Loss: 0.005875
Validation Loss: 0.00511468
Epoch [47/300], Train Loss: 0.005840
Validation Loss: 0.00511301
Epoch [48/300], Train Loss: 0.005870
Validation Loss: 0.00510582
Epoch [49/300], Train Loss: 0.005872
Validation Loss: 0.00510246
Epoch [50/300], Train Loss: 0.005851
Validation Loss: 0.00509756
Epoch [51/300], Train Loss: 0.005844
Validation Loss: 0.00509338
Epoch [52/300], Train Loss: 0.005842
Validation Loss: 0.00508995
Epoch [53/300], Train Loss: 0.005845
Validation Loss: 0.00508490
Epoch [54/300], Train Loss: 0.005830
Validation Loss: 0.00508274
Epoch [55/300], Train Loss: 0.005828
Validation Loss: 0.00507618
Epoch [56/300], Train Loss: 0.005837
Validation Loss: 0.00507386
Epoch [57/300], Train Loss: 0.005819
Validation Loss: 0.00507721
Epoch [58/300], Train Loss: 0.005810
Validation Loss: 0.00506733
Epoch [59/300], Train Loss: 0.005811
Validation Loss: 0.00505964
Epoch [60/300], Train Loss: 0.005795
Validation Loss: 0.00505621
Epoch [61/300], Train Loss: 0.005773
Validation Loss: 0.00505181
Epoch [62/300], Train Loss: 0.005786
Validation Loss: 0.00504810
Epoch [63/300], Train Loss: 0.005794
Validation Loss: 0.00504634
Epoch [64/300], Train Loss: 0.005781
Validation Loss: 0.00504148
Epoch [65/300], Train Loss: 0.005792
Validation Loss: 0.00503780
Epoch [66/300], Train Loss: 0.005799
Validation Loss: 0.00503387
Epoch [67/300], Train Loss: 0.005770
Validation Loss: 0.00503344
Epoch [68/300], Train Loss: 0.005790
Validation Loss: 0.00502628
Epoch [69/300], Train Loss: 0.005768
Validation Loss: 0.00502444
Epoch [70/300], Train Loss: 0.005786
Validation Loss: 0.00501957
Epoch [71/300], Train Loss: 0.005771
Validation Loss: 0.00501597
Epoch [72/300], Train Loss: 0.005734
Validation Loss: 0.00501292
Epoch [73/300], Train Loss: 0.005743
Validation Loss: 0.00500934
Epoch [74/300], Train Loss: 0.005775
Validation Loss: 0.00500587
Epoch [75/300], Train Loss: 0.005732
Validation Loss: 0.00500226
Epoch [76/300], Train Loss: 0.005734
Validation Loss: 0.00500086
Epoch [77/300], Train Loss: 0.005738
Validation Loss: 0.00499722
Epoch [78/300], Train Loss: 0.005753
Validation Loss: 0.00499392
Epoch [79/300], Train Loss: 0.005765
Validation Loss: 0.00499122
Epoch [80/300], Train Loss: 0.005724
Validation Loss: 0.00499871
Epoch [81/300], Train Loss: 0.005758
Validation Loss: 0.00498575
Epoch [82/300], Train Loss: 0.005725
Validation Loss: 0.00498533
Epoch [83/300], Train Loss: 0.005717
Validation Loss: 0.00497985
Epoch [84/300], Train Loss: 0.005743
Validation Loss: 0.00497716
Epoch [85/300], Train Loss: 0.005728
Validation Loss: 0.00497399
Epoch [86/300], Train Loss: 0.005748
Validation Loss: 0.00497362
Epoch [87/300], Train Loss: 0.005723
Validation Loss: 0.00497693
Epoch [88/300], Train Loss: 0.005726
Validation Loss: 0.00496711
Epoch [89/300], Train Loss: 0.005707
Validation Loss: 0.00496753
Epoch [90/300], Train Loss: 0.005736
Validation Loss: 0.00496150
Epoch [91/300], Train Loss: 0.005724
Validation Loss: 0.00496175
Epoch [92/300], Train Loss: 0.005720
Validation Loss: 0.00496265
Epoch [93/300], Train Loss: 0.005737
Validation Loss: 0.00495653
Epoch [94/300], Train Loss: 0.005712
Validation Loss: 0.00496044
Epoch [95/300], Train Loss: 0.005701
Validation Loss: 0.00495465
Epoch [96/300], Train Loss: 0.005704
Validation Loss: 0.00494812
Epoch [97/300], Train Loss: 0.005706
Validation Loss: 0.00495413
Epoch [98/300], Train Loss: 0.005695
Validation Loss: 0.00494870
Epoch [99/300], Train Loss: 0.005682
Validation Loss: 0.00494853
Epoch [100/300], Train Loss: 0.005684
Validation Loss: 0.00494245
Epoch [101/300], Train Loss: 0.005700
Validation Loss: 0.00494932
Epoch [102/300], Train Loss: 0.005689
Validation Loss: 0.00494480
Epoch [103/300], Train Loss: 0.005678
Validation Loss: 0.00493959
Epoch [104/300], Train Loss: 0.005681
Validation Loss: 0.00493229
Epoch [105/300], Train Loss: 0.005681
Validation Loss: 0.00493051
Epoch [106/300], Train Loss: 0.005690
Validation Loss: 0.00492864
Epoch [107/300], Train Loss: 0.005676
Validation Loss: 0.00492631
Epoch [108/300], Train Loss: 0.005662
Validation Loss: 0.00492563
Epoch [109/300], Train Loss: 0.005667
Validation Loss: 0.00492327
Epoch [110/300], Train Loss: 0.005661
Validation Loss: 0.00492135
Epoch [111/300], Train Loss: 0.005655
Validation Loss: 0.00491960
Epoch [112/300], Train Loss: 0.005665
Validation Loss: 0.00492052
Epoch [113/300], Train Loss: 0.005656
Validation Loss: 0.00491744
Epoch [114/300], Train Loss: 0.005660
Validation Loss: 0.00491572
Epoch [115/300], Train Loss: 0.005669
Validation Loss: 0.00491716
Epoch [116/300], Train Loss: 0.005655
Validation Loss: 0.00491813
Epoch [117/300], Train Loss: 0.005641
Validation Loss: 0.00491439
Epoch [118/300], Train Loss: 0.005646
Validation Loss: 0.00490935
Epoch [119/300], Train Loss: 0.005652
Validation Loss: 0.00490752
Epoch [120/300], Train Loss: 0.005657
Validation Loss: 0.00490492
Epoch [121/300], Train Loss: 0.005653
Validation Loss: 0.00490405
Epoch [122/300], Train Loss: 0.005644
Validation Loss: 0.00490582
Epoch [123/300], Train Loss: 0.005663
Validation Loss: 0.00490367
Epoch [124/300], Train Loss: 0.005647
Validation Loss: 0.00490045
Epoch [125/300], Train Loss: 0.005646
Validation Loss: 0.00490006
Epoch [126/300], Train Loss: 0.005640
Validation Loss: 0.00489852
Epoch [127/300], Train Loss: 0.005642
Validation Loss: 0.00489707
Epoch [128/300], Train Loss: 0.005645
Validation Loss: 0.00489478
Epoch [129/300], Train Loss: 0.005640
Validation Loss: 0.00489310
Epoch [130/300], Train Loss: 0.005639
Validation Loss: 0.00489282
Epoch [131/300], Train Loss: 0.005627
Validation Loss: 0.00489503
Epoch [132/300], Train Loss: 0.005633
Validation Loss: 0.00489482
Epoch [133/300], Train Loss: 0.005653
Validation Loss: 0.00489130
Epoch [134/300], Train Loss: 0.005613
Validation Loss: 0.00488939
Epoch [135/300], Train Loss: 0.005634
Validation Loss: 0.00488545
Epoch [136/300], Train Loss: 0.005630
Validation Loss: 0.00488563
Epoch [137/300], Train Loss: 0.005620
Validation Loss: 0.00488957
Epoch [138/300], Train Loss: 0.005649
Validation Loss: 0.00488927
Epoch [139/300], Train Loss: 0.005650
Validation Loss: 0.00489297
Epoch [140/300], Train Loss: 0.005636
Validation Loss: 0.00489421
Epoch [141/300], Train Loss: 0.005632
Validation Loss: 0.00489282
Epoch [142/300], Train Loss: 0.005627
Validation Loss: 0.00487901
Epoch [143/300], Train Loss: 0.005631
Validation Loss: 0.00488046
Epoch [144/300], Train Loss: 0.005613
Validation Loss: 0.00487826
Epoch [145/300], Train Loss: 0.005621
Validation Loss: 0.00487490
Epoch [146/300], Train Loss: 0.005616
Validation Loss: 0.00487566
Epoch [147/300], Train Loss: 0.005622
Validation Loss: 0.00487281
Epoch [148/300], Train Loss: 0.005618
Validation Loss: 0.00487285
Epoch [149/300], Train Loss: 0.005612
Validation Loss: 0.00487069
Epoch [150/300], Train Loss: 0.005599
Validation Loss: 0.00486976
Epoch [151/300], Train Loss: 0.005616
Validation Loss: 0.00487034
Epoch [152/300], Train Loss: 0.005610
Validation Loss: 0.00487269
Epoch [153/300], Train Loss: 0.005617
Validation Loss: 0.00486798
Epoch [154/300], Train Loss: 0.005598
Validation Loss: 0.00486630
Epoch [155/300], Train Loss: 0.005616
Validation Loss: 0.00486651
Epoch [156/300], Train Loss: 0.005627
Validation Loss: 0.00486807
Epoch [157/300], Train Loss: 0.005607
Validation Loss: 0.00487116
Epoch [158/300], Train Loss: 0.005607
Validation Loss: 0.00486451
Epoch [159/300], Train Loss: 0.005614
Validation Loss: 0.00486390
Epoch [160/300], Train Loss: 0.005623
Validation Loss: 0.00486233
Epoch [161/300], Train Loss: 0.005622
Validation Loss: 0.00486865
Epoch [162/300], Train Loss: 0.005601
Validation Loss: 0.00486136
Epoch [163/300], Train Loss: 0.005592
Validation Loss: 0.00485857
Epoch [164/300], Train Loss: 0.005612
Validation Loss: 0.00485836
Epoch [165/300], Train Loss: 0.005594
Validation Loss: 0.00485651
Epoch [166/300], Train Loss: 0.005591
Validation Loss: 0.00485591
Epoch [167/300], Train Loss: 0.005593
Validation Loss: 0.00485492
Epoch [168/300], Train Loss: 0.005595
Validation Loss: 0.00485476
Epoch [169/300], Train Loss: 0.005613
Validation Loss: 0.00485329
Epoch [170/300], Train Loss: 0.005589
Validation Loss: 0.00485254
Epoch [171/300], Train Loss: 0.005603
Validation Loss: 0.00485423
Epoch [172/300], Train Loss: 0.005594
Validation Loss: 0.00485460
Epoch [173/300], Train Loss: 0.005602
Validation Loss: 0.00485106
Epoch [174/300], Train Loss: 0.005596
Validation Loss: 0.00485007
Epoch [175/300], Train Loss: 0.005591
Validation Loss: 0.00484921
Epoch [176/300], Train Loss: 0.005597
Validation Loss: 0.00484795
Epoch [177/300], Train Loss: 0.005588
Validation Loss: 0.00485030
Epoch [178/300], Train Loss: 0.005580
Validation Loss: 0.00484644
Epoch [179/300], Train Loss: 0.005580
Validation Loss: 0.00484577
Epoch [180/300], Train Loss: 0.005585
Validation Loss: 0.00484623
Epoch [181/300], Train Loss: 0.005582
Validation Loss: 0.00484433
Epoch [182/300], Train Loss: 0.005597
Validation Loss: 0.00484358
Epoch [183/300], Train Loss: 0.005575
Validation Loss: 0.00484640
Epoch [184/300], Train Loss: 0.005575
Validation Loss: 0.00484226
Epoch [185/300], Train Loss: 0.005592
Validation Loss: 0.00484158
Epoch [186/300], Train Loss: 0.005587
Validation Loss: 0.00484206
Epoch [187/300], Train Loss: 0.005583
Validation Loss: 0.00484623
Epoch [188/300], Train Loss: 0.005582
Validation Loss: 0.00484093
Epoch [189/300], Train Loss: 0.005576
Validation Loss: 0.00483885
Epoch [190/300], Train Loss: 0.005609
Validation Loss: 0.00484065
Epoch [191/300], Train Loss: 0.005582
Validation Loss: 0.00484814
Epoch [192/300], Train Loss: 0.005574
Validation Loss: 0.00483686
Epoch [193/300], Train Loss: 0.005565
Validation Loss: 0.00483666
Epoch [194/300], Train Loss: 0.005592
Validation Loss: 0.00483618
Epoch [195/300], Train Loss: 0.005577
Validation Loss: 0.00483481
Epoch [196/300], Train Loss: 0.005565
Validation Loss: 0.00483463
Epoch [197/300], Train Loss: 0.005575
Validation Loss: 0.00483366
Epoch [198/300], Train Loss: 0.005571
Validation Loss: 0.00483709
Epoch [199/300], Train Loss: 0.005569
Validation Loss: 0.00483322
Epoch [200/300], Train Loss: 0.005577
Validation Loss: 0.00483210
Epoch [201/300], Train Loss: 0.005554
Validation Loss: 0.00483251
Epoch [202/300], Train Loss: 0.005560
Validation Loss: 0.00483113
Epoch [203/300], Train Loss: 0.005563
Validation Loss: 0.00482999
Epoch [204/300], Train Loss: 0.005586
Validation Loss: 0.00482947
Epoch [205/300], Train Loss: 0.005566
Validation Loss: 0.00482895
Epoch [206/300], Train Loss: 0.005576
Validation Loss: 0.00482839
Epoch [207/300], Train Loss: 0.005568
Validation Loss: 0.00482759
Epoch [208/300], Train Loss: 0.005557
Validation Loss: 0.00483100
Epoch [209/300], Train Loss: 0.005582
Validation Loss: 0.00482743
Epoch [210/300], Train Loss: 0.005549
Validation Loss: 0.00482643
Epoch [211/300], Train Loss: 0.005551
Validation Loss: 0.00482671
Epoch [212/300], Train Loss: 0.005550
Validation Loss: 0.00482540
Epoch [213/300], Train Loss: 0.005575
Validation Loss: 0.00482429
Epoch [214/300], Train Loss: 0.005557
Validation Loss: 0.00482494
Epoch [215/300], Train Loss: 0.005556
Validation Loss: 0.00482300
Epoch [216/300], Train Loss: 0.005561
Validation Loss: 0.00482291
Epoch [217/300], Train Loss: 0.005539
Validation Loss: 0.00482251
Epoch [218/300], Train Loss: 0.005582
Validation Loss: 0.00482133
Epoch [219/300], Train Loss: 0.005554
Validation Loss: 0.00482076
Epoch [220/300], Train Loss: 0.005562
Validation Loss: 0.00482117
Epoch [221/300], Train Loss: 0.005557
Validation Loss: 0.00482009
Epoch [222/300], Train Loss: 0.005557
Validation Loss: 0.00481913
Epoch [223/300], Train Loss: 0.005557
Validation Loss: 0.00481995
Epoch [224/300], Train Loss: 0.005562
Validation Loss: 0.00481868
Epoch [225/300], Train Loss: 0.005550
Validation Loss: 0.00481751
Epoch [226/300], Train Loss: 0.005568
Validation Loss: 0.00481697
Epoch [227/300], Train Loss: 0.005550
Validation Loss: 0.00481847
Epoch [228/300], Train Loss: 0.005540
Validation Loss: 0.00481603
Epoch [229/300], Train Loss: 0.005539
Validation Loss: 0.00481544
Epoch [230/300], Train Loss: 0.005550
Validation Loss: 0.00481489
Epoch [231/300], Train Loss: 0.005551
Validation Loss: 0.00481496
Epoch [232/300], Train Loss: 0.005555
Validation Loss: 0.00481389
Epoch [233/300], Train Loss: 0.005560
Validation Loss: 0.00481698
Epoch [234/300], Train Loss: 0.005562
Validation Loss: 0.00481618
Epoch [235/300], Train Loss: 0.005557
Validation Loss: 0.00481235
Epoch [236/300], Train Loss: 0.005567
Validation Loss: 0.00481287
Epoch [237/300], Train Loss: 0.005553
Validation Loss: 0.00481174
Epoch [238/300], Train Loss: 0.005536
Validation Loss: 0.00481087
Epoch [239/300], Train Loss: 0.005542
Validation Loss: 0.00481084
Epoch [240/300], Train Loss: 0.005547
Validation Loss: 0.00481013
Epoch [241/300], Train Loss: 0.005542
Validation Loss: 0.00480932
Epoch [242/300], Train Loss: 0.005546
Validation Loss: 0.00480907
Epoch [243/300], Train Loss: 0.005556
Validation Loss: 0.00480839
Epoch [244/300], Train Loss: 0.005536
Validation Loss: 0.00480783
Epoch [245/300], Train Loss: 0.005545
Validation Loss: 0.00481010
Epoch [246/300], Train Loss: 0.005551
Validation Loss: 0.00480786
Epoch [247/300], Train Loss: 0.005557
Validation Loss: 0.00480767
Epoch [248/300], Train Loss: 0.005537
Validation Loss: 0.00480603
Epoch [249/300], Train Loss: 0.005546
Validation Loss: 0.00480651
Epoch [250/300], Train Loss: 0.005552
Validation Loss: 0.00480660
Epoch [251/300], Train Loss: 0.005532
Validation Loss: 0.00480716
Epoch [252/300], Train Loss: 0.005544
Validation Loss: 0.00480418
Epoch [253/300], Train Loss: 0.005554
Validation Loss: 0.00480408
Epoch [254/300], Train Loss: 0.005533
Validation Loss: 0.00480458
Epoch [255/300], Train Loss: 0.005534
Validation Loss: 0.00480444
Epoch [256/300], Train Loss: 0.005533
Validation Loss: 0.00480314
Epoch [257/300], Train Loss: 0.005537
Validation Loss: 0.00480201
Epoch [258/300], Train Loss: 0.005534
Validation Loss: 0.00480170
Epoch [259/300], Train Loss: 0.005542
Validation Loss: 0.00480126
Epoch [260/300], Train Loss: 0.005543
Validation Loss: 0.00480150
Epoch [261/300], Train Loss: 0.005530
Validation Loss: 0.00480087
Epoch [262/300], Train Loss: 0.005531
Validation Loss: 0.00479990
Epoch [263/300], Train Loss: 0.005527
Validation Loss: 0.00479981
Epoch [264/300], Train Loss: 0.005542
Validation Loss: 0.00479920
Epoch [265/300], Train Loss: 0.005538
Validation Loss: 0.00479929
Epoch [266/300], Train Loss: 0.005553
Validation Loss: 0.00480072
Epoch [267/300], Train Loss: 0.005545
Validation Loss: 0.00479856
Epoch [268/300], Train Loss: 0.005547
Validation Loss: 0.00479764
Epoch [269/300], Train Loss: 0.005544
Validation Loss: 0.00480565
Epoch [270/300], Train Loss: 0.005536
Validation Loss: 0.00479655
Epoch [271/300], Train Loss: 0.005555
Validation Loss: 0.00479926
Epoch [272/300], Train Loss: 0.005525
Validation Loss: 0.00480283
Epoch [273/300], Train Loss: 0.005547
Validation Loss: 0.00479600
Epoch [274/300], Train Loss: 0.005532
Validation Loss: 0.00479517
Epoch [275/300], Train Loss: 0.005535
Validation Loss: 0.00479540
Epoch [276/300], Train Loss: 0.005519
Validation Loss: 0.00479445
Epoch [277/300], Train Loss: 0.005532
Validation Loss: 0.00479683
Epoch [278/300], Train Loss: 0.005544
Validation Loss: 0.00479677
Epoch [279/300], Train Loss: 0.005534
Validation Loss: 0.00479389
Epoch [280/300], Train Loss: 0.005553
Validation Loss: 0.00479454
Epoch [281/300], Train Loss: 0.005529
Validation Loss: 0.00479294
Epoch [282/300], Train Loss: 0.005532
Validation Loss: 0.00479217
Epoch [283/300], Train Loss: 0.005530
Validation Loss: 0.00479229
Epoch [284/300], Train Loss: 0.005515
Validation Loss: 0.00479143
Epoch [285/300], Train Loss: 0.005522
Validation Loss: 0.00479133
Epoch [286/300], Train Loss: 0.005538
Validation Loss: 0.00479308
Epoch [287/300], Train Loss: 0.005539
Validation Loss: 0.00479092
Epoch [288/300], Train Loss: 0.005514
Validation Loss: 0.00479113
Epoch [289/300], Train Loss: 0.005513
Validation Loss: 0.00479008
Epoch [290/300], Train Loss: 0.005510
Validation Loss: 0.00478954
Epoch [291/300], Train Loss: 0.005521
Validation Loss: 0.00478912
Epoch [292/300], Train Loss: 0.005527
Validation Loss: 0.00478976
Epoch [293/300], Train Loss: 0.005523
Validation Loss: 0.00478849
Epoch [294/300], Train Loss: 0.005519
Validation Loss: 0.00478867
Epoch [295/300], Train Loss: 0.005513
Validation Loss: 0.00478849
Epoch [296/300], Train Loss: 0.005529
Validation Loss: 0.00478791
Epoch [297/300], Train Loss: 0.005518
Validation Loss: 0.00478742
Epoch [298/300], Train Loss: 0.005540
Validation Loss: 0.00478710
Epoch [299/300], Train Loss: 0.005527
Validation Loss: 0.00478805
Epoch [300/300], Train Loss: 0.005525
Validation Loss: 0.00478617

Evaluating model for: Router
Run 61/72 completed in 562.06 seconds with: {'MAE': np.float32(0.2109846), 'MSE': np.float32(0.07602812), 'RMSE': np.float32(0.27573198), 'SAE': np.float32(0.00095291313), 'NDE': np.float32(0.0137913795)}

Run 62/72: hidden=512, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Router
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.082607
Validation Loss: 0.06735224
Epoch [2/300], Train Loss: 0.056042
Validation Loss: 0.03665976
Epoch [3/300], Train Loss: 0.020296
Validation Loss: 0.01211870
Epoch [4/300], Train Loss: 0.010379
Validation Loss: 0.00655877
Epoch [5/300], Train Loss: 0.008711
Validation Loss: 0.00731424
Epoch [6/300], Train Loss: 0.006741
Validation Loss: 0.00588316
Epoch [7/300], Train Loss: 0.006689
Validation Loss: 0.00538023
Epoch [8/300], Train Loss: 0.006268
Validation Loss: 0.00561394
Epoch [9/300], Train Loss: 0.006175
Validation Loss: 0.00536132
Epoch [10/300], Train Loss: 0.006171
Validation Loss: 0.00533979
Epoch [11/300], Train Loss: 0.006090
Validation Loss: 0.00535321
Epoch [12/300], Train Loss: 0.006075
Validation Loss: 0.00531602
Epoch [13/300], Train Loss: 0.006075
Validation Loss: 0.00531164
Epoch [14/300], Train Loss: 0.006072
Validation Loss: 0.00530692
Epoch [15/300], Train Loss: 0.006060
Validation Loss: 0.00530098
Epoch [16/300], Train Loss: 0.006059
Validation Loss: 0.00529862
Epoch [17/300], Train Loss: 0.006065
Validation Loss: 0.00529327
Epoch [18/300], Train Loss: 0.006038
Validation Loss: 0.00528714
Epoch [19/300], Train Loss: 0.006063
Validation Loss: 0.00528392
Epoch [20/300], Train Loss: 0.006033
Validation Loss: 0.00528218
Epoch [21/300], Train Loss: 0.006036
Validation Loss: 0.00527657
Epoch [22/300], Train Loss: 0.006018
Validation Loss: 0.00526964
Epoch [23/300], Train Loss: 0.006025
Validation Loss: 0.00526521
Epoch [24/300], Train Loss: 0.006025
Validation Loss: 0.00525884
Epoch [25/300], Train Loss: 0.006008
Validation Loss: 0.00526075
Epoch [26/300], Train Loss: 0.005995
Validation Loss: 0.00525500
Epoch [27/300], Train Loss: 0.006003
Validation Loss: 0.00524397
Epoch [28/300], Train Loss: 0.006010
Validation Loss: 0.00523689
Epoch [29/300], Train Loss: 0.006021
Validation Loss: 0.00523151
Epoch [30/300], Train Loss: 0.005999
Validation Loss: 0.00523490
Epoch [31/300], Train Loss: 0.005993
Validation Loss: 0.00523137
Epoch [32/300], Train Loss: 0.005993
Validation Loss: 0.00521843
Epoch [33/300], Train Loss: 0.005973
Validation Loss: 0.00521169
Epoch [34/300], Train Loss: 0.005959
Validation Loss: 0.00520702
Epoch [35/300], Train Loss: 0.005956
Validation Loss: 0.00520329
Epoch [36/300], Train Loss: 0.005972
Validation Loss: 0.00520491
Epoch [37/300], Train Loss: 0.005964
Validation Loss: 0.00519575
Epoch [38/300], Train Loss: 0.005956
Validation Loss: 0.00518708
Epoch [39/300], Train Loss: 0.005925
Validation Loss: 0.00518209
Epoch [40/300], Train Loss: 0.005957
Validation Loss: 0.00517685
Epoch [41/300], Train Loss: 0.005950
Validation Loss: 0.00517205
Epoch [42/300], Train Loss: 0.005916
Validation Loss: 0.00516982
Epoch [43/300], Train Loss: 0.005933
Validation Loss: 0.00516545
Epoch [44/300], Train Loss: 0.005932
Validation Loss: 0.00515784
Epoch [45/300], Train Loss: 0.005906
Validation Loss: 0.00515266
Epoch [46/300], Train Loss: 0.005918
Validation Loss: 0.00514742
Epoch [47/300], Train Loss: 0.005886
Validation Loss: 0.00514502
Epoch [48/300], Train Loss: 0.005905
Validation Loss: 0.00513731
Epoch [49/300], Train Loss: 0.005911
Validation Loss: 0.00513341
Epoch [50/300], Train Loss: 0.005887
Validation Loss: 0.00512913
Epoch [51/300], Train Loss: 0.005881
Validation Loss: 0.00512411
Epoch [52/300], Train Loss: 0.005879
Validation Loss: 0.00511772
Epoch [53/300], Train Loss: 0.005882
Validation Loss: 0.00511288
Epoch [54/300], Train Loss: 0.005870
Validation Loss: 0.00511112
Epoch [55/300], Train Loss: 0.005862
Validation Loss: 0.00510414
Epoch [56/300], Train Loss: 0.005872
Validation Loss: 0.00509824
Epoch [57/300], Train Loss: 0.005855
Validation Loss: 0.00509624
Epoch [58/300], Train Loss: 0.005842
Validation Loss: 0.00509262
Epoch [59/300], Train Loss: 0.005838
Validation Loss: 0.00508559
Epoch [60/300], Train Loss: 0.005826
Validation Loss: 0.00507931
Epoch [61/300], Train Loss: 0.005807
Validation Loss: 0.00507550
Epoch [62/300], Train Loss: 0.005817
Validation Loss: 0.00507120
Epoch [63/300], Train Loss: 0.005825
Validation Loss: 0.00507224
Epoch [64/300], Train Loss: 0.005808
Validation Loss: 0.00506133
Epoch [65/300], Train Loss: 0.005816
Validation Loss: 0.00505697
Epoch [66/300], Train Loss: 0.005832
Validation Loss: 0.00505515
Epoch [67/300], Train Loss: 0.005805
Validation Loss: 0.00504899
Epoch [68/300], Train Loss: 0.005824
Validation Loss: 0.00504450
Epoch [69/300], Train Loss: 0.005791
Validation Loss: 0.00504416
Epoch [70/300], Train Loss: 0.005813
Validation Loss: 0.00503594
Epoch [71/300], Train Loss: 0.005798
Validation Loss: 0.00503140
Epoch [72/300], Train Loss: 0.005764
Validation Loss: 0.00503013
Epoch [73/300], Train Loss: 0.005761
Validation Loss: 0.00503004
Epoch [74/300], Train Loss: 0.005806
Validation Loss: 0.00503147
Epoch [75/300], Train Loss: 0.005759
Validation Loss: 0.00502339
Epoch [76/300], Train Loss: 0.005762
Validation Loss: 0.00501336
Epoch [77/300], Train Loss: 0.005771
Validation Loss: 0.00500813
Epoch [78/300], Train Loss: 0.005771
Validation Loss: 0.00500539
Epoch [79/300], Train Loss: 0.005794
Validation Loss: 0.00501039
Epoch [80/300], Train Loss: 0.005758
Validation Loss: 0.00499830
Epoch [81/300], Train Loss: 0.005777
Validation Loss: 0.00499757
Epoch [82/300], Train Loss: 0.005746
Validation Loss: 0.00499178
Epoch [83/300], Train Loss: 0.005733
Validation Loss: 0.00498846
Epoch [84/300], Train Loss: 0.005752
Validation Loss: 0.00498758
Epoch [85/300], Train Loss: 0.005738
Validation Loss: 0.00498708
Epoch [86/300], Train Loss: 0.005756
Validation Loss: 0.00498107
Epoch [87/300], Train Loss: 0.005745
Validation Loss: 0.00497575
Epoch [88/300], Train Loss: 0.005734
Validation Loss: 0.00497458
Epoch [89/300], Train Loss: 0.005719
Validation Loss: 0.00497260
Epoch [90/300], Train Loss: 0.005743
Validation Loss: 0.00496686
Epoch [91/300], Train Loss: 0.005727
Validation Loss: 0.00496398
Epoch [92/300], Train Loss: 0.005726
Validation Loss: 0.00496147
Epoch [93/300], Train Loss: 0.005751
Validation Loss: 0.00496410
Epoch [94/300], Train Loss: 0.005739
Validation Loss: 0.00495629
Epoch [95/300], Train Loss: 0.005698
Validation Loss: 0.00496072
Epoch [96/300], Train Loss: 0.005707
Validation Loss: 0.00495157
Epoch [97/300], Train Loss: 0.005706
Validation Loss: 0.00494950
Epoch [98/300], Train Loss: 0.005701
Validation Loss: 0.00494704
Epoch [99/300], Train Loss: 0.005692
Validation Loss: 0.00494425
Epoch [100/300], Train Loss: 0.005698
Validation Loss: 0.00494368
Epoch [101/300], Train Loss: 0.005711
Validation Loss: 0.00494045
Epoch [102/300], Train Loss: 0.005697
Validation Loss: 0.00493891
Epoch [103/300], Train Loss: 0.005677
Validation Loss: 0.00494048
Epoch [104/300], Train Loss: 0.005676
Validation Loss: 0.00494037
Epoch [105/300], Train Loss: 0.005687
Validation Loss: 0.00494934
Epoch [106/300], Train Loss: 0.005711
Validation Loss: 0.00492983
Epoch [107/300], Train Loss: 0.005680
Validation Loss: 0.00493022
Epoch [108/300], Train Loss: 0.005665
Validation Loss: 0.00492569
Epoch [109/300], Train Loss: 0.005674
Validation Loss: 0.00492321
Epoch [110/300], Train Loss: 0.005670
Validation Loss: 0.00492142
Epoch [111/300], Train Loss: 0.005661
Validation Loss: 0.00491948
Epoch [112/300], Train Loss: 0.005670
Validation Loss: 0.00491843
Epoch [113/300], Train Loss: 0.005664
Validation Loss: 0.00491555
Epoch [114/300], Train Loss: 0.005669
Validation Loss: 0.00491385
Epoch [115/300], Train Loss: 0.005679
Validation Loss: 0.00491186
Epoch [116/300], Train Loss: 0.005664
Validation Loss: 0.00491243
Epoch [117/300], Train Loss: 0.005643
Validation Loss: 0.00491176
Epoch [118/300], Train Loss: 0.005652
Validation Loss: 0.00490858
Epoch [119/300], Train Loss: 0.005648
Validation Loss: 0.00490979
Epoch [120/300], Train Loss: 0.005653
Validation Loss: 0.00490567
Epoch [121/300], Train Loss: 0.005644
Validation Loss: 0.00490504
Epoch [122/300], Train Loss: 0.005643
Validation Loss: 0.00489988
Epoch [123/300], Train Loss: 0.005656
Validation Loss: 0.00489795
Epoch [124/300], Train Loss: 0.005653
Validation Loss: 0.00489686
Epoch [125/300], Train Loss: 0.005643
Validation Loss: 0.00489481
Epoch [126/300], Train Loss: 0.005643
Validation Loss: 0.00489384
Epoch [127/300], Train Loss: 0.005642
Validation Loss: 0.00489181
Epoch [128/300], Train Loss: 0.005647
Validation Loss: 0.00489102
Epoch [129/300], Train Loss: 0.005639
Validation Loss: 0.00489053
Epoch [130/300], Train Loss: 0.005634
Validation Loss: 0.00488935
Epoch [131/300], Train Loss: 0.005623
Validation Loss: 0.00488615
Epoch [132/300], Train Loss: 0.005632
Validation Loss: 0.00488448
Epoch [133/300], Train Loss: 0.005653
Validation Loss: 0.00488313
Epoch [134/300], Train Loss: 0.005612
Validation Loss: 0.00488232
Epoch [135/300], Train Loss: 0.005633
Validation Loss: 0.00488019
Epoch [136/300], Train Loss: 0.005622
Validation Loss: 0.00487874
Epoch [137/300], Train Loss: 0.005611
Validation Loss: 0.00487856
Epoch [138/300], Train Loss: 0.005647
Validation Loss: 0.00487711
Epoch [139/300], Train Loss: 0.005659
Validation Loss: 0.00487805
Epoch [140/300], Train Loss: 0.005648
Validation Loss: 0.00488110
Epoch [141/300], Train Loss: 0.005641
Validation Loss: 0.00489348
Epoch [142/300], Train Loss: 0.005648
Validation Loss: 0.00487490
Epoch [143/300], Train Loss: 0.005644
Validation Loss: 0.00488370
Epoch [144/300], Train Loss: 0.005609
Validation Loss: 0.00488717
Epoch [145/300], Train Loss: 0.005623
Validation Loss: 0.00487568
Epoch [146/300], Train Loss: 0.005631
Validation Loss: 0.00486677
Epoch [147/300], Train Loss: 0.005617
Validation Loss: 0.00486625
Epoch [148/300], Train Loss: 0.005610
Validation Loss: 0.00486611
Epoch [149/300], Train Loss: 0.005605
Validation Loss: 0.00486324
Epoch [150/300], Train Loss: 0.005602
Validation Loss: 0.00486212
Epoch [151/300], Train Loss: 0.005616
Validation Loss: 0.00486191
Epoch [152/300], Train Loss: 0.005596
Validation Loss: 0.00486704
Epoch [153/300], Train Loss: 0.005614
Validation Loss: 0.00486363
Epoch [154/300], Train Loss: 0.005590
Validation Loss: 0.00486389
Epoch [155/300], Train Loss: 0.005608
Validation Loss: 0.00485870
Epoch [156/300], Train Loss: 0.005616
Validation Loss: 0.00485608
Epoch [157/300], Train Loss: 0.005611
Validation Loss: 0.00485706
Epoch [158/300], Train Loss: 0.005604
Validation Loss: 0.00485555
Epoch [159/300], Train Loss: 0.005616
Validation Loss: 0.00485894
Epoch [160/300], Train Loss: 0.005632
Validation Loss: 0.00485614
Epoch [161/300], Train Loss: 0.005630
Validation Loss: 0.00487036
Epoch [162/300], Train Loss: 0.005599
Validation Loss: 0.00486021
Epoch [163/300], Train Loss: 0.005585
Validation Loss: 0.00485976
Epoch [164/300], Train Loss: 0.005620
Validation Loss: 0.00484932
Epoch [165/300], Train Loss: 0.005592
Validation Loss: 0.00484810
Epoch [166/300], Train Loss: 0.005585
Validation Loss: 0.00484621
Epoch [167/300], Train Loss: 0.005593
Validation Loss: 0.00484580
Epoch [168/300], Train Loss: 0.005581
Validation Loss: 0.00484490
Epoch [169/300], Train Loss: 0.005606
Validation Loss: 0.00484336
Epoch [170/300], Train Loss: 0.005584
Validation Loss: 0.00484241
Epoch [171/300], Train Loss: 0.005595
Validation Loss: 0.00484207
Epoch [172/300], Train Loss: 0.005592
Validation Loss: 0.00484330
Epoch [173/300], Train Loss: 0.005593
Validation Loss: 0.00484209
Epoch [174/300], Train Loss: 0.005591
Validation Loss: 0.00484371
Epoch [175/300], Train Loss: 0.005581
Validation Loss: 0.00483835
Epoch [176/300], Train Loss: 0.005590
Validation Loss: 0.00484021
Epoch [177/300], Train Loss: 0.005579
Validation Loss: 0.00483668
Epoch [178/300], Train Loss: 0.005581
Validation Loss: 0.00483597
Epoch [179/300], Train Loss: 0.005567
Validation Loss: 0.00483455
Epoch [180/300], Train Loss: 0.005572
Validation Loss: 0.00483456
Epoch [181/300], Train Loss: 0.005568
Validation Loss: 0.00483287
Epoch [182/300], Train Loss: 0.005593
Validation Loss: 0.00483209
Epoch [183/300], Train Loss: 0.005568
Validation Loss: 0.00483438
Epoch [184/300], Train Loss: 0.005566
Validation Loss: 0.00483055
Epoch [185/300], Train Loss: 0.005581
Validation Loss: 0.00483071
Epoch [186/300], Train Loss: 0.005577
Validation Loss: 0.00482902
Epoch [187/300], Train Loss: 0.005573
Validation Loss: 0.00483369
Epoch [188/300], Train Loss: 0.005579
Validation Loss: 0.00483107
Epoch [189/300], Train Loss: 0.005566
Validation Loss: 0.00482949
Epoch [190/300], Train Loss: 0.005598
Validation Loss: 0.00482613
Epoch [191/300], Train Loss: 0.005577
Validation Loss: 0.00483691
Epoch [192/300], Train Loss: 0.005556
Validation Loss: 0.00482578
Epoch [193/300], Train Loss: 0.005559
Validation Loss: 0.00482513
Epoch [194/300], Train Loss: 0.005579
Validation Loss: 0.00482300
Epoch [195/300], Train Loss: 0.005568
Validation Loss: 0.00482261
Epoch [196/300], Train Loss: 0.005557
Validation Loss: 0.00482229
Epoch [197/300], Train Loss: 0.005572
Validation Loss: 0.00482090
Epoch [198/300], Train Loss: 0.005564
Validation Loss: 0.00482715
Epoch [199/300], Train Loss: 0.005554
Validation Loss: 0.00482423
Epoch [200/300], Train Loss: 0.005576
Validation Loss: 0.00482091
Epoch [201/300], Train Loss: 0.005546
Validation Loss: 0.00482135
Epoch [202/300], Train Loss: 0.005542
Validation Loss: 0.00481987
Epoch [203/300], Train Loss: 0.005551
Validation Loss: 0.00481730
Epoch [204/300], Train Loss: 0.005569
Validation Loss: 0.00481623
Epoch [205/300], Train Loss: 0.005554
Validation Loss: 0.00481592
Epoch [206/300], Train Loss: 0.005567
Validation Loss: 0.00481532
Epoch [207/300], Train Loss: 0.005557
Validation Loss: 0.00481443
Epoch [208/300], Train Loss: 0.005547
Validation Loss: 0.00481719
Epoch [209/300], Train Loss: 0.005575
Validation Loss: 0.00481532
Epoch [210/300], Train Loss: 0.005542
Validation Loss: 0.00481727
Epoch [211/300], Train Loss: 0.005544
Validation Loss: 0.00481167
Epoch [212/300], Train Loss: 0.005535
Validation Loss: 0.00481192
Epoch [213/300], Train Loss: 0.005559
Validation Loss: 0.00481269
Epoch [214/300], Train Loss: 0.005544
Validation Loss: 0.00480982
Epoch [215/300], Train Loss: 0.005550
Validation Loss: 0.00480931
Epoch [216/300], Train Loss: 0.005549
Validation Loss: 0.00480857
Epoch [217/300], Train Loss: 0.005532
Validation Loss: 0.00480817
Epoch [218/300], Train Loss: 0.005565
Validation Loss: 0.00480736
Epoch [219/300], Train Loss: 0.005543
Validation Loss: 0.00480718
Epoch [220/300], Train Loss: 0.005552
Validation Loss: 0.00480654
Epoch [221/300], Train Loss: 0.005543
Validation Loss: 0.00480636
Epoch [222/300], Train Loss: 0.005551
Validation Loss: 0.00480548
Epoch [223/300], Train Loss: 0.005544
Validation Loss: 0.00480501
Epoch [224/300], Train Loss: 0.005549
Validation Loss: 0.00480480
Epoch [225/300], Train Loss: 0.005534
Validation Loss: 0.00480539
Epoch [226/300], Train Loss: 0.005561
Validation Loss: 0.00480275
Epoch [227/300], Train Loss: 0.005543
Validation Loss: 0.00480441
Epoch [228/300], Train Loss: 0.005529
Validation Loss: 0.00480222
Epoch [229/300], Train Loss: 0.005530
Validation Loss: 0.00480102
Epoch [230/300], Train Loss: 0.005546
Validation Loss: 0.00480052
Epoch [231/300], Train Loss: 0.005536
Validation Loss: 0.00480040
Epoch [232/300], Train Loss: 0.005546
Validation Loss: 0.00480028
Epoch [233/300], Train Loss: 0.005554
Validation Loss: 0.00480128
Epoch [234/300], Train Loss: 0.005549
Validation Loss: 0.00480555
Epoch [235/300], Train Loss: 0.005545
Validation Loss: 0.00480030
Epoch [236/300], Train Loss: 0.005554
Validation Loss: 0.00480192
Epoch [237/300], Train Loss: 0.005541
Validation Loss: 0.00479854
Epoch [238/300], Train Loss: 0.005525
Validation Loss: 0.00479680
Epoch [239/300], Train Loss: 0.005530
Validation Loss: 0.00479592
Epoch [240/300], Train Loss: 0.005538
Validation Loss: 0.00479562
Epoch [241/300], Train Loss: 0.005532
Validation Loss: 0.00479521
Epoch [242/300], Train Loss: 0.005532
Validation Loss: 0.00479419
Epoch [243/300], Train Loss: 0.005544
Validation Loss: 0.00479369
Epoch [244/300], Train Loss: 0.005525
Validation Loss: 0.00479312
Epoch [245/300], Train Loss: 0.005534
Validation Loss: 0.00479493
Epoch [246/300], Train Loss: 0.005533
Validation Loss: 0.00479567
Epoch [247/300], Train Loss: 0.005547
Validation Loss: 0.00479166
Epoch [248/300], Train Loss: 0.005521
Validation Loss: 0.00479119
Epoch [249/300], Train Loss: 0.005536
Validation Loss: 0.00479372
Epoch [250/300], Train Loss: 0.005546
Validation Loss: 0.00479576
Epoch [251/300], Train Loss: 0.005525
Validation Loss: 0.00479779
Epoch [252/300], Train Loss: 0.005534
Validation Loss: 0.00479118
Epoch [253/300], Train Loss: 0.005537
Validation Loss: 0.00478895
Epoch [254/300], Train Loss: 0.005516
Validation Loss: 0.00479131
Epoch [255/300], Train Loss: 0.005519
Validation Loss: 0.00478787
Epoch [256/300], Train Loss: 0.005520
Validation Loss: 0.00478861
Epoch [257/300], Train Loss: 0.005516
Validation Loss: 0.00478741
Epoch [258/300], Train Loss: 0.005524
Validation Loss: 0.00478655
Epoch [259/300], Train Loss: 0.005528
Validation Loss: 0.00478619
Epoch [260/300], Train Loss: 0.005535
Validation Loss: 0.00478728
Epoch [261/300], Train Loss: 0.005521
Validation Loss: 0.00478714
Epoch [262/300], Train Loss: 0.005509
Validation Loss: 0.00478486
Epoch [263/300], Train Loss: 0.005508
Validation Loss: 0.00478513
Epoch [264/300], Train Loss: 0.005527
Validation Loss: 0.00478408
Epoch [265/300], Train Loss: 0.005519
Validation Loss: 0.00478389
Epoch [266/300], Train Loss: 0.005542
Validation Loss: 0.00478903
Epoch [267/300], Train Loss: 0.005536
Validation Loss: 0.00478840
Epoch [268/300], Train Loss: 0.005534
Validation Loss: 0.00478256
Epoch [269/300], Train Loss: 0.005537
Validation Loss: 0.00479492
Epoch [270/300], Train Loss: 0.005525
Validation Loss: 0.00478522
Epoch [271/300], Train Loss: 0.005542
Validation Loss: 0.00478138
Epoch [272/300], Train Loss: 0.005523
Validation Loss: 0.00479657
Epoch [273/300], Train Loss: 0.005544
Validation Loss: 0.00478964
Epoch [274/300], Train Loss: 0.005518
Validation Loss: 0.00478145
Epoch [275/300], Train Loss: 0.005529
Validation Loss: 0.00478104
Epoch [276/300], Train Loss: 0.005502
Validation Loss: 0.00477992
Epoch [277/300], Train Loss: 0.005517
Validation Loss: 0.00478107
Epoch [278/300], Train Loss: 0.005529
Validation Loss: 0.00478848
Epoch [279/300], Train Loss: 0.005519
Validation Loss: 0.00477835
Epoch [280/300], Train Loss: 0.005539
Validation Loss: 0.00478010
Epoch [281/300], Train Loss: 0.005515
Validation Loss: 0.00478087
Epoch [282/300], Train Loss: 0.005522
Validation Loss: 0.00477765
Epoch [283/300], Train Loss: 0.005509
Validation Loss: 0.00477672
Epoch [284/300], Train Loss: 0.005497
Validation Loss: 0.00477598
Epoch [285/300], Train Loss: 0.005505
Validation Loss: 0.00477578
Epoch [286/300], Train Loss: 0.005522
Validation Loss: 0.00477951
Epoch [287/300], Train Loss: 0.005526
Validation Loss: 0.00477757
Epoch [288/300], Train Loss: 0.005499
Validation Loss: 0.00477470
Epoch [289/300], Train Loss: 0.005500
Validation Loss: 0.00477594
Epoch [290/300], Train Loss: 0.005490
Validation Loss: 0.00477405
Epoch [291/300], Train Loss: 0.005506
Validation Loss: 0.00477354
Epoch [292/300], Train Loss: 0.005508
Validation Loss: 0.00477346
Epoch [293/300], Train Loss: 0.005514
Validation Loss: 0.00477314
Epoch [294/300], Train Loss: 0.005505
Validation Loss: 0.00477266
Epoch [295/300], Train Loss: 0.005492
Validation Loss: 0.00477376
Epoch [296/300], Train Loss: 0.005512
Validation Loss: 0.00477173
Epoch [297/300], Train Loss: 0.005501
Validation Loss: 0.00477213
Epoch [298/300], Train Loss: 0.005523
Validation Loss: 0.00477102
Epoch [299/300], Train Loss: 0.005510
Validation Loss: 0.00477225
Epoch [300/300], Train Loss: 0.005521
Validation Loss: 0.00477127

Evaluating model for: Router
Run 62/72 completed in 698.39 seconds with: {'MAE': np.float32(0.21168311), 'MSE': np.float32(0.07614553), 'RMSE': np.float32(0.2759448), 'SAE': np.float32(0.0011074161), 'NDE': np.float32(0.013802025)}

Run 63/72: hidden=512, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Router
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.100138
Validation Loss: 0.08140241
Epoch [2/300], Train Loss: 0.066287
Validation Loss: 0.03913071
Epoch [3/300], Train Loss: 0.020988
Validation Loss: 0.01666745
Epoch [4/300], Train Loss: 0.009420
Validation Loss: 0.00943857
Epoch [5/300], Train Loss: 0.009472
Validation Loss: 0.00599128
Epoch [6/300], Train Loss: 0.006924
Validation Loss: 0.00658917
Epoch [7/300], Train Loss: 0.006701
Validation Loss: 0.00583070
Epoch [8/300], Train Loss: 0.006645
Validation Loss: 0.00559135
Epoch [9/300], Train Loss: 0.006382
Validation Loss: 0.00566973
Epoch [10/300], Train Loss: 0.006372
Validation Loss: 0.00558053
Epoch [11/300], Train Loss: 0.006376
Validation Loss: 0.00553236
Epoch [12/300], Train Loss: 0.006324
Validation Loss: 0.00552842
Epoch [13/300], Train Loss: 0.006305
Validation Loss: 0.00552447
Epoch [14/300], Train Loss: 0.006320
Validation Loss: 0.00551370
Epoch [15/300], Train Loss: 0.006304
Validation Loss: 0.00550627
Epoch [16/300], Train Loss: 0.006289
Validation Loss: 0.00549889
Epoch [17/300], Train Loss: 0.006294
Validation Loss: 0.00549171
Epoch [18/300], Train Loss: 0.006275
Validation Loss: 0.00548494
Epoch [19/300], Train Loss: 0.006295
Validation Loss: 0.00547863
Epoch [20/300], Train Loss: 0.006264
Validation Loss: 0.00547485
Epoch [21/300], Train Loss: 0.006260
Validation Loss: 0.00546858
Epoch [22/300], Train Loss: 0.006245
Validation Loss: 0.00546081
Epoch [23/300], Train Loss: 0.006244
Validation Loss: 0.00545605
Epoch [24/300], Train Loss: 0.006246
Validation Loss: 0.00544930
Epoch [25/300], Train Loss: 0.006229
Validation Loss: 0.00543895
Epoch [26/300], Train Loss: 0.006213
Validation Loss: 0.00543432
Epoch [27/300], Train Loss: 0.006209
Validation Loss: 0.00542462
Epoch [28/300], Train Loss: 0.006225
Validation Loss: 0.00541492
Epoch [29/300], Train Loss: 0.006218
Validation Loss: 0.00540727
Epoch [30/300], Train Loss: 0.006195
Validation Loss: 0.00540172
Epoch [31/300], Train Loss: 0.006199
Validation Loss: 0.00539834
Epoch [32/300], Train Loss: 0.006200
Validation Loss: 0.00538752
Epoch [33/300], Train Loss: 0.006173
Validation Loss: 0.00537881
Epoch [34/300], Train Loss: 0.006155
Validation Loss: 0.00537284
Epoch [35/300], Train Loss: 0.006159
Validation Loss: 0.00536626
Epoch [36/300], Train Loss: 0.006168
Validation Loss: 0.00536590
Epoch [37/300], Train Loss: 0.006151
Validation Loss: 0.00535697
Epoch [38/300], Train Loss: 0.006150
Validation Loss: 0.00534451
Epoch [39/300], Train Loss: 0.006100
Validation Loss: 0.00533849
Epoch [40/300], Train Loss: 0.006141
Validation Loss: 0.00533141
Epoch [41/300], Train Loss: 0.006133
Validation Loss: 0.00532384
Epoch [42/300], Train Loss: 0.006100
Validation Loss: 0.00531759
Epoch [43/300], Train Loss: 0.006109
Validation Loss: 0.00531256
Epoch [44/300], Train Loss: 0.006109
Validation Loss: 0.00530484
Epoch [45/300], Train Loss: 0.006083
Validation Loss: 0.00529790
Epoch [46/300], Train Loss: 0.006091
Validation Loss: 0.00529009
Epoch [47/300], Train Loss: 0.006053
Validation Loss: 0.00528768
Epoch [48/300], Train Loss: 0.006084
Validation Loss: 0.00527655
Epoch [49/300], Train Loss: 0.006080
Validation Loss: 0.00527128
Epoch [50/300], Train Loss: 0.006057
Validation Loss: 0.00526570
Epoch [51/300], Train Loss: 0.006045
Validation Loss: 0.00526107
Epoch [52/300], Train Loss: 0.006045
Validation Loss: 0.00525063
Epoch [53/300], Train Loss: 0.006036
Validation Loss: 0.00524426
Epoch [54/300], Train Loss: 0.006026
Validation Loss: 0.00524122
Epoch [55/300], Train Loss: 0.006026
Validation Loss: 0.00523414
Epoch [56/300], Train Loss: 0.006025
Validation Loss: 0.00522653
Epoch [57/300], Train Loss: 0.006011
Validation Loss: 0.00521894
Epoch [58/300], Train Loss: 0.005991
Validation Loss: 0.00521337
Epoch [59/300], Train Loss: 0.005992
Validation Loss: 0.00520775
Epoch [60/300], Train Loss: 0.005977
Validation Loss: 0.00520035
Epoch [61/300], Train Loss: 0.005962
Validation Loss: 0.00519541
Epoch [62/300], Train Loss: 0.005961
Validation Loss: 0.00518917
Epoch [63/300], Train Loss: 0.005969
Validation Loss: 0.00519433
Epoch [64/300], Train Loss: 0.005956
Validation Loss: 0.00517780
Epoch [65/300], Train Loss: 0.005955
Validation Loss: 0.00517388
Epoch [66/300], Train Loss: 0.005974
Validation Loss: 0.00518603
Epoch [67/300], Train Loss: 0.005957
Validation Loss: 0.00516291
Epoch [68/300], Train Loss: 0.005957
Validation Loss: 0.00516201
Epoch [69/300], Train Loss: 0.005934
Validation Loss: 0.00516579
Epoch [70/300], Train Loss: 0.005963
Validation Loss: 0.00514392
Epoch [71/300], Train Loss: 0.005955
Validation Loss: 0.00514071
Epoch [72/300], Train Loss: 0.005903
Validation Loss: 0.00514258
Epoch [73/300], Train Loss: 0.005887
Validation Loss: 0.00514609
Epoch [74/300], Train Loss: 0.005940
Validation Loss: 0.00516098
Epoch [75/300], Train Loss: 0.005885
Validation Loss: 0.00514543
Epoch [76/300], Train Loss: 0.005903
Validation Loss: 0.00512480
Epoch [77/300], Train Loss: 0.005918
Validation Loss: 0.00510971
Epoch [78/300], Train Loss: 0.005924
Validation Loss: 0.00511358
Epoch [79/300], Train Loss: 0.005944
Validation Loss: 0.00515185
Epoch [80/300], Train Loss: 0.005911
Validation Loss: 0.00510766
Epoch [81/300], Train Loss: 0.005895
Validation Loss: 0.00512149
Epoch [82/300], Train Loss: 0.005880
Validation Loss: 0.00509848
Epoch [83/300], Train Loss: 0.005860
Validation Loss: 0.00509399
Epoch [84/300], Train Loss: 0.005890
Validation Loss: 0.00508382
Epoch [85/300], Train Loss: 0.005868
Validation Loss: 0.00508479
Epoch [86/300], Train Loss: 0.005874
Validation Loss: 0.00508229
Epoch [87/300], Train Loss: 0.005862
Validation Loss: 0.00507348
Epoch [88/300], Train Loss: 0.005848
Validation Loss: 0.00507587
Epoch [89/300], Train Loss: 0.005851
Validation Loss: 0.00506816
Epoch [90/300], Train Loss: 0.005864
Validation Loss: 0.00506308
Epoch [91/300], Train Loss: 0.005850
Validation Loss: 0.00506130
Epoch [92/300], Train Loss: 0.005848
Validation Loss: 0.00506062
Epoch [93/300], Train Loss: 0.005866
Validation Loss: 0.00507481
Epoch [94/300], Train Loss: 0.005863
Validation Loss: 0.00505349
Epoch [95/300], Train Loss: 0.005820
Validation Loss: 0.00505018
Epoch [96/300], Train Loss: 0.005821
Validation Loss: 0.00504472
Epoch [97/300], Train Loss: 0.005832
Validation Loss: 0.00504314
Epoch [98/300], Train Loss: 0.005816
Validation Loss: 0.00504130
Epoch [99/300], Train Loss: 0.005809
Validation Loss: 0.00503876
Epoch [100/300], Train Loss: 0.005814
Validation Loss: 0.00504348
Epoch [101/300], Train Loss: 0.005821
Validation Loss: 0.00503257
Epoch [102/300], Train Loss: 0.005820
Validation Loss: 0.00502937
Epoch [103/300], Train Loss: 0.005788
Validation Loss: 0.00502659
Epoch [104/300], Train Loss: 0.005793
Validation Loss: 0.00502624
Epoch [105/300], Train Loss: 0.005800
Validation Loss: 0.00503508
Epoch [106/300], Train Loss: 0.005821
Validation Loss: 0.00501874
Epoch [107/300], Train Loss: 0.005793
Validation Loss: 0.00501707
Epoch [108/300], Train Loss: 0.005788
Validation Loss: 0.00501798
Epoch [109/300], Train Loss: 0.005784
Validation Loss: 0.00501231
Epoch [110/300], Train Loss: 0.005779
Validation Loss: 0.00501052
Epoch [111/300], Train Loss: 0.005772
Validation Loss: 0.00500877
Epoch [112/300], Train Loss: 0.005782
Validation Loss: 0.00500635
Epoch [113/300], Train Loss: 0.005768
Validation Loss: 0.00500343
Epoch [114/300], Train Loss: 0.005771
Validation Loss: 0.00500256
Epoch [115/300], Train Loss: 0.005778
Validation Loss: 0.00499990
Epoch [116/300], Train Loss: 0.005771
Validation Loss: 0.00499757
Epoch [117/300], Train Loss: 0.005750
Validation Loss: 0.00499597
Epoch [118/300], Train Loss: 0.005762
Validation Loss: 0.00499336
Epoch [119/300], Train Loss: 0.005751
Validation Loss: 0.00499414
Epoch [120/300], Train Loss: 0.005757
Validation Loss: 0.00499077
Epoch [121/300], Train Loss: 0.005759
Validation Loss: 0.00499033
Epoch [122/300], Train Loss: 0.005745
Validation Loss: 0.00498566
Epoch [123/300], Train Loss: 0.005761
Validation Loss: 0.00498338
Epoch [124/300], Train Loss: 0.005752
Validation Loss: 0.00498172
Epoch [125/300], Train Loss: 0.005742
Validation Loss: 0.00497990
Epoch [126/300], Train Loss: 0.005745
Validation Loss: 0.00497915
Epoch [127/300], Train Loss: 0.005743
Validation Loss: 0.00497613
Epoch [128/300], Train Loss: 0.005745
Validation Loss: 0.00497531
Epoch [129/300], Train Loss: 0.005745
Validation Loss: 0.00497389
Epoch [130/300], Train Loss: 0.005738
Validation Loss: 0.00497463
Epoch [131/300], Train Loss: 0.005732
Validation Loss: 0.00497031
Epoch [132/300], Train Loss: 0.005731
Validation Loss: 0.00496768
Epoch [133/300], Train Loss: 0.005744
Validation Loss: 0.00496554
Epoch [134/300], Train Loss: 0.005713
Validation Loss: 0.00496375
Epoch [135/300], Train Loss: 0.005730
Validation Loss: 0.00496202
Epoch [136/300], Train Loss: 0.005723
Validation Loss: 0.00496076
Epoch [137/300], Train Loss: 0.005709
Validation Loss: 0.00495928
Epoch [138/300], Train Loss: 0.005750
Validation Loss: 0.00495766
Epoch [139/300], Train Loss: 0.005756
Validation Loss: 0.00495574
Epoch [140/300], Train Loss: 0.005747
Validation Loss: 0.00495538
Epoch [141/300], Train Loss: 0.005736
Validation Loss: 0.00496022
Epoch [142/300], Train Loss: 0.005758
Validation Loss: 0.00495112
Epoch [143/300], Train Loss: 0.005744
Validation Loss: 0.00495285
Epoch [144/300], Train Loss: 0.005708
Validation Loss: 0.00495832
Epoch [145/300], Train Loss: 0.005715
Validation Loss: 0.00494978
Epoch [146/300], Train Loss: 0.005734
Validation Loss: 0.00494557
Epoch [147/300], Train Loss: 0.005718
Validation Loss: 0.00494348
Epoch [148/300], Train Loss: 0.005709
Validation Loss: 0.00494448
Epoch [149/300], Train Loss: 0.005698
Validation Loss: 0.00494115
Epoch [150/300], Train Loss: 0.005686
Validation Loss: 0.00493888
Epoch [151/300], Train Loss: 0.005702
Validation Loss: 0.00493864
Epoch [152/300], Train Loss: 0.005689
Validation Loss: 0.00494142
Epoch [153/300], Train Loss: 0.005703
Validation Loss: 0.00494048
Epoch [154/300], Train Loss: 0.005686
Validation Loss: 0.00493890
Epoch [155/300], Train Loss: 0.005696
Validation Loss: 0.00493774
Epoch [156/300], Train Loss: 0.005708
Validation Loss: 0.00493267
Epoch [157/300], Train Loss: 0.005703
Validation Loss: 0.00492944
Epoch [158/300], Train Loss: 0.005696
Validation Loss: 0.00492829
Epoch [159/300], Train Loss: 0.005705
Validation Loss: 0.00492775
Epoch [160/300], Train Loss: 0.005724
Validation Loss: 0.00492641
Epoch [161/300], Train Loss: 0.005719
Validation Loss: 0.00493455
Epoch [162/300], Train Loss: 0.005694
Validation Loss: 0.00492997
Epoch [163/300], Train Loss: 0.005673
Validation Loss: 0.00493076
Epoch [164/300], Train Loss: 0.005704
Validation Loss: 0.00492319
Epoch [165/300], Train Loss: 0.005688
Validation Loss: 0.00491983
Epoch [166/300], Train Loss: 0.005676
Validation Loss: 0.00491856
Epoch [167/300], Train Loss: 0.005680
Validation Loss: 0.00491683
Epoch [168/300], Train Loss: 0.005669
Validation Loss: 0.00491709
Epoch [169/300], Train Loss: 0.005693
Validation Loss: 0.00491410
Epoch [170/300], Train Loss: 0.005669
Validation Loss: 0.00491304
Epoch [171/300], Train Loss: 0.005674
Validation Loss: 0.00491151
Epoch [172/300], Train Loss: 0.005666
Validation Loss: 0.00491044
Epoch [173/300], Train Loss: 0.005678
Validation Loss: 0.00491011
Epoch [174/300], Train Loss: 0.005678
Validation Loss: 0.00491047
Epoch [175/300], Train Loss: 0.005660
Validation Loss: 0.00490707
Epoch [176/300], Train Loss: 0.005673
Validation Loss: 0.00490947
Epoch [177/300], Train Loss: 0.005662
Validation Loss: 0.00490369
Epoch [178/300], Train Loss: 0.005662
Validation Loss: 0.00490532
Epoch [179/300], Train Loss: 0.005648
Validation Loss: 0.00490185
Epoch [180/300], Train Loss: 0.005654
Validation Loss: 0.00490190
Epoch [181/300], Train Loss: 0.005648
Validation Loss: 0.00489880
Epoch [182/300], Train Loss: 0.005667
Validation Loss: 0.00489743
Epoch [183/300], Train Loss: 0.005646
Validation Loss: 0.00489772
Epoch [184/300], Train Loss: 0.005649
Validation Loss: 0.00489511
Epoch [185/300], Train Loss: 0.005656
Validation Loss: 0.00489446
Epoch [186/300], Train Loss: 0.005650
Validation Loss: 0.00489356
Epoch [187/300], Train Loss: 0.005648
Validation Loss: 0.00489542
Epoch [188/300], Train Loss: 0.005655
Validation Loss: 0.00489116
Epoch [189/300], Train Loss: 0.005640
Validation Loss: 0.00489349
Epoch [190/300], Train Loss: 0.005667
Validation Loss: 0.00488935
Epoch [191/300], Train Loss: 0.005652
Validation Loss: 0.00489297
Epoch [192/300], Train Loss: 0.005630
Validation Loss: 0.00488686
Epoch [193/300], Train Loss: 0.005630
Validation Loss: 0.00488519
Epoch [194/300], Train Loss: 0.005654
Validation Loss: 0.00488368
Epoch [195/300], Train Loss: 0.005638
Validation Loss: 0.00488315
Epoch [196/300], Train Loss: 0.005623
Validation Loss: 0.00488064
Epoch [197/300], Train Loss: 0.005642
Validation Loss: 0.00487985
Epoch [198/300], Train Loss: 0.005629
Validation Loss: 0.00488236
Epoch [199/300], Train Loss: 0.005627
Validation Loss: 0.00488472
Epoch [200/300], Train Loss: 0.005656
Validation Loss: 0.00487846
Epoch [201/300], Train Loss: 0.005611
Validation Loss: 0.00488241
Epoch [202/300], Train Loss: 0.005614
Validation Loss: 0.00487771
Epoch [203/300], Train Loss: 0.005614
Validation Loss: 0.00487548
Epoch [204/300], Train Loss: 0.005636
Validation Loss: 0.00487144
Epoch [205/300], Train Loss: 0.005616
Validation Loss: 0.00487014
Epoch [206/300], Train Loss: 0.005624
Validation Loss: 0.00486987
Epoch [207/300], Train Loss: 0.005611
Validation Loss: 0.00486795
Epoch [208/300], Train Loss: 0.005605
Validation Loss: 0.00486791
Epoch [209/300], Train Loss: 0.005630
Validation Loss: 0.00486811
Epoch [210/300], Train Loss: 0.005596
Validation Loss: 0.00486911
Epoch [211/300], Train Loss: 0.005600
Validation Loss: 0.00486318
Epoch [212/300], Train Loss: 0.005593
Validation Loss: 0.00486189
Epoch [213/300], Train Loss: 0.005607
Validation Loss: 0.00486154
Epoch [214/300], Train Loss: 0.005598
Validation Loss: 0.00485938
Epoch [215/300], Train Loss: 0.005599
Validation Loss: 0.00485845
Epoch [216/300], Train Loss: 0.005597
Validation Loss: 0.00485730
Epoch [217/300], Train Loss: 0.005571
Validation Loss: 0.00485565
Epoch [218/300], Train Loss: 0.005613
Validation Loss: 0.00485474
Epoch [219/300], Train Loss: 0.005585
Validation Loss: 0.00485344
Epoch [220/300], Train Loss: 0.005595
Validation Loss: 0.00485189
Epoch [221/300], Train Loss: 0.005586
Validation Loss: 0.00485068
Epoch [222/300], Train Loss: 0.005586
Validation Loss: 0.00484868
Epoch [223/300], Train Loss: 0.005575
Validation Loss: 0.00484700
Epoch [224/300], Train Loss: 0.005574
Validation Loss: 0.00484519
Epoch [225/300], Train Loss: 0.005564
Validation Loss: 0.00484605
Epoch [226/300], Train Loss: 0.005586
Validation Loss: 0.00484221
Epoch [227/300], Train Loss: 0.005553
Validation Loss: 0.00484352
Epoch [228/300], Train Loss: 0.005608
Validation Loss: 0.00487056
Epoch [229/300], Train Loss: 0.005569
Validation Loss: 0.00484697
Epoch [230/300], Train Loss: 0.005576
Validation Loss: 0.00483632
Epoch [231/300], Train Loss: 0.005561
Validation Loss: 0.00482843
Epoch [232/300], Train Loss: 0.005574
Validation Loss: 0.00482788
Epoch [233/300], Train Loss: 0.005570
Validation Loss: 0.00482630
Epoch [234/300], Train Loss: 0.005563
Validation Loss: 0.00483041
Epoch [235/300], Train Loss: 0.005560
Validation Loss: 0.00482616
Epoch [236/300], Train Loss: 0.005565
Validation Loss: 0.00482851
Epoch [237/300], Train Loss: 0.005624
Validation Loss: 0.00483906
Epoch [238/300], Train Loss: 0.005546
Validation Loss: 0.00483072
Epoch [239/300], Train Loss: 0.005547
Validation Loss: 0.00482262
Epoch [240/300], Train Loss: 0.005554
Validation Loss: 0.00481128
Epoch [241/300], Train Loss: 0.005541
Validation Loss: 0.00480884
Epoch [242/300], Train Loss: 0.005535
Validation Loss: 0.00480630
Epoch [243/300], Train Loss: 0.005542
Validation Loss: 0.00480330
Epoch [244/300], Train Loss: 0.005519
Validation Loss: 0.00480166
Epoch [245/300], Train Loss: 0.005525
Validation Loss: 0.00479902
Epoch [246/300], Train Loss: 0.005507
Validation Loss: 0.00479668
Epoch [247/300], Train Loss: 0.005523
Validation Loss: 0.00480612
Epoch [248/300], Train Loss: 0.005511
Validation Loss: 0.00480051
Epoch [249/300], Train Loss: 0.005519
Validation Loss: 0.00479155
Epoch [250/300], Train Loss: 0.005523
Validation Loss: 0.00479343
Epoch [251/300], Train Loss: 0.005503
Validation Loss: 0.00480052
Epoch [252/300], Train Loss: 0.005506
Validation Loss: 0.00479409
Epoch [253/300], Train Loss: 0.005490
Validation Loss: 0.00478192
Epoch [254/300], Train Loss: 0.005509
Validation Loss: 0.00483139
Epoch [255/300], Train Loss: 0.005556
Validation Loss: 0.00483497
Epoch [256/300], Train Loss: 0.005549
Validation Loss: 0.00481604
Epoch [257/300], Train Loss: 0.005542
Validation Loss: 0.00479929
Epoch [258/300], Train Loss: 0.005538
Validation Loss: 0.00479692
Epoch [259/300], Train Loss: 0.005532
Validation Loss: 0.00479470
Epoch [260/300], Train Loss: 0.005544
Validation Loss: 0.00479316
Epoch [261/300], Train Loss: 0.005525
Validation Loss: 0.00479237
Epoch [262/300], Train Loss: 0.005513
Validation Loss: 0.00478869
Epoch [263/300], Train Loss: 0.005516
Validation Loss: 0.00478714
Early stopping triggered

Evaluating model for: Router
Run 63/72 completed in 720.53 seconds with: {'MAE': np.float32(0.21080124), 'MSE': np.float32(0.07566332), 'RMSE': np.float32(0.27506965), 'SAE': np.float32(0.0008633851), 'NDE': np.float32(0.013758253)}

Run 64/72: hidden=512, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Router
Dataset length: 1091 windows

Epoch [1/300], Train Loss: 0.086359
Validation Loss: 0.07051460
Epoch [2/300], Train Loss: 0.058729
Validation Loss: 0.03743273
Epoch [3/300], Train Loss: 0.020717
Validation Loss: 0.01292740
Epoch [4/300], Train Loss: 0.008582
Validation Loss: 0.00905803
Epoch [5/300], Train Loss: 0.008272
Validation Loss: 0.00553992
Epoch [6/300], Train Loss: 0.006910
Validation Loss: 0.00565429
Epoch [7/300], Train Loss: 0.006452
Validation Loss: 0.00579474
Epoch [8/300], Train Loss: 0.006344
Validation Loss: 0.00552199
Epoch [9/300], Train Loss: 0.006305
Validation Loss: 0.00543629
Epoch [10/300], Train Loss: 0.006210
Validation Loss: 0.00545585
Epoch [11/300], Train Loss: 0.006241
Validation Loss: 0.00544042
Epoch [12/300], Train Loss: 0.006202
Validation Loss: 0.00542468
Epoch [13/300], Train Loss: 0.006193
Validation Loss: 0.00540735
Epoch [14/300], Train Loss: 0.006205
Validation Loss: 0.00540202
Epoch [15/300], Train Loss: 0.006202
Validation Loss: 0.00540016
Epoch [16/300], Train Loss: 0.006180
Validation Loss: 0.00539701
Epoch [17/300], Train Loss: 0.006177
Validation Loss: 0.00538703
Epoch [18/300], Train Loss: 0.006151
Validation Loss: 0.00537562
Epoch [19/300], Train Loss: 0.006180
Validation Loss: 0.00536935
Epoch [20/300], Train Loss: 0.006159
Validation Loss: 0.00536493
Epoch [21/300], Train Loss: 0.006161
Validation Loss: 0.00536144
Epoch [22/300], Train Loss: 0.006137
Validation Loss: 0.00535292
Epoch [23/300], Train Loss: 0.006127
Validation Loss: 0.00535386
Epoch [24/300], Train Loss: 0.006125
Validation Loss: 0.00534931
Epoch [25/300], Train Loss: 0.006113
Validation Loss: 0.00532765
Epoch [26/300], Train Loss: 0.006100
Validation Loss: 0.00532270
Epoch [27/300], Train Loss: 0.006091
Validation Loss: 0.00531419
Epoch [28/300], Train Loss: 0.006115
Validation Loss: 0.00530664
Epoch [29/300], Train Loss: 0.006097
Validation Loss: 0.00530038
Epoch [30/300], Train Loss: 0.006087
Validation Loss: 0.00529155
Epoch [31/300], Train Loss: 0.006085
Validation Loss: 0.00528658
Epoch [32/300], Train Loss: 0.006094
Validation Loss: 0.00527865
Epoch [33/300], Train Loss: 0.006065
Validation Loss: 0.00527220
Epoch [34/300], Train Loss: 0.006047
Validation Loss: 0.00526600
Epoch [35/300], Train Loss: 0.006056
Validation Loss: 0.00525981
Epoch [36/300], Train Loss: 0.006059
Validation Loss: 0.00525795
Epoch [37/300], Train Loss: 0.006039
Validation Loss: 0.00525418
Epoch [38/300], Train Loss: 0.006041
Validation Loss: 0.00523976
Epoch [39/300], Train Loss: 0.005997
Validation Loss: 0.00523525
Epoch [40/300], Train Loss: 0.006024
Validation Loss: 0.00522808
Epoch [41/300], Train Loss: 0.006019
Validation Loss: 0.00522322
Epoch [42/300], Train Loss: 0.005988
Validation Loss: 0.00521326
Epoch [43/300], Train Loss: 0.005999
Validation Loss: 0.00520727
Epoch [44/300], Train Loss: 0.005993
Validation Loss: 0.00520165
Epoch [45/300], Train Loss: 0.005970
Validation Loss: 0.00519376
Epoch [46/300], Train Loss: 0.005989
Validation Loss: 0.00518676
Epoch [47/300], Train Loss: 0.005945
Validation Loss: 0.00518246
Epoch [48/300], Train Loss: 0.005973
Validation Loss: 0.00517388
Epoch [49/300], Train Loss: 0.005974
Validation Loss: 0.00516753
Epoch [50/300], Train Loss: 0.005947
Validation Loss: 0.00516247
Epoch [51/300], Train Loss: 0.005932
Validation Loss: 0.00515618
Epoch [52/300], Train Loss: 0.005936
Validation Loss: 0.00514739
Epoch [53/300], Train Loss: 0.005931
Validation Loss: 0.00514070
Epoch [54/300], Train Loss: 0.005916
Validation Loss: 0.00513750
Epoch [55/300], Train Loss: 0.005912
Validation Loss: 0.00513306
Epoch [56/300], Train Loss: 0.005906
Validation Loss: 0.00512303
Epoch [57/300], Train Loss: 0.005890
Validation Loss: 0.00511494
Epoch [58/300], Train Loss: 0.005890
Validation Loss: 0.00510503
Epoch [59/300], Train Loss: 0.005872
Validation Loss: 0.00509806
Epoch [60/300], Train Loss: 0.005862
Validation Loss: 0.00508972
Epoch [61/300], Train Loss: 0.005838
Validation Loss: 0.00508231
Epoch [62/300], Train Loss: 0.005841
Validation Loss: 0.00507576
Epoch [63/300], Train Loss: 0.005856
Validation Loss: 0.00507913
Epoch [64/300], Train Loss: 0.005837
Validation Loss: 0.00506264
Epoch [65/300], Train Loss: 0.005832
Validation Loss: 0.00505847
Epoch [66/300], Train Loss: 0.005851
Validation Loss: 0.00508584
Epoch [67/300], Train Loss: 0.005849
Validation Loss: 0.00504817
Epoch [68/300], Train Loss: 0.005833
Validation Loss: 0.00504706
Epoch [69/300], Train Loss: 0.005811
Validation Loss: 0.00504617
Epoch [70/300], Train Loss: 0.005848
Validation Loss: 0.00503165
Epoch [71/300], Train Loss: 0.005858
Validation Loss: 0.00504326
Epoch [72/300], Train Loss: 0.005797
Validation Loss: 0.00504529
Epoch [73/300], Train Loss: 0.005769
Validation Loss: 0.00505237
Epoch [74/300], Train Loss: 0.005839
Validation Loss: 0.00505940
Epoch [75/300], Train Loss: 0.005767
Validation Loss: 0.00503455
Epoch [76/300], Train Loss: 0.005782
Validation Loss: 0.00501126
Epoch [77/300], Train Loss: 0.005804
Validation Loss: 0.00500404
Epoch [78/300], Train Loss: 0.005823
Validation Loss: 0.00502164
Epoch [79/300], Train Loss: 0.005850
Validation Loss: 0.00508496
Epoch [80/300], Train Loss: 0.005822
Validation Loss: 0.00501844
Epoch [81/300], Train Loss: 0.005788
Validation Loss: 0.00502991
Epoch [82/300], Train Loss: 0.005778
Validation Loss: 0.00500012
Epoch [83/300], Train Loss: 0.005752
Validation Loss: 0.00499196
Epoch [84/300], Train Loss: 0.005781
Validation Loss: 0.00497992
Epoch [85/300], Train Loss: 0.005765
Validation Loss: 0.00498291
Epoch [86/300], Train Loss: 0.005766
Validation Loss: 0.00498099
Epoch [87/300], Train Loss: 0.005753
Validation Loss: 0.00497267
Epoch [88/300], Train Loss: 0.005742
Validation Loss: 0.00497635
Epoch [89/300], Train Loss: 0.005745
Validation Loss: 0.00496582
Epoch [90/300], Train Loss: 0.005755
Validation Loss: 0.00496245
Epoch [91/300], Train Loss: 0.005745
Validation Loss: 0.00496089
Epoch [92/300], Train Loss: 0.005747
Validation Loss: 0.00496268
Epoch [93/300], Train Loss: 0.005761
Validation Loss: 0.00498018
Epoch [94/300], Train Loss: 0.005765
Validation Loss: 0.00495736
Epoch [95/300], Train Loss: 0.005730
Validation Loss: 0.00495159
Epoch [96/300], Train Loss: 0.005715
Validation Loss: 0.00494689
Epoch [97/300], Train Loss: 0.005731
Validation Loss: 0.00494541
Epoch [98/300], Train Loss: 0.005716
Validation Loss: 0.00494431
Epoch [99/300], Train Loss: 0.005709
Validation Loss: 0.00494355
Epoch [100/300], Train Loss: 0.005719
Validation Loss: 0.00494938
Epoch [101/300], Train Loss: 0.005718
Validation Loss: 0.00493888
Epoch [102/300], Train Loss: 0.005726
Validation Loss: 0.00493474
Epoch [103/300], Train Loss: 0.005689
Validation Loss: 0.00493096
Epoch [104/300], Train Loss: 0.005688
Validation Loss: 0.00493135
Epoch [105/300], Train Loss: 0.005700
Validation Loss: 0.00493931
Epoch [106/300], Train Loss: 0.005723
Validation Loss: 0.00492445
Epoch [107/300], Train Loss: 0.005691
Validation Loss: 0.00492254
Epoch [108/300], Train Loss: 0.005688
Validation Loss: 0.00492386
Epoch [109/300], Train Loss: 0.005688
Validation Loss: 0.00491882
Epoch [110/300], Train Loss: 0.005681
Validation Loss: 0.00491683
Epoch [111/300], Train Loss: 0.005673
Validation Loss: 0.00491645
Epoch [112/300], Train Loss: 0.005686
Validation Loss: 0.00491324
Epoch [113/300], Train Loss: 0.005665
Validation Loss: 0.00491104
Epoch [114/300], Train Loss: 0.005686
Validation Loss: 0.00491046
Epoch [115/300], Train Loss: 0.005685
Validation Loss: 0.00490916
Epoch [116/300], Train Loss: 0.005669
Validation Loss: 0.00490529
Epoch [117/300], Train Loss: 0.005656
Validation Loss: 0.00490324
Epoch [118/300], Train Loss: 0.005662
Validation Loss: 0.00490161
Epoch [119/300], Train Loss: 0.005660
Validation Loss: 0.00490087
Epoch [120/300], Train Loss: 0.005664
Validation Loss: 0.00489965
Epoch [121/300], Train Loss: 0.005656
Validation Loss: 0.00489828
Epoch [122/300], Train Loss: 0.005649
Validation Loss: 0.00489493
Epoch [123/300], Train Loss: 0.005664
Validation Loss: 0.00489242
Epoch [124/300], Train Loss: 0.005660
Validation Loss: 0.00489083
Epoch [125/300], Train Loss: 0.005647
Validation Loss: 0.00488953
Epoch [126/300], Train Loss: 0.005649
Validation Loss: 0.00488861
Epoch [127/300], Train Loss: 0.005651
Validation Loss: 0.00488603
Epoch [128/300], Train Loss: 0.005656
Validation Loss: 0.00488561
Epoch [129/300], Train Loss: 0.005645
Validation Loss: 0.00488395
Epoch [130/300], Train Loss: 0.005639
Validation Loss: 0.00488605
Epoch [131/300], Train Loss: 0.005634
Validation Loss: 0.00488045
Epoch [132/300], Train Loss: 0.005637
Validation Loss: 0.00487859
Epoch [133/300], Train Loss: 0.005651
Validation Loss: 0.00487599
Epoch [134/300], Train Loss: 0.005614
Validation Loss: 0.00487447
Epoch [135/300], Train Loss: 0.005631
Validation Loss: 0.00487246
Epoch [136/300], Train Loss: 0.005628
Validation Loss: 0.00487156
Epoch [137/300], Train Loss: 0.005617
Validation Loss: 0.00487008
Epoch [138/300], Train Loss: 0.005652
Validation Loss: 0.00486780
Epoch [139/300], Train Loss: 0.005667
Validation Loss: 0.00486642
Epoch [140/300], Train Loss: 0.005649
Validation Loss: 0.00486465
Epoch [141/300], Train Loss: 0.005642
Validation Loss: 0.00486474
Epoch [142/300], Train Loss: 0.005661
Validation Loss: 0.00486239
Epoch [143/300], Train Loss: 0.005653
Validation Loss: 0.00486058
Epoch [144/300], Train Loss: 0.005610
Validation Loss: 0.00486650
Epoch [145/300], Train Loss: 0.005618
Validation Loss: 0.00485758
Epoch [146/300], Train Loss: 0.005636
Validation Loss: 0.00485606
Epoch [147/300], Train Loss: 0.005627
Validation Loss: 0.00485522
Epoch [148/300], Train Loss: 0.005615
Validation Loss: 0.00485838
Epoch [149/300], Train Loss: 0.005610
Validation Loss: 0.00485144
Epoch [150/300], Train Loss: 0.005601
Validation Loss: 0.00484689
Epoch [151/300], Train Loss: 0.005601
Validation Loss: 0.00484582
Epoch [152/300], Train Loss: 0.005595
Validation Loss: 0.00484618
Epoch [153/300], Train Loss: 0.005606
Validation Loss: 0.00484951
Epoch [154/300], Train Loss: 0.005581
Validation Loss: 0.00484536
Epoch [155/300], Train Loss: 0.005595
Validation Loss: 0.00485117
Epoch [156/300], Train Loss: 0.005601
Validation Loss: 0.00484042
Epoch [157/300], Train Loss: 0.005601
Validation Loss: 0.00484058
Epoch [158/300], Train Loss: 0.005595
Validation Loss: 0.00483705
Epoch [159/300], Train Loss: 0.005606
Validation Loss: 0.00483117
Epoch [160/300], Train Loss: 0.005628
Validation Loss: 0.00483019
Epoch [161/300], Train Loss: 0.005628
Validation Loss: 0.00482823
Epoch [162/300], Train Loss: 0.005597
Validation Loss: 0.00482724
Epoch [163/300], Train Loss: 0.005568
Validation Loss: 0.00482800
Epoch [164/300], Train Loss: 0.005601
Validation Loss: 0.00482487
Epoch [165/300], Train Loss: 0.005583
Validation Loss: 0.00482049
Epoch [166/300], Train Loss: 0.005565
Validation Loss: 0.00481214
Epoch [167/300], Train Loss: 0.005570
Validation Loss: 0.00482012
Epoch [168/300], Train Loss: 0.005560
Validation Loss: 0.00480712
Epoch [169/300], Train Loss: 0.005577
Validation Loss: 0.00480835
Epoch [170/300], Train Loss: 0.005573
Validation Loss: 0.00483935
Epoch [171/300], Train Loss: 0.005610
Validation Loss: 0.00483638
Epoch [172/300], Train Loss: 0.005608
Validation Loss: 0.00483256
Epoch [173/300], Train Loss: 0.005599
Validation Loss: 0.00482673
Epoch [174/300], Train Loss: 0.005581
Validation Loss: 0.00481815
Epoch [175/300], Train Loss: 0.005564
Validation Loss: 0.00480239
Epoch [176/300], Train Loss: 0.005570
Validation Loss: 0.00481054
Epoch [177/300], Train Loss: 0.005552
Validation Loss: 0.00480153
Epoch [178/300], Train Loss: 0.005568
Validation Loss: 0.00481124
Epoch [179/300], Train Loss: 0.005547
Validation Loss: 0.00479439
Epoch [180/300], Train Loss: 0.005549
Validation Loss: 0.00479108
Epoch [181/300], Train Loss: 0.005543
Validation Loss: 0.00478937
Epoch [182/300], Train Loss: 0.005549
Validation Loss: 0.00477884
Epoch [183/300], Train Loss: 0.005514
Validation Loss: 0.00477086
Epoch [184/300], Train Loss: 0.005529
Validation Loss: 0.00477523
Epoch [185/300], Train Loss: 0.005524
Validation Loss: 0.00476036
Epoch [186/300], Train Loss: 0.005516
Validation Loss: 0.00476916
Epoch [187/300], Train Loss: 0.005503
Validation Loss: 0.00475155
Epoch [188/300], Train Loss: 0.005493
Validation Loss: 0.00476796
Epoch [189/300], Train Loss: 0.005516
Validation Loss: 0.00473909
Epoch [190/300], Train Loss: 0.005513
Validation Loss: 0.00475951
Epoch [191/300], Train Loss: 0.005537
Validation Loss: 0.00476547
Epoch [192/300], Train Loss: 0.005499
Validation Loss: 0.00473188
Epoch [193/300], Train Loss: 0.005483
Validation Loss: 0.00474800
Epoch [194/300], Train Loss: 0.005514
Validation Loss: 0.00473580
Epoch [195/300], Train Loss: 0.005470
Validation Loss: 0.00472050
Epoch [196/300], Train Loss: 0.005449
Validation Loss: 0.00470557
Epoch [197/300], Train Loss: 0.005451
Validation Loss: 0.00471773
Epoch [198/300], Train Loss: 0.005464
Validation Loss: 0.00472943
Epoch [199/300], Train Loss: 0.005451
Validation Loss: 0.00475809
Epoch [200/300], Train Loss: 0.005472
Validation Loss: 0.00480114
Epoch [201/300], Train Loss: 0.005532
Validation Loss: 0.00478272
Epoch [202/300], Train Loss: 0.005511
Validation Loss: 0.00474241
Epoch [203/300], Train Loss: 0.005458
Validation Loss: 0.00472909
Epoch [204/300], Train Loss: 0.005456
Validation Loss: 0.00468529
Epoch [205/300], Train Loss: 0.005436
Validation Loss: 0.00473958
Epoch [206/300], Train Loss: 0.005488
Validation Loss: 0.00470910
Epoch [207/300], Train Loss: 0.005438
Validation Loss: 0.00471143
Epoch [208/300], Train Loss: 0.005443
Validation Loss: 0.00465729
Epoch [209/300], Train Loss: 0.005470
Validation Loss: 0.00470239
Epoch [210/300], Train Loss: 0.005441
Validation Loss: 0.00465256
Epoch [211/300], Train Loss: 0.005459
Validation Loss: 0.00465312
Epoch [212/300], Train Loss: 0.005430
Validation Loss: 0.00467746
Epoch [213/300], Train Loss: 0.005392
Validation Loss: 0.00477904
Epoch [214/300], Train Loss: 0.005399
Validation Loss: 0.00463545
Epoch [215/300], Train Loss: 0.005398
Validation Loss: 0.00474705
Epoch [216/300], Train Loss: 0.005504
Validation Loss: 0.00474420
Epoch [217/300], Train Loss: 0.005471
Validation Loss: 0.00469078
Epoch [218/300], Train Loss: 0.005400
Validation Loss: 0.00470251
Epoch [219/300], Train Loss: 0.005405
Validation Loss: 0.00462692
Epoch [220/300], Train Loss: 0.005391
Validation Loss: 0.00466229
Epoch [221/300], Train Loss: 0.005388
Validation Loss: 0.00464451
Epoch [222/300], Train Loss: 0.005404
Validation Loss: 0.00468295
Epoch [223/300], Train Loss: 0.005424
Validation Loss: 0.00461576
Epoch [224/300], Train Loss: 0.005480
Validation Loss: 0.00474279
Epoch [225/300], Train Loss: 0.005466
Validation Loss: 0.00470841
Epoch [226/300], Train Loss: 0.005425
Validation Loss: 0.00462644
Epoch [227/300], Train Loss: 0.005358
Validation Loss: 0.00461476
Epoch [228/300], Train Loss: 0.005345
Validation Loss: 0.00460678
Epoch [229/300], Train Loss: 0.005361
Validation Loss: 0.00467668
Epoch [230/300], Train Loss: 0.005446
Validation Loss: 0.00467584
Epoch [231/300], Train Loss: 0.005391
Validation Loss: 0.00461194
Epoch [232/300], Train Loss: 0.005327
Validation Loss: 0.00462588
Epoch [233/300], Train Loss: 0.005389
Validation Loss: 0.00461012
Epoch [234/300], Train Loss: 0.005366
Validation Loss: 0.00459131
Epoch [235/300], Train Loss: 0.005404
Validation Loss: 0.00459788
Epoch [236/300], Train Loss: 0.005380
Validation Loss: 0.00468379
Epoch [237/300], Train Loss: 0.005471
Validation Loss: 0.00470408
Epoch [238/300], Train Loss: 0.005427
Validation Loss: 0.00464024
Epoch [239/300], Train Loss: 0.005326
Validation Loss: 0.00460275
Epoch [240/300], Train Loss: 0.005346
Validation Loss: 0.00458414
Epoch [241/300], Train Loss: 0.005310
Validation Loss: 0.00458683
Epoch [242/300], Train Loss: 0.005302
Validation Loss: 0.00458981
Epoch [243/300], Train Loss: 0.005335
Validation Loss: 0.00459022
Epoch [244/300], Train Loss: 0.005332
Validation Loss: 0.00468661
Epoch [245/300], Train Loss: 0.005462
Validation Loss: 0.00470862
Epoch [246/300], Train Loss: 0.005438
Validation Loss: 0.00467096
Epoch [247/300], Train Loss: 0.005346
Validation Loss: 0.00465314
Epoch [248/300], Train Loss: 0.005323
Validation Loss: 0.00458806
Epoch [249/300], Train Loss: 0.005323
Validation Loss: 0.00457069
Epoch [250/300], Train Loss: 0.005319
Validation Loss: 0.00454977
Epoch [251/300], Train Loss: 0.005264
Validation Loss: 0.00456714
Epoch [252/300], Train Loss: 0.005288
Validation Loss: 0.00464522
Epoch [253/300], Train Loss: 0.005314
Validation Loss: 0.00456345
Epoch [254/300], Train Loss: 0.005274
Validation Loss: 0.00453915
Epoch [255/300], Train Loss: 0.005307
Validation Loss: 0.00454565
Epoch [256/300], Train Loss: 0.005255
Validation Loss: 0.00453895
Epoch [257/300], Train Loss: 0.005253
Validation Loss: 0.00453152
Epoch [258/300], Train Loss: 0.005254
Validation Loss: 0.00453032
Epoch [259/300], Train Loss: 0.005250
Validation Loss: 0.00452780
Epoch [260/300], Train Loss: 0.005258
Validation Loss: 0.00452604
Epoch [261/300], Train Loss: 0.005244
Validation Loss: 0.00452580
Epoch [262/300], Train Loss: 0.005241
Validation Loss: 0.00457559
Epoch [263/300], Train Loss: 0.005239
Validation Loss: 0.00452131
Epoch [264/300], Train Loss: 0.005260
Validation Loss: 0.00457817
Epoch [265/300], Train Loss: 0.005266
Validation Loss: 0.00452445
Epoch [266/300], Train Loss: 0.005293
Validation Loss: 0.00453217
Epoch [267/300], Train Loss: 0.005252
Validation Loss: 0.00451942
Epoch [268/300], Train Loss: 0.005256
Validation Loss: 0.00459899
Epoch [269/300], Train Loss: 0.005240
Validation Loss: 0.00453592
Epoch [270/300], Train Loss: 0.005241
Validation Loss: 0.00451121
Epoch [271/300], Train Loss: 0.005263
Validation Loss: 0.00458307
Epoch [272/300], Train Loss: 0.005232
Validation Loss: 0.00453997
Epoch [273/300], Train Loss: 0.005255
Validation Loss: 0.00464569
Epoch [274/300], Train Loss: 0.005267
Validation Loss: 0.00461333
Epoch [275/300], Train Loss: 0.005285
Validation Loss: 0.00456794
Epoch [276/300], Train Loss: 0.005222
Validation Loss: 0.00458684
Epoch [277/300], Train Loss: 0.005277
Validation Loss: 0.00456843
Epoch [278/300], Train Loss: 0.005268
Validation Loss: 0.00457521
Epoch [279/300], Train Loss: 0.005289
Validation Loss: 0.00451101
Epoch [280/300], Train Loss: 0.005240
Validation Loss: 0.00450337
Epoch [281/300], Train Loss: 0.005227
Validation Loss: 0.00455112
Epoch [282/300], Train Loss: 0.005277
Validation Loss: 0.00451301
Epoch [283/300], Train Loss: 0.005263
Validation Loss: 0.00452237
Epoch [284/300], Train Loss: 0.005239
Validation Loss: 0.00450292
Epoch [285/300], Train Loss: 0.005215
Validation Loss: 0.00453165
Epoch [286/300], Train Loss: 0.005252
Validation Loss: 0.00449725
Epoch [287/300], Train Loss: 0.005218
Validation Loss: 0.00450402
Epoch [288/300], Train Loss: 0.005211
Validation Loss: 0.00449197
Epoch [289/300], Train Loss: 0.005194
Validation Loss: 0.00449477
Epoch [290/300], Train Loss: 0.005194
Validation Loss: 0.00450617
Epoch [291/300], Train Loss: 0.005197
Validation Loss: 0.00450366
Epoch [292/300], Train Loss: 0.005194
Validation Loss: 0.00451447
Epoch [293/300], Train Loss: 0.005196
Validation Loss: 0.00449948
Epoch [294/300], Train Loss: 0.005189
Validation Loss: 0.00449743
Epoch [295/300], Train Loss: 0.005185
Validation Loss: 0.00449251
Epoch [296/300], Train Loss: 0.005185
Validation Loss: 0.00448562
Epoch [297/300], Train Loss: 0.005177
Validation Loss: 0.00453519
Epoch [298/300], Train Loss: 0.005222
Validation Loss: 0.00448207
Epoch [299/300], Train Loss: 0.005203
Validation Loss: 0.00450983
Epoch [300/300], Train Loss: 0.005228
Validation Loss: 0.00449325

Evaluating model for: Router
Run 64/72 completed in 1053.24 seconds with: {'MAE': np.float32(0.20859577), 'MSE': np.float32(0.07185802), 'RMSE': np.float32(0.26806346), 'SAE': np.float32(0.0005995379), 'NDE': np.float32(0.013407821)}

Run 65/72: hidden=512, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Router
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.105898
Validation Loss: 0.09186565
Epoch [2/300], Train Loss: 0.080029
Validation Loss: 0.06328033
Epoch [3/300], Train Loss: 0.046420
Validation Loss: 0.02077211
Epoch [4/300], Train Loss: 0.012968
Validation Loss: 0.01123063
Epoch [5/300], Train Loss: 0.008056
Validation Loss: 0.00844217
Epoch [6/300], Train Loss: 0.008368
Validation Loss: 0.00614880
Epoch [7/300], Train Loss: 0.006053
Validation Loss: 0.00594252
Epoch [8/300], Train Loss: 0.006216
Validation Loss: 0.00525920
Epoch [9/300], Train Loss: 0.005934
Validation Loss: 0.00554655
Epoch [10/300], Train Loss: 0.005815
Validation Loss: 0.00525139
Epoch [11/300], Train Loss: 0.005809
Validation Loss: 0.00523616
Epoch [12/300], Train Loss: 0.005728
Validation Loss: 0.00527056
Epoch [13/300], Train Loss: 0.005754
Validation Loss: 0.00523285
Epoch [14/300], Train Loss: 0.005756
Validation Loss: 0.00523021
Epoch [15/300], Train Loss: 0.005712
Validation Loss: 0.00523634
Epoch [16/300], Train Loss: 0.005762
Validation Loss: 0.00523396
Epoch [17/300], Train Loss: 0.005706
Validation Loss: 0.00522645
Epoch [18/300], Train Loss: 0.005718
Validation Loss: 0.00522651
Epoch [19/300], Train Loss: 0.005724
Validation Loss: 0.00522927
Epoch [20/300], Train Loss: 0.005749
Validation Loss: 0.00522180
Epoch [21/300], Train Loss: 0.005772
Validation Loss: 0.00522474
Epoch [22/300], Train Loss: 0.005754
Validation Loss: 0.00522903
Epoch [23/300], Train Loss: 0.005732
Validation Loss: 0.00521573
Epoch [24/300], Train Loss: 0.005751
Validation Loss: 0.00522170
Epoch [25/300], Train Loss: 0.005719
Validation Loss: 0.00522787
Epoch [26/300], Train Loss: 0.005726
Validation Loss: 0.00521069
Epoch [27/300], Train Loss: 0.005700
Validation Loss: 0.00521735
Epoch [28/300], Train Loss: 0.005692
Validation Loss: 0.00521941
Epoch [29/300], Train Loss: 0.005700
Validation Loss: 0.00520614
Epoch [30/300], Train Loss: 0.005686
Validation Loss: 0.00521804
Epoch [31/300], Train Loss: 0.005691
Validation Loss: 0.00520737
Epoch [32/300], Train Loss: 0.005715
Validation Loss: 0.00520482
Epoch [33/300], Train Loss: 0.005698
Validation Loss: 0.00521453
Epoch [34/300], Train Loss: 0.005694
Validation Loss: 0.00519812
Epoch [35/300], Train Loss: 0.005690
Validation Loss: 0.00520291
Epoch [36/300], Train Loss: 0.005662
Validation Loss: 0.00520509
Epoch [37/300], Train Loss: 0.005674
Validation Loss: 0.00519334
Epoch [38/300], Train Loss: 0.005687
Validation Loss: 0.00519738
Epoch [39/300], Train Loss: 0.005714
Validation Loss: 0.00519954
Epoch [40/300], Train Loss: 0.005721
Validation Loss: 0.00519031
Epoch [41/300], Train Loss: 0.005694
Validation Loss: 0.00519865
Epoch [42/300], Train Loss: 0.005687
Validation Loss: 0.00518534
Epoch [43/300], Train Loss: 0.005677
Validation Loss: 0.00518472
Epoch [44/300], Train Loss: 0.005681
Validation Loss: 0.00519082
Epoch [45/300], Train Loss: 0.005676
Validation Loss: 0.00518580
Epoch [46/300], Train Loss: 0.005674
Validation Loss: 0.00517888
Epoch [47/300], Train Loss: 0.005686
Validation Loss: 0.00518542
Epoch [48/300], Train Loss: 0.005654
Validation Loss: 0.00517869
Epoch [49/300], Train Loss: 0.005652
Validation Loss: 0.00517385
Epoch [50/300], Train Loss: 0.005674
Validation Loss: 0.00518999
Epoch [51/300], Train Loss: 0.005689
Validation Loss: 0.00517076
Epoch [52/300], Train Loss: 0.005640
Validation Loss: 0.00518163
Epoch [53/300], Train Loss: 0.005656
Validation Loss: 0.00516991
Epoch [54/300], Train Loss: 0.005649
Validation Loss: 0.00516685
Epoch [55/300], Train Loss: 0.005673
Validation Loss: 0.00518197
Epoch [56/300], Train Loss: 0.005665
Validation Loss: 0.00516354
Epoch [57/300], Train Loss: 0.005639
Validation Loss: 0.00516811
Epoch [58/300], Train Loss: 0.005669
Validation Loss: 0.00516137
Epoch [59/300], Train Loss: 0.005644
Validation Loss: 0.00515903
Epoch [60/300], Train Loss: 0.005655
Validation Loss: 0.00516994
Epoch [61/300], Train Loss: 0.005674
Validation Loss: 0.00515513
Epoch [62/300], Train Loss: 0.005646
Validation Loss: 0.00516877
Epoch [63/300], Train Loss: 0.005653
Validation Loss: 0.00515376
Epoch [64/300], Train Loss: 0.005641
Validation Loss: 0.00515693
Epoch [65/300], Train Loss: 0.005662
Validation Loss: 0.00515039
Epoch [66/300], Train Loss: 0.005653
Validation Loss: 0.00515416
Epoch [67/300], Train Loss: 0.005662
Validation Loss: 0.00515361
Epoch [68/300], Train Loss: 0.005660
Validation Loss: 0.00515146
Epoch [69/300], Train Loss: 0.005670
Validation Loss: 0.00514318
Epoch [70/300], Train Loss: 0.005680
Validation Loss: 0.00515241
Epoch [71/300], Train Loss: 0.005662
Validation Loss: 0.00515556
Epoch [72/300], Train Loss: 0.005665
Validation Loss: 0.00513905
Epoch [73/300], Train Loss: 0.005635
Validation Loss: 0.00515046
Epoch [74/300], Train Loss: 0.005616
Validation Loss: 0.00513846
Epoch [75/300], Train Loss: 0.005672
Validation Loss: 0.00513776
Epoch [76/300], Train Loss: 0.005599
Validation Loss: 0.00513487
Epoch [77/300], Train Loss: 0.005648
Validation Loss: 0.00513696
Epoch [78/300], Train Loss: 0.005606
Validation Loss: 0.00513051
Epoch [79/300], Train Loss: 0.005673
Validation Loss: 0.00514198
Epoch [80/300], Train Loss: 0.005622
Validation Loss: 0.00512612
Epoch [81/300], Train Loss: 0.005645
Validation Loss: 0.00514119
Epoch [82/300], Train Loss: 0.005629
Validation Loss: 0.00512556
Epoch [83/300], Train Loss: 0.005624
Validation Loss: 0.00512376
Epoch [84/300], Train Loss: 0.005591
Validation Loss: 0.00512789
Epoch [85/300], Train Loss: 0.005648
Validation Loss: 0.00512530
Epoch [86/300], Train Loss: 0.005617
Validation Loss: 0.00512338
Epoch [87/300], Train Loss: 0.005594
Validation Loss: 0.00511674
Epoch [88/300], Train Loss: 0.005631
Validation Loss: 0.00514145
Epoch [89/300], Train Loss: 0.005637
Validation Loss: 0.00512088
Epoch [90/300], Train Loss: 0.005598
Validation Loss: 0.00511343
Epoch [91/300], Train Loss: 0.005580
Validation Loss: 0.00511754
Epoch [92/300], Train Loss: 0.005612
Validation Loss: 0.00512756
Epoch [93/300], Train Loss: 0.005577
Validation Loss: 0.00510910
Epoch [94/300], Train Loss: 0.005607
Validation Loss: 0.00511387
Epoch [95/300], Train Loss: 0.005581
Validation Loss: 0.00511952
Epoch [96/300], Train Loss: 0.005646
Validation Loss: 0.00510538
Epoch [97/300], Train Loss: 0.005604
Validation Loss: 0.00511136
Epoch [98/300], Train Loss: 0.005586
Validation Loss: 0.00510779
Epoch [99/300], Train Loss: 0.005601
Validation Loss: 0.00510258
Epoch [100/300], Train Loss: 0.005571
Validation Loss: 0.00510781
Epoch [101/300], Train Loss: 0.005605
Validation Loss: 0.00509989
Epoch [102/300], Train Loss: 0.005590
Validation Loss: 0.00510783
Epoch [103/300], Train Loss: 0.005585
Validation Loss: 0.00509825
Epoch [104/300], Train Loss: 0.005608
Validation Loss: 0.00509578
Epoch [105/300], Train Loss: 0.005580
Validation Loss: 0.00510705
Epoch [106/300], Train Loss: 0.005604
Validation Loss: 0.00509302
Epoch [107/300], Train Loss: 0.005579
Validation Loss: 0.00509888
Epoch [108/300], Train Loss: 0.005602
Validation Loss: 0.00509804
Epoch [109/300], Train Loss: 0.005572
Validation Loss: 0.00508985
Epoch [110/300], Train Loss: 0.005586
Validation Loss: 0.00509753
Epoch [111/300], Train Loss: 0.005595
Validation Loss: 0.00509038
Epoch [112/300], Train Loss: 0.005576
Validation Loss: 0.00510141
Epoch [113/300], Train Loss: 0.005585
Validation Loss: 0.00508540
Epoch [114/300], Train Loss: 0.005612
Validation Loss: 0.00509066
Epoch [115/300], Train Loss: 0.005565
Validation Loss: 0.00510027
Epoch [116/300], Train Loss: 0.005569
Validation Loss: 0.00508185
Epoch [117/300], Train Loss: 0.005557
Validation Loss: 0.00508915
Epoch [118/300], Train Loss: 0.005590
Validation Loss: 0.00508570
Epoch [119/300], Train Loss: 0.005567
Validation Loss: 0.00507893
Epoch [120/300], Train Loss: 0.005576
Validation Loss: 0.00508340
Epoch [121/300], Train Loss: 0.005590
Validation Loss: 0.00509114
Epoch [122/300], Train Loss: 0.005582
Validation Loss: 0.00507679
Epoch [123/300], Train Loss: 0.005563
Validation Loss: 0.00508383
Epoch [124/300], Train Loss: 0.005559
Validation Loss: 0.00507715
Epoch [125/300], Train Loss: 0.005560
Validation Loss: 0.00508144
Epoch [126/300], Train Loss: 0.005547
Validation Loss: 0.00507306
Epoch [127/300], Train Loss: 0.005574
Validation Loss: 0.00507381
Epoch [128/300], Train Loss: 0.005601
Validation Loss: 0.00508453
Epoch [129/300], Train Loss: 0.005546
Validation Loss: 0.00506899
Epoch [130/300], Train Loss: 0.005557
Validation Loss: 0.00507588
Epoch [131/300], Train Loss: 0.005564
Validation Loss: 0.00507167
Epoch [132/300], Train Loss: 0.005548
Validation Loss: 0.00506963
Epoch [133/300], Train Loss: 0.005542
Validation Loss: 0.00506958
Epoch [134/300], Train Loss: 0.005546
Validation Loss: 0.00506456
Epoch [135/300], Train Loss: 0.005539
Validation Loss: 0.00506752
Epoch [136/300], Train Loss: 0.005525
Validation Loss: 0.00507156
Epoch [137/300], Train Loss: 0.005567
Validation Loss: 0.00506321
Epoch [138/300], Train Loss: 0.005555
Validation Loss: 0.00507873
Epoch [139/300], Train Loss: 0.005548
Validation Loss: 0.00506074
Epoch [140/300], Train Loss: 0.005548
Validation Loss: 0.00507594
Epoch [141/300], Train Loss: 0.005537
Validation Loss: 0.00505983
Epoch [142/300], Train Loss: 0.005575
Validation Loss: 0.00506117
Epoch [143/300], Train Loss: 0.005541
Validation Loss: 0.00507674
Epoch [144/300], Train Loss: 0.005532
Validation Loss: 0.00505590
Epoch [145/300], Train Loss: 0.005537
Validation Loss: 0.00507103
Epoch [146/300], Train Loss: 0.005539
Validation Loss: 0.00505458
Epoch [147/300], Train Loss: 0.005545
Validation Loss: 0.00505457
Epoch [148/300], Train Loss: 0.005561
Validation Loss: 0.00506222
Epoch [149/300], Train Loss: 0.005540
Validation Loss: 0.00505848
Epoch [150/300], Train Loss: 0.005522
Validation Loss: 0.00505123
Epoch [151/300], Train Loss: 0.005530
Validation Loss: 0.00506012
Epoch [152/300], Train Loss: 0.005538
Validation Loss: 0.00505460
Epoch [153/300], Train Loss: 0.005515
Validation Loss: 0.00504993
Epoch [154/300], Train Loss: 0.005505
Validation Loss: 0.00505482
Epoch [155/300], Train Loss: 0.005542
Validation Loss: 0.00504990
Epoch [156/300], Train Loss: 0.005557
Validation Loss: 0.00504727
Epoch [157/300], Train Loss: 0.005545
Validation Loss: 0.00505108
Epoch [158/300], Train Loss: 0.005517
Validation Loss: 0.00504899
Epoch [159/300], Train Loss: 0.005519
Validation Loss: 0.00504677
Epoch [160/300], Train Loss: 0.005533
Validation Loss: 0.00504675
Epoch [161/300], Train Loss: 0.005533
Validation Loss: 0.00504947
Epoch [162/300], Train Loss: 0.005511
Validation Loss: 0.00504620
Epoch [163/300], Train Loss: 0.005547
Validation Loss: 0.00504177
Epoch [164/300], Train Loss: 0.005585
Validation Loss: 0.00505137
Epoch [165/300], Train Loss: 0.005560
Validation Loss: 0.00504113
Epoch [166/300], Train Loss: 0.005556
Validation Loss: 0.00508305
Epoch [167/300], Train Loss: 0.005517
Validation Loss: 0.00503999
Epoch [168/300], Train Loss: 0.005529
Validation Loss: 0.00504517
Epoch [169/300], Train Loss: 0.005491
Validation Loss: 0.00503989
Epoch [170/300], Train Loss: 0.005541
Validation Loss: 0.00503981
Epoch [171/300], Train Loss: 0.005521
Validation Loss: 0.00504005
Epoch [172/300], Train Loss: 0.005544
Validation Loss: 0.00504055
Epoch [173/300], Train Loss: 0.005508
Validation Loss: 0.00504132
Epoch [174/300], Train Loss: 0.005546
Validation Loss: 0.00503425
Epoch [175/300], Train Loss: 0.005537
Validation Loss: 0.00505163
Epoch [176/300], Train Loss: 0.005541
Validation Loss: 0.00503286
Epoch [177/300], Train Loss: 0.005524
Validation Loss: 0.00504803
Epoch [178/300], Train Loss: 0.005538
Validation Loss: 0.00503573
Epoch [179/300], Train Loss: 0.005558
Validation Loss: 0.00503153
Epoch [180/300], Train Loss: 0.005498
Validation Loss: 0.00503905
Epoch [181/300], Train Loss: 0.005526
Validation Loss: 0.00503266
Epoch [182/300], Train Loss: 0.005509
Validation Loss: 0.00503191
Epoch [183/300], Train Loss: 0.005497
Validation Loss: 0.00503484
Epoch [184/300], Train Loss: 0.005507
Validation Loss: 0.00503644
Epoch [185/300], Train Loss: 0.005524
Validation Loss: 0.00502750
Epoch [186/300], Train Loss: 0.005549
Validation Loss: 0.00503162
Epoch [187/300], Train Loss: 0.005527
Validation Loss: 0.00504138
Epoch [188/300], Train Loss: 0.005480
Validation Loss: 0.00502558
Epoch [189/300], Train Loss: 0.005551
Validation Loss: 0.00502718
Epoch [190/300], Train Loss: 0.005476
Validation Loss: 0.00503115
Epoch [191/300], Train Loss: 0.005503
Validation Loss: 0.00502634
Epoch [192/300], Train Loss: 0.005492
Validation Loss: 0.00502748
Epoch [193/300], Train Loss: 0.005523
Validation Loss: 0.00503227
Epoch [194/300], Train Loss: 0.005477
Validation Loss: 0.00502596
Epoch [195/300], Train Loss: 0.005497
Validation Loss: 0.00502590
Epoch [196/300], Train Loss: 0.005551
Validation Loss: 0.00503068
Epoch [197/300], Train Loss: 0.005536
Validation Loss: 0.00502070
Epoch [198/300], Train Loss: 0.005502
Validation Loss: 0.00503046
Epoch [199/300], Train Loss: 0.005488
Validation Loss: 0.00502962
Epoch [200/300], Train Loss: 0.005537
Validation Loss: 0.00501950
Epoch [201/300], Train Loss: 0.005501
Validation Loss: 0.00502758
Epoch [202/300], Train Loss: 0.005493
Validation Loss: 0.00502510
Epoch [203/300], Train Loss: 0.005506
Validation Loss: 0.00501808
Epoch [204/300], Train Loss: 0.005490
Validation Loss: 0.00503320
Epoch [205/300], Train Loss: 0.005525
Validation Loss: 0.00502268
Epoch [206/300], Train Loss: 0.005495
Validation Loss: 0.00501934
Epoch [207/300], Train Loss: 0.005509
Validation Loss: 0.00501595
Epoch [208/300], Train Loss: 0.005579
Validation Loss: 0.00501786
Epoch [209/300], Train Loss: 0.005518
Validation Loss: 0.00504425
Epoch [210/300], Train Loss: 0.005482
Validation Loss: 0.00501537
Epoch [211/300], Train Loss: 0.005527
Validation Loss: 0.00501588
Epoch [212/300], Train Loss: 0.005510
Validation Loss: 0.00502541
Epoch [213/300], Train Loss: 0.005496
Validation Loss: 0.00501500
Epoch [214/300], Train Loss: 0.005470
Validation Loss: 0.00501382
Epoch [215/300], Train Loss: 0.005490
Validation Loss: 0.00502182
Epoch [216/300], Train Loss: 0.005545
Validation Loss: 0.00501239
Epoch [217/300], Train Loss: 0.005516
Validation Loss: 0.00502444
Epoch [218/300], Train Loss: 0.005508
Validation Loss: 0.00501125
Epoch [219/300], Train Loss: 0.005499
Validation Loss: 0.00501813
Epoch [220/300], Train Loss: 0.005516
Validation Loss: 0.00502692
Epoch [221/300], Train Loss: 0.005505
Validation Loss: 0.00500966
Epoch [222/300], Train Loss: 0.005498
Validation Loss: 0.00501814
Epoch [223/300], Train Loss: 0.005481
Validation Loss: 0.00501341
Epoch [224/300], Train Loss: 0.005498
Validation Loss: 0.00501313
Epoch [225/300], Train Loss: 0.005485
Validation Loss: 0.00500841
Epoch [226/300], Train Loss: 0.005493
Validation Loss: 0.00501440
Epoch [227/300], Train Loss: 0.005491
Validation Loss: 0.00500923
Epoch [228/300], Train Loss: 0.005495
Validation Loss: 0.00501007
Epoch [229/300], Train Loss: 0.005484
Validation Loss: 0.00502842
Epoch [230/300], Train Loss: 0.005475
Validation Loss: 0.00500585
Epoch [231/300], Train Loss: 0.005508
Validation Loss: 0.00500553
Epoch [232/300], Train Loss: 0.005506
Validation Loss: 0.00503126
Epoch [233/300], Train Loss: 0.005494
Validation Loss: 0.00500987
Epoch [234/300], Train Loss: 0.005501
Validation Loss: 0.00500439
Epoch [235/300], Train Loss: 0.005472
Validation Loss: 0.00500926
Epoch [236/300], Train Loss: 0.005507
Validation Loss: 0.00501824
Epoch [237/300], Train Loss: 0.005477
Validation Loss: 0.00500324
Epoch [238/300], Train Loss: 0.005532
Validation Loss: 0.00500469
Epoch [239/300], Train Loss: 0.005528
Validation Loss: 0.00501872
Epoch [240/300], Train Loss: 0.005473
Validation Loss: 0.00500786
Epoch [241/300], Train Loss: 0.005463
Validation Loss: 0.00500182
Epoch [242/300], Train Loss: 0.005476
Validation Loss: 0.00500931
Epoch [243/300], Train Loss: 0.005502
Validation Loss: 0.00500586
Epoch [244/300], Train Loss: 0.005458
Validation Loss: 0.00500190
Epoch [245/300], Train Loss: 0.005487
Validation Loss: 0.00500728
Epoch [246/300], Train Loss: 0.005498
Validation Loss: 0.00500216
Epoch [247/300], Train Loss: 0.005494
Validation Loss: 0.00501199
Epoch [248/300], Train Loss: 0.005475
Validation Loss: 0.00500041
Epoch [249/300], Train Loss: 0.005491
Validation Loss: 0.00500546
Epoch [250/300], Train Loss: 0.005491
Validation Loss: 0.00500348
Epoch [251/300], Train Loss: 0.005479
Validation Loss: 0.00499998
Epoch [252/300], Train Loss: 0.005448
Validation Loss: 0.00500620
Epoch [253/300], Train Loss: 0.005483
Validation Loss: 0.00500247
Epoch [254/300], Train Loss: 0.005456
Validation Loss: 0.00500228
Epoch [255/300], Train Loss: 0.005515
Validation Loss: 0.00500379
Epoch [256/300], Train Loss: 0.005458
Validation Loss: 0.00499954
Epoch [257/300], Train Loss: 0.005514
Validation Loss: 0.00499875
Epoch [258/300], Train Loss: 0.005468
Validation Loss: 0.00500826
Epoch [259/300], Train Loss: 0.005484
Validation Loss: 0.00500006
Epoch [260/300], Train Loss: 0.005482
Validation Loss: 0.00499935
Epoch [261/300], Train Loss: 0.005457
Validation Loss: 0.00499988
Epoch [262/300], Train Loss: 0.005468
Validation Loss: 0.00499975
Epoch [263/300], Train Loss: 0.005508
Validation Loss: 0.00499608
Epoch [264/300], Train Loss: 0.005474
Validation Loss: 0.00500371
Epoch [265/300], Train Loss: 0.005485
Validation Loss: 0.00499619
Epoch [266/300], Train Loss: 0.005474
Validation Loss: 0.00499594
Epoch [267/300], Train Loss: 0.005499
Validation Loss: 0.00500810
Epoch [268/300], Train Loss: 0.005464
Validation Loss: 0.00499364
Epoch [269/300], Train Loss: 0.005495
Validation Loss: 0.00499566
Epoch [270/300], Train Loss: 0.005461
Validation Loss: 0.00500132
Epoch [271/300], Train Loss: 0.005442
Validation Loss: 0.00499393
Epoch [272/300], Train Loss: 0.005466
Validation Loss: 0.00499353
Epoch [273/300], Train Loss: 0.005467
Validation Loss: 0.00499991
Epoch [274/300], Train Loss: 0.005460
Validation Loss: 0.00499148
Epoch [275/300], Train Loss: 0.005475
Validation Loss: 0.00499512
Epoch [276/300], Train Loss: 0.005447
Validation Loss: 0.00499716
Epoch [277/300], Train Loss: 0.005464
Validation Loss: 0.00499325
Epoch [278/300], Train Loss: 0.005455
Validation Loss: 0.00499436
Epoch [279/300], Train Loss: 0.005437
Validation Loss: 0.00499149
Epoch [280/300], Train Loss: 0.005463
Validation Loss: 0.00499296
Epoch [281/300], Train Loss: 0.005467
Validation Loss: 0.00499799
Epoch [282/300], Train Loss: 0.005477
Validation Loss: 0.00498939
Epoch [283/300], Train Loss: 0.005462
Validation Loss: 0.00499488
Epoch [284/300], Train Loss: 0.005495
Validation Loss: 0.00499632
Epoch [285/300], Train Loss: 0.005457
Validation Loss: 0.00499191
Epoch [286/300], Train Loss: 0.005467
Validation Loss: 0.00498903
Epoch [287/300], Train Loss: 0.005477
Validation Loss: 0.00499117
Epoch [288/300], Train Loss: 0.005453
Validation Loss: 0.00499975
Epoch [289/300], Train Loss: 0.005469
Validation Loss: 0.00498978
Epoch [290/300], Train Loss: 0.005489
Validation Loss: 0.00498871
Epoch [291/300], Train Loss: 0.005463
Validation Loss: 0.00499311
Epoch [292/300], Train Loss: 0.005448
Validation Loss: 0.00499593
Epoch [293/300], Train Loss: 0.005462
Validation Loss: 0.00498755
Epoch [294/300], Train Loss: 0.005467
Validation Loss: 0.00499589
Epoch [295/300], Train Loss: 0.005456
Validation Loss: 0.00498592
Epoch [296/300], Train Loss: 0.005490
Validation Loss: 0.00498659
Epoch [297/300], Train Loss: 0.005451
Validation Loss: 0.00500074
Epoch [298/300], Train Loss: 0.005462
Validation Loss: 0.00499173
Epoch [299/300], Train Loss: 0.005440
Validation Loss: 0.00498559
Epoch [300/300], Train Loss: 0.005466
Validation Loss: 0.00498777

Evaluating model for: Router
Run 65/72 completed in 784.29 seconds with: {'MAE': np.float32(0.20734468), 'MSE': np.float32(0.07755296), 'RMSE': np.float32(0.27848333), 'SAE': np.float32(0.00014268258), 'NDE': np.float32(0.013921016)}

Run 66/72: hidden=512, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Router
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.085759
Validation Loss: 0.06989475
Epoch [2/300], Train Loss: 0.057180
Validation Loss: 0.03791251
Epoch [3/300], Train Loss: 0.019886
Validation Loss: 0.01174949
Epoch [4/300], Train Loss: 0.010223
Validation Loss: 0.00633186
Epoch [5/300], Train Loss: 0.008069
Validation Loss: 0.00713256
Epoch [6/300], Train Loss: 0.006291
Validation Loss: 0.00574464
Epoch [7/300], Train Loss: 0.006218
Validation Loss: 0.00525859
Epoch [8/300], Train Loss: 0.005759
Validation Loss: 0.00549682
Epoch [9/300], Train Loss: 0.005782
Validation Loss: 0.00525302
Epoch [10/300], Train Loss: 0.005730
Validation Loss: 0.00524708
Epoch [11/300], Train Loss: 0.005742
Validation Loss: 0.00528240
Epoch [12/300], Train Loss: 0.005674
Validation Loss: 0.00523802
Epoch [13/300], Train Loss: 0.005697
Validation Loss: 0.00523409
Epoch [14/300], Train Loss: 0.005701
Validation Loss: 0.00524098
Epoch [15/300], Train Loss: 0.005658
Validation Loss: 0.00522621
Epoch [16/300], Train Loss: 0.005714
Validation Loss: 0.00523113
Epoch [17/300], Train Loss: 0.005650
Validation Loss: 0.00522086
Epoch [18/300], Train Loss: 0.005660
Validation Loss: 0.00521746
Epoch [19/300], Train Loss: 0.005672
Validation Loss: 0.00522064
Epoch [20/300], Train Loss: 0.005696
Validation Loss: 0.00521132
Epoch [21/300], Train Loss: 0.005717
Validation Loss: 0.00521321
Epoch [22/300], Train Loss: 0.005696
Validation Loss: 0.00521169
Epoch [23/300], Train Loss: 0.005667
Validation Loss: 0.00520286
Epoch [24/300], Train Loss: 0.005687
Validation Loss: 0.00521141
Epoch [25/300], Train Loss: 0.005656
Validation Loss: 0.00519893
Epoch [26/300], Train Loss: 0.005657
Validation Loss: 0.00519208
Epoch [27/300], Train Loss: 0.005627
Validation Loss: 0.00519776
Epoch [28/300], Train Loss: 0.005620
Validation Loss: 0.00518868
Epoch [29/300], Train Loss: 0.005635
Validation Loss: 0.00518236
Epoch [30/300], Train Loss: 0.005613
Validation Loss: 0.00519345
Epoch [31/300], Train Loss: 0.005624
Validation Loss: 0.00517614
Epoch [32/300], Train Loss: 0.005647
Validation Loss: 0.00517603
Epoch [33/300], Train Loss: 0.005632
Validation Loss: 0.00517957
Epoch [34/300], Train Loss: 0.005624
Validation Loss: 0.00516675
Epoch [35/300], Train Loss: 0.005618
Validation Loss: 0.00517179
Epoch [36/300], Train Loss: 0.005581
Validation Loss: 0.00516339
Epoch [37/300], Train Loss: 0.005605
Validation Loss: 0.00515713
Epoch [38/300], Train Loss: 0.005615
Validation Loss: 0.00515772
Epoch [39/300], Train Loss: 0.005634
Validation Loss: 0.00515286
Epoch [40/300], Train Loss: 0.005639
Validation Loss: 0.00515031
Epoch [41/300], Train Loss: 0.005622
Validation Loss: 0.00515021
Epoch [42/300], Train Loss: 0.005613
Validation Loss: 0.00514048
Epoch [43/300], Train Loss: 0.005600
Validation Loss: 0.00513858
Epoch [44/300], Train Loss: 0.005605
Validation Loss: 0.00513902
Epoch [45/300], Train Loss: 0.005598
Validation Loss: 0.00513154
Epoch [46/300], Train Loss: 0.005593
Validation Loss: 0.00512733
Epoch [47/300], Train Loss: 0.005606
Validation Loss: 0.00513039
Epoch [48/300], Train Loss: 0.005563
Validation Loss: 0.00512082
Epoch [49/300], Train Loss: 0.005576
Validation Loss: 0.00511860
Epoch [50/300], Train Loss: 0.005588
Validation Loss: 0.00512352
Epoch [51/300], Train Loss: 0.005614
Validation Loss: 0.00511206
Epoch [52/300], Train Loss: 0.005554
Validation Loss: 0.00512345
Epoch [53/300], Train Loss: 0.005571
Validation Loss: 0.00510620
Epoch [54/300], Train Loss: 0.005564
Validation Loss: 0.00510934
Epoch [55/300], Train Loss: 0.005587
Validation Loss: 0.00510611
Epoch [56/300], Train Loss: 0.005580
Validation Loss: 0.00510000
Epoch [57/300], Train Loss: 0.005552
Validation Loss: 0.00509989
Epoch [58/300], Train Loss: 0.005585
Validation Loss: 0.00509190
Epoch [59/300], Train Loss: 0.005555
Validation Loss: 0.00509412
Epoch [60/300], Train Loss: 0.005570
Validation Loss: 0.00509147
Epoch [61/300], Train Loss: 0.005587
Validation Loss: 0.00508507
Epoch [62/300], Train Loss: 0.005563
Validation Loss: 0.00509599
Epoch [63/300], Train Loss: 0.005573
Validation Loss: 0.00508100
Epoch [64/300], Train Loss: 0.005558
Validation Loss: 0.00508520
Epoch [65/300], Train Loss: 0.005578
Validation Loss: 0.00507489
Epoch [66/300], Train Loss: 0.005562
Validation Loss: 0.00508409
Epoch [67/300], Train Loss: 0.005583
Validation Loss: 0.00507766
Epoch [68/300], Train Loss: 0.005573
Validation Loss: 0.00507086
Epoch [69/300], Train Loss: 0.005583
Validation Loss: 0.00506986
Epoch [70/300], Train Loss: 0.005592
Validation Loss: 0.00507467
Epoch [71/300], Train Loss: 0.005569
Validation Loss: 0.00507255
Epoch [72/300], Train Loss: 0.005577
Validation Loss: 0.00506359
Epoch [73/300], Train Loss: 0.005547
Validation Loss: 0.00507039
Epoch [74/300], Train Loss: 0.005528
Validation Loss: 0.00505865
Epoch [75/300], Train Loss: 0.005588
Validation Loss: 0.00505658
Epoch [76/300], Train Loss: 0.005512
Validation Loss: 0.00505625
Epoch [77/300], Train Loss: 0.005559
Validation Loss: 0.00505612
Epoch [78/300], Train Loss: 0.005526
Validation Loss: 0.00505164
Epoch [79/300], Train Loss: 0.005592
Validation Loss: 0.00505510
Epoch [80/300], Train Loss: 0.005542
Validation Loss: 0.00504616
Epoch [81/300], Train Loss: 0.005554
Validation Loss: 0.00506259
Epoch [82/300], Train Loss: 0.005541
Validation Loss: 0.00504325
Epoch [83/300], Train Loss: 0.005546
Validation Loss: 0.00504734
Epoch [84/300], Train Loss: 0.005504
Validation Loss: 0.00504341
Epoch [85/300], Train Loss: 0.005561
Validation Loss: 0.00505404
Epoch [86/300], Train Loss: 0.005533
Validation Loss: 0.00503729
Epoch [87/300], Train Loss: 0.005515
Validation Loss: 0.00503754
Epoch [88/300], Train Loss: 0.005538
Validation Loss: 0.00506701
Epoch [89/300], Train Loss: 0.005554
Validation Loss: 0.00503387
Epoch [90/300], Train Loss: 0.005508
Validation Loss: 0.00503771
Epoch [91/300], Train Loss: 0.005499
Validation Loss: 0.00503381
Epoch [92/300], Train Loss: 0.005527
Validation Loss: 0.00504793
Epoch [93/300], Train Loss: 0.005493
Validation Loss: 0.00502881
Epoch [94/300], Train Loss: 0.005521
Validation Loss: 0.00503725
Epoch [95/300], Train Loss: 0.005493
Validation Loss: 0.00503080
Epoch [96/300], Train Loss: 0.005562
Validation Loss: 0.00502610
Epoch [97/300], Train Loss: 0.005521
Validation Loss: 0.00502879
Epoch [98/300], Train Loss: 0.005496
Validation Loss: 0.00502699
Epoch [99/300], Train Loss: 0.005514
Validation Loss: 0.00502286
Epoch [100/300], Train Loss: 0.005484
Validation Loss: 0.00502311
Epoch [101/300], Train Loss: 0.005519
Validation Loss: 0.00502172
Epoch [102/300], Train Loss: 0.005502
Validation Loss: 0.00502586
Epoch [103/300], Train Loss: 0.005498
Validation Loss: 0.00501664
Epoch [104/300], Train Loss: 0.005525
Validation Loss: 0.00501907
Epoch [105/300], Train Loss: 0.005498
Validation Loss: 0.00501802
Epoch [106/300], Train Loss: 0.005520
Validation Loss: 0.00501292
Epoch [107/300], Train Loss: 0.005497
Validation Loss: 0.00502261
Epoch [108/300], Train Loss: 0.005512
Validation Loss: 0.00501221
Epoch [109/300], Train Loss: 0.005494
Validation Loss: 0.00501368
Epoch [110/300], Train Loss: 0.005505
Validation Loss: 0.00501094
Epoch [111/300], Train Loss: 0.005518
Validation Loss: 0.00501904
Epoch [112/300], Train Loss: 0.005489
Validation Loss: 0.00501559
Epoch [113/300], Train Loss: 0.005501
Validation Loss: 0.00500648
Epoch [114/300], Train Loss: 0.005518
Validation Loss: 0.00502085
Epoch [115/300], Train Loss: 0.005480
Validation Loss: 0.00500917
Epoch [116/300], Train Loss: 0.005481
Validation Loss: 0.00500347
Epoch [117/300], Train Loss: 0.005471
Validation Loss: 0.00500928
Epoch [118/300], Train Loss: 0.005502
Validation Loss: 0.00500098
Epoch [119/300], Train Loss: 0.005496
Validation Loss: 0.00500600
Epoch [120/300], Train Loss: 0.005495
Validation Loss: 0.00500286
Epoch [121/300], Train Loss: 0.005509
Validation Loss: 0.00501015
Epoch [122/300], Train Loss: 0.005495
Validation Loss: 0.00499969
Epoch [123/300], Train Loss: 0.005474
Validation Loss: 0.00500313
Epoch [124/300], Train Loss: 0.005480
Validation Loss: 0.00500182
Epoch [125/300], Train Loss: 0.005483
Validation Loss: 0.00499910
Epoch [126/300], Train Loss: 0.005465
Validation Loss: 0.00499493
Epoch [127/300], Train Loss: 0.005488
Validation Loss: 0.00500093
Epoch [128/300], Train Loss: 0.005517
Validation Loss: 0.00499823
Epoch [129/300], Train Loss: 0.005460
Validation Loss: 0.00499186
Epoch [130/300], Train Loss: 0.005474
Validation Loss: 0.00500137
Epoch [131/300], Train Loss: 0.005482
Validation Loss: 0.00499085
Epoch [132/300], Train Loss: 0.005469
Validation Loss: 0.00499670
Epoch [133/300], Train Loss: 0.005462
Validation Loss: 0.00498846
Epoch [134/300], Train Loss: 0.005465
Validation Loss: 0.00498828
Epoch [135/300], Train Loss: 0.005456
Validation Loss: 0.00499038
Epoch [136/300], Train Loss: 0.005446
Validation Loss: 0.00499641
Epoch [137/300], Train Loss: 0.005485
Validation Loss: 0.00498657
Epoch [138/300], Train Loss: 0.005473
Validation Loss: 0.00499745
Epoch [139/300], Train Loss: 0.005474
Validation Loss: 0.00498414
Epoch [140/300], Train Loss: 0.005475
Validation Loss: 0.00500150
Epoch [141/300], Train Loss: 0.005451
Validation Loss: 0.00498250
Epoch [142/300], Train Loss: 0.005488
Validation Loss: 0.00500201
Epoch [143/300], Train Loss: 0.005461
Validation Loss: 0.00498506
Epoch [144/300], Train Loss: 0.005459
Validation Loss: 0.00498604
Epoch [145/300], Train Loss: 0.005470
Validation Loss: 0.00498756
Epoch [146/300], Train Loss: 0.005451
Validation Loss: 0.00498095
Epoch [147/300], Train Loss: 0.005468
Validation Loss: 0.00498683
Epoch [148/300], Train Loss: 0.005480
Validation Loss: 0.00498048
Epoch [149/300], Train Loss: 0.005463
Validation Loss: 0.00498766
Epoch [150/300], Train Loss: 0.005441
Validation Loss: 0.00497707
Epoch [151/300], Train Loss: 0.005451
Validation Loss: 0.00499243
Epoch [152/300], Train Loss: 0.005460
Validation Loss: 0.00497668
Epoch [153/300], Train Loss: 0.005435
Validation Loss: 0.00497759
Epoch [154/300], Train Loss: 0.005425
Validation Loss: 0.00498033
Epoch [155/300], Train Loss: 0.005465
Validation Loss: 0.00497439
Epoch [156/300], Train Loss: 0.005482
Validation Loss: 0.00497433
Epoch [157/300], Train Loss: 0.005464
Validation Loss: 0.00497434
Epoch [158/300], Train Loss: 0.005439
Validation Loss: 0.00497765
Epoch [159/300], Train Loss: 0.005439
Validation Loss: 0.00497268
Epoch [160/300], Train Loss: 0.005453
Validation Loss: 0.00497292
Epoch [161/300], Train Loss: 0.005454
Validation Loss: 0.00497683
Epoch [162/300], Train Loss: 0.005428
Validation Loss: 0.00497102
Epoch [163/300], Train Loss: 0.005466
Validation Loss: 0.00497137
Epoch [164/300], Train Loss: 0.005518
Validation Loss: 0.00496954
Epoch [165/300], Train Loss: 0.005505
Validation Loss: 0.00496841
Epoch [166/300], Train Loss: 0.005498
Validation Loss: 0.00500641
Epoch [167/300], Train Loss: 0.005446
Validation Loss: 0.00497704
Epoch [168/300], Train Loss: 0.005472
Validation Loss: 0.00499673
Epoch [169/300], Train Loss: 0.005416
Validation Loss: 0.00496620
Epoch [170/300], Train Loss: 0.005468
Validation Loss: 0.00497574
Epoch [171/300], Train Loss: 0.005438
Validation Loss: 0.00496750
Epoch [172/300], Train Loss: 0.005467
Validation Loss: 0.00496944
Epoch [173/300], Train Loss: 0.005433
Validation Loss: 0.00496896
Epoch [174/300], Train Loss: 0.005473
Validation Loss: 0.00496441
Epoch [175/300], Train Loss: 0.005476
Validation Loss: 0.00497897
Epoch [176/300], Train Loss: 0.005466
Validation Loss: 0.00496363
Epoch [177/300], Train Loss: 0.005446
Validation Loss: 0.00499090
Epoch [178/300], Train Loss: 0.005466
Validation Loss: 0.00496166
Epoch [179/300], Train Loss: 0.005478
Validation Loss: 0.00496308
Epoch [180/300], Train Loss: 0.005423
Validation Loss: 0.00496812
Epoch [181/300], Train Loss: 0.005451
Validation Loss: 0.00496124
Epoch [182/300], Train Loss: 0.005433
Validation Loss: 0.00496559
Epoch [183/300], Train Loss: 0.005423
Validation Loss: 0.00496363
Epoch [184/300], Train Loss: 0.005433
Validation Loss: 0.00496523
Epoch [185/300], Train Loss: 0.005446
Validation Loss: 0.00495809
Epoch [186/300], Train Loss: 0.005474
Validation Loss: 0.00496433
Epoch [187/300], Train Loss: 0.005446
Validation Loss: 0.00496836
Epoch [188/300], Train Loss: 0.005406
Validation Loss: 0.00495613
Epoch [189/300], Train Loss: 0.005475
Validation Loss: 0.00496195
Epoch [190/300], Train Loss: 0.005398
Validation Loss: 0.00495876
Epoch [191/300], Train Loss: 0.005425
Validation Loss: 0.00495692
Epoch [192/300], Train Loss: 0.005415
Validation Loss: 0.00496082
Epoch [193/300], Train Loss: 0.005449
Validation Loss: 0.00496181
Epoch [194/300], Train Loss: 0.005406
Validation Loss: 0.00495736
Epoch [195/300], Train Loss: 0.005427
Validation Loss: 0.00495900
Epoch [196/300], Train Loss: 0.005480
Validation Loss: 0.00495793
Epoch [197/300], Train Loss: 0.005460
Validation Loss: 0.00495253
Epoch [198/300], Train Loss: 0.005424
Validation Loss: 0.00496815
Epoch [199/300], Train Loss: 0.005415
Validation Loss: 0.00495546
Epoch [200/300], Train Loss: 0.005459
Validation Loss: 0.00495239
Epoch [201/300], Train Loss: 0.005431
Validation Loss: 0.00496151
Epoch [202/300], Train Loss: 0.005411
Validation Loss: 0.00495169
Epoch [203/300], Train Loss: 0.005432
Validation Loss: 0.00495024
Epoch [204/300], Train Loss: 0.005413
Validation Loss: 0.00496972
Epoch [205/300], Train Loss: 0.005446
Validation Loss: 0.00495001
Epoch [206/300], Train Loss: 0.005430
Validation Loss: 0.00495445
Epoch [207/300], Train Loss: 0.005432
Validation Loss: 0.00494852
Epoch [208/300], Train Loss: 0.005506
Validation Loss: 0.00495372
Epoch [209/300], Train Loss: 0.005456
Validation Loss: 0.00496999
Epoch [210/300], Train Loss: 0.005413
Validation Loss: 0.00495093
Epoch [211/300], Train Loss: 0.005450
Validation Loss: 0.00495800
Epoch [212/300], Train Loss: 0.005438
Validation Loss: 0.00495066
Epoch [213/300], Train Loss: 0.005419
Validation Loss: 0.00494705
Epoch [214/300], Train Loss: 0.005398
Validation Loss: 0.00495035
Epoch [215/300], Train Loss: 0.005416
Validation Loss: 0.00495142
Epoch [216/300], Train Loss: 0.005472
Validation Loss: 0.00494580
Epoch [217/300], Train Loss: 0.005447
Validation Loss: 0.00496166
Epoch [218/300], Train Loss: 0.005436
Validation Loss: 0.00494468
Epoch [219/300], Train Loss: 0.005422
Validation Loss: 0.00495976
Epoch [220/300], Train Loss: 0.005442
Validation Loss: 0.00495400
Epoch [221/300], Train Loss: 0.005438
Validation Loss: 0.00494381
Epoch [222/300], Train Loss: 0.005431
Validation Loss: 0.00496093
Epoch [223/300], Train Loss: 0.005413
Validation Loss: 0.00494345
Epoch [224/300], Train Loss: 0.005425
Validation Loss: 0.00494921
Epoch [225/300], Train Loss: 0.005415
Validation Loss: 0.00494203
Epoch [226/300], Train Loss: 0.005423
Validation Loss: 0.00494872
Epoch [227/300], Train Loss: 0.005419
Validation Loss: 0.00494326
Epoch [228/300], Train Loss: 0.005420
Validation Loss: 0.00494630
Epoch [229/300], Train Loss: 0.005412
Validation Loss: 0.00496098
Epoch [230/300], Train Loss: 0.005399
Validation Loss: 0.00494158
Epoch [231/300], Train Loss: 0.005435
Validation Loss: 0.00494155
Epoch [232/300], Train Loss: 0.005434
Validation Loss: 0.00496563
Epoch [233/300], Train Loss: 0.005415
Validation Loss: 0.00494014
Epoch [234/300], Train Loss: 0.005430
Validation Loss: 0.00494013
Epoch [235/300], Train Loss: 0.005400
Validation Loss: 0.00494524
Epoch [236/300], Train Loss: 0.005432
Validation Loss: 0.00494567
Epoch [237/300], Train Loss: 0.005408
Validation Loss: 0.00493857
Epoch [238/300], Train Loss: 0.005454
Validation Loss: 0.00494377
Epoch [239/300], Train Loss: 0.005457
Validation Loss: 0.00494966
Epoch [240/300], Train Loss: 0.005398
Validation Loss: 0.00494038
Epoch [241/300], Train Loss: 0.005395
Validation Loss: 0.00493760
Epoch [242/300], Train Loss: 0.005405
Validation Loss: 0.00494718
Epoch [243/300], Train Loss: 0.005430
Validation Loss: 0.00493875
Epoch [244/300], Train Loss: 0.005389
Validation Loss: 0.00493888
Epoch [245/300], Train Loss: 0.005417
Validation Loss: 0.00494510
Epoch [246/300], Train Loss: 0.005425
Validation Loss: 0.00493672
Epoch [247/300], Train Loss: 0.005420
Validation Loss: 0.00495265
Epoch [248/300], Train Loss: 0.005408
Validation Loss: 0.00493589
Epoch [249/300], Train Loss: 0.005420
Validation Loss: 0.00494334
Epoch [250/300], Train Loss: 0.005422
Validation Loss: 0.00493830
Epoch [251/300], Train Loss: 0.005407
Validation Loss: 0.00493624
Epoch [252/300], Train Loss: 0.005379
Validation Loss: 0.00494539
Epoch [253/300], Train Loss: 0.005415
Validation Loss: 0.00493730
Epoch [254/300], Train Loss: 0.005388
Validation Loss: 0.00494010
Epoch [255/300], Train Loss: 0.005445
Validation Loss: 0.00494017
Epoch [256/300], Train Loss: 0.005384
Validation Loss: 0.00493466
Epoch [257/300], Train Loss: 0.005441
Validation Loss: 0.00493639
Epoch [258/300], Train Loss: 0.005401
Validation Loss: 0.00494801
Epoch [259/300], Train Loss: 0.005418
Validation Loss: 0.00493460
Epoch [260/300], Train Loss: 0.005412
Validation Loss: 0.00493727
Epoch [261/300], Train Loss: 0.005387
Validation Loss: 0.00493697
Epoch [262/300], Train Loss: 0.005400
Validation Loss: 0.00493510
Epoch [263/300], Train Loss: 0.005435
Validation Loss: 0.00493301
Epoch [264/300], Train Loss: 0.005410
Validation Loss: 0.00494336
Epoch [265/300], Train Loss: 0.005418
Validation Loss: 0.00493202
Epoch [266/300], Train Loss: 0.005402
Validation Loss: 0.00493456
Epoch [267/300], Train Loss: 0.005432
Validation Loss: 0.00494458
Epoch [268/300], Train Loss: 0.005401
Validation Loss: 0.00493034
Epoch [269/300], Train Loss: 0.005426
Validation Loss: 0.00493745
Epoch [270/300], Train Loss: 0.005394
Validation Loss: 0.00493729
Epoch [271/300], Train Loss: 0.005375
Validation Loss: 0.00493013
Epoch [272/300], Train Loss: 0.005400
Validation Loss: 0.00493328
Epoch [273/300], Train Loss: 0.005398
Validation Loss: 0.00493774
Epoch [274/300], Train Loss: 0.005392
Validation Loss: 0.00492907
Epoch [275/300], Train Loss: 0.005403
Validation Loss: 0.00493678
Epoch [276/300], Train Loss: 0.005379
Validation Loss: 0.00493445
Epoch [277/300], Train Loss: 0.005397
Validation Loss: 0.00492977
Epoch [278/300], Train Loss: 0.005388
Validation Loss: 0.00493429
Epoch [279/300], Train Loss: 0.005367
Validation Loss: 0.00492969
Epoch [280/300], Train Loss: 0.005393
Validation Loss: 0.00493095
Epoch [281/300], Train Loss: 0.005399
Validation Loss: 0.00493664
Epoch [282/300], Train Loss: 0.005407
Validation Loss: 0.00492773
Epoch [283/300], Train Loss: 0.005395
Validation Loss: 0.00493646
Epoch [284/300], Train Loss: 0.005424
Validation Loss: 0.00493384
Epoch [285/300], Train Loss: 0.005390
Validation Loss: 0.00492904
Epoch [286/300], Train Loss: 0.005401
Validation Loss: 0.00492832
Epoch [287/300], Train Loss: 0.005409
Validation Loss: 0.00493192
Epoch [288/300], Train Loss: 0.005389
Validation Loss: 0.00493728
Epoch [289/300], Train Loss: 0.005400
Validation Loss: 0.00492744
Epoch [290/300], Train Loss: 0.005418
Validation Loss: 0.00492889
Epoch [291/300], Train Loss: 0.005394
Validation Loss: 0.00493278
Epoch [292/300], Train Loss: 0.005385
Validation Loss: 0.00493279
Epoch [293/300], Train Loss: 0.005397
Validation Loss: 0.00492642
Epoch [294/300], Train Loss: 0.005410
Validation Loss: 0.00493876
Epoch [295/300], Train Loss: 0.005386
Validation Loss: 0.00492505
Epoch [296/300], Train Loss: 0.005421
Validation Loss: 0.00492682
Epoch [297/300], Train Loss: 0.005382
Validation Loss: 0.00494435
Epoch [298/300], Train Loss: 0.005394
Validation Loss: 0.00492757
Epoch [299/300], Train Loss: 0.005373
Validation Loss: 0.00492486
Epoch [300/300], Train Loss: 0.005400
Validation Loss: 0.00492984

Evaluating model for: Router
Run 66/72 completed in 1054.22 seconds with: {'MAE': np.float32(0.20700538), 'MSE': np.float32(0.07696745), 'RMSE': np.float32(0.2774301), 'SAE': np.float32(6.6352666e-05), 'NDE': np.float32(0.013868365)}

Run 67/72: hidden=512, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Router
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.107408
Validation Loss: 0.09124005
Epoch [2/300], Train Loss: 0.077330
Validation Loss: 0.05535568
Epoch [3/300], Train Loss: 0.029176
Validation Loss: 0.02076244
Epoch [4/300], Train Loss: 0.012107
Validation Loss: 0.00946815
Epoch [5/300], Train Loss: 0.009870
Validation Loss: 0.00649911
Epoch [6/300], Train Loss: 0.006667
Validation Loss: 0.00680415
Epoch [7/300], Train Loss: 0.006411
Validation Loss: 0.00583072
Epoch [8/300], Train Loss: 0.006241
Validation Loss: 0.00545523
Epoch [9/300], Train Loss: 0.005966
Validation Loss: 0.00549941
Epoch [10/300], Train Loss: 0.005912
Validation Loss: 0.00546242
Epoch [11/300], Train Loss: 0.005948
Validation Loss: 0.00539805
Epoch [12/300], Train Loss: 0.005886
Validation Loss: 0.00540086
Epoch [13/300], Train Loss: 0.005889
Validation Loss: 0.00541954
Epoch [14/300], Train Loss: 0.005900
Validation Loss: 0.00538815
Epoch [15/300], Train Loss: 0.005858
Validation Loss: 0.00538586
Epoch [16/300], Train Loss: 0.005919
Validation Loss: 0.00539070
Epoch [17/300], Train Loss: 0.005838
Validation Loss: 0.00538009
Epoch [18/300], Train Loss: 0.005855
Validation Loss: 0.00538007
Epoch [19/300], Train Loss: 0.005864
Validation Loss: 0.00537513
Epoch [20/300], Train Loss: 0.005891
Validation Loss: 0.00537042
Epoch [21/300], Train Loss: 0.005906
Validation Loss: 0.00537522
Epoch [22/300], Train Loss: 0.005892
Validation Loss: 0.00536573
Epoch [23/300], Train Loss: 0.005862
Validation Loss: 0.00536094
Epoch [24/300], Train Loss: 0.005877
Validation Loss: 0.00537221
Epoch [25/300], Train Loss: 0.005849
Validation Loss: 0.00535444
Epoch [26/300], Train Loss: 0.005847
Validation Loss: 0.00535065
Epoch [27/300], Train Loss: 0.005818
Validation Loss: 0.00535499
Epoch [28/300], Train Loss: 0.005810
Validation Loss: 0.00534521
Epoch [29/300], Train Loss: 0.005825
Validation Loss: 0.00534063
Epoch [30/300], Train Loss: 0.005806
Validation Loss: 0.00535164
Epoch [31/300], Train Loss: 0.005813
Validation Loss: 0.00533370
Epoch [32/300], Train Loss: 0.005834
Validation Loss: 0.00533411
Epoch [33/300], Train Loss: 0.005814
Validation Loss: 0.00533395
Epoch [34/300], Train Loss: 0.005808
Validation Loss: 0.00532451
Epoch [35/300], Train Loss: 0.005798
Validation Loss: 0.00532948
Epoch [36/300], Train Loss: 0.005764
Validation Loss: 0.00531851
Epoch [37/300], Train Loss: 0.005790
Validation Loss: 0.00531408
Epoch [38/300], Train Loss: 0.005801
Validation Loss: 0.00531225
Epoch [39/300], Train Loss: 0.005816
Validation Loss: 0.00530877
Epoch [40/300], Train Loss: 0.005820
Validation Loss: 0.00530776
Epoch [41/300], Train Loss: 0.005804
Validation Loss: 0.00530329
Epoch [42/300], Train Loss: 0.005793
Validation Loss: 0.00529739
Epoch [43/300], Train Loss: 0.005779
Validation Loss: 0.00529417
Epoch [44/300], Train Loss: 0.005788
Validation Loss: 0.00529386
Epoch [45/300], Train Loss: 0.005774
Validation Loss: 0.00528547
Epoch [46/300], Train Loss: 0.005770
Validation Loss: 0.00528265
Epoch [47/300], Train Loss: 0.005784
Validation Loss: 0.00528266
Epoch [48/300], Train Loss: 0.005738
Validation Loss: 0.00527507
Epoch [49/300], Train Loss: 0.005748
Validation Loss: 0.00527295
Epoch [50/300], Train Loss: 0.005765
Validation Loss: 0.00526978
Epoch [51/300], Train Loss: 0.005782
Validation Loss: 0.00526357
Epoch [52/300], Train Loss: 0.005729
Validation Loss: 0.00526622
Epoch [53/300], Train Loss: 0.005745
Validation Loss: 0.00525542
Epoch [54/300], Train Loss: 0.005727
Validation Loss: 0.00525673
Epoch [55/300], Train Loss: 0.005752
Validation Loss: 0.00524946
Epoch [56/300], Train Loss: 0.005745
Validation Loss: 0.00524813
Epoch [57/300], Train Loss: 0.005706
Validation Loss: 0.00524011
Epoch [58/300], Train Loss: 0.005741
Validation Loss: 0.00523440
Epoch [59/300], Train Loss: 0.005713
Validation Loss: 0.00523545
Epoch [60/300], Train Loss: 0.005727
Validation Loss: 0.00522775
Epoch [61/300], Train Loss: 0.005746
Validation Loss: 0.00522353
Epoch [62/300], Train Loss: 0.005714
Validation Loss: 0.00522495
Epoch [63/300], Train Loss: 0.005729
Validation Loss: 0.00521903
Epoch [64/300], Train Loss: 0.005711
Validation Loss: 0.00521213
Epoch [65/300], Train Loss: 0.005725
Validation Loss: 0.00520606
Epoch [66/300], Train Loss: 0.005708
Validation Loss: 0.00520798
Epoch [67/300], Train Loss: 0.005731
Validation Loss: 0.00520992
Epoch [68/300], Train Loss: 0.005725
Validation Loss: 0.00519300
Epoch [69/300], Train Loss: 0.005733
Validation Loss: 0.00520385
Epoch [70/300], Train Loss: 0.005749
Validation Loss: 0.00518895
Epoch [71/300], Train Loss: 0.005708
Validation Loss: 0.00519283
Epoch [72/300], Train Loss: 0.005717
Validation Loss: 0.00518046
Epoch [73/300], Train Loss: 0.005686
Validation Loss: 0.00518234
Epoch [74/300], Train Loss: 0.005665
Validation Loss: 0.00517197
Epoch [75/300], Train Loss: 0.005726
Validation Loss: 0.00516338
Epoch [76/300], Train Loss: 0.005644
Validation Loss: 0.00517107
Epoch [77/300], Train Loss: 0.005687
Validation Loss: 0.00515778
Epoch [78/300], Train Loss: 0.005647
Validation Loss: 0.00516338
Epoch [79/300], Train Loss: 0.005724
Validation Loss: 0.00515025
Epoch [80/300], Train Loss: 0.005675
Validation Loss: 0.00515758
Epoch [81/300], Train Loss: 0.005681
Validation Loss: 0.00514894
Epoch [82/300], Train Loss: 0.005666
Validation Loss: 0.00514371
Epoch [83/300], Train Loss: 0.005665
Validation Loss: 0.00513968
Epoch [84/300], Train Loss: 0.005631
Validation Loss: 0.00514524
Epoch [85/300], Train Loss: 0.005681
Validation Loss: 0.00514736
Epoch [86/300], Train Loss: 0.005649
Validation Loss: 0.00513106
Epoch [87/300], Train Loss: 0.005635
Validation Loss: 0.00513353
Epoch [88/300], Train Loss: 0.005664
Validation Loss: 0.00516256
Epoch [89/300], Train Loss: 0.005677
Validation Loss: 0.00512242
Epoch [90/300], Train Loss: 0.005625
Validation Loss: 0.00512832
Epoch [91/300], Train Loss: 0.005619
Validation Loss: 0.00512092
Epoch [92/300], Train Loss: 0.005641
Validation Loss: 0.00513170
Epoch [93/300], Train Loss: 0.005616
Validation Loss: 0.00511476
Epoch [94/300], Train Loss: 0.005636
Validation Loss: 0.00512098
Epoch [95/300], Train Loss: 0.005603
Validation Loss: 0.00511099
Epoch [96/300], Train Loss: 0.005672
Validation Loss: 0.00510948
Epoch [97/300], Train Loss: 0.005626
Validation Loss: 0.00510562
Epoch [98/300], Train Loss: 0.005614
Validation Loss: 0.00511072
Epoch [99/300], Train Loss: 0.005626
Validation Loss: 0.00509989
Epoch [100/300], Train Loss: 0.005598
Validation Loss: 0.00509800
Epoch [101/300], Train Loss: 0.005632
Validation Loss: 0.00510351
Epoch [102/300], Train Loss: 0.005609
Validation Loss: 0.00509622
Epoch [103/300], Train Loss: 0.005606
Validation Loss: 0.00509082
Epoch [104/300], Train Loss: 0.005627
Validation Loss: 0.00509464
Epoch [105/300], Train Loss: 0.005601
Validation Loss: 0.00508670
Epoch [106/300], Train Loss: 0.005620
Validation Loss: 0.00508482
Epoch [107/300], Train Loss: 0.005597
Validation Loss: 0.00508911
Epoch [108/300], Train Loss: 0.005615
Validation Loss: 0.00508161
Epoch [109/300], Train Loss: 0.005595
Validation Loss: 0.00508849
Epoch [110/300], Train Loss: 0.005604
Validation Loss: 0.00507791
Epoch [111/300], Train Loss: 0.005617
Validation Loss: 0.00511662
Epoch [112/300], Train Loss: 0.005595
Validation Loss: 0.00507471
Epoch [113/300], Train Loss: 0.005607
Validation Loss: 0.00507632
Epoch [114/300], Train Loss: 0.005618
Validation Loss: 0.00508074
Epoch [115/300], Train Loss: 0.005575
Validation Loss: 0.00507603
Epoch [116/300], Train Loss: 0.005575
Validation Loss: 0.00506834
Epoch [117/300], Train Loss: 0.005566
Validation Loss: 0.00507383
Epoch [118/300], Train Loss: 0.005596
Validation Loss: 0.00506536
Epoch [119/300], Train Loss: 0.005602
Validation Loss: 0.00508113
Epoch [120/300], Train Loss: 0.005595
Validation Loss: 0.00506403
Epoch [121/300], Train Loss: 0.005603
Validation Loss: 0.00507178
Epoch [122/300], Train Loss: 0.005591
Validation Loss: 0.00506444
Epoch [123/300], Train Loss: 0.005570
Validation Loss: 0.00506101
Epoch [124/300], Train Loss: 0.005572
Validation Loss: 0.00507308
Epoch [125/300], Train Loss: 0.005577
Validation Loss: 0.00505519
Epoch [126/300], Train Loss: 0.005561
Validation Loss: 0.00505934
Epoch [127/300], Train Loss: 0.005578
Validation Loss: 0.00506114
Epoch [128/300], Train Loss: 0.005607
Validation Loss: 0.00505612
Epoch [129/300], Train Loss: 0.005553
Validation Loss: 0.00505110
Epoch [130/300], Train Loss: 0.005559
Validation Loss: 0.00506172
Epoch [131/300], Train Loss: 0.005570
Validation Loss: 0.00504831
Epoch [132/300], Train Loss: 0.005556
Validation Loss: 0.00505689
Epoch [133/300], Train Loss: 0.005549
Validation Loss: 0.00504582
Epoch [134/300], Train Loss: 0.005558
Validation Loss: 0.00504599
Epoch [135/300], Train Loss: 0.005544
Validation Loss: 0.00504677
Epoch [136/300], Train Loss: 0.005537
Validation Loss: 0.00505796
Epoch [137/300], Train Loss: 0.005576
Validation Loss: 0.00504250
Epoch [138/300], Train Loss: 0.005568
Validation Loss: 0.00504864
Epoch [139/300], Train Loss: 0.005570
Validation Loss: 0.00504063
Epoch [140/300], Train Loss: 0.005563
Validation Loss: 0.00504499
Epoch [141/300], Train Loss: 0.005541
Validation Loss: 0.00503863
Epoch [142/300], Train Loss: 0.005568
Validation Loss: 0.00505890
Epoch [143/300], Train Loss: 0.005537
Validation Loss: 0.00503705
Epoch [144/300], Train Loss: 0.005537
Validation Loss: 0.00505861
Epoch [145/300], Train Loss: 0.005559
Validation Loss: 0.00503482
Epoch [146/300], Train Loss: 0.005546
Validation Loss: 0.00503503
Epoch [147/300], Train Loss: 0.005545
Validation Loss: 0.00503483
Epoch [148/300], Train Loss: 0.005565
Validation Loss: 0.00503764
Epoch [149/300], Train Loss: 0.005548
Validation Loss: 0.00503661
Epoch [150/300], Train Loss: 0.005522
Validation Loss: 0.00502964
Epoch [151/300], Train Loss: 0.005528
Validation Loss: 0.00505047
Epoch [152/300], Train Loss: 0.005541
Validation Loss: 0.00502775
Epoch [153/300], Train Loss: 0.005513
Validation Loss: 0.00503406
Epoch [154/300], Train Loss: 0.005507
Validation Loss: 0.00502882
Epoch [155/300], Train Loss: 0.005545
Validation Loss: 0.00502667
Epoch [156/300], Train Loss: 0.005563
Validation Loss: 0.00502459
Epoch [157/300], Train Loss: 0.005548
Validation Loss: 0.00502451
Epoch [158/300], Train Loss: 0.005517
Validation Loss: 0.00503199
Epoch [159/300], Train Loss: 0.005517
Validation Loss: 0.00502235
Epoch [160/300], Train Loss: 0.005533
Validation Loss: 0.00502486
Epoch [161/300], Train Loss: 0.005531
Validation Loss: 0.00502553
Epoch [162/300], Train Loss: 0.005506
Validation Loss: 0.00502099
Epoch [163/300], Train Loss: 0.005546
Validation Loss: 0.00502521
Epoch [164/300], Train Loss: 0.005594
Validation Loss: 0.00501924
Epoch [165/300], Train Loss: 0.005594
Validation Loss: 0.00504436
Epoch [166/300], Train Loss: 0.005596
Validation Loss: 0.00502393
Epoch [167/300], Train Loss: 0.005546
Validation Loss: 0.00501734
Epoch [168/300], Train Loss: 0.005560
Validation Loss: 0.00504044
Epoch [169/300], Train Loss: 0.005511
Validation Loss: 0.00501693
Epoch [170/300], Train Loss: 0.005551
Validation Loss: 0.00503703
Epoch [171/300], Train Loss: 0.005524
Validation Loss: 0.00501460
Epoch [172/300], Train Loss: 0.005538
Validation Loss: 0.00503156
Epoch [173/300], Train Loss: 0.005510
Validation Loss: 0.00501300
Epoch [174/300], Train Loss: 0.005551
Validation Loss: 0.00502354
Epoch [175/300], Train Loss: 0.005561
Validation Loss: 0.00501629
Epoch [176/300], Train Loss: 0.005554
Validation Loss: 0.00501176
Epoch [177/300], Train Loss: 0.005525
Validation Loss: 0.00503955
Epoch [178/300], Train Loss: 0.005550
Validation Loss: 0.00501023
Epoch [179/300], Train Loss: 0.005560
Validation Loss: 0.00501453
Epoch [180/300], Train Loss: 0.005496
Validation Loss: 0.00501312
Epoch [181/300], Train Loss: 0.005527
Validation Loss: 0.00501118
Epoch [182/300], Train Loss: 0.005510
Validation Loss: 0.00501454
Epoch [183/300], Train Loss: 0.005496
Validation Loss: 0.00501079
Epoch [184/300], Train Loss: 0.005508
Validation Loss: 0.00501414
Epoch [185/300], Train Loss: 0.005518
Validation Loss: 0.00500594
Epoch [186/300], Train Loss: 0.005545
Validation Loss: 0.00501514
Epoch [187/300], Train Loss: 0.005524
Validation Loss: 0.00501289
Epoch [188/300], Train Loss: 0.005481
Validation Loss: 0.00500344
Epoch [189/300], Train Loss: 0.005552
Validation Loss: 0.00501169
Epoch [190/300], Train Loss: 0.005477
Validation Loss: 0.00500434
Epoch [191/300], Train Loss: 0.005504
Validation Loss: 0.00500489
Epoch [192/300], Train Loss: 0.005492
Validation Loss: 0.00500897
Epoch [193/300], Train Loss: 0.005524
Validation Loss: 0.00500786
Epoch [194/300], Train Loss: 0.005480
Validation Loss: 0.00500575
Epoch [195/300], Train Loss: 0.005498
Validation Loss: 0.00500626
Epoch [196/300], Train Loss: 0.005548
Validation Loss: 0.00500127
Epoch [197/300], Train Loss: 0.005534
Validation Loss: 0.00499943
Epoch [198/300], Train Loss: 0.005499
Validation Loss: 0.00501474
Epoch [199/300], Train Loss: 0.005485
Validation Loss: 0.00499974
Epoch [200/300], Train Loss: 0.005528
Validation Loss: 0.00500167
Epoch [201/300], Train Loss: 0.005499
Validation Loss: 0.00500474
Epoch [202/300], Train Loss: 0.005483
Validation Loss: 0.00499654
Epoch [203/300], Train Loss: 0.005500
Validation Loss: 0.00499824
Epoch [204/300], Train Loss: 0.005489
Validation Loss: 0.00501090
Epoch [205/300], Train Loss: 0.005517
Validation Loss: 0.00499535
Epoch [206/300], Train Loss: 0.005507
Validation Loss: 0.00500204
Epoch [207/300], Train Loss: 0.005503
Validation Loss: 0.00499526
Epoch [208/300], Train Loss: 0.005572
Validation Loss: 0.00500971
Epoch [209/300], Train Loss: 0.005535
Validation Loss: 0.00500140
Epoch [210/300], Train Loss: 0.005488
Validation Loss: 0.00499340
Epoch [211/300], Train Loss: 0.005523
Validation Loss: 0.00500798
Epoch [212/300], Train Loss: 0.005505
Validation Loss: 0.00499190
Epoch [213/300], Train Loss: 0.005495
Validation Loss: 0.00499623
Epoch [214/300], Train Loss: 0.005465
Validation Loss: 0.00499398
Epoch [215/300], Train Loss: 0.005487
Validation Loss: 0.00499642
Epoch [216/300], Train Loss: 0.005543
Validation Loss: 0.00499122
Epoch [217/300], Train Loss: 0.005528
Validation Loss: 0.00500351
Epoch [218/300], Train Loss: 0.005508
Validation Loss: 0.00498975
Epoch [219/300], Train Loss: 0.005492
Validation Loss: 0.00501679
Epoch [220/300], Train Loss: 0.005510
Validation Loss: 0.00499079
Epoch [221/300], Train Loss: 0.005512
Validation Loss: 0.00498768
Epoch [222/300], Train Loss: 0.005504
Validation Loss: 0.00500549
Epoch [223/300], Train Loss: 0.005487
Validation Loss: 0.00498699
Epoch [224/300], Train Loss: 0.005499
Validation Loss: 0.00500081
Epoch [225/300], Train Loss: 0.005492
Validation Loss: 0.00498616
Epoch [226/300], Train Loss: 0.005494
Validation Loss: 0.00499741
Epoch [227/300], Train Loss: 0.005486
Validation Loss: 0.00498721
Epoch [228/300], Train Loss: 0.005493
Validation Loss: 0.00499202
Epoch [229/300], Train Loss: 0.005485
Validation Loss: 0.00500411
Epoch [230/300], Train Loss: 0.005467
Validation Loss: 0.00498724
Epoch [231/300], Train Loss: 0.005500
Validation Loss: 0.00499030
Epoch [232/300], Train Loss: 0.005504
Validation Loss: 0.00500371
Epoch [233/300], Train Loss: 0.005479
Validation Loss: 0.00498391
Epoch [234/300], Train Loss: 0.005497
Validation Loss: 0.00498708
Epoch [235/300], Train Loss: 0.005472
Validation Loss: 0.00498591
Epoch [236/300], Train Loss: 0.005505
Validation Loss: 0.00498868
Epoch [237/300], Train Loss: 0.005479
Validation Loss: 0.00498248
Epoch [238/300], Train Loss: 0.005522
Validation Loss: 0.00498962
Epoch [239/300], Train Loss: 0.005526
Validation Loss: 0.00499127
Epoch [240/300], Train Loss: 0.005465
Validation Loss: 0.00498313
Epoch [241/300], Train Loss: 0.005463
Validation Loss: 0.00498104
Epoch [242/300], Train Loss: 0.005475
Validation Loss: 0.00499065
Epoch [243/300], Train Loss: 0.005495
Validation Loss: 0.00498087
Epoch [244/300], Train Loss: 0.005457
Validation Loss: 0.00498408
Epoch [245/300], Train Loss: 0.005484
Validation Loss: 0.00498606
Epoch [246/300], Train Loss: 0.005498
Validation Loss: 0.00497940
Epoch [247/300], Train Loss: 0.005494
Validation Loss: 0.00500156
Epoch [248/300], Train Loss: 0.005480
Validation Loss: 0.00497825
Epoch [249/300], Train Loss: 0.005492
Validation Loss: 0.00499020
Epoch [250/300], Train Loss: 0.005486
Validation Loss: 0.00497950
Epoch [251/300], Train Loss: 0.005479
Validation Loss: 0.00497958
Epoch [252/300], Train Loss: 0.005444
Validation Loss: 0.00498951
Epoch [253/300], Train Loss: 0.005483
Validation Loss: 0.00497781
Epoch [254/300], Train Loss: 0.005454
Validation Loss: 0.00498551
Epoch [255/300], Train Loss: 0.005513
Validation Loss: 0.00498095
Epoch [256/300], Train Loss: 0.005453
Validation Loss: 0.00497628
Epoch [257/300], Train Loss: 0.005508
Validation Loss: 0.00498120
Epoch [258/300], Train Loss: 0.005470
Validation Loss: 0.00498996
Epoch [259/300], Train Loss: 0.005485
Validation Loss: 0.00497563
Epoch [260/300], Train Loss: 0.005476
Validation Loss: 0.00498251
Epoch [261/300], Train Loss: 0.005456
Validation Loss: 0.00497711
Epoch [262/300], Train Loss: 0.005468
Validation Loss: 0.00497649
Epoch [263/300], Train Loss: 0.005504
Validation Loss: 0.00497554
Epoch [264/300], Train Loss: 0.005472
Validation Loss: 0.00498580
Epoch [265/300], Train Loss: 0.005485
Validation Loss: 0.00497318
Epoch [266/300], Train Loss: 0.005466
Validation Loss: 0.00497786
Epoch [267/300], Train Loss: 0.005500
Validation Loss: 0.00498337
Epoch [268/300], Train Loss: 0.005465
Validation Loss: 0.00497182
Epoch [269/300], Train Loss: 0.005491
Validation Loss: 0.00498474
Epoch [270/300], Train Loss: 0.005458
Validation Loss: 0.00497478
Epoch [271/300], Train Loss: 0.005441
Validation Loss: 0.00497154
Epoch [272/300], Train Loss: 0.005464
Validation Loss: 0.00497729
Epoch [273/300], Train Loss: 0.005466
Validation Loss: 0.00497591
Epoch [274/300], Train Loss: 0.005460
Validation Loss: 0.00497023
Epoch [275/300], Train Loss: 0.005468
Validation Loss: 0.00498364
Epoch [276/300], Train Loss: 0.005442
Validation Loss: 0.00497257
Epoch [277/300], Train Loss: 0.005460
Validation Loss: 0.00497085
Epoch [278/300], Train Loss: 0.005456
Validation Loss: 0.00497766
Epoch [279/300], Train Loss: 0.005434
Validation Loss: 0.00496958
Epoch [280/300], Train Loss: 0.005460
Validation Loss: 0.00497306
Epoch [281/300], Train Loss: 0.005465
Validation Loss: 0.00497704
Epoch [282/300], Train Loss: 0.005477
Validation Loss: 0.00496846
Epoch [283/300], Train Loss: 0.005461
Validation Loss: 0.00498288
Epoch [284/300], Train Loss: 0.005494
Validation Loss: 0.00497187
Epoch [285/300], Train Loss: 0.005456
Validation Loss: 0.00496926
Epoch [286/300], Train Loss: 0.005458
Validation Loss: 0.00497009
Epoch [287/300], Train Loss: 0.005476
Validation Loss: 0.00497294
Epoch [288/300], Train Loss: 0.005448
Validation Loss: 0.00497636
Epoch [289/300], Train Loss: 0.005465
Validation Loss: 0.00496747
Epoch [290/300], Train Loss: 0.005484
Validation Loss: 0.00497091
Epoch [291/300], Train Loss: 0.005464
Validation Loss: 0.00497206
Epoch [292/300], Train Loss: 0.005448
Validation Loss: 0.00497174
Epoch [293/300], Train Loss: 0.005464
Validation Loss: 0.00496707
Epoch [294/300], Train Loss: 0.005477
Validation Loss: 0.00497960
Epoch [295/300], Train Loss: 0.005456
Validation Loss: 0.00496597
Epoch [296/300], Train Loss: 0.005484
Validation Loss: 0.00497046
Epoch [297/300], Train Loss: 0.005449
Validation Loss: 0.00498418
Epoch [298/300], Train Loss: 0.005454
Validation Loss: 0.00496512
Epoch [299/300], Train Loss: 0.005440
Validation Loss: 0.00496605
Epoch [300/300], Train Loss: 0.005467
Validation Loss: 0.00497017

Evaluating model for: Router
Run 67/72 completed in 1351.74 seconds with: {'MAE': np.float32(0.20736171), 'MSE': np.float32(0.07745957), 'RMSE': np.float32(0.27831557), 'SAE': np.float32(2.392914e-05), 'NDE': np.float32(0.013912631)}

Run 68/72: hidden=512, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Router
Dataset length: 1065 windows

Epoch [1/300], Train Loss: 0.070957
Validation Loss: 0.05552100
Epoch [2/300], Train Loss: 0.041030
Validation Loss: 0.01709485
Epoch [3/300], Train Loss: 0.010953
Validation Loss: 0.00545466
Epoch [4/300], Train Loss: 0.007521
Validation Loss: 0.00796288
Epoch [5/300], Train Loss: 0.006612
Validation Loss: 0.00556244
Epoch [6/300], Train Loss: 0.006304
Validation Loss: 0.00525086
Epoch [7/300], Train Loss: 0.005889
Validation Loss: 0.00559560
Epoch [8/300], Train Loss: 0.005782
Validation Loss: 0.00530087
Epoch [9/300], Train Loss: 0.005724
Validation Loss: 0.00523058
Epoch [10/300], Train Loss: 0.005667
Validation Loss: 0.00524891
Epoch [11/300], Train Loss: 0.005665
Validation Loss: 0.00522915
Epoch [12/300], Train Loss: 0.005638
Validation Loss: 0.00522316
Epoch [13/300], Train Loss: 0.005657
Validation Loss: 0.00522598
Epoch [14/300], Train Loss: 0.005666
Validation Loss: 0.00521718
Epoch [15/300], Train Loss: 0.005620
Validation Loss: 0.00521764
Epoch [16/300], Train Loss: 0.005683
Validation Loss: 0.00521742
Epoch [17/300], Train Loss: 0.005615
Validation Loss: 0.00521274
Epoch [18/300], Train Loss: 0.005626
Validation Loss: 0.00521402
Epoch [19/300], Train Loss: 0.005636
Validation Loss: 0.00521050
Epoch [20/300], Train Loss: 0.005664
Validation Loss: 0.00520797
Epoch [21/300], Train Loss: 0.005689
Validation Loss: 0.00521321
Epoch [22/300], Train Loss: 0.005671
Validation Loss: 0.00520575
Epoch [23/300], Train Loss: 0.005639
Validation Loss: 0.00520334
Epoch [24/300], Train Loss: 0.005658
Validation Loss: 0.00521508
Epoch [25/300], Train Loss: 0.005631
Validation Loss: 0.00519975
Epoch [26/300], Train Loss: 0.005632
Validation Loss: 0.00519791
Epoch [27/300], Train Loss: 0.005606
Validation Loss: 0.00520264
Epoch [28/300], Train Loss: 0.005597
Validation Loss: 0.00519535
Epoch [29/300], Train Loss: 0.005614
Validation Loss: 0.00519249
Epoch [30/300], Train Loss: 0.005591
Validation Loss: 0.00520439
Epoch [31/300], Train Loss: 0.005603
Validation Loss: 0.00518879
Epoch [32/300], Train Loss: 0.005628
Validation Loss: 0.00519028
Epoch [33/300], Train Loss: 0.005602
Validation Loss: 0.00519078
Epoch [34/300], Train Loss: 0.005603
Validation Loss: 0.00518438
Epoch [35/300], Train Loss: 0.005601
Validation Loss: 0.00518964
Epoch [36/300], Train Loss: 0.005564
Validation Loss: 0.00518110
Epoch [37/300], Train Loss: 0.005589
Validation Loss: 0.00517860
Epoch [38/300], Train Loss: 0.005600
Validation Loss: 0.00517771
Epoch [39/300], Train Loss: 0.005622
Validation Loss: 0.00517578
Epoch [40/300], Train Loss: 0.005624
Validation Loss: 0.00517653
Epoch [41/300], Train Loss: 0.005614
Validation Loss: 0.00517348
Epoch [42/300], Train Loss: 0.005600
Validation Loss: 0.00517008
Epoch [43/300], Train Loss: 0.005586
Validation Loss: 0.00516793
Epoch [44/300], Train Loss: 0.005595
Validation Loss: 0.00516897
Epoch [45/300], Train Loss: 0.005583
Validation Loss: 0.00516322
Epoch [46/300], Train Loss: 0.005578
Validation Loss: 0.00516173
Epoch [47/300], Train Loss: 0.005595
Validation Loss: 0.00516360
Epoch [48/300], Train Loss: 0.005554
Validation Loss: 0.00515822
Epoch [49/300], Train Loss: 0.005566
Validation Loss: 0.00515688
Epoch [50/300], Train Loss: 0.005575
Validation Loss: 0.00515577
Epoch [51/300], Train Loss: 0.005607
Validation Loss: 0.00515167
Epoch [52/300], Train Loss: 0.005550
Validation Loss: 0.00515688
Epoch [53/300], Train Loss: 0.005566
Validation Loss: 0.00514756
Epoch [54/300], Train Loss: 0.005554
Validation Loss: 0.00515025
Epoch [55/300], Train Loss: 0.005579
Validation Loss: 0.00514424
Epoch [56/300], Train Loss: 0.005572
Validation Loss: 0.00514462
Epoch [57/300], Train Loss: 0.005537
Validation Loss: 0.00513929
Epoch [58/300], Train Loss: 0.005573
Validation Loss: 0.00513583
Epoch [59/300], Train Loss: 0.005544
Validation Loss: 0.00513660
Epoch [60/300], Train Loss: 0.005562
Validation Loss: 0.00513195
Epoch [61/300], Train Loss: 0.005575
Validation Loss: 0.00512803
Epoch [62/300], Train Loss: 0.005553
Validation Loss: 0.00513234
Epoch [63/300], Train Loss: 0.005563
Validation Loss: 0.00512328
Epoch [64/300], Train Loss: 0.005544
Validation Loss: 0.00512126
Epoch [65/300], Train Loss: 0.005564
Validation Loss: 0.00511465
Epoch [66/300], Train Loss: 0.005550
Validation Loss: 0.00511700
Epoch [67/300], Train Loss: 0.005573
Validation Loss: 0.00511716
Epoch [68/300], Train Loss: 0.005567
Validation Loss: 0.00510244
Epoch [69/300], Train Loss: 0.005576
Validation Loss: 0.00510968
Epoch [70/300], Train Loss: 0.005594
Validation Loss: 0.00509543
Epoch [71/300], Train Loss: 0.005548
Validation Loss: 0.00509441
Epoch [72/300], Train Loss: 0.005557
Validation Loss: 0.00508133
Epoch [73/300], Train Loss: 0.005525
Validation Loss: 0.00507610
Epoch [74/300], Train Loss: 0.005501
Validation Loss: 0.00506290
Epoch [75/300], Train Loss: 0.005557
Validation Loss: 0.00504503
Epoch [76/300], Train Loss: 0.005482
Validation Loss: 0.00505971
Epoch [77/300], Train Loss: 0.005521
Validation Loss: 0.00502502
Epoch [78/300], Train Loss: 0.005470
Validation Loss: 0.00504939
Epoch [79/300], Train Loss: 0.005543
Validation Loss: 0.00501999
Epoch [80/300], Train Loss: 0.005503
Validation Loss: 0.00505759
Epoch [81/300], Train Loss: 0.005514
Validation Loss: 0.00500832
Epoch [82/300], Train Loss: 0.005492
Validation Loss: 0.00501216
Epoch [83/300], Train Loss: 0.005482
Validation Loss: 0.00499964
Epoch [84/300], Train Loss: 0.005454
Validation Loss: 0.00500594
Epoch [85/300], Train Loss: 0.005517
Validation Loss: 0.00502817
Epoch [86/300], Train Loss: 0.005478
Validation Loss: 0.00501066
Epoch [87/300], Train Loss: 0.005466
Validation Loss: 0.00500700
Epoch [88/300], Train Loss: 0.005513
Validation Loss: 0.00504296
Epoch [89/300], Train Loss: 0.005520
Validation Loss: 0.00499450
Epoch [90/300], Train Loss: 0.005453
Validation Loss: 0.00499874
Epoch [91/300], Train Loss: 0.005449
Validation Loss: 0.00498786
Epoch [92/300], Train Loss: 0.005471
Validation Loss: 0.00498883
Epoch [93/300], Train Loss: 0.005445
Validation Loss: 0.00498610
Epoch [94/300], Train Loss: 0.005459
Validation Loss: 0.00497671
Epoch [95/300], Train Loss: 0.005427
Validation Loss: 0.00497153
Epoch [96/300], Train Loss: 0.005497
Validation Loss: 0.00496643
Epoch [97/300], Train Loss: 0.005452
Validation Loss: 0.00496241
Epoch [98/300], Train Loss: 0.005438
Validation Loss: 0.00496891
Epoch [99/300], Train Loss: 0.005448
Validation Loss: 0.00496019
Epoch [100/300], Train Loss: 0.005425
Validation Loss: 0.00496036
Epoch [101/300], Train Loss: 0.005474
Validation Loss: 0.00498469
Epoch [102/300], Train Loss: 0.005439
Validation Loss: 0.00495739
Epoch [103/300], Train Loss: 0.005431
Validation Loss: 0.00495462
Epoch [104/300], Train Loss: 0.005453
Validation Loss: 0.00496265
Epoch [105/300], Train Loss: 0.005432
Validation Loss: 0.00494882
Epoch [106/300], Train Loss: 0.005460
Validation Loss: 0.00494663
Epoch [107/300], Train Loss: 0.005427
Validation Loss: 0.00494961
Epoch [108/300], Train Loss: 0.005445
Validation Loss: 0.00494523
Epoch [109/300], Train Loss: 0.005424
Validation Loss: 0.00496266
Epoch [110/300], Train Loss: 0.005437
Validation Loss: 0.00495383
Epoch [111/300], Train Loss: 0.005445
Validation Loss: 0.00501805
Epoch [112/300], Train Loss: 0.005431
Validation Loss: 0.00494615
Epoch [113/300], Train Loss: 0.005446
Validation Loss: 0.00494320
Epoch [114/300], Train Loss: 0.005452
Validation Loss: 0.00494297
Epoch [115/300], Train Loss: 0.005408
Validation Loss: 0.00492594
Epoch [116/300], Train Loss: 0.005407
Validation Loss: 0.00492204
Epoch [117/300], Train Loss: 0.005406
Validation Loss: 0.00491769
Epoch [118/300], Train Loss: 0.005429
Validation Loss: 0.00494266
Epoch [119/300], Train Loss: 0.005465
Validation Loss: 0.00496446
Epoch [120/300], Train Loss: 0.005441
Validation Loss: 0.00493400
Epoch [121/300], Train Loss: 0.005440
Validation Loss: 0.00493848
Epoch [122/300], Train Loss: 0.005424
Validation Loss: 0.00492633
Epoch [123/300], Train Loss: 0.005404
Validation Loss: 0.00490814
Epoch [124/300], Train Loss: 0.005404
Validation Loss: 0.00492804
Epoch [125/300], Train Loss: 0.005404
Validation Loss: 0.00490653
Epoch [126/300], Train Loss: 0.005398
Validation Loss: 0.00490084
Epoch [127/300], Train Loss: 0.005415
Validation Loss: 0.00488675
Epoch [128/300], Train Loss: 0.005433
Validation Loss: 0.00490757
Epoch [129/300], Train Loss: 0.005379
Validation Loss: 0.00489994
Epoch [130/300], Train Loss: 0.005382
Validation Loss: 0.00483870
Epoch [131/300], Train Loss: 0.005367
Validation Loss: 0.00483015
Epoch [132/300], Train Loss: 0.005352
Validation Loss: 0.00492281
Epoch [133/300], Train Loss: 0.005401
Validation Loss: 0.00494327
Epoch [134/300], Train Loss: 0.005377
Validation Loss: 0.00492361
Epoch [135/300], Train Loss: 0.005378
Validation Loss: 0.00490078
Epoch [136/300], Train Loss: 0.005360
Validation Loss: 0.00482715
Epoch [137/300], Train Loss: 0.005366
Validation Loss: 0.00476727
Epoch [138/300], Train Loss: 0.005345
Validation Loss: 0.00487581
Epoch [139/300], Train Loss: 0.005359
Validation Loss: 0.00483704
Epoch [140/300], Train Loss: 0.005336
Validation Loss: 0.00490746
Epoch [141/300], Train Loss: 0.005399
Validation Loss: 0.00488618
Epoch [142/300], Train Loss: 0.005408
Validation Loss: 0.00489942
Epoch [143/300], Train Loss: 0.005358
Validation Loss: 0.00479591
Epoch [144/300], Train Loss: 0.005347
Validation Loss: 0.00468662
Epoch [145/300], Train Loss: 0.005357
Validation Loss: 0.00491838
Epoch [146/300], Train Loss: 0.005378
Validation Loss: 0.00490488
Epoch [147/300], Train Loss: 0.005368
Validation Loss: 0.00481969
Epoch [148/300], Train Loss: 0.005350
Validation Loss: 0.00469960
Epoch [149/300], Train Loss: 0.005303
Validation Loss: 0.00480442
Epoch [150/300], Train Loss: 0.005312
Validation Loss: 0.00484876
Epoch [151/300], Train Loss: 0.005319
Validation Loss: 0.00471482
Epoch [152/300], Train Loss: 0.005308
Validation Loss: 0.00479606
Epoch [153/300], Train Loss: 0.005293
Validation Loss: 0.00489092
Epoch [154/300], Train Loss: 0.005346
Validation Loss: 0.00494470
Early stopping triggered

Evaluating model for: Router
Run 68/72 completed in 926.00 seconds with: {'MAE': np.float32(0.20494665), 'MSE': np.float32(0.076964974), 'RMSE': np.float32(0.27742562), 'SAE': np.float32(0.00034230837), 'NDE': np.float32(0.013868142)}

Run 69/72: hidden=512, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Router
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.074977
Validation Loss: 0.06747151
Epoch [2/300], Train Loss: 0.064130
Validation Loss: 0.05673972
Epoch [3/300], Train Loss: 0.053527
Validation Loss: 0.04544530
Epoch [4/300], Train Loss: 0.041212
Validation Loss: 0.03257393
Epoch [5/300], Train Loss: 0.027029
Validation Loss: 0.01748615
Epoch [6/300], Train Loss: 0.011894
Validation Loss: 0.00596782
Epoch [7/300], Train Loss: 0.008868
Validation Loss: 0.01061191
Epoch [8/300], Train Loss: 0.007520
Validation Loss: 0.00595295
Epoch [9/300], Train Loss: 0.006214
Validation Loss: 0.00731502
Epoch [10/300], Train Loss: 0.007179
Validation Loss: 0.00705114
Epoch [11/300], Train Loss: 0.006369
Validation Loss: 0.00599205
Epoch [12/300], Train Loss: 0.005611
Validation Loss: 0.00610999
Epoch [13/300], Train Loss: 0.005883
Validation Loss: 0.00628350
Epoch [14/300], Train Loss: 0.005742
Validation Loss: 0.00589011
Epoch [15/300], Train Loss: 0.005628
Validation Loss: 0.00593321
Epoch [16/300], Train Loss: 0.005677
Validation Loss: 0.00595549
Epoch [17/300], Train Loss: 0.005718
Validation Loss: 0.00586068
Epoch [18/300], Train Loss: 0.005610
Validation Loss: 0.00589616
Epoch [19/300], Train Loss: 0.005528
Validation Loss: 0.00590538
Epoch [20/300], Train Loss: 0.005655
Validation Loss: 0.00586447
Epoch [21/300], Train Loss: 0.005565
Validation Loss: 0.00586159
Epoch [22/300], Train Loss: 0.005570
Validation Loss: 0.00585947
Epoch [23/300], Train Loss: 0.005649
Validation Loss: 0.00585911
Epoch [24/300], Train Loss: 0.005597
Validation Loss: 0.00588850
Epoch [25/300], Train Loss: 0.005552
Validation Loss: 0.00586311
Epoch [26/300], Train Loss: 0.005467
Validation Loss: 0.00585214
Epoch [27/300], Train Loss: 0.005590
Validation Loss: 0.00585347
Epoch [28/300], Train Loss: 0.005581
Validation Loss: 0.00585056
Epoch [29/300], Train Loss: 0.005691
Validation Loss: 0.00585083
Epoch [30/300], Train Loss: 0.005478
Validation Loss: 0.00585252
Epoch [31/300], Train Loss: 0.005485
Validation Loss: 0.00585962
Epoch [32/300], Train Loss: 0.005531
Validation Loss: 0.00585820
Epoch [33/300], Train Loss: 0.005716
Validation Loss: 0.00585769
Epoch [34/300], Train Loss: 0.005535
Validation Loss: 0.00584578
Epoch [35/300], Train Loss: 0.005559
Validation Loss: 0.00584506
Epoch [36/300], Train Loss: 0.005595
Validation Loss: 0.00584954
Epoch [37/300], Train Loss: 0.005529
Validation Loss: 0.00585088
Epoch [38/300], Train Loss: 0.005403
Validation Loss: 0.00584899
Epoch [39/300], Train Loss: 0.005528
Validation Loss: 0.00585217
Epoch [40/300], Train Loss: 0.005651
Validation Loss: 0.00584181
Epoch [41/300], Train Loss: 0.005607
Validation Loss: 0.00584896
Epoch [42/300], Train Loss: 0.005734
Validation Loss: 0.00583954
Epoch [43/300], Train Loss: 0.005658
Validation Loss: 0.00583921
Epoch [44/300], Train Loss: 0.005539
Validation Loss: 0.00584337
Epoch [45/300], Train Loss: 0.005530
Validation Loss: 0.00583777
Epoch [46/300], Train Loss: 0.005509
Validation Loss: 0.00583601
Epoch [47/300], Train Loss: 0.005592
Validation Loss: 0.00584016
Epoch [48/300], Train Loss: 0.005723
Validation Loss: 0.00584397
Epoch [49/300], Train Loss: 0.005605
Validation Loss: 0.00583529
Epoch [50/300], Train Loss: 0.005604
Validation Loss: 0.00583297
Epoch [51/300], Train Loss: 0.005580
Validation Loss: 0.00583208
Epoch [52/300], Train Loss: 0.005622
Validation Loss: 0.00583099
Epoch [53/300], Train Loss: 0.005591
Validation Loss: 0.00583227
Epoch [54/300], Train Loss: 0.005576
Validation Loss: 0.00583957
Epoch [55/300], Train Loss: 0.005583
Validation Loss: 0.00582881
Epoch [56/300], Train Loss: 0.005581
Validation Loss: 0.00582887
Epoch [57/300], Train Loss: 0.005661
Validation Loss: 0.00582753
Epoch [58/300], Train Loss: 0.005517
Validation Loss: 0.00582652
Epoch [59/300], Train Loss: 0.005561
Validation Loss: 0.00582533
Epoch [60/300], Train Loss: 0.005549
Validation Loss: 0.00582855
Epoch [61/300], Train Loss: 0.005497
Validation Loss: 0.00584477
Epoch [62/300], Train Loss: 0.005663
Validation Loss: 0.00583925
Epoch [63/300], Train Loss: 0.005419
Validation Loss: 0.00582387
Epoch [64/300], Train Loss: 0.005657
Validation Loss: 0.00582976
Epoch [65/300], Train Loss: 0.005481
Validation Loss: 0.00582791
Epoch [66/300], Train Loss: 0.005686
Validation Loss: 0.00585504
Epoch [67/300], Train Loss: 0.005520
Validation Loss: 0.00582361
Epoch [68/300], Train Loss: 0.005503
Validation Loss: 0.00582729
Epoch [69/300], Train Loss: 0.005547
Validation Loss: 0.00582239
Epoch [70/300], Train Loss: 0.005561
Validation Loss: 0.00581851
Epoch [71/300], Train Loss: 0.005616
Validation Loss: 0.00582454
Epoch [72/300], Train Loss: 0.005389
Validation Loss: 0.00581812
Epoch [73/300], Train Loss: 0.005465
Validation Loss: 0.00581871
Epoch [74/300], Train Loss: 0.005593
Validation Loss: 0.00581509
Epoch [75/300], Train Loss: 0.005449
Validation Loss: 0.00581438
Epoch [76/300], Train Loss: 0.005581
Validation Loss: 0.00581634
Epoch [77/300], Train Loss: 0.005561
Validation Loss: 0.00581579
Epoch [78/300], Train Loss: 0.005590
Validation Loss: 0.00581266
Epoch [79/300], Train Loss: 0.005454
Validation Loss: 0.00581242
Epoch [80/300], Train Loss: 0.005608
Validation Loss: 0.00581569
Epoch [81/300], Train Loss: 0.005450
Validation Loss: 0.00581032
Epoch [82/300], Train Loss: 0.005673
Validation Loss: 0.00581058
Epoch [83/300], Train Loss: 0.005568
Validation Loss: 0.00580905
Epoch [84/300], Train Loss: 0.005474
Validation Loss: 0.00581486
Epoch [85/300], Train Loss: 0.005526
Validation Loss: 0.00581314
Epoch [86/300], Train Loss: 0.005475
Validation Loss: 0.00580725
Epoch [87/300], Train Loss: 0.005552
Validation Loss: 0.00580620
Epoch [88/300], Train Loss: 0.005529
Validation Loss: 0.00580526
Epoch [89/300], Train Loss: 0.005541
Validation Loss: 0.00580534
Epoch [90/300], Train Loss: 0.005661
Validation Loss: 0.00580521
Epoch [91/300], Train Loss: 0.005598
Validation Loss: 0.00580989
Epoch [92/300], Train Loss: 0.005534
Validation Loss: 0.00581442
Epoch [93/300], Train Loss: 0.005591
Validation Loss: 0.00580900
Epoch [94/300], Train Loss: 0.005377
Validation Loss: 0.00580264
Epoch [95/300], Train Loss: 0.005520
Validation Loss: 0.00580092
Epoch [96/300], Train Loss: 0.005597
Validation Loss: 0.00580077
Epoch [97/300], Train Loss: 0.005490
Validation Loss: 0.00580076
Epoch [98/300], Train Loss: 0.005583
Validation Loss: 0.00580290
Epoch [99/300], Train Loss: 0.005538
Validation Loss: 0.00580239
Epoch [100/300], Train Loss: 0.005539
Validation Loss: 0.00580154
Epoch [101/300], Train Loss: 0.005500
Validation Loss: 0.00580244
Epoch [102/300], Train Loss: 0.005566
Validation Loss: 0.00579701
Epoch [103/300], Train Loss: 0.005523
Validation Loss: 0.00579872
Epoch [104/300], Train Loss: 0.005471
Validation Loss: 0.00579545
Epoch [105/300], Train Loss: 0.005551
Validation Loss: 0.00580327
Epoch [106/300], Train Loss: 0.005710
Validation Loss: 0.00579806
Epoch [107/300], Train Loss: 0.005504
Validation Loss: 0.00579362
Epoch [108/300], Train Loss: 0.005688
Validation Loss: 0.00579346
Epoch [109/300], Train Loss: 0.005770
Validation Loss: 0.00579376
Epoch [110/300], Train Loss: 0.005486
Validation Loss: 0.00579421
Epoch [111/300], Train Loss: 0.005464
Validation Loss: 0.00579723
Epoch [112/300], Train Loss: 0.005625
Validation Loss: 0.00580079
Epoch [113/300], Train Loss: 0.005628
Validation Loss: 0.00579040
Epoch [114/300], Train Loss: 0.005662
Validation Loss: 0.00579761
Epoch [115/300], Train Loss: 0.005610
Validation Loss: 0.00579016
Epoch [116/300], Train Loss: 0.005500
Validation Loss: 0.00579863
Epoch [117/300], Train Loss: 0.005542
Validation Loss: 0.00580394
Epoch [118/300], Train Loss: 0.005518
Validation Loss: 0.00578739
Epoch [119/300], Train Loss: 0.005499
Validation Loss: 0.00578795
Epoch [120/300], Train Loss: 0.005527
Validation Loss: 0.00578606
Epoch [121/300], Train Loss: 0.005457
Validation Loss: 0.00578560
Epoch [122/300], Train Loss: 0.005454
Validation Loss: 0.00578715
Epoch [123/300], Train Loss: 0.005533
Validation Loss: 0.00579657
Epoch [124/300], Train Loss: 0.005534
Validation Loss: 0.00579281
Epoch [125/300], Train Loss: 0.005605
Validation Loss: 0.00578498
Epoch [126/300], Train Loss: 0.005591
Validation Loss: 0.00578313
Epoch [127/300], Train Loss: 0.005524
Validation Loss: 0.00578420
Epoch [128/300], Train Loss: 0.005633
Validation Loss: 0.00578270
Epoch [129/300], Train Loss: 0.005451
Validation Loss: 0.00578992
Epoch [130/300], Train Loss: 0.005648
Validation Loss: 0.00578893
Epoch [131/300], Train Loss: 0.005496
Validation Loss: 0.00578228
Epoch [132/300], Train Loss: 0.005476
Validation Loss: 0.00578110
Epoch [133/300], Train Loss: 0.005476
Validation Loss: 0.00577998
Epoch [134/300], Train Loss: 0.005639
Validation Loss: 0.00578243
Epoch [135/300], Train Loss: 0.005427
Validation Loss: 0.00577885
Epoch [136/300], Train Loss: 0.005524
Validation Loss: 0.00577877
Epoch [137/300], Train Loss: 0.005670
Validation Loss: 0.00577819
Epoch [138/300], Train Loss: 0.005496
Validation Loss: 0.00577857
Epoch [139/300], Train Loss: 0.005479
Validation Loss: 0.00577774
Epoch [140/300], Train Loss: 0.005451
Validation Loss: 0.00577877
Epoch [141/300], Train Loss: 0.005379
Validation Loss: 0.00577939
Epoch [142/300], Train Loss: 0.005428
Validation Loss: 0.00577679
Epoch [143/300], Train Loss: 0.005541
Validation Loss: 0.00577644
Epoch [144/300], Train Loss: 0.005506
Validation Loss: 0.00577449
Epoch [145/300], Train Loss: 0.005455
Validation Loss: 0.00577547
Epoch [146/300], Train Loss: 0.005414
Validation Loss: 0.00578090
Epoch [147/300], Train Loss: 0.005581
Validation Loss: 0.00577709
Epoch [148/300], Train Loss: 0.005401
Validation Loss: 0.00577308
Epoch [149/300], Train Loss: 0.005622
Validation Loss: 0.00577307
Epoch [150/300], Train Loss: 0.005739
Validation Loss: 0.00577518
Epoch [151/300], Train Loss: 0.005503
Validation Loss: 0.00577350
Epoch [152/300], Train Loss: 0.005691
Validation Loss: 0.00577234
Epoch [153/300], Train Loss: 0.005373
Validation Loss: 0.00577095
Epoch [154/300], Train Loss: 0.005396
Validation Loss: 0.00577180
Epoch [155/300], Train Loss: 0.005606
Validation Loss: 0.00577754
Epoch [156/300], Train Loss: 0.005529
Validation Loss: 0.00577046
Epoch [157/300], Train Loss: 0.005591
Validation Loss: 0.00577252
Epoch [158/300], Train Loss: 0.005501
Validation Loss: 0.00577205
Epoch [159/300], Train Loss: 0.005638
Validation Loss: 0.00577201
Epoch [160/300], Train Loss: 0.005477
Validation Loss: 0.00577191
Epoch [161/300], Train Loss: 0.005562
Validation Loss: 0.00577909
Epoch [162/300], Train Loss: 0.005448
Validation Loss: 0.00576880
Epoch [163/300], Train Loss: 0.005554
Validation Loss: 0.00576657
Epoch [164/300], Train Loss: 0.005428
Validation Loss: 0.00576607
Epoch [165/300], Train Loss: 0.005400
Validation Loss: 0.00576781
Epoch [166/300], Train Loss: 0.005387
Validation Loss: 0.00577063
Epoch [167/300], Train Loss: 0.005436
Validation Loss: 0.00576954
Epoch [168/300], Train Loss: 0.005460
Validation Loss: 0.00576613
Epoch [169/300], Train Loss: 0.005618
Validation Loss: 0.00576429
Epoch [170/300], Train Loss: 0.005377
Validation Loss: 0.00576383
Epoch [171/300], Train Loss: 0.005529
Validation Loss: 0.00576544
Epoch [172/300], Train Loss: 0.005471
Validation Loss: 0.00577333
Epoch [173/300], Train Loss: 0.005375
Validation Loss: 0.00576708
Epoch [174/300], Train Loss: 0.005586
Validation Loss: 0.00576313
Epoch [175/300], Train Loss: 0.005613
Validation Loss: 0.00576225
Epoch [176/300], Train Loss: 0.005512
Validation Loss: 0.00576229
Epoch [177/300], Train Loss: 0.005365
Validation Loss: 0.00576218
Epoch [178/300], Train Loss: 0.005374
Validation Loss: 0.00576410
Epoch [179/300], Train Loss: 0.005467
Validation Loss: 0.00577250
Epoch [180/300], Train Loss: 0.005692
Validation Loss: 0.00576894
Epoch [181/300], Train Loss: 0.005500
Validation Loss: 0.00575986
Epoch [182/300], Train Loss: 0.005480
Validation Loss: 0.00575986
Epoch [183/300], Train Loss: 0.005653
Validation Loss: 0.00575975
Epoch [184/300], Train Loss: 0.005481
Validation Loss: 0.00576070
Epoch [185/300], Train Loss: 0.005365
Validation Loss: 0.00575900
Epoch [186/300], Train Loss: 0.005564
Validation Loss: 0.00575825
Epoch [187/300], Train Loss: 0.005539
Validation Loss: 0.00575775
Epoch [188/300], Train Loss: 0.005447
Validation Loss: 0.00575742
Epoch [189/300], Train Loss: 0.005543
Validation Loss: 0.00575719
Epoch [190/300], Train Loss: 0.005469
Validation Loss: 0.00575674
Epoch [191/300], Train Loss: 0.005596
Validation Loss: 0.00575648
Epoch [192/300], Train Loss: 0.005360
Validation Loss: 0.00575791
Epoch [193/300], Train Loss: 0.005548
Validation Loss: 0.00577339
Epoch [194/300], Train Loss: 0.005584
Validation Loss: 0.00576393
Epoch [195/300], Train Loss: 0.005495
Validation Loss: 0.00575510
Epoch [196/300], Train Loss: 0.005471
Validation Loss: 0.00575495
Epoch [197/300], Train Loss: 0.005488
Validation Loss: 0.00575629
Epoch [198/300], Train Loss: 0.005497
Validation Loss: 0.00575516
Epoch [199/300], Train Loss: 0.005479
Validation Loss: 0.00575640
Epoch [200/300], Train Loss: 0.005555
Validation Loss: 0.00575929
Epoch [201/300], Train Loss: 0.005760
Validation Loss: 0.00575448
Epoch [202/300], Train Loss: 0.005558
Validation Loss: 0.00575796
Epoch [203/300], Train Loss: 0.005454
Validation Loss: 0.00575437
Epoch [204/300], Train Loss: 0.005576
Validation Loss: 0.00575715
Epoch [205/300], Train Loss: 0.005372
Validation Loss: 0.00576159
Epoch [206/300], Train Loss: 0.005444
Validation Loss: 0.00575774
Epoch [207/300], Train Loss: 0.005418
Validation Loss: 0.00575203
Epoch [208/300], Train Loss: 0.005534
Validation Loss: 0.00575131
Epoch [209/300], Train Loss: 0.005467
Validation Loss: 0.00575099
Epoch [210/300], Train Loss: 0.005560
Validation Loss: 0.00575097
Epoch [211/300], Train Loss: 0.005530
Validation Loss: 0.00575146
Epoch [212/300], Train Loss: 0.005465
Validation Loss: 0.00575122
Epoch [213/300], Train Loss: 0.005635
Validation Loss: 0.00575016
Epoch [214/300], Train Loss: 0.005379
Validation Loss: 0.00575023
Epoch [215/300], Train Loss: 0.005443
Validation Loss: 0.00574942
Epoch [216/300], Train Loss: 0.005729
Validation Loss: 0.00574998
Epoch [217/300], Train Loss: 0.005428
Validation Loss: 0.00575136
Epoch [218/300], Train Loss: 0.005438
Validation Loss: 0.00574921
Epoch [219/300], Train Loss: 0.005473
Validation Loss: 0.00574983
Epoch [220/300], Train Loss: 0.005376
Validation Loss: 0.00575093
Epoch [221/300], Train Loss: 0.005606
Validation Loss: 0.00575391
Epoch [222/300], Train Loss: 0.005444
Validation Loss: 0.00574904
Epoch [223/300], Train Loss: 0.005490
Validation Loss: 0.00574752
Epoch [224/300], Train Loss: 0.005566
Validation Loss: 0.00574728
Epoch [225/300], Train Loss: 0.005468
Validation Loss: 0.00575010
Epoch [226/300], Train Loss: 0.005489
Validation Loss: 0.00575040
Epoch [227/300], Train Loss: 0.005410
Validation Loss: 0.00574749
Epoch [228/300], Train Loss: 0.005312
Validation Loss: 0.00574704
Epoch [229/300], Train Loss: 0.005498
Validation Loss: 0.00574996
Epoch [230/300], Train Loss: 0.005499
Validation Loss: 0.00575011
Epoch [231/300], Train Loss: 0.005384
Validation Loss: 0.00574723
Epoch [232/300], Train Loss: 0.005370
Validation Loss: 0.00574600
Epoch [233/300], Train Loss: 0.005569
Validation Loss: 0.00574635
Epoch [234/300], Train Loss: 0.005502
Validation Loss: 0.00574489
Epoch [235/300], Train Loss: 0.005494
Validation Loss: 0.00574476
Epoch [236/300], Train Loss: 0.005521
Validation Loss: 0.00574480
Epoch [237/300], Train Loss: 0.005374
Validation Loss: 0.00574467
Epoch [238/300], Train Loss: 0.005557
Validation Loss: 0.00574521
Epoch [239/300], Train Loss: 0.005689
Validation Loss: 0.00574433
Epoch [240/300], Train Loss: 0.005511
Validation Loss: 0.00574329
Epoch [241/300], Train Loss: 0.005469
Validation Loss: 0.00574303
Epoch [242/300], Train Loss: 0.005428
Validation Loss: 0.00574454
Epoch [243/300], Train Loss: 0.005499
Validation Loss: 0.00574589
Epoch [244/300], Train Loss: 0.005415
Validation Loss: 0.00574465
Epoch [245/300], Train Loss: 0.005558
Validation Loss: 0.00574481
Epoch [246/300], Train Loss: 0.005422
Validation Loss: 0.00574358
Epoch [247/300], Train Loss: 0.005383
Validation Loss: 0.00574178
Epoch [248/300], Train Loss: 0.005529
Validation Loss: 0.00574148
Epoch [249/300], Train Loss: 0.005447
Validation Loss: 0.00574127
Epoch [250/300], Train Loss: 0.005518
Validation Loss: 0.00574218
Epoch [251/300], Train Loss: 0.005534
Validation Loss: 0.00574362
Epoch [252/300], Train Loss: 0.005526
Validation Loss: 0.00574063
Epoch [253/300], Train Loss: 0.005481
Validation Loss: 0.00574125
Epoch [254/300], Train Loss: 0.005380
Validation Loss: 0.00574036
Epoch [255/300], Train Loss: 0.005561
Validation Loss: 0.00574190
Epoch [256/300], Train Loss: 0.005476
Validation Loss: 0.00574415
Epoch [257/300], Train Loss: 0.005416
Validation Loss: 0.00574329
Epoch [258/300], Train Loss: 0.005722
Validation Loss: 0.00574205
Epoch [259/300], Train Loss: 0.005418
Validation Loss: 0.00573938
Epoch [260/300], Train Loss: 0.005404
Validation Loss: 0.00573904
Epoch [261/300], Train Loss: 0.005409
Validation Loss: 0.00573899
Epoch [262/300], Train Loss: 0.005535
Validation Loss: 0.00573960
Epoch [263/300], Train Loss: 0.005523
Validation Loss: 0.00573873
Epoch [264/300], Train Loss: 0.005504
Validation Loss: 0.00573879
Epoch [265/300], Train Loss: 0.005517
Validation Loss: 0.00573834
Epoch [266/300], Train Loss: 0.005472
Validation Loss: 0.00573792
Epoch [267/300], Train Loss: 0.005429
Validation Loss: 0.00573839
Epoch [268/300], Train Loss: 0.005388
Validation Loss: 0.00574375
Epoch [269/300], Train Loss: 0.005405
Validation Loss: 0.00574401
Epoch [270/300], Train Loss: 0.005506
Validation Loss: 0.00574042
Epoch [271/300], Train Loss: 0.005376
Validation Loss: 0.00573979
Epoch [272/300], Train Loss: 0.005491
Validation Loss: 0.00573729
Epoch [273/300], Train Loss: 0.005417
Validation Loss: 0.00573650
Epoch [274/300], Train Loss: 0.005605
Validation Loss: 0.00573669
Epoch [275/300], Train Loss: 0.005412
Validation Loss: 0.00573645
Epoch [276/300], Train Loss: 0.005520
Validation Loss: 0.00573605
Epoch [277/300], Train Loss: 0.005481
Validation Loss: 0.00573608
Epoch [278/300], Train Loss: 0.005474
Validation Loss: 0.00573654
Epoch [279/300], Train Loss: 0.005481
Validation Loss: 0.00573687
Epoch [280/300], Train Loss: 0.005453
Validation Loss: 0.00573597
Epoch [281/300], Train Loss: 0.005516
Validation Loss: 0.00573564
Epoch [282/300], Train Loss: 0.005497
Validation Loss: 0.00573497
Epoch [283/300], Train Loss: 0.005369
Validation Loss: 0.00573450
Epoch [284/300], Train Loss: 0.005519
Validation Loss: 0.00573445
Epoch [285/300], Train Loss: 0.005470
Validation Loss: 0.00573510
Epoch [286/300], Train Loss: 0.005611
Validation Loss: 0.00573569
Epoch [287/300], Train Loss: 0.005466
Validation Loss: 0.00573540
Epoch [288/300], Train Loss: 0.005411
Validation Loss: 0.00573411
Epoch [289/300], Train Loss: 0.005598
Validation Loss: 0.00573508
Epoch [290/300], Train Loss: 0.005341
Validation Loss: 0.00573514
Epoch [291/300], Train Loss: 0.005332
Validation Loss: 0.00573689
Epoch [292/300], Train Loss: 0.005502
Validation Loss: 0.00573983
Epoch [293/300], Train Loss: 0.005702
Validation Loss: 0.00573537
Epoch [294/300], Train Loss: 0.005363
Validation Loss: 0.00573297
Epoch [295/300], Train Loss: 0.005487
Validation Loss: 0.00573286
Epoch [296/300], Train Loss: 0.005501
Validation Loss: 0.00573236
Epoch [297/300], Train Loss: 0.005544
Validation Loss: 0.00573248
Epoch [298/300], Train Loss: 0.005400
Validation Loss: 0.00573272
Epoch [299/300], Train Loss: 0.005338
Validation Loss: 0.00573424
Epoch [300/300], Train Loss: 0.005554
Validation Loss: 0.00574092

Evaluating model for: Router
Run 69/72 completed in 417.87 seconds with: {'MAE': np.float32(0.19324355), 'MSE': np.float32(0.06264707), 'RMSE': np.float32(0.25029397), 'SAE': np.float32(0.0008384131), 'NDE': np.float32(0.01251774)}

Run 70/72: hidden=512, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Router
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.079453
Validation Loss: 0.06971719
Epoch [2/300], Train Loss: 0.065203
Validation Loss: 0.05576995
Epoch [3/300], Train Loss: 0.050928
Validation Loss: 0.04000820
Epoch [4/300], Train Loss: 0.033303
Validation Loss: 0.02017998
Epoch [5/300], Train Loss: 0.012646
Validation Loss: 0.00725984
Epoch [6/300], Train Loss: 0.011571
Validation Loss: 0.00901944
Epoch [7/300], Train Loss: 0.006987
Validation Loss: 0.00674847
Epoch [8/300], Train Loss: 0.007381
Validation Loss: 0.00820235
Epoch [9/300], Train Loss: 0.007729
Validation Loss: 0.00687764
Epoch [10/300], Train Loss: 0.006149
Validation Loss: 0.00596581
Epoch [11/300], Train Loss: 0.005807
Validation Loss: 0.00659078
Epoch [12/300], Train Loss: 0.006125
Validation Loss: 0.00614781
Epoch [13/300], Train Loss: 0.005699
Validation Loss: 0.00597435
Epoch [14/300], Train Loss: 0.005688
Validation Loss: 0.00607776
Epoch [15/300], Train Loss: 0.005829
Validation Loss: 0.00596655
Epoch [16/300], Train Loss: 0.005587
Validation Loss: 0.00595335
Epoch [17/300], Train Loss: 0.005762
Validation Loss: 0.00602003
Epoch [18/300], Train Loss: 0.005722
Validation Loss: 0.00594949
Epoch [19/300], Train Loss: 0.005572
Validation Loss: 0.00593543
Epoch [20/300], Train Loss: 0.005702
Validation Loss: 0.00593567
Epoch [21/300], Train Loss: 0.005631
Validation Loss: 0.00592832
Epoch [22/300], Train Loss: 0.005604
Validation Loss: 0.00593670
Epoch [23/300], Train Loss: 0.005716
Validation Loss: 0.00594724
Epoch [24/300], Train Loss: 0.005663
Validation Loss: 0.00593843
Epoch [25/300], Train Loss: 0.005608
Validation Loss: 0.00592165
Epoch [26/300], Train Loss: 0.005544
Validation Loss: 0.00592129
Epoch [27/300], Train Loss: 0.005651
Validation Loss: 0.00591803
Epoch [28/300], Train Loss: 0.005648
Validation Loss: 0.00592076
Epoch [29/300], Train Loss: 0.005757
Validation Loss: 0.00591497
Epoch [30/300], Train Loss: 0.005551
Validation Loss: 0.00591274
Epoch [31/300], Train Loss: 0.005546
Validation Loss: 0.00591981
Epoch [32/300], Train Loss: 0.005588
Validation Loss: 0.00592455
Epoch [33/300], Train Loss: 0.005788
Validation Loss: 0.00592277
Epoch [34/300], Train Loss: 0.005585
Validation Loss: 0.00590600
Epoch [35/300], Train Loss: 0.005621
Validation Loss: 0.00590555
Epoch [36/300], Train Loss: 0.005658
Validation Loss: 0.00590970
Epoch [37/300], Train Loss: 0.005588
Validation Loss: 0.00590998
Epoch [38/300], Train Loss: 0.005465
Validation Loss: 0.00590459
Epoch [39/300], Train Loss: 0.005586
Validation Loss: 0.00590584
Epoch [40/300], Train Loss: 0.005704
Validation Loss: 0.00589630
Epoch [41/300], Train Loss: 0.005663
Validation Loss: 0.00590673
Epoch [42/300], Train Loss: 0.005794
Validation Loss: 0.00589288
Epoch [43/300], Train Loss: 0.005710
Validation Loss: 0.00589257
Epoch [44/300], Train Loss: 0.005590
Validation Loss: 0.00589289
Epoch [45/300], Train Loss: 0.005583
Validation Loss: 0.00588761
Epoch [46/300], Train Loss: 0.005559
Validation Loss: 0.00588608
Epoch [47/300], Train Loss: 0.005645
Validation Loss: 0.00589246
Epoch [48/300], Train Loss: 0.005769
Validation Loss: 0.00589350
Epoch [49/300], Train Loss: 0.005659
Validation Loss: 0.00588152
Epoch [50/300], Train Loss: 0.005660
Validation Loss: 0.00588166
Epoch [51/300], Train Loss: 0.005640
Validation Loss: 0.00587822
Epoch [52/300], Train Loss: 0.005665
Validation Loss: 0.00587664
Epoch [53/300], Train Loss: 0.005641
Validation Loss: 0.00587711
Epoch [54/300], Train Loss: 0.005619
Validation Loss: 0.00588002
Epoch [55/300], Train Loss: 0.005629
Validation Loss: 0.00587220
Epoch [56/300], Train Loss: 0.005627
Validation Loss: 0.00587248
Epoch [57/300], Train Loss: 0.005705
Validation Loss: 0.00586887
Epoch [58/300], Train Loss: 0.005568
Validation Loss: 0.00586819
Epoch [59/300], Train Loss: 0.005608
Validation Loss: 0.00586675
Epoch [60/300], Train Loss: 0.005602
Validation Loss: 0.00586706
Epoch [61/300], Train Loss: 0.005534
Validation Loss: 0.00588568
Epoch [62/300], Train Loss: 0.005721
Validation Loss: 0.00587499
Epoch [63/300], Train Loss: 0.005467
Validation Loss: 0.00586766
Epoch [64/300], Train Loss: 0.005714
Validation Loss: 0.00587032
Epoch [65/300], Train Loss: 0.005525
Validation Loss: 0.00587477
Epoch [66/300], Train Loss: 0.005742
Validation Loss: 0.00589726
Epoch [67/300], Train Loss: 0.005561
Validation Loss: 0.00585562
Epoch [68/300], Train Loss: 0.005557
Validation Loss: 0.00587674
Epoch [69/300], Train Loss: 0.005593
Validation Loss: 0.00585500
Epoch [70/300], Train Loss: 0.005601
Validation Loss: 0.00585877
Epoch [71/300], Train Loss: 0.005657
Validation Loss: 0.00585550
Epoch [72/300], Train Loss: 0.005440
Validation Loss: 0.00585022
Epoch [73/300], Train Loss: 0.005502
Validation Loss: 0.00585028
Epoch [74/300], Train Loss: 0.005642
Validation Loss: 0.00584919
Epoch [75/300], Train Loss: 0.005493
Validation Loss: 0.00584766
Epoch [76/300], Train Loss: 0.005618
Validation Loss: 0.00584756
Epoch [77/300], Train Loss: 0.005602
Validation Loss: 0.00584557
Epoch [78/300], Train Loss: 0.005626
Validation Loss: 0.00584373
Epoch [79/300], Train Loss: 0.005498
Validation Loss: 0.00584393
Epoch [80/300], Train Loss: 0.005649
Validation Loss: 0.00584759
Epoch [81/300], Train Loss: 0.005490
Validation Loss: 0.00584053
Epoch [82/300], Train Loss: 0.005714
Validation Loss: 0.00584401
Epoch [83/300], Train Loss: 0.005607
Validation Loss: 0.00583904
Epoch [84/300], Train Loss: 0.005519
Validation Loss: 0.00584660
Epoch [85/300], Train Loss: 0.005563
Validation Loss: 0.00583926
Epoch [86/300], Train Loss: 0.005518
Validation Loss: 0.00583538
Epoch [87/300], Train Loss: 0.005586
Validation Loss: 0.00583413
Epoch [88/300], Train Loss: 0.005571
Validation Loss: 0.00583322
Epoch [89/300], Train Loss: 0.005576
Validation Loss: 0.00583376
Epoch [90/300], Train Loss: 0.005694
Validation Loss: 0.00583217
Epoch [91/300], Train Loss: 0.005637
Validation Loss: 0.00583557
Epoch [92/300], Train Loss: 0.005576
Validation Loss: 0.00583794
Epoch [93/300], Train Loss: 0.005628
Validation Loss: 0.00583223
Epoch [94/300], Train Loss: 0.005414
Validation Loss: 0.00582787
Epoch [95/300], Train Loss: 0.005554
Validation Loss: 0.00582683
Epoch [96/300], Train Loss: 0.005627
Validation Loss: 0.00582632
Epoch [97/300], Train Loss: 0.005524
Validation Loss: 0.00582585
Epoch [98/300], Train Loss: 0.005619
Validation Loss: 0.00582673
Epoch [99/300], Train Loss: 0.005579
Validation Loss: 0.00582525
Epoch [100/300], Train Loss: 0.005568
Validation Loss: 0.00582456
Epoch [101/300], Train Loss: 0.005535
Validation Loss: 0.00582613
Epoch [102/300], Train Loss: 0.005606
Validation Loss: 0.00582100
Epoch [103/300], Train Loss: 0.005568
Validation Loss: 0.00582598
Epoch [104/300], Train Loss: 0.005500
Validation Loss: 0.00581961
Epoch [105/300], Train Loss: 0.005593
Validation Loss: 0.00582882
Epoch [106/300], Train Loss: 0.005747
Validation Loss: 0.00581891
Epoch [107/300], Train Loss: 0.005539
Validation Loss: 0.00581861
Epoch [108/300], Train Loss: 0.005719
Validation Loss: 0.00581710
Epoch [109/300], Train Loss: 0.005793
Validation Loss: 0.00581827
Epoch [110/300], Train Loss: 0.005528
Validation Loss: 0.00581662
Epoch [111/300], Train Loss: 0.005504
Validation Loss: 0.00581636
Epoch [112/300], Train Loss: 0.005659
Validation Loss: 0.00581834
Epoch [113/300], Train Loss: 0.005660
Validation Loss: 0.00581184
Epoch [114/300], Train Loss: 0.005691
Validation Loss: 0.00582224
Epoch [115/300], Train Loss: 0.005636
Validation Loss: 0.00581055
Epoch [116/300], Train Loss: 0.005533
Validation Loss: 0.00582553
Epoch [117/300], Train Loss: 0.005574
Validation Loss: 0.00581829
Epoch [118/300], Train Loss: 0.005547
Validation Loss: 0.00581033
Epoch [119/300], Train Loss: 0.005530
Validation Loss: 0.00581043
Epoch [120/300], Train Loss: 0.005567
Validation Loss: 0.00580744
Epoch [121/300], Train Loss: 0.005491
Validation Loss: 0.00580618
Epoch [122/300], Train Loss: 0.005489
Validation Loss: 0.00580638
Epoch [123/300], Train Loss: 0.005568
Validation Loss: 0.00581299
Epoch [124/300], Train Loss: 0.005564
Validation Loss: 0.00580991
Epoch [125/300], Train Loss: 0.005637
Validation Loss: 0.00580427
Epoch [126/300], Train Loss: 0.005626
Validation Loss: 0.00580337
Epoch [127/300], Train Loss: 0.005562
Validation Loss: 0.00580480
Epoch [128/300], Train Loss: 0.005656
Validation Loss: 0.00580309
Epoch [129/300], Train Loss: 0.005494
Validation Loss: 0.00580971
Epoch [130/300], Train Loss: 0.005685
Validation Loss: 0.00580444
Epoch [131/300], Train Loss: 0.005525
Validation Loss: 0.00580059
Epoch [132/300], Train Loss: 0.005521
Validation Loss: 0.00580051
Epoch [133/300], Train Loss: 0.005509
Validation Loss: 0.00579980
Epoch [134/300], Train Loss: 0.005676
Validation Loss: 0.00580244
Epoch [135/300], Train Loss: 0.005465
Validation Loss: 0.00579920
Epoch [136/300], Train Loss: 0.005559
Validation Loss: 0.00579978
Epoch [137/300], Train Loss: 0.005703
Validation Loss: 0.00579754
Epoch [138/300], Train Loss: 0.005526
Validation Loss: 0.00579798
Epoch [139/300], Train Loss: 0.005509
Validation Loss: 0.00579587
Epoch [140/300], Train Loss: 0.005489
Validation Loss: 0.00579588
Epoch [141/300], Train Loss: 0.005418
Validation Loss: 0.00579640
Epoch [142/300], Train Loss: 0.005463
Validation Loss: 0.00579467
Epoch [143/300], Train Loss: 0.005577
Validation Loss: 0.00579451
Epoch [144/300], Train Loss: 0.005538
Validation Loss: 0.00579365
Epoch [145/300], Train Loss: 0.005487
Validation Loss: 0.00579380
Epoch [146/300], Train Loss: 0.005442
Validation Loss: 0.00579897
Epoch [147/300], Train Loss: 0.005606
Validation Loss: 0.00579323
Epoch [148/300], Train Loss: 0.005444
Validation Loss: 0.00579389
Epoch [149/300], Train Loss: 0.005659
Validation Loss: 0.00579218
Epoch [150/300], Train Loss: 0.005767
Validation Loss: 0.00579342
Epoch [151/300], Train Loss: 0.005538
Validation Loss: 0.00579161
Epoch [152/300], Train Loss: 0.005720
Validation Loss: 0.00579102
Epoch [153/300], Train Loss: 0.005403
Validation Loss: 0.00578915
Epoch [154/300], Train Loss: 0.005436
Validation Loss: 0.00578886
Epoch [155/300], Train Loss: 0.005635
Validation Loss: 0.00579534
Epoch [156/300], Train Loss: 0.005563
Validation Loss: 0.00578813
Epoch [157/300], Train Loss: 0.005623
Validation Loss: 0.00579474
Epoch [158/300], Train Loss: 0.005538
Validation Loss: 0.00579106
Epoch [159/300], Train Loss: 0.005672
Validation Loss: 0.00579349
Epoch [160/300], Train Loss: 0.005513
Validation Loss: 0.00578927
Epoch [161/300], Train Loss: 0.005597
Validation Loss: 0.00579255
Epoch [162/300], Train Loss: 0.005484
Validation Loss: 0.00578474
Epoch [163/300], Train Loss: 0.005585
Validation Loss: 0.00578436
Epoch [164/300], Train Loss: 0.005456
Validation Loss: 0.00578377
Epoch [165/300], Train Loss: 0.005431
Validation Loss: 0.00578691
Epoch [166/300], Train Loss: 0.005423
Validation Loss: 0.00578717
Epoch [167/300], Train Loss: 0.005468
Validation Loss: 0.00578414
Epoch [168/300], Train Loss: 0.005490
Validation Loss: 0.00578228
Epoch [169/300], Train Loss: 0.005641
Validation Loss: 0.00578162
Epoch [170/300], Train Loss: 0.005406
Validation Loss: 0.00578114
Epoch [171/300], Train Loss: 0.005557
Validation Loss: 0.00578379
Epoch [172/300], Train Loss: 0.005504
Validation Loss: 0.00578990
Epoch [173/300], Train Loss: 0.005407
Validation Loss: 0.00578110
Epoch [174/300], Train Loss: 0.005619
Validation Loss: 0.00577961
Epoch [175/300], Train Loss: 0.005654
Validation Loss: 0.00578011
Epoch [176/300], Train Loss: 0.005544
Validation Loss: 0.00577924
Epoch [177/300], Train Loss: 0.005390
Validation Loss: 0.00577902
Epoch [178/300], Train Loss: 0.005397
Validation Loss: 0.00578181
Epoch [179/300], Train Loss: 0.005496
Validation Loss: 0.00578743
Epoch [180/300], Train Loss: 0.005715
Validation Loss: 0.00578129
Epoch [181/300], Train Loss: 0.005528
Validation Loss: 0.00577800
Epoch [182/300], Train Loss: 0.005517
Validation Loss: 0.00577705
Epoch [183/300], Train Loss: 0.005683
Validation Loss: 0.00577806
Epoch [184/300], Train Loss: 0.005514
Validation Loss: 0.00577824
Epoch [185/300], Train Loss: 0.005398
Validation Loss: 0.00577507
Epoch [186/300], Train Loss: 0.005592
Validation Loss: 0.00577503
Epoch [187/300], Train Loss: 0.005568
Validation Loss: 0.00577466
Epoch [188/300], Train Loss: 0.005470
Validation Loss: 0.00577383
Epoch [189/300], Train Loss: 0.005574
Validation Loss: 0.00577371
Epoch [190/300], Train Loss: 0.005493
Validation Loss: 0.00577353
Epoch [191/300], Train Loss: 0.005623
Validation Loss: 0.00577353
Epoch [192/300], Train Loss: 0.005388
Validation Loss: 0.00577409
Epoch [193/300], Train Loss: 0.005580
Validation Loss: 0.00579173
Epoch [194/300], Train Loss: 0.005617
Validation Loss: 0.00577633
Epoch [195/300], Train Loss: 0.005531
Validation Loss: 0.00577351
Epoch [196/300], Train Loss: 0.005499
Validation Loss: 0.00577096
Epoch [197/300], Train Loss: 0.005519
Validation Loss: 0.00577413
Epoch [198/300], Train Loss: 0.005526
Validation Loss: 0.00577152
Epoch [199/300], Train Loss: 0.005513
Validation Loss: 0.00577146
Epoch [200/300], Train Loss: 0.005584
Validation Loss: 0.00577313
Epoch [201/300], Train Loss: 0.005780
Validation Loss: 0.00576947
Epoch [202/300], Train Loss: 0.005592
Validation Loss: 0.00577817
Epoch [203/300], Train Loss: 0.005485
Validation Loss: 0.00576966
Epoch [204/300], Train Loss: 0.005611
Validation Loss: 0.00577857
Epoch [205/300], Train Loss: 0.005406
Validation Loss: 0.00577736
Epoch [206/300], Train Loss: 0.005479
Validation Loss: 0.00576921
Epoch [207/300], Train Loss: 0.005453
Validation Loss: 0.00576782
Epoch [208/300], Train Loss: 0.005561
Validation Loss: 0.00576748
Epoch [209/300], Train Loss: 0.005490
Validation Loss: 0.00576729
Epoch [210/300], Train Loss: 0.005586
Validation Loss: 0.00576749
Epoch [211/300], Train Loss: 0.005556
Validation Loss: 0.00576692
Epoch [212/300], Train Loss: 0.005486
Validation Loss: 0.00576605
Epoch [213/300], Train Loss: 0.005657
Validation Loss: 0.00576577
Epoch [214/300], Train Loss: 0.005409
Validation Loss: 0.00576701
Epoch [215/300], Train Loss: 0.005470
Validation Loss: 0.00576514
Epoch [216/300], Train Loss: 0.005751
Validation Loss: 0.00576644
Epoch [217/300], Train Loss: 0.005460
Validation Loss: 0.00576678
Epoch [218/300], Train Loss: 0.005467
Validation Loss: 0.00576435
Epoch [219/300], Train Loss: 0.005496
Validation Loss: 0.00576452
Epoch [220/300], Train Loss: 0.005404
Validation Loss: 0.00576641
Epoch [221/300], Train Loss: 0.005634
Validation Loss: 0.00577037
Epoch [222/300], Train Loss: 0.005470
Validation Loss: 0.00576383
Epoch [223/300], Train Loss: 0.005517
Validation Loss: 0.00576334
Epoch [224/300], Train Loss: 0.005591
Validation Loss: 0.00576293
Epoch [225/300], Train Loss: 0.005499
Validation Loss: 0.00576675
Epoch [226/300], Train Loss: 0.005523
Validation Loss: 0.00576610
Epoch [227/300], Train Loss: 0.005437
Validation Loss: 0.00576232
Epoch [228/300], Train Loss: 0.005343
Validation Loss: 0.00576192
Epoch [229/300], Train Loss: 0.005528
Validation Loss: 0.00576503
Epoch [230/300], Train Loss: 0.005527
Validation Loss: 0.00576527
Epoch [231/300], Train Loss: 0.005414
Validation Loss: 0.00576203
Epoch [232/300], Train Loss: 0.005393
Validation Loss: 0.00576105
Epoch [233/300], Train Loss: 0.005600
Validation Loss: 0.00576143
Epoch [234/300], Train Loss: 0.005531
Validation Loss: 0.00576061
Epoch [235/300], Train Loss: 0.005520
Validation Loss: 0.00576059
Epoch [236/300], Train Loss: 0.005548
Validation Loss: 0.00576030
Epoch [237/300], Train Loss: 0.005406
Validation Loss: 0.00575992
Epoch [238/300], Train Loss: 0.005579
Validation Loss: 0.00575993
Epoch [239/300], Train Loss: 0.005711
Validation Loss: 0.00575891
Epoch [240/300], Train Loss: 0.005538
Validation Loss: 0.00575856
Epoch [241/300], Train Loss: 0.005499
Validation Loss: 0.00575815
Epoch [242/300], Train Loss: 0.005454
Validation Loss: 0.00576002
Epoch [243/300], Train Loss: 0.005528
Validation Loss: 0.00576136
Epoch [244/300], Train Loss: 0.005444
Validation Loss: 0.00575874
Epoch [245/300], Train Loss: 0.005585
Validation Loss: 0.00575826
Epoch [246/300], Train Loss: 0.005447
Validation Loss: 0.00575735
Epoch [247/300], Train Loss: 0.005412
Validation Loss: 0.00575654
Epoch [248/300], Train Loss: 0.005551
Validation Loss: 0.00575629
Epoch [249/300], Train Loss: 0.005474
Validation Loss: 0.00575610
Epoch [250/300], Train Loss: 0.005545
Validation Loss: 0.00575735
Epoch [251/300], Train Loss: 0.005562
Validation Loss: 0.00575796
Epoch [252/300], Train Loss: 0.005549
Validation Loss: 0.00575598
Epoch [253/300], Train Loss: 0.005511
Validation Loss: 0.00575802
Epoch [254/300], Train Loss: 0.005404
Validation Loss: 0.00575518
Epoch [255/300], Train Loss: 0.005586
Validation Loss: 0.00575837
Epoch [256/300], Train Loss: 0.005504
Validation Loss: 0.00575990
Epoch [257/300], Train Loss: 0.005450
Validation Loss: 0.00575656
Epoch [258/300], Train Loss: 0.005742
Validation Loss: 0.00575489
Epoch [259/300], Train Loss: 0.005441
Validation Loss: 0.00575421
Epoch [260/300], Train Loss: 0.005433
Validation Loss: 0.00575396
Epoch [261/300], Train Loss: 0.005442
Validation Loss: 0.00575384
Epoch [262/300], Train Loss: 0.005559
Validation Loss: 0.00575479
Epoch [263/300], Train Loss: 0.005548
Validation Loss: 0.00575306
Epoch [264/300], Train Loss: 0.005531
Validation Loss: 0.00575282
Epoch [265/300], Train Loss: 0.005541
Validation Loss: 0.00575255
Epoch [266/300], Train Loss: 0.005499
Validation Loss: 0.00575232
Epoch [267/300], Train Loss: 0.005459
Validation Loss: 0.00575284
Epoch [268/300], Train Loss: 0.005412
Validation Loss: 0.00575976
Epoch [269/300], Train Loss: 0.005432
Validation Loss: 0.00575779
Epoch [270/300], Train Loss: 0.005534
Validation Loss: 0.00575286
Epoch [271/300], Train Loss: 0.005404
Validation Loss: 0.00575241
Epoch [272/300], Train Loss: 0.005516
Validation Loss: 0.00575123
Epoch [273/300], Train Loss: 0.005444
Validation Loss: 0.00575117
Epoch [274/300], Train Loss: 0.005640
Validation Loss: 0.00575134
Epoch [275/300], Train Loss: 0.005437
Validation Loss: 0.00575095
Epoch [276/300], Train Loss: 0.005540
Validation Loss: 0.00575033
Epoch [277/300], Train Loss: 0.005506
Validation Loss: 0.00575007
Epoch [278/300], Train Loss: 0.005497
Validation Loss: 0.00575023
Epoch [279/300], Train Loss: 0.005508
Validation Loss: 0.00575044
Epoch [280/300], Train Loss: 0.005478
Validation Loss: 0.00574962
Epoch [281/300], Train Loss: 0.005543
Validation Loss: 0.00574942
Epoch [282/300], Train Loss: 0.005521
Validation Loss: 0.00574887
Epoch [283/300], Train Loss: 0.005395
Validation Loss: 0.00574882
Epoch [284/300], Train Loss: 0.005542
Validation Loss: 0.00574848
Epoch [285/300], Train Loss: 0.005496
Validation Loss: 0.00574917
Epoch [286/300], Train Loss: 0.005634
Validation Loss: 0.00574969
Epoch [287/300], Train Loss: 0.005492
Validation Loss: 0.00574889
Epoch [288/300], Train Loss: 0.005441
Validation Loss: 0.00574764
Epoch [289/300], Train Loss: 0.005623
Validation Loss: 0.00574837
Epoch [290/300], Train Loss: 0.005368
Validation Loss: 0.00574862
Epoch [291/300], Train Loss: 0.005356
Validation Loss: 0.00575077
Epoch [292/300], Train Loss: 0.005531
Validation Loss: 0.00575392
Epoch [293/300], Train Loss: 0.005720
Validation Loss: 0.00574818
Epoch [294/300], Train Loss: 0.005391
Validation Loss: 0.00574877
Epoch [295/300], Train Loss: 0.005509
Validation Loss: 0.00574753
Epoch [296/300], Train Loss: 0.005528
Validation Loss: 0.00574640
Epoch [297/300], Train Loss: 0.005568
Validation Loss: 0.00574676
Epoch [298/300], Train Loss: 0.005423
Validation Loss: 0.00574654
Epoch [299/300], Train Loss: 0.005365
Validation Loss: 0.00574744
Epoch [300/300], Train Loss: 0.005575
Validation Loss: 0.00575359

Evaluating model for: Router
Run 70/72 completed in 556.97 seconds with: {'MAE': np.float32(0.1938579), 'MSE': np.float32(0.06317376), 'RMSE': np.float32(0.2513439), 'SAE': np.float32(0.00085191167), 'NDE': np.float32(0.012570251)}

Run 71/72: hidden=512, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Router
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.076016
Validation Loss: 0.06568364
Epoch [2/300], Train Loss: 0.060632
Validation Loss: 0.05045584
Epoch [3/300], Train Loss: 0.045354
Validation Loss: 0.03391198
Epoch [4/300], Train Loss: 0.026517
Validation Loss: 0.01257886
Epoch [5/300], Train Loss: 0.009603
Validation Loss: 0.01490919
Epoch [6/300], Train Loss: 0.010187
Validation Loss: 0.00598009
Epoch [7/300], Train Loss: 0.006830
Validation Loss: 0.00817081
Epoch [8/300], Train Loss: 0.008117
Validation Loss: 0.00763790
Epoch [9/300], Train Loss: 0.006895
Validation Loss: 0.00601507
Epoch [10/300], Train Loss: 0.005828
Validation Loss: 0.00652651
Epoch [11/300], Train Loss: 0.006167
Validation Loss: 0.00631649
Epoch [12/300], Train Loss: 0.005782
Validation Loss: 0.00595985
Epoch [13/300], Train Loss: 0.005761
Validation Loss: 0.00610804
Epoch [14/300], Train Loss: 0.005747
Validation Loss: 0.00598334
Epoch [15/300], Train Loss: 0.005742
Validation Loss: 0.00596843
Epoch [16/300], Train Loss: 0.005596
Validation Loss: 0.00600591
Epoch [17/300], Train Loss: 0.005762
Validation Loss: 0.00596369
Epoch [18/300], Train Loss: 0.005680
Validation Loss: 0.00594219
Epoch [19/300], Train Loss: 0.005604
Validation Loss: 0.00594608
Epoch [20/300], Train Loss: 0.005716
Validation Loss: 0.00593788
Epoch [21/300], Train Loss: 0.005626
Validation Loss: 0.00594169
Epoch [22/300], Train Loss: 0.005616
Validation Loss: 0.00594223
Epoch [23/300], Train Loss: 0.005731
Validation Loss: 0.00593951
Epoch [24/300], Train Loss: 0.005664
Validation Loss: 0.00593982
Epoch [25/300], Train Loss: 0.005624
Validation Loss: 0.00592954
Epoch [26/300], Train Loss: 0.005548
Validation Loss: 0.00592753
Epoch [27/300], Train Loss: 0.005658
Validation Loss: 0.00592595
Epoch [28/300], Train Loss: 0.005661
Validation Loss: 0.00592695
Epoch [29/300], Train Loss: 0.005764
Validation Loss: 0.00592246
Epoch [30/300], Train Loss: 0.005562
Validation Loss: 0.00592127
Epoch [31/300], Train Loss: 0.005557
Validation Loss: 0.00593281
Epoch [32/300], Train Loss: 0.005600
Validation Loss: 0.00593375
Epoch [33/300], Train Loss: 0.005800
Validation Loss: 0.00592848
Epoch [34/300], Train Loss: 0.005602
Validation Loss: 0.00591381
Epoch [35/300], Train Loss: 0.005639
Validation Loss: 0.00591222
Epoch [36/300], Train Loss: 0.005672
Validation Loss: 0.00592301
Epoch [37/300], Train Loss: 0.005600
Validation Loss: 0.00591869
Epoch [38/300], Train Loss: 0.005483
Validation Loss: 0.00590981
Epoch [39/300], Train Loss: 0.005598
Validation Loss: 0.00591203
Epoch [40/300], Train Loss: 0.005719
Validation Loss: 0.00590265
Epoch [41/300], Train Loss: 0.005666
Validation Loss: 0.00591075
Epoch [42/300], Train Loss: 0.005811
Validation Loss: 0.00589889
Epoch [43/300], Train Loss: 0.005723
Validation Loss: 0.00589799
Epoch [44/300], Train Loss: 0.005601
Validation Loss: 0.00589724
Epoch [45/300], Train Loss: 0.005589
Validation Loss: 0.00589182
Epoch [46/300], Train Loss: 0.005573
Validation Loss: 0.00588994
Epoch [47/300], Train Loss: 0.005655
Validation Loss: 0.00590038
Epoch [48/300], Train Loss: 0.005783
Validation Loss: 0.00589757
Epoch [49/300], Train Loss: 0.005667
Validation Loss: 0.00588357
Epoch [50/300], Train Loss: 0.005669
Validation Loss: 0.00588287
Epoch [51/300], Train Loss: 0.005648
Validation Loss: 0.00587894
Epoch [52/300], Train Loss: 0.005676
Validation Loss: 0.00587742
Epoch [53/300], Train Loss: 0.005647
Validation Loss: 0.00587653
Epoch [54/300], Train Loss: 0.005627
Validation Loss: 0.00587896
Epoch [55/300], Train Loss: 0.005638
Validation Loss: 0.00586994
Epoch [56/300], Train Loss: 0.005635
Validation Loss: 0.00586845
Epoch [57/300], Train Loss: 0.005713
Validation Loss: 0.00586485
Epoch [58/300], Train Loss: 0.005573
Validation Loss: 0.00586367
Epoch [59/300], Train Loss: 0.005613
Validation Loss: 0.00586139
Epoch [60/300], Train Loss: 0.005594
Validation Loss: 0.00586314
Epoch [61/300], Train Loss: 0.005544
Validation Loss: 0.00588754
Epoch [62/300], Train Loss: 0.005716
Validation Loss: 0.00586442
Epoch [63/300], Train Loss: 0.005468
Validation Loss: 0.00586450
Epoch [64/300], Train Loss: 0.005722
Validation Loss: 0.00585691
Epoch [65/300], Train Loss: 0.005510
Validation Loss: 0.00588419
Epoch [66/300], Train Loss: 0.005753
Validation Loss: 0.00588460
Epoch [67/300], Train Loss: 0.005545
Validation Loss: 0.00584784
Epoch [68/300], Train Loss: 0.005573
Validation Loss: 0.00586630
Epoch [69/300], Train Loss: 0.005593
Validation Loss: 0.00584181
Epoch [70/300], Train Loss: 0.005606
Validation Loss: 0.00585242
Epoch [71/300], Train Loss: 0.005654
Validation Loss: 0.00583804
Epoch [72/300], Train Loss: 0.005453
Validation Loss: 0.00583789
Epoch [73/300], Train Loss: 0.005505
Validation Loss: 0.00584039
Epoch [74/300], Train Loss: 0.005640
Validation Loss: 0.00583742
Epoch [75/300], Train Loss: 0.005493
Validation Loss: 0.00583142
Epoch [76/300], Train Loss: 0.005616
Validation Loss: 0.00583075
Epoch [77/300], Train Loss: 0.005594
Validation Loss: 0.00583001
Epoch [78/300], Train Loss: 0.005621
Validation Loss: 0.00582723
Epoch [79/300], Train Loss: 0.005491
Validation Loss: 0.00582729
Epoch [80/300], Train Loss: 0.005651
Validation Loss: 0.00582886
Epoch [81/300], Train Loss: 0.005489
Validation Loss: 0.00582238
Epoch [82/300], Train Loss: 0.005723
Validation Loss: 0.00582405
Epoch [83/300], Train Loss: 0.005604
Validation Loss: 0.00582320
Epoch [84/300], Train Loss: 0.005516
Validation Loss: 0.00582913
Epoch [85/300], Train Loss: 0.005560
Validation Loss: 0.00581630
Epoch [86/300], Train Loss: 0.005514
Validation Loss: 0.00581484
Epoch [87/300], Train Loss: 0.005595
Validation Loss: 0.00581378
Epoch [88/300], Train Loss: 0.005566
Validation Loss: 0.00581184
Epoch [89/300], Train Loss: 0.005577
Validation Loss: 0.00581282
Epoch [90/300], Train Loss: 0.005683
Validation Loss: 0.00581050
Epoch [91/300], Train Loss: 0.005639
Validation Loss: 0.00581701
Epoch [92/300], Train Loss: 0.005570
Validation Loss: 0.00581666
Epoch [93/300], Train Loss: 0.005621
Validation Loss: 0.00580824
Epoch [94/300], Train Loss: 0.005413
Validation Loss: 0.00580481
Epoch [95/300], Train Loss: 0.005544
Validation Loss: 0.00580390
Epoch [96/300], Train Loss: 0.005623
Validation Loss: 0.00580421
Epoch [97/300], Train Loss: 0.005515
Validation Loss: 0.00580253
Epoch [98/300], Train Loss: 0.005615
Validation Loss: 0.00580301
Epoch [99/300], Train Loss: 0.005568
Validation Loss: 0.00580203
Epoch [100/300], Train Loss: 0.005566
Validation Loss: 0.00580227
Epoch [101/300], Train Loss: 0.005527
Validation Loss: 0.00580344
Epoch [102/300], Train Loss: 0.005598
Validation Loss: 0.00579729
Epoch [103/300], Train Loss: 0.005556
Validation Loss: 0.00580288
Epoch [104/300], Train Loss: 0.005507
Validation Loss: 0.00579809
Epoch [105/300], Train Loss: 0.005581
Validation Loss: 0.00580863
Epoch [106/300], Train Loss: 0.005733
Validation Loss: 0.00579364
Epoch [107/300], Train Loss: 0.005526
Validation Loss: 0.00579548
Epoch [108/300], Train Loss: 0.005717
Validation Loss: 0.00579120
Epoch [109/300], Train Loss: 0.005798
Validation Loss: 0.00579790
Epoch [110/300], Train Loss: 0.005518
Validation Loss: 0.00578982
Epoch [111/300], Train Loss: 0.005498
Validation Loss: 0.00578911
Epoch [112/300], Train Loss: 0.005646
Validation Loss: 0.00579498
Epoch [113/300], Train Loss: 0.005650
Validation Loss: 0.00578616
Epoch [114/300], Train Loss: 0.005700
Validation Loss: 0.00579821
Epoch [115/300], Train Loss: 0.005631
Validation Loss: 0.00578472
Epoch [116/300], Train Loss: 0.005523
Validation Loss: 0.00580829
Epoch [117/300], Train Loss: 0.005566
Validation Loss: 0.00578915
Epoch [118/300], Train Loss: 0.005540
Validation Loss: 0.00578990
Epoch [119/300], Train Loss: 0.005531
Validation Loss: 0.00578373
Epoch [120/300], Train Loss: 0.005563
Validation Loss: 0.00578683
Epoch [121/300], Train Loss: 0.005485
Validation Loss: 0.00578155
Epoch [122/300], Train Loss: 0.005487
Validation Loss: 0.00578121
Epoch [123/300], Train Loss: 0.005559
Validation Loss: 0.00579045
Epoch [124/300], Train Loss: 0.005554
Validation Loss: 0.00578948
Epoch [125/300], Train Loss: 0.005629
Validation Loss: 0.00578014
Epoch [126/300], Train Loss: 0.005625
Validation Loss: 0.00577946
Epoch [127/300], Train Loss: 0.005556
Validation Loss: 0.00578097
Epoch [128/300], Train Loss: 0.005656
Validation Loss: 0.00578132
Epoch [129/300], Train Loss: 0.005478
Validation Loss: 0.00578963
Epoch [130/300], Train Loss: 0.005679
Validation Loss: 0.00577969
Epoch [131/300], Train Loss: 0.005530
Validation Loss: 0.00577702
Epoch [132/300], Train Loss: 0.005509
Validation Loss: 0.00577778
Epoch [133/300], Train Loss: 0.005494
Validation Loss: 0.00577737
Epoch [134/300], Train Loss: 0.005661
Validation Loss: 0.00578114
Epoch [135/300], Train Loss: 0.005454
Validation Loss: 0.00577662
Epoch [136/300], Train Loss: 0.005552
Validation Loss: 0.00577630
Epoch [137/300], Train Loss: 0.005692
Validation Loss: 0.00577530
Epoch [138/300], Train Loss: 0.005514
Validation Loss: 0.00577498
Epoch [139/300], Train Loss: 0.005501
Validation Loss: 0.00577121
Epoch [140/300], Train Loss: 0.005479
Validation Loss: 0.00577132
Epoch [141/300], Train Loss: 0.005403
Validation Loss: 0.00577339
Epoch [142/300], Train Loss: 0.005453
Validation Loss: 0.00577045
Epoch [143/300], Train Loss: 0.005566
Validation Loss: 0.00576955
Epoch [144/300], Train Loss: 0.005528
Validation Loss: 0.00576914
Epoch [145/300], Train Loss: 0.005477
Validation Loss: 0.00577051
Epoch [146/300], Train Loss: 0.005439
Validation Loss: 0.00577760
Epoch [147/300], Train Loss: 0.005598
Validation Loss: 0.00576808
Epoch [148/300], Train Loss: 0.005432
Validation Loss: 0.00577139
Epoch [149/300], Train Loss: 0.005653
Validation Loss: 0.00576749
Epoch [150/300], Train Loss: 0.005758
Validation Loss: 0.00576778
Epoch [151/300], Train Loss: 0.005526
Validation Loss: 0.00576676
Epoch [152/300], Train Loss: 0.005709
Validation Loss: 0.00576727
Epoch [153/300], Train Loss: 0.005397
Validation Loss: 0.00576473
Epoch [154/300], Train Loss: 0.005421
Validation Loss: 0.00576441
Epoch [155/300], Train Loss: 0.005626
Validation Loss: 0.00577411
Epoch [156/300], Train Loss: 0.005549
Validation Loss: 0.00576318
Epoch [157/300], Train Loss: 0.005607
Validation Loss: 0.00577173
Epoch [158/300], Train Loss: 0.005530
Validation Loss: 0.00576392
Epoch [159/300], Train Loss: 0.005663
Validation Loss: 0.00577564
Epoch [160/300], Train Loss: 0.005508
Validation Loss: 0.00576381
Epoch [161/300], Train Loss: 0.005583
Validation Loss: 0.00576500
Epoch [162/300], Train Loss: 0.005470
Validation Loss: 0.00575900
Epoch [163/300], Train Loss: 0.005573
Validation Loss: 0.00575842
Epoch [164/300], Train Loss: 0.005442
Validation Loss: 0.00575875
Epoch [165/300], Train Loss: 0.005421
Validation Loss: 0.00576279
Epoch [166/300], Train Loss: 0.005417
Validation Loss: 0.00576004
Epoch [167/300], Train Loss: 0.005450
Validation Loss: 0.00575691
Epoch [168/300], Train Loss: 0.005477
Validation Loss: 0.00575593
Epoch [169/300], Train Loss: 0.005630
Validation Loss: 0.00575548
Epoch [170/300], Train Loss: 0.005398
Validation Loss: 0.00575461
Epoch [171/300], Train Loss: 0.005549
Validation Loss: 0.00575877
Epoch [172/300], Train Loss: 0.005495
Validation Loss: 0.00576343
Epoch [173/300], Train Loss: 0.005404
Validation Loss: 0.00575353
Epoch [174/300], Train Loss: 0.005606
Validation Loss: 0.00575307
Epoch [175/300], Train Loss: 0.005638
Validation Loss: 0.00575305
Epoch [176/300], Train Loss: 0.005534
Validation Loss: 0.00575243
Epoch [177/300], Train Loss: 0.005383
Validation Loss: 0.00575227
Epoch [178/300], Train Loss: 0.005381
Validation Loss: 0.00575685
Epoch [179/300], Train Loss: 0.005487
Validation Loss: 0.00576217
Epoch [180/300], Train Loss: 0.005707
Validation Loss: 0.00575394
Epoch [181/300], Train Loss: 0.005509
Validation Loss: 0.00575206
Epoch [182/300], Train Loss: 0.005503
Validation Loss: 0.00574981
Epoch [183/300], Train Loss: 0.005669
Validation Loss: 0.00575484
Epoch [184/300], Train Loss: 0.005501
Validation Loss: 0.00575237
Epoch [185/300], Train Loss: 0.005384
Validation Loss: 0.00574834
Epoch [186/300], Train Loss: 0.005577
Validation Loss: 0.00574852
Epoch [187/300], Train Loss: 0.005558
Validation Loss: 0.00574731
Epoch [188/300], Train Loss: 0.005456
Validation Loss: 0.00574702
Epoch [189/300], Train Loss: 0.005572
Validation Loss: 0.00574710
Epoch [190/300], Train Loss: 0.005481
Validation Loss: 0.00574700
Epoch [191/300], Train Loss: 0.005613
Validation Loss: 0.00574689
Epoch [192/300], Train Loss: 0.005374
Validation Loss: 0.00574930
Epoch [193/300], Train Loss: 0.005571
Validation Loss: 0.00577306
Epoch [194/300], Train Loss: 0.005601
Validation Loss: 0.00574856
Epoch [195/300], Train Loss: 0.005523
Validation Loss: 0.00574875
Epoch [196/300], Train Loss: 0.005488
Validation Loss: 0.00574434
Epoch [197/300], Train Loss: 0.005509
Validation Loss: 0.00575136
Epoch [198/300], Train Loss: 0.005516
Validation Loss: 0.00574514
Epoch [199/300], Train Loss: 0.005498
Validation Loss: 0.00574401
Epoch [200/300], Train Loss: 0.005573
Validation Loss: 0.00574579
Epoch [201/300], Train Loss: 0.005763
Validation Loss: 0.00574250
Epoch [202/300], Train Loss: 0.005577
Validation Loss: 0.00575067
Epoch [203/300], Train Loss: 0.005469
Validation Loss: 0.00574161
Epoch [204/300], Train Loss: 0.005602
Validation Loss: 0.00575839
Epoch [205/300], Train Loss: 0.005404
Validation Loss: 0.00574958
Epoch [206/300], Train Loss: 0.005460
Validation Loss: 0.00574119
Epoch [207/300], Train Loss: 0.005437
Validation Loss: 0.00574116
Epoch [208/300], Train Loss: 0.005544
Validation Loss: 0.00574046
Epoch [209/300], Train Loss: 0.005479
Validation Loss: 0.00574221
Epoch [210/300], Train Loss: 0.005577
Validation Loss: 0.00574064
Epoch [211/300], Train Loss: 0.005534
Validation Loss: 0.00573964
Epoch [212/300], Train Loss: 0.005475
Validation Loss: 0.00573901
Epoch [213/300], Train Loss: 0.005639
Validation Loss: 0.00573868
Epoch [214/300], Train Loss: 0.005396
Validation Loss: 0.00573910
Epoch [215/300], Train Loss: 0.005451
Validation Loss: 0.00573835
Epoch [216/300], Train Loss: 0.005742
Validation Loss: 0.00574042
Epoch [217/300], Train Loss: 0.005451
Validation Loss: 0.00573985
Epoch [218/300], Train Loss: 0.005454
Validation Loss: 0.00573735
Epoch [219/300], Train Loss: 0.005484
Validation Loss: 0.00573776
Epoch [220/300], Train Loss: 0.005387
Validation Loss: 0.00574135
Epoch [221/300], Train Loss: 0.005629
Validation Loss: 0.00574605
Epoch [222/300], Train Loss: 0.005454
Validation Loss: 0.00573680
Epoch [223/300], Train Loss: 0.005509
Validation Loss: 0.00573679
Epoch [224/300], Train Loss: 0.005575
Validation Loss: 0.00573635
Epoch [225/300], Train Loss: 0.005483
Validation Loss: 0.00574412
Epoch [226/300], Train Loss: 0.005511
Validation Loss: 0.00574098
Epoch [227/300], Train Loss: 0.005419
Validation Loss: 0.00573534
Epoch [228/300], Train Loss: 0.005333
Validation Loss: 0.00573499
Epoch [229/300], Train Loss: 0.005509
Validation Loss: 0.00574002
Epoch [230/300], Train Loss: 0.005515
Validation Loss: 0.00574097
Epoch [231/300], Train Loss: 0.005407
Validation Loss: 0.00573546
Epoch [232/300], Train Loss: 0.005378
Validation Loss: 0.00573413
Epoch [233/300], Train Loss: 0.005576
Validation Loss: 0.00573488
Epoch [234/300], Train Loss: 0.005516
Validation Loss: 0.00573347
Epoch [235/300], Train Loss: 0.005506
Validation Loss: 0.00573302
Epoch [236/300], Train Loss: 0.005529
Validation Loss: 0.00573380
Epoch [237/300], Train Loss: 0.005395
Validation Loss: 0.00573277
Epoch [238/300], Train Loss: 0.005563
Validation Loss: 0.00573254
Epoch [239/300], Train Loss: 0.005695
Validation Loss: 0.00573102
Epoch [240/300], Train Loss: 0.005523
Validation Loss: 0.00573041
Epoch [241/300], Train Loss: 0.005489
Validation Loss: 0.00572982
Epoch [242/300], Train Loss: 0.005440
Validation Loss: 0.00573364
Epoch [243/300], Train Loss: 0.005515
Validation Loss: 0.00573450
Epoch [244/300], Train Loss: 0.005433
Validation Loss: 0.00573028
Epoch [245/300], Train Loss: 0.005561
Validation Loss: 0.00572986
Epoch [246/300], Train Loss: 0.005434
Validation Loss: 0.00572927
Epoch [247/300], Train Loss: 0.005398
Validation Loss: 0.00572808
Epoch [248/300], Train Loss: 0.005531
Validation Loss: 0.00572791
Epoch [249/300], Train Loss: 0.005459
Validation Loss: 0.00572757
Epoch [250/300], Train Loss: 0.005520
Validation Loss: 0.00572964
Epoch [251/300], Train Loss: 0.005542
Validation Loss: 0.00572995
Epoch [252/300], Train Loss: 0.005536
Validation Loss: 0.00572767
Epoch [253/300], Train Loss: 0.005502
Validation Loss: 0.00572951
Epoch [254/300], Train Loss: 0.005392
Validation Loss: 0.00572640
Epoch [255/300], Train Loss: 0.005571
Validation Loss: 0.00573353
Epoch [256/300], Train Loss: 0.005489
Validation Loss: 0.00573362
Epoch [257/300], Train Loss: 0.005426
Validation Loss: 0.00572798
Epoch [258/300], Train Loss: 0.005723
Validation Loss: 0.00572648
Epoch [259/300], Train Loss: 0.005429
Validation Loss: 0.00572590
Epoch [260/300], Train Loss: 0.005412
Validation Loss: 0.00572528
Epoch [261/300], Train Loss: 0.005420
Validation Loss: 0.00572662
Epoch [262/300], Train Loss: 0.005544
Validation Loss: 0.00572758
Epoch [263/300], Train Loss: 0.005537
Validation Loss: 0.00572435
Epoch [264/300], Train Loss: 0.005519
Validation Loss: 0.00572412
Epoch [265/300], Train Loss: 0.005527
Validation Loss: 0.00572393
Epoch [266/300], Train Loss: 0.005479
Validation Loss: 0.00572375
Epoch [267/300], Train Loss: 0.005434
Validation Loss: 0.00572540
Epoch [268/300], Train Loss: 0.005396
Validation Loss: 0.00573441
Epoch [269/300], Train Loss: 0.005414
Validation Loss: 0.00572973
Epoch [270/300], Train Loss: 0.005516
Validation Loss: 0.00572369
Epoch [271/300], Train Loss: 0.005391
Validation Loss: 0.00572375
Epoch [272/300], Train Loss: 0.005496
Validation Loss: 0.00572279
Epoch [273/300], Train Loss: 0.005430
Validation Loss: 0.00572236
Epoch [274/300], Train Loss: 0.005620
Validation Loss: 0.00572395
Epoch [275/300], Train Loss: 0.005413
Validation Loss: 0.00572281
Epoch [276/300], Train Loss: 0.005521
Validation Loss: 0.00572147
Epoch [277/300], Train Loss: 0.005488
Validation Loss: 0.00572100
Epoch [278/300], Train Loss: 0.005483
Validation Loss: 0.00572136
Epoch [279/300], Train Loss: 0.005488
Validation Loss: 0.00572189
Epoch [280/300], Train Loss: 0.005457
Validation Loss: 0.00572063
Epoch [281/300], Train Loss: 0.005523
Validation Loss: 0.00572032
Epoch [282/300], Train Loss: 0.005508
Validation Loss: 0.00571961
Epoch [283/300], Train Loss: 0.005384
Validation Loss: 0.00571941
Epoch [284/300], Train Loss: 0.005523
Validation Loss: 0.00571942
Epoch [285/300], Train Loss: 0.005479
Validation Loss: 0.00572086
Epoch [286/300], Train Loss: 0.005602
Validation Loss: 0.00572118
Epoch [287/300], Train Loss: 0.005474
Validation Loss: 0.00571975
Epoch [288/300], Train Loss: 0.005424
Validation Loss: 0.00571803
Epoch [289/300], Train Loss: 0.005606
Validation Loss: 0.00571910
Epoch [290/300], Train Loss: 0.005357
Validation Loss: 0.00571984
Epoch [291/300], Train Loss: 0.005341
Validation Loss: 0.00572263
Epoch [292/300], Train Loss: 0.005510
Validation Loss: 0.00572595
Epoch [293/300], Train Loss: 0.005704
Validation Loss: 0.00571880
Epoch [294/300], Train Loss: 0.005378
Validation Loss: 0.00571997
Epoch [295/300], Train Loss: 0.005499
Validation Loss: 0.00571784
Epoch [296/300], Train Loss: 0.005503
Validation Loss: 0.00571754
Epoch [297/300], Train Loss: 0.005546
Validation Loss: 0.00571810
Epoch [298/300], Train Loss: 0.005407
Validation Loss: 0.00571721
Epoch [299/300], Train Loss: 0.005353
Validation Loss: 0.00571789
Epoch [300/300], Train Loss: 0.005558
Validation Loss: 0.00572514

Evaluating model for: Router
Run 71/72 completed in 721.70 seconds with: {'MAE': np.float32(0.19410062), 'MSE': np.float32(0.06311438), 'RMSE': np.float32(0.25122577), 'SAE': np.float32(0.0008467017), 'NDE': np.float32(0.012564342)}

Run 72/72: hidden=512, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Router
Dataset length: 539 windows

Epoch [1/300], Train Loss: 0.111241
Validation Loss: 0.09911096
Epoch [2/300], Train Loss: 0.093652
Validation Loss: 0.08164864
Epoch [3/300], Train Loss: 0.075356
Validation Loss: 0.06005603
Epoch [4/300], Train Loss: 0.049408
Validation Loss: 0.02654703
Epoch [5/300], Train Loss: 0.015681
Validation Loss: 0.02063885
Epoch [6/300], Train Loss: 0.012395
Validation Loss: 0.00666561
Epoch [7/300], Train Loss: 0.008904
Validation Loss: 0.01064851
Epoch [8/300], Train Loss: 0.009798
Validation Loss: 0.00756348
Epoch [9/300], Train Loss: 0.006840
Validation Loss: 0.00677677
Epoch [10/300], Train Loss: 0.007048
Validation Loss: 0.00722110
Epoch [11/300], Train Loss: 0.006291
Validation Loss: 0.00620973
Epoch [12/300], Train Loss: 0.006200
Validation Loss: 0.00661273
Epoch [13/300], Train Loss: 0.006298
Validation Loss: 0.00621612
Epoch [14/300], Train Loss: 0.005933
Validation Loss: 0.00633860
Epoch [15/300], Train Loss: 0.006147
Validation Loss: 0.00626953
Epoch [16/300], Train Loss: 0.005903
Validation Loss: 0.00616593
Epoch [17/300], Train Loss: 0.006012
Validation Loss: 0.00617912
Epoch [18/300], Train Loss: 0.005975
Validation Loss: 0.00615614
Epoch [19/300], Train Loss: 0.005848
Validation Loss: 0.00618229
Epoch [20/300], Train Loss: 0.005999
Validation Loss: 0.00617246
Epoch [21/300], Train Loss: 0.005893
Validation Loss: 0.00615394
Epoch [22/300], Train Loss: 0.005906
Validation Loss: 0.00615076
Epoch [23/300], Train Loss: 0.005991
Validation Loss: 0.00616849
Epoch [24/300], Train Loss: 0.005952
Validation Loss: 0.00618596
Epoch [25/300], Train Loss: 0.005890
Validation Loss: 0.00614612
Epoch [26/300], Train Loss: 0.005815
Validation Loss: 0.00614831
Epoch [27/300], Train Loss: 0.005923
Validation Loss: 0.00614386
Epoch [28/300], Train Loss: 0.005931
Validation Loss: 0.00615392
Epoch [29/300], Train Loss: 0.006030
Validation Loss: 0.00614057
Epoch [30/300], Train Loss: 0.005830
Validation Loss: 0.00613891
Epoch [31/300], Train Loss: 0.005818
Validation Loss: 0.00615689
Epoch [32/300], Train Loss: 0.005864
Validation Loss: 0.00615976
Epoch [33/300], Train Loss: 0.006061
Validation Loss: 0.00614841
Epoch [34/300], Train Loss: 0.005859
Validation Loss: 0.00613500
Epoch [35/300], Train Loss: 0.005899
Validation Loss: 0.00613151
Epoch [36/300], Train Loss: 0.005935
Validation Loss: 0.00615950
Epoch [37/300], Train Loss: 0.005873
Validation Loss: 0.00613703
Epoch [38/300], Train Loss: 0.005751
Validation Loss: 0.00612782
Epoch [39/300], Train Loss: 0.005858
Validation Loss: 0.00613750
Epoch [40/300], Train Loss: 0.005985
Validation Loss: 0.00612552
Epoch [41/300], Train Loss: 0.005934
Validation Loss: 0.00613427
Epoch [42/300], Train Loss: 0.006079
Validation Loss: 0.00612358
Epoch [43/300], Train Loss: 0.005989
Validation Loss: 0.00612164
Epoch [44/300], Train Loss: 0.005853
Validation Loss: 0.00612026
Epoch [45/300], Train Loss: 0.005850
Validation Loss: 0.00611593
Epoch [46/300], Train Loss: 0.005829
Validation Loss: 0.00611546
Epoch [47/300], Train Loss: 0.005918
Validation Loss: 0.00613373
Epoch [48/300], Train Loss: 0.006042
Validation Loss: 0.00612190
Epoch [49/300], Train Loss: 0.005928
Validation Loss: 0.00611067
Epoch [50/300], Train Loss: 0.005939
Validation Loss: 0.00610887
Epoch [51/300], Train Loss: 0.005911
Validation Loss: 0.00610903
Epoch [52/300], Train Loss: 0.005938
Validation Loss: 0.00610639
Epoch [53/300], Train Loss: 0.005909
Validation Loss: 0.00610549
Epoch [54/300], Train Loss: 0.005892
Validation Loss: 0.00611093
Epoch [55/300], Train Loss: 0.005893
Validation Loss: 0.00610036
Epoch [56/300], Train Loss: 0.005901
Validation Loss: 0.00609872
Epoch [57/300], Train Loss: 0.005971
Validation Loss: 0.00609701
Epoch [58/300], Train Loss: 0.005826
Validation Loss: 0.00609638
Epoch [59/300], Train Loss: 0.005884
Validation Loss: 0.00609467
Epoch [60/300], Train Loss: 0.005857
Validation Loss: 0.00610145
Epoch [61/300], Train Loss: 0.005803
Validation Loss: 0.00613116
Epoch [62/300], Train Loss: 0.005982
Validation Loss: 0.00609557
Epoch [63/300], Train Loss: 0.005718
Validation Loss: 0.00610435
Epoch [64/300], Train Loss: 0.005974
Validation Loss: 0.00608604
Epoch [65/300], Train Loss: 0.005766
Validation Loss: 0.00615642
Epoch [66/300], Train Loss: 0.006035
Validation Loss: 0.00611434
Epoch [67/300], Train Loss: 0.005792
Validation Loss: 0.00609368
Epoch [68/300], Train Loss: 0.005822
Validation Loss: 0.00609335
Epoch [69/300], Train Loss: 0.005854
Validation Loss: 0.00609108
Epoch [70/300], Train Loss: 0.005866
Validation Loss: 0.00608717
Epoch [71/300], Train Loss: 0.005893
Validation Loss: 0.00607366
Epoch [72/300], Train Loss: 0.005705
Validation Loss: 0.00607224
Epoch [73/300], Train Loss: 0.005750
Validation Loss: 0.00609311
Epoch [74/300], Train Loss: 0.005904
Validation Loss: 0.00607351
Epoch [75/300], Train Loss: 0.005737
Validation Loss: 0.00606607
Epoch [76/300], Train Loss: 0.005882
Validation Loss: 0.00606566
Epoch [77/300], Train Loss: 0.005862
Validation Loss: 0.00606861
Epoch [78/300], Train Loss: 0.005868
Validation Loss: 0.00606202
Epoch [79/300], Train Loss: 0.005738
Validation Loss: 0.00606109
Epoch [80/300], Train Loss: 0.005906
Validation Loss: 0.00606409
Epoch [81/300], Train Loss: 0.005728
Validation Loss: 0.00605579
Epoch [82/300], Train Loss: 0.005966
Validation Loss: 0.00605572
Epoch [83/300], Train Loss: 0.005848
Validation Loss: 0.00606251
Epoch [84/300], Train Loss: 0.005758
Validation Loss: 0.00606393
Epoch [85/300], Train Loss: 0.005810
Validation Loss: 0.00604739
Epoch [86/300], Train Loss: 0.005768
Validation Loss: 0.00604550
Epoch [87/300], Train Loss: 0.005826
Validation Loss: 0.00604918
Epoch [88/300], Train Loss: 0.005810
Validation Loss: 0.00604174
Epoch [89/300], Train Loss: 0.005823
Validation Loss: 0.00604312
Epoch [90/300], Train Loss: 0.005944
Validation Loss: 0.00604031
Epoch [91/300], Train Loss: 0.005867
Validation Loss: 0.00604904
Epoch [92/300], Train Loss: 0.005820
Validation Loss: 0.00604421
Epoch [93/300], Train Loss: 0.005858
Validation Loss: 0.00603339
Epoch [94/300], Train Loss: 0.005653
Validation Loss: 0.00602951
Epoch [95/300], Train Loss: 0.005789
Validation Loss: 0.00602904
Epoch [96/300], Train Loss: 0.005863
Validation Loss: 0.00602798
Epoch [97/300], Train Loss: 0.005764
Validation Loss: 0.00602334
Epoch [98/300], Train Loss: 0.005845
Validation Loss: 0.00602493
Epoch [99/300], Train Loss: 0.005810
Validation Loss: 0.00602429
Epoch [100/300], Train Loss: 0.005802
Validation Loss: 0.00602203
Epoch [101/300], Train Loss: 0.005750
Validation Loss: 0.00601957
Epoch [102/300], Train Loss: 0.005821
Validation Loss: 0.00601306
Epoch [103/300], Train Loss: 0.005799
Validation Loss: 0.00601441
Epoch [104/300], Train Loss: 0.005721
Validation Loss: 0.00601786
Epoch [105/300], Train Loss: 0.005819
Validation Loss: 0.00601914
Epoch [106/300], Train Loss: 0.005971
Validation Loss: 0.00600566
Epoch [107/300], Train Loss: 0.005765
Validation Loss: 0.00600397
Epoch [108/300], Train Loss: 0.005944
Validation Loss: 0.00600194
Epoch [109/300], Train Loss: 0.006025
Validation Loss: 0.00600904
Epoch [110/300], Train Loss: 0.005749
Validation Loss: 0.00599552
Epoch [111/300], Train Loss: 0.005724
Validation Loss: 0.00599532
Epoch [112/300], Train Loss: 0.005883
Validation Loss: 0.00601088
Epoch [113/300], Train Loss: 0.005873
Validation Loss: 0.00598986
Epoch [114/300], Train Loss: 0.005922
Validation Loss: 0.00600874
Epoch [115/300], Train Loss: 0.005852
Validation Loss: 0.00598990
Epoch [116/300], Train Loss: 0.005758
Validation Loss: 0.00602400
Epoch [117/300], Train Loss: 0.005775
Validation Loss: 0.00598285
Epoch [118/300], Train Loss: 0.005758
Validation Loss: 0.00599611
Epoch [119/300], Train Loss: 0.005747
Validation Loss: 0.00598111
Epoch [120/300], Train Loss: 0.005789
Validation Loss: 0.00598952
Epoch [121/300], Train Loss: 0.005711
Validation Loss: 0.00598114
Epoch [122/300], Train Loss: 0.005708
Validation Loss: 0.00597568
Epoch [123/300], Train Loss: 0.005774
Validation Loss: 0.00599920
Epoch [124/300], Train Loss: 0.005781
Validation Loss: 0.00598268
Epoch [125/300], Train Loss: 0.005837
Validation Loss: 0.00597228
Epoch [126/300], Train Loss: 0.005829
Validation Loss: 0.00597091
Epoch [127/300], Train Loss: 0.005758
Validation Loss: 0.00596924
Epoch [128/300], Train Loss: 0.005865
Validation Loss: 0.00597661
Epoch [129/300], Train Loss: 0.005698
Validation Loss: 0.00597466
Epoch [130/300], Train Loss: 0.005885
Validation Loss: 0.00596525
Epoch [131/300], Train Loss: 0.005727
Validation Loss: 0.00596394
Epoch [132/300], Train Loss: 0.005718
Validation Loss: 0.00596910
Epoch [133/300], Train Loss: 0.005710
Validation Loss: 0.00596232
Epoch [134/300], Train Loss: 0.005867
Validation Loss: 0.00596298
Epoch [135/300], Train Loss: 0.005663
Validation Loss: 0.00596293
Epoch [136/300], Train Loss: 0.005759
Validation Loss: 0.00595781
Epoch [137/300], Train Loss: 0.005899
Validation Loss: 0.00596351
Epoch [138/300], Train Loss: 0.005723
Validation Loss: 0.00595528
Epoch [139/300], Train Loss: 0.005705
Validation Loss: 0.00595382
Epoch [140/300], Train Loss: 0.005683
Validation Loss: 0.00595493
Epoch [141/300], Train Loss: 0.005611
Validation Loss: 0.00595857
Epoch [142/300], Train Loss: 0.005656
Validation Loss: 0.00594959
Epoch [143/300], Train Loss: 0.005758
Validation Loss: 0.00594855
Epoch [144/300], Train Loss: 0.005737
Validation Loss: 0.00594816
Epoch [145/300], Train Loss: 0.005682
Validation Loss: 0.00595518
Epoch [146/300], Train Loss: 0.005640
Validation Loss: 0.00595474
Epoch [147/300], Train Loss: 0.005785
Validation Loss: 0.00594537
Epoch [148/300], Train Loss: 0.005641
Validation Loss: 0.00595053
Epoch [149/300], Train Loss: 0.005858
Validation Loss: 0.00594502
Epoch [150/300], Train Loss: 0.005958
Validation Loss: 0.00594392
Epoch [151/300], Train Loss: 0.005731
Validation Loss: 0.00594502
Epoch [152/300], Train Loss: 0.005903
Validation Loss: 0.00594363
Epoch [153/300], Train Loss: 0.005591
Validation Loss: 0.00594007
Epoch [154/300], Train Loss: 0.005617
Validation Loss: 0.00594007
Epoch [155/300], Train Loss: 0.005832
Validation Loss: 0.00595210
Epoch [156/300], Train Loss: 0.005746
Validation Loss: 0.00593776
Epoch [157/300], Train Loss: 0.005813
Validation Loss: 0.00595331
Epoch [158/300], Train Loss: 0.005725
Validation Loss: 0.00593474
Epoch [159/300], Train Loss: 0.005881
Validation Loss: 0.00596684
Epoch [160/300], Train Loss: 0.005714
Validation Loss: 0.00593290
Epoch [161/300], Train Loss: 0.005768
Validation Loss: 0.00593281
Epoch [162/300], Train Loss: 0.005665
Validation Loss: 0.00593088
Epoch [163/300], Train Loss: 0.005765
Validation Loss: 0.00593176
Epoch [164/300], Train Loss: 0.005630
Validation Loss: 0.00592961
Epoch [165/300], Train Loss: 0.005613
Validation Loss: 0.00593072
Epoch [166/300], Train Loss: 0.005605
Validation Loss: 0.00592874
Epoch [167/300], Train Loss: 0.005641
Validation Loss: 0.00592682
Epoch [168/300], Train Loss: 0.005668
Validation Loss: 0.00592538
Epoch [169/300], Train Loss: 0.005822
Validation Loss: 0.00592426
Epoch [170/300], Train Loss: 0.005590
Validation Loss: 0.00592299
Epoch [171/300], Train Loss: 0.005736
Validation Loss: 0.00592953
Epoch [172/300], Train Loss: 0.005687
Validation Loss: 0.00593098
Epoch [173/300], Train Loss: 0.005588
Validation Loss: 0.00592054
Epoch [174/300], Train Loss: 0.005789
Validation Loss: 0.00592005
Epoch [175/300], Train Loss: 0.005825
Validation Loss: 0.00591948
Epoch [176/300], Train Loss: 0.005714
Validation Loss: 0.00591858
Epoch [177/300], Train Loss: 0.005574
Validation Loss: 0.00591912
Epoch [178/300], Train Loss: 0.005568
Validation Loss: 0.00592410
Epoch [179/300], Train Loss: 0.005675
Validation Loss: 0.00592813
Epoch [180/300], Train Loss: 0.005881
Validation Loss: 0.00591627
Epoch [181/300], Train Loss: 0.005711
Validation Loss: 0.00591954
Epoch [182/300], Train Loss: 0.005694
Validation Loss: 0.00591402
Epoch [183/300], Train Loss: 0.005865
Validation Loss: 0.00592566
Epoch [184/300], Train Loss: 0.005683
Validation Loss: 0.00591302
Epoch [185/300], Train Loss: 0.005566
Validation Loss: 0.00591558
Epoch [186/300], Train Loss: 0.005769
Validation Loss: 0.00591076
Epoch [187/300], Train Loss: 0.005745
Validation Loss: 0.00591055
Epoch [188/300], Train Loss: 0.005639
Validation Loss: 0.00590943
Epoch [189/300], Train Loss: 0.005746
Validation Loss: 0.00590794
Epoch [190/300], Train Loss: 0.005667
Validation Loss: 0.00591157
Epoch [191/300], Train Loss: 0.005803
Validation Loss: 0.00590698
Epoch [192/300], Train Loss: 0.005541
Validation Loss: 0.00591959
Epoch [193/300], Train Loss: 0.005767
Validation Loss: 0.00593613
Epoch [194/300], Train Loss: 0.005773
Validation Loss: 0.00590541
Epoch [195/300], Train Loss: 0.005727
Validation Loss: 0.00591521
Epoch [196/300], Train Loss: 0.005672
Validation Loss: 0.00591214
Epoch [197/300], Train Loss: 0.005707
Validation Loss: 0.00592224
Epoch [198/300], Train Loss: 0.005702
Validation Loss: 0.00590250
Epoch [199/300], Train Loss: 0.005688
Validation Loss: 0.00590208
Epoch [200/300], Train Loss: 0.005750
Validation Loss: 0.00590735
Epoch [201/300], Train Loss: 0.005948
Validation Loss: 0.00590171
Epoch [202/300], Train Loss: 0.005765
Validation Loss: 0.00591380
Epoch [203/300], Train Loss: 0.005653
Validation Loss: 0.00589919
Epoch [204/300], Train Loss: 0.005781
Validation Loss: 0.00592821
Epoch [205/300], Train Loss: 0.005589
Validation Loss: 0.00590205
Epoch [206/300], Train Loss: 0.005633
Validation Loss: 0.00589881
Epoch [207/300], Train Loss: 0.005615
Validation Loss: 0.00589769
Epoch [208/300], Train Loss: 0.005728
Validation Loss: 0.00589960
Epoch [209/300], Train Loss: 0.005657
Validation Loss: 0.00590046
Epoch [210/300], Train Loss: 0.005745
Validation Loss: 0.00589521
Epoch [211/300], Train Loss: 0.005711
Validation Loss: 0.00589504
Epoch [212/300], Train Loss: 0.005651
Validation Loss: 0.00589427
Epoch [213/300], Train Loss: 0.005824
Validation Loss: 0.00589392
Epoch [214/300], Train Loss: 0.005568
Validation Loss: 0.00589403
Epoch [215/300], Train Loss: 0.005632
Validation Loss: 0.00589283
Epoch [216/300], Train Loss: 0.005915
Validation Loss: 0.00589423
Epoch [217/300], Train Loss: 0.005619
Validation Loss: 0.00589268
Epoch [218/300], Train Loss: 0.005642
Validation Loss: 0.00589187
Epoch [219/300], Train Loss: 0.005654
Validation Loss: 0.00589228
Epoch [220/300], Train Loss: 0.005563
Validation Loss: 0.00589777
Epoch [221/300], Train Loss: 0.005806
Validation Loss: 0.00589792
Epoch [222/300], Train Loss: 0.005631
Validation Loss: 0.00588996
Epoch [223/300], Train Loss: 0.005682
Validation Loss: 0.00589008
Epoch [224/300], Train Loss: 0.005739
Validation Loss: 0.00589009
Epoch [225/300], Train Loss: 0.005658
Validation Loss: 0.00590247
Epoch [226/300], Train Loss: 0.005686
Validation Loss: 0.00588950
Epoch [227/300], Train Loss: 0.005594
Validation Loss: 0.00588873
Epoch [228/300], Train Loss: 0.005506
Validation Loss: 0.00588623
Epoch [229/300], Train Loss: 0.005682
Validation Loss: 0.00589923
Epoch [230/300], Train Loss: 0.005678
Validation Loss: 0.00589309
Epoch [231/300], Train Loss: 0.005580
Validation Loss: 0.00588485
Epoch [232/300], Train Loss: 0.005555
Validation Loss: 0.00588461
Epoch [233/300], Train Loss: 0.005757
Validation Loss: 0.00588628
Epoch [234/300], Train Loss: 0.005685
Validation Loss: 0.00588352
Epoch [235/300], Train Loss: 0.005677
Validation Loss: 0.00588316
Epoch [236/300], Train Loss: 0.005704
Validation Loss: 0.00588356
Epoch [237/300], Train Loss: 0.005560
Validation Loss: 0.00588170
Epoch [238/300], Train Loss: 0.005732
Validation Loss: 0.00588119
Epoch [239/300], Train Loss: 0.005865
Validation Loss: 0.00588004
Epoch [240/300], Train Loss: 0.005694
Validation Loss: 0.00587945
Epoch [241/300], Train Loss: 0.005652
Validation Loss: 0.00587861
Epoch [242/300], Train Loss: 0.005609
Validation Loss: 0.00588485
Epoch [243/300], Train Loss: 0.005675
Validation Loss: 0.00588177
Epoch [244/300], Train Loss: 0.005600
Validation Loss: 0.00587713
Epoch [245/300], Train Loss: 0.005731
Validation Loss: 0.00587737
Epoch [246/300], Train Loss: 0.005604
Validation Loss: 0.00587747
Epoch [247/300], Train Loss: 0.005566
Validation Loss: 0.00587582
Epoch [248/300], Train Loss: 0.005706
Validation Loss: 0.00587551
Epoch [249/300], Train Loss: 0.005625
Validation Loss: 0.00587505
Epoch [250/300], Train Loss: 0.005692
Validation Loss: 0.00587770
Epoch [251/300], Train Loss: 0.005716
Validation Loss: 0.00587670
Epoch [252/300], Train Loss: 0.005705
Validation Loss: 0.00587756
Epoch [253/300], Train Loss: 0.005662
Validation Loss: 0.00587789
Epoch [254/300], Train Loss: 0.005541
Validation Loss: 0.00587393
Epoch [255/300], Train Loss: 0.005741
Validation Loss: 0.00588713
Epoch [256/300], Train Loss: 0.005658
Validation Loss: 0.00587765
Epoch [257/300], Train Loss: 0.005595
Validation Loss: 0.00587222
Epoch [258/300], Train Loss: 0.005888
Validation Loss: 0.00587209
Epoch [259/300], Train Loss: 0.005593
Validation Loss: 0.00587155
Epoch [260/300], Train Loss: 0.005576
Validation Loss: 0.00587124
Epoch [261/300], Train Loss: 0.005591
Validation Loss: 0.00587378
Epoch [262/300], Train Loss: 0.005714
Validation Loss: 0.00587144
Epoch [263/300], Train Loss: 0.005703
Validation Loss: 0.00587018
Epoch [264/300], Train Loss: 0.005684
Validation Loss: 0.00586915
Epoch [265/300], Train Loss: 0.005692
Validation Loss: 0.00586919
Epoch [266/300], Train Loss: 0.005646
Validation Loss: 0.00586899
Epoch [267/300], Train Loss: 0.005606
Validation Loss: 0.00587034
Epoch [268/300], Train Loss: 0.005558
Validation Loss: 0.00587898
Epoch [269/300], Train Loss: 0.005578
Validation Loss: 0.00587056
Epoch [270/300], Train Loss: 0.005691
Validation Loss: 0.00586704
Epoch [271/300], Train Loss: 0.005550
Validation Loss: 0.00586799
Epoch [272/300], Train Loss: 0.005659
Validation Loss: 0.00586723
Epoch [273/300], Train Loss: 0.005590
Validation Loss: 0.00586625
Epoch [274/300], Train Loss: 0.005786
Validation Loss: 0.00586835
Epoch [275/300], Train Loss: 0.005582
Validation Loss: 0.00586586
Epoch [276/300], Train Loss: 0.005693
Validation Loss: 0.00586514
Epoch [277/300], Train Loss: 0.005650
Validation Loss: 0.00586445
Epoch [278/300], Train Loss: 0.005646
Validation Loss: 0.00586607
Epoch [279/300], Train Loss: 0.005649
Validation Loss: 0.00586588
Epoch [280/300], Train Loss: 0.005623
Validation Loss: 0.00586300
Epoch [281/300], Train Loss: 0.005690
Validation Loss: 0.00586268
Epoch [282/300], Train Loss: 0.005666
Validation Loss: 0.00586219
Epoch [283/300], Train Loss: 0.005538
Validation Loss: 0.00586190
Epoch [284/300], Train Loss: 0.005689
Validation Loss: 0.00586241
Epoch [285/300], Train Loss: 0.005641
Validation Loss: 0.00586376
Epoch [286/300], Train Loss: 0.005774
Validation Loss: 0.00586253
Epoch [287/300], Train Loss: 0.005631
Validation Loss: 0.00586074
Epoch [288/300], Train Loss: 0.005585
Validation Loss: 0.00586002
Epoch [289/300], Train Loss: 0.005764
Validation Loss: 0.00586209
Epoch [290/300], Train Loss: 0.005511
Validation Loss: 0.00586317
Epoch [291/300], Train Loss: 0.005502
Validation Loss: 0.00586553
Epoch [292/300], Train Loss: 0.005666
Validation Loss: 0.00586622
Epoch [293/300], Train Loss: 0.005861
Validation Loss: 0.00585884
Epoch [294/300], Train Loss: 0.005547
Validation Loss: 0.00586627
Epoch [295/300], Train Loss: 0.005651
Validation Loss: 0.00585804
Epoch [296/300], Train Loss: 0.005671
Validation Loss: 0.00586347
Epoch [297/300], Train Loss: 0.005714
Validation Loss: 0.00585995
Epoch [298/300], Train Loss: 0.005571
Validation Loss: 0.00585657
Epoch [299/300], Train Loss: 0.005511
Validation Loss: 0.00585660
Epoch [300/300], Train Loss: 0.005719
Validation Loss: 0.00586760

Evaluating model for: Router
Run 72/72 completed in 957.12 seconds with: {'MAE': np.float32(0.19598879), 'MSE': np.float32(0.06496741), 'RMSE': np.float32(0.25488704), 'SAE': np.float32(0.0009076427), 'NDE': np.float32(0.012747452)}
    hidden_size  seq_length  stride  num_layers  eval_result
27          256         120    0.25           5     0.173466
2           128         120    0.25           4     0.177624
25          256         120    0.25           3     0.179208
3           128         120    0.25           5     0.182085
51          512         120    0.25           5     0.183368
..          ...         ...     ...         ...          ...
12          128         360    0.50           2     0.212037
13          128         360    0.50           3     0.212092
37          256         360    0.50           3     0.212633
14          128         360    0.50           4     0.213804
15          128         360    0.50           5     0.214279

[72 rows x 5 columns]
