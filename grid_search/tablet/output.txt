Using device: cuda

Run 1/72: hidden=128, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Tablet
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.049818
Validation Loss: 0.02000078
Epoch [2/300], Train Loss: 0.017797
Validation Loss: 0.01490237
Epoch [3/300], Train Loss: 0.013130
Validation Loss: 0.01187346
Epoch [4/300], Train Loss: 0.011612
Validation Loss: 0.01087366
Epoch [5/300], Train Loss: 0.010664
Validation Loss: 0.01009005
Epoch [6/300], Train Loss: 0.010110
Validation Loss: 0.00970053
Epoch [7/300], Train Loss: 0.009752
Validation Loss: 0.00947810
Epoch [8/300], Train Loss: 0.009497
Validation Loss: 0.00927774
Epoch [9/300], Train Loss: 0.009263
Validation Loss: 0.00908819
Epoch [10/300], Train Loss: 0.009081
Validation Loss: 0.00894143
Epoch [11/300], Train Loss: 0.008899
Validation Loss: 0.00875964
Epoch [12/300], Train Loss: 0.008755
Validation Loss: 0.00913061
Epoch [13/300], Train Loss: 0.008628
Validation Loss: 0.00869294
Epoch [14/300], Train Loss: 0.008440
Validation Loss: 0.00826799
Epoch [15/300], Train Loss: 0.008266
Validation Loss: 0.00812365
Epoch [16/300], Train Loss: 0.008139
Validation Loss: 0.00813454
Epoch [17/300], Train Loss: 0.007938
Validation Loss: 0.00776793
Epoch [18/300], Train Loss: 0.007719
Validation Loss: 0.00832996
Epoch [19/300], Train Loss: 0.007603
Validation Loss: 0.00734962
Epoch [20/300], Train Loss: 0.007348
Validation Loss: 0.00713379
Epoch [21/300], Train Loss: 0.007294
Validation Loss: 0.00705478
Epoch [22/300], Train Loss: 0.007177
Validation Loss: 0.00701588
Epoch [23/300], Train Loss: 0.007189
Validation Loss: 0.00716840
Epoch [24/300], Train Loss: 0.007067
Validation Loss: 0.00689319
Epoch [25/300], Train Loss: 0.007118
Validation Loss: 0.00686493
Epoch [26/300], Train Loss: 0.006996
Validation Loss: 0.00689537
Epoch [27/300], Train Loss: 0.006943
Validation Loss: 0.00677749
Epoch [28/300], Train Loss: 0.006896
Validation Loss: 0.00673029
Epoch [29/300], Train Loss: 0.006847
Validation Loss: 0.00671552
Epoch [30/300], Train Loss: 0.006801
Validation Loss: 0.00665008
Epoch [31/300], Train Loss: 0.006805
Validation Loss: 0.00662767
Epoch [32/300], Train Loss: 0.006672
Validation Loss: 0.00658334
Epoch [33/300], Train Loss: 0.006681
Validation Loss: 0.00662116
Epoch [34/300], Train Loss: 0.006633
Validation Loss: 0.00653831
Epoch [35/300], Train Loss: 0.006642
Validation Loss: 0.00660653
Epoch [36/300], Train Loss: 0.006624
Validation Loss: 0.00651763
Epoch [37/300], Train Loss: 0.006569
Validation Loss: 0.00641947
Epoch [38/300], Train Loss: 0.006550
Validation Loss: 0.00642387
Epoch [39/300], Train Loss: 0.006484
Validation Loss: 0.00643793
Epoch [40/300], Train Loss: 0.006440
Validation Loss: 0.00652280
Epoch [41/300], Train Loss: 0.006392
Validation Loss: 0.00646672
Epoch [42/300], Train Loss: 0.006441
Validation Loss: 0.00625063
Epoch [43/300], Train Loss: 0.006290
Validation Loss: 0.00625071
Epoch [44/300], Train Loss: 0.006228
Validation Loss: 0.00606031
Epoch [45/300], Train Loss: 0.006172
Validation Loss: 0.00600677
Epoch [46/300], Train Loss: 0.005996
Validation Loss: 0.00616708
Epoch [47/300], Train Loss: 0.006024
Validation Loss: 0.00568115
Epoch [48/300], Train Loss: 0.005645
Validation Loss: 0.00535308
Epoch [49/300], Train Loss: 0.005415
Validation Loss: 0.00511360
Epoch [50/300], Train Loss: 0.005208
Validation Loss: 0.00485461
Epoch [51/300], Train Loss: 0.004852
Validation Loss: 0.00460565
Epoch [52/300], Train Loss: 0.004571
Validation Loss: 0.00411695
Epoch [53/300], Train Loss: 0.004422
Validation Loss: 0.00408657
Epoch [54/300], Train Loss: 0.004227
Validation Loss: 0.00371233
Epoch [55/300], Train Loss: 0.003964
Validation Loss: 0.00341811
Epoch [56/300], Train Loss: 0.003753
Validation Loss: 0.00329633
Epoch [57/300], Train Loss: 0.003683
Validation Loss: 0.00329442
Epoch [58/300], Train Loss: 0.003565
Validation Loss: 0.00306458
Epoch [59/300], Train Loss: 0.003530
Validation Loss: 0.00298316
Epoch [60/300], Train Loss: 0.003340
Validation Loss: 0.00294951
Epoch [61/300], Train Loss: 0.003299
Validation Loss: 0.00306396
Epoch [62/300], Train Loss: 0.003466
Validation Loss: 0.00299455
Epoch [63/300], Train Loss: 0.003218
Validation Loss: 0.00282147
Epoch [64/300], Train Loss: 0.003169
Validation Loss: 0.00278311
Epoch [65/300], Train Loss: 0.003179
Validation Loss: 0.00283365
Epoch [66/300], Train Loss: 0.003125
Validation Loss: 0.00275415
Epoch [67/300], Train Loss: 0.003213
Validation Loss: 0.00277653
Epoch [68/300], Train Loss: 0.003081
Validation Loss: 0.00276220
Epoch [69/300], Train Loss: 0.003112
Validation Loss: 0.00268697
Epoch [70/300], Train Loss: 0.003032
Validation Loss: 0.00271746
Epoch [71/300], Train Loss: 0.003031
Validation Loss: 0.00266511
Epoch [72/300], Train Loss: 0.003017
Validation Loss: 0.00270340
Epoch [73/300], Train Loss: 0.003016
Validation Loss: 0.00264689
Epoch [74/300], Train Loss: 0.003056
Validation Loss: 0.00290289
Epoch [75/300], Train Loss: 0.002983
Validation Loss: 0.00260833
Epoch [76/300], Train Loss: 0.002944
Validation Loss: 0.00261871
Epoch [77/300], Train Loss: 0.002917
Validation Loss: 0.00264961
Epoch [78/300], Train Loss: 0.002899
Validation Loss: 0.00257896
Epoch [79/300], Train Loss: 0.002879
Validation Loss: 0.00255035
Epoch [80/300], Train Loss: 0.002865
Validation Loss: 0.00259153
Epoch [81/300], Train Loss: 0.002887
Validation Loss: 0.00255503
Epoch [82/300], Train Loss: 0.002886
Validation Loss: 0.00262034
Epoch [83/300], Train Loss: 0.004777
Validation Loss: 0.00355973
Epoch [84/300], Train Loss: 0.003966
Validation Loss: 0.00317948
Epoch [85/300], Train Loss: 0.003471
Validation Loss: 0.00296763
Epoch [86/300], Train Loss: 0.003321
Validation Loss: 0.00287387
Epoch [87/300], Train Loss: 0.003215
Validation Loss: 0.00283252
Epoch [88/300], Train Loss: 0.003196
Validation Loss: 0.00279647
Epoch [89/300], Train Loss: 0.003114
Validation Loss: 0.00275155
Early stopping triggered

Evaluating model for: Tablet
Run 1/72 completed in 2110.66 seconds with: {'MAE': np.float32(0.45968387), 'MSE': np.float32(0.44850832), 'RMSE': np.float32(0.66970766), 'SAE': np.float32(0.005532883), 'NDE': np.float32(0.15370457)}

Run 2/72: hidden=128, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Tablet
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.045892
Validation Loss: 0.01923052
Epoch [2/300], Train Loss: 0.016527
Validation Loss: 0.01333775
Epoch [3/300], Train Loss: 0.012574
Validation Loss: 0.01184360
Epoch [4/300], Train Loss: 0.011574
Validation Loss: 0.01109231
Epoch [5/300], Train Loss: 0.010631
Validation Loss: 0.01004213
Epoch [6/300], Train Loss: 0.009879
Validation Loss: 0.00958621
Epoch [7/300], Train Loss: 0.009368
Validation Loss: 0.00901708
Epoch [8/300], Train Loss: 0.009036
Validation Loss: 0.00877160
Epoch [9/300], Train Loss: 0.008720
Validation Loss: 0.00842525
Epoch [10/300], Train Loss: 0.008380
Validation Loss: 0.00803493
Epoch [11/300], Train Loss: 0.008180
Validation Loss: 0.00786994
Epoch [12/300], Train Loss: 0.007987
Validation Loss: 0.00771649
Epoch [13/300], Train Loss: 0.007885
Validation Loss: 0.00762257
Epoch [14/300], Train Loss: 0.007708
Validation Loss: 0.00752046
Epoch [15/300], Train Loss: 0.007601
Validation Loss: 0.00742541
Epoch [16/300], Train Loss: 0.007545
Validation Loss: 0.00747409
Epoch [17/300], Train Loss: 0.007445
Validation Loss: 0.00729428
Epoch [18/300], Train Loss: 0.007385
Validation Loss: 0.00735411
Epoch [19/300], Train Loss: 0.007339
Validation Loss: 0.00723809
Epoch [20/300], Train Loss: 0.007270
Validation Loss: 0.00711756
Epoch [21/300], Train Loss: 0.007241
Validation Loss: 0.00705869
Epoch [22/300], Train Loss: 0.007153
Validation Loss: 0.00730874
Epoch [23/300], Train Loss: 0.007101
Validation Loss: 0.00698015
Epoch [24/300], Train Loss: 0.007035
Validation Loss: 0.00689250
Epoch [25/300], Train Loss: 0.006968
Validation Loss: 0.00680342
Epoch [26/300], Train Loss: 0.006910
Validation Loss: 0.00672827
Epoch [27/300], Train Loss: 0.006825
Validation Loss: 0.00669345
Epoch [28/300], Train Loss: 0.006742
Validation Loss: 0.00663636
Epoch [29/300], Train Loss: 0.006739
Validation Loss: 0.00678455
Epoch [30/300], Train Loss: 0.006599
Validation Loss: 0.00644553
Epoch [31/300], Train Loss: 0.006495
Validation Loss: 0.00650788
Epoch [32/300], Train Loss: 0.006275
Validation Loss: 0.00586020
Epoch [33/300], Train Loss: 0.005747
Validation Loss: 0.00511774
Epoch [34/300], Train Loss: 0.004728
Validation Loss: 0.00386561
Epoch [35/300], Train Loss: 0.004984
Validation Loss: 0.00408438
Epoch [36/300], Train Loss: 0.004227
Validation Loss: 0.00350209
Epoch [37/300], Train Loss: 0.003903
Validation Loss: 0.00335170
Epoch [38/300], Train Loss: 0.003715
Validation Loss: 0.00315446
Epoch [39/300], Train Loss: 0.003534
Validation Loss: 0.00299785
Epoch [40/300], Train Loss: 0.003361
Validation Loss: 0.00290713
Epoch [41/300], Train Loss: 0.003255
Validation Loss: 0.00284486
Epoch [42/300], Train Loss: 0.003162
Validation Loss: 0.00274505
Epoch [43/300], Train Loss: 0.003037
Validation Loss: 0.00270505
Epoch [44/300], Train Loss: 0.002955
Validation Loss: 0.00255707
Epoch [45/300], Train Loss: 0.002860
Validation Loss: 0.00265345
Epoch [46/300], Train Loss: 0.002792
Validation Loss: 0.00245759
Epoch [47/300], Train Loss: 0.002750
Validation Loss: 0.00243505
Epoch [48/300], Train Loss: 0.002727
Validation Loss: 0.00241923
Epoch [49/300], Train Loss: 0.002677
Validation Loss: 0.00241026
Epoch [50/300], Train Loss: 0.002630
Validation Loss: 0.00246152
Epoch [51/300], Train Loss: 0.002642
Validation Loss: 0.00236271
Epoch [52/300], Train Loss: 0.002617
Validation Loss: 0.00233645
Epoch [53/300], Train Loss: 0.002577
Validation Loss: 0.00255128
Epoch [54/300], Train Loss: 0.002583
Validation Loss: 0.00260774
Epoch [55/300], Train Loss: 0.002600
Validation Loss: 0.00233384
Epoch [56/300], Train Loss: 0.002531
Validation Loss: 0.00232114
Epoch [57/300], Train Loss: 0.002559
Validation Loss: 0.00229361
Epoch [58/300], Train Loss: 0.002518
Validation Loss: 0.00229047
Epoch [59/300], Train Loss: 0.002494
Validation Loss: 0.00227457
Epoch [60/300], Train Loss: 0.002480
Validation Loss: 0.00228359
Epoch [61/300], Train Loss: 0.002476
Validation Loss: 0.00230015
Epoch [62/300], Train Loss: 0.002478
Validation Loss: 0.00234214
Epoch [63/300], Train Loss: 0.002485
Validation Loss: 0.00225277
Epoch [64/300], Train Loss: 0.002453
Validation Loss: 0.00226415
Epoch [65/300], Train Loss: 0.002453
Validation Loss: 0.00233120
Epoch [66/300], Train Loss: 0.002439
Validation Loss: 0.00229135
Epoch [67/300], Train Loss: 0.002433
Validation Loss: 0.00227423
Epoch [68/300], Train Loss: 0.002444
Validation Loss: 0.00223255
Epoch [69/300], Train Loss: 0.002426
Validation Loss: 0.00230801
Epoch [70/300], Train Loss: 0.002404
Validation Loss: 0.00222956
Epoch [71/300], Train Loss: 0.002435
Validation Loss: 0.00232511
Epoch [72/300], Train Loss: 0.002477
Validation Loss: 0.00224346
Epoch [73/300], Train Loss: 0.002401
Validation Loss: 0.00242758
Epoch [74/300], Train Loss: 0.002396
Validation Loss: 0.00222923
Epoch [75/300], Train Loss: 0.002388
Validation Loss: 0.00222986
Epoch [76/300], Train Loss: 0.002385
Validation Loss: 0.00222725
Epoch [77/300], Train Loss: 0.002380
Validation Loss: 0.00233268
Epoch [78/300], Train Loss: 0.002390
Validation Loss: 0.00224575
Epoch [79/300], Train Loss: 0.002354
Validation Loss: 0.00225355
Epoch [80/300], Train Loss: 0.002362
Validation Loss: 0.00224024
Epoch [81/300], Train Loss: 0.002371
Validation Loss: 0.00227180
Epoch [82/300], Train Loss: 0.002370
Validation Loss: 0.00220586
Epoch [83/300], Train Loss: 0.002369
Validation Loss: 0.00221548
Epoch [84/300], Train Loss: 0.002349
Validation Loss: 0.00222053
Epoch [85/300], Train Loss: 0.002349
Validation Loss: 0.00221036
Epoch [86/300], Train Loss: 0.002342
Validation Loss: 0.00223996
Epoch [87/300], Train Loss: 0.002353
Validation Loss: 0.00220880
Epoch [88/300], Train Loss: 0.002357
Validation Loss: 0.00220536
Epoch [89/300], Train Loss: 0.002324
Validation Loss: 0.00219890
Epoch [90/300], Train Loss: 0.002323
Validation Loss: 0.00220206
Epoch [91/300], Train Loss: 0.002348
Validation Loss: 0.00220173
Epoch [92/300], Train Loss: 0.002327
Validation Loss: 0.00220667
Epoch [93/300], Train Loss: 0.002343
Validation Loss: 0.00218901
Epoch [94/300], Train Loss: 0.002313
Validation Loss: 0.00219148
Epoch [95/300], Train Loss: 0.002321
Validation Loss: 0.00218481
Epoch [96/300], Train Loss: 0.002309
Validation Loss: 0.00218774
Epoch [97/300], Train Loss: 0.002301
Validation Loss: 0.00218192
Epoch [98/300], Train Loss: 0.002341
Validation Loss: 0.00219362
Epoch [99/300], Train Loss: 0.002303
Validation Loss: 0.00219771
Epoch [100/300], Train Loss: 0.002315
Validation Loss: 0.00218399
Epoch [101/300], Train Loss: 0.002326
Validation Loss: 0.00218136
Epoch [102/300], Train Loss: 0.002307
Validation Loss: 0.00218476
Epoch [103/300], Train Loss: 0.002292
Validation Loss: 0.00223686
Epoch [104/300], Train Loss: 0.002296
Validation Loss: 0.00217276
Epoch [105/300], Train Loss: 0.002318
Validation Loss: 0.00221229
Epoch [106/300], Train Loss: 0.002302
Validation Loss: 0.00220027
Epoch [107/300], Train Loss: 0.002293
Validation Loss: 0.00217857
Epoch [108/300], Train Loss: 0.002278
Validation Loss: 0.00218228
Epoch [109/300], Train Loss: 0.002282
Validation Loss: 0.00219413
Epoch [110/300], Train Loss: 0.002289
Validation Loss: 0.00218496
Epoch [111/300], Train Loss: 0.002307
Validation Loss: 0.00241395
Epoch [112/300], Train Loss: 0.002285
Validation Loss: 0.00217067
Epoch [113/300], Train Loss: 0.002278
Validation Loss: 0.00218074
Epoch [114/300], Train Loss: 0.002314
Validation Loss: 0.00221703
Epoch [115/300], Train Loss: 0.002307
Validation Loss: 0.00217994
Epoch [116/300], Train Loss: 0.002265
Validation Loss: 0.00218921
Epoch [117/300], Train Loss: 0.002262
Validation Loss: 0.00216764
Epoch [118/300], Train Loss: 0.002266
Validation Loss: 0.00217620
Epoch [119/300], Train Loss: 0.002260
Validation Loss: 0.00217080
Epoch [120/300], Train Loss: 0.002278
Validation Loss: 0.00216089
Epoch [121/300], Train Loss: 0.002276
Validation Loss: 0.00218097
Epoch [122/300], Train Loss: 0.002275
Validation Loss: 0.00216964
Epoch [123/300], Train Loss: 0.002252
Validation Loss: 0.00222986
Epoch [124/300], Train Loss: 0.002263
Validation Loss: 0.00216991
Epoch [125/300], Train Loss: 0.002253
Validation Loss: 0.00215955
Epoch [126/300], Train Loss: 0.002265
Validation Loss: 0.00216590
Epoch [127/300], Train Loss: 0.002290
Validation Loss: 0.00216747
Epoch [128/300], Train Loss: 0.002247
Validation Loss: 0.00216924
Epoch [129/300], Train Loss: 0.002248
Validation Loss: 0.00216577
Epoch [130/300], Train Loss: 0.002241
Validation Loss: 0.00231773
Epoch [131/300], Train Loss: 0.002258
Validation Loss: 0.00215772
Epoch [132/300], Train Loss: 0.002241
Validation Loss: 0.00216607
Epoch [133/300], Train Loss: 0.002256
Validation Loss: 0.00216981
Epoch [134/300], Train Loss: 0.002246
Validation Loss: 0.00218651
Epoch [135/300], Train Loss: 0.002276
Validation Loss: 0.00215643
Epoch [136/300], Train Loss: 0.002244
Validation Loss: 0.00217239
Epoch [137/300], Train Loss: 0.002248
Validation Loss: 0.00216083
Epoch [138/300], Train Loss: 0.002237
Validation Loss: 0.00259800
Epoch [139/300], Train Loss: 0.002259
Validation Loss: 0.00215377
Epoch [140/300], Train Loss: 0.002237
Validation Loss: 0.00216182
Epoch [141/300], Train Loss: 0.002231
Validation Loss: 0.00216556
Epoch [142/300], Train Loss: 0.002231
Validation Loss: 0.00215341
Epoch [143/300], Train Loss: 0.002280
Validation Loss: 0.00215496
Epoch [144/300], Train Loss: 0.002232
Validation Loss: 0.00215569
Epoch [145/300], Train Loss: 0.002227
Validation Loss: 0.00218825
Epoch [146/300], Train Loss: 0.002221
Validation Loss: 0.00215304
Epoch [147/300], Train Loss: 0.002226
Validation Loss: 0.00215214
Epoch [148/300], Train Loss: 0.002394
Validation Loss: 0.00216670
Epoch [149/300], Train Loss: 0.002229
Validation Loss: 0.00215043
Epoch [150/300], Train Loss: 0.002224
Validation Loss: 0.00215968
Epoch [151/300], Train Loss: 0.002224
Validation Loss: 0.00214818
Epoch [152/300], Train Loss: 0.002224
Validation Loss: 0.00214590
Epoch [153/300], Train Loss: 0.002224
Validation Loss: 0.00214655
Epoch [154/300], Train Loss: 0.002220
Validation Loss: 0.00214046
Epoch [155/300], Train Loss: 0.002219
Validation Loss: 0.00214454
Epoch [156/300], Train Loss: 0.002216
Validation Loss: 0.00217012
Epoch [157/300], Train Loss: 0.002308
Validation Loss: 0.00217641
Epoch [158/300], Train Loss: 0.002223
Validation Loss: 0.00215636
Epoch [159/300], Train Loss: 0.002221
Validation Loss: 0.00216191
Epoch [160/300], Train Loss: 0.002214
Validation Loss: 0.00214196
Epoch [161/300], Train Loss: 0.002214
Validation Loss: 0.00213798
Epoch [162/300], Train Loss: 0.002224
Validation Loss: 0.00215383
Epoch [163/300], Train Loss: 0.002215
Validation Loss: 0.00214552
Epoch [164/300], Train Loss: 0.002213
Validation Loss: 0.00215218
Epoch [165/300], Train Loss: 0.002209
Validation Loss: 0.00214536
Epoch [166/300], Train Loss: 0.002210
Validation Loss: 0.00214073
Epoch [167/300], Train Loss: 0.002210
Validation Loss: 0.00215878
Epoch [168/300], Train Loss: 0.002213
Validation Loss: 0.00215206
Epoch [169/300], Train Loss: 0.002209
Validation Loss: 0.00226494
Epoch [170/300], Train Loss: 0.002221
Validation Loss: 0.00213927
Epoch [171/300], Train Loss: 0.002202
Validation Loss: 0.00215286
Early stopping triggered

Evaluating model for: Tablet
Run 2/72 completed in 4116.83 seconds with: {'MAE': np.float32(0.39080444), 'MSE': np.float32(0.34475443), 'RMSE': np.float32(0.5871579), 'SAE': np.float32(0.003449672), 'NDE': np.float32(0.13475855)}

Run 3/72: hidden=128, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Tablet
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.036353
Validation Loss: 0.01859797
Epoch [2/300], Train Loss: 0.016525
Validation Loss: 0.01269516
Epoch [3/300], Train Loss: 0.011687
Validation Loss: 0.01086459
Epoch [4/300], Train Loss: 0.010495
Validation Loss: 0.01006161
Epoch [5/300], Train Loss: 0.009647
Validation Loss: 0.00928813
Epoch [6/300], Train Loss: 0.009164
Validation Loss: 0.00902122
Epoch [7/300], Train Loss: 0.008743
Validation Loss: 0.00853840
Epoch [8/300], Train Loss: 0.008464
Validation Loss: 0.00832439
Epoch [9/300], Train Loss: 0.008125
Validation Loss: 0.00797840
Epoch [10/300], Train Loss: 0.007854
Validation Loss: 0.00777630
Epoch [11/300], Train Loss: 0.007619
Validation Loss: 0.00749004
Epoch [12/300], Train Loss: 0.007472
Validation Loss: 0.00736998
Epoch [13/300], Train Loss: 0.007393
Validation Loss: 0.00729310
Epoch [14/300], Train Loss: 0.007322
Validation Loss: 0.00718633
Epoch [15/300], Train Loss: 0.007206
Validation Loss: 0.00711290
Epoch [16/300], Train Loss: 0.007165
Validation Loss: 0.00716951
Epoch [17/300], Train Loss: 0.007097
Validation Loss: 0.00701855
Epoch [18/300], Train Loss: 0.007036
Validation Loss: 0.00714228
Epoch [19/300], Train Loss: 0.007029
Validation Loss: 0.00697076
Epoch [20/300], Train Loss: 0.006950
Validation Loss: 0.00688036
Epoch [21/300], Train Loss: 0.006943
Validation Loss: 0.00679153
Epoch [22/300], Train Loss: 0.006872
Validation Loss: 0.00677429
Epoch [23/300], Train Loss: 0.006814
Validation Loss: 0.00666382
Epoch [24/300], Train Loss: 0.006689
Validation Loss: 0.00689946
Epoch [25/300], Train Loss: 0.006696
Validation Loss: 0.00649177
Epoch [26/300], Train Loss: 0.006750
Validation Loss: 0.00662870
Epoch [27/300], Train Loss: 0.006504
Validation Loss: 0.00634162
Epoch [28/300], Train Loss: 0.006396
Validation Loss: 0.00621613
Epoch [29/300], Train Loss: 0.006250
Validation Loss: 0.00596189
Epoch [30/300], Train Loss: 0.005946
Validation Loss: 0.00533862
Epoch [31/300], Train Loss: 0.005528
Validation Loss: 0.00486201
Epoch [32/300], Train Loss: 0.004910
Validation Loss: 0.00432015
Epoch [33/300], Train Loss: 0.004424
Validation Loss: 0.00351218
Epoch [34/300], Train Loss: 0.004304
Validation Loss: 0.00336957
Epoch [35/300], Train Loss: 0.003682
Validation Loss: 0.00299316
Epoch [36/300], Train Loss: 0.003397
Validation Loss: 0.00281273
Epoch [37/300], Train Loss: 0.003246
Validation Loss: 0.00278487
Epoch [38/300], Train Loss: 0.003149
Validation Loss: 0.00284575
Epoch [39/300], Train Loss: 0.002982
Validation Loss: 0.00249407
Epoch [40/300], Train Loss: 0.002843
Validation Loss: 0.00252104
Epoch [41/300], Train Loss: 0.002800
Validation Loss: 0.00236757
Epoch [42/300], Train Loss: 0.002747
Validation Loss: 0.00233372
Epoch [43/300], Train Loss: 0.002650
Validation Loss: 0.00230128
Epoch [44/300], Train Loss: 0.002606
Validation Loss: 0.00227427
Epoch [45/300], Train Loss: 0.002581
Validation Loss: 0.00233281
Epoch [46/300], Train Loss: 0.002545
Validation Loss: 0.00222377
Epoch [47/300], Train Loss: 0.002473
Validation Loss: 0.00227511
Epoch [48/300], Train Loss: 0.002465
Validation Loss: 0.00218872
Epoch [49/300], Train Loss: 0.002444
Validation Loss: 0.00219806
Epoch [50/300], Train Loss: 0.002412
Validation Loss: 0.00239922
Epoch [51/300], Train Loss: 0.002558
Validation Loss: 0.00466927
Epoch [52/300], Train Loss: 0.002510
Validation Loss: 0.00217559
Epoch [53/300], Train Loss: 0.002383
Validation Loss: 0.00228937
Epoch [54/300], Train Loss: 0.002371
Validation Loss: 0.00216520
Epoch [55/300], Train Loss: 0.002364
Validation Loss: 0.00216418
Epoch [56/300], Train Loss: 0.002482
Validation Loss: 0.00229137
Epoch [57/300], Train Loss: 0.002371
Validation Loss: 0.00215451
Epoch [58/300], Train Loss: 0.002347
Validation Loss: 0.00216241
Epoch [59/300], Train Loss: 0.002326
Validation Loss: 0.00215429
Epoch [60/300], Train Loss: 0.005632
Validation Loss: 0.00417125
Epoch [61/300], Train Loss: 0.002929
Validation Loss: 0.00224865
Epoch [62/300], Train Loss: 0.002498
Validation Loss: 0.00218546
Epoch [63/300], Train Loss: 0.002411
Validation Loss: 0.00222989
Epoch [64/300], Train Loss: 0.002492
Validation Loss: 0.00217047
Epoch [65/300], Train Loss: 0.002367
Validation Loss: 0.00215116
Epoch [66/300], Train Loss: 0.002329
Validation Loss: 0.00215674
Epoch [67/300], Train Loss: 0.002334
Validation Loss: 0.00219454
Epoch [68/300], Train Loss: 0.002295
Validation Loss: 0.00214608
Epoch [69/300], Train Loss: 0.002284
Validation Loss: 0.00219851
Epoch [70/300], Train Loss: 0.002282
Validation Loss: 0.00213588
Epoch [71/300], Train Loss: 0.002271
Validation Loss: 0.00215923
Epoch [72/300], Train Loss: 0.002271
Validation Loss: 0.00240846
Epoch [73/300], Train Loss: 0.002407
Validation Loss: 0.00219017
Epoch [74/300], Train Loss: 0.002292
Validation Loss: 0.00214962
Epoch [75/300], Train Loss: 0.002266
Validation Loss: 0.00214169
Epoch [76/300], Train Loss: 0.002259
Validation Loss: 0.00212978
Epoch [77/300], Train Loss: 0.002274
Validation Loss: 0.00212940
Epoch [78/300], Train Loss: 0.002246
Validation Loss: 0.00214549
Epoch [79/300], Train Loss: 0.002237
Validation Loss: 0.00211692
Epoch [80/300], Train Loss: 0.002233
Validation Loss: 0.00212208
Epoch [81/300], Train Loss: 0.002254
Validation Loss: 0.00213812
Epoch [82/300], Train Loss: 0.002255
Validation Loss: 0.00214312
Epoch [83/300], Train Loss: 0.002239
Validation Loss: 0.00213419
Epoch [84/300], Train Loss: 0.002233
Validation Loss: 0.00211969
Epoch [85/300], Train Loss: 0.002259
Validation Loss: 0.00210507
Epoch [86/300], Train Loss: 0.002222
Validation Loss: 0.00213139
Epoch [87/300], Train Loss: 0.002241
Validation Loss: 0.00214369
Epoch [88/300], Train Loss: 0.002224
Validation Loss: 0.00211000
Epoch [89/300], Train Loss: 0.002265
Validation Loss: 0.00236246
Epoch [90/300], Train Loss: 0.002303
Validation Loss: 0.00211595
Epoch [91/300], Train Loss: 0.002201
Validation Loss: 0.00216998
Epoch [92/300], Train Loss: 0.002207
Validation Loss: 0.00213456
Epoch [93/300], Train Loss: 0.002193
Validation Loss: 0.00210280
Epoch [94/300], Train Loss: 0.002194
Validation Loss: 0.00211341
Epoch [95/300], Train Loss: 0.002227
Validation Loss: 0.00211897
Epoch [96/300], Train Loss: 0.002230
Validation Loss: 0.00212344
Epoch [97/300], Train Loss: 0.002184
Validation Loss: 0.00209110
Epoch [98/300], Train Loss: 0.002198
Validation Loss: 0.00210163
Epoch [99/300], Train Loss: 0.002196
Validation Loss: 0.00211124
Epoch [100/300], Train Loss: 0.002197
Validation Loss: 0.00210450
Epoch [101/300], Train Loss: 0.002236
Validation Loss: 0.00213102
Epoch [102/300], Train Loss: 0.002382
Validation Loss: 0.00211149
Epoch [103/300], Train Loss: 0.002187
Validation Loss: 0.00214882
Epoch [104/300], Train Loss: 0.002195
Validation Loss: 0.00210080
Epoch [105/300], Train Loss: 0.002187
Validation Loss: 0.00213455
Epoch [106/300], Train Loss: 0.002173
Validation Loss: 0.00211879
Epoch [107/300], Train Loss: 0.002172
Validation Loss: 0.00210805
Early stopping triggered

Evaluating model for: Tablet
Run 3/72 completed in 2630.67 seconds with: {'MAE': np.float32(0.39222834), 'MSE': np.float32(0.35014546), 'RMSE': np.float32(0.5917309), 'SAE': np.float32(0.0047711013), 'NDE': np.float32(0.13580811)}

Run 4/72: hidden=128, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Tablet
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.043681
Validation Loss: 0.01904806
Epoch [2/300], Train Loss: 0.016612
Validation Loss: 0.01256722
Epoch [3/300], Train Loss: 0.012051
Validation Loss: 0.01115105
Epoch [4/300], Train Loss: 0.011004
Validation Loss: 0.01045866
Epoch [5/300], Train Loss: 0.010282
Validation Loss: 0.00990120
Epoch [6/300], Train Loss: 0.009817
Validation Loss: 0.00952586
Epoch [7/300], Train Loss: 0.009432
Validation Loss: 0.00918728
Epoch [8/300], Train Loss: 0.009142
Validation Loss: 0.00899952
Epoch [9/300], Train Loss: 0.008846
Validation Loss: 0.00885080
Epoch [10/300], Train Loss: 0.008588
Validation Loss: 0.00842615
Epoch [11/300], Train Loss: 0.008302
Validation Loss: 0.00809008
Epoch [12/300], Train Loss: 0.008075
Validation Loss: 0.00795902
Epoch [13/300], Train Loss: 0.008028
Validation Loss: 0.00778962
Epoch [14/300], Train Loss: 0.007766
Validation Loss: 0.00758857
Epoch [15/300], Train Loss: 0.007634
Validation Loss: 0.00750816
Epoch [16/300], Train Loss: 0.007572
Validation Loss: 0.00766452
Epoch [17/300], Train Loss: 0.007482
Validation Loss: 0.00747320
Epoch [18/300], Train Loss: 0.007410
Validation Loss: 0.00736286
Epoch [19/300], Train Loss: 0.007326
Validation Loss: 0.00725683
Epoch [20/300], Train Loss: 0.007262
Validation Loss: 0.00718198
Epoch [21/300], Train Loss: 0.007220
Validation Loss: 0.00708397
Epoch [22/300], Train Loss: 0.007183
Validation Loss: 0.00749304
Epoch [23/300], Train Loss: 0.007134
Validation Loss: 0.00700545
Epoch [24/300], Train Loss: 0.007048
Validation Loss: 0.00698543
Epoch [25/300], Train Loss: 0.007036
Validation Loss: 0.00691831
Epoch [26/300], Train Loss: 0.007051
Validation Loss: 0.00686476
Epoch [27/300], Train Loss: 0.006919
Validation Loss: 0.00693295
Epoch [28/300], Train Loss: 0.006850
Validation Loss: 0.00685585
Epoch [29/300], Train Loss: 0.006776
Validation Loss: 0.00665530
Epoch [30/300], Train Loss: 0.006693
Validation Loss: 0.00646893
Epoch [31/300], Train Loss: 0.006518
Validation Loss: 0.00631442
Epoch [32/300], Train Loss: 0.006324
Validation Loss: 0.00601661
Epoch [33/300], Train Loss: 0.006087
Validation Loss: 0.00518822
Epoch [34/300], Train Loss: 0.005279
Validation Loss: 0.00393572
Epoch [35/300], Train Loss: 0.004280
Validation Loss: 0.00331886
Epoch [36/300], Train Loss: 0.003813
Validation Loss: 0.00303742
Epoch [37/300], Train Loss: 0.003421
Validation Loss: 0.00278102
Epoch [38/300], Train Loss: 0.003162
Validation Loss: 0.00266462
Epoch [39/300], Train Loss: 0.003020
Validation Loss: 0.00245996
Epoch [40/300], Train Loss: 0.002801
Validation Loss: 0.00238346
Epoch [41/300], Train Loss: 0.002709
Validation Loss: 0.00235458
Epoch [42/300], Train Loss: 0.002653
Validation Loss: 0.00240517
Epoch [43/300], Train Loss: 0.002783
Validation Loss: 0.00230744
Epoch [44/300], Train Loss: 0.002579
Validation Loss: 0.00270277
Epoch [45/300], Train Loss: 0.002571
Validation Loss: 0.00227470
Epoch [46/300], Train Loss: 0.002504
Validation Loss: 0.00225050
Epoch [47/300], Train Loss: 0.002559
Validation Loss: 0.00230522
Epoch [48/300], Train Loss: 0.002488
Validation Loss: 0.00232025
Epoch [49/300], Train Loss: 0.002452
Validation Loss: 0.00224884
Epoch [50/300], Train Loss: 0.002429
Validation Loss: 0.00226598
Epoch [51/300], Train Loss: 0.002442
Validation Loss: 0.00228344
Epoch [52/300], Train Loss: 0.002468
Validation Loss: 0.00219257
Epoch [53/300], Train Loss: 0.002443
Validation Loss: 0.00232169
Epoch [54/300], Train Loss: 0.002491
Validation Loss: 0.00229167
Epoch [55/300], Train Loss: 0.002424
Validation Loss: 0.00220291
Epoch [56/300], Train Loss: 0.002465
Validation Loss: 0.00221330
Epoch [57/300], Train Loss: 0.002372
Validation Loss: 0.00220966
Epoch [58/300], Train Loss: 0.002363
Validation Loss: 0.00216856
Epoch [59/300], Train Loss: 0.002900
Validation Loss: 0.00221547
Epoch [60/300], Train Loss: 0.002387
Validation Loss: 0.00218020
Epoch [61/300], Train Loss: 0.002336
Validation Loss: 0.00218101
Epoch [62/300], Train Loss: 0.002378
Validation Loss: 0.00219060
Epoch [63/300], Train Loss: 0.003641
Validation Loss: 0.00281879
Epoch [64/300], Train Loss: 0.002607
Validation Loss: 0.00228345
Epoch [65/300], Train Loss: 0.002441
Validation Loss: 0.00220676
Epoch [66/300], Train Loss: 0.002393
Validation Loss: 0.00220721
Epoch [67/300], Train Loss: 0.002354
Validation Loss: 0.00219284
Epoch [68/300], Train Loss: 0.002332
Validation Loss: 0.00217566
Early stopping triggered

Evaluating model for: Tablet
Run 4/72 completed in 1702.05 seconds with: {'MAE': np.float32(0.39541608), 'MSE': np.float32(0.34835654), 'RMSE': np.float32(0.59021735), 'SAE': np.float32(0.0036119474), 'NDE': np.float32(0.13546069)}

Run 5/72: hidden=128, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Tablet
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.058348
Validation Loss: 0.01847817
Epoch [2/300], Train Loss: 0.018292
Validation Loss: 0.01646155
Epoch [3/300], Train Loss: 0.016259
Validation Loss: 0.01393875
Epoch [4/300], Train Loss: 0.013334
Validation Loss: 0.01176876
Epoch [5/300], Train Loss: 0.012121
Validation Loss: 0.01083637
Epoch [6/300], Train Loss: 0.011315
Validation Loss: 0.01014222
Epoch [7/300], Train Loss: 0.010718
Validation Loss: 0.00949037
Epoch [8/300], Train Loss: 0.010318
Validation Loss: 0.00912186
Epoch [9/300], Train Loss: 0.010019
Validation Loss: 0.00884969
Epoch [10/300], Train Loss: 0.009757
Validation Loss: 0.00851826
Epoch [11/300], Train Loss: 0.009480
Validation Loss: 0.00833747
Epoch [12/300], Train Loss: 0.009311
Validation Loss: 0.00806867
Epoch [13/300], Train Loss: 0.009175
Validation Loss: 0.00794300
Epoch [14/300], Train Loss: 0.008954
Validation Loss: 0.00785638
Epoch [15/300], Train Loss: 0.008867
Validation Loss: 0.00765073
Epoch [16/300], Train Loss: 0.008664
Validation Loss: 0.00754937
Epoch [17/300], Train Loss: 0.008488
Validation Loss: 0.00740047
Epoch [18/300], Train Loss: 0.008368
Validation Loss: 0.00721216
Epoch [19/300], Train Loss: 0.008176
Validation Loss: 0.00706331
Epoch [20/300], Train Loss: 0.008080
Validation Loss: 0.00697548
Epoch [21/300], Train Loss: 0.007927
Validation Loss: 0.00687503
Epoch [22/300], Train Loss: 0.007920
Validation Loss: 0.00696408
Epoch [23/300], Train Loss: 0.007820
Validation Loss: 0.00680587
Epoch [24/300], Train Loss: 0.007752
Validation Loss: 0.00702124
Epoch [25/300], Train Loss: 0.007721
Validation Loss: 0.00669643
Epoch [26/300], Train Loss: 0.007704
Validation Loss: 0.00680539
Epoch [27/300], Train Loss: 0.007623
Validation Loss: 0.00664573
Epoch [28/300], Train Loss: 0.007626
Validation Loss: 0.00667641
Epoch [29/300], Train Loss: 0.007576
Validation Loss: 0.00658687
Epoch [30/300], Train Loss: 0.007525
Validation Loss: 0.00657440
Epoch [31/300], Train Loss: 0.007515
Validation Loss: 0.00654201
Epoch [32/300], Train Loss: 0.007496
Validation Loss: 0.00672802
Epoch [33/300], Train Loss: 0.007480
Validation Loss: 0.00656919
Epoch [34/300], Train Loss: 0.007430
Validation Loss: 0.00657764
Epoch [35/300], Train Loss: 0.007410
Validation Loss: 0.00647161
Epoch [36/300], Train Loss: 0.007381
Validation Loss: 0.00646660
Epoch [37/300], Train Loss: 0.007330
Validation Loss: 0.00643768
Epoch [38/300], Train Loss: 0.007311
Validation Loss: 0.00643464
Epoch [39/300], Train Loss: 0.007297
Validation Loss: 0.00638988
Epoch [40/300], Train Loss: 0.007259
Validation Loss: 0.00635330
Epoch [41/300], Train Loss: 0.007225
Validation Loss: 0.00633099
Epoch [42/300], Train Loss: 0.007215
Validation Loss: 0.00632233
Epoch [43/300], Train Loss: 0.007195
Validation Loss: 0.00631905
Epoch [44/300], Train Loss: 0.007208
Validation Loss: 0.00629853
Epoch [45/300], Train Loss: 0.007187
Validation Loss: 0.00631243
Epoch [46/300], Train Loss: 0.007180
Validation Loss: 0.00632056
Epoch [47/300], Train Loss: 0.007127
Validation Loss: 0.00632360
Epoch [48/300], Train Loss: 0.007143
Validation Loss: 0.00656369
Epoch [49/300], Train Loss: 0.007095
Validation Loss: 0.00626332
Epoch [50/300], Train Loss: 0.007087
Validation Loss: 0.00637158
Epoch [51/300], Train Loss: 0.007100
Validation Loss: 0.00638842
Epoch [52/300], Train Loss: 0.007086
Validation Loss: 0.00619432
Epoch [53/300], Train Loss: 0.007040
Validation Loss: 0.00626675
Epoch [54/300], Train Loss: 0.007004
Validation Loss: 0.00616849
Epoch [55/300], Train Loss: 0.007016
Validation Loss: 0.00614663
Epoch [56/300], Train Loss: 0.006962
Validation Loss: 0.00629479
Epoch [57/300], Train Loss: 0.006998
Validation Loss: 0.00614650
Epoch [58/300], Train Loss: 0.006949
Validation Loss: 0.00610900
Epoch [59/300], Train Loss: 0.006948
Validation Loss: 0.00610765
Epoch [60/300], Train Loss: 0.006914
Validation Loss: 0.00610171
Epoch [61/300], Train Loss: 0.006895
Validation Loss: 0.00616914
Epoch [62/300], Train Loss: 0.006893
Validation Loss: 0.00608924
Epoch [63/300], Train Loss: 0.006878
Validation Loss: 0.00607867
Epoch [64/300], Train Loss: 0.006903
Validation Loss: 0.00603439
Epoch [65/300], Train Loss: 0.006849
Validation Loss: 0.00603417
Epoch [66/300], Train Loss: 0.006832
Validation Loss: 0.00601983
Epoch [67/300], Train Loss: 0.006844
Validation Loss: 0.00609967
Epoch [68/300], Train Loss: 0.006810
Validation Loss: 0.00603776
Epoch [69/300], Train Loss: 0.006820
Validation Loss: 0.00596652
Epoch [70/300], Train Loss: 0.006806
Validation Loss: 0.00604595
Epoch [71/300], Train Loss: 0.006801
Validation Loss: 0.00596065
Epoch [72/300], Train Loss: 0.006824
Validation Loss: 0.00595768
Epoch [73/300], Train Loss: 0.006726
Validation Loss: 0.00591042
Epoch [74/300], Train Loss: 0.006719
Validation Loss: 0.00599538
Epoch [75/300], Train Loss: 0.006720
Validation Loss: 0.00588179
Epoch [76/300], Train Loss: 0.006722
Validation Loss: 0.00586895
Epoch [77/300], Train Loss: 0.006726
Validation Loss: 0.00592954
Epoch [78/300], Train Loss: 0.006671
Validation Loss: 0.00602255
Epoch [79/300], Train Loss: 0.006652
Validation Loss: 0.00590866
Epoch [80/300], Train Loss: 0.006682
Validation Loss: 0.00583450
Epoch [81/300], Train Loss: 0.006650
Validation Loss: 0.00592725
Epoch [82/300], Train Loss: 0.006636
Validation Loss: 0.00590492
Epoch [83/300], Train Loss: 0.006649
Validation Loss: 0.00583617
Epoch [84/300], Train Loss: 0.006615
Validation Loss: 0.00580009
Epoch [85/300], Train Loss: 0.006596
Validation Loss: 0.00590578
Epoch [86/300], Train Loss: 0.006570
Validation Loss: 0.00576460
Epoch [87/300], Train Loss: 0.006547
Validation Loss: 0.00591516
Epoch [88/300], Train Loss: 0.006525
Validation Loss: 0.00575354
Epoch [89/300], Train Loss: 0.006516
Validation Loss: 0.00583877
Epoch [90/300], Train Loss: 0.006581
Validation Loss: 0.00580202
Epoch [91/300], Train Loss: 0.006505
Validation Loss: 0.00572698
Epoch [92/300], Train Loss: 0.006488
Validation Loss: 0.00571678
Epoch [93/300], Train Loss: 0.006467
Validation Loss: 0.00586473
Epoch [94/300], Train Loss: 0.006461
Validation Loss: 0.00566898
Epoch [95/300], Train Loss: 0.006442
Validation Loss: 0.00576738
Epoch [96/300], Train Loss: 0.006439
Validation Loss: 0.00568840
Epoch [97/300], Train Loss: 0.006429
Validation Loss: 0.00564289
Epoch [98/300], Train Loss: 0.006427
Validation Loss: 0.00564146
Epoch [99/300], Train Loss: 0.006417
Validation Loss: 0.00563761
Epoch [100/300], Train Loss: 0.006382
Validation Loss: 0.00563936
Epoch [101/300], Train Loss: 0.006352
Validation Loss: 0.00565524
Epoch [102/300], Train Loss: 0.006386
Validation Loss: 0.00558788
Epoch [103/300], Train Loss: 0.006323
Validation Loss: 0.00586398
Epoch [104/300], Train Loss: 0.006361
Validation Loss: 0.00554472
Epoch [105/300], Train Loss: 0.006296
Validation Loss: 0.00552572
Epoch [106/300], Train Loss: 0.006252
Validation Loss: 0.00552217
Epoch [107/300], Train Loss: 0.006223
Validation Loss: 0.00565364
Epoch [108/300], Train Loss: 0.006203
Validation Loss: 0.00548093
Epoch [109/300], Train Loss: 0.006190
Validation Loss: 0.00551875
Epoch [110/300], Train Loss: 0.006162
Validation Loss: 0.00540045
Epoch [111/300], Train Loss: 0.006100
Validation Loss: 0.00538868
Epoch [112/300], Train Loss: 0.006114
Validation Loss: 0.00545127
Epoch [113/300], Train Loss: 0.006030
Validation Loss: 0.00529992
Epoch [114/300], Train Loss: 0.005969
Validation Loss: 0.00523185
Epoch [115/300], Train Loss: 0.005898
Validation Loss: 0.00518684
Epoch [116/300], Train Loss: 0.005854
Validation Loss: 0.00520771
Epoch [117/300], Train Loss: 0.005749
Validation Loss: 0.00507129
Epoch [118/300], Train Loss: 0.005629
Validation Loss: 0.00500478
Epoch [119/300], Train Loss: 0.005487
Validation Loss: 0.00473845
Epoch [120/300], Train Loss: 0.005350
Validation Loss: 0.00471820
Epoch [121/300], Train Loss: 0.005170
Validation Loss: 0.00449520
Epoch [122/300], Train Loss: 0.005017
Validation Loss: 0.00429725
Epoch [123/300], Train Loss: 0.004868
Validation Loss: 0.00415489
Epoch [124/300], Train Loss: 0.004675
Validation Loss: 0.00409883
Epoch [125/300], Train Loss: 0.004541
Validation Loss: 0.00385871
Epoch [126/300], Train Loss: 0.004409
Validation Loss: 0.00380818
Epoch [127/300], Train Loss: 0.004290
Validation Loss: 0.00359447
Epoch [128/300], Train Loss: 0.004207
Validation Loss: 0.00355154
Epoch [129/300], Train Loss: 0.004096
Validation Loss: 0.00343458
Epoch [130/300], Train Loss: 0.004059
Validation Loss: 0.00338287
Epoch [131/300], Train Loss: 0.003957
Validation Loss: 0.00328365
Epoch [132/300], Train Loss: 0.003881
Validation Loss: 0.00328289
Epoch [133/300], Train Loss: 0.003839
Validation Loss: 0.00322661
Epoch [134/300], Train Loss: 0.003747
Validation Loss: 0.00315831
Epoch [135/300], Train Loss: 0.003694
Validation Loss: 0.00307835
Epoch [136/300], Train Loss: 0.003644
Validation Loss: 0.00305841
Epoch [137/300], Train Loss: 0.003618
Validation Loss: 0.00305697
Epoch [138/300], Train Loss: 0.003555
Validation Loss: 0.00300830
Epoch [139/300], Train Loss: 0.003556
Validation Loss: 0.00298828
Epoch [140/300], Train Loss: 0.003499
Validation Loss: 0.00316395
Epoch [141/300], Train Loss: 0.003459
Validation Loss: 0.00292141
Epoch [142/300], Train Loss: 0.003451
Validation Loss: 0.00288260
Epoch [143/300], Train Loss: 0.003404
Validation Loss: 0.00285358
Epoch [144/300], Train Loss: 0.003380
Validation Loss: 0.00285333
Epoch [145/300], Train Loss: 0.003350
Validation Loss: 0.00282813
Epoch [146/300], Train Loss: 0.003308
Validation Loss: 0.00282048
Epoch [147/300], Train Loss: 0.003337
Validation Loss: 0.00294403
Epoch [148/300], Train Loss: 0.003291
Validation Loss: 0.00280659
Epoch [149/300], Train Loss: 0.003261
Validation Loss: 0.00277994
Epoch [150/300], Train Loss: 0.003240
Validation Loss: 0.00278259
Epoch [151/300], Train Loss: 0.003222
Validation Loss: 0.00273328
Epoch [152/300], Train Loss: 0.003209
Validation Loss: 0.00273770
Epoch [153/300], Train Loss: 0.003213
Validation Loss: 0.00275225
Epoch [154/300], Train Loss: 0.003175
Validation Loss: 0.00274415
Epoch [155/300], Train Loss: 0.003159
Validation Loss: 0.00270574
Epoch [156/300], Train Loss: 0.003207
Validation Loss: 0.00272492
Epoch [157/300], Train Loss: 0.003141
Validation Loss: 0.00270012
Epoch [158/300], Train Loss: 0.003137
Validation Loss: 0.00268830
Epoch [159/300], Train Loss: 0.003119
Validation Loss: 0.00276615
Epoch [160/300], Train Loss: 0.003131
Validation Loss: 0.00264394
Epoch [161/300], Train Loss: 0.003091
Validation Loss: 0.00279465
Epoch [162/300], Train Loss: 0.003080
Validation Loss: 0.00263643
Epoch [163/300], Train Loss: 0.003063
Validation Loss: 0.00269347
Epoch [164/300], Train Loss: 0.003049
Validation Loss: 0.00264249
Epoch [165/300], Train Loss: 0.003044
Validation Loss: 0.00261624
Epoch [166/300], Train Loss: 0.003034
Validation Loss: 0.00260213
Epoch [167/300], Train Loss: 0.003013
Validation Loss: 0.00261926
Epoch [168/300], Train Loss: 0.003009
Validation Loss: 0.00260593
Epoch [169/300], Train Loss: 0.002993
Validation Loss: 0.00257987
Epoch [170/300], Train Loss: 0.002981
Validation Loss: 0.00263695
Epoch [171/300], Train Loss: 0.002996
Validation Loss: 0.00255395
Epoch [172/300], Train Loss: 0.002961
Validation Loss: 0.00258193
Epoch [173/300], Train Loss: 0.002972
Validation Loss: 0.00262935
Epoch [174/300], Train Loss: 0.002954
Validation Loss: 0.00258059
Epoch [175/300], Train Loss: 0.002935
Validation Loss: 0.00253726
Epoch [176/300], Train Loss: 0.002960
Validation Loss: 0.00275145
Epoch [177/300], Train Loss: 0.002951
Validation Loss: 0.00254836
Epoch [178/300], Train Loss: 0.002915
Validation Loss: 0.00252328
Epoch [179/300], Train Loss: 0.002965
Validation Loss: 0.00256741
Epoch [180/300], Train Loss: 0.002968
Validation Loss: 0.00250882
Epoch [181/300], Train Loss: 0.002877
Validation Loss: 0.00254907
Epoch [182/300], Train Loss: 0.002879
Validation Loss: 0.00253225
Epoch [183/300], Train Loss: 0.002882
Validation Loss: 0.00250014
Epoch [184/300], Train Loss: 0.002872
Validation Loss: 0.00251957
Epoch [185/300], Train Loss: 0.002858
Validation Loss: 0.00248869
Epoch [186/300], Train Loss: 0.002864
Validation Loss: 0.00250289
Epoch [187/300], Train Loss: 0.002844
Validation Loss: 0.00247734
Epoch [188/300], Train Loss: 0.002852
Validation Loss: 0.00246637
Epoch [189/300], Train Loss: 0.002838
Validation Loss: 0.00247275
Epoch [190/300], Train Loss: 0.002824
Validation Loss: 0.00248197
Epoch [191/300], Train Loss: 0.002816
Validation Loss: 0.00244897
Epoch [192/300], Train Loss: 0.002800
Validation Loss: 0.00243962
Epoch [193/300], Train Loss: 0.002838
Validation Loss: 0.00251434
Epoch [194/300], Train Loss: 0.002784
Validation Loss: 0.00247673
Epoch [195/300], Train Loss: 0.002788
Validation Loss: 0.00244560
Epoch [196/300], Train Loss: 0.002766
Validation Loss: 0.00243354
Epoch [197/300], Train Loss: 0.002759
Validation Loss: 0.00244919
Epoch [198/300], Train Loss: 0.002770
Validation Loss: 0.00244239
Epoch [199/300], Train Loss: 0.002749
Validation Loss: 0.00239768
Epoch [200/300], Train Loss: 0.002736
Validation Loss: 0.00242428
Epoch [201/300], Train Loss: 0.002767
Validation Loss: 0.00245269
Epoch [202/300], Train Loss: 0.002732
Validation Loss: 0.00238291
Epoch [203/300], Train Loss: 0.002739
Validation Loss: 0.00239441
Epoch [204/300], Train Loss: 0.002730
Validation Loss: 0.00238369
Epoch [205/300], Train Loss: 0.002718
Validation Loss: 0.00238274
Epoch [206/300], Train Loss: 0.002698
Validation Loss: 0.00236040
Epoch [207/300], Train Loss: 0.002694
Validation Loss: 0.00236102
Epoch [208/300], Train Loss: 0.002696
Validation Loss: 0.00235389
Epoch [209/300], Train Loss: 0.002710
Validation Loss: 0.00236798
Epoch [210/300], Train Loss: 0.002691
Validation Loss: 0.00233067
Epoch [211/300], Train Loss: 0.002685
Validation Loss: 0.00238335
Epoch [212/300], Train Loss: 0.002680
Validation Loss: 0.00232678
Epoch [213/300], Train Loss: 0.002655
Validation Loss: 0.00234731
Epoch [214/300], Train Loss: 0.002678
Validation Loss: 0.00233698
Epoch [215/300], Train Loss: 0.002651
Validation Loss: 0.00231848
Epoch [216/300], Train Loss: 0.002649
Validation Loss: 0.00234089
Epoch [217/300], Train Loss: 0.002657
Validation Loss: 0.00233794
Epoch [218/300], Train Loss: 0.002638
Validation Loss: 0.00231329
Epoch [219/300], Train Loss: 0.002652
Validation Loss: 0.00230683
Epoch [220/300], Train Loss: 0.002632
Validation Loss: 0.00230120
Epoch [221/300], Train Loss: 0.002633
Validation Loss: 0.00230846
Epoch [222/300], Train Loss: 0.002631
Validation Loss: 0.00230221
Epoch [223/300], Train Loss: 0.002616
Validation Loss: 0.00229411
Epoch [224/300], Train Loss: 0.002620
Validation Loss: 0.00231239
Epoch [225/300], Train Loss: 0.002616
Validation Loss: 0.00232552
Epoch [226/300], Train Loss: 0.002608
Validation Loss: 0.00229972
Epoch [227/300], Train Loss: 0.002599
Validation Loss: 0.00228038
Epoch [228/300], Train Loss: 0.002635
Validation Loss: 0.00234197
Epoch [229/300], Train Loss: 0.002595
Validation Loss: 0.00229024
Epoch [230/300], Train Loss: 0.002606
Validation Loss: 0.00228497
Epoch [231/300], Train Loss: 0.002706
Validation Loss: 0.00234022
Epoch [232/300], Train Loss: 0.002607
Validation Loss: 0.00228499
Epoch [233/300], Train Loss: 0.002597
Validation Loss: 0.00226685
Epoch [234/300], Train Loss: 0.002589
Validation Loss: 0.00226665
Epoch [235/300], Train Loss: 0.002587
Validation Loss: 0.00227226
Epoch [236/300], Train Loss: 0.002581
Validation Loss: 0.00240965
Epoch [237/300], Train Loss: 0.002599
Validation Loss: 0.00231424
Epoch [238/300], Train Loss: 0.002583
Validation Loss: 0.00227924
Epoch [239/300], Train Loss: 0.002585
Validation Loss: 0.00237445
Epoch [240/300], Train Loss: 0.002583
Validation Loss: 0.00225299
Epoch [241/300], Train Loss: 0.002579
Validation Loss: 0.00226637
Epoch [242/300], Train Loss: 0.002569
Validation Loss: 0.00225262
Epoch [243/300], Train Loss: 0.002556
Validation Loss: 0.00225770
Epoch [244/300], Train Loss: 0.002570
Validation Loss: 0.00227283
Epoch [245/300], Train Loss: 0.002565
Validation Loss: 0.00225607
Epoch [246/300], Train Loss: 0.002550
Validation Loss: 0.00225352
Epoch [247/300], Train Loss: 0.002551
Validation Loss: 0.00225890
Epoch [248/300], Train Loss: 0.002551
Validation Loss: 0.00224972
Epoch [249/300], Train Loss: 0.002544
Validation Loss: 0.00229463
Epoch [250/300], Train Loss: 0.003184
Validation Loss: 0.00234699
Epoch [251/300], Train Loss: 0.002606
Validation Loss: 0.00228307
Epoch [252/300], Train Loss: 0.002564
Validation Loss: 0.00226313
Epoch [253/300], Train Loss: 0.002556
Validation Loss: 0.00225089
Epoch [254/300], Train Loss: 0.002553
Validation Loss: 0.00225594
Epoch [255/300], Train Loss: 0.002544
Validation Loss: 0.00225179
Epoch [256/300], Train Loss: 0.002540
Validation Loss: 0.00225011
Epoch [257/300], Train Loss: 0.002539
Validation Loss: 0.00224585
Epoch [258/300], Train Loss: 0.002538
Validation Loss: 0.00223658
Epoch [259/300], Train Loss: 0.002542
Validation Loss: 0.00224637
Epoch [260/300], Train Loss: 0.002532
Validation Loss: 0.00224176
Epoch [261/300], Train Loss: 0.002534
Validation Loss: 0.00223400
Epoch [262/300], Train Loss: 0.002528
Validation Loss: 0.00223673
Epoch [263/300], Train Loss: 0.002529
Validation Loss: 0.00224795
Epoch [264/300], Train Loss: 0.002538
Validation Loss: 0.00224744
Epoch [265/300], Train Loss: 0.002532
Validation Loss: 0.00222856
Epoch [266/300], Train Loss: 0.002530
Validation Loss: 0.00223467
Epoch [267/300], Train Loss: 0.002525
Validation Loss: 0.00223519
Epoch [268/300], Train Loss: 0.002520
Validation Loss: 0.00224172
Epoch [269/300], Train Loss: 0.002525
Validation Loss: 0.00223282
Epoch [270/300], Train Loss: 0.002520
Validation Loss: 0.00225146
Epoch [271/300], Train Loss: 0.002524
Validation Loss: 0.00223791
Epoch [272/300], Train Loss: 0.002515
Validation Loss: 0.00223323
Epoch [273/300], Train Loss: 0.002521
Validation Loss: 0.00227569
Epoch [274/300], Train Loss: 0.002520
Validation Loss: 0.00226487
Epoch [275/300], Train Loss: 0.002514
Validation Loss: 0.00228677
Early stopping triggered

Evaluating model for: Tablet
Run 5/72 completed in 3271.55 seconds with: {'MAE': np.float32(0.41892248), 'MSE': np.float32(0.4009885), 'RMSE': np.float32(0.6332365), 'SAE': np.float32(0.00651694), 'NDE': np.float32(0.14552166)}

Run 6/72: hidden=128, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Tablet
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.085118
Validation Loss: 0.02045315
Epoch [2/300], Train Loss: 0.020051
Validation Loss: 0.01817377
Epoch [3/300], Train Loss: 0.018483
Validation Loss: 0.01611428
Epoch [4/300], Train Loss: 0.015251
Validation Loss: 0.01305044
Epoch [5/300], Train Loss: 0.013641
Validation Loss: 0.01217082
Epoch [6/300], Train Loss: 0.012873
Validation Loss: 0.01149657
Epoch [7/300], Train Loss: 0.012260
Validation Loss: 0.01091198
Epoch [8/300], Train Loss: 0.011751
Validation Loss: 0.01032949
Epoch [9/300], Train Loss: 0.011291
Validation Loss: 0.00988806
Epoch [10/300], Train Loss: 0.010935
Validation Loss: 0.00953852
Epoch [11/300], Train Loss: 0.010593
Validation Loss: 0.00928154
Epoch [12/300], Train Loss: 0.010238
Validation Loss: 0.00887227
Epoch [13/300], Train Loss: 0.009918
Validation Loss: 0.00852815
Epoch [14/300], Train Loss: 0.009577
Validation Loss: 0.00827503
Epoch [15/300], Train Loss: 0.009346
Validation Loss: 0.00815778
Epoch [16/300], Train Loss: 0.009068
Validation Loss: 0.00784701
Epoch [17/300], Train Loss: 0.008847
Validation Loss: 0.00768130
Epoch [18/300], Train Loss: 0.008683
Validation Loss: 0.00746205
Epoch [19/300], Train Loss: 0.008479
Validation Loss: 0.00734540
Epoch [20/300], Train Loss: 0.008366
Validation Loss: 0.00732003
Epoch [21/300], Train Loss: 0.008211
Validation Loss: 0.00715180
Epoch [22/300], Train Loss: 0.008154
Validation Loss: 0.00723139
Epoch [23/300], Train Loss: 0.008081
Validation Loss: 0.00699177
Epoch [24/300], Train Loss: 0.007968
Validation Loss: 0.00708616
Epoch [25/300], Train Loss: 0.007947
Validation Loss: 0.00686012
Epoch [26/300], Train Loss: 0.007844
Validation Loss: 0.00688583
Epoch [27/300], Train Loss: 0.007760
Validation Loss: 0.00676712
Epoch [28/300], Train Loss: 0.007723
Validation Loss: 0.00669962
Epoch [29/300], Train Loss: 0.007680
Validation Loss: 0.00665081
Epoch [30/300], Train Loss: 0.007605
Validation Loss: 0.00662781
Epoch [31/300], Train Loss: 0.007583
Validation Loss: 0.00657150
Epoch [32/300], Train Loss: 0.007545
Validation Loss: 0.00660461
Epoch [33/300], Train Loss: 0.007497
Validation Loss: 0.00649341
Epoch [34/300], Train Loss: 0.007437
Validation Loss: 0.00649180
Epoch [35/300], Train Loss: 0.007402
Validation Loss: 0.00642479
Epoch [36/300], Train Loss: 0.007379
Validation Loss: 0.00638966
Epoch [37/300], Train Loss: 0.007312
Validation Loss: 0.00636765
Epoch [38/300], Train Loss: 0.007283
Validation Loss: 0.00633928
Epoch [39/300], Train Loss: 0.007238
Validation Loss: 0.00628046
Epoch [40/300], Train Loss: 0.007203
Validation Loss: 0.00625431
Epoch [41/300], Train Loss: 0.007158
Validation Loss: 0.00619936
Epoch [42/300], Train Loss: 0.007125
Validation Loss: 0.00618306
Epoch [43/300], Train Loss: 0.007096
Validation Loss: 0.00613297
Epoch [44/300], Train Loss: 0.007061
Validation Loss: 0.00614451
Epoch [45/300], Train Loss: 0.007035
Validation Loss: 0.00606312
Epoch [46/300], Train Loss: 0.007007
Validation Loss: 0.00601390
Epoch [47/300], Train Loss: 0.006925
Validation Loss: 0.00598925
Epoch [48/300], Train Loss: 0.006900
Validation Loss: 0.00614315
Epoch [49/300], Train Loss: 0.006796
Validation Loss: 0.00591938
Epoch [50/300], Train Loss: 0.006747
Validation Loss: 0.00579200
Epoch [51/300], Train Loss: 0.006666
Validation Loss: 0.00580785
Epoch [52/300], Train Loss: 0.006596
Validation Loss: 0.00558196
Epoch [53/300], Train Loss: 0.006418
Validation Loss: 0.00552540
Epoch [54/300], Train Loss: 0.006236
Validation Loss: 0.00517782
Epoch [55/300], Train Loss: 0.006000
Validation Loss: 0.00484781
Epoch [56/300], Train Loss: 0.005619
Validation Loss: 0.00442568
Epoch [57/300], Train Loss: 0.005264
Validation Loss: 0.00407143
Epoch [58/300], Train Loss: 0.004910
Validation Loss: 0.00369013
Epoch [59/300], Train Loss: 0.004552
Validation Loss: 0.00347845
Epoch [60/300], Train Loss: 0.004297
Validation Loss: 0.00329825
Epoch [61/300], Train Loss: 0.004155
Validation Loss: 0.00313182
Epoch [62/300], Train Loss: 0.004012
Validation Loss: 0.00312259
Epoch [63/300], Train Loss: 0.003882
Validation Loss: 0.00312954
Epoch [64/300], Train Loss: 0.003802
Validation Loss: 0.00288005
Epoch [65/300], Train Loss: 0.003751
Validation Loss: 0.00288630
Epoch [66/300], Train Loss: 0.003662
Validation Loss: 0.00281855
Epoch [67/300], Train Loss: 0.003612
Validation Loss: 0.00280621
Epoch [68/300], Train Loss: 0.003535
Validation Loss: 0.00275422
Epoch [69/300], Train Loss: 0.003517
Validation Loss: 0.00274240
Epoch [70/300], Train Loss: 0.003464
Validation Loss: 0.00269695
Epoch [71/300], Train Loss: 0.003424
Validation Loss: 0.00270526
Epoch [72/300], Train Loss: 0.003383
Validation Loss: 0.00263376
Epoch [73/300], Train Loss: 0.003329
Validation Loss: 0.00264161
Epoch [74/300], Train Loss: 0.003289
Validation Loss: 0.00259370
Epoch [75/300], Train Loss: 0.003260
Validation Loss: 0.00280247
Epoch [76/300], Train Loss: 0.003288
Validation Loss: 0.00258515
Epoch [77/300], Train Loss: 0.003238
Validation Loss: 0.00293926
Epoch [78/300], Train Loss: 0.003164
Validation Loss: 0.00257148
Epoch [79/300], Train Loss: 0.003136
Validation Loss: 0.00248495
Epoch [80/300], Train Loss: 0.003105
Validation Loss: 0.00247186
Epoch [81/300], Train Loss: 0.003086
Validation Loss: 0.00250423
Epoch [82/300], Train Loss: 0.003288
Validation Loss: 0.00331462
Epoch [83/300], Train Loss: 0.003400
Validation Loss: 0.00251111
Epoch [84/300], Train Loss: 0.003068
Validation Loss: 0.00249106
Epoch [85/300], Train Loss: 0.003007
Validation Loss: 0.00241162
Epoch [86/300], Train Loss: 0.003040
Validation Loss: 0.00242261
Epoch [87/300], Train Loss: 0.002959
Validation Loss: 0.00240901
Epoch [88/300], Train Loss: 0.002933
Validation Loss: 0.00239236
Epoch [89/300], Train Loss: 0.002956
Validation Loss: 0.00234520
Epoch [90/300], Train Loss: 0.002921
Validation Loss: 0.00232398
Epoch [91/300], Train Loss: 0.002878
Validation Loss: 0.00234014
Epoch [92/300], Train Loss: 0.002872
Validation Loss: 0.00233881
Epoch [93/300], Train Loss: 0.002856
Validation Loss: 0.00232161
Epoch [94/300], Train Loss: 0.002864
Validation Loss: 0.00234519
Epoch [95/300], Train Loss: 0.002983
Validation Loss: 0.00231515
Epoch [96/300], Train Loss: 0.002827
Validation Loss: 0.00225977
Epoch [97/300], Train Loss: 0.002818
Validation Loss: 0.00227682
Epoch [98/300], Train Loss: 0.002784
Validation Loss: 0.00224728
Epoch [99/300], Train Loss: 0.002771
Validation Loss: 0.00223793
Epoch [100/300], Train Loss: 0.002778
Validation Loss: 0.00223615
Epoch [101/300], Train Loss: 0.002751
Validation Loss: 0.00225017
Epoch [102/300], Train Loss: 0.002759
Validation Loss: 0.00224673
Epoch [103/300], Train Loss: 0.002751
Validation Loss: 0.00232150
Epoch [104/300], Train Loss: 0.002741
Validation Loss: 0.00223438
Epoch [105/300], Train Loss: 0.002719
Validation Loss: 0.00222246
Epoch [106/300], Train Loss: 0.002698
Validation Loss: 0.00223807
Epoch [107/300], Train Loss: 0.002691
Validation Loss: 0.00226677
Epoch [108/300], Train Loss: 0.002687
Validation Loss: 0.00222904
Epoch [109/300], Train Loss: 0.002673
Validation Loss: 0.00223654
Epoch [110/300], Train Loss: 0.002694
Validation Loss: 0.00221826
Epoch [111/300], Train Loss: 0.002683
Validation Loss: 0.00222565
Epoch [112/300], Train Loss: 0.002647
Validation Loss: 0.00221009
Epoch [113/300], Train Loss: 0.002634
Validation Loss: 0.00217251
Epoch [114/300], Train Loss: 0.002632
Validation Loss: 0.00220197
Epoch [115/300], Train Loss: 0.002645
Validation Loss: 0.00218268
Epoch [116/300], Train Loss: 0.002649
Validation Loss: 0.00216475
Epoch [117/300], Train Loss: 0.002614
Validation Loss: 0.00217174
Epoch [118/300], Train Loss: 0.002619
Validation Loss: 0.00218565
Epoch [119/300], Train Loss: 0.002603
Validation Loss: 0.00220456
Epoch [120/300], Train Loss: 0.002590
Validation Loss: 0.00213507
Epoch [121/300], Train Loss: 0.002579
Validation Loss: 0.00214894
Epoch [122/300], Train Loss: 0.002576
Validation Loss: 0.00214129
Epoch [123/300], Train Loss: 0.002608
Validation Loss: 0.00212870
Epoch [124/300], Train Loss: 0.002566
Validation Loss: 0.00218878
Epoch [125/300], Train Loss: 0.002562
Validation Loss: 0.00219472
Epoch [126/300], Train Loss: 0.002596
Validation Loss: 0.00215992
Epoch [127/300], Train Loss: 0.002553
Validation Loss: 0.00213409
Epoch [128/300], Train Loss: 0.002571
Validation Loss: 0.00214690
Epoch [129/300], Train Loss: 0.002570
Validation Loss: 0.00215112
Epoch [130/300], Train Loss: 0.002536
Validation Loss: 0.00213739
Epoch [131/300], Train Loss: 0.002548
Validation Loss: 0.00215009
Epoch [132/300], Train Loss: 0.002521
Validation Loss: 0.00215829
Epoch [133/300], Train Loss: 0.002526
Validation Loss: 0.00215459
Early stopping triggered

Evaluating model for: Tablet
Run 6/72 completed in 1585.51 seconds with: {'MAE': np.float32(0.4175469), 'MSE': np.float32(0.35493165), 'RMSE': np.float32(0.5957614), 'SAE': np.float32(0.006885971), 'NDE': np.float32(0.13690966)}

Run 7/72: hidden=128, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Tablet
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.048257
Validation Loss: 0.01724901
Epoch [2/300], Train Loss: 0.017768
Validation Loss: 0.01633266
Epoch [3/300], Train Loss: 0.016402
Validation Loss: 0.01349813
Epoch [4/300], Train Loss: 0.012453
Validation Loss: 0.01037895
Epoch [5/300], Train Loss: 0.011016
Validation Loss: 0.00954535
Epoch [6/300], Train Loss: 0.010413
Validation Loss: 0.00905545
Epoch [7/300], Train Loss: 0.010026
Validation Loss: 0.00878233
Epoch [8/300], Train Loss: 0.009744
Validation Loss: 0.00849534
Epoch [9/300], Train Loss: 0.009519
Validation Loss: 0.00829758
Epoch [10/300], Train Loss: 0.009355
Validation Loss: 0.00814349
Epoch [11/300], Train Loss: 0.009158
Validation Loss: 0.00804536
Epoch [12/300], Train Loss: 0.009029
Validation Loss: 0.00794017
Epoch [13/300], Train Loss: 0.008948
Validation Loss: 0.00780398
Epoch [14/300], Train Loss: 0.008797
Validation Loss: 0.00770827
Epoch [15/300], Train Loss: 0.008701
Validation Loss: 0.00759392
Epoch [16/300], Train Loss: 0.008541
Validation Loss: 0.00750824
Epoch [17/300], Train Loss: 0.008435
Validation Loss: 0.00755480
Epoch [18/300], Train Loss: 0.008369
Validation Loss: 0.00737207
Epoch [19/300], Train Loss: 0.008236
Validation Loss: 0.00724369
Epoch [20/300], Train Loss: 0.008136
Validation Loss: 0.00722774
Epoch [21/300], Train Loss: 0.008053
Validation Loss: 0.00704911
Epoch [22/300], Train Loss: 0.007894
Validation Loss: 0.00694281
Epoch [23/300], Train Loss: 0.007760
Validation Loss: 0.00682113
Epoch [24/300], Train Loss: 0.007646
Validation Loss: 0.00686413
Epoch [25/300], Train Loss: 0.007621
Validation Loss: 0.00670073
Epoch [26/300], Train Loss: 0.007618
Validation Loss: 0.00668286
Epoch [27/300], Train Loss: 0.007512
Validation Loss: 0.00669475
Epoch [28/300], Train Loss: 0.007486
Validation Loss: 0.00660524
Epoch [29/300], Train Loss: 0.007445
Validation Loss: 0.00657482
Epoch [30/300], Train Loss: 0.007393
Validation Loss: 0.00659656
Epoch [31/300], Train Loss: 0.007384
Validation Loss: 0.00652496
Epoch [32/300], Train Loss: 0.007374
Validation Loss: 0.00654303
Epoch [33/300], Train Loss: 0.007351
Validation Loss: 0.00647611
Epoch [34/300], Train Loss: 0.007286
Validation Loss: 0.00648560
Epoch [35/300], Train Loss: 0.007269
Validation Loss: 0.00644070
Epoch [36/300], Train Loss: 0.007257
Validation Loss: 0.00642115
Epoch [37/300], Train Loss: 0.007212
Validation Loss: 0.00642728
Epoch [38/300], Train Loss: 0.007230
Validation Loss: 0.00642455
Epoch [39/300], Train Loss: 0.007192
Validation Loss: 0.00636448
Epoch [40/300], Train Loss: 0.007183
Validation Loss: 0.00636754
Epoch [41/300], Train Loss: 0.007128
Validation Loss: 0.00631657
Epoch [42/300], Train Loss: 0.007114
Validation Loss: 0.00630911
Epoch [43/300], Train Loss: 0.007093
Validation Loss: 0.00628382
Epoch [44/300], Train Loss: 0.007099
Validation Loss: 0.00632765
Epoch [45/300], Train Loss: 0.007073
Validation Loss: 0.00623715
Epoch [46/300], Train Loss: 0.007066
Validation Loss: 0.00620805
Epoch [47/300], Train Loss: 0.006991
Validation Loss: 0.00620040
Epoch [48/300], Train Loss: 0.006981
Validation Loss: 0.00626324
Epoch [49/300], Train Loss: 0.006929
Validation Loss: 0.00609484
Epoch [50/300], Train Loss: 0.006902
Validation Loss: 0.00611968
Epoch [51/300], Train Loss: 0.006885
Validation Loss: 0.00608661
Epoch [52/300], Train Loss: 0.006983
Validation Loss: 0.00610973
Epoch [53/300], Train Loss: 0.006875
Validation Loss: 0.00614192
Epoch [54/300], Train Loss: 0.006831
Validation Loss: 0.00603383
Epoch [55/300], Train Loss: 0.006855
Validation Loss: 0.00604213
Epoch [56/300], Train Loss: 0.006842
Validation Loss: 0.00606421
Epoch [57/300], Train Loss: 0.006844
Validation Loss: 0.00601048
Epoch [58/300], Train Loss: 0.006814
Validation Loss: 0.00612451
Epoch [59/300], Train Loss: 0.006824
Validation Loss: 0.00598548
Epoch [60/300], Train Loss: 0.006775
Validation Loss: 0.00600823
Epoch [61/300], Train Loss: 0.006784
Validation Loss: 0.00614647
Epoch [62/300], Train Loss: 0.006782
Validation Loss: 0.00595579
Epoch [63/300], Train Loss: 0.006736
Validation Loss: 0.00596414
Epoch [64/300], Train Loss: 0.006789
Validation Loss: 0.00615756
Epoch [65/300], Train Loss: 0.006828
Validation Loss: 0.00609632
Epoch [66/300], Train Loss: 0.006714
Validation Loss: 0.00603681
Epoch [67/300], Train Loss: 0.006753
Validation Loss: 0.00607631
Epoch [68/300], Train Loss: 0.006712
Validation Loss: 0.00597398
Epoch [69/300], Train Loss: 0.006709
Validation Loss: 0.00590946
Epoch [70/300], Train Loss: 0.006702
Validation Loss: 0.00587107
Epoch [71/300], Train Loss: 0.006666
Validation Loss: 0.00589995
Epoch [72/300], Train Loss: 0.006678
Validation Loss: 0.00589667
Epoch [73/300], Train Loss: 0.006652
Validation Loss: 0.00589780
Epoch [74/300], Train Loss: 0.006652
Validation Loss: 0.00585958
Epoch [75/300], Train Loss: 0.006666
Validation Loss: 0.00586096
Epoch [76/300], Train Loss: 0.006629
Validation Loss: 0.00590971
Epoch [77/300], Train Loss: 0.006667
Validation Loss: 0.00597455
Epoch [78/300], Train Loss: 0.006643
Validation Loss: 0.00589849
Epoch [79/300], Train Loss: 0.006634
Validation Loss: 0.00585282
Epoch [80/300], Train Loss: 0.006635
Validation Loss: 0.00588852
Epoch [81/300], Train Loss: 0.006613
Validation Loss: 0.00586005
Epoch [82/300], Train Loss: 0.006603
Validation Loss: 0.00585838
Epoch [83/300], Train Loss: 0.006628
Validation Loss: 0.00584736
Epoch [84/300], Train Loss: 0.006620
Validation Loss: 0.00588166
Epoch [85/300], Train Loss: 0.006605
Validation Loss: 0.00583349
Epoch [86/300], Train Loss: 0.006608
Validation Loss: 0.00582725
Epoch [87/300], Train Loss: 0.006598
Validation Loss: 0.00583081
Epoch [88/300], Train Loss: 0.006566
Validation Loss: 0.00581856
Epoch [89/300], Train Loss: 0.006557
Validation Loss: 0.00584436
Epoch [90/300], Train Loss: 0.006599
Validation Loss: 0.00590093
Epoch [91/300], Train Loss: 0.006550
Validation Loss: 0.00578020
Epoch [92/300], Train Loss: 0.006601
Validation Loss: 0.00580638
Epoch [93/300], Train Loss: 0.006563
Validation Loss: 0.00582850
Epoch [94/300], Train Loss: 0.006549
Validation Loss: 0.00582453
Epoch [95/300], Train Loss: 0.006575
Validation Loss: 0.00586500
Epoch [96/300], Train Loss: 0.006615
Validation Loss: 0.00579638
Epoch [97/300], Train Loss: 0.006519
Validation Loss: 0.00576044
Epoch [98/300], Train Loss: 0.006536
Validation Loss: 0.00581759
Epoch [99/300], Train Loss: 0.006518
Validation Loss: 0.00576728
Epoch [100/300], Train Loss: 0.006520
Validation Loss: 0.00582238
Epoch [101/300], Train Loss: 0.006540
Validation Loss: 0.00579911
Epoch [102/300], Train Loss: 0.006507
Validation Loss: 0.00579509
Epoch [103/300], Train Loss: 0.006498
Validation Loss: 0.00580190
Epoch [104/300], Train Loss: 0.006506
Validation Loss: 0.00575816
Epoch [105/300], Train Loss: 0.006554
Validation Loss: 0.00577988
Epoch [106/300], Train Loss: 0.006475
Validation Loss: 0.00577742
Epoch [107/300], Train Loss: 0.006499
Validation Loss: 0.00576875
Epoch [108/300], Train Loss: 0.006495
Validation Loss: 0.00576196
Epoch [109/300], Train Loss: 0.006501
Validation Loss: 0.00577926
Epoch [110/300], Train Loss: 0.006458
Validation Loss: 0.00572770
Epoch [111/300], Train Loss: 0.006464
Validation Loss: 0.00576965
Epoch [112/300], Train Loss: 0.006461
Validation Loss: 0.00576651
Epoch [113/300], Train Loss: 0.006459
Validation Loss: 0.00575020
Epoch [114/300], Train Loss: 0.006517
Validation Loss: 0.00573326
Epoch [115/300], Train Loss: 0.006445
Validation Loss: 0.00567475
Epoch [116/300], Train Loss: 0.006435
Validation Loss: 0.00567994
Epoch [117/300], Train Loss: 0.006409
Validation Loss: 0.00566789
Epoch [118/300], Train Loss: 0.006391
Validation Loss: 0.00564252
Epoch [119/300], Train Loss: 0.006357
Validation Loss: 0.00568375
Epoch [120/300], Train Loss: 0.006349
Validation Loss: 0.00561778
Epoch [121/300], Train Loss: 0.006357
Validation Loss: 0.00557557
Epoch [122/300], Train Loss: 0.006288
Validation Loss: 0.00555108
Epoch [123/300], Train Loss: 0.006251
Validation Loss: 0.00544986
Epoch [124/300], Train Loss: 0.006170
Validation Loss: 0.00564272
Epoch [125/300], Train Loss: 0.006138
Validation Loss: 0.00527959
Epoch [126/300], Train Loss: 0.005984
Validation Loss: 0.00510567
Epoch [127/300], Train Loss: 0.005804
Validation Loss: 0.00484860
Epoch [128/300], Train Loss: 0.005559
Validation Loss: 0.00458415
Epoch [129/300], Train Loss: 0.005424
Validation Loss: 0.00427193
Epoch [130/300], Train Loss: 0.005129
Validation Loss: 0.00411140
Epoch [131/300], Train Loss: 0.004958
Validation Loss: 0.00394472
Epoch [132/300], Train Loss: 0.004773
Validation Loss: 0.00361026
Epoch [133/300], Train Loss: 0.004512
Validation Loss: 0.00356382
Epoch [134/300], Train Loss: 0.004332
Validation Loss: 0.00342120
Epoch [135/300], Train Loss: 0.004302
Validation Loss: 0.00373555
Epoch [136/300], Train Loss: 0.004198
Validation Loss: 0.00317765
Epoch [137/300], Train Loss: 0.003959
Validation Loss: 0.00309492
Epoch [138/300], Train Loss: 0.003876
Validation Loss: 0.00323292
Epoch [139/300], Train Loss: 0.003817
Validation Loss: 0.00309680
Epoch [140/300], Train Loss: 0.003779
Validation Loss: 0.00295792
Epoch [141/300], Train Loss: 0.003703
Validation Loss: 0.00292764
Epoch [142/300], Train Loss: 0.003668
Validation Loss: 0.00290672
Epoch [143/300], Train Loss: 0.003577
Validation Loss: 0.00288901
Epoch [144/300], Train Loss: 0.003528
Validation Loss: 0.00284891
Epoch [145/300], Train Loss: 0.003744
Validation Loss: 0.00286054
Epoch [146/300], Train Loss: 0.003459
Validation Loss: 0.00289268
Epoch [147/300], Train Loss: 0.003453
Validation Loss: 0.00278269
Epoch [148/300], Train Loss: 0.003364
Validation Loss: 0.00272863
Epoch [149/300], Train Loss: 0.003481
Validation Loss: 0.00281362
Epoch [150/300], Train Loss: 0.003399
Validation Loss: 0.00282969
Epoch [151/300], Train Loss: 0.003285
Validation Loss: 0.00263989
Epoch [152/300], Train Loss: 0.003244
Validation Loss: 0.00262931
Epoch [153/300], Train Loss: 0.003216
Validation Loss: 0.00261697
Epoch [154/300], Train Loss: 0.003198
Validation Loss: 0.00263328
Epoch [155/300], Train Loss: 0.003161
Validation Loss: 0.00260726
Epoch [156/300], Train Loss: 0.003163
Validation Loss: 0.00267252
Epoch [157/300], Train Loss: 0.003385
Validation Loss: 0.00262587
Epoch [158/300], Train Loss: 0.003122
Validation Loss: 0.00254182
Epoch [159/300], Train Loss: 0.003065
Validation Loss: 0.00250063
Epoch [160/300], Train Loss: 0.003044
Validation Loss: 0.00248699
Epoch [161/300], Train Loss: 0.003018
Validation Loss: 0.00248409
Epoch [162/300], Train Loss: 0.002999
Validation Loss: 0.00244896
Epoch [163/300], Train Loss: 0.003011
Validation Loss: 0.00248343
Epoch [164/300], Train Loss: 0.003020
Validation Loss: 0.00240195
Epoch [165/300], Train Loss: 0.002916
Validation Loss: 0.00243839
Epoch [166/300], Train Loss: 0.002883
Validation Loss: 0.00247818
Epoch [167/300], Train Loss: 0.002876
Validation Loss: 0.00248804
Epoch [168/300], Train Loss: 0.002869
Validation Loss: 0.00233310
Epoch [169/300], Train Loss: 0.002822
Validation Loss: 0.00235907
Epoch [170/300], Train Loss: 0.002809
Validation Loss: 0.00233956
Epoch [171/300], Train Loss: 0.002789
Validation Loss: 0.00230913
Epoch [172/300], Train Loss: 0.002769
Validation Loss: 0.00233997
Epoch [173/300], Train Loss: 0.002743
Validation Loss: 0.00228982
Epoch [174/300], Train Loss: 0.002765
Validation Loss: 0.00232484
Epoch [175/300], Train Loss: 0.002747
Validation Loss: 0.00227193
Epoch [176/300], Train Loss: 0.002693
Validation Loss: 0.00225612
Epoch [177/300], Train Loss: 0.002688
Validation Loss: 0.00224724
Epoch [178/300], Train Loss: 0.002698
Validation Loss: 0.00225983
Epoch [179/300], Train Loss: 0.002651
Validation Loss: 0.00224118
Epoch [180/300], Train Loss: 0.002643
Validation Loss: 0.00223146
Epoch [181/300], Train Loss: 0.002640
Validation Loss: 0.00224115
Epoch [182/300], Train Loss: 0.002616
Validation Loss: 0.00221959
Epoch [183/300], Train Loss: 0.002631
Validation Loss: 0.00221344
Epoch [184/300], Train Loss: 0.002620
Validation Loss: 0.00220799
Epoch [185/300], Train Loss: 0.002592
Validation Loss: 0.00220530
Epoch [186/300], Train Loss: 0.002652
Validation Loss: 0.00220436
Epoch [187/300], Train Loss: 0.002586
Validation Loss: 0.00219953
Epoch [188/300], Train Loss: 0.002574
Validation Loss: 0.00221202
Epoch [189/300], Train Loss: 0.002583
Validation Loss: 0.00222066
Epoch [190/300], Train Loss: 0.002561
Validation Loss: 0.00234719
Epoch [191/300], Train Loss: 0.002556
Validation Loss: 0.00216983
Epoch [192/300], Train Loss: 0.002533
Validation Loss: 0.00218117
Epoch [193/300], Train Loss: 0.002531
Validation Loss: 0.00216993
Epoch [194/300], Train Loss: 0.002534
Validation Loss: 0.00218139
Epoch [195/300], Train Loss: 0.002534
Validation Loss: 0.00220318
Epoch [196/300], Train Loss: 0.002517
Validation Loss: 0.00215878
Epoch [197/300], Train Loss: 0.002528
Validation Loss: 0.00216015
Epoch [198/300], Train Loss: 0.002773
Validation Loss: 0.00219590
Epoch [199/300], Train Loss: 0.002558
Validation Loss: 0.00217472
Epoch [200/300], Train Loss: 0.002513
Validation Loss: 0.00217882
Epoch [201/300], Train Loss: 0.002497
Validation Loss: 0.00215841
Epoch [202/300], Train Loss: 0.002494
Validation Loss: 0.00216602
Epoch [203/300], Train Loss: 0.002480
Validation Loss: 0.00213062
Epoch [204/300], Train Loss: 0.002483
Validation Loss: 0.00214714
Epoch [205/300], Train Loss: 0.002472
Validation Loss: 0.00213785
Epoch [206/300], Train Loss: 0.002472
Validation Loss: 0.00215267
Epoch [207/300], Train Loss: 0.002472
Validation Loss: 0.00215721
Epoch [208/300], Train Loss: 0.002467
Validation Loss: 0.00214381
Epoch [209/300], Train Loss: 0.002472
Validation Loss: 0.00213727
Epoch [210/300], Train Loss: 0.002460
Validation Loss: 0.00214207
Epoch [211/300], Train Loss: 0.002446
Validation Loss: 0.00217501
Epoch [212/300], Train Loss: 0.002452
Validation Loss: 0.00214739
Epoch [213/300], Train Loss: 0.002447
Validation Loss: 0.00214085
Early stopping triggered

Evaluating model for: Tablet
Run 7/72 completed in 2632.77 seconds with: {'MAE': np.float32(0.40385565), 'MSE': np.float32(0.36468107), 'RMSE': np.float32(0.6038883), 'SAE': np.float32(0.0010823761), 'NDE': np.float32(0.13877727)}

Run 8/72: hidden=128, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Tablet
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.057597
Validation Loss: 0.01794468
Epoch [2/300], Train Loss: 0.018608
Validation Loss: 0.01729438
Epoch [3/300], Train Loss: 0.017957
Validation Loss: 0.01653607
Epoch [4/300], Train Loss: 0.015781
Validation Loss: 0.01227668
Epoch [5/300], Train Loss: 0.012288
Validation Loss: 0.01071068
Epoch [6/300], Train Loss: 0.011511
Validation Loss: 0.01006334
Epoch [7/300], Train Loss: 0.011015
Validation Loss: 0.00974670
Epoch [8/300], Train Loss: 0.010658
Validation Loss: 0.00934864
Epoch [9/300], Train Loss: 0.010372
Validation Loss: 0.00907840
Epoch [10/300], Train Loss: 0.010169
Validation Loss: 0.00888854
Epoch [11/300], Train Loss: 0.009947
Validation Loss: 0.00876435
Epoch [12/300], Train Loss: 0.009798
Validation Loss: 0.00861109
Epoch [13/300], Train Loss: 0.009693
Validation Loss: 0.00846870
Epoch [14/300], Train Loss: 0.009556
Validation Loss: 0.00836443
Epoch [15/300], Train Loss: 0.009425
Validation Loss: 0.00823887
Epoch [16/300], Train Loss: 0.009292
Validation Loss: 0.00814146
Epoch [17/300], Train Loss: 0.009179
Validation Loss: 0.00818774
Epoch [18/300], Train Loss: 0.009123
Validation Loss: 0.00797191
Epoch [19/300], Train Loss: 0.008994
Validation Loss: 0.00786492
Epoch [20/300], Train Loss: 0.008893
Validation Loss: 0.00781827
Epoch [21/300], Train Loss: 0.008803
Validation Loss: 0.00767278
Epoch [22/300], Train Loss: 0.008679
Validation Loss: 0.00758536
Epoch [23/300], Train Loss: 0.008534
Validation Loss: 0.00744252
Epoch [24/300], Train Loss: 0.008402
Validation Loss: 0.00740412
Epoch [25/300], Train Loss: 0.008184
Validation Loss: 0.00707575
Epoch [26/300], Train Loss: 0.008020
Validation Loss: 0.00700687
Epoch [27/300], Train Loss: 0.007791
Validation Loss: 0.00678517
Epoch [28/300], Train Loss: 0.007689
Validation Loss: 0.00674886
Epoch [29/300], Train Loss: 0.007701
Validation Loss: 0.00671665
Epoch [30/300], Train Loss: 0.007580
Validation Loss: 0.00667053
Epoch [31/300], Train Loss: 0.007617
Validation Loss: 0.00662487
Epoch [32/300], Train Loss: 0.007526
Validation Loss: 0.00676118
Epoch [33/300], Train Loss: 0.007509
Validation Loss: 0.00660456
Epoch [34/300], Train Loss: 0.007434
Validation Loss: 0.00663243
Epoch [35/300], Train Loss: 0.007408
Validation Loss: 0.00649305
Epoch [36/300], Train Loss: 0.007386
Validation Loss: 0.00647614
Epoch [37/300], Train Loss: 0.007331
Validation Loss: 0.00644870
Epoch [38/300], Train Loss: 0.007309
Validation Loss: 0.00646571
Epoch [39/300], Train Loss: 0.007292
Validation Loss: 0.00640226
Epoch [40/300], Train Loss: 0.007247
Validation Loss: 0.00638562
Epoch [41/300], Train Loss: 0.007210
Validation Loss: 0.00633436
Epoch [42/300], Train Loss: 0.007198
Validation Loss: 0.00632689
Epoch [43/300], Train Loss: 0.007174
Validation Loss: 0.00633060
Epoch [44/300], Train Loss: 0.007166
Validation Loss: 0.00627156
Epoch [45/300], Train Loss: 0.007152
Validation Loss: 0.00625514
Epoch [46/300], Train Loss: 0.007270
Validation Loss: 0.00631097
Epoch [47/300], Train Loss: 0.007099
Validation Loss: 0.00623291
Epoch [48/300], Train Loss: 0.007092
Validation Loss: 0.00650540
Epoch [49/300], Train Loss: 0.007057
Validation Loss: 0.00623792
Epoch [50/300], Train Loss: 0.007048
Validation Loss: 0.00619100
Epoch [51/300], Train Loss: 0.007031
Validation Loss: 0.00634089
Epoch [52/300], Train Loss: 0.007052
Validation Loss: 0.00617557
Epoch [53/300], Train Loss: 0.006987
Validation Loss: 0.00625986
Epoch [54/300], Train Loss: 0.006971
Validation Loss: 0.00611239
Epoch [55/300], Train Loss: 0.006974
Validation Loss: 0.00618163
Epoch [56/300], Train Loss: 0.006929
Validation Loss: 0.00616023
Epoch [57/300], Train Loss: 0.006940
Validation Loss: 0.00612637
Epoch [58/300], Train Loss: 0.006908
Validation Loss: 0.00605025
Epoch [59/300], Train Loss: 0.006882
Validation Loss: 0.00602173
Epoch [60/300], Train Loss: 0.006862
Validation Loss: 0.00600566
Epoch [61/300], Train Loss: 0.006840
Validation Loss: 0.00603725
Epoch [62/300], Train Loss: 0.006839
Validation Loss: 0.00599663
Epoch [63/300], Train Loss: 0.006815
Validation Loss: 0.00595513
Epoch [64/300], Train Loss: 0.006809
Validation Loss: 0.00589917
Epoch [65/300], Train Loss: 0.006751
Validation Loss: 0.00591982
Epoch [66/300], Train Loss: 0.006735
Validation Loss: 0.00585696
Epoch [67/300], Train Loss: 0.006820
Validation Loss: 0.00626767
Epoch [68/300], Train Loss: 0.006736
Validation Loss: 0.00588312
Epoch [69/300], Train Loss: 0.006716
Validation Loss: 0.00582595
Epoch [70/300], Train Loss: 0.006665
Validation Loss: 0.00580797
Epoch [71/300], Train Loss: 0.006704
Validation Loss: 0.00579979
Epoch [72/300], Train Loss: 0.006663
Validation Loss: 0.00584341
Epoch [73/300], Train Loss: 0.006624
Validation Loss: 0.00573815
Epoch [74/300], Train Loss: 0.006584
Validation Loss: 0.00591563
Epoch [75/300], Train Loss: 0.006617
Validation Loss: 0.00572176
Epoch [76/300], Train Loss: 0.006556
Validation Loss: 0.00565816
Epoch [77/300], Train Loss: 0.006533
Validation Loss: 0.00562868
Epoch [78/300], Train Loss: 0.006448
Validation Loss: 0.00565956
Epoch [79/300], Train Loss: 0.006351
Validation Loss: 0.00541704
Epoch [80/300], Train Loss: 0.006272
Validation Loss: 0.00531681
Epoch [81/300], Train Loss: 0.006147
Validation Loss: 0.00517843
Epoch [82/300], Train Loss: 0.005965
Validation Loss: 0.00496484
Epoch [83/300], Train Loss: 0.005774
Validation Loss: 0.00479149
Epoch [84/300], Train Loss: 0.005448
Validation Loss: 0.00427359
Epoch [85/300], Train Loss: 0.005178
Validation Loss: 0.00403296
Epoch [86/300], Train Loss: 0.004813
Validation Loss: 0.00379637
Epoch [87/300], Train Loss: 0.004523
Validation Loss: 0.00344365
Epoch [88/300], Train Loss: 0.004152
Validation Loss: 0.00322150
Epoch [89/300], Train Loss: 0.003922
Validation Loss: 0.00308429
Epoch [90/300], Train Loss: 0.003728
Validation Loss: 0.00285846
Epoch [91/300], Train Loss: 0.003521
Validation Loss: 0.00272796
Epoch [92/300], Train Loss: 0.003426
Validation Loss: 0.00267526
Epoch [93/300], Train Loss: 0.003277
Validation Loss: 0.00261563
Epoch [94/300], Train Loss: 0.005818
Validation Loss: 0.00288489
Epoch [95/300], Train Loss: 0.003683
Validation Loss: 0.00280125
Epoch [96/300], Train Loss: 0.003114
Validation Loss: 0.00242187
Epoch [97/300], Train Loss: 0.002957
Validation Loss: 0.00237671
Epoch [98/300], Train Loss: 0.002896
Validation Loss: 0.00234683
Epoch [99/300], Train Loss: 0.002850
Validation Loss: 0.00236083
Epoch [100/300], Train Loss: 0.002805
Validation Loss: 0.00229851
Epoch [101/300], Train Loss: 0.002788
Validation Loss: 0.00230861
Epoch [102/300], Train Loss: 0.002743
Validation Loss: 0.00224240
Epoch [103/300], Train Loss: 0.002724
Validation Loss: 0.00226876
Epoch [104/300], Train Loss: 0.002701
Validation Loss: 0.00222978
Epoch [105/300], Train Loss: 0.002662
Validation Loss: 0.00223787
Epoch [106/300], Train Loss: 0.002644
Validation Loss: 0.00222966
Epoch [107/300], Train Loss: 0.002635
Validation Loss: 0.00230529
Epoch [108/300], Train Loss: 0.002604
Validation Loss: 0.00223080
Epoch [109/300], Train Loss: 0.002587
Validation Loss: 0.00219542
Epoch [110/300], Train Loss: 0.002579
Validation Loss: 0.00219588
Epoch [111/300], Train Loss: 0.002567
Validation Loss: 0.00222461
Epoch [112/300], Train Loss: 0.002561
Validation Loss: 0.00220477
Epoch [113/300], Train Loss: 0.002551
Validation Loss: 0.00216753
Epoch [114/300], Train Loss: 0.002525
Validation Loss: 0.00217896
Epoch [115/300], Train Loss: 0.002516
Validation Loss: 0.00211493
Epoch [116/300], Train Loss: 0.002526
Validation Loss: 0.00218067
Epoch [117/300], Train Loss: 0.002496
Validation Loss: 0.00214656
Epoch [118/300], Train Loss: 0.002483
Validation Loss: 0.00215410
Epoch [119/300], Train Loss: 0.002467
Validation Loss: 0.00211102
Epoch [120/300], Train Loss: 0.002508
Validation Loss: 0.00210059
Epoch [121/300], Train Loss: 0.002450
Validation Loss: 0.00209686
Epoch [122/300], Train Loss: 0.002601
Validation Loss: 0.00213101
Epoch [123/300], Train Loss: 0.002612
Validation Loss: 0.00214062
Epoch [124/300], Train Loss: 0.002439
Validation Loss: 0.00213336
Epoch [125/300], Train Loss: 0.002438
Validation Loss: 0.00210926
Epoch [126/300], Train Loss: 0.002436
Validation Loss: 0.00209750
Epoch [127/300], Train Loss: 0.002434
Validation Loss: 0.00218589
Epoch [128/300], Train Loss: 0.002454
Validation Loss: 0.00205856
Epoch [129/300], Train Loss: 0.002592
Validation Loss: 0.00236081
Epoch [130/300], Train Loss: 0.002455
Validation Loss: 0.00205695
Epoch [131/300], Train Loss: 0.002415
Validation Loss: 0.00208629
Epoch [132/300], Train Loss: 0.002405
Validation Loss: 0.00205815
Epoch [133/300], Train Loss: 0.002406
Validation Loss: 0.00205968
Epoch [134/300], Train Loss: 0.002408
Validation Loss: 0.00206188
Epoch [135/300], Train Loss: 0.002397
Validation Loss: 0.00209876
Epoch [136/300], Train Loss: 0.002403
Validation Loss: 0.00206403
Epoch [137/300], Train Loss: 0.002379
Validation Loss: 0.00207576
Epoch [138/300], Train Loss: 0.002470
Validation Loss: 0.00206289
Epoch [139/300], Train Loss: 0.002377
Validation Loss: 0.00205563
Epoch [140/300], Train Loss: 0.002399
Validation Loss: 0.00204706
Epoch [141/300], Train Loss: 0.002381
Validation Loss: 0.00204626
Epoch [142/300], Train Loss: 0.002361
Validation Loss: 0.00203045
Epoch [143/300], Train Loss: 0.002392
Validation Loss: 0.00203751
Epoch [144/300], Train Loss: 0.002358
Validation Loss: 0.00203888
Epoch [145/300], Train Loss: 0.002386
Validation Loss: 0.00203079
Epoch [146/300], Train Loss: 0.002374
Validation Loss: 0.00211675
Epoch [147/300], Train Loss: 0.002458
Validation Loss: 0.00208661
Epoch [148/300], Train Loss: 0.002369
Validation Loss: 0.00202508
Epoch [149/300], Train Loss: 0.002351
Validation Loss: 0.00207568
Epoch [150/300], Train Loss: 0.002348
Validation Loss: 0.00209885
Epoch [151/300], Train Loss: 0.002340
Validation Loss: 0.00203627
Epoch [152/300], Train Loss: 0.002343
Validation Loss: 0.00203171
Epoch [153/300], Train Loss: 0.002341
Validation Loss: 0.00209443
Epoch [154/300], Train Loss: 0.002332
Validation Loss: 0.00203542
Epoch [155/300], Train Loss: 0.002332
Validation Loss: 0.00205484
Epoch [156/300], Train Loss: 0.002329
Validation Loss: 0.00201254
Epoch [157/300], Train Loss: 0.002326
Validation Loss: 0.00201578
Epoch [158/300], Train Loss: 0.002324
Validation Loss: 0.00200687
Epoch [159/300], Train Loss: 0.002435
Validation Loss: 0.00207549
Epoch [160/300], Train Loss: 0.002353
Validation Loss: 0.00208222
Epoch [161/300], Train Loss: 0.002319
Validation Loss: 0.00204843
Epoch [162/300], Train Loss: 0.002319
Validation Loss: 0.00202944
Epoch [163/300], Train Loss: 0.002319
Validation Loss: 0.00200370
Epoch [164/300], Train Loss: 0.002323
Validation Loss: 0.00204218
Epoch [165/300], Train Loss: 0.002349
Validation Loss: 0.00200014
Epoch [166/300], Train Loss: 0.002310
Validation Loss: 0.00201622
Epoch [167/300], Train Loss: 0.002317
Validation Loss: 0.00200528
Epoch [168/300], Train Loss: 0.002388
Validation Loss: 0.00202108
Epoch [169/300], Train Loss: 0.002326
Validation Loss: 0.00200080
Epoch [170/300], Train Loss: 0.002303
Validation Loss: 0.00200507
Epoch [171/300], Train Loss: 0.002305
Validation Loss: 0.00199701
Epoch [172/300], Train Loss: 0.002300
Validation Loss: 0.00199777
Epoch [173/300], Train Loss: 0.002295
Validation Loss: 0.00199723
Epoch [174/300], Train Loss: 0.002298
Validation Loss: 0.00200949
Epoch [175/300], Train Loss: 0.002300
Validation Loss: 0.00200201
Epoch [176/300], Train Loss: 0.002287
Validation Loss: 0.00201137
Epoch [177/300], Train Loss: 0.002533
Validation Loss: 0.00627900
Epoch [178/300], Train Loss: 0.002696
Validation Loss: 0.00210542
Epoch [179/300], Train Loss: 0.002323
Validation Loss: 0.00203577
Epoch [180/300], Train Loss: 0.002302
Validation Loss: 0.00201519
Epoch [181/300], Train Loss: 0.002305
Validation Loss: 0.00201720
Early stopping triggered

Evaluating model for: Tablet
Run 8/72 completed in 2243.65 seconds with: {'MAE': np.float32(0.3905725), 'MSE': np.float32(0.34372166), 'RMSE': np.float32(0.5862778), 'SAE': np.float32(0.005634642), 'NDE': np.float32(0.13473028)}

Run 9/72: hidden=128, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Tablet
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.076292
Validation Loss: 0.03762052
Epoch [2/300], Train Loss: 0.019214
Validation Loss: 0.01787056
Epoch [3/300], Train Loss: 0.015817
Validation Loss: 0.01696945
Epoch [4/300], Train Loss: 0.014822
Validation Loss: 0.01567255
Epoch [5/300], Train Loss: 0.013207
Validation Loss: 0.01367464
Epoch [6/300], Train Loss: 0.012122
Validation Loss: 0.01302849
Epoch [7/300], Train Loss: 0.011618
Validation Loss: 0.01263060
Epoch [8/300], Train Loss: 0.011316
Validation Loss: 0.01232780
Epoch [9/300], Train Loss: 0.010936
Validation Loss: 0.01179724
Epoch [10/300], Train Loss: 0.010501
Validation Loss: 0.01117124
Epoch [11/300], Train Loss: 0.010068
Validation Loss: 0.01062847
Epoch [12/300], Train Loss: 0.009578
Validation Loss: 0.01008390
Epoch [13/300], Train Loss: 0.009245
Validation Loss: 0.00988014
Epoch [14/300], Train Loss: 0.009084
Validation Loss: 0.00947776
Epoch [15/300], Train Loss: 0.009028
Validation Loss: 0.00956225
Epoch [16/300], Train Loss: 0.008814
Validation Loss: 0.00939213
Epoch [17/300], Train Loss: 0.008921
Validation Loss: 0.00933890
Epoch [18/300], Train Loss: 0.008885
Validation Loss: 0.00921529
Epoch [19/300], Train Loss: 0.008690
Validation Loss: 0.00927042
Epoch [20/300], Train Loss: 0.008601
Validation Loss: 0.00920703
Epoch [21/300], Train Loss: 0.008530
Validation Loss: 0.00906897
Epoch [22/300], Train Loss: 0.008629
Validation Loss: 0.00901540
Epoch [23/300], Train Loss: 0.008523
Validation Loss: 0.00891561
Epoch [24/300], Train Loss: 0.008365
Validation Loss: 0.00891216
Epoch [25/300], Train Loss: 0.008688
Validation Loss: 0.00903530
Epoch [26/300], Train Loss: 0.008481
Validation Loss: 0.00879068
Epoch [27/300], Train Loss: 0.008407
Validation Loss: 0.00919825
Epoch [28/300], Train Loss: 0.008309
Validation Loss: 0.00870031
Epoch [29/300], Train Loss: 0.008206
Validation Loss: 0.00856814
Epoch [30/300], Train Loss: 0.008159
Validation Loss: 0.00855065
Epoch [31/300], Train Loss: 0.008177
Validation Loss: 0.00849408
Epoch [32/300], Train Loss: 0.008080
Validation Loss: 0.00852761
Epoch [33/300], Train Loss: 0.008237
Validation Loss: 0.00850189
Epoch [34/300], Train Loss: 0.008093
Validation Loss: 0.00838436
Epoch [35/300], Train Loss: 0.008186
Validation Loss: 0.00840106
Epoch [36/300], Train Loss: 0.007855
Validation Loss: 0.00827757
Epoch [37/300], Train Loss: 0.007895
Validation Loss: 0.00831407
Epoch [38/300], Train Loss: 0.007868
Validation Loss: 0.00826610
Epoch [39/300], Train Loss: 0.008472
Validation Loss: 0.00848254
Epoch [40/300], Train Loss: 0.007965
Validation Loss: 0.00817189
Epoch [41/300], Train Loss: 0.007758
Validation Loss: 0.00816003
Epoch [42/300], Train Loss: 0.008049
Validation Loss: 0.00815214
Epoch [43/300], Train Loss: 0.007767
Validation Loss: 0.00848055
Epoch [44/300], Train Loss: 0.007651
Validation Loss: 0.00808171
Epoch [45/300], Train Loss: 0.007601
Validation Loss: 0.00801579
Epoch [46/300], Train Loss: 0.008632
Validation Loss: 0.00911987
Epoch [47/300], Train Loss: 0.007835
Validation Loss: 0.00803560
Epoch [48/300], Train Loss: 0.007601
Validation Loss: 0.00797962
Epoch [49/300], Train Loss: 0.007501
Validation Loss: 0.00799244
Epoch [50/300], Train Loss: 0.007586
Validation Loss: 0.00796181
Epoch [51/300], Train Loss: 0.007541
Validation Loss: 0.00811605
Epoch [52/300], Train Loss: 0.007591
Validation Loss: 0.00798518
Epoch [53/300], Train Loss: 0.007518
Validation Loss: 0.00792686
Epoch [54/300], Train Loss: 0.007609
Validation Loss: 0.00784219
Epoch [55/300], Train Loss: 0.007329
Validation Loss: 0.00778160
Epoch [56/300], Train Loss: 0.007521
Validation Loss: 0.00780529
Epoch [57/300], Train Loss: 0.007446
Validation Loss: 0.00777107
Epoch [58/300], Train Loss: 0.007229
Validation Loss: 0.00775200
Epoch [59/300], Train Loss: 0.007209
Validation Loss: 0.00763799
Epoch [60/300], Train Loss: 0.007252
Validation Loss: 0.00761168
Epoch [61/300], Train Loss: 0.007100
Validation Loss: 0.00759086
Epoch [62/300], Train Loss: 0.007186
Validation Loss: 0.00753684
Epoch [63/300], Train Loss: 0.007261
Validation Loss: 0.00756604
Epoch [64/300], Train Loss: 0.007133
Validation Loss: 0.00749624
Epoch [65/300], Train Loss: 0.007098
Validation Loss: 0.00742210
Epoch [66/300], Train Loss: 0.008988
Validation Loss: 0.00913852
Epoch [67/300], Train Loss: 0.007508
Validation Loss: 0.00776912
Epoch [68/300], Train Loss: 0.007440
Validation Loss: 0.00763814
Epoch [69/300], Train Loss: 0.007054
Validation Loss: 0.00754510
Epoch [70/300], Train Loss: 0.007069
Validation Loss: 0.00743869
Epoch [71/300], Train Loss: 0.007027
Validation Loss: 0.00739061
Epoch [72/300], Train Loss: 0.007310
Validation Loss: 0.00815074
Epoch [73/300], Train Loss: 0.007037
Validation Loss: 0.00732946
Epoch [74/300], Train Loss: 0.006848
Validation Loss: 0.00729098
Epoch [75/300], Train Loss: 0.006969
Validation Loss: 0.00732561
Epoch [76/300], Train Loss: 0.006840
Validation Loss: 0.00729277
Epoch [77/300], Train Loss: 0.007027
Validation Loss: 0.00721919
Epoch [78/300], Train Loss: 0.006822
Validation Loss: 0.00717772
Epoch [79/300], Train Loss: 0.006880
Validation Loss: 0.00719522
Epoch [80/300], Train Loss: 0.006834
Validation Loss: 0.00719899
Epoch [81/300], Train Loss: 0.006837
Validation Loss: 0.00718589
Epoch [82/300], Train Loss: 0.007008
Validation Loss: 0.00717529
Epoch [83/300], Train Loss: 0.006775
Validation Loss: 0.00714170
Epoch [84/300], Train Loss: 0.006738
Validation Loss: 0.00714144
Epoch [85/300], Train Loss: 0.006812
Validation Loss: 0.00717419
Epoch [86/300], Train Loss: 0.006651
Validation Loss: 0.00718226
Epoch [87/300], Train Loss: 0.006774
Validation Loss: 0.00713935
Epoch [88/300], Train Loss: 0.006640
Validation Loss: 0.00715717
Epoch [89/300], Train Loss: 0.006778
Validation Loss: 0.00709909
Epoch [90/300], Train Loss: 0.006834
Validation Loss: 0.00712083
Epoch [91/300], Train Loss: 0.006608
Validation Loss: 0.00710780
Epoch [92/300], Train Loss: 0.006665
Validation Loss: 0.00709096
Epoch [93/300], Train Loss: 0.006592
Validation Loss: 0.00706760
Epoch [94/300], Train Loss: 0.006735
Validation Loss: 0.00714229
Epoch [95/300], Train Loss: 0.006729
Validation Loss: 0.00707402
Epoch [96/300], Train Loss: 0.006584
Validation Loss: 0.00704407
Epoch [97/300], Train Loss: 0.006682
Validation Loss: 0.00704165
Epoch [98/300], Train Loss: 0.006682
Validation Loss: 0.00703642
Epoch [99/300], Train Loss: 0.006568
Validation Loss: 0.00703572
Epoch [100/300], Train Loss: 0.006637
Validation Loss: 0.00706194
Epoch [101/300], Train Loss: 0.006584
Validation Loss: 0.00704032
Epoch [102/300], Train Loss: 0.006547
Validation Loss: 0.00701097
Epoch [103/300], Train Loss: 0.006657
Validation Loss: 0.00699234
Epoch [104/300], Train Loss: 0.006693
Validation Loss: 0.00703697
Epoch [105/300], Train Loss: 0.006623
Validation Loss: 0.00700527
Epoch [106/300], Train Loss: 0.006579
Validation Loss: 0.00701499
Epoch [107/300], Train Loss: 0.006695
Validation Loss: 0.00697532
Epoch [108/300], Train Loss: 0.006700
Validation Loss: 0.00784604
Epoch [109/300], Train Loss: 0.006619
Validation Loss: 0.00699985
Epoch [110/300], Train Loss: 0.006698
Validation Loss: 0.00703120
Epoch [111/300], Train Loss: 0.006565
Validation Loss: 0.00696058
Epoch [112/300], Train Loss: 0.006537
Validation Loss: 0.00695664
Epoch [113/300], Train Loss: 0.006494
Validation Loss: 0.00700601
Epoch [114/300], Train Loss: 0.006620
Validation Loss: 0.00704323
Epoch [115/300], Train Loss: 0.006636
Validation Loss: 0.00701531
Epoch [116/300], Train Loss: 0.006606
Validation Loss: 0.00692955
Epoch [117/300], Train Loss: 0.006524
Validation Loss: 0.00696439
Epoch [118/300], Train Loss: 0.006476
Validation Loss: 0.00700238
Epoch [119/300], Train Loss: 0.006436
Validation Loss: 0.00696443
Epoch [120/300], Train Loss: 0.006526
Validation Loss: 0.00688227
Epoch [121/300], Train Loss: 0.006465
Validation Loss: 0.00689658
Epoch [122/300], Train Loss: 0.006486
Validation Loss: 0.00688681
Epoch [123/300], Train Loss: 0.006628
Validation Loss: 0.00686949
Epoch [124/300], Train Loss: 0.006401
Validation Loss: 0.00703068
Epoch [125/300], Train Loss: 0.006442
Validation Loss: 0.00692393
Epoch [126/300], Train Loss: 0.006466
Validation Loss: 0.00685627
Epoch [127/300], Train Loss: 0.006451
Validation Loss: 0.00691216
Epoch [128/300], Train Loss: 0.006530
Validation Loss: 0.00684812
Epoch [129/300], Train Loss: 0.006469
Validation Loss: 0.00705795
Epoch [130/300], Train Loss: 0.006617
Validation Loss: 0.00683905
Epoch [131/300], Train Loss: 0.006503
Validation Loss: 0.00683906
Epoch [132/300], Train Loss: 0.006434
Validation Loss: 0.00689851
Epoch [133/300], Train Loss: 0.006468
Validation Loss: 0.00680187
Epoch [134/300], Train Loss: 0.006332
Validation Loss: 0.00674346
Epoch [135/300], Train Loss: 0.006328
Validation Loss: 0.00672410
Epoch [136/300], Train Loss: 0.006333
Validation Loss: 0.00691523
Epoch [137/300], Train Loss: 0.006288
Validation Loss: 0.00696139
Epoch [138/300], Train Loss: 0.006323
Validation Loss: 0.00673752
Epoch [139/300], Train Loss: 0.006306
Validation Loss: 0.00668572
Epoch [140/300], Train Loss: 0.006314
Validation Loss: 0.00682874
Epoch [141/300], Train Loss: 0.006361
Validation Loss: 0.00670853
Epoch [142/300], Train Loss: 0.006484
Validation Loss: 0.00668216
Epoch [143/300], Train Loss: 0.006409
Validation Loss: 0.00668618
Epoch [144/300], Train Loss: 0.006919
Validation Loss: 0.01176516
Epoch [145/300], Train Loss: 0.007532
Validation Loss: 0.00682854
Epoch [146/300], Train Loss: 0.006466
Validation Loss: 0.00674559
Epoch [147/300], Train Loss: 0.006270
Validation Loss: 0.00669410
Epoch [148/300], Train Loss: 0.006984
Validation Loss: 0.00680150
Epoch [149/300], Train Loss: 0.006391
Validation Loss: 0.00674575
Epoch [150/300], Train Loss: 0.006284
Validation Loss: 0.00669695
Epoch [151/300], Train Loss: 0.006209
Validation Loss: 0.00669087
Epoch [152/300], Train Loss: 0.006264
Validation Loss: 0.00665986
Epoch [153/300], Train Loss: 0.006172
Validation Loss: 0.00668701
Epoch [154/300], Train Loss: 0.006186
Validation Loss: 0.00669934
Epoch [155/300], Train Loss: 0.006250
Validation Loss: 0.00663101
Epoch [156/300], Train Loss: 0.006203
Validation Loss: 0.00662357
Epoch [157/300], Train Loss: 0.006386
Validation Loss: 0.00662573
Epoch [158/300], Train Loss: 0.006162
Validation Loss: 0.00661446
Epoch [159/300], Train Loss: 0.006167
Validation Loss: 0.00661515
Epoch [160/300], Train Loss: 0.006270
Validation Loss: 0.00659487
Epoch [161/300], Train Loss: 0.006358
Validation Loss: 0.00660960
Epoch [162/300], Train Loss: 0.006226
Validation Loss: 0.00683158
Epoch [163/300], Train Loss: 0.006207
Validation Loss: 0.00659503
Epoch [164/300], Train Loss: 0.006116
Validation Loss: 0.00658632
Epoch [165/300], Train Loss: 0.006133
Validation Loss: 0.00663451
Epoch [166/300], Train Loss: 0.006368
Validation Loss: 0.00683324
Epoch [167/300], Train Loss: 0.007334
Validation Loss: 0.00674764
Epoch [168/300], Train Loss: 0.006192
Validation Loss: 0.00658748
Epoch [169/300], Train Loss: 0.006219
Validation Loss: 0.00669232
Epoch [170/300], Train Loss: 0.006113
Validation Loss: 0.00657091
Epoch [171/300], Train Loss: 0.006176
Validation Loss: 0.00662433
Epoch [172/300], Train Loss: 0.006217
Validation Loss: 0.00658471
Epoch [173/300], Train Loss: 0.006160
Validation Loss: 0.00659563
Epoch [174/300], Train Loss: 0.006250
Validation Loss: 0.00656313
Epoch [175/300], Train Loss: 0.006264
Validation Loss: 0.00655395
Epoch [176/300], Train Loss: 0.006135
Validation Loss: 0.00660801
Epoch [177/300], Train Loss: 0.006311
Validation Loss: 0.00659187
Epoch [178/300], Train Loss: 0.006245
Validation Loss: 0.00655070
Epoch [179/300], Train Loss: 0.006081
Validation Loss: 0.00655095
Epoch [180/300], Train Loss: 0.006110
Validation Loss: 0.00652170
Epoch [181/300], Train Loss: 0.006082
Validation Loss: 0.00651398
Epoch [182/300], Train Loss: 0.006114
Validation Loss: 0.00659956
Epoch [183/300], Train Loss: 0.006097
Validation Loss: 0.00650419
Epoch [184/300], Train Loss: 0.006168
Validation Loss: 0.00653149
Epoch [185/300], Train Loss: 0.006181
Validation Loss: 0.00674554
Epoch [186/300], Train Loss: 0.006263
Validation Loss: 0.00654108
Epoch [187/300], Train Loss: 0.006183
Validation Loss: 0.00651463
Epoch [188/300], Train Loss: 0.006064
Validation Loss: 0.00651373
Epoch [189/300], Train Loss: 0.006124
Validation Loss: 0.00648791
Epoch [190/300], Train Loss: 0.006180
Validation Loss: 0.00647104
Epoch [191/300], Train Loss: 0.006097
Validation Loss: 0.00647775
Epoch [192/300], Train Loss: 0.006219
Validation Loss: 0.00647124
Epoch [193/300], Train Loss: 0.006039
Validation Loss: 0.00646519
Epoch [194/300], Train Loss: 0.006163
Validation Loss: 0.00648402
Epoch [195/300], Train Loss: 0.006190
Validation Loss: 0.00654529
Epoch [196/300], Train Loss: 0.006090
Validation Loss: 0.00645099
Epoch [197/300], Train Loss: 0.006068
Validation Loss: 0.00663472
Epoch [198/300], Train Loss: 0.006121
Validation Loss: 0.00644362
Epoch [199/300], Train Loss: 0.006019
Validation Loss: 0.00644268
Epoch [200/300], Train Loss: 0.006214
Validation Loss: 0.00661694
Epoch [201/300], Train Loss: 0.006143
Validation Loss: 0.00650922
Epoch [202/300], Train Loss: 0.006063
Validation Loss: 0.00649463
Epoch [203/300], Train Loss: 0.006039
Validation Loss: 0.00643706
Epoch [204/300], Train Loss: 0.006050
Validation Loss: 0.00650150
Epoch [205/300], Train Loss: 0.006137
Validation Loss: 0.00643158
Epoch [206/300], Train Loss: 0.005997
Validation Loss: 0.00643325
Epoch [207/300], Train Loss: 0.006093
Validation Loss: 0.00645291
Epoch [208/300], Train Loss: 0.006099
Validation Loss: 0.00640110
Epoch [209/300], Train Loss: 0.006133
Validation Loss: 0.00645933
Epoch [210/300], Train Loss: 0.006035
Validation Loss: 0.00638268
Epoch [211/300], Train Loss: 0.006119
Validation Loss: 0.00638561
Epoch [212/300], Train Loss: 0.006115
Validation Loss: 0.00639853
Epoch [213/300], Train Loss: 0.006044
Validation Loss: 0.00638812
Epoch [214/300], Train Loss: 0.006147
Validation Loss: 0.00637256
Epoch [215/300], Train Loss: 0.006149
Validation Loss: 0.00635100
Epoch [216/300], Train Loss: 0.005982
Validation Loss: 0.00634123
Epoch [217/300], Train Loss: 0.005967
Validation Loss: 0.00635229
Epoch [218/300], Train Loss: 0.006059
Validation Loss: 0.00646914
Epoch [219/300], Train Loss: 0.006142
Validation Loss: 0.00632730
Epoch [220/300], Train Loss: 0.005984
Validation Loss: 0.00633387
Epoch [221/300], Train Loss: 0.005909
Validation Loss: 0.00632036
Epoch [222/300], Train Loss: 0.005928
Validation Loss: 0.00639233
Epoch [223/300], Train Loss: 0.006138
Validation Loss: 0.00631998
Epoch [224/300], Train Loss: 0.006004
Validation Loss: 0.00628504
Epoch [225/300], Train Loss: 0.006007
Validation Loss: 0.00627209
Epoch [226/300], Train Loss: 0.005997
Validation Loss: 0.00654009
Epoch [227/300], Train Loss: 0.006004
Validation Loss: 0.00666871
Epoch [228/300], Train Loss: 0.006083
Validation Loss: 0.00638039
Epoch [229/300], Train Loss: 0.005923
Validation Loss: 0.00628211
Epoch [230/300], Train Loss: 0.005802
Validation Loss: 0.00624320
Epoch [231/300], Train Loss: 0.005829
Validation Loss: 0.00624040
Epoch [232/300], Train Loss: 0.005810
Validation Loss: 0.00624701
Epoch [233/300], Train Loss: 0.005909
Validation Loss: 0.00628904
Epoch [234/300], Train Loss: 0.005872
Validation Loss: 0.00621782
Epoch [235/300], Train Loss: 0.005859
Validation Loss: 0.00636467
Epoch [236/300], Train Loss: 0.005816
Validation Loss: 0.00618882
Epoch [237/300], Train Loss: 0.005801
Validation Loss: 0.00617945
Epoch [238/300], Train Loss: 0.005733
Validation Loss: 0.00618819
Epoch [239/300], Train Loss: 0.005826
Validation Loss: 0.00616494
Epoch [240/300], Train Loss: 0.005875
Validation Loss: 0.00617609
Epoch [241/300], Train Loss: 0.005746
Validation Loss: 0.00616384
Epoch [242/300], Train Loss: 0.005827
Validation Loss: 0.00615946
Epoch [243/300], Train Loss: 0.005745
Validation Loss: 0.00613040
Epoch [244/300], Train Loss: 0.005902
Validation Loss: 0.00610543
Epoch [245/300], Train Loss: 0.005721
Validation Loss: 0.00611112
Epoch [246/300], Train Loss: 0.005846
Validation Loss: 0.00653413
Epoch [247/300], Train Loss: 0.005791
Validation Loss: 0.00615337
Epoch [248/300], Train Loss: 0.005719
Validation Loss: 0.00606179
Epoch [249/300], Train Loss: 0.005718
Validation Loss: 0.00603680
Epoch [250/300], Train Loss: 0.005728
Validation Loss: 0.00603876
Epoch [251/300], Train Loss: 0.005637
Validation Loss: 0.00603566
Epoch [252/300], Train Loss: 0.005649
Validation Loss: 0.00599087
Epoch [253/300], Train Loss: 0.005725
Validation Loss: 0.00605063
Epoch [254/300], Train Loss: 0.005663
Validation Loss: 0.00598265
Epoch [255/300], Train Loss: 0.005569
Validation Loss: 0.00600518
Epoch [256/300], Train Loss: 0.005769
Validation Loss: 0.00592913
Epoch [257/300], Train Loss: 0.005527
Validation Loss: 0.00595606
Epoch [258/300], Train Loss: 0.005607
Validation Loss: 0.00590958
Epoch [259/300], Train Loss: 0.005624
Validation Loss: 0.00591204
Epoch [260/300], Train Loss: 0.005583
Validation Loss: 0.00588299
Epoch [261/300], Train Loss: 0.005640
Validation Loss: 0.00608006
Epoch [262/300], Train Loss: 0.012608
Validation Loss: 0.01348262
Epoch [263/300], Train Loss: 0.010479
Validation Loss: 0.01035650
Epoch [264/300], Train Loss: 0.007383
Validation Loss: 0.00727437
Epoch [265/300], Train Loss: 0.006780
Validation Loss: 0.00694044
Epoch [266/300], Train Loss: 0.006577
Validation Loss: 0.00706859
Epoch [267/300], Train Loss: 0.006599
Validation Loss: 0.00700911
Epoch [268/300], Train Loss: 0.006593
Validation Loss: 0.00692878
Epoch [269/300], Train Loss: 0.006452
Validation Loss: 0.00690094
Epoch [270/300], Train Loss: 0.006422
Validation Loss: 0.00685771
Early stopping triggered

Evaluating model for: Tablet
Run 9/72 completed in 2258.97 seconds with: {'MAE': np.float32(0.5905368), 'MSE': np.float32(1.065474), 'RMSE': np.float32(1.032218), 'SAE': np.float32(0.0055265147), 'NDE': np.float32(0.23873435)}

Run 10/72: hidden=128, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Tablet
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.084437
Validation Loss: 0.02093784
Epoch [2/300], Train Loss: 0.018747
Validation Loss: 0.01886330
Epoch [3/300], Train Loss: 0.016963
Validation Loss: 0.01816497
Epoch [4/300], Train Loss: 0.016234
Validation Loss: 0.01717523
Epoch [5/300], Train Loss: 0.014586
Validation Loss: 0.01441084
Epoch [6/300], Train Loss: 0.012102
Validation Loss: 0.01269637
Epoch [7/300], Train Loss: 0.011224
Validation Loss: 0.01190949
Epoch [8/300], Train Loss: 0.010700
Validation Loss: 0.01197987
Epoch [9/300], Train Loss: 0.010379
Validation Loss: 0.01115766
Epoch [10/300], Train Loss: 0.010075
Validation Loss: 0.01067722
Epoch [11/300], Train Loss: 0.009834
Validation Loss: 0.01041839
Epoch [12/300], Train Loss: 0.009664
Validation Loss: 0.01023839
Epoch [13/300], Train Loss: 0.009440
Validation Loss: 0.00999454
Epoch [14/300], Train Loss: 0.009263
Validation Loss: 0.00985078
Epoch [15/300], Train Loss: 0.009225
Validation Loss: 0.00973229
Epoch [16/300], Train Loss: 0.008983
Validation Loss: 0.00958942
Epoch [17/300], Train Loss: 0.009087
Validation Loss: 0.00933292
Epoch [18/300], Train Loss: 0.009049
Validation Loss: 0.00947136
Epoch [19/300], Train Loss: 0.008814
Validation Loss: 0.00959291
Epoch [20/300], Train Loss: 0.008740
Validation Loss: 0.00909824
Epoch [21/300], Train Loss: 0.008681
Validation Loss: 0.00918355
Epoch [22/300], Train Loss: 0.008690
Validation Loss: 0.00910008
Epoch [23/300], Train Loss: 0.008554
Validation Loss: 0.00898003
Epoch [24/300], Train Loss: 0.008391
Validation Loss: 0.00897207
Epoch [25/300], Train Loss: 0.008693
Validation Loss: 0.00876912
Epoch [26/300], Train Loss: 0.008494
Validation Loss: 0.00876864
Epoch [27/300], Train Loss: 0.008212
Validation Loss: 0.00875369
Epoch [28/300], Train Loss: 0.008318
Validation Loss: 0.00863987
Epoch [29/300], Train Loss: 0.008227
Validation Loss: 0.00890041
Epoch [30/300], Train Loss: 0.008254
Validation Loss: 0.00856500
Epoch [31/300], Train Loss: 0.008142
Validation Loss: 0.00848707
Epoch [32/300], Train Loss: 0.008062
Validation Loss: 0.00857439
Epoch [33/300], Train Loss: 0.007937
Validation Loss: 0.00841063
Epoch [34/300], Train Loss: 0.008096
Validation Loss: 0.00876924
Epoch [35/300], Train Loss: 0.007904
Validation Loss: 0.00843395
Epoch [36/300], Train Loss: 0.007815
Validation Loss: 0.00869243
Epoch [37/300], Train Loss: 0.007852
Validation Loss: 0.00854354
Epoch [38/300], Train Loss: 0.008085
Validation Loss: 0.00828279
Epoch [39/300], Train Loss: 0.007764
Validation Loss: 0.00829013
Epoch [40/300], Train Loss: 0.007937
Validation Loss: 0.00815180
Epoch [41/300], Train Loss: 0.007854
Validation Loss: 0.00815038
Epoch [42/300], Train Loss: 0.007775
Validation Loss: 0.00813062
Epoch [43/300], Train Loss: 0.007674
Validation Loss: 0.00798698
Epoch [44/300], Train Loss: 0.007545
Validation Loss: 0.00886068
Epoch [45/300], Train Loss: 0.007593
Validation Loss: 0.00811190
Epoch [46/300], Train Loss: 0.007643
Validation Loss: 0.00789692
Epoch [47/300], Train Loss: 0.007559
Validation Loss: 0.00794208
Epoch [48/300], Train Loss: 0.007941
Validation Loss: 0.00791188
Epoch [49/300], Train Loss: 0.007449
Validation Loss: 0.00782005
Epoch [50/300], Train Loss: 0.008100
Validation Loss: 0.01226355
Epoch [51/300], Train Loss: 0.008481
Validation Loss: 0.00811836
Epoch [52/300], Train Loss: 0.007623
Validation Loss: 0.00799536
Epoch [53/300], Train Loss: 0.007563
Validation Loss: 0.00792809
Epoch [54/300], Train Loss: 0.007591
Validation Loss: 0.00783731
Epoch [55/300], Train Loss: 0.007300
Validation Loss: 0.00776655
Epoch [56/300], Train Loss: 0.007534
Validation Loss: 0.00796627
Epoch [57/300], Train Loss: 0.007465
Validation Loss: 0.00767548
Epoch [58/300], Train Loss: 0.007271
Validation Loss: 0.00771008
Epoch [59/300], Train Loss: 0.007210
Validation Loss: 0.00764821
Epoch [60/300], Train Loss: 0.007289
Validation Loss: 0.00760874
Epoch [61/300], Train Loss: 0.007232
Validation Loss: 0.00763239
Epoch [62/300], Train Loss: 0.007257
Validation Loss: 0.00762509
Epoch [63/300], Train Loss: 0.007422
Validation Loss: 0.00758016
Epoch [64/300], Train Loss: 0.007658
Validation Loss: 0.00783564
Epoch [65/300], Train Loss: 0.007400
Validation Loss: 0.00761629
Epoch [66/300], Train Loss: 0.007347
Validation Loss: 0.00759218
Epoch [67/300], Train Loss: 0.007290
Validation Loss: 0.00754093
Epoch [68/300], Train Loss: 0.007522
Validation Loss: 0.00757706
Epoch [69/300], Train Loss: 0.007110
Validation Loss: 0.00751963
Epoch [70/300], Train Loss: 0.007172
Validation Loss: 0.00764436
Epoch [71/300], Train Loss: 0.007189
Validation Loss: 0.00758696
Epoch [72/300], Train Loss: 0.007141
Validation Loss: 0.00749754
Epoch [73/300], Train Loss: 0.007100
Validation Loss: 0.00748704
Epoch [74/300], Train Loss: 0.007054
Validation Loss: 0.00756247
Epoch [75/300], Train Loss: 0.007202
Validation Loss: 0.00744730
Epoch [76/300], Train Loss: 0.007082
Validation Loss: 0.00781555
Epoch [77/300], Train Loss: 0.007296
Validation Loss: 0.00747060
Epoch [78/300], Train Loss: 0.007136
Validation Loss: 0.00743472
Epoch [79/300], Train Loss: 0.007153
Validation Loss: 0.00757125
Epoch [80/300], Train Loss: 0.007295
Validation Loss: 0.00744248
Epoch [81/300], Train Loss: 0.007113
Validation Loss: 0.00742693
Epoch [82/300], Train Loss: 0.007284
Validation Loss: 0.00749691
Epoch [83/300], Train Loss: 0.007044
Validation Loss: 0.00739464
Epoch [84/300], Train Loss: 0.007037
Validation Loss: 0.00747075
Epoch [85/300], Train Loss: 0.007120
Validation Loss: 0.00744676
Epoch [86/300], Train Loss: 0.006937
Validation Loss: 0.00739229
Epoch [87/300], Train Loss: 0.007118
Validation Loss: 0.00742072
Epoch [88/300], Train Loss: 0.006997
Validation Loss: 0.00742553
Epoch [89/300], Train Loss: 0.007067
Validation Loss: 0.00735282
Epoch [90/300], Train Loss: 0.007131
Validation Loss: 0.00737482
Epoch [91/300], Train Loss: 0.006900
Validation Loss: 0.00739486
Epoch [92/300], Train Loss: 0.006981
Validation Loss: 0.00737258
Epoch [93/300], Train Loss: 0.006882
Validation Loss: 0.00735102
Epoch [94/300], Train Loss: 0.007116
Validation Loss: 0.00735878
Epoch [95/300], Train Loss: 0.007002
Validation Loss: 0.00732283
Epoch [96/300], Train Loss: 0.006923
Validation Loss: 0.00731079
Epoch [97/300], Train Loss: 0.006973
Validation Loss: 0.00731717
Epoch [98/300], Train Loss: 0.006983
Validation Loss: 0.00729501
Epoch [99/300], Train Loss: 0.006855
Validation Loss: 0.00734176
Epoch [100/300], Train Loss: 0.006925
Validation Loss: 0.00729973
Epoch [101/300], Train Loss: 0.006897
Validation Loss: 0.00729703
Epoch [102/300], Train Loss: 0.006836
Validation Loss: 0.00728690
Epoch [103/300], Train Loss: 0.007086
Validation Loss: 0.00728599
Epoch [104/300], Train Loss: 0.006967
Validation Loss: 0.00729145
Epoch [105/300], Train Loss: 0.006940
Validation Loss: 0.00726737
Epoch [106/300], Train Loss: 0.006896
Validation Loss: 0.00727675
Epoch [107/300], Train Loss: 0.007093
Validation Loss: 0.00765004
Epoch [108/300], Train Loss: 0.007120
Validation Loss: 0.00730729
Epoch [109/300], Train Loss: 0.006828
Validation Loss: 0.00725116
Epoch [110/300], Train Loss: 0.006988
Validation Loss: 0.00734582
Epoch [111/300], Train Loss: 0.006851
Validation Loss: 0.00724568
Epoch [112/300], Train Loss: 0.006839
Validation Loss: 0.00725714
Epoch [113/300], Train Loss: 0.006796
Validation Loss: 0.00733439
Epoch [114/300], Train Loss: 0.006916
Validation Loss: 0.00728620
Epoch [115/300], Train Loss: 0.006940
Validation Loss: 0.00750997
Epoch [116/300], Train Loss: 0.006979
Validation Loss: 0.00731425
Epoch [117/300], Train Loss: 0.006912
Validation Loss: 0.00726671
Epoch [118/300], Train Loss: 0.006801
Validation Loss: 0.00728625
Epoch [119/300], Train Loss: 0.006771
Validation Loss: 0.00724581
Epoch [120/300], Train Loss: 0.006874
Validation Loss: 0.00721307
Epoch [121/300], Train Loss: 0.006806
Validation Loss: 0.00725002
Epoch [122/300], Train Loss: 0.006825
Validation Loss: 0.00720118
Epoch [123/300], Train Loss: 0.006987
Validation Loss: 0.00725221
Epoch [124/300], Train Loss: 0.006744
Validation Loss: 0.00720738
Epoch [125/300], Train Loss: 0.006797
Validation Loss: 0.00718324
Epoch [126/300], Train Loss: 0.006889
Validation Loss: 0.00718583
Epoch [127/300], Train Loss: 0.006782
Validation Loss: 0.00717270
Epoch [128/300], Train Loss: 0.006848
Validation Loss: 0.00717227
Epoch [129/300], Train Loss: 0.006781
Validation Loss: 0.00721590
Epoch [130/300], Train Loss: 0.006965
Validation Loss: 0.00737547
Epoch [131/300], Train Loss: 0.006805
Validation Loss: 0.00716596
Epoch [132/300], Train Loss: 0.006844
Validation Loss: 0.00724562
Epoch [133/300], Train Loss: 0.006872
Validation Loss: 0.00716327
Epoch [134/300], Train Loss: 0.006731
Validation Loss: 0.00715561
Epoch [135/300], Train Loss: 0.006746
Validation Loss: 0.00716047
Epoch [136/300], Train Loss: 0.006742
Validation Loss: 0.00720475
Epoch [137/300], Train Loss: 0.006694
Validation Loss: 0.00715584
Epoch [138/300], Train Loss: 0.006675
Validation Loss: 0.00716035
Epoch [139/300], Train Loss: 0.006740
Validation Loss: 0.00713349
Epoch [140/300], Train Loss: 0.006731
Validation Loss: 0.00719052
Epoch [141/300], Train Loss: 0.006799
Validation Loss: 0.00713842
Epoch [142/300], Train Loss: 0.006918
Validation Loss: 0.00711856
Epoch [143/300], Train Loss: 0.006873
Validation Loss: 0.00713253
Epoch [144/300], Train Loss: 0.006685
Validation Loss: 0.00715811
Epoch [145/300], Train Loss: 0.006696
Validation Loss: 0.00713594
Epoch [146/300], Train Loss: 0.006757
Validation Loss: 0.00709653
Epoch [147/300], Train Loss: 0.006661
Validation Loss: 0.00708799
Epoch [148/300], Train Loss: 0.006797
Validation Loss: 0.00709355
Epoch [149/300], Train Loss: 0.006745
Validation Loss: 0.00710242
Epoch [150/300], Train Loss: 0.006684
Validation Loss: 0.00708957
Epoch [151/300], Train Loss: 0.006644
Validation Loss: 0.00714418
Epoch [152/300], Train Loss: 0.006712
Validation Loss: 0.00726817
Epoch [153/300], Train Loss: 0.006632
Validation Loss: 0.00706692
Epoch [154/300], Train Loss: 0.006592
Validation Loss: 0.00714521
Epoch [155/300], Train Loss: 0.006697
Validation Loss: 0.00705145
Epoch [156/300], Train Loss: 0.006662
Validation Loss: 0.00708960
Epoch [157/300], Train Loss: 0.006826
Validation Loss: 0.00718499
Epoch [158/300], Train Loss: 0.006661
Validation Loss: 0.00707851
Epoch [159/300], Train Loss: 0.006636
Validation Loss: 0.00704644
Epoch [160/300], Train Loss: 0.006692
Validation Loss: 0.00703119
Epoch [161/300], Train Loss: 0.006718
Validation Loss: 0.00703713
Epoch [162/300], Train Loss: 0.006658
Validation Loss: 0.00713087
Epoch [163/300], Train Loss: 0.006613
Validation Loss: 0.00703498
Epoch [164/300], Train Loss: 0.006534
Validation Loss: 0.00701479
Epoch [165/300], Train Loss: 0.006562
Validation Loss: 0.00704865
Epoch [166/300], Train Loss: 0.006591
Validation Loss: 0.00698712
Epoch [167/300], Train Loss: 0.006828
Validation Loss: 0.00704331
Epoch [168/300], Train Loss: 0.006575
Validation Loss: 0.00699417
Epoch [169/300], Train Loss: 0.006622
Validation Loss: 0.00704760
Epoch [170/300], Train Loss: 0.006572
Validation Loss: 0.00696755
Epoch [171/300], Train Loss: 0.006601
Validation Loss: 0.00708373
Epoch [172/300], Train Loss: 0.006617
Validation Loss: 0.00697573
Epoch [173/300], Train Loss: 0.006554
Validation Loss: 0.00692865
Epoch [174/300], Train Loss: 0.006545
Validation Loss: 0.00712326
Epoch [175/300], Train Loss: 0.006653
Validation Loss: 0.00685210
Epoch [176/300], Train Loss: 0.006442
Validation Loss: 0.00683747
Epoch [177/300], Train Loss: 0.006442
Validation Loss: 0.00683320
Epoch [178/300], Train Loss: 0.006489
Validation Loss: 0.00683038
Epoch [179/300], Train Loss: 0.006434
Validation Loss: 0.00697851
Epoch [180/300], Train Loss: 0.006432
Validation Loss: 0.00681570
Epoch [181/300], Train Loss: 0.006435
Validation Loss: 0.00688215
Epoch [182/300], Train Loss: 0.006447
Validation Loss: 0.00681181
Epoch [183/300], Train Loss: 0.006389
Validation Loss: 0.00678060
Epoch [184/300], Train Loss: 0.006447
Validation Loss: 0.00681099
Epoch [185/300], Train Loss: 0.008875
Validation Loss: 0.00746383
Epoch [186/300], Train Loss: 0.006892
Validation Loss: 0.00721012
Epoch [187/300], Train Loss: 0.006831
Validation Loss: 0.00714657
Epoch [188/300], Train Loss: 0.006647
Validation Loss: 0.00710786
Epoch [189/300], Train Loss: 0.006711
Validation Loss: 0.00710161
Epoch [190/300], Train Loss: 0.006749
Validation Loss: 0.00708238
Epoch [191/300], Train Loss: 0.006669
Validation Loss: 0.00705712
Epoch [192/300], Train Loss: 0.006812
Validation Loss: 0.00702802
Epoch [193/300], Train Loss: 0.006545
Validation Loss: 0.00701465
Early stopping triggered

Evaluating model for: Tablet
Run 10/72 completed in 1738.09 seconds with: {'MAE': np.float32(0.6489143), 'MSE': np.float32(1.0826801), 'RMSE': np.float32(1.0405191), 'SAE': np.float32(0.0021762555), 'NDE': np.float32(0.24065429)}

Run 11/72: hidden=128, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Tablet
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.082646
Validation Loss: 0.01900653
Epoch [2/300], Train Loss: 0.017993
Validation Loss: 0.01828056
Epoch [3/300], Train Loss: 0.016689
Validation Loss: 0.01802507
Epoch [4/300], Train Loss: 0.016409
Validation Loss: 0.01751183
Epoch [5/300], Train Loss: 0.015422
Validation Loss: 0.01567863
Epoch [6/300], Train Loss: 0.012328
Validation Loss: 0.01222660
Epoch [7/300], Train Loss: 0.010756
Validation Loss: 0.01131701
Epoch [8/300], Train Loss: 0.010305
Validation Loss: 0.01127103
Epoch [9/300], Train Loss: 0.009967
Validation Loss: 0.01051413
Epoch [10/300], Train Loss: 0.009768
Validation Loss: 0.01026942
Epoch [11/300], Train Loss: 0.009630
Validation Loss: 0.01008329
Epoch [12/300], Train Loss: 0.009472
Validation Loss: 0.00989160
Epoch [13/300], Train Loss: 0.009230
Validation Loss: 0.00967612
Epoch [14/300], Train Loss: 0.009057
Validation Loss: 0.00956972
Epoch [15/300], Train Loss: 0.009003
Validation Loss: 0.00953615
Epoch [16/300], Train Loss: 0.008761
Validation Loss: 0.00925257
Epoch [17/300], Train Loss: 0.008802
Validation Loss: 0.00915316
Epoch [18/300], Train Loss: 0.008700
Validation Loss: 0.00907873
Epoch [19/300], Train Loss: 0.008450
Validation Loss: 0.00899186
Epoch [20/300], Train Loss: 0.008294
Validation Loss: 0.00872844
Epoch [21/300], Train Loss: 0.008152
Validation Loss: 0.00862327
Epoch [22/300], Train Loss: 0.008191
Validation Loss: 0.00848936
Epoch [23/300], Train Loss: 0.007972
Validation Loss: 0.00826276
Epoch [24/300], Train Loss: 0.007746
Validation Loss: 0.00822525
Epoch [25/300], Train Loss: 0.008002
Validation Loss: 0.00796428
Epoch [26/300], Train Loss: 0.007748
Validation Loss: 0.00804053
Epoch [27/300], Train Loss: 0.007522
Validation Loss: 0.00776335
Epoch [28/300], Train Loss: 0.007488
Validation Loss: 0.00793477
Epoch [29/300], Train Loss: 0.007478
Validation Loss: 0.00771146
Epoch [30/300], Train Loss: 0.007438
Validation Loss: 0.00768443
Epoch [31/300], Train Loss: 0.007469
Validation Loss: 0.00774360
Epoch [32/300], Train Loss: 0.007407
Validation Loss: 0.00762845
Epoch [33/300], Train Loss: 0.007276
Validation Loss: 0.00761418
Epoch [34/300], Train Loss: 0.007376
Validation Loss: 0.00781810
Epoch [35/300], Train Loss: 0.007223
Validation Loss: 0.00759677
Epoch [36/300], Train Loss: 0.007171
Validation Loss: 0.00759668
Epoch [37/300], Train Loss: 0.007215
Validation Loss: 0.00813256
Epoch [38/300], Train Loss: 0.007363
Validation Loss: 0.00756401
Epoch [39/300], Train Loss: 0.007181
Validation Loss: 0.00752625
Epoch [40/300], Train Loss: 0.007320
Validation Loss: 0.00754109
Epoch [41/300], Train Loss: 0.007192
Validation Loss: 0.00747937
Epoch [42/300], Train Loss: 0.007221
Validation Loss: 0.00770626
Epoch [43/300], Train Loss: 0.007212
Validation Loss: 0.00752088
Epoch [44/300], Train Loss: 0.007094
Validation Loss: 0.00791073
Epoch [45/300], Train Loss: 0.007138
Validation Loss: 0.00740930
Epoch [46/300], Train Loss: 0.007095
Validation Loss: 0.00740992
Epoch [47/300], Train Loss: 0.007101
Validation Loss: 0.00754866
Epoch [48/300], Train Loss: 0.007083
Validation Loss: 0.00740749
Epoch [49/300], Train Loss: 0.006938
Validation Loss: 0.00738334
Epoch [50/300], Train Loss: 0.007064
Validation Loss: 0.00736873
Epoch [51/300], Train Loss: 0.007034
Validation Loss: 0.00745254
Epoch [52/300], Train Loss: 0.007089
Validation Loss: 0.00730693
Epoch [53/300], Train Loss: 0.007074
Validation Loss: 0.00749041
Epoch [54/300], Train Loss: 0.007134
Validation Loss: 0.00731377
Epoch [55/300], Train Loss: 0.006883
Validation Loss: 0.00728541
Epoch [56/300], Train Loss: 0.007143
Validation Loss: 0.00742260
Epoch [57/300], Train Loss: 0.007055
Validation Loss: 0.00731641
Epoch [58/300], Train Loss: 0.006884
Validation Loss: 0.00731955
Epoch [59/300], Train Loss: 0.006845
Validation Loss: 0.00723597
Epoch [60/300], Train Loss: 0.006946
Validation Loss: 0.00724126
Epoch [61/300], Train Loss: 0.006843
Validation Loss: 0.00722289
Epoch [62/300], Train Loss: 0.006885
Validation Loss: 0.00724123
Epoch [63/300], Train Loss: 0.007029
Validation Loss: 0.00722173
Epoch [64/300], Train Loss: 0.006908
Validation Loss: 0.00735644
Epoch [65/300], Train Loss: 0.006916
Validation Loss: 0.00721645
Epoch [66/300], Train Loss: 0.006911
Validation Loss: 0.00721831
Epoch [67/300], Train Loss: 0.011297
Validation Loss: 0.01480459
Epoch [68/300], Train Loss: 0.009667
Validation Loss: 0.00807523
Epoch [69/300], Train Loss: 0.007226
Validation Loss: 0.00746612
Epoch [70/300], Train Loss: 0.007152
Validation Loss: 0.00740671
Epoch [71/300], Train Loss: 0.007040
Validation Loss: 0.00735943
Epoch [72/300], Train Loss: 0.006952
Validation Loss: 0.00733579
Epoch [73/300], Train Loss: 0.006921
Validation Loss: 0.00729453
Epoch [74/300], Train Loss: 0.006875
Validation Loss: 0.00773959
Epoch [75/300], Train Loss: 0.006967
Validation Loss: 0.00724820
Early stopping triggered

Evaluating model for: Tablet
Run 11/72 completed in 706.63 seconds with: {'MAE': np.float32(0.65279675), 'MSE': np.float32(1.1257015), 'RMSE': np.float32(1.0609908), 'SAE': np.float32(0.006666355), 'NDE': np.float32(0.24538906)}

Run 12/72: hidden=128, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Tablet
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.099295
Validation Loss: 0.02513780
Epoch [2/300], Train Loss: 0.018593
Validation Loss: 0.01841122
Epoch [3/300], Train Loss: 0.016868
Validation Loss: 0.01804921
Epoch [4/300], Train Loss: 0.016296
Validation Loss: 0.01689085
Epoch [5/300], Train Loss: 0.013541
Validation Loss: 0.01280045
Epoch [6/300], Train Loss: 0.011332
Validation Loss: 0.01175317
Epoch [7/300], Train Loss: 0.010749
Validation Loss: 0.01191255
Epoch [8/300], Train Loss: 0.010452
Validation Loss: 0.01119314
Epoch [9/300], Train Loss: 0.010193
Validation Loss: 0.01080096
Epoch [10/300], Train Loss: 0.010070
Validation Loss: 0.01057384
Epoch [11/300], Train Loss: 0.009987
Validation Loss: 0.01043406
Epoch [12/300], Train Loss: 0.009861
Validation Loss: 0.01045349
Epoch [13/300], Train Loss: 0.009664
Validation Loss: 0.01021668
Epoch [14/300], Train Loss: 0.009544
Validation Loss: 0.01010362
Epoch [15/300], Train Loss: 0.009499
Validation Loss: 0.01005284
Epoch [16/300], Train Loss: 0.009260
Validation Loss: 0.00985458
Epoch [17/300], Train Loss: 0.009352
Validation Loss: 0.00976884
Epoch [18/300], Train Loss: 0.009252
Validation Loss: 0.00967915
Epoch [19/300], Train Loss: 0.009028
Validation Loss: 0.00959585
Epoch [20/300], Train Loss: 0.008936
Validation Loss: 0.00940817
Epoch [21/300], Train Loss: 0.008867
Validation Loss: 0.00946562
Epoch [22/300], Train Loss: 0.008891
Validation Loss: 0.00925780
Epoch [23/300], Train Loss: 0.008766
Validation Loss: 0.00913116
Epoch [24/300], Train Loss: 0.008576
Validation Loss: 0.00910148
Epoch [25/300], Train Loss: 0.008964
Validation Loss: 0.00900303
Epoch [26/300], Train Loss: 0.008708
Validation Loss: 0.00895620
Epoch [27/300], Train Loss: 0.009490
Validation Loss: 0.01471499
Epoch [28/300], Train Loss: 0.010292
Validation Loss: 0.00959889
Epoch [29/300], Train Loss: 0.008780
Validation Loss: 0.00937231
Epoch [30/300], Train Loss: 0.008713
Validation Loss: 0.00923085
Epoch [31/300], Train Loss: 0.008623
Validation Loss: 0.00916882
Epoch [32/300], Train Loss: 0.008546
Validation Loss: 0.00910702
Epoch [33/300], Train Loss: 0.008367
Validation Loss: 0.00932429
Epoch [34/300], Train Loss: 0.008523
Validation Loss: 0.00997447
Epoch [35/300], Train Loss: 0.008505
Validation Loss: 0.00895735
Epoch [36/300], Train Loss: 0.008281
Validation Loss: 0.00894095
Epoch [37/300], Train Loss: 0.008346
Validation Loss: 0.00880560
Epoch [38/300], Train Loss: 0.008326
Validation Loss: 0.00895091
Epoch [39/300], Train Loss: 0.008272
Validation Loss: 0.00876534
Epoch [40/300], Train Loss: 0.008538
Validation Loss: 0.00880401
Epoch [41/300], Train Loss: 0.008351
Validation Loss: 0.00864525
Epoch [42/300], Train Loss: 0.008281
Validation Loss: 0.00862975
Epoch [43/300], Train Loss: 0.008176
Validation Loss: 0.00862018
Epoch [44/300], Train Loss: 0.008039
Validation Loss: 0.00859757
Epoch [45/300], Train Loss: 0.008094
Validation Loss: 0.00850806
Epoch [46/300], Train Loss: 0.008113
Validation Loss: 0.00845996
Epoch [47/300], Train Loss: 0.008010
Validation Loss: 0.00846732
Epoch [48/300], Train Loss: 0.008081
Validation Loss: 0.00855275
Epoch [49/300], Train Loss: 0.008026
Validation Loss: 0.00909786
Epoch [50/300], Train Loss: 0.008129
Validation Loss: 0.00847678
Epoch [51/300], Train Loss: 0.007940
Validation Loss: 0.00852553
Epoch [52/300], Train Loss: 0.007980
Validation Loss: 0.00846286
Epoch [53/300], Train Loss: 0.007986
Validation Loss: 0.00836537
Epoch [54/300], Train Loss: 0.008165
Validation Loss: 0.00829206
Epoch [55/300], Train Loss: 0.007792
Validation Loss: 0.00852642
Epoch [56/300], Train Loss: 0.008061
Validation Loss: 0.00834303
Epoch [57/300], Train Loss: 0.007942
Validation Loss: 0.00821777
Epoch [58/300], Train Loss: 0.007835
Validation Loss: 0.00853787
Epoch [59/300], Train Loss: 0.007693
Validation Loss: 0.00817609
Epoch [60/300], Train Loss: 0.007759
Validation Loss: 0.00815375
Epoch [61/300], Train Loss: 0.007653
Validation Loss: 0.00810652
Epoch [62/300], Train Loss: 0.007836
Validation Loss: 0.00828620
Epoch [63/300], Train Loss: 0.007936
Validation Loss: 0.00826228
Epoch [64/300], Train Loss: 0.007712
Validation Loss: 0.00803670
Epoch [65/300], Train Loss: 0.008266
Validation Loss: 0.01148783
Epoch [66/300], Train Loss: 0.008315
Validation Loss: 0.00805868
Epoch [67/300], Train Loss: 0.007693
Validation Loss: 0.00804282
Epoch [68/300], Train Loss: 0.007908
Validation Loss: 0.00809545
Epoch [69/300], Train Loss: 0.007742
Validation Loss: 0.00858927
Epoch [70/300], Train Loss: 0.007940
Validation Loss: 0.00809899
Epoch [71/300], Train Loss: 0.007802
Validation Loss: 0.00800043
Epoch [72/300], Train Loss: 0.008356
Validation Loss: 0.00869691
Epoch [73/300], Train Loss: 0.007710
Validation Loss: 0.00804906
Epoch [74/300], Train Loss: 0.008447
Validation Loss: 0.00827349
Epoch [75/300], Train Loss: 0.007786
Validation Loss: 0.00811877
Epoch [76/300], Train Loss: 0.007655
Validation Loss: 0.00801331
Epoch [77/300], Train Loss: 0.007745
Validation Loss: 0.00801120
Epoch [78/300], Train Loss: 0.007780
Validation Loss: 0.00804022
Epoch [79/300], Train Loss: 0.007627
Validation Loss: 0.00847812
Epoch [80/300], Train Loss: 0.007664
Validation Loss: 0.00795295
Epoch [81/300], Train Loss: 0.007593
Validation Loss: 0.00796012
Epoch [82/300], Train Loss: 0.008151
Validation Loss: 0.00798009
Epoch [83/300], Train Loss: 0.007582
Validation Loss: 0.00790928
Epoch [84/300], Train Loss: 0.007428
Validation Loss: 0.00789368
Epoch [85/300], Train Loss: 0.007556
Validation Loss: 0.00791986
Epoch [86/300], Train Loss: 0.007682
Validation Loss: 0.01894557
Epoch [87/300], Train Loss: 0.009358
Validation Loss: 0.00808592
Epoch [88/300], Train Loss: 0.007476
Validation Loss: 0.00791520
Epoch [89/300], Train Loss: 0.007535
Validation Loss: 0.00789769
Epoch [90/300], Train Loss: 0.007591
Validation Loss: 0.00790806
Epoch [91/300], Train Loss: 0.007361
Validation Loss: 0.00787073
Epoch [92/300], Train Loss: 0.007410
Validation Loss: 0.00790069
Epoch [93/300], Train Loss: 0.007322
Validation Loss: 0.00783710
Epoch [94/300], Train Loss: 0.007460
Validation Loss: 0.00783966
Epoch [95/300], Train Loss: 0.007398
Validation Loss: 0.00781944
Epoch [96/300], Train Loss: 0.007365
Validation Loss: 0.00783756
Epoch [97/300], Train Loss: 0.007394
Validation Loss: 0.00784854
Epoch [98/300], Train Loss: 0.007512
Validation Loss: 0.00780794
Epoch [99/300], Train Loss: 0.007259
Validation Loss: 0.00775832
Epoch [100/300], Train Loss: 0.007310
Validation Loss: 0.00772784
Epoch [101/300], Train Loss: 0.007310
Validation Loss: 0.00799184
Epoch [102/300], Train Loss: 0.007229
Validation Loss: 0.00766752
Epoch [103/300], Train Loss: 0.007498
Validation Loss: 0.00779301
Epoch [104/300], Train Loss: 0.007398
Validation Loss: 0.00762506
Epoch [105/300], Train Loss: 0.007283
Validation Loss: 0.00762975
Epoch [106/300], Train Loss: 0.007285
Validation Loss: 0.00761001
Epoch [107/300], Train Loss: 0.007593
Validation Loss: 0.00809628
Epoch [108/300], Train Loss: 0.007598
Validation Loss: 0.00772087
Epoch [109/300], Train Loss: 0.007259
Validation Loss: 0.00770521
Epoch [110/300], Train Loss: 0.007385
Validation Loss: 0.00780102
Epoch [111/300], Train Loss: 0.007212
Validation Loss: 0.00765749
Epoch [112/300], Train Loss: 0.007208
Validation Loss: 0.00762685
Epoch [113/300], Train Loss: 0.007360
Validation Loss: 0.00783450
Epoch [114/300], Train Loss: 0.007363
Validation Loss: 0.00774554
Epoch [115/300], Train Loss: 0.007306
Validation Loss: 0.00761185
Epoch [116/300], Train Loss: 0.007261
Validation Loss: 0.00772572
Early stopping triggered

Evaluating model for: Tablet
Run 12/72 completed in 1085.27 seconds with: {'MAE': np.float32(0.6469599), 'MSE': np.float32(1.1712712), 'RMSE': np.float32(1.0822529), 'SAE': np.float32(0.009093251), 'NDE': np.float32(0.2503066)}

Run 13/72: hidden=128, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Tablet
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.083411
Validation Loss: 0.07078859
Epoch [2/300], Train Loss: 0.049293
Validation Loss: 0.02705790
Epoch [3/300], Train Loss: 0.018992
Validation Loss: 0.01818246
Epoch [4/300], Train Loss: 0.017140
Validation Loss: 0.01715201
Epoch [5/300], Train Loss: 0.017039
Validation Loss: 0.01666147
Epoch [6/300], Train Loss: 0.016407
Validation Loss: 0.01616956
Epoch [7/300], Train Loss: 0.015383
Validation Loss: 0.01548713
Epoch [8/300], Train Loss: 0.015142
Validation Loss: 0.01470252
Epoch [9/300], Train Loss: 0.014277
Validation Loss: 0.01366301
Epoch [10/300], Train Loss: 0.013190
Validation Loss: 0.01254205
Epoch [11/300], Train Loss: 0.012335
Validation Loss: 0.01204004
Epoch [12/300], Train Loss: 0.011971
Validation Loss: 0.01191840
Epoch [13/300], Train Loss: 0.011686
Validation Loss: 0.01159889
Epoch [14/300], Train Loss: 0.011378
Validation Loss: 0.01132129
Epoch [15/300], Train Loss: 0.011191
Validation Loss: 0.01100786
Epoch [16/300], Train Loss: 0.010852
Validation Loss: 0.01062109
Epoch [17/300], Train Loss: 0.010416
Validation Loss: 0.01019656
Epoch [18/300], Train Loss: 0.010190
Validation Loss: 0.00999562
Epoch [19/300], Train Loss: 0.009848
Validation Loss: 0.00987402
Epoch [20/300], Train Loss: 0.009656
Validation Loss: 0.01007706
Epoch [21/300], Train Loss: 0.009674
Validation Loss: 0.00969231
Epoch [22/300], Train Loss: 0.009499
Validation Loss: 0.00960506
Epoch [23/300], Train Loss: 0.009534
Validation Loss: 0.00962987
Epoch [24/300], Train Loss: 0.009480
Validation Loss: 0.00956037
Epoch [25/300], Train Loss: 0.009421
Validation Loss: 0.00946453
Epoch [26/300], Train Loss: 0.009378
Validation Loss: 0.00937556
Epoch [27/300], Train Loss: 0.009108
Validation Loss: 0.00930099
Epoch [28/300], Train Loss: 0.009181
Validation Loss: 0.00927285
Epoch [29/300], Train Loss: 0.009148
Validation Loss: 0.00921608
Epoch [30/300], Train Loss: 0.009036
Validation Loss: 0.00915318
Epoch [31/300], Train Loss: 0.009127
Validation Loss: 0.00922269
Epoch [32/300], Train Loss: 0.009000
Validation Loss: 0.00908584
Epoch [33/300], Train Loss: 0.009012
Validation Loss: 0.00910669
Epoch [34/300], Train Loss: 0.008923
Validation Loss: 0.00900561
Epoch [35/300], Train Loss: 0.008773
Validation Loss: 0.00896752
Epoch [36/300], Train Loss: 0.008826
Validation Loss: 0.00904840
Epoch [37/300], Train Loss: 0.008947
Validation Loss: 0.00890580
Epoch [38/300], Train Loss: 0.008900
Validation Loss: 0.00897984
Epoch [39/300], Train Loss: 0.008747
Validation Loss: 0.00881829
Epoch [40/300], Train Loss: 0.008761
Validation Loss: 0.00880227
Epoch [41/300], Train Loss: 0.008659
Validation Loss: 0.00874946
Epoch [42/300], Train Loss: 0.008577
Validation Loss: 0.00892674
Epoch [43/300], Train Loss: 0.009158
Validation Loss: 0.00941484
Epoch [44/300], Train Loss: 0.008866
Validation Loss: 0.00870183
Epoch [45/300], Train Loss: 0.008615
Validation Loss: 0.00875887
Epoch [46/300], Train Loss: 0.008503
Validation Loss: 0.00891079
Epoch [47/300], Train Loss: 0.008633
Validation Loss: 0.00861799
Epoch [48/300], Train Loss: 0.008425
Validation Loss: 0.00863736
Epoch [49/300], Train Loss: 0.008525
Validation Loss: 0.00860708
Epoch [50/300], Train Loss: 0.008765
Validation Loss: 0.00892753
Epoch [51/300], Train Loss: 0.008347
Validation Loss: 0.00854511
Epoch [52/300], Train Loss: 0.008411
Validation Loss: 0.00858486
Epoch [53/300], Train Loss: 0.008628
Validation Loss: 0.00849923
Epoch [54/300], Train Loss: 0.008741
Validation Loss: 0.00879742
Epoch [55/300], Train Loss: 0.008417
Validation Loss: 0.00851320
Epoch [56/300], Train Loss: 0.008243
Validation Loss: 0.00869965
Epoch [57/300], Train Loss: 0.008236
Validation Loss: 0.00845738
Epoch [58/300], Train Loss: 0.008345
Validation Loss: 0.00863125
Epoch [59/300], Train Loss: 0.008314
Validation Loss: 0.00859802
Epoch [60/300], Train Loss: 0.008385
Validation Loss: 0.00842814
Epoch [61/300], Train Loss: 0.008375
Validation Loss: 0.00835476
Epoch [62/300], Train Loss: 0.008178
Validation Loss: 0.00836471
Epoch [63/300], Train Loss: 0.008200
Validation Loss: 0.00849549
Epoch [64/300], Train Loss: 0.008036
Validation Loss: 0.00838731
Epoch [65/300], Train Loss: 0.008308
Validation Loss: 0.00839898
Epoch [66/300], Train Loss: 0.008130
Validation Loss: 0.00827605
Epoch [67/300], Train Loss: 0.008012
Validation Loss: 0.00823868
Epoch [68/300], Train Loss: 0.007972
Validation Loss: 0.00822789
Epoch [69/300], Train Loss: 0.008060
Validation Loss: 0.00844130
Epoch [70/300], Train Loss: 0.008159
Validation Loss: 0.00832111
Epoch [71/300], Train Loss: 0.008091
Validation Loss: 0.00821116
Epoch [72/300], Train Loss: 0.008328
Validation Loss: 0.00834529
Epoch [73/300], Train Loss: 0.008148
Validation Loss: 0.00814563
Epoch [74/300], Train Loss: 0.007856
Validation Loss: 0.00822956
Epoch [75/300], Train Loss: 0.007905
Validation Loss: 0.00813654
Epoch [76/300], Train Loss: 0.008088
Validation Loss: 0.00818270
Epoch [77/300], Train Loss: 0.007875
Validation Loss: 0.00811152
Epoch [78/300], Train Loss: 0.007801
Validation Loss: 0.00799134
Epoch [79/300], Train Loss: 0.007937
Validation Loss: 0.00799136
Epoch [80/300], Train Loss: 0.007845
Validation Loss: 0.00795340
Epoch [81/300], Train Loss: 0.007792
Validation Loss: 0.00788768
Epoch [82/300], Train Loss: 0.007698
Validation Loss: 0.00785825
Epoch [83/300], Train Loss: 0.007754
Validation Loss: 0.00786190
Epoch [84/300], Train Loss: 0.007757
Validation Loss: 0.00783480
Epoch [85/300], Train Loss: 0.007550
Validation Loss: 0.00780075
Epoch [86/300], Train Loss: 0.007569
Validation Loss: 0.00840200
Epoch [87/300], Train Loss: 0.007601
Validation Loss: 0.00793312
Epoch [88/300], Train Loss: 0.007574
Validation Loss: 0.00774982
Epoch [89/300], Train Loss: 0.007692
Validation Loss: 0.00797329
Epoch [90/300], Train Loss: 0.007606
Validation Loss: 0.00772259
Epoch [91/300], Train Loss: 0.007698
Validation Loss: 0.00767599
Epoch [92/300], Train Loss: 0.007366
Validation Loss: 0.00762463
Epoch [93/300], Train Loss: 0.007407
Validation Loss: 0.00755380
Epoch [94/300], Train Loss: 0.007474
Validation Loss: 0.00766241
Epoch [95/300], Train Loss: 0.007314
Validation Loss: 0.00753785
Epoch [96/300], Train Loss: 0.007302
Validation Loss: 0.00760319
Epoch [97/300], Train Loss: 0.007470
Validation Loss: 0.00754481
Epoch [98/300], Train Loss: 0.007161
Validation Loss: 0.00742205
Epoch [99/300], Train Loss: 0.007235
Validation Loss: 0.00744975
Epoch [100/300], Train Loss: 0.007214
Validation Loss: 0.00748532
Epoch [101/300], Train Loss: 0.007346
Validation Loss: 0.00742079
Epoch [102/300], Train Loss: 0.007189
Validation Loss: 0.00740328
Epoch [103/300], Train Loss: 0.007125
Validation Loss: 0.00744016
Epoch [104/300], Train Loss: 0.007201
Validation Loss: 0.00749347
Epoch [105/300], Train Loss: 0.007194
Validation Loss: 0.00741337
Epoch [106/300], Train Loss: 0.007173
Validation Loss: 0.00746649
Epoch [107/300], Train Loss: 0.007384
Validation Loss: 0.00737996
Epoch [108/300], Train Loss: 0.007200
Validation Loss: 0.00753128
Epoch [109/300], Train Loss: 0.007224
Validation Loss: 0.00745288
Epoch [110/300], Train Loss: 0.007287
Validation Loss: 0.00751017
Epoch [111/300], Train Loss: 0.007495
Validation Loss: 0.00741757
Epoch [112/300], Train Loss: 0.007386
Validation Loss: 0.00731540
Epoch [113/300], Train Loss: 0.007122
Validation Loss: 0.00748106
Epoch [114/300], Train Loss: 0.007297
Validation Loss: 0.00729038
Epoch [115/300], Train Loss: 0.007255
Validation Loss: 0.00732153
Epoch [116/300], Train Loss: 0.007050
Validation Loss: 0.00728769
Epoch [117/300], Train Loss: 0.007030
Validation Loss: 0.00733415
Epoch [118/300], Train Loss: 0.006980
Validation Loss: 0.00735516
Epoch [119/300], Train Loss: 0.007090
Validation Loss: 0.00734674
Epoch [120/300], Train Loss: 0.007152
Validation Loss: 0.00738299
Epoch [121/300], Train Loss: 0.007311
Validation Loss: 0.00731771
Epoch [122/300], Train Loss: 0.007198
Validation Loss: 0.00735546
Epoch [123/300], Train Loss: 0.007167
Validation Loss: 0.00723068
Epoch [124/300], Train Loss: 0.007191
Validation Loss: 0.00757100
Epoch [125/300], Train Loss: 0.007088
Validation Loss: 0.00724873
Epoch [126/300], Train Loss: 0.007030
Validation Loss: 0.00723902
Epoch [127/300], Train Loss: 0.006978
Validation Loss: 0.00722176
Epoch [128/300], Train Loss: 0.006977
Validation Loss: 0.00737036
Epoch [129/300], Train Loss: 0.006902
Validation Loss: 0.00733411
Epoch [130/300], Train Loss: 0.007174
Validation Loss: 0.00728944
Epoch [131/300], Train Loss: 0.006957
Validation Loss: 0.00734877
Epoch [132/300], Train Loss: 0.007028
Validation Loss: 0.00721012
Epoch [133/300], Train Loss: 0.007100
Validation Loss: 0.00721154
Epoch [134/300], Train Loss: 0.007090
Validation Loss: 0.00721923
Epoch [135/300], Train Loss: 0.007076
Validation Loss: 0.00717947
Epoch [136/300], Train Loss: 0.007032
Validation Loss: 0.00720490
Epoch [137/300], Train Loss: 0.007056
Validation Loss: 0.00728286
Epoch [138/300], Train Loss: 0.006963
Validation Loss: 0.00718128
Epoch [139/300], Train Loss: 0.007119
Validation Loss: 0.00717485
Epoch [140/300], Train Loss: 0.007055
Validation Loss: 0.00715091
Epoch [141/300], Train Loss: 0.006955
Validation Loss: 0.00721101
Epoch [142/300], Train Loss: 0.007199
Validation Loss: 0.00734674
Epoch [143/300], Train Loss: 0.006870
Validation Loss: 0.00717127
Epoch [144/300], Train Loss: 0.006970
Validation Loss: 0.00720350
Epoch [145/300], Train Loss: 0.006780
Validation Loss: 0.00716035
Epoch [146/300], Train Loss: 0.006938
Validation Loss: 0.00716457
Epoch [147/300], Train Loss: 0.006868
Validation Loss: 0.00714323
Epoch [148/300], Train Loss: 0.006923
Validation Loss: 0.00724546
Epoch [149/300], Train Loss: 0.007056
Validation Loss: 0.00714603
Epoch [150/300], Train Loss: 0.006890
Validation Loss: 0.00733085
Epoch [151/300], Train Loss: 0.007004
Validation Loss: 0.00721058
Epoch [152/300], Train Loss: 0.006783
Validation Loss: 0.00717660
Epoch [153/300], Train Loss: 0.006900
Validation Loss: 0.00713563
Epoch [154/300], Train Loss: 0.006974
Validation Loss: 0.00732998
Epoch [155/300], Train Loss: 0.007067
Validation Loss: 0.00713406
Epoch [156/300], Train Loss: 0.007066
Validation Loss: 0.00713306
Epoch [157/300], Train Loss: 0.006936
Validation Loss: 0.00719115
Epoch [158/300], Train Loss: 0.006883
Validation Loss: 0.00711826
Epoch [159/300], Train Loss: 0.006888
Validation Loss: 0.00711658
Epoch [160/300], Train Loss: 0.006883
Validation Loss: 0.00714386
Epoch [161/300], Train Loss: 0.006984
Validation Loss: 0.00713120
Epoch [162/300], Train Loss: 0.006828
Validation Loss: 0.00710956
Epoch [163/300], Train Loss: 0.006947
Validation Loss: 0.00732575
Epoch [164/300], Train Loss: 0.006869
Validation Loss: 0.00735753
Epoch [165/300], Train Loss: 0.006987
Validation Loss: 0.00710770
Epoch [166/300], Train Loss: 0.006938
Validation Loss: 0.00712026
Epoch [167/300], Train Loss: 0.006828
Validation Loss: 0.00709038
Epoch [168/300], Train Loss: 0.006837
Validation Loss: 0.00719834
Epoch [169/300], Train Loss: 0.006803
Validation Loss: 0.00709577
Epoch [170/300], Train Loss: 0.006914
Validation Loss: 0.00713465
Epoch [171/300], Train Loss: 0.006770
Validation Loss: 0.00710045
Epoch [172/300], Train Loss: 0.006842
Validation Loss: 0.00717762
Epoch [173/300], Train Loss: 0.006818
Validation Loss: 0.00707742
Epoch [174/300], Train Loss: 0.006808
Validation Loss: 0.00712000
Epoch [175/300], Train Loss: 0.006907
Validation Loss: 0.00706537
Epoch [176/300], Train Loss: 0.006844
Validation Loss: 0.00754205
Epoch [177/300], Train Loss: 0.006876
Validation Loss: 0.00706834
Epoch [178/300], Train Loss: 0.006871
Validation Loss: 0.00719681
Epoch [179/300], Train Loss: 0.006813
Validation Loss: 0.00717717
Epoch [180/300], Train Loss: 0.006919
Validation Loss: 0.00710756
Epoch [181/300], Train Loss: 0.006858
Validation Loss: 0.00705928
Epoch [182/300], Train Loss: 0.006848
Validation Loss: 0.00705897
Epoch [183/300], Train Loss: 0.006826
Validation Loss: 0.00709309
Epoch [184/300], Train Loss: 0.006830
Validation Loss: 0.00720963
Epoch [185/300], Train Loss: 0.006845
Validation Loss: 0.00718655
Epoch [186/300], Train Loss: 0.007003
Validation Loss: 0.00706581
Epoch [187/300], Train Loss: 0.006819
Validation Loss: 0.00707370
Epoch [188/300], Train Loss: 0.006844
Validation Loss: 0.00704490
Epoch [189/300], Train Loss: 0.006966
Validation Loss: 0.00705259
Epoch [190/300], Train Loss: 0.006839
Validation Loss: 0.00704279
Epoch [191/300], Train Loss: 0.006882
Validation Loss: 0.00705237
Epoch [192/300], Train Loss: 0.006738
Validation Loss: 0.00713217
Epoch [193/300], Train Loss: 0.006799
Validation Loss: 0.00708851
Epoch [194/300], Train Loss: 0.007002
Validation Loss: 0.00707738
Epoch [195/300], Train Loss: 0.006805
Validation Loss: 0.00703367
Epoch [196/300], Train Loss: 0.006802
Validation Loss: 0.00702930
Epoch [197/300], Train Loss: 0.006745
Validation Loss: 0.00705160
Epoch [198/300], Train Loss: 0.006876
Validation Loss: 0.00702645
Epoch [199/300], Train Loss: 0.006920
Validation Loss: 0.00703370
Epoch [200/300], Train Loss: 0.006898
Validation Loss: 0.00705809
Epoch [201/300], Train Loss: 0.006741
Validation Loss: 0.00702132
Epoch [202/300], Train Loss: 0.006662
Validation Loss: 0.00703463
Epoch [203/300], Train Loss: 0.006858
Validation Loss: 0.00701032
Epoch [204/300], Train Loss: 0.006915
Validation Loss: 0.00703548
Epoch [205/300], Train Loss: 0.006920
Validation Loss: 0.00701279
Epoch [206/300], Train Loss: 0.006776
Validation Loss: 0.00725629
Epoch [207/300], Train Loss: 0.006887
Validation Loss: 0.00703922
Epoch [208/300], Train Loss: 0.006854
Validation Loss: 0.00707019
Epoch [209/300], Train Loss: 0.006896
Validation Loss: 0.00704639
Epoch [210/300], Train Loss: 0.006841
Validation Loss: 0.00702902
Epoch [211/300], Train Loss: 0.006732
Validation Loss: 0.00715953
Epoch [212/300], Train Loss: 0.006860
Validation Loss: 0.00702455
Epoch [213/300], Train Loss: 0.006753
Validation Loss: 0.00701094
Early stopping triggered

Evaluating model for: Tablet
Run 13/72 completed in 912.14 seconds with: {'MAE': np.float32(0.64424115), 'MSE': np.float32(1.0713761), 'RMSE': np.float32(1.035073), 'SAE': np.float32(0.01186701), 'NDE': np.float32(0.23806955)}

Run 14/72: hidden=128, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Tablet
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.085909
Validation Loss: 0.07090218
Epoch [2/300], Train Loss: 0.042106
Validation Loss: 0.02038177
Epoch [3/300], Train Loss: 0.018588
Validation Loss: 0.01748257
Epoch [4/300], Train Loss: 0.016918
Validation Loss: 0.01689579
Epoch [5/300], Train Loss: 0.016609
Validation Loss: 0.01603456
Epoch [6/300], Train Loss: 0.015576
Validation Loss: 0.01506953
Epoch [7/300], Train Loss: 0.013994
Validation Loss: 0.01342463
Epoch [8/300], Train Loss: 0.012944
Validation Loss: 0.01241246
Epoch [9/300], Train Loss: 0.012367
Validation Loss: 0.01195174
Epoch [10/300], Train Loss: 0.011951
Validation Loss: 0.01147920
Epoch [11/300], Train Loss: 0.011456
Validation Loss: 0.01112827
Epoch [12/300], Train Loss: 0.011014
Validation Loss: 0.01085943
Epoch [13/300], Train Loss: 0.010656
Validation Loss: 0.01061549
Epoch [14/300], Train Loss: 0.010462
Validation Loss: 0.01052612
Epoch [15/300], Train Loss: 0.010431
Validation Loss: 0.01037690
Epoch [16/300], Train Loss: 0.010266
Validation Loss: 0.01018738
Epoch [17/300], Train Loss: 0.010083
Validation Loss: 0.01009923
Epoch [18/300], Train Loss: 0.010166
Validation Loss: 0.01002567
Epoch [19/300], Train Loss: 0.009897
Validation Loss: 0.01002230
Epoch [20/300], Train Loss: 0.009706
Validation Loss: 0.01005914
Epoch [21/300], Train Loss: 0.009812
Validation Loss: 0.00984141
Epoch [22/300], Train Loss: 0.009676
Validation Loss: 0.00984472
Epoch [23/300], Train Loss: 0.009753
Validation Loss: 0.00975420
Epoch [24/300], Train Loss: 0.009647
Validation Loss: 0.00969967
Epoch [25/300], Train Loss: 0.009557
Validation Loss: 0.00965106
Epoch [26/300], Train Loss: 0.009556
Validation Loss: 0.00964750
Epoch [27/300], Train Loss: 0.009319
Validation Loss: 0.00951124
Epoch [28/300], Train Loss: 0.009388
Validation Loss: 0.00945303
Epoch [29/300], Train Loss: 0.009374
Validation Loss: 0.00942857
Epoch [30/300], Train Loss: 0.009258
Validation Loss: 0.00938443
Epoch [31/300], Train Loss: 0.009288
Validation Loss: 0.00927441
Epoch [32/300], Train Loss: 0.009232
Validation Loss: 0.00930418
Epoch [33/300], Train Loss: 0.009255
Validation Loss: 0.00935839
Epoch [34/300], Train Loss: 0.009162
Validation Loss: 0.00917975
Epoch [35/300], Train Loss: 0.008982
Validation Loss: 0.00912767
Epoch [36/300], Train Loss: 0.008994
Validation Loss: 0.00912810
Epoch [37/300], Train Loss: 0.009139
Validation Loss: 0.00906273
Epoch [38/300], Train Loss: 0.009108
Validation Loss: 0.00921126
Epoch [39/300], Train Loss: 0.008893
Validation Loss: 0.00911756
Epoch [40/300], Train Loss: 0.009069
Validation Loss: 0.00905412
Epoch [41/300], Train Loss: 0.008988
Validation Loss: 0.00921559
Epoch [42/300], Train Loss: 0.008845
Validation Loss: 0.00892166
Epoch [43/300], Train Loss: 0.008956
Validation Loss: 0.00889154
Epoch [44/300], Train Loss: 0.008903
Validation Loss: 0.00894567
Epoch [45/300], Train Loss: 0.008896
Validation Loss: 0.00896908
Epoch [46/300], Train Loss: 0.008825
Validation Loss: 0.00887579
Epoch [47/300], Train Loss: 0.008731
Validation Loss: 0.00888081
Epoch [48/300], Train Loss: 0.008667
Validation Loss: 0.00888236
Epoch [49/300], Train Loss: 0.008770
Validation Loss: 0.00881938
Epoch [50/300], Train Loss: 0.008969
Validation Loss: 0.00876240
Epoch [51/300], Train Loss: 0.008558
Validation Loss: 0.00879594
Epoch [52/300], Train Loss: 0.008668
Validation Loss: 0.00868499
Epoch [53/300], Train Loss: 0.008617
Validation Loss: 0.00869833
Epoch [54/300], Train Loss: 0.008795
Validation Loss: 0.00879985
Epoch [55/300], Train Loss: 0.008622
Validation Loss: 0.00860986
Epoch [56/300], Train Loss: 0.008417
Validation Loss: 0.00863127
Epoch [57/300], Train Loss: 0.008400
Validation Loss: 0.00858482
Epoch [58/300], Train Loss: 0.008557
Validation Loss: 0.00861386
Epoch [59/300], Train Loss: 0.008585
Validation Loss: 0.00884682
Epoch [60/300], Train Loss: 0.008626
Validation Loss: 0.00878461
Epoch [61/300], Train Loss: 0.008604
Validation Loss: 0.00845556
Epoch [62/300], Train Loss: 0.008447
Validation Loss: 0.00848931
Epoch [63/300], Train Loss: 0.008389
Validation Loss: 0.00895192
Epoch [64/300], Train Loss: 0.008318
Validation Loss: 0.00839558
Epoch [65/300], Train Loss: 0.008456
Validation Loss: 0.00855244
Epoch [66/300], Train Loss: 0.008310
Validation Loss: 0.00840944
Epoch [67/300], Train Loss: 0.008190
Validation Loss: 0.00833103
Epoch [68/300], Train Loss: 0.008384
Validation Loss: 0.00834763
Epoch [69/300], Train Loss: 0.008201
Validation Loss: 0.00828126
Epoch [70/300], Train Loss: 0.008362
Validation Loss: 0.00836773
Epoch [71/300], Train Loss: 0.008188
Validation Loss: 0.00852727
Epoch [72/300], Train Loss: 0.008921
Validation Loss: 0.00976798
Epoch [73/300], Train Loss: 0.008814
Validation Loss: 0.00839116
Epoch [74/300], Train Loss: 0.008085
Validation Loss: 0.00837150
Epoch [75/300], Train Loss: 0.008125
Validation Loss: 0.00832263
Epoch [76/300], Train Loss: 0.008383
Validation Loss: 0.00822362
Epoch [77/300], Train Loss: 0.008084
Validation Loss: 0.00817513
Epoch [78/300], Train Loss: 0.008265
Validation Loss: 0.00856485
Epoch [79/300], Train Loss: 0.008339
Validation Loss: 0.00846974
Epoch [80/300], Train Loss: 0.008241
Validation Loss: 0.00893308
Epoch [81/300], Train Loss: 0.008241
Validation Loss: 0.00808859
Epoch [82/300], Train Loss: 0.008901
Validation Loss: 0.01338087
Epoch [83/300], Train Loss: 0.011535
Validation Loss: 0.00948715
Epoch [84/300], Train Loss: 0.009138
Validation Loss: 0.00877974
Epoch [85/300], Train Loss: 0.008453
Validation Loss: 0.00860465
Epoch [86/300], Train Loss: 0.008414
Validation Loss: 0.00858809
Epoch [87/300], Train Loss: 0.008300
Validation Loss: 0.00859249
Epoch [88/300], Train Loss: 0.008313
Validation Loss: 0.00854883
Epoch [89/300], Train Loss: 0.008494
Validation Loss: 0.00853612
Epoch [90/300], Train Loss: 0.008323
Validation Loss: 0.00845368
Epoch [91/300], Train Loss: 0.008250
Validation Loss: 0.00850609
Early stopping triggered

Evaluating model for: Tablet
Run 14/72 completed in 402.95 seconds with: {'MAE': np.float32(0.7005206), 'MSE': np.float32(1.2794844), 'RMSE': np.float32(1.131143), 'SAE': np.float32(0.014010728), 'NDE': np.float32(0.26016587)}

Run 15/72: hidden=128, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Tablet
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.126231
Validation Loss: 0.10800443
Epoch [2/300], Train Loss: 0.065358
Validation Loss: 0.01861555
Epoch [3/300], Train Loss: 0.019537
Validation Loss: 0.01765070
Epoch [4/300], Train Loss: 0.017666
Validation Loss: 0.01760015
Epoch [5/300], Train Loss: 0.017850
Validation Loss: 0.01732670
Epoch [6/300], Train Loss: 0.017549
Validation Loss: 0.01722136
Epoch [7/300], Train Loss: 0.016949
Validation Loss: 0.01700497
Epoch [8/300], Train Loss: 0.017205
Validation Loss: 0.01682617
Epoch [9/300], Train Loss: 0.016950
Validation Loss: 0.01659401
Epoch [10/300], Train Loss: 0.016544
Validation Loss: 0.01614196
Epoch [11/300], Train Loss: 0.015749
Validation Loss: 0.01533716
Epoch [12/300], Train Loss: 0.014277
Validation Loss: 0.01347823
Epoch [13/300], Train Loss: 0.012866
Validation Loss: 0.01239004
Epoch [14/300], Train Loss: 0.011809
Validation Loss: 0.01130163
Epoch [15/300], Train Loss: 0.011261
Validation Loss: 0.01071361
Epoch [16/300], Train Loss: 0.010859
Validation Loss: 0.01059266
Epoch [17/300], Train Loss: 0.010760
Validation Loss: 0.01042694
Epoch [18/300], Train Loss: 0.010747
Validation Loss: 0.01029806
Epoch [19/300], Train Loss: 0.010383
Validation Loss: 0.01016457
Epoch [20/300], Train Loss: 0.010081
Validation Loss: 0.01011391
Epoch [21/300], Train Loss: 0.010018
Validation Loss: 0.00978000
Epoch [22/300], Train Loss: 0.009674
Validation Loss: 0.00958174
Epoch [23/300], Train Loss: 0.009605
Validation Loss: 0.00960819
Epoch [24/300], Train Loss: 0.009516
Validation Loss: 0.00957787
Epoch [25/300], Train Loss: 0.009347
Validation Loss: 0.00947161
Epoch [26/300], Train Loss: 0.009358
Validation Loss: 0.00925882
Epoch [27/300], Train Loss: 0.009098
Validation Loss: 0.00920019
Epoch [28/300], Train Loss: 0.009164
Validation Loss: 0.00910457
Epoch [29/300], Train Loss: 0.009115
Validation Loss: 0.00928335
Epoch [30/300], Train Loss: 0.009053
Validation Loss: 0.00906292
Epoch [31/300], Train Loss: 0.008991
Validation Loss: 0.00899111
Epoch [32/300], Train Loss: 0.008883
Validation Loss: 0.00892585
Epoch [33/300], Train Loss: 0.008864
Validation Loss: 0.00893387
Epoch [34/300], Train Loss: 0.008803
Validation Loss: 0.00873907
Epoch [35/300], Train Loss: 0.008610
Validation Loss: 0.00876736
Epoch [36/300], Train Loss: 0.008588
Validation Loss: 0.00869547
Epoch [37/300], Train Loss: 0.008691
Validation Loss: 0.00872483
Epoch [38/300], Train Loss: 0.008674
Validation Loss: 0.00858338
Epoch [39/300], Train Loss: 0.008375
Validation Loss: 0.00852815
Epoch [40/300], Train Loss: 0.008581
Validation Loss: 0.00847482
Epoch [41/300], Train Loss: 0.008352
Validation Loss: 0.00842862
Epoch [42/300], Train Loss: 0.008242
Validation Loss: 0.00838732
Epoch [43/300], Train Loss: 0.008295
Validation Loss: 0.00841719
Epoch [44/300], Train Loss: 0.008270
Validation Loss: 0.00844717
Epoch [45/300], Train Loss: 0.008272
Validation Loss: 0.00832457
Epoch [46/300], Train Loss: 0.008038
Validation Loss: 0.00811682
Epoch [47/300], Train Loss: 0.008036
Validation Loss: 0.00807300
Epoch [48/300], Train Loss: 0.007938
Validation Loss: 0.00806515
Epoch [49/300], Train Loss: 0.007988
Validation Loss: 0.00839371
Epoch [50/300], Train Loss: 0.008399
Validation Loss: 0.00797347
Epoch [51/300], Train Loss: 0.007814
Validation Loss: 0.00809043
Epoch [52/300], Train Loss: 0.007879
Validation Loss: 0.00795063
Epoch [53/300], Train Loss: 0.007837
Validation Loss: 0.00789505
Epoch [54/300], Train Loss: 0.007870
Validation Loss: 0.00784119
Epoch [55/300], Train Loss: 0.007754
Validation Loss: 0.00779688
Epoch [56/300], Train Loss: 0.007612
Validation Loss: 0.00814989
Epoch [57/300], Train Loss: 0.007657
Validation Loss: 0.00795104
Epoch [58/300], Train Loss: 0.007530
Validation Loss: 0.00781944
Epoch [59/300], Train Loss: 0.007498
Validation Loss: 0.00769011
Epoch [60/300], Train Loss: 0.007512
Validation Loss: 0.00786923
Epoch [61/300], Train Loss: 0.007695
Validation Loss: 0.00764621
Epoch [62/300], Train Loss: 0.007441
Validation Loss: 0.00765787
Epoch [63/300], Train Loss: 0.007508
Validation Loss: 0.00782649
Epoch [64/300], Train Loss: 0.007362
Validation Loss: 0.00759690
Epoch [65/300], Train Loss: 0.007566
Validation Loss: 0.00762775
Epoch [66/300], Train Loss: 0.007456
Validation Loss: 0.00766835
Epoch [67/300], Train Loss: 0.007379
Validation Loss: 0.00756867
Epoch [68/300], Train Loss: 0.007325
Validation Loss: 0.00765496
Epoch [69/300], Train Loss: 0.007423
Validation Loss: 0.00762570
Epoch [70/300], Train Loss: 0.007433
Validation Loss: 0.00751396
Epoch [71/300], Train Loss: 0.007320
Validation Loss: 0.00755733
Epoch [72/300], Train Loss: 0.007604
Validation Loss: 0.00745894
Epoch [73/300], Train Loss: 0.007355
Validation Loss: 0.00762316
Epoch [74/300], Train Loss: 0.007212
Validation Loss: 0.00745899
Epoch [75/300], Train Loss: 0.007321
Validation Loss: 0.00742305
Epoch [76/300], Train Loss: 0.007481
Validation Loss: 0.00751898
Epoch [77/300], Train Loss: 0.007227
Validation Loss: 0.00741335
Epoch [78/300], Train Loss: 0.007232
Validation Loss: 0.00740027
Epoch [79/300], Train Loss: 0.007366
Validation Loss: 0.00743651
Epoch [80/300], Train Loss: 0.007367
Validation Loss: 0.00772417
Epoch [81/300], Train Loss: 0.007306
Validation Loss: 0.00736039
Epoch [82/300], Train Loss: 0.007228
Validation Loss: 0.00735405
Epoch [83/300], Train Loss: 0.007231
Validation Loss: 0.00737924
Epoch [84/300], Train Loss: 0.007212
Validation Loss: 0.00768943
Epoch [85/300], Train Loss: 0.007318
Validation Loss: 0.00748581
Epoch [86/300], Train Loss: 0.007178
Validation Loss: 0.00764270
Epoch [87/300], Train Loss: 0.007166
Validation Loss: 0.00736400
Epoch [88/300], Train Loss: 0.007164
Validation Loss: 0.00739269
Epoch [89/300], Train Loss: 0.007358
Validation Loss: 0.00769711
Epoch [90/300], Train Loss: 0.007247
Validation Loss: 0.00730746
Epoch [91/300], Train Loss: 0.007154
Validation Loss: 0.00731172
Epoch [92/300], Train Loss: 0.007077
Validation Loss: 0.00737644
Epoch [93/300], Train Loss: 0.007122
Validation Loss: 0.00726640
Epoch [94/300], Train Loss: 0.007113
Validation Loss: 0.00729598
Epoch [95/300], Train Loss: 0.007060
Validation Loss: 0.00732842
Epoch [96/300], Train Loss: 0.007079
Validation Loss: 0.00729862
Epoch [97/300], Train Loss: 0.007265
Validation Loss: 0.00726324
Epoch [98/300], Train Loss: 0.007006
Validation Loss: 0.00752247
Epoch [99/300], Train Loss: 0.007111
Validation Loss: 0.00725086
Epoch [100/300], Train Loss: 0.007093
Validation Loss: 0.00727687
Epoch [101/300], Train Loss: 0.007140
Validation Loss: 0.00731816
Epoch [102/300], Train Loss: 0.007051
Validation Loss: 0.00723879
Epoch [103/300], Train Loss: 0.007001
Validation Loss: 0.00728089
Epoch [104/300], Train Loss: 0.007117
Validation Loss: 0.00722063
Epoch [105/300], Train Loss: 0.007042
Validation Loss: 0.00721657
Epoch [106/300], Train Loss: 0.007088
Validation Loss: 0.00719669
Epoch [107/300], Train Loss: 0.007137
Validation Loss: 0.00713949
Epoch [108/300], Train Loss: 0.007105
Validation Loss: 0.00725141
Epoch [109/300], Train Loss: 0.007096
Validation Loss: 0.00716154
Epoch [110/300], Train Loss: 0.007129
Validation Loss: 0.00744328
Epoch [111/300], Train Loss: 0.007160
Validation Loss: 0.00719365
Epoch [112/300], Train Loss: 0.007262
Validation Loss: 0.00711658
Epoch [113/300], Train Loss: 0.007032
Validation Loss: 0.00708027
Epoch [114/300], Train Loss: 0.007120
Validation Loss: 0.00705418
Epoch [115/300], Train Loss: 0.007101
Validation Loss: 0.00719877
Epoch [116/300], Train Loss: 0.006969
Validation Loss: 0.00707851
Epoch [117/300], Train Loss: 0.006905
Validation Loss: 0.00710026
Epoch [118/300], Train Loss: 0.006911
Validation Loss: 0.00711684
Epoch [119/300], Train Loss: 0.006984
Validation Loss: 0.00710552
Epoch [120/300], Train Loss: 0.006893
Validation Loss: 0.00708722
Epoch [121/300], Train Loss: 0.007073
Validation Loss: 0.00705196
Epoch [122/300], Train Loss: 0.007059
Validation Loss: 0.00705734
Epoch [123/300], Train Loss: 0.007690
Validation Loss: 0.00783372
Epoch [124/300], Train Loss: 0.007573
Validation Loss: 0.00722625
Epoch [125/300], Train Loss: 0.007309
Validation Loss: 0.00720251
Epoch [126/300], Train Loss: 0.007277
Validation Loss: 0.00719093
Epoch [127/300], Train Loss: 0.007226
Validation Loss: 0.00716849
Epoch [128/300], Train Loss: 0.007175
Validation Loss: 0.00718014
Epoch [129/300], Train Loss: 0.007078
Validation Loss: 0.00724468
Epoch [130/300], Train Loss: 0.007380
Validation Loss: 0.00717193
Epoch [131/300], Train Loss: 0.007100
Validation Loss: 0.00716836
Early stopping triggered

Evaluating model for: Tablet
Run 15/72 completed in 594.42 seconds with: {'MAE': np.float32(0.6590531), 'MSE': np.float32(1.1034379), 'RMSE': np.float32(1.0504465), 'SAE': np.float32(0.012574525), 'NDE': np.float32(0.24160554)}

Run 16/72: hidden=128, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Tablet
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.101256
Validation Loss: 0.08736558
Epoch [2/300], Train Loss: 0.053373
Validation Loss: 0.02261024
Epoch [3/300], Train Loss: 0.018457
Validation Loss: 0.01707850
Epoch [4/300], Train Loss: 0.016716
Validation Loss: 0.01684509
Epoch [5/300], Train Loss: 0.016954
Validation Loss: 0.01661979
Epoch [6/300], Train Loss: 0.016513
Validation Loss: 0.01641613
Epoch [7/300], Train Loss: 0.015734
Validation Loss: 0.01583634
Epoch [8/300], Train Loss: 0.015443
Validation Loss: 0.01463214
Epoch [9/300], Train Loss: 0.013590
Validation Loss: 0.01210110
Epoch [10/300], Train Loss: 0.011890
Validation Loss: 0.01102871
Epoch [11/300], Train Loss: 0.010734
Validation Loss: 0.01049031
Epoch [12/300], Train Loss: 0.010289
Validation Loss: 0.01035782
Epoch [13/300], Train Loss: 0.009983
Validation Loss: 0.01013079
Epoch [14/300], Train Loss: 0.009883
Validation Loss: 0.00999293
Epoch [15/300], Train Loss: 0.009878
Validation Loss: 0.00995748
Epoch [16/300], Train Loss: 0.009850
Validation Loss: 0.00989448
Epoch [17/300], Train Loss: 0.009689
Validation Loss: 0.00985057
Epoch [18/300], Train Loss: 0.009814
Validation Loss: 0.00984574
Epoch [19/300], Train Loss: 0.009642
Validation Loss: 0.00984153
Epoch [20/300], Train Loss: 0.009397
Validation Loss: 0.00978803
Epoch [21/300], Train Loss: 0.009564
Validation Loss: 0.00970919
Epoch [22/300], Train Loss: 0.009415
Validation Loss: 0.00966608
Epoch [23/300], Train Loss: 0.009504
Validation Loss: 0.00959748
Epoch [24/300], Train Loss: 0.009448
Validation Loss: 0.00957361
Epoch [25/300], Train Loss: 0.009358
Validation Loss: 0.00957671
Epoch [26/300], Train Loss: 0.009393
Validation Loss: 0.00951500
Epoch [27/300], Train Loss: 0.009171
Validation Loss: 0.00948550
Epoch [28/300], Train Loss: 0.009286
Validation Loss: 0.00952010
Epoch [29/300], Train Loss: 0.009290
Validation Loss: 0.00945678
Epoch [30/300], Train Loss: 0.009165
Validation Loss: 0.00937249
Epoch [31/300], Train Loss: 0.009238
Validation Loss: 0.00934263
Epoch [32/300], Train Loss: 0.009125
Validation Loss: 0.00931933
Epoch [33/300], Train Loss: 0.009190
Validation Loss: 0.00930148
Epoch [34/300], Train Loss: 0.009127
Validation Loss: 0.00924905
Epoch [35/300], Train Loss: 0.008961
Validation Loss: 0.00922380
Epoch [36/300], Train Loss: 0.008967
Validation Loss: 0.00927170
Epoch [37/300], Train Loss: 0.009109
Validation Loss: 0.00916511
Epoch [38/300], Train Loss: 0.009094
Validation Loss: 0.00926047
Epoch [39/300], Train Loss: 0.008860
Validation Loss: 0.00926889
Epoch [40/300], Train Loss: 0.009024
Validation Loss: 0.00908098
Epoch [41/300], Train Loss: 0.008937
Validation Loss: 0.00916905
Epoch [42/300], Train Loss: 0.008799
Validation Loss: 0.00906498
Epoch [43/300], Train Loss: 0.008861
Validation Loss: 0.00898596
Epoch [44/300], Train Loss: 0.008930
Validation Loss: 0.00904422
Epoch [45/300], Train Loss: 0.008831
Validation Loss: 0.00895232
Epoch [46/300], Train Loss: 0.008661
Validation Loss: 0.00890624
Epoch [47/300], Train Loss: 0.008686
Validation Loss: 0.00892633
Epoch [48/300], Train Loss: 0.008684
Validation Loss: 0.00896963
Epoch [49/300], Train Loss: 0.008741
Validation Loss: 0.00885182
Epoch [50/300], Train Loss: 0.008910
Validation Loss: 0.00887215
Epoch [51/300], Train Loss: 0.008501
Validation Loss: 0.00879751
Epoch [52/300], Train Loss: 0.008610
Validation Loss: 0.00886292
Epoch [53/300], Train Loss: 0.008594
Validation Loss: 0.00877549
Epoch [54/300], Train Loss: 0.008657
Validation Loss: 0.00894628
Epoch [55/300], Train Loss: 0.008528
Validation Loss: 0.00874539
Epoch [56/300], Train Loss: 0.008407
Validation Loss: 0.00873516
Epoch [57/300], Train Loss: 0.008397
Validation Loss: 0.00877555
Epoch [58/300], Train Loss: 0.008459
Validation Loss: 0.00877214
Epoch [59/300], Train Loss: 0.008433
Validation Loss: 0.00877466
Epoch [60/300], Train Loss: 0.008441
Validation Loss: 0.00864134
Epoch [61/300], Train Loss: 0.008512
Validation Loss: 0.00858650
Epoch [62/300], Train Loss: 0.008328
Validation Loss: 0.00859665
Epoch [63/300], Train Loss: 0.008342
Validation Loss: 0.00863743
Epoch [64/300], Train Loss: 0.008164
Validation Loss: 0.00859785
Epoch [65/300], Train Loss: 0.008423
Validation Loss: 0.00867990
Epoch [66/300], Train Loss: 0.008301
Validation Loss: 0.00857701
Epoch [67/300], Train Loss: 0.008210
Validation Loss: 0.00852802
Epoch [68/300], Train Loss: 0.008208
Validation Loss: 0.00855758
Epoch [69/300], Train Loss: 0.008299
Validation Loss: 0.00866876
Epoch [70/300], Train Loss: 0.008521
Validation Loss: 0.00860491
Epoch [71/300], Train Loss: 0.008281
Validation Loss: 0.00881768
Epoch [72/300], Train Loss: 0.008488
Validation Loss: 0.00843157
Epoch [73/300], Train Loss: 0.008181
Validation Loss: 0.00842457
Epoch [74/300], Train Loss: 0.008020
Validation Loss: 0.00841143
Epoch [75/300], Train Loss: 0.008116
Validation Loss: 0.00838572
Epoch [76/300], Train Loss: 0.008283
Validation Loss: 0.00847891
Epoch [77/300], Train Loss: 0.008039
Validation Loss: 0.00833459
Epoch [78/300], Train Loss: 0.008004
Validation Loss: 0.00829459
Epoch [79/300], Train Loss: 0.008179
Validation Loss: 0.00831991
Epoch [80/300], Train Loss: 0.008073
Validation Loss: 0.00832026
Epoch [81/300], Train Loss: 0.008009
Validation Loss: 0.00826399
Epoch [82/300], Train Loss: 0.007964
Validation Loss: 0.00823037
Epoch [83/300], Train Loss: 0.007960
Validation Loss: 0.00821711
Epoch [84/300], Train Loss: 0.007883
Validation Loss: 0.00821026
Epoch [85/300], Train Loss: 0.007794
Validation Loss: 0.00819334
Epoch [86/300], Train Loss: 0.007804
Validation Loss: 0.00824459
Epoch [87/300], Train Loss: 0.007796
Validation Loss: 0.00815691
Epoch [88/300], Train Loss: 0.007694
Validation Loss: 0.00809857
Epoch [89/300], Train Loss: 0.007961
Validation Loss: 0.00826376
Epoch [90/300], Train Loss: 0.007842
Validation Loss: 0.00810443
Epoch [91/300], Train Loss: 0.007686
Validation Loss: 0.00796665
Epoch [92/300], Train Loss: 0.007648
Validation Loss: 0.00801389
Epoch [93/300], Train Loss: 0.007634
Validation Loss: 0.00793964
Epoch [94/300], Train Loss: 0.007599
Validation Loss: 0.00788444
Epoch [95/300], Train Loss: 0.007514
Validation Loss: 0.00794911
Epoch [96/300], Train Loss: 0.007509
Validation Loss: 0.00786112
Epoch [97/300], Train Loss: 0.007733
Validation Loss: 0.00791764
Epoch [98/300], Train Loss: 0.007401
Validation Loss: 0.00798133
Epoch [99/300], Train Loss: 0.007494
Validation Loss: 0.00771949
Epoch [100/300], Train Loss: 0.007462
Validation Loss: 0.00772749
Epoch [101/300], Train Loss: 0.007482
Validation Loss: 0.00770165
Epoch [102/300], Train Loss: 0.007372
Validation Loss: 0.00765276
Epoch [103/300], Train Loss: 0.007343
Validation Loss: 0.00762205
Epoch [104/300], Train Loss: 0.007406
Validation Loss: 0.00763571
Epoch [105/300], Train Loss: 0.007325
Validation Loss: 0.00756763
Epoch [106/300], Train Loss: 0.007343
Validation Loss: 0.00761785
Epoch [107/300], Train Loss: 0.007470
Validation Loss: 0.00748746
Epoch [108/300], Train Loss: 0.007407
Validation Loss: 0.00773769
Epoch [109/300], Train Loss: 0.007365
Validation Loss: 0.00754706
Epoch [110/300], Train Loss: 0.007292
Validation Loss: 0.00764917
Epoch [111/300], Train Loss: 0.007263
Validation Loss: 0.00741837
Epoch [112/300], Train Loss: 0.007444
Validation Loss: 0.00740914
Epoch [113/300], Train Loss: 0.007240
Validation Loss: 0.00754746
Epoch [114/300], Train Loss: 0.007346
Validation Loss: 0.00738250
Epoch [115/300], Train Loss: 0.007317
Validation Loss: 0.00762758
Epoch [116/300], Train Loss: 0.007175
Validation Loss: 0.00738861
Epoch [117/300], Train Loss: 0.007122
Validation Loss: 0.00748171
Epoch [118/300], Train Loss: 0.007057
Validation Loss: 0.00740008
Epoch [119/300], Train Loss: 0.007169
Validation Loss: 0.00734201
Epoch [120/300], Train Loss: 0.007154
Validation Loss: 0.00735024
Epoch [121/300], Train Loss: 0.007252
Validation Loss: 0.00732556
Epoch [122/300], Train Loss: 0.007237
Validation Loss: 0.00732404
Epoch [123/300], Train Loss: 0.007264
Validation Loss: 0.00732763
Epoch [124/300], Train Loss: 0.007237
Validation Loss: 0.00737402
Epoch [125/300], Train Loss: 0.007133
Validation Loss: 0.00732336
Epoch [126/300], Train Loss: 0.007085
Validation Loss: 0.00739860
Epoch [127/300], Train Loss: 0.007071
Validation Loss: 0.00727514
Epoch [128/300], Train Loss: 0.007045
Validation Loss: 0.00735569
Epoch [129/300], Train Loss: 0.006981
Validation Loss: 0.00737799
Epoch [130/300], Train Loss: 0.007276
Validation Loss: 0.00726601
Epoch [131/300], Train Loss: 0.006996
Validation Loss: 0.00730539
Epoch [132/300], Train Loss: 0.007078
Validation Loss: 0.00725872
Epoch [133/300], Train Loss: 0.007202
Validation Loss: 0.00724632
Epoch [134/300], Train Loss: 0.007122
Validation Loss: 0.00741512
Epoch [135/300], Train Loss: 0.007140
Validation Loss: 0.00720518
Epoch [136/300], Train Loss: 0.007071
Validation Loss: 0.00724953
Epoch [137/300], Train Loss: 0.007125
Validation Loss: 0.00726141
Epoch [138/300], Train Loss: 0.007048
Validation Loss: 0.00726799
Epoch [139/300], Train Loss: 0.007155
Validation Loss: 0.00726945
Epoch [140/300], Train Loss: 0.007107
Validation Loss: 0.00720052
Epoch [141/300], Train Loss: 0.006999
Validation Loss: 0.00724112
Epoch [142/300], Train Loss: 0.007267
Validation Loss: 0.00722109
Epoch [143/300], Train Loss: 0.006875
Validation Loss: 0.00719870
Epoch [144/300], Train Loss: 0.006995
Validation Loss: 0.00727469
Epoch [145/300], Train Loss: 0.006846
Validation Loss: 0.00719901
Epoch [146/300], Train Loss: 0.006962
Validation Loss: 0.00721747
Epoch [147/300], Train Loss: 0.006923
Validation Loss: 0.00719242
Epoch [148/300], Train Loss: 0.006941
Validation Loss: 0.00718852
Epoch [149/300], Train Loss: 0.007079
Validation Loss: 0.00722251
Epoch [150/300], Train Loss: 0.006914
Validation Loss: 0.00723896
Epoch [151/300], Train Loss: 0.007022
Validation Loss: 0.00716815
Epoch [152/300], Train Loss: 0.006811
Validation Loss: 0.00721561
Epoch [153/300], Train Loss: 0.006925
Validation Loss: 0.00719489
Epoch [154/300], Train Loss: 0.007014
Validation Loss: 0.00737082
Epoch [155/300], Train Loss: 0.007107
Validation Loss: 0.00718966
Epoch [156/300], Train Loss: 0.007064
Validation Loss: 0.00716365
Epoch [157/300], Train Loss: 0.006953
Validation Loss: 0.00714250
Epoch [158/300], Train Loss: 0.006903
Validation Loss: 0.00716009
Epoch [159/300], Train Loss: 0.006924
Validation Loss: 0.00726222
Epoch [160/300], Train Loss: 0.006889
Validation Loss: 0.00717761
Epoch [161/300], Train Loss: 0.007029
Validation Loss: 0.00718736
Epoch [162/300], Train Loss: 0.006873
Validation Loss: 0.00727828
Epoch [163/300], Train Loss: 0.007001
Validation Loss: 0.00714889
Epoch [164/300], Train Loss: 0.006876
Validation Loss: 0.00719463
Epoch [165/300], Train Loss: 0.006983
Validation Loss: 0.00716144
Epoch [166/300], Train Loss: 0.007002
Validation Loss: 0.00714007
Epoch [167/300], Train Loss: 0.006844
Validation Loss: 0.00710802
Epoch [168/300], Train Loss: 0.006875
Validation Loss: 0.00723252
Epoch [169/300], Train Loss: 0.006803
Validation Loss: 0.00712697
Epoch [170/300], Train Loss: 0.006922
Validation Loss: 0.00712623
Epoch [171/300], Train Loss: 0.006773
Validation Loss: 0.00711895
Epoch [172/300], Train Loss: 0.006868
Validation Loss: 0.00712114
Epoch [173/300], Train Loss: 0.006844
Validation Loss: 0.00715886
Epoch [174/300], Train Loss: 0.006849
Validation Loss: 0.00713753
Epoch [175/300], Train Loss: 0.006906
Validation Loss: 0.00709068
Epoch [176/300], Train Loss: 0.006872
Validation Loss: 0.00712394
Epoch [177/300], Train Loss: 0.006996
Validation Loss: 0.00764591
Epoch [178/300], Train Loss: 0.007090
Validation Loss: 0.00727260
Epoch [179/300], Train Loss: 0.006921
Validation Loss: 0.00717141
Epoch [180/300], Train Loss: 0.006896
Validation Loss: 0.00713336
Epoch [181/300], Train Loss: 0.006866
Validation Loss: 0.00711225
Epoch [182/300], Train Loss: 0.006843
Validation Loss: 0.00708282
Epoch [183/300], Train Loss: 0.006845
Validation Loss: 0.00711856
Epoch [184/300], Train Loss: 0.006845
Validation Loss: 0.00712798
Epoch [185/300], Train Loss: 0.006838
Validation Loss: 0.00722737
Epoch [186/300], Train Loss: 0.006990
Validation Loss: 0.00714867
Epoch [187/300], Train Loss: 0.006832
Validation Loss: 0.00709526
Epoch [188/300], Train Loss: 0.006847
Validation Loss: 0.00707368
Epoch [189/300], Train Loss: 0.006907
Validation Loss: 0.00714607
Epoch [190/300], Train Loss: 0.006860
Validation Loss: 0.00707138
Epoch [191/300], Train Loss: 0.006905
Validation Loss: 0.00718102
Epoch [192/300], Train Loss: 0.006752
Validation Loss: 0.00712581
Epoch [193/300], Train Loss: 0.006796
Validation Loss: 0.00707473
Epoch [194/300], Train Loss: 0.006993
Validation Loss: 0.00712312
Epoch [195/300], Train Loss: 0.006813
Validation Loss: 0.00705612
Epoch [196/300], Train Loss: 0.006801
Validation Loss: 0.00707052
Epoch [197/300], Train Loss: 0.006716
Validation Loss: 0.00714507
Epoch [198/300], Train Loss: 0.006866
Validation Loss: 0.00705968
Epoch [199/300], Train Loss: 0.006931
Validation Loss: 0.00705701
Epoch [200/300], Train Loss: 0.006914
Validation Loss: 0.00707008
Epoch [201/300], Train Loss: 0.006747
Validation Loss: 0.00707144
Epoch [202/300], Train Loss: 0.006679
Validation Loss: 0.00714226
Epoch [203/300], Train Loss: 0.006856
Validation Loss: 0.00706945
Epoch [204/300], Train Loss: 0.006935
Validation Loss: 0.00703117
Epoch [205/300], Train Loss: 0.006898
Validation Loss: 0.00706152
Epoch [206/300], Train Loss: 0.006738
Validation Loss: 0.00706147
Epoch [207/300], Train Loss: 0.006886
Validation Loss: 0.00702474
Epoch [208/300], Train Loss: 0.006873
Validation Loss: 0.00704086
Epoch [209/300], Train Loss: 0.006869
Validation Loss: 0.00704758
Epoch [210/300], Train Loss: 0.006852
Validation Loss: 0.00710803
Epoch [211/300], Train Loss: 0.006743
Validation Loss: 0.00710649
Epoch [212/300], Train Loss: 0.006838
Validation Loss: 0.00708005
Epoch [213/300], Train Loss: 0.006758
Validation Loss: 0.00703452
Epoch [214/300], Train Loss: 0.006768
Validation Loss: 0.00700487
Epoch [215/300], Train Loss: 0.006850
Validation Loss: 0.00708599
Epoch [216/300], Train Loss: 0.006663
Validation Loss: 0.00702147
Epoch [217/300], Train Loss: 0.006793
Validation Loss: 0.00703816
Epoch [218/300], Train Loss: 0.006746
Validation Loss: 0.00711480
Epoch [219/300], Train Loss: 0.006818
Validation Loss: 0.00702380
Epoch [220/300], Train Loss: 0.006772
Validation Loss: 0.00709456
Epoch [221/300], Train Loss: 0.006732
Validation Loss: 0.00700152
Epoch [222/300], Train Loss: 0.006873
Validation Loss: 0.00704949
Epoch [223/300], Train Loss: 0.006709
Validation Loss: 0.00703536
Epoch [224/300], Train Loss: 0.006797
Validation Loss: 0.00699875
Epoch [225/300], Train Loss: 0.006684
Validation Loss: 0.00701963
Epoch [226/300], Train Loss: 0.006851
Validation Loss: 0.00700968
Epoch [227/300], Train Loss: 0.007011
Validation Loss: 0.00701756
Epoch [228/300], Train Loss: 0.006753
Validation Loss: 0.00698584
Epoch [229/300], Train Loss: 0.006862
Validation Loss: 0.00699654
Epoch [230/300], Train Loss: 0.006727
Validation Loss: 0.00705500
Epoch [231/300], Train Loss: 0.006662
Validation Loss: 0.00704839
Epoch [232/300], Train Loss: 0.006875
Validation Loss: 0.00699217
Epoch [233/300], Train Loss: 0.006755
Validation Loss: 0.00699201
Epoch [234/300], Train Loss: 0.006744
Validation Loss: 0.00703362
Epoch [235/300], Train Loss: 0.006734
Validation Loss: 0.00697252
Epoch [236/300], Train Loss: 0.006767
Validation Loss: 0.00699253
Epoch [237/300], Train Loss: 0.006570
Validation Loss: 0.00697792
Epoch [238/300], Train Loss: 0.006693
Validation Loss: 0.00700500
Epoch [239/300], Train Loss: 0.006826
Validation Loss: 0.00700346
Epoch [240/300], Train Loss: 0.006909
Validation Loss: 0.00698495
Epoch [241/300], Train Loss: 0.006744
Validation Loss: 0.00699244
Epoch [242/300], Train Loss: 0.006752
Validation Loss: 0.00697259
Epoch [243/300], Train Loss: 0.006637
Validation Loss: 0.00696190
Epoch [244/300], Train Loss: 0.006665
Validation Loss: 0.00696393
Epoch [245/300], Train Loss: 0.006587
Validation Loss: 0.00696939
Epoch [246/300], Train Loss: 0.006630
Validation Loss: 0.00695455
Epoch [247/300], Train Loss: 0.006825
Validation Loss: 0.00700515
Epoch [248/300], Train Loss: 0.006825
Validation Loss: 0.00697564
Epoch [249/300], Train Loss: 0.006664
Validation Loss: 0.00694967
Epoch [250/300], Train Loss: 0.006655
Validation Loss: 0.00696003
Epoch [251/300], Train Loss: 0.006654
Validation Loss: 0.00695012
Epoch [252/300], Train Loss: 0.006785
Validation Loss: 0.00696205
Epoch [253/300], Train Loss: 0.006722
Validation Loss: 0.00697222
Epoch [254/300], Train Loss: 0.006615
Validation Loss: 0.00694581
Epoch [255/300], Train Loss: 0.006858
Validation Loss: 0.00695890
Epoch [256/300], Train Loss: 0.006706
Validation Loss: 0.00692788
Epoch [257/300], Train Loss: 0.006669
Validation Loss: 0.00694499
Epoch [258/300], Train Loss: 0.006625
Validation Loss: 0.00695931
Epoch [259/300], Train Loss: 0.006610
Validation Loss: 0.00690142
Epoch [260/300], Train Loss: 0.006606
Validation Loss: 0.00693633
Epoch [261/300], Train Loss: 0.006776
Validation Loss: 0.00689883
Epoch [262/300], Train Loss: 0.006574
Validation Loss: 0.00692847
Epoch [263/300], Train Loss: 0.006588
Validation Loss: 0.00691707
Epoch [264/300], Train Loss: 0.006606
Validation Loss: 0.00690469
Epoch [265/300], Train Loss: 0.006568
Validation Loss: 0.00691093
Epoch [266/300], Train Loss: 0.006658
Validation Loss: 0.00687117
Epoch [267/300], Train Loss: 0.006675
Validation Loss: 0.00687291
Epoch [268/300], Train Loss: 0.006629
Validation Loss: 0.00687656
Epoch [269/300], Train Loss: 0.006694
Validation Loss: 0.00686254
Epoch [270/300], Train Loss: 0.006619
Validation Loss: 0.00688259
Epoch [271/300], Train Loss: 0.006492
Validation Loss: 0.00685186
Epoch [272/300], Train Loss: 0.006616
Validation Loss: 0.00684404
Epoch [273/300], Train Loss: 0.006537
Validation Loss: 0.00689290
Epoch [274/300], Train Loss: 0.006636
Validation Loss: 0.00683651
Epoch [275/300], Train Loss: 0.006570
Validation Loss: 0.00682381
Epoch [276/300], Train Loss: 0.006554
Validation Loss: 0.00684538
Epoch [277/300], Train Loss: 0.006453
Validation Loss: 0.00683568
Epoch [278/300], Train Loss: 0.006668
Validation Loss: 0.00684703
Epoch [279/300], Train Loss: 0.006553
Validation Loss: 0.00682807
Epoch [280/300], Train Loss: 0.006488
Validation Loss: 0.00678257
Epoch [281/300], Train Loss: 0.006625
Validation Loss: 0.00678143
Epoch [282/300], Train Loss: 0.008800
Validation Loss: 0.01193074
Epoch [283/300], Train Loss: 0.010085
Validation Loss: 0.00911763
Epoch [284/300], Train Loss: 0.008283
Validation Loss: 0.00789858
Epoch [285/300], Train Loss: 0.007479
Validation Loss: 0.00750210
Epoch [286/300], Train Loss: 0.007041
Validation Loss: 0.00719887
Epoch [287/300], Train Loss: 0.007056
Validation Loss: 0.00736063
Epoch [288/300], Train Loss: 0.006990
Validation Loss: 0.00710551
Epoch [289/300], Train Loss: 0.007041
Validation Loss: 0.00708229
Epoch [290/300], Train Loss: 0.006891
Validation Loss: 0.00704182
Epoch [291/300], Train Loss: 0.006918
Validation Loss: 0.00701575
Early stopping triggered

Evaluating model for: Tablet
Run 16/72 completed in 1402.43 seconds with: {'MAE': np.float32(0.6540105), 'MSE': np.float32(1.066873), 'RMSE': np.float32(1.0328954), 'SAE': np.float32(0.0032960013), 'NDE': np.float32(0.23756868)}

Run 17/72: hidden=128, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Tablet
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.123536
Validation Loss: 0.10774147
Epoch [2/300], Train Loss: 0.090151
Validation Loss: 0.06876350
Epoch [3/300], Train Loss: 0.038952
Validation Loss: 0.01934579
Epoch [4/300], Train Loss: 0.018878
Validation Loss: 0.01604638
Epoch [5/300], Train Loss: 0.017818
Validation Loss: 0.01563729
Epoch [6/300], Train Loss: 0.017427
Validation Loss: 0.01540518
Epoch [7/300], Train Loss: 0.017070
Validation Loss: 0.01495798
Epoch [8/300], Train Loss: 0.016740
Validation Loss: 0.01466038
Epoch [9/300], Train Loss: 0.016483
Validation Loss: 0.01434845
Epoch [10/300], Train Loss: 0.016107
Validation Loss: 0.01398634
Epoch [11/300], Train Loss: 0.015704
Validation Loss: 0.01357349
Epoch [12/300], Train Loss: 0.015170
Validation Loss: 0.01289684
Epoch [13/300], Train Loss: 0.014451
Validation Loss: 0.01206991
Epoch [14/300], Train Loss: 0.013315
Validation Loss: 0.01105760
Epoch [15/300], Train Loss: 0.012207
Validation Loss: 0.00979729
Epoch [16/300], Train Loss: 0.011031
Validation Loss: 0.00994320
Epoch [17/300], Train Loss: 0.011696
Validation Loss: 0.01020437
Epoch [18/300], Train Loss: 0.011065
Validation Loss: 0.00891555
Epoch [19/300], Train Loss: 0.010281
Validation Loss: 0.00863917
Epoch [20/300], Train Loss: 0.014229
Validation Loss: 0.01223237
Epoch [21/300], Train Loss: 0.011324
Validation Loss: 0.00855622
Epoch [22/300], Train Loss: 0.010236
Validation Loss: 0.00839297
Epoch [23/300], Train Loss: 0.010230
Validation Loss: 0.00831101
Epoch [24/300], Train Loss: 0.011373
Validation Loss: 0.01041020
Epoch [25/300], Train Loss: 0.011021
Validation Loss: 0.00851058
Epoch [26/300], Train Loss: 0.010165
Validation Loss: 0.00860509
Epoch [27/300], Train Loss: 0.010007
Validation Loss: 0.00829775
Epoch [28/300], Train Loss: 0.009980
Validation Loss: 0.00868364
Epoch [29/300], Train Loss: 0.009944
Validation Loss: 0.00834216
Epoch [30/300], Train Loss: 0.009985
Validation Loss: 0.00823429
Epoch [31/300], Train Loss: 0.009772
Validation Loss: 0.00808593
Epoch [32/300], Train Loss: 0.010285
Validation Loss: 0.00842111
Epoch [33/300], Train Loss: 0.009783
Validation Loss: 0.00795792
Epoch [34/300], Train Loss: 0.009689
Validation Loss: 0.00814489
Epoch [35/300], Train Loss: 0.009731
Validation Loss: 0.00817728
Epoch [36/300], Train Loss: 0.009597
Validation Loss: 0.00779632
Epoch [37/300], Train Loss: 0.011576
Validation Loss: 0.01022391
Epoch [38/300], Train Loss: 0.011261
Validation Loss: 0.00818687
Epoch [39/300], Train Loss: 0.009651
Validation Loss: 0.00780335
Epoch [40/300], Train Loss: 0.009850
Validation Loss: 0.00775182
Epoch [41/300], Train Loss: 0.009975
Validation Loss: 0.00847759
Epoch [42/300], Train Loss: 0.009620
Validation Loss: 0.00848406
Epoch [43/300], Train Loss: 0.009709
Validation Loss: 0.00815016
Epoch [44/300], Train Loss: 0.009508
Validation Loss: 0.00764042
Epoch [45/300], Train Loss: 0.009425
Validation Loss: 0.00764769
Epoch [46/300], Train Loss: 0.009595
Validation Loss: 0.00920073
Epoch [47/300], Train Loss: 0.009780
Validation Loss: 0.00788098
Epoch [48/300], Train Loss: 0.009490
Validation Loss: 0.00813873
Epoch [49/300], Train Loss: 0.009430
Validation Loss: 0.00761610
Epoch [50/300], Train Loss: 0.009463
Validation Loss: 0.00770924
Epoch [51/300], Train Loss: 0.010412
Validation Loss: 0.00797901
Epoch [52/300], Train Loss: 0.009404
Validation Loss: 0.00782781
Epoch [53/300], Train Loss: 0.009283
Validation Loss: 0.00753761
Epoch [54/300], Train Loss: 0.009262
Validation Loss: 0.00756384
Epoch [55/300], Train Loss: 0.009323
Validation Loss: 0.00796753
Epoch [56/300], Train Loss: 0.009291
Validation Loss: 0.00752843
Epoch [57/300], Train Loss: 0.009274
Validation Loss: 0.00825719
Epoch [58/300], Train Loss: 0.009356
Validation Loss: 0.00752357
Epoch [59/300], Train Loss: 0.009201
Validation Loss: 0.00747345
Epoch [60/300], Train Loss: 0.009157
Validation Loss: 0.00764408
Epoch [61/300], Train Loss: 0.009148
Validation Loss: 0.00752474
Epoch [62/300], Train Loss: 0.009180
Validation Loss: 0.00760562
Epoch [63/300], Train Loss: 0.009154
Validation Loss: 0.00741817
Epoch [64/300], Train Loss: 0.009091
Validation Loss: 0.00738761
Epoch [65/300], Train Loss: 0.009101
Validation Loss: 0.00745757
Epoch [66/300], Train Loss: 0.011122
Validation Loss: 0.00912517
Epoch [67/300], Train Loss: 0.010206
Validation Loss: 0.00831079
Epoch [68/300], Train Loss: 0.009454
Validation Loss: 0.00825382
Epoch [69/300], Train Loss: 0.009460
Validation Loss: 0.01439802
Epoch [70/300], Train Loss: 0.015014
Validation Loss: 0.01126155
Epoch [71/300], Train Loss: 0.012914
Validation Loss: 0.01051581
Epoch [72/300], Train Loss: 0.011719
Validation Loss: 0.00938138
Epoch [73/300], Train Loss: 0.010545
Validation Loss: 0.00852943
Epoch [74/300], Train Loss: 0.009803
Validation Loss: 0.00812533
Early stopping triggered

Evaluating model for: Tablet
Run 17/72 completed in 329.04 seconds with: {'MAE': np.float32(0.75312626), 'MSE': np.float32(1.2266454), 'RMSE': np.float32(1.1075402), 'SAE': np.float32(0.019519811), 'NDE': np.float32(0.25266314)}

Run 18/72: hidden=128, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Tablet
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.089042
Validation Loss: 0.06918995
Epoch [2/300], Train Loss: 0.046002
Validation Loss: 0.01758941
Epoch [3/300], Train Loss: 0.018131
Validation Loss: 0.01559282
Epoch [4/300], Train Loss: 0.016707
Validation Loss: 0.01472522
Epoch [5/300], Train Loss: 0.016226
Validation Loss: 0.01414323
Epoch [6/300], Train Loss: 0.015713
Validation Loss: 0.01362438
Epoch [7/300], Train Loss: 0.014938
Validation Loss: 0.01261056
Epoch [8/300], Train Loss: 0.013708
Validation Loss: 0.01122554
Epoch [9/300], Train Loss: 0.012365
Validation Loss: 0.01059045
Epoch [10/300], Train Loss: 0.011884
Validation Loss: 0.01019724
Epoch [11/300], Train Loss: 0.011545
Validation Loss: 0.00985933
Epoch [12/300], Train Loss: 0.011187
Validation Loss: 0.00948374
Epoch [13/300], Train Loss: 0.010797
Validation Loss: 0.00912269
Epoch [14/300], Train Loss: 0.010454
Validation Loss: 0.00871857
Epoch [15/300], Train Loss: 0.010254
Validation Loss: 0.00851781
Epoch [16/300], Train Loss: 0.010038
Validation Loss: 0.00828077
Epoch [17/300], Train Loss: 0.009812
Validation Loss: 0.00804021
Epoch [18/300], Train Loss: 0.009684
Validation Loss: 0.00790971
Epoch [19/300], Train Loss: 0.009540
Validation Loss: 0.00782833
Epoch [20/300], Train Loss: 0.009398
Validation Loss: 0.00774427
Epoch [21/300], Train Loss: 0.009315
Validation Loss: 0.00764584
Epoch [22/300], Train Loss: 0.009184
Validation Loss: 0.00768786
Epoch [23/300], Train Loss: 0.009178
Validation Loss: 0.00755127
Epoch [24/300], Train Loss: 0.009052
Validation Loss: 0.00765747
Epoch [25/300], Train Loss: 0.009007
Validation Loss: 0.00742532
Epoch [26/300], Train Loss: 0.008944
Validation Loss: 0.00742847
Epoch [27/300], Train Loss: 0.009100
Validation Loss: 0.00744365
Epoch [28/300], Train Loss: 0.008928
Validation Loss: 0.00760323
Epoch [29/300], Train Loss: 0.009015
Validation Loss: 0.00734727
Epoch [30/300], Train Loss: 0.008856
Validation Loss: 0.00726479
Epoch [31/300], Train Loss: 0.008762
Validation Loss: 0.00724631
Epoch [32/300], Train Loss: 0.008699
Validation Loss: 0.00725536
Epoch [33/300], Train Loss: 0.008726
Validation Loss: 0.00725232
Epoch [34/300], Train Loss: 0.008698
Validation Loss: 0.00718995
Epoch [35/300], Train Loss: 0.008698
Validation Loss: 0.00718735
Epoch [36/300], Train Loss: 0.008620
Validation Loss: 0.00716484
Epoch [37/300], Train Loss: 0.008612
Validation Loss: 0.00716717
Epoch [38/300], Train Loss: 0.008580
Validation Loss: 0.00712520
Epoch [39/300], Train Loss: 0.008529
Validation Loss: 0.00710042
Epoch [40/300], Train Loss: 0.008525
Validation Loss: 0.00709801
Epoch [41/300], Train Loss: 0.008586
Validation Loss: 0.00706503
Epoch [42/300], Train Loss: 0.008482
Validation Loss: 0.00703629
Epoch [43/300], Train Loss: 0.008945
Validation Loss: 0.00894143
Epoch [44/300], Train Loss: 0.009024
Validation Loss: 0.00709694
Epoch [45/300], Train Loss: 0.008479
Validation Loss: 0.00705298
Epoch [46/300], Train Loss: 0.008409
Validation Loss: 0.00699941
Epoch [47/300], Train Loss: 0.008553
Validation Loss: 0.00701712
Epoch [48/300], Train Loss: 0.008400
Validation Loss: 0.00696374
Epoch [49/300], Train Loss: 0.008367
Validation Loss: 0.00695081
Epoch [50/300], Train Loss: 0.008367
Validation Loss: 0.00691720
Epoch [51/300], Train Loss: 0.008365
Validation Loss: 0.00691367
Epoch [52/300], Train Loss: 0.008376
Validation Loss: 0.00712577
Epoch [53/300], Train Loss: 0.008361
Validation Loss: 0.00692923
Epoch [54/300], Train Loss: 0.008279
Validation Loss: 0.00690751
Epoch [55/300], Train Loss: 0.008338
Validation Loss: 0.00684364
Epoch [56/300], Train Loss: 0.008298
Validation Loss: 0.00684563
Epoch [57/300], Train Loss: 0.008248
Validation Loss: 0.00681664
Epoch [58/300], Train Loss: 0.008225
Validation Loss: 0.00679546
Epoch [59/300], Train Loss: 0.008180
Validation Loss: 0.00679946
Epoch [60/300], Train Loss: 0.008182
Validation Loss: 0.00694053
Epoch [61/300], Train Loss: 0.008204
Validation Loss: 0.00689387
Epoch [62/300], Train Loss: 0.008169
Validation Loss: 0.00679813
Epoch [63/300], Train Loss: 0.008199
Validation Loss: 0.00672334
Epoch [64/300], Train Loss: 0.008094
Validation Loss: 0.00680211
Epoch [65/300], Train Loss: 0.008169
Validation Loss: 0.00668339
Epoch [66/300], Train Loss: 0.008086
Validation Loss: 0.00671464
Epoch [67/300], Train Loss: 0.008034
Validation Loss: 0.00665812
Epoch [68/300], Train Loss: 0.008057
Validation Loss: 0.00664939
Epoch [69/300], Train Loss: 0.008039
Validation Loss: 0.00663220
Epoch [70/300], Train Loss: 0.008198
Validation Loss: 0.00667952
Epoch [71/300], Train Loss: 0.008011
Validation Loss: 0.00662026
Epoch [72/300], Train Loss: 0.008033
Validation Loss: 0.00663557
Epoch [73/300], Train Loss: 0.007954
Validation Loss: 0.00665787
Epoch [74/300], Train Loss: 0.007928
Validation Loss: 0.00657577
Epoch [75/300], Train Loss: 0.008252
Validation Loss: 0.00656989
Epoch [76/300], Train Loss: 0.007909
Validation Loss: 0.00650924
Epoch [77/300], Train Loss: 0.008353
Validation Loss: 0.00696997
Epoch [78/300], Train Loss: 0.007912
Validation Loss: 0.00644962
Epoch [79/300], Train Loss: 0.007868
Validation Loss: 0.00646407
Epoch [80/300], Train Loss: 0.007782
Validation Loss: 0.00632857
Epoch [81/300], Train Loss: 0.007732
Validation Loss: 0.00799126
Epoch [82/300], Train Loss: 0.008171
Validation Loss: 0.00638416
Epoch [83/300], Train Loss: 0.007650
Validation Loss: 0.00633732
Epoch [84/300], Train Loss: 0.007597
Validation Loss: 0.00630337
Epoch [85/300], Train Loss: 0.007631
Validation Loss: 0.00632259
Epoch [86/300], Train Loss: 0.007554
Validation Loss: 0.00624650
Epoch [87/300], Train Loss: 0.007546
Validation Loss: 0.00625645
Epoch [88/300], Train Loss: 0.007515
Validation Loss: 0.00621329
Epoch [89/300], Train Loss: 0.007504
Validation Loss: 0.00609700
Epoch [90/300], Train Loss: 0.007397
Validation Loss: 0.00604611
Epoch [91/300], Train Loss: 0.007380
Validation Loss: 0.00608108
Epoch [92/300], Train Loss: 0.007329
Validation Loss: 0.00601306
Epoch [93/300], Train Loss: 0.007313
Validation Loss: 0.00607063
Epoch [94/300], Train Loss: 0.007314
Validation Loss: 0.00601739
Epoch [95/300], Train Loss: 0.007292
Validation Loss: 0.00603319
Epoch [96/300], Train Loss: 0.007235
Validation Loss: 0.00588377
Epoch [97/300], Train Loss: 0.007225
Validation Loss: 0.00603033
Epoch [98/300], Train Loss: 0.007230
Validation Loss: 0.00587225
Epoch [99/300], Train Loss: 0.007183
Validation Loss: 0.00587706
Epoch [100/300], Train Loss: 0.007173
Validation Loss: 0.00585620
Epoch [101/300], Train Loss: 0.007233
Validation Loss: 0.00707254
Epoch [102/300], Train Loss: 0.007702
Validation Loss: 0.00605585
Epoch [103/300], Train Loss: 0.007258
Validation Loss: 0.00586233
Epoch [104/300], Train Loss: 0.007194
Validation Loss: 0.00584125
Epoch [105/300], Train Loss: 0.007182
Validation Loss: 0.00584851
Epoch [106/300], Train Loss: 0.007138
Validation Loss: 0.00582972
Epoch [107/300], Train Loss: 0.007131
Validation Loss: 0.00580701
Epoch [108/300], Train Loss: 0.007186
Validation Loss: 0.00582018
Epoch [109/300], Train Loss: 0.007193
Validation Loss: 0.00583055
Epoch [110/300], Train Loss: 0.007141
Validation Loss: 0.00583549
Epoch [111/300], Train Loss: 0.007105
Validation Loss: 0.00581250
Epoch [112/300], Train Loss: 0.007092
Validation Loss: 0.00579506
Epoch [113/300], Train Loss: 0.007132
Validation Loss: 0.00580843
Epoch [114/300], Train Loss: 0.007143
Validation Loss: 0.00584842
Epoch [115/300], Train Loss: 0.007105
Validation Loss: 0.00579571
Epoch [116/300], Train Loss: 0.007145
Validation Loss: 0.00582780
Epoch [117/300], Train Loss: 0.007093
Validation Loss: 0.00582068
Epoch [118/300], Train Loss: 0.007088
Validation Loss: 0.00581058
Epoch [119/300], Train Loss: 0.007084
Validation Loss: 0.00588972
Epoch [120/300], Train Loss: 0.007100
Validation Loss: 0.00576394
Epoch [121/300], Train Loss: 0.007064
Validation Loss: 0.00575239
Epoch [122/300], Train Loss: 0.007126
Validation Loss: 0.00574011
Epoch [123/300], Train Loss: 0.007079
Validation Loss: 0.00572112
Epoch [124/300], Train Loss: 0.007048
Validation Loss: 0.00573811
Epoch [125/300], Train Loss: 0.007044
Validation Loss: 0.00571774
Epoch [126/300], Train Loss: 0.007044
Validation Loss: 0.00570927
Epoch [127/300], Train Loss: 0.007050
Validation Loss: 0.00570648
Epoch [128/300], Train Loss: 0.007050
Validation Loss: 0.00566755
Epoch [129/300], Train Loss: 0.007013
Validation Loss: 0.00566124
Epoch [130/300], Train Loss: 0.007006
Validation Loss: 0.00564183
Epoch [131/300], Train Loss: 0.007044
Validation Loss: 0.00579211
Epoch [132/300], Train Loss: 0.007019
Validation Loss: 0.00564950
Epoch [133/300], Train Loss: 0.006966
Validation Loss: 0.00562672
Epoch [134/300], Train Loss: 0.007026
Validation Loss: 0.00610054
Epoch [135/300], Train Loss: 0.007164
Validation Loss: 0.00583671
Epoch [136/300], Train Loss: 0.007091
Validation Loss: 0.00581076
Epoch [137/300], Train Loss: 0.008559
Validation Loss: 0.01004421
Epoch [138/300], Train Loss: 0.013107
Validation Loss: 0.01461633
Epoch [139/300], Train Loss: 0.015795
Validation Loss: 0.01400108
Epoch [140/300], Train Loss: 0.015619
Validation Loss: 0.01393110
Epoch [141/300], Train Loss: 0.015588
Validation Loss: 0.01387031
Epoch [142/300], Train Loss: 0.015476
Validation Loss: 0.01380428
Epoch [143/300], Train Loss: 0.015381
Validation Loss: 0.01369125
Early stopping triggered

Evaluating model for: Tablet
Run 18/72 completed in 683.91 seconds with: {'MAE': np.float32(1.1143724), 'MSE': np.float32(2.2796152), 'RMSE': np.float32(1.5098394), 'SAE': np.float32(0.01446301), 'NDE': np.float32(0.34443977)}

Run 19/72: hidden=128, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Tablet
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.087136
Validation Loss: 0.07136221
Epoch [2/300], Train Loss: 0.049030
Validation Loss: 0.01615619
Epoch [3/300], Train Loss: 0.018272
Validation Loss: 0.01520631
Epoch [4/300], Train Loss: 0.016660
Validation Loss: 0.01496514
Epoch [5/300], Train Loss: 0.016460
Validation Loss: 0.01459987
Epoch [6/300], Train Loss: 0.016265
Validation Loss: 0.01449700
Epoch [7/300], Train Loss: 0.016022
Validation Loss: 0.01415304
Epoch [8/300], Train Loss: 0.015683
Validation Loss: 0.01374354
Epoch [9/300], Train Loss: 0.015138
Validation Loss: 0.01295295
Epoch [10/300], Train Loss: 0.013901
Validation Loss: 0.01121042
Epoch [11/300], Train Loss: 0.012111
Validation Loss: 0.01033194
Epoch [12/300], Train Loss: 0.011329
Validation Loss: 0.00944402
Epoch [13/300], Train Loss: 0.010576
Validation Loss: 0.00869045
Epoch [14/300], Train Loss: 0.010102
Validation Loss: 0.00834623
Epoch [15/300], Train Loss: 0.009945
Validation Loss: 0.00814546
Epoch [16/300], Train Loss: 0.009747
Validation Loss: 0.00813923
Epoch [17/300], Train Loss: 0.009651
Validation Loss: 0.00797894
Epoch [18/300], Train Loss: 0.009578
Validation Loss: 0.00786154
Epoch [19/300], Train Loss: 0.009472
Validation Loss: 0.00783145
Epoch [20/300], Train Loss: 0.009371
Validation Loss: 0.00775282
Epoch [21/300], Train Loss: 0.009327
Validation Loss: 0.00765942
Epoch [22/300], Train Loss: 0.009199
Validation Loss: 0.00772713
Epoch [23/300], Train Loss: 0.009228
Validation Loss: 0.00757761
Epoch [24/300], Train Loss: 0.009139
Validation Loss: 0.00774260
Epoch [25/300], Train Loss: 0.009110
Validation Loss: 0.00758611
Epoch [26/300], Train Loss: 0.009122
Validation Loss: 0.00757163
Epoch [27/300], Train Loss: 0.009043
Validation Loss: 0.00749743
Epoch [28/300], Train Loss: 0.009039
Validation Loss: 0.00746955
Epoch [29/300], Train Loss: 0.008915
Validation Loss: 0.00766445
Epoch [30/300], Train Loss: 0.009204
Validation Loss: 0.00759969
Epoch [31/300], Train Loss: 0.008895
Validation Loss: 0.00761738
Epoch [32/300], Train Loss: 0.008891
Validation Loss: 0.00775916
Epoch [33/300], Train Loss: 0.009233
Validation Loss: 0.00759173
Epoch [34/300], Train Loss: 0.008940
Validation Loss: 0.00744536
Epoch [35/300], Train Loss: 0.008859
Validation Loss: 0.00737737
Epoch [36/300], Train Loss: 0.008750
Validation Loss: 0.00731924
Epoch [37/300], Train Loss: 0.008772
Validation Loss: 0.00744639
Epoch [38/300], Train Loss: 0.008811
Validation Loss: 0.00729395
Epoch [39/300], Train Loss: 0.008769
Validation Loss: 0.00730465
Epoch [40/300], Train Loss: 0.008726
Validation Loss: 0.00727818
Epoch [41/300], Train Loss: 0.008735
Validation Loss: 0.00729066
Epoch [42/300], Train Loss: 0.008702
Validation Loss: 0.00727412
Epoch [43/300], Train Loss: 0.008725
Validation Loss: 0.00725951
Epoch [44/300], Train Loss: 0.008671
Validation Loss: 0.00723560
Epoch [45/300], Train Loss: 0.008666
Validation Loss: 0.00723832
Epoch [46/300], Train Loss: 0.008651
Validation Loss: 0.00725101
Epoch [47/300], Train Loss: 0.008611
Validation Loss: 0.00722242
Epoch [48/300], Train Loss: 0.008608
Validation Loss: 0.00719596
Epoch [49/300], Train Loss: 0.008631
Validation Loss: 0.00733326
Epoch [50/300], Train Loss: 0.008616
Validation Loss: 0.00715908
Epoch [51/300], Train Loss: 0.008598
Validation Loss: 0.00715515
Epoch [52/300], Train Loss: 0.008556
Validation Loss: 0.00721632
Epoch [53/300], Train Loss: 0.008530
Validation Loss: 0.00716025
Epoch [54/300], Train Loss: 0.008527
Validation Loss: 0.00715360
Epoch [55/300], Train Loss: 0.008553
Validation Loss: 0.00735821
Epoch [56/300], Train Loss: 0.008645
Validation Loss: 0.00715631
Epoch [57/300], Train Loss: 0.008551
Validation Loss: 0.00712893
Epoch [58/300], Train Loss: 0.008521
Validation Loss: 0.00712160
Epoch [59/300], Train Loss: 0.008521
Validation Loss: 0.00714101
Epoch [60/300], Train Loss: 0.008535
Validation Loss: 0.00711488
Epoch [61/300], Train Loss: 0.008461
Validation Loss: 0.00706453
Epoch [62/300], Train Loss: 0.008473
Validation Loss: 0.00727416
Epoch [63/300], Train Loss: 0.008480
Validation Loss: 0.00705638
Epoch [64/300], Train Loss: 0.008445
Validation Loss: 0.00699427
Epoch [65/300], Train Loss: 0.008470
Validation Loss: 0.00704802
Epoch [66/300], Train Loss: 0.010420
Validation Loss: 0.00900673
Epoch [67/300], Train Loss: 0.010273
Validation Loss: 0.00762615
Epoch [68/300], Train Loss: 0.008553
Validation Loss: 0.00708866
Epoch [69/300], Train Loss: 0.008500
Validation Loss: 0.00711022
Epoch [70/300], Train Loss: 0.008459
Validation Loss: 0.00705397
Epoch [71/300], Train Loss: 0.008369
Validation Loss: 0.00702230
Epoch [72/300], Train Loss: 0.008377
Validation Loss: 0.00703061
Epoch [73/300], Train Loss: 0.008400
Validation Loss: 0.00709976
Epoch [74/300], Train Loss: 0.008428
Validation Loss: 0.00704454
Early stopping triggered

Evaluating model for: Tablet
Run 19/72 completed in 374.84 seconds with: {'MAE': np.float32(0.61642617), 'MSE': np.float32(1.0590355), 'RMSE': np.float32(1.0290946), 'SAE': np.float32(0.028439017), 'NDE': np.float32(0.23476733)}

Run 20/72: hidden=128, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Tablet
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.089339
Validation Loss: 0.07055919
Epoch [2/300], Train Loss: 0.041760
Validation Loss: 0.02075779
Epoch [3/300], Train Loss: 0.017970
Validation Loss: 0.01453058
Epoch [4/300], Train Loss: 0.016337
Validation Loss: 0.01449531
Epoch [5/300], Train Loss: 0.016187
Validation Loss: 0.01423224
Epoch [6/300], Train Loss: 0.015999
Validation Loss: 0.01407969
Epoch [7/300], Train Loss: 0.015629
Validation Loss: 0.01346991
Epoch [8/300], Train Loss: 0.014661
Validation Loss: 0.01187163
Epoch [9/300], Train Loss: 0.012430
Validation Loss: 0.01004250
Epoch [10/300], Train Loss: 0.010788
Validation Loss: 0.00863230
Epoch [11/300], Train Loss: 0.010083
Validation Loss: 0.00838709
Epoch [12/300], Train Loss: 0.009854
Validation Loss: 0.00834811
Epoch [13/300], Train Loss: 0.009721
Validation Loss: 0.00820610
Epoch [14/300], Train Loss: 0.009570
Validation Loss: 0.00824378
Epoch [15/300], Train Loss: 0.009605
Validation Loss: 0.00781397
Epoch [16/300], Train Loss: 0.009441
Validation Loss: 0.00822387
Epoch [17/300], Train Loss: 0.009460
Validation Loss: 0.00811722
Epoch [18/300], Train Loss: 0.009363
Validation Loss: 0.00798068
Epoch [19/300], Train Loss: 0.009346
Validation Loss: 0.00803581
Epoch [20/300], Train Loss: 0.009795
Validation Loss: 0.00931980
Epoch [21/300], Train Loss: 0.010441
Validation Loss: 0.00794810
Epoch [22/300], Train Loss: 0.009343
Validation Loss: 0.00793694
Epoch [23/300], Train Loss: 0.009278
Validation Loss: 0.00782147
Epoch [24/300], Train Loss: 0.009199
Validation Loss: 0.00777552
Epoch [25/300], Train Loss: 0.009187
Validation Loss: 0.00767109
Epoch [26/300], Train Loss: 0.009268
Validation Loss: 0.00825824
Epoch [27/300], Train Loss: 0.009314
Validation Loss: 0.00811169
Epoch [28/300], Train Loss: 0.009889
Validation Loss: 0.00791181
Epoch [29/300], Train Loss: 0.009204
Validation Loss: 0.00776797
Epoch [30/300], Train Loss: 0.009261
Validation Loss: 0.00779697
Epoch [31/300], Train Loss: 0.009077
Validation Loss: 0.00767568
Epoch [32/300], Train Loss: 0.009038
Validation Loss: 0.00771982
Epoch [33/300], Train Loss: 0.009054
Validation Loss: 0.00762034
Epoch [34/300], Train Loss: 0.009021
Validation Loss: 0.00754256
Epoch [35/300], Train Loss: 0.009009
Validation Loss: 0.00762270
Epoch [36/300], Train Loss: 0.008992
Validation Loss: 0.00767017
Epoch [37/300], Train Loss: 0.008969
Validation Loss: 0.00752159
Epoch [38/300], Train Loss: 0.008980
Validation Loss: 0.00744810
Epoch [39/300], Train Loss: 0.008896
Validation Loss: 0.00758560
Epoch [40/300], Train Loss: 0.008906
Validation Loss: 0.00740876
Epoch [41/300], Train Loss: 0.008926
Validation Loss: 0.00745106
Epoch [42/300], Train Loss: 0.008854
Validation Loss: 0.00738136
Epoch [43/300], Train Loss: 0.009525
Validation Loss: 0.00782746
Epoch [44/300], Train Loss: 0.009218
Validation Loss: 0.00743083
Epoch [45/300], Train Loss: 0.008944
Validation Loss: 0.00768124
Epoch [46/300], Train Loss: 0.008890
Validation Loss: 0.00738909
Epoch [47/300], Train Loss: 0.008812
Validation Loss: 0.00733385
Epoch [48/300], Train Loss: 0.008785
Validation Loss: 0.00735429
Epoch [49/300], Train Loss: 0.008755
Validation Loss: 0.00733418
Epoch [50/300], Train Loss: 0.008773
Validation Loss: 0.00731157
Epoch [51/300], Train Loss: 0.008770
Validation Loss: 0.00729576
Epoch [52/300], Train Loss: 0.008728
Validation Loss: 0.00728214
Epoch [53/300], Train Loss: 0.008700
Validation Loss: 0.00725524
Epoch [54/300], Train Loss: 0.008688
Validation Loss: 0.00734166
Epoch [55/300], Train Loss: 0.008763
Validation Loss: 0.00734467
Epoch [56/300], Train Loss: 0.008757
Validation Loss: 0.00723331
Epoch [57/300], Train Loss: 0.008658
Validation Loss: 0.00735477
Epoch [58/300], Train Loss: 0.008653
Validation Loss: 0.00720464
Epoch [59/300], Train Loss: 0.008627
Validation Loss: 0.00720870
Epoch [60/300], Train Loss: 0.008609
Validation Loss: 0.00715532
Epoch [61/300], Train Loss: 0.008576
Validation Loss: 0.00717659
Epoch [62/300], Train Loss: 0.008584
Validation Loss: 0.00719865
Epoch [63/300], Train Loss: 0.008613
Validation Loss: 0.00714438
Epoch [64/300], Train Loss: 0.008552
Validation Loss: 0.00723035
Epoch [65/300], Train Loss: 0.008711
Validation Loss: 0.00728686
Epoch [66/300], Train Loss: 0.008535
Validation Loss: 0.00720182
Epoch [67/300], Train Loss: 0.008509
Validation Loss: 0.00713348
Epoch [68/300], Train Loss: 0.008550
Validation Loss: 0.00711121
Epoch [69/300], Train Loss: 0.008498
Validation Loss: 0.00721587
Epoch [70/300], Train Loss: 0.008519
Validation Loss: 0.00712596
Epoch [71/300], Train Loss: 0.008458
Validation Loss: 0.00707996
Epoch [72/300], Train Loss: 0.008421
Validation Loss: 0.00704543
Epoch [73/300], Train Loss: 0.008438
Validation Loss: 0.00713792
Epoch [74/300], Train Loss: 0.008517
Validation Loss: 0.00710442
Epoch [75/300], Train Loss: 0.008456
Validation Loss: 0.00704405
Epoch [76/300], Train Loss: 0.008447
Validation Loss: 0.00774693
Epoch [77/300], Train Loss: 0.008814
Validation Loss: 0.00704519
Epoch [78/300], Train Loss: 0.008401
Validation Loss: 0.00697270
Epoch [79/300], Train Loss: 0.008347
Validation Loss: 0.00697061
Epoch [80/300], Train Loss: 0.008386
Validation Loss: 0.00699210
Epoch [81/300], Train Loss: 0.008381
Validation Loss: 0.00687727
Epoch [82/300], Train Loss: 0.008290
Validation Loss: 0.00690615
Epoch [83/300], Train Loss: 0.008238
Validation Loss: 0.00698937
Epoch [84/300], Train Loss: 0.008282
Validation Loss: 0.00695208
Epoch [85/300], Train Loss: 0.008323
Validation Loss: 0.00690545
Epoch [86/300], Train Loss: 0.008420
Validation Loss: 0.00688358
Epoch [87/300], Train Loss: 0.008281
Validation Loss: 0.00684735
Epoch [88/300], Train Loss: 0.008209
Validation Loss: 0.00680851
Epoch [89/300], Train Loss: 0.008199
Validation Loss: 0.00687559
Epoch [90/300], Train Loss: 0.008171
Validation Loss: 0.00685139
Epoch [91/300], Train Loss: 0.008183
Validation Loss: 0.00683795
Epoch [92/300], Train Loss: 0.008134
Validation Loss: 0.00686476
Epoch [93/300], Train Loss: 0.008116
Validation Loss: 0.00668080
Epoch [94/300], Train Loss: 0.008091
Validation Loss: 0.00679016
Epoch [95/300], Train Loss: 0.008126
Validation Loss: 0.00667425
Epoch [96/300], Train Loss: 0.007995
Validation Loss: 0.00664063
Epoch [97/300], Train Loss: 0.008015
Validation Loss: 0.00662442
Epoch [98/300], Train Loss: 0.007954
Validation Loss: 0.00662179
Epoch [99/300], Train Loss: 0.007953
Validation Loss: 0.00658057
Epoch [100/300], Train Loss: 0.007901
Validation Loss: 0.00661376
Epoch [101/300], Train Loss: 0.007991
Validation Loss: 0.00659445
Epoch [102/300], Train Loss: 0.007989
Validation Loss: 0.00674034
Epoch [103/300], Train Loss: 0.008017
Validation Loss: 0.00654536
Epoch [104/300], Train Loss: 0.007903
Validation Loss: 0.00670638
Epoch [105/300], Train Loss: 0.007938
Validation Loss: 0.00665534
Epoch [106/300], Train Loss: 0.007806
Validation Loss: 0.00642557
Epoch [107/300], Train Loss: 0.007730
Validation Loss: 0.00642082
Epoch [108/300], Train Loss: 0.007768
Validation Loss: 0.00636304
Epoch [109/300], Train Loss: 0.007670
Validation Loss: 0.00633393
Epoch [110/300], Train Loss: 0.007594
Validation Loss: 0.00641257
Epoch [111/300], Train Loss: 0.007648
Validation Loss: 0.00729709
Epoch [112/300], Train Loss: 0.007773
Validation Loss: 0.00628580
Epoch [113/300], Train Loss: 0.007599
Validation Loss: 0.00625396
Epoch [114/300], Train Loss: 0.007485
Validation Loss: 0.00612268
Epoch [115/300], Train Loss: 0.007451
Validation Loss: 0.00652091
Epoch [116/300], Train Loss: 0.008065
Validation Loss: 0.00671929
Epoch [117/300], Train Loss: 0.007523
Validation Loss: 0.00620417
Epoch [118/300], Train Loss: 0.007382
Validation Loss: 0.00600870
Epoch [119/300], Train Loss: 0.007321
Validation Loss: 0.00606572
Epoch [120/300], Train Loss: 0.007846
Validation Loss: 0.00636774
Epoch [121/300], Train Loss: 0.007571
Validation Loss: 0.00625685
Epoch [122/300], Train Loss: 0.007466
Validation Loss: 0.00608856
Epoch [123/300], Train Loss: 0.007325
Validation Loss: 0.00596261
Epoch [124/300], Train Loss: 0.007245
Validation Loss: 0.00587850
Epoch [125/300], Train Loss: 0.007199
Validation Loss: 0.00585464
Epoch [126/300], Train Loss: 0.007183
Validation Loss: 0.00588182
Epoch [127/300], Train Loss: 0.007188
Validation Loss: 0.00586547
Epoch [128/300], Train Loss: 0.007211
Validation Loss: 0.00591721
Epoch [129/300], Train Loss: 0.007146
Validation Loss: 0.00583945
Epoch [130/300], Train Loss: 0.007121
Validation Loss: 0.00582311
Epoch [131/300], Train Loss: 0.007125
Validation Loss: 0.00585709
Epoch [132/300], Train Loss: 0.007150
Validation Loss: 0.00582369
Epoch [133/300], Train Loss: 0.007081
Validation Loss: 0.00581091
Epoch [134/300], Train Loss: 0.007104
Validation Loss: 0.00585166
Epoch [135/300], Train Loss: 0.007082
Validation Loss: 0.00579281
Epoch [136/300], Train Loss: 0.007067
Validation Loss: 0.00584230
Epoch [137/300], Train Loss: 0.007098
Validation Loss: 0.00577451
Epoch [138/300], Train Loss: 0.007081
Validation Loss: 0.00582001
Epoch [139/300], Train Loss: 0.007090
Validation Loss: 0.00574370
Epoch [140/300], Train Loss: 0.007016
Validation Loss: 0.00572620
Epoch [141/300], Train Loss: 0.007084
Validation Loss: 0.00573488
Epoch [142/300], Train Loss: 0.006996
Validation Loss: 0.00580074
Epoch [143/300], Train Loss: 0.007041
Validation Loss: 0.00583086
Epoch [144/300], Train Loss: 0.007312
Validation Loss: 0.00676247
Epoch [145/300], Train Loss: 0.008040
Validation Loss: 0.00652815
Epoch [146/300], Train Loss: 0.007629
Validation Loss: 0.00619891
Epoch [147/300], Train Loss: 0.007382
Validation Loss: 0.00594460
Epoch [148/300], Train Loss: 0.007235
Validation Loss: 0.00582445
Epoch [149/300], Train Loss: 0.007131
Validation Loss: 0.00576737
Epoch [150/300], Train Loss: 0.007070
Validation Loss: 0.00579870
Early stopping triggered

Evaluating model for: Tablet
Run 20/72 completed in 808.15 seconds with: {'MAE': np.float32(0.5846323), 'MSE': np.float32(0.88863194), 'RMSE': np.float32(0.9426728), 'SAE': np.float32(0.023143379), 'NDE': np.float32(0.21505198)}

Run 21/72: hidden=128, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Tablet
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.083849
Validation Loss: 0.08286242
Epoch [2/300], Train Loss: 0.072722
Validation Loss: 0.07130501
Epoch [3/300], Train Loss: 0.060829
Validation Loss: 0.05769195
Epoch [4/300], Train Loss: 0.045730
Validation Loss: 0.03922428
Epoch [5/300], Train Loss: 0.026369
Validation Loss: 0.01814057
Epoch [6/300], Train Loss: 0.017579
Validation Loss: 0.01740239
Epoch [7/300], Train Loss: 0.016494
Validation Loss: 0.01774739
Epoch [8/300], Train Loss: 0.016170
Validation Loss: 0.01710167
Epoch [9/300], Train Loss: 0.016039
Validation Loss: 0.01709248
Epoch [10/300], Train Loss: 0.015885
Validation Loss: 0.01689510
Epoch [11/300], Train Loss: 0.015728
Validation Loss: 0.01677115
Epoch [12/300], Train Loss: 0.015572
Validation Loss: 0.01661404
Epoch [13/300], Train Loss: 0.015385
Validation Loss: 0.01640362
Epoch [14/300], Train Loss: 0.015193
Validation Loss: 0.01621011
Epoch [15/300], Train Loss: 0.014946
Validation Loss: 0.01594443
Epoch [16/300], Train Loss: 0.014644
Validation Loss: 0.01568079
Epoch [17/300], Train Loss: 0.014299
Validation Loss: 0.01535182
Epoch [18/300], Train Loss: 0.013870
Validation Loss: 0.01474352
Epoch [19/300], Train Loss: 0.013218
Validation Loss: 0.01415824
Epoch [20/300], Train Loss: 0.012472
Validation Loss: 0.01338971
Epoch [21/300], Train Loss: 0.011736
Validation Loss: 0.01294102
Epoch [22/300], Train Loss: 0.011314
Validation Loss: 0.01289160
Epoch [23/300], Train Loss: 0.011098
Validation Loss: 0.01268332
Epoch [24/300], Train Loss: 0.010911
Validation Loss: 0.01241675
Epoch [25/300], Train Loss: 0.010740
Validation Loss: 0.01230348
Epoch [26/300], Train Loss: 0.010608
Validation Loss: 0.01216574
Epoch [27/300], Train Loss: 0.010383
Validation Loss: 0.01201251
Epoch [28/300], Train Loss: 0.010196
Validation Loss: 0.01171959
Epoch [29/300], Train Loss: 0.009951
Validation Loss: 0.01144052
Epoch [30/300], Train Loss: 0.009709
Validation Loss: 0.01125030
Epoch [31/300], Train Loss: 0.009396
Validation Loss: 0.01084296
Epoch [32/300], Train Loss: 0.009128
Validation Loss: 0.01063026
Epoch [33/300], Train Loss: 0.008895
Validation Loss: 0.01040346
Epoch [34/300], Train Loss: 0.008748
Validation Loss: 0.01026963
Epoch [35/300], Train Loss: 0.008663
Validation Loss: 0.01021361
Epoch [36/300], Train Loss: 0.008569
Validation Loss: 0.01019601
Epoch [37/300], Train Loss: 0.008532
Validation Loss: 0.01007981
Epoch [38/300], Train Loss: 0.008486
Validation Loss: 0.01002430
Epoch [39/300], Train Loss: 0.008428
Validation Loss: 0.01008536
Epoch [40/300], Train Loss: 0.008400
Validation Loss: 0.01014867
Epoch [41/300], Train Loss: 0.008315
Validation Loss: 0.00993723
Epoch [42/300], Train Loss: 0.008303
Validation Loss: 0.00984776
Epoch [43/300], Train Loss: 0.008253
Validation Loss: 0.00982268
Epoch [44/300], Train Loss: 0.008215
Validation Loss: 0.00975971
Epoch [45/300], Train Loss: 0.008188
Validation Loss: 0.00974173
Epoch [46/300], Train Loss: 0.008194
Validation Loss: 0.00964330
Epoch [47/300], Train Loss: 0.008063
Validation Loss: 0.00965511
Epoch [48/300], Train Loss: 0.008055
Validation Loss: 0.00958872
Epoch [49/300], Train Loss: 0.008031
Validation Loss: 0.00974158
Epoch [50/300], Train Loss: 0.008024
Validation Loss: 0.00964550
Epoch [51/300], Train Loss: 0.008004
Validation Loss: 0.00963665
Epoch [52/300], Train Loss: 0.008004
Validation Loss: 0.00989072
Epoch [53/300], Train Loss: 0.008027
Validation Loss: 0.01022145
Epoch [54/300], Train Loss: 0.008015
Validation Loss: 0.00979660
Epoch [55/300], Train Loss: 0.007971
Validation Loss: 0.00950396
Epoch [56/300], Train Loss: 0.007967
Validation Loss: 0.00957147
Epoch [57/300], Train Loss: 0.007926
Validation Loss: 0.00941507
Epoch [58/300], Train Loss: 0.007805
Validation Loss: 0.00939936
Epoch [59/300], Train Loss: 0.007858
Validation Loss: 0.00941370
Epoch [60/300], Train Loss: 0.007765
Validation Loss: 0.00932339
Epoch [61/300], Train Loss: 0.007736
Validation Loss: 0.00935227
Epoch [62/300], Train Loss: 0.007714
Validation Loss: 0.00929483
Epoch [63/300], Train Loss: 0.007895
Validation Loss: 0.00964661
Epoch [64/300], Train Loss: 0.007746
Validation Loss: 0.00923574
Epoch [65/300], Train Loss: 0.007693
Validation Loss: 0.00923518
Epoch [66/300], Train Loss: 0.007667
Validation Loss: 0.00943870
Epoch [67/300], Train Loss: 0.007659
Validation Loss: 0.00921956
Epoch [68/300], Train Loss: 0.007631
Validation Loss: 0.00933332
Epoch [69/300], Train Loss: 0.007630
Validation Loss: 0.00919438
Epoch [70/300], Train Loss: 0.007606
Validation Loss: 0.00924054
Epoch [71/300], Train Loss: 0.007596
Validation Loss: 0.00944659
Epoch [72/300], Train Loss: 0.007634
Validation Loss: 0.00936918
Epoch [73/300], Train Loss: 0.007617
Validation Loss: 0.00915798
Epoch [74/300], Train Loss: 0.007583
Validation Loss: 0.00917448
Epoch [75/300], Train Loss: 0.007576
Validation Loss: 0.00908568
Epoch [76/300], Train Loss: 0.007583
Validation Loss: 0.00911677
Epoch [77/300], Train Loss: 0.007536
Validation Loss: 0.00908585
Epoch [78/300], Train Loss: 0.007540
Validation Loss: 0.00912920
Epoch [79/300], Train Loss: 0.007630
Validation Loss: 0.00912371
Epoch [80/300], Train Loss: 0.007567
Validation Loss: 0.00914636
Epoch [81/300], Train Loss: 0.007569
Validation Loss: 0.00909734
Epoch [82/300], Train Loss: 0.007493
Validation Loss: 0.00910550
Epoch [83/300], Train Loss: 0.007557
Validation Loss: 0.00907018
Epoch [84/300], Train Loss: 0.007612
Validation Loss: 0.00905319
Epoch [85/300], Train Loss: 0.007760
Validation Loss: 0.00907928
Epoch [86/300], Train Loss: 0.007593
Validation Loss: 0.00916182
Epoch [87/300], Train Loss: 0.007559
Validation Loss: 0.00921462
Epoch [88/300], Train Loss: 0.007501
Validation Loss: 0.00921557
Epoch [89/300], Train Loss: 0.007460
Validation Loss: 0.00902863
Epoch [90/300], Train Loss: 0.007455
Validation Loss: 0.00903271
Epoch [91/300], Train Loss: 0.007454
Validation Loss: 0.00916558
Epoch [92/300], Train Loss: 0.007707
Validation Loss: 0.01042373
Epoch [93/300], Train Loss: 0.008110
Validation Loss: 0.00946593
Epoch [94/300], Train Loss: 0.007639
Validation Loss: 0.00909200
Epoch [95/300], Train Loss: 0.007479
Validation Loss: 0.00905479
Epoch [96/300], Train Loss: 0.007435
Validation Loss: 0.00900845
Epoch [97/300], Train Loss: 0.007402
Validation Loss: 0.00899291
Epoch [98/300], Train Loss: 0.007400
Validation Loss: 0.00899986
Epoch [99/300], Train Loss: 0.007381
Validation Loss: 0.00897561
Epoch [100/300], Train Loss: 0.007374
Validation Loss: 0.00897528
Epoch [101/300], Train Loss: 0.007381
Validation Loss: 0.00896762
Epoch [102/300], Train Loss: 0.007355
Validation Loss: 0.00896505
Epoch [103/300], Train Loss: 0.007358
Validation Loss: 0.00900025
Epoch [104/300], Train Loss: 0.007405
Validation Loss: 0.00896186
Epoch [105/300], Train Loss: 0.007394
Validation Loss: 0.00895687
Epoch [106/300], Train Loss: 0.007347
Validation Loss: 0.00896105
Epoch [107/300], Train Loss: 0.007323
Validation Loss: 0.00893255
Epoch [108/300], Train Loss: 0.007338
Validation Loss: 0.00894967
Epoch [109/300], Train Loss: 0.007360
Validation Loss: 0.00900219
Epoch [110/300], Train Loss: 0.007346
Validation Loss: 0.00895083
Epoch [111/300], Train Loss: 0.007320
Validation Loss: 0.00890733
Epoch [112/300], Train Loss: 0.007324
Validation Loss: 0.00892614
Epoch [113/300], Train Loss: 0.007301
Validation Loss: 0.00890776
Epoch [114/300], Train Loss: 0.007328
Validation Loss: 0.00889451
Epoch [115/300], Train Loss: 0.007328
Validation Loss: 0.00891702
Epoch [116/300], Train Loss: 0.007323
Validation Loss: 0.00896707
Epoch [117/300], Train Loss: 0.007283
Validation Loss: 0.00888637
Epoch [118/300], Train Loss: 0.007295
Validation Loss: 0.00889335
Epoch [119/300], Train Loss: 0.007284
Validation Loss: 0.00888003
Epoch [120/300], Train Loss: 0.007274
Validation Loss: 0.00886255
Epoch [121/300], Train Loss: 0.007273
Validation Loss: 0.00890976
Epoch [122/300], Train Loss: 0.007255
Validation Loss: 0.00887046
Epoch [123/300], Train Loss: 0.007250
Validation Loss: 0.00885510
Epoch [124/300], Train Loss: 0.007240
Validation Loss: 0.00884409
Epoch [125/300], Train Loss: 0.007243
Validation Loss: 0.00886529
Epoch [126/300], Train Loss: 0.007273
Validation Loss: 0.00884040
Epoch [127/300], Train Loss: 0.007238
Validation Loss: 0.00883165
Epoch [128/300], Train Loss: 0.007238
Validation Loss: 0.00882088
Epoch [129/300], Train Loss: 0.007230
Validation Loss: 0.00884030
Epoch [130/300], Train Loss: 0.007212
Validation Loss: 0.00881309
Epoch [131/300], Train Loss: 0.007214
Validation Loss: 0.00881464
Epoch [132/300], Train Loss: 0.007204
Validation Loss: 0.00880638
Epoch [133/300], Train Loss: 0.007214
Validation Loss: 0.00881411
Epoch [134/300], Train Loss: 0.007186
Validation Loss: 0.00879169
Epoch [135/300], Train Loss: 0.007192
Validation Loss: 0.00879348
Epoch [136/300], Train Loss: 0.007186
Validation Loss: 0.00884490
Epoch [137/300], Train Loss: 0.007206
Validation Loss: 0.00878176
Epoch [138/300], Train Loss: 0.007196
Validation Loss: 0.00880006
Epoch [139/300], Train Loss: 0.007172
Validation Loss: 0.00880942
Epoch [140/300], Train Loss: 0.007166
Validation Loss: 0.00882367
Epoch [141/300], Train Loss: 0.007168
Validation Loss: 0.00875804
Epoch [142/300], Train Loss: 0.007151
Validation Loss: 0.00874503
Epoch [143/300], Train Loss: 0.007171
Validation Loss: 0.00875389
Epoch [144/300], Train Loss: 0.007160
Validation Loss: 0.00874957
Epoch [145/300], Train Loss: 0.007138
Validation Loss: 0.00875013
Epoch [146/300], Train Loss: 0.007145
Validation Loss: 0.00879942
Epoch [147/300], Train Loss: 0.007115
Validation Loss: 0.00875956
Epoch [148/300], Train Loss: 0.007134
Validation Loss: 0.00871986
Epoch [149/300], Train Loss: 0.007163
Validation Loss: 0.00871007
Epoch [150/300], Train Loss: 0.007117
Validation Loss: 0.00873631
Epoch [151/300], Train Loss: 0.007107
Validation Loss: 0.00869196
Epoch [152/300], Train Loss: 0.007111
Validation Loss: 0.00869827
Epoch [153/300], Train Loss: 0.007100
Validation Loss: 0.00868807
Epoch [154/300], Train Loss: 0.007080
Validation Loss: 0.00868823
Epoch [155/300], Train Loss: 0.007081
Validation Loss: 0.00867659
Epoch [156/300], Train Loss: 0.007082
Validation Loss: 0.00867279
Epoch [157/300], Train Loss: 0.007075
Validation Loss: 0.00865719
Epoch [158/300], Train Loss: 0.007066
Validation Loss: 0.00874070
Epoch [159/300], Train Loss: 0.007129
Validation Loss: 0.00868597
Epoch [160/300], Train Loss: 0.007103
Validation Loss: 0.00869787
Epoch [161/300], Train Loss: 0.007090
Validation Loss: 0.00868185
Epoch [162/300], Train Loss: 0.007059
Validation Loss: 0.00862613
Epoch [163/300], Train Loss: 0.007066
Validation Loss: 0.00863812
Epoch [164/300], Train Loss: 0.007043
Validation Loss: 0.00865324
Epoch [165/300], Train Loss: 0.007037
Validation Loss: 0.00864869
Epoch [166/300], Train Loss: 0.007048
Validation Loss: 0.00860199
Epoch [167/300], Train Loss: 0.007103
Validation Loss: 0.00865206
Epoch [168/300], Train Loss: 0.007040
Validation Loss: 0.00862590
Epoch [169/300], Train Loss: 0.007019
Validation Loss: 0.00860697
Epoch [170/300], Train Loss: 0.007009
Validation Loss: 0.00860544
Epoch [171/300], Train Loss: 0.007022
Validation Loss: 0.00861835
Epoch [172/300], Train Loss: 0.007011
Validation Loss: 0.00857265
Epoch [173/300], Train Loss: 0.006996
Validation Loss: 0.00859902
Epoch [174/300], Train Loss: 0.007009
Validation Loss: 0.00859194
Epoch [175/300], Train Loss: 0.007016
Validation Loss: 0.00857952
Epoch [176/300], Train Loss: 0.007020
Validation Loss: 0.00856621
Epoch [177/300], Train Loss: 0.007012
Validation Loss: 0.00856606
Epoch [178/300], Train Loss: 0.006969
Validation Loss: 0.00854926
Epoch [179/300], Train Loss: 0.006971
Validation Loss: 0.00860030
Epoch [180/300], Train Loss: 0.007003
Validation Loss: 0.00861098
Epoch [181/300], Train Loss: 0.007025
Validation Loss: 0.00857222
Epoch [182/300], Train Loss: 0.006968
Validation Loss: 0.00856648
Epoch [183/300], Train Loss: 0.006995
Validation Loss: 0.00865262
Epoch [184/300], Train Loss: 0.007040
Validation Loss: 0.00864958
Epoch [185/300], Train Loss: 0.006985
Validation Loss: 0.00853406
Epoch [186/300], Train Loss: 0.006959
Validation Loss: 0.00853933
Epoch [187/300], Train Loss: 0.006960
Validation Loss: 0.00851980
Epoch [188/300], Train Loss: 0.006958
Validation Loss: 0.00852318
Epoch [189/300], Train Loss: 0.006941
Validation Loss: 0.00850307
Epoch [190/300], Train Loss: 0.006937
Validation Loss: 0.00851859
Epoch [191/300], Train Loss: 0.006930
Validation Loss: 0.00850345
Epoch [192/300], Train Loss: 0.006936
Validation Loss: 0.00848648
Epoch [193/300], Train Loss: 0.006919
Validation Loss: 0.00848396
Epoch [194/300], Train Loss: 0.006929
Validation Loss: 0.00848584
Epoch [195/300], Train Loss: 0.006915
Validation Loss: 0.00850057
Epoch [196/300], Train Loss: 0.006907
Validation Loss: 0.00847682
Epoch [197/300], Train Loss: 0.006927
Validation Loss: 0.00847258
Epoch [198/300], Train Loss: 0.006910
Validation Loss: 0.00847020
Epoch [199/300], Train Loss: 0.006899
Validation Loss: 0.00846208
Epoch [200/300], Train Loss: 0.006898
Validation Loss: 0.00845281
Epoch [201/300], Train Loss: 0.006906
Validation Loss: 0.00847834
Epoch [202/300], Train Loss: 0.006899
Validation Loss: 0.00849347
Epoch [203/300], Train Loss: 0.006937
Validation Loss: 0.00845434
Epoch [204/300], Train Loss: 0.006931
Validation Loss: 0.00851249
Epoch [205/300], Train Loss: 0.006924
Validation Loss: 0.00847644
Epoch [206/300], Train Loss: 0.006892
Validation Loss: 0.00843286
Epoch [207/300], Train Loss: 0.006901
Validation Loss: 0.00845678
Epoch [208/300], Train Loss: 0.006898
Validation Loss: 0.00841705
Epoch [209/300], Train Loss: 0.006873
Validation Loss: 0.00842981
Epoch [210/300], Train Loss: 0.006903
Validation Loss: 0.00845949
Epoch [211/300], Train Loss: 0.006882
Validation Loss: 0.00839975
Epoch [212/300], Train Loss: 0.006863
Validation Loss: 0.00842955
Epoch [213/300], Train Loss: 0.006854
Validation Loss: 0.00840648
Epoch [214/300], Train Loss: 0.006869
Validation Loss: 0.00840416
Epoch [215/300], Train Loss: 0.006865
Validation Loss: 0.00840550
Epoch [216/300], Train Loss: 0.006848
Validation Loss: 0.00841579
Epoch [217/300], Train Loss: 0.006851
Validation Loss: 0.00839781
Epoch [218/300], Train Loss: 0.006870
Validation Loss: 0.00842599
Epoch [219/300], Train Loss: 0.006851
Validation Loss: 0.00838348
Epoch [220/300], Train Loss: 0.006841
Validation Loss: 0.00838436
Epoch [221/300], Train Loss: 0.006841
Validation Loss: 0.00838727
Epoch [222/300], Train Loss: 0.006856
Validation Loss: 0.00837886
Epoch [223/300], Train Loss: 0.006858
Validation Loss: 0.00837622
Epoch [224/300], Train Loss: 0.006826
Validation Loss: 0.00837323
Epoch [225/300], Train Loss: 0.006832
Validation Loss: 0.00836269
Epoch [226/300], Train Loss: 0.006833
Validation Loss: 0.00838199
Epoch [227/300], Train Loss: 0.006824
Validation Loss: 0.00840289
Epoch [228/300], Train Loss: 0.006843
Validation Loss: 0.00834839
Epoch [229/300], Train Loss: 0.006826
Validation Loss: 0.00836500
Epoch [230/300], Train Loss: 0.006819
Validation Loss: 0.00834514
Epoch [231/300], Train Loss: 0.006816
Validation Loss: 0.00835583
Epoch [232/300], Train Loss: 0.006823
Validation Loss: 0.00837424
Epoch [233/300], Train Loss: 0.006809
Validation Loss: 0.00834527
Epoch [234/300], Train Loss: 0.006802
Validation Loss: 0.00835339
Epoch [235/300], Train Loss: 0.006801
Validation Loss: 0.00833962
Epoch [236/300], Train Loss: 0.006799
Validation Loss: 0.00833623
Epoch [237/300], Train Loss: 0.006791
Validation Loss: 0.00835438
Epoch [238/300], Train Loss: 0.006830
Validation Loss: 0.00850434
Epoch [239/300], Train Loss: 0.006855
Validation Loss: 0.00838990
Epoch [240/300], Train Loss: 0.006833
Validation Loss: 0.00831762
Epoch [241/300], Train Loss: 0.006818
Validation Loss: 0.00834679
Epoch [242/300], Train Loss: 0.006775
Validation Loss: 0.00833818
Epoch [243/300], Train Loss: 0.006784
Validation Loss: 0.00832964
Epoch [244/300], Train Loss: 0.006773
Validation Loss: 0.00831484
Epoch [245/300], Train Loss: 0.006782
Validation Loss: 0.00830955
Epoch [246/300], Train Loss: 0.006799
Validation Loss: 0.00832761
Epoch [247/300], Train Loss: 0.006795
Validation Loss: 0.00832782
Epoch [248/300], Train Loss: 0.006797
Validation Loss: 0.00834226
Epoch [249/300], Train Loss: 0.006778
Validation Loss: 0.00830678
Epoch [250/300], Train Loss: 0.006779
Validation Loss: 0.00831798
Epoch [251/300], Train Loss: 0.006763
Validation Loss: 0.00830370
Epoch [252/300], Train Loss: 0.006777
Validation Loss: 0.00832735
Epoch [253/300], Train Loss: 0.006780
Validation Loss: 0.00830415
Epoch [254/300], Train Loss: 0.006800
Validation Loss: 0.00836962
Epoch [255/300], Train Loss: 0.006807
Validation Loss: 0.00829890
Epoch [256/300], Train Loss: 0.006785
Validation Loss: 0.00827823
Epoch [257/300], Train Loss: 0.006768
Validation Loss: 0.00829574
Epoch [258/300], Train Loss: 0.006764
Validation Loss: 0.00829396
Epoch [259/300], Train Loss: 0.006800
Validation Loss: 0.00830902
Epoch [260/300], Train Loss: 0.006767
Validation Loss: 0.00827520
Epoch [261/300], Train Loss: 0.006754
Validation Loss: 0.00828490
Epoch [262/300], Train Loss: 0.006742
Validation Loss: 0.00827400
Epoch [263/300], Train Loss: 0.006756
Validation Loss: 0.00826562
Epoch [264/300], Train Loss: 0.006744
Validation Loss: 0.00827030
Epoch [265/300], Train Loss: 0.006748
Validation Loss: 0.00826388
Epoch [266/300], Train Loss: 0.006736
Validation Loss: 0.00827742
Epoch [267/300], Train Loss: 0.006740
Validation Loss: 0.00829133
Epoch [268/300], Train Loss: 0.006736
Validation Loss: 0.00826072
Epoch [269/300], Train Loss: 0.006732
Validation Loss: 0.00827480
Epoch [270/300], Train Loss: 0.006765
Validation Loss: 0.00828311
Epoch [271/300], Train Loss: 0.006734
Validation Loss: 0.00825272
Epoch [272/300], Train Loss: 0.006734
Validation Loss: 0.00825078
Epoch [273/300], Train Loss: 0.006718
Validation Loss: 0.00826441
Epoch [274/300], Train Loss: 0.006725
Validation Loss: 0.00825914
Epoch [275/300], Train Loss: 0.006729
Validation Loss: 0.00824720
Epoch [276/300], Train Loss: 0.006730
Validation Loss: 0.00825038
Epoch [277/300], Train Loss: 0.006788
Validation Loss: 0.00826760
Epoch [278/300], Train Loss: 0.006768
Validation Loss: 0.00832206
Epoch [279/300], Train Loss: 0.006728
Validation Loss: 0.00825826
Epoch [280/300], Train Loss: 0.006735
Validation Loss: 0.00823865
Epoch [281/300], Train Loss: 0.006709
Validation Loss: 0.00823930
Epoch [282/300], Train Loss: 0.006717
Validation Loss: 0.00824717
Epoch [283/300], Train Loss: 0.006714
Validation Loss: 0.00824877
Epoch [284/300], Train Loss: 0.006717
Validation Loss: 0.00824078
Epoch [285/300], Train Loss: 0.006713
Validation Loss: 0.00823539
Epoch [286/300], Train Loss: 0.006714
Validation Loss: 0.00824526
Epoch [287/300], Train Loss: 0.006713
Validation Loss: 0.00823787
Epoch [288/300], Train Loss: 0.006708
Validation Loss: 0.00822943
Epoch [289/300], Train Loss: 0.006698
Validation Loss: 0.00822254
Epoch [290/300], Train Loss: 0.006711
Validation Loss: 0.00823477
Epoch [291/300], Train Loss: 0.006693
Validation Loss: 0.00826566
Epoch [292/300], Train Loss: 0.006713
Validation Loss: 0.00823592
Epoch [293/300], Train Loss: 0.006700
Validation Loss: 0.00822514
Epoch [294/300], Train Loss: 0.006695
Validation Loss: 0.00822712
Epoch [295/300], Train Loss: 0.006695
Validation Loss: 0.00821117
Epoch [296/300], Train Loss: 0.006697
Validation Loss: 0.00822254
Epoch [297/300], Train Loss: 0.006699
Validation Loss: 0.00824769
Epoch [298/300], Train Loss: 0.006694
Validation Loss: 0.00822831
Epoch [299/300], Train Loss: 0.006699
Validation Loss: 0.00823534
Epoch [300/300], Train Loss: 0.006695
Validation Loss: 0.00821059

Evaluating model for: Tablet
Run 21/72 completed in 655.38 seconds with: {'MAE': np.float32(0.70846725), 'MSE': np.float32(1.2630788), 'RMSE': np.float32(1.1238678), 'SAE': np.float32(0.006624043), 'NDE': np.float32(0.25861692)}

Run 22/72: hidden=128, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Tablet
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.131059
Validation Loss: 0.12831930
Epoch [2/300], Train Loss: 0.114259
Validation Loss: 0.11035591
Epoch [3/300], Train Loss: 0.094422
Validation Loss: 0.08555844
Epoch [4/300], Train Loss: 0.062710
Validation Loss: 0.04054919
Epoch [5/300], Train Loss: 0.025234
Validation Loss: 0.02187761
Epoch [6/300], Train Loss: 0.019000
Validation Loss: 0.02044103
Epoch [7/300], Train Loss: 0.018051
Validation Loss: 0.01808928
Epoch [8/300], Train Loss: 0.017382
Validation Loss: 0.01794556
Epoch [9/300], Train Loss: 0.017047
Validation Loss: 0.01776093
Epoch [10/300], Train Loss: 0.016836
Validation Loss: 0.01748683
Epoch [11/300], Train Loss: 0.016609
Validation Loss: 0.01735692
Epoch [12/300], Train Loss: 0.016380
Validation Loss: 0.01708923
Epoch [13/300], Train Loss: 0.016137
Validation Loss: 0.01683869
Epoch [14/300], Train Loss: 0.015849
Validation Loss: 0.01656301
Epoch [15/300], Train Loss: 0.015521
Validation Loss: 0.01622972
Epoch [16/300], Train Loss: 0.015126
Validation Loss: 0.01587620
Epoch [17/300], Train Loss: 0.014663
Validation Loss: 0.01545459
Epoch [18/300], Train Loss: 0.014145
Validation Loss: 0.01481045
Epoch [19/300], Train Loss: 0.013415
Validation Loss: 0.01421927
Epoch [20/300], Train Loss: 0.012683
Validation Loss: 0.01354519
Epoch [21/300], Train Loss: 0.012017
Validation Loss: 0.01315472
Epoch [22/300], Train Loss: 0.011587
Validation Loss: 0.01306567
Epoch [23/300], Train Loss: 0.011400
Validation Loss: 0.01284370
Epoch [24/300], Train Loss: 0.011212
Validation Loss: 0.01269806
Epoch [25/300], Train Loss: 0.011064
Validation Loss: 0.01256295
Epoch [26/300], Train Loss: 0.010925
Validation Loss: 0.01249128
Epoch [27/300], Train Loss: 0.010808
Validation Loss: 0.01230245
Epoch [28/300], Train Loss: 0.010666
Validation Loss: 0.01217441
Epoch [29/300], Train Loss: 0.010537
Validation Loss: 0.01203277
Epoch [30/300], Train Loss: 0.010392
Validation Loss: 0.01192189
Epoch [31/300], Train Loss: 0.010243
Validation Loss: 0.01178823
Epoch [32/300], Train Loss: 0.010165
Validation Loss: 0.01170515
Epoch [33/300], Train Loss: 0.010081
Validation Loss: 0.01164646
Epoch [34/300], Train Loss: 0.010048
Validation Loss: 0.01162845
Epoch [35/300], Train Loss: 0.009975
Validation Loss: 0.01155021
Epoch [36/300], Train Loss: 0.009933
Validation Loss: 0.01148714
Epoch [37/300], Train Loss: 0.009895
Validation Loss: 0.01144437
Epoch [38/300], Train Loss: 0.009865
Validation Loss: 0.01144055
Epoch [39/300], Train Loss: 0.009823
Validation Loss: 0.01142861
Epoch [40/300], Train Loss: 0.009787
Validation Loss: 0.01134268
Epoch [41/300], Train Loss: 0.009731
Validation Loss: 0.01120140
Epoch [42/300], Train Loss: 0.009627
Validation Loss: 0.01112542
Epoch [43/300], Train Loss: 0.009573
Validation Loss: 0.01114417
Epoch [44/300], Train Loss: 0.009509
Validation Loss: 0.01107544
Epoch [45/300], Train Loss: 0.009440
Validation Loss: 0.01096925
Epoch [46/300], Train Loss: 0.009405
Validation Loss: 0.01093720
Epoch [47/300], Train Loss: 0.009351
Validation Loss: 0.01096220
Epoch [48/300], Train Loss: 0.009341
Validation Loss: 0.01088899
Epoch [49/300], Train Loss: 0.009304
Validation Loss: 0.01089722
Epoch [50/300], Train Loss: 0.009295
Validation Loss: 0.01086502
Epoch [51/300], Train Loss: 0.009257
Validation Loss: 0.01082494
Epoch [52/300], Train Loss: 0.009252
Validation Loss: 0.01096271
Epoch [53/300], Train Loss: 0.009260
Validation Loss: 0.01090988
Epoch [54/300], Train Loss: 0.009268
Validation Loss: 0.01072052
Epoch [55/300], Train Loss: 0.009193
Validation Loss: 0.01070764
Epoch [56/300], Train Loss: 0.009112
Validation Loss: 0.01067786
Epoch [57/300], Train Loss: 0.009080
Validation Loss: 0.01066432
Epoch [58/300], Train Loss: 0.009055
Validation Loss: 0.01062564
Epoch [59/300], Train Loss: 0.009047
Validation Loss: 0.01069039
Epoch [60/300], Train Loss: 0.008984
Validation Loss: 0.01054236
Epoch [61/300], Train Loss: 0.008973
Validation Loss: 0.01068932
Epoch [62/300], Train Loss: 0.008928
Validation Loss: 0.01046495
Epoch [63/300], Train Loss: 0.008900
Validation Loss: 0.01044763
Epoch [64/300], Train Loss: 0.008886
Validation Loss: 0.01040260
Epoch [65/300], Train Loss: 0.008885
Validation Loss: 0.01041034
Epoch [66/300], Train Loss: 0.008836
Validation Loss: 0.01045345
Epoch [67/300], Train Loss: 0.008820
Validation Loss: 0.01032242
Epoch [68/300], Train Loss: 0.008802
Validation Loss: 0.01049853
Epoch [69/300], Train Loss: 0.008787
Validation Loss: 0.01027068
Epoch [70/300], Train Loss: 0.008776
Validation Loss: 0.01026257
Epoch [71/300], Train Loss: 0.008767
Validation Loss: 0.01030551
Epoch [72/300], Train Loss: 0.008769
Validation Loss: 0.01019803
Epoch [73/300], Train Loss: 0.008736
Validation Loss: 0.01017117
Epoch [74/300], Train Loss: 0.008734
Validation Loss: 0.01027245
Epoch [75/300], Train Loss: 0.008722
Validation Loss: 0.01019057
Epoch [76/300], Train Loss: 0.008701
Validation Loss: 0.01017387
Epoch [77/300], Train Loss: 0.008714
Validation Loss: 0.01021090
Epoch [78/300], Train Loss: 0.008678
Validation Loss: 0.01015021
Epoch [79/300], Train Loss: 0.008637
Validation Loss: 0.01008105
Epoch [80/300], Train Loss: 0.008625
Validation Loss: 0.01015263
Epoch [81/300], Train Loss: 0.008696
Validation Loss: 0.01016941
Epoch [82/300], Train Loss: 0.008656
Validation Loss: 0.01021767
Epoch [83/300], Train Loss: 0.008708
Validation Loss: 0.01028622
Epoch [84/300], Train Loss: 0.008649
Validation Loss: 0.01009327
Epoch [85/300], Train Loss: 0.008620
Validation Loss: 0.01004512
Epoch [86/300], Train Loss: 0.008569
Validation Loss: 0.01006766
Epoch [87/300], Train Loss: 0.008564
Validation Loss: 0.01005074
Epoch [88/300], Train Loss: 0.008573
Validation Loss: 0.01007281
Epoch [89/300], Train Loss: 0.008603
Validation Loss: 0.01005472
Epoch [90/300], Train Loss: 0.008569
Validation Loss: 0.01003674
Epoch [91/300], Train Loss: 0.008493
Validation Loss: 0.00999858
Epoch [92/300], Train Loss: 0.008515
Validation Loss: 0.00999913
Epoch [93/300], Train Loss: 0.008492
Validation Loss: 0.01003412
Epoch [94/300], Train Loss: 0.008473
Validation Loss: 0.00999085
Epoch [95/300], Train Loss: 0.008466
Validation Loss: 0.00997538
Epoch [96/300], Train Loss: 0.008459
Validation Loss: 0.01007728
Epoch [97/300], Train Loss: 0.008479
Validation Loss: 0.00997948
Epoch [98/300], Train Loss: 0.008459
Validation Loss: 0.01001339
Epoch [99/300], Train Loss: 0.008435
Validation Loss: 0.00995546
Epoch [100/300], Train Loss: 0.008420
Validation Loss: 0.00998625
Epoch [101/300], Train Loss: 0.008442
Validation Loss: 0.00995063
Epoch [102/300], Train Loss: 0.008425
Validation Loss: 0.00998542
Epoch [103/300], Train Loss: 0.008371
Validation Loss: 0.01005629
Epoch [104/300], Train Loss: 0.008531
Validation Loss: 0.00996730
Epoch [105/300], Train Loss: 0.008401
Validation Loss: 0.01016420
Epoch [106/300], Train Loss: 0.008410
Validation Loss: 0.00993445
Epoch [107/300], Train Loss: 0.008356
Validation Loss: 0.00993394
Epoch [108/300], Train Loss: 0.008335
Validation Loss: 0.00993941
Epoch [109/300], Train Loss: 0.008354
Validation Loss: 0.01000846
Epoch [110/300], Train Loss: 0.008334
Validation Loss: 0.00995605
Epoch [111/300], Train Loss: 0.008346
Validation Loss: 0.00992943
Epoch [112/300], Train Loss: 0.008301
Validation Loss: 0.01001339
Epoch [113/300], Train Loss: 0.008399
Validation Loss: 0.00991369
Epoch [114/300], Train Loss: 0.008363
Validation Loss: 0.00992741
Epoch [115/300], Train Loss: 0.008359
Validation Loss: 0.00991582
Epoch [116/300], Train Loss: 0.008334
Validation Loss: 0.01001339
Epoch [117/300], Train Loss: 0.008370
Validation Loss: 0.00989123
Epoch [118/300], Train Loss: 0.008284
Validation Loss: 0.00992046
Epoch [119/300], Train Loss: 0.008492
Validation Loss: 0.01004912
Epoch [120/300], Train Loss: 0.008389
Validation Loss: 0.00997163
Epoch [121/300], Train Loss: 0.008279
Validation Loss: 0.00993635
Epoch [122/300], Train Loss: 0.008297
Validation Loss: 0.00990679
Epoch [123/300], Train Loss: 0.008254
Validation Loss: 0.00991599
Epoch [124/300], Train Loss: 0.008278
Validation Loss: 0.01010052
Epoch [125/300], Train Loss: 0.008426
Validation Loss: 0.00987902
Epoch [126/300], Train Loss: 0.008259
Validation Loss: 0.00988639
Epoch [127/300], Train Loss: 0.008242
Validation Loss: 0.00988127
Epoch [128/300], Train Loss: 0.008220
Validation Loss: 0.00987486
Epoch [129/300], Train Loss: 0.008244
Validation Loss: 0.00990535
Epoch [130/300], Train Loss: 0.008256
Validation Loss: 0.00985797
Epoch [131/300], Train Loss: 0.008191
Validation Loss: 0.00988162
Epoch [132/300], Train Loss: 0.008196
Validation Loss: 0.00987651
Epoch [133/300], Train Loss: 0.008151
Validation Loss: 0.00986184
Epoch [134/300], Train Loss: 0.008205
Validation Loss: 0.00985769
Epoch [135/300], Train Loss: 0.008167
Validation Loss: 0.00985819
Epoch [136/300], Train Loss: 0.008171
Validation Loss: 0.00984637
Epoch [137/300], Train Loss: 0.008167
Validation Loss: 0.00985286
Epoch [138/300], Train Loss: 0.008165
Validation Loss: 0.00984229
Epoch [139/300], Train Loss: 0.008170
Validation Loss: 0.00990673
Epoch [140/300], Train Loss: 0.008177
Validation Loss: 0.00982366
Epoch [141/300], Train Loss: 0.008152
Validation Loss: 0.00984081
Epoch [142/300], Train Loss: 0.008163
Validation Loss: 0.00986531
Epoch [143/300], Train Loss: 0.008180
Validation Loss: 0.00982314
Epoch [144/300], Train Loss: 0.008286
Validation Loss: 0.01018565
Epoch [145/300], Train Loss: 0.008576
Validation Loss: 0.00985528
Epoch [146/300], Train Loss: 0.008199
Validation Loss: 0.00989057
Epoch [147/300], Train Loss: 0.008248
Validation Loss: 0.00981223
Epoch [148/300], Train Loss: 0.008194
Validation Loss: 0.00984243
Epoch [149/300], Train Loss: 0.008131
Validation Loss: 0.00985142
Epoch [150/300], Train Loss: 0.008136
Validation Loss: 0.00980550
Epoch [151/300], Train Loss: 0.008102
Validation Loss: 0.00981877
Epoch [152/300], Train Loss: 0.008120
Validation Loss: 0.00981891
Epoch [153/300], Train Loss: 0.008114
Validation Loss: 0.00980855
Epoch [154/300], Train Loss: 0.008089
Validation Loss: 0.00981609
Epoch [155/300], Train Loss: 0.008133
Validation Loss: 0.00982164
Epoch [156/300], Train Loss: 0.008099
Validation Loss: 0.00981530
Epoch [157/300], Train Loss: 0.008123
Validation Loss: 0.00981766
Epoch [158/300], Train Loss: 0.008126
Validation Loss: 0.00981160
Epoch [159/300], Train Loss: 0.008097
Validation Loss: 0.00977922
Epoch [160/300], Train Loss: 0.008102
Validation Loss: 0.00978295
Epoch [161/300], Train Loss: 0.008079
Validation Loss: 0.00979803
Epoch [162/300], Train Loss: 0.008082
Validation Loss: 0.00977589
Epoch [163/300], Train Loss: 0.008090
Validation Loss: 0.00977285
Epoch [164/300], Train Loss: 0.008065
Validation Loss: 0.00980590
Epoch [165/300], Train Loss: 0.008095
Validation Loss: 0.00975941
Epoch [166/300], Train Loss: 0.008062
Validation Loss: 0.00975699
Epoch [167/300], Train Loss: 0.008056
Validation Loss: 0.00975793
Epoch [168/300], Train Loss: 0.008046
Validation Loss: 0.00977337
Epoch [169/300], Train Loss: 0.008035
Validation Loss: 0.00974795
Epoch [170/300], Train Loss: 0.008039
Validation Loss: 0.00977087
Epoch [171/300], Train Loss: 0.008034
Validation Loss: 0.00976543
Epoch [172/300], Train Loss: 0.008039
Validation Loss: 0.00975826
Epoch [173/300], Train Loss: 0.008022
Validation Loss: 0.00973806
Epoch [174/300], Train Loss: 0.008039
Validation Loss: 0.00973825
Epoch [175/300], Train Loss: 0.008017
Validation Loss: 0.00974248
Epoch [176/300], Train Loss: 0.008018
Validation Loss: 0.00972826
Epoch [177/300], Train Loss: 0.008014
Validation Loss: 0.00975154
Epoch [178/300], Train Loss: 0.008009
Validation Loss: 0.00973276
Epoch [179/300], Train Loss: 0.008013
Validation Loss: 0.00971983
Epoch [180/300], Train Loss: 0.007999
Validation Loss: 0.00974141
Epoch [181/300], Train Loss: 0.008009
Validation Loss: 0.00973426
Epoch [182/300], Train Loss: 0.007994
Validation Loss: 0.00971847
Epoch [183/300], Train Loss: 0.007994
Validation Loss: 0.00974063
Epoch [184/300], Train Loss: 0.008006
Validation Loss: 0.00972106
Epoch [185/300], Train Loss: 0.008005
Validation Loss: 0.00971476
Epoch [186/300], Train Loss: 0.007996
Validation Loss: 0.00971024
Epoch [187/300], Train Loss: 0.007988
Validation Loss: 0.00969923
Epoch [188/300], Train Loss: 0.007989
Validation Loss: 0.00970374
Epoch [189/300], Train Loss: 0.007986
Validation Loss: 0.00969823
Epoch [190/300], Train Loss: 0.007995
Validation Loss: 0.00971134
Epoch [191/300], Train Loss: 0.007977
Validation Loss: 0.00968877
Epoch [192/300], Train Loss: 0.007970
Validation Loss: 0.00971115
Epoch [193/300], Train Loss: 0.007975
Validation Loss: 0.00969091
Epoch [194/300], Train Loss: 0.007973
Validation Loss: 0.00968484
Epoch [195/300], Train Loss: 0.007968
Validation Loss: 0.00969668
Epoch [196/300], Train Loss: 0.008054
Validation Loss: 0.00970281
Epoch [197/300], Train Loss: 0.007971
Validation Loss: 0.00971068
Epoch [198/300], Train Loss: 0.008000
Validation Loss: 0.00968150
Epoch [199/300], Train Loss: 0.007971
Validation Loss: 0.00969808
Epoch [200/300], Train Loss: 0.007974
Validation Loss: 0.00967049
Epoch [201/300], Train Loss: 0.007959
Validation Loss: 0.00967901
Epoch [202/300], Train Loss: 0.007950
Validation Loss: 0.00966861
Epoch [203/300], Train Loss: 0.007941
Validation Loss: 0.00966665
Epoch [204/300], Train Loss: 0.007961
Validation Loss: 0.00968904
Epoch [205/300], Train Loss: 0.007940
Validation Loss: 0.00966088
Epoch [206/300], Train Loss: 0.007948
Validation Loss: 0.00969571
Epoch [207/300], Train Loss: 0.007960
Validation Loss: 0.00969436
Epoch [208/300], Train Loss: 0.007972
Validation Loss: 0.00967246
Epoch [209/300], Train Loss: 0.007963
Validation Loss: 0.00968515
Epoch [210/300], Train Loss: 0.007925
Validation Loss: 0.00965787
Epoch [211/300], Train Loss: 0.007928
Validation Loss: 0.00966371
Epoch [212/300], Train Loss: 0.007925
Validation Loss: 0.00965086
Epoch [213/300], Train Loss: 0.007925
Validation Loss: 0.00965968
Epoch [214/300], Train Loss: 0.007937
Validation Loss: 0.00964098
Epoch [215/300], Train Loss: 0.007920
Validation Loss: 0.00964612
Epoch [216/300], Train Loss: 0.007925
Validation Loss: 0.00964296
Epoch [217/300], Train Loss: 0.007921
Validation Loss: 0.00963699
Epoch [218/300], Train Loss: 0.007933
Validation Loss: 0.00965449
Epoch [219/300], Train Loss: 0.007905
Validation Loss: 0.00963564
Epoch [220/300], Train Loss: 0.007914
Validation Loss: 0.00965311
Epoch [221/300], Train Loss: 0.007907
Validation Loss: 0.00962993
Epoch [222/300], Train Loss: 0.007911
Validation Loss: 0.00962900
Epoch [223/300], Train Loss: 0.007896
Validation Loss: 0.00964332
Epoch [224/300], Train Loss: 0.007903
Validation Loss: 0.00962679
Epoch [225/300], Train Loss: 0.007901
Validation Loss: 0.00964087
Epoch [226/300], Train Loss: 0.007902
Validation Loss: 0.00962054
Epoch [227/300], Train Loss: 0.007895
Validation Loss: 0.00962012
Epoch [228/300], Train Loss: 0.007898
Validation Loss: 0.00962392
Epoch [229/300], Train Loss: 0.007894
Validation Loss: 0.00962586
Epoch [230/300], Train Loss: 0.007882
Validation Loss: 0.00964050
Epoch [231/300], Train Loss: 0.007887
Validation Loss: 0.00961434
Epoch [232/300], Train Loss: 0.007890
Validation Loss: 0.00961406
Epoch [233/300], Train Loss: 0.007890
Validation Loss: 0.00964302
Epoch [234/300], Train Loss: 0.007880
Validation Loss: 0.00960646
Epoch [235/300], Train Loss: 0.007873
Validation Loss: 0.00961578
Epoch [236/300], Train Loss: 0.007872
Validation Loss: 0.00960552
Epoch [237/300], Train Loss: 0.007877
Validation Loss: 0.00962112
Epoch [238/300], Train Loss: 0.007902
Validation Loss: 0.00960711
Epoch [239/300], Train Loss: 0.007887
Validation Loss: 0.00961467
Epoch [240/300], Train Loss: 0.008013
Validation Loss: 0.00967871
Epoch [241/300], Train Loss: 0.007877
Validation Loss: 0.00960589
Epoch [242/300], Train Loss: 0.007872
Validation Loss: 0.00961862
Epoch [243/300], Train Loss: 0.007962
Validation Loss: 0.00961987
Epoch [244/300], Train Loss: 0.007929
Validation Loss: 0.00959722
Epoch [245/300], Train Loss: 0.007867
Validation Loss: 0.00962652
Epoch [246/300], Train Loss: 0.007896
Validation Loss: 0.00963794
Epoch [247/300], Train Loss: 0.007872
Validation Loss: 0.00960386
Epoch [248/300], Train Loss: 0.007854
Validation Loss: 0.00959893
Epoch [249/300], Train Loss: 0.007851
Validation Loss: 0.00958596
Epoch [250/300], Train Loss: 0.007848
Validation Loss: 0.00959525
Epoch [251/300], Train Loss: 0.007859
Validation Loss: 0.00959259
Epoch [252/300], Train Loss: 0.007852
Validation Loss: 0.00959243
Epoch [253/300], Train Loss: 0.007882
Validation Loss: 0.00958360
Epoch [254/300], Train Loss: 0.007838
Validation Loss: 0.00962108
Epoch [255/300], Train Loss: 0.007868
Validation Loss: 0.00960156
Epoch [256/300], Train Loss: 0.007853
Validation Loss: 0.00961597
Epoch [257/300], Train Loss: 0.007848
Validation Loss: 0.00957961
Epoch [258/300], Train Loss: 0.007834
Validation Loss: 0.00975019
Epoch [259/300], Train Loss: 0.007947
Validation Loss: 0.00963163
Epoch [260/300], Train Loss: 0.007909
Validation Loss: 0.00965277
Epoch [261/300], Train Loss: 0.007872
Validation Loss: 0.00959392
Epoch [262/300], Train Loss: 0.007832
Validation Loss: 0.00957124
Epoch [263/300], Train Loss: 0.007840
Validation Loss: 0.00958040
Epoch [264/300], Train Loss: 0.007836
Validation Loss: 0.00957785
Epoch [265/300], Train Loss: 0.007837
Validation Loss: 0.00958098
Epoch [266/300], Train Loss: 0.007824
Validation Loss: 0.00957169
Epoch [267/300], Train Loss: 0.007816
Validation Loss: 0.00956581
Epoch [268/300], Train Loss: 0.007810
Validation Loss: 0.00956168
Epoch [269/300], Train Loss: 0.007810
Validation Loss: 0.00956590
Epoch [270/300], Train Loss: 0.007820
Validation Loss: 0.00957199
Epoch [271/300], Train Loss: 0.007817
Validation Loss: 0.00956295
Epoch [272/300], Train Loss: 0.007817
Validation Loss: 0.00957078
Epoch [273/300], Train Loss: 0.007807
Validation Loss: 0.00956313
Epoch [274/300], Train Loss: 0.007802
Validation Loss: 0.00955809
Epoch [275/300], Train Loss: 0.007814
Validation Loss: 0.00955466
Epoch [276/300], Train Loss: 0.007800
Validation Loss: 0.00956588
Epoch [277/300], Train Loss: 0.007834
Validation Loss: 0.00958540
Epoch [278/300], Train Loss: 0.007835
Validation Loss: 0.00957993
Epoch [279/300], Train Loss: 0.007816
Validation Loss: 0.00954785
Epoch [280/300], Train Loss: 0.007797
Validation Loss: 0.00954923
Epoch [281/300], Train Loss: 0.007806
Validation Loss: 0.00955641
Epoch [282/300], Train Loss: 0.007801
Validation Loss: 0.00957553
Epoch [283/300], Train Loss: 0.007833
Validation Loss: 0.00956359
Epoch [284/300], Train Loss: 0.007802
Validation Loss: 0.00954137
Epoch [285/300], Train Loss: 0.007800
Validation Loss: 0.00959216
Epoch [286/300], Train Loss: 0.007845
Validation Loss: 0.00957699
Epoch [287/300], Train Loss: 0.007795
Validation Loss: 0.00952823
Epoch [288/300], Train Loss: 0.007837
Validation Loss: 0.00950752
Epoch [289/300], Train Loss: 0.007786
Validation Loss: 0.00953813
Epoch [290/300], Train Loss: 0.007782
Validation Loss: 0.00953825
Epoch [291/300], Train Loss: 0.007787
Validation Loss: 0.00955179
Epoch [292/300], Train Loss: 0.007789
Validation Loss: 0.00955450
Epoch [293/300], Train Loss: 0.007779
Validation Loss: 0.00954704
Epoch [294/300], Train Loss: 0.007781
Validation Loss: 0.00952801
Epoch [295/300], Train Loss: 0.007769
Validation Loss: 0.00954645
Epoch [296/300], Train Loss: 0.007777
Validation Loss: 0.00953782
Epoch [297/300], Train Loss: 0.007771
Validation Loss: 0.00957476
Epoch [298/300], Train Loss: 0.007854
Validation Loss: 0.00954007
Early stopping triggered

Evaluating model for: Tablet
Run 22/72 completed in 727.73 seconds with: {'MAE': np.float32(0.7273659), 'MSE': np.float32(1.4344274), 'RMSE': np.float32(1.1976758), 'SAE': np.float32(0.00091907126), 'NDE': np.float32(0.2756011)}

Run 23/72: hidden=128, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Tablet
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.123523
Validation Loss: 0.12070314
Epoch [2/300], Train Loss: 0.106458
Validation Loss: 0.10134777
Epoch [3/300], Train Loss: 0.083711
Validation Loss: 0.07063181
Epoch [4/300], Train Loss: 0.040648
Validation Loss: 0.01831218
Epoch [5/300], Train Loss: 0.020257
Validation Loss: 0.01865740
Epoch [6/300], Train Loss: 0.017755
Validation Loss: 0.01761244
Epoch [7/300], Train Loss: 0.016748
Validation Loss: 0.01730629
Epoch [8/300], Train Loss: 0.016559
Validation Loss: 0.01745206
Epoch [9/300], Train Loss: 0.016422
Validation Loss: 0.01721563
Epoch [10/300], Train Loss: 0.016333
Validation Loss: 0.01722587
Epoch [11/300], Train Loss: 0.016281
Validation Loss: 0.01716972
Epoch [12/300], Train Loss: 0.016217
Validation Loss: 0.01711904
Epoch [13/300], Train Loss: 0.016147
Validation Loss: 0.01703166
Epoch [14/300], Train Loss: 0.016068
Validation Loss: 0.01699356
Epoch [15/300], Train Loss: 0.015997
Validation Loss: 0.01691100
Epoch [16/300], Train Loss: 0.015896
Validation Loss: 0.01686748
Epoch [17/300], Train Loss: 0.015812
Validation Loss: 0.01679938
Epoch [18/300], Train Loss: 0.015705
Validation Loss: 0.01660716
Epoch [19/300], Train Loss: 0.015495
Validation Loss: 0.01650477
Epoch [20/300], Train Loss: 0.015310
Validation Loss: 0.01623107
Epoch [21/300], Train Loss: 0.015001
Validation Loss: 0.01601554
Epoch [22/300], Train Loss: 0.014573
Validation Loss: 0.01553214
Epoch [23/300], Train Loss: 0.013951
Validation Loss: 0.01489107
Epoch [24/300], Train Loss: 0.013194
Validation Loss: 0.01422781
Epoch [25/300], Train Loss: 0.012441
Validation Loss: 0.01380922
Epoch [26/300], Train Loss: 0.011985
Validation Loss: 0.01347842
Epoch [27/300], Train Loss: 0.011508
Validation Loss: 0.01292237
Epoch [28/300], Train Loss: 0.011059
Validation Loss: 0.01249462
Epoch [29/300], Train Loss: 0.010633
Validation Loss: 0.01216342
Epoch [30/300], Train Loss: 0.010342
Validation Loss: 0.01185722
Epoch [31/300], Train Loss: 0.010067
Validation Loss: 0.01170478
Epoch [32/300], Train Loss: 0.009995
Validation Loss: 0.01161350
Epoch [33/300], Train Loss: 0.009879
Validation Loss: 0.01153095
Epoch [34/300], Train Loss: 0.009831
Validation Loss: 0.01144977
Epoch [35/300], Train Loss: 0.009725
Validation Loss: 0.01135904
Epoch [36/300], Train Loss: 0.009613
Validation Loss: 0.01124141
Epoch [37/300], Train Loss: 0.009530
Validation Loss: 0.01112422
Epoch [38/300], Train Loss: 0.009429
Validation Loss: 0.01103977
Epoch [39/300], Train Loss: 0.009321
Validation Loss: 0.01106294
Epoch [40/300], Train Loss: 0.009263
Validation Loss: 0.01113001
Epoch [41/300], Train Loss: 0.009138
Validation Loss: 0.01076844
Epoch [42/300], Train Loss: 0.009053
Validation Loss: 0.01067832
Epoch [43/300], Train Loss: 0.008994
Validation Loss: 0.01066897
Epoch [44/300], Train Loss: 0.008948
Validation Loss: 0.01056292
Epoch [45/300], Train Loss: 0.008885
Validation Loss: 0.01042946
Epoch [46/300], Train Loss: 0.008863
Validation Loss: 0.01039063
Epoch [47/300], Train Loss: 0.008815
Validation Loss: 0.01038570
Epoch [48/300], Train Loss: 0.008850
Validation Loss: 0.01031982
Epoch [49/300], Train Loss: 0.008833
Validation Loss: 0.01044369
Epoch [50/300], Train Loss: 0.008826
Validation Loss: 0.01029011
Epoch [51/300], Train Loss: 0.008758
Validation Loss: 0.01025641
Epoch [52/300], Train Loss: 0.008748
Validation Loss: 0.01043864
Epoch [53/300], Train Loss: 0.008775
Validation Loss: 0.01049003
Epoch [54/300], Train Loss: 0.008874
Validation Loss: 0.01025624
Epoch [55/300], Train Loss: 0.008773
Validation Loss: 0.01024886
Epoch [56/300], Train Loss: 0.008658
Validation Loss: 0.01025628
Epoch [57/300], Train Loss: 0.008626
Validation Loss: 0.01025951
Epoch [58/300], Train Loss: 0.008719
Validation Loss: 0.01024511
Epoch [59/300], Train Loss: 0.008628
Validation Loss: 0.01020873
Epoch [60/300], Train Loss: 0.008586
Validation Loss: 0.01020087
Epoch [61/300], Train Loss: 0.008539
Validation Loss: 0.01028289
Epoch [62/300], Train Loss: 0.008573
Validation Loss: 0.01031308
Epoch [63/300], Train Loss: 0.008642
Validation Loss: 0.01026321
Epoch [64/300], Train Loss: 0.008618
Validation Loss: 0.01019013
Epoch [65/300], Train Loss: 0.008620
Validation Loss: 0.01017052
Epoch [66/300], Train Loss: 0.008550
Validation Loss: 0.01022769
Epoch [67/300], Train Loss: 0.008551
Validation Loss: 0.01011326
Epoch [68/300], Train Loss: 0.008474
Validation Loss: 0.01018084
Epoch [69/300], Train Loss: 0.008469
Validation Loss: 0.01011020
Epoch [70/300], Train Loss: 0.008453
Validation Loss: 0.01012930
Epoch [71/300], Train Loss: 0.008492
Validation Loss: 0.01016411
Epoch [72/300], Train Loss: 0.008424
Validation Loss: 0.01006851
Epoch [73/300], Train Loss: 0.008436
Validation Loss: 0.01008309
Epoch [74/300], Train Loss: 0.008510
Validation Loss: 0.01022592
Epoch [75/300], Train Loss: 0.008479
Validation Loss: 0.01008068
Epoch [76/300], Train Loss: 0.008408
Validation Loss: 0.01006049
Epoch [77/300], Train Loss: 0.008395
Validation Loss: 0.01005517
Epoch [78/300], Train Loss: 0.008386
Validation Loss: 0.01013120
Epoch [79/300], Train Loss: 0.009008
Validation Loss: 0.01031327
Epoch [80/300], Train Loss: 0.008515
Validation Loss: 0.01005050
Epoch [81/300], Train Loss: 0.008381
Validation Loss: 0.01003746
Epoch [82/300], Train Loss: 0.008361
Validation Loss: 0.01003904
Epoch [83/300], Train Loss: 0.008355
Validation Loss: 0.01012662
Epoch [84/300], Train Loss: 0.008468
Validation Loss: 0.01009488
Epoch [85/300], Train Loss: 0.008489
Validation Loss: 0.01009800
Epoch [86/300], Train Loss: 0.008423
Validation Loss: 0.01003214
Epoch [87/300], Train Loss: 0.008322
Validation Loss: 0.01000335
Epoch [88/300], Train Loss: 0.008293
Validation Loss: 0.01003627
Epoch [89/300], Train Loss: 0.008289
Validation Loss: 0.01000194
Epoch [90/300], Train Loss: 0.008298
Validation Loss: 0.01004096
Epoch [91/300], Train Loss: 0.008288
Validation Loss: 0.00998649
Epoch [92/300], Train Loss: 0.008283
Validation Loss: 0.00997381
Epoch [93/300], Train Loss: 0.008372
Validation Loss: 0.01009710
Epoch [94/300], Train Loss: 0.008316
Validation Loss: 0.01000209
Epoch [95/300], Train Loss: 0.008277
Validation Loss: 0.00996302
Epoch [96/300], Train Loss: 0.008255
Validation Loss: 0.00999189
Epoch [97/300], Train Loss: 0.008222
Validation Loss: 0.00995316
Epoch [98/300], Train Loss: 0.008236
Validation Loss: 0.00998109
Epoch [99/300], Train Loss: 0.008233
Validation Loss: 0.00995027
Epoch [100/300], Train Loss: 0.008215
Validation Loss: 0.00994142
Epoch [101/300], Train Loss: 0.008250
Validation Loss: 0.00995023
Epoch [102/300], Train Loss: 0.008215
Validation Loss: 0.00994232
Epoch [103/300], Train Loss: 0.008195
Validation Loss: 0.00992356
Epoch [104/300], Train Loss: 0.008213
Validation Loss: 0.00998040
Epoch [105/300], Train Loss: 0.008192
Validation Loss: 0.00992308
Epoch [106/300], Train Loss: 0.008179
Validation Loss: 0.00991588
Epoch [107/300], Train Loss: 0.008172
Validation Loss: 0.00991438
Epoch [108/300], Train Loss: 0.008214
Validation Loss: 0.00989636
Epoch [109/300], Train Loss: 0.008195
Validation Loss: 0.00999209
Epoch [110/300], Train Loss: 0.008169
Validation Loss: 0.00990032
Epoch [111/300], Train Loss: 0.008153
Validation Loss: 0.00989357
Epoch [112/300], Train Loss: 0.008174
Validation Loss: 0.00993921
Epoch [113/300], Train Loss: 0.008155
Validation Loss: 0.00991522
Epoch [114/300], Train Loss: 0.008197
Validation Loss: 0.00989650
Epoch [115/300], Train Loss: 0.008183
Validation Loss: 0.00987410
Epoch [116/300], Train Loss: 0.008190
Validation Loss: 0.01000919
Epoch [117/300], Train Loss: 0.008160
Validation Loss: 0.00987148
Epoch [118/300], Train Loss: 0.008130
Validation Loss: 0.00986068
Epoch [119/300], Train Loss: 0.008144
Validation Loss: 0.00986954
Epoch [120/300], Train Loss: 0.008163
Validation Loss: 0.00991393
Epoch [121/300], Train Loss: 0.008122
Validation Loss: 0.00987173
Epoch [122/300], Train Loss: 0.008118
Validation Loss: 0.00986976
Epoch [123/300], Train Loss: 0.008128
Validation Loss: 0.00985776
Epoch [124/300], Train Loss: 0.008078
Validation Loss: 0.00984805
Epoch [125/300], Train Loss: 0.008107
Validation Loss: 0.00983042
Epoch [126/300], Train Loss: 0.008076
Validation Loss: 0.00984152
Epoch [127/300], Train Loss: 0.008068
Validation Loss: 0.00983104
Epoch [128/300], Train Loss: 0.008050
Validation Loss: 0.00982095
Epoch [129/300], Train Loss: 0.008074
Validation Loss: 0.00984687
Epoch [130/300], Train Loss: 0.008084
Validation Loss: 0.00982691
Epoch [131/300], Train Loss: 0.008072
Validation Loss: 0.00980455
Epoch [132/300], Train Loss: 0.008060
Validation Loss: 0.00984885
Epoch [133/300], Train Loss: 0.008033
Validation Loss: 0.00982366
Epoch [134/300], Train Loss: 0.008126
Validation Loss: 0.00979080
Epoch [135/300], Train Loss: 0.008076
Validation Loss: 0.00985444
Epoch [136/300], Train Loss: 0.008124
Validation Loss: 0.00979570
Epoch [137/300], Train Loss: 0.008076
Validation Loss: 0.00982732
Epoch [138/300], Train Loss: 0.008012
Validation Loss: 0.00978130
Epoch [139/300], Train Loss: 0.008093
Validation Loss: 0.00977761
Epoch [140/300], Train Loss: 0.008012
Validation Loss: 0.00985164
Epoch [141/300], Train Loss: 0.008017
Validation Loss: 0.00975191
Epoch [142/300], Train Loss: 0.008031
Validation Loss: 0.00978908
Epoch [143/300], Train Loss: 0.007983
Validation Loss: 0.00974198
Epoch [144/300], Train Loss: 0.007986
Validation Loss: 0.00972922
Epoch [145/300], Train Loss: 0.007995
Validation Loss: 0.00973937
Epoch [146/300], Train Loss: 0.007987
Validation Loss: 0.00985532
Epoch [147/300], Train Loss: 0.008011
Validation Loss: 0.00973295
Epoch [148/300], Train Loss: 0.007975
Validation Loss: 0.00969369
Epoch [149/300], Train Loss: 0.008030
Validation Loss: 0.00982260
Epoch [150/300], Train Loss: 0.007983
Validation Loss: 0.00979460
Epoch [151/300], Train Loss: 0.007973
Validation Loss: 0.00972803
Epoch [152/300], Train Loss: 0.007955
Validation Loss: 0.00970389
Epoch [153/300], Train Loss: 0.007974
Validation Loss: 0.00977215
Epoch [154/300], Train Loss: 0.007981
Validation Loss: 0.00972721
Epoch [155/300], Train Loss: 0.007949
Validation Loss: 0.00971775
Epoch [156/300], Train Loss: 0.007944
Validation Loss: 0.00968361
Epoch [157/300], Train Loss: 0.007946
Validation Loss: 0.00969233
Epoch [158/300], Train Loss: 0.008129
Validation Loss: 0.01004138
Epoch [159/300], Train Loss: 0.008135
Validation Loss: 0.00981124
Epoch [160/300], Train Loss: 0.008235
Validation Loss: 0.00975913
Epoch [161/300], Train Loss: 0.008024
Validation Loss: 0.00972813
Epoch [162/300], Train Loss: 0.007949
Validation Loss: 0.00970097
Epoch [163/300], Train Loss: 0.007930
Validation Loss: 0.00966188
Epoch [164/300], Train Loss: 0.007895
Validation Loss: 0.00972763
Epoch [165/300], Train Loss: 0.007929
Validation Loss: 0.00967013
Epoch [166/300], Train Loss: 0.007907
Validation Loss: 0.00966581
Epoch [167/300], Train Loss: 0.007896
Validation Loss: 0.00966018
Epoch [168/300], Train Loss: 0.007879
Validation Loss: 0.00969441
Epoch [169/300], Train Loss: 0.007877
Validation Loss: 0.00966045
Epoch [170/300], Train Loss: 0.007882
Validation Loss: 0.00968447
Epoch [171/300], Train Loss: 0.007879
Validation Loss: 0.00967476
Epoch [172/300], Train Loss: 0.007877
Validation Loss: 0.00965909
Epoch [173/300], Train Loss: 0.007852
Validation Loss: 0.00962158
Epoch [174/300], Train Loss: 0.007877
Validation Loss: 0.00963140
Epoch [175/300], Train Loss: 0.007839
Validation Loss: 0.00964097
Epoch [176/300], Train Loss: 0.007855
Validation Loss: 0.00961395
Epoch [177/300], Train Loss: 0.007837
Validation Loss: 0.00962316
Epoch [178/300], Train Loss: 0.007812
Validation Loss: 0.00965960
Epoch [179/300], Train Loss: 0.007862
Validation Loss: 0.00959362
Epoch [180/300], Train Loss: 0.007816
Validation Loss: 0.00957594
Epoch [181/300], Train Loss: 0.008004
Validation Loss: 0.00956596
Epoch [182/300], Train Loss: 0.007864
Validation Loss: 0.00963436
Epoch [183/300], Train Loss: 0.007852
Validation Loss: 0.00957010
Epoch [184/300], Train Loss: 0.007873
Validation Loss: 0.00958324
Epoch [185/300], Train Loss: 0.007829
Validation Loss: 0.00966306
Epoch [186/300], Train Loss: 0.007858
Validation Loss: 0.00957443
Epoch [187/300], Train Loss: 0.007824
Validation Loss: 0.00955268
Epoch [188/300], Train Loss: 0.007811
Validation Loss: 0.00959519
Epoch [189/300], Train Loss: 0.007834
Validation Loss: 0.00959192
Epoch [190/300], Train Loss: 0.007820
Validation Loss: 0.00958388
Epoch [191/300], Train Loss: 0.007835
Validation Loss: 0.00953438
Epoch [192/300], Train Loss: 0.007778
Validation Loss: 0.00959200
Epoch [193/300], Train Loss: 0.007790
Validation Loss: 0.00955227
Epoch [194/300], Train Loss: 0.007812
Validation Loss: 0.00953193
Epoch [195/300], Train Loss: 0.007797
Validation Loss: 0.00953248
Epoch [196/300], Train Loss: 0.007793
Validation Loss: 0.00953670
Epoch [197/300], Train Loss: 0.007773
Validation Loss: 0.00954688
Epoch [198/300], Train Loss: 0.007781
Validation Loss: 0.00952214
Epoch [199/300], Train Loss: 0.007776
Validation Loss: 0.00954454
Epoch [200/300], Train Loss: 0.007773
Validation Loss: 0.00951634
Epoch [201/300], Train Loss: 0.007765
Validation Loss: 0.00951963
Epoch [202/300], Train Loss: 0.007762
Validation Loss: 0.00950620
Epoch [203/300], Train Loss: 0.007748
Validation Loss: 0.00950232
Epoch [204/300], Train Loss: 0.007773
Validation Loss: 0.00953397
Epoch [205/300], Train Loss: 0.007755
Validation Loss: 0.00951094
Epoch [206/300], Train Loss: 0.007774
Validation Loss: 0.00952071
Epoch [207/300], Train Loss: 0.007766
Validation Loss: 0.00950560
Epoch [208/300], Train Loss: 0.007749
Validation Loss: 0.00949484
Epoch [209/300], Train Loss: 0.007785
Validation Loss: 0.00949875
Epoch [210/300], Train Loss: 0.007784
Validation Loss: 0.00951050
Epoch [211/300], Train Loss: 0.007788
Validation Loss: 0.00957911
Epoch [212/300], Train Loss: 0.007796
Validation Loss: 0.00950826
Epoch [213/300], Train Loss: 0.007735
Validation Loss: 0.00949812
Epoch [214/300], Train Loss: 0.007757
Validation Loss: 0.00948618
Epoch [215/300], Train Loss: 0.007806
Validation Loss: 0.00948297
Epoch [216/300], Train Loss: 0.007924
Validation Loss: 0.00961204
Epoch [217/300], Train Loss: 0.007964
Validation Loss: 0.00947640
Epoch [218/300], Train Loss: 0.007781
Validation Loss: 0.00947977
Epoch [219/300], Train Loss: 0.007751
Validation Loss: 0.00948399
Epoch [220/300], Train Loss: 0.007764
Validation Loss: 0.00948056
Epoch [221/300], Train Loss: 0.007745
Validation Loss: 0.00947613
Epoch [222/300], Train Loss: 0.007725
Validation Loss: 0.00946549
Epoch [223/300], Train Loss: 0.007696
Validation Loss: 0.00947717
Epoch [224/300], Train Loss: 0.007698
Validation Loss: 0.00945279
Epoch [225/300], Train Loss: 0.007705
Validation Loss: 0.00945624
Epoch [226/300], Train Loss: 0.007741
Validation Loss: 0.00944545
Epoch [227/300], Train Loss: 0.007733
Validation Loss: 0.00943764
Epoch [228/300], Train Loss: 0.007768
Validation Loss: 0.00945376
Epoch [229/300], Train Loss: 0.007728
Validation Loss: 0.00947711
Epoch [230/300], Train Loss: 0.007698
Validation Loss: 0.00945824
Epoch [231/300], Train Loss: 0.007681
Validation Loss: 0.00944145
Epoch [232/300], Train Loss: 0.007692
Validation Loss: 0.00945346
Epoch [233/300], Train Loss: 0.007710
Validation Loss: 0.00952147
Epoch [234/300], Train Loss: 0.007702
Validation Loss: 0.00943526
Epoch [235/300], Train Loss: 0.007673
Validation Loss: 0.00943013
Epoch [236/300], Train Loss: 0.007695
Validation Loss: 0.00943478
Epoch [237/300], Train Loss: 0.007670
Validation Loss: 0.00949877
Epoch [238/300], Train Loss: 0.007766
Validation Loss: 0.00945104
Epoch [239/300], Train Loss: 0.007696
Validation Loss: 0.00944912
Epoch [240/300], Train Loss: 0.007671
Validation Loss: 0.00944510
Epoch [241/300], Train Loss: 0.007662
Validation Loss: 0.00941826
Epoch [242/300], Train Loss: 0.007661
Validation Loss: 0.00944013
Epoch [243/300], Train Loss: 0.007660
Validation Loss: 0.00942603
Epoch [244/300], Train Loss: 0.007638
Validation Loss: 0.00942575
Epoch [245/300], Train Loss: 0.007705
Validation Loss: 0.00945348
Epoch [246/300], Train Loss: 0.007653
Validation Loss: 0.00942532
Epoch [247/300], Train Loss: 0.007676
Validation Loss: 0.00942618
Epoch [248/300], Train Loss: 0.007648
Validation Loss: 0.00941201
Epoch [249/300], Train Loss: 0.007640
Validation Loss: 0.00942202
Epoch [250/300], Train Loss: 0.007646
Validation Loss: 0.00941726
Epoch [251/300], Train Loss: 0.007649
Validation Loss: 0.00943750
Epoch [252/300], Train Loss: 0.007652
Validation Loss: 0.00943148
Epoch [253/300], Train Loss: 0.007645
Validation Loss: 0.00941342
Epoch [254/300], Train Loss: 0.007638
Validation Loss: 0.00946775
Epoch [255/300], Train Loss: 0.007659
Validation Loss: 0.00944641
Epoch [256/300], Train Loss: 0.007655
Validation Loss: 0.00944468
Epoch [257/300], Train Loss: 0.007632
Validation Loss: 0.00940011
Epoch [258/300], Train Loss: 0.007632
Validation Loss: 0.00945874
Epoch [259/300], Train Loss: 0.007665
Validation Loss: 0.00940436
Epoch [260/300], Train Loss: 0.007658
Validation Loss: 0.00941163
Epoch [261/300], Train Loss: 0.007630
Validation Loss: 0.00939516
Epoch [262/300], Train Loss: 0.007613
Validation Loss: 0.00939366
Epoch [263/300], Train Loss: 0.007608
Validation Loss: 0.00945080
Epoch [264/300], Train Loss: 0.007668
Validation Loss: 0.00945439
Epoch [265/300], Train Loss: 0.007662
Validation Loss: 0.00943972
Epoch [266/300], Train Loss: 0.007621
Validation Loss: 0.00940613
Epoch [267/300], Train Loss: 0.007634
Validation Loss: 0.00939647
Epoch [268/300], Train Loss: 0.007600
Validation Loss: 0.00938147
Epoch [269/300], Train Loss: 0.007600
Validation Loss: 0.00938902
Epoch [270/300], Train Loss: 0.007620
Validation Loss: 0.00938197
Epoch [271/300], Train Loss: 0.007643
Validation Loss: 0.00933625
Epoch [272/300], Train Loss: 0.007626
Validation Loss: 0.00943620
Epoch [273/300], Train Loss: 0.007654
Validation Loss: 0.00943422
Epoch [274/300], Train Loss: 0.007628
Validation Loss: 0.00939373
Epoch [275/300], Train Loss: 0.007637
Validation Loss: 0.00934202
Epoch [276/300], Train Loss: 0.007622
Validation Loss: 0.00938923
Epoch [277/300], Train Loss: 0.007636
Validation Loss: 0.00942259
Epoch [278/300], Train Loss: 0.007615
Validation Loss: 0.00934690
Epoch [279/300], Train Loss: 0.007666
Validation Loss: 0.00933239
Epoch [280/300], Train Loss: 0.007610
Validation Loss: 0.00939578
Epoch [281/300], Train Loss: 0.007612
Validation Loss: 0.00940685
Epoch [282/300], Train Loss: 0.007605
Validation Loss: 0.00934590
Epoch [283/300], Train Loss: 0.007615
Validation Loss: 0.00934545
Epoch [284/300], Train Loss: 0.007602
Validation Loss: 0.00934073
Epoch [285/300], Train Loss: 0.007686
Validation Loss: 0.00981874
Epoch [286/300], Train Loss: 0.008284
Validation Loss: 0.00974700
Epoch [287/300], Train Loss: 0.007951
Validation Loss: 0.00961777
Epoch [288/300], Train Loss: 0.007752
Validation Loss: 0.00954913
Epoch [289/300], Train Loss: 0.007735
Validation Loss: 0.00952655
Early stopping triggered

Evaluating model for: Tablet
Run 23/72 completed in 757.69 seconds with: {'MAE': np.float32(0.7268942), 'MSE': np.float32(1.4336578), 'RMSE': np.float32(1.1973544), 'SAE': np.float32(0.0025056666), 'NDE': np.float32(0.27552715)}

Run 24/72: hidden=128, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Tablet
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.078523
Validation Loss: 0.07494841
Epoch [2/300], Train Loss: 0.062178
Validation Loss: 0.05612286
Epoch [3/300], Train Loss: 0.040933
Validation Loss: 0.02885505
Epoch [4/300], Train Loss: 0.018953
Validation Loss: 0.01806927
Epoch [5/300], Train Loss: 0.015993
Validation Loss: 0.01759618
Epoch [6/300], Train Loss: 0.015747
Validation Loss: 0.01665324
Epoch [7/300], Train Loss: 0.015562
Validation Loss: 0.01672187
Epoch [8/300], Train Loss: 0.015497
Validation Loss: 0.01663855
Epoch [9/300], Train Loss: 0.015460
Validation Loss: 0.01661997
Epoch [10/300], Train Loss: 0.015412
Validation Loss: 0.01655610
Epoch [11/300], Train Loss: 0.015350
Validation Loss: 0.01655637
Epoch [12/300], Train Loss: 0.015287
Validation Loss: 0.01645566
Epoch [13/300], Train Loss: 0.015187
Validation Loss: 0.01632523
Epoch [14/300], Train Loss: 0.015032
Validation Loss: 0.01618070
Epoch [15/300], Train Loss: 0.014754
Validation Loss: 0.01580705
Epoch [16/300], Train Loss: 0.014232
Validation Loss: 0.01520224
Epoch [17/300], Train Loss: 0.013078
Validation Loss: 0.01397380
Epoch [18/300], Train Loss: 0.011711
Validation Loss: 0.01343363
Epoch [19/300], Train Loss: 0.010913
Validation Loss: 0.01244976
Epoch [20/300], Train Loss: 0.010117
Validation Loss: 0.01148686
Epoch [21/300], Train Loss: 0.009478
Validation Loss: 0.01104164
Epoch [22/300], Train Loss: 0.009219
Validation Loss: 0.01070650
Epoch [23/300], Train Loss: 0.008977
Validation Loss: 0.01051734
Epoch [24/300], Train Loss: 0.008863
Validation Loss: 0.01066121
Epoch [25/300], Train Loss: 0.008816
Validation Loss: 0.01012662
Epoch [26/300], Train Loss: 0.008632
Validation Loss: 0.01010297
Epoch [27/300], Train Loss: 0.008518
Validation Loss: 0.01005294
Epoch [28/300], Train Loss: 0.008480
Validation Loss: 0.00998771
Epoch [29/300], Train Loss: 0.008399
Validation Loss: 0.00993596
Epoch [30/300], Train Loss: 0.008493
Validation Loss: 0.00997706
Epoch [31/300], Train Loss: 0.008329
Validation Loss: 0.01000833
Epoch [32/300], Train Loss: 0.008310
Validation Loss: 0.00996872
Epoch [33/300], Train Loss: 0.008277
Validation Loss: 0.00986234
Epoch [34/300], Train Loss: 0.008321
Validation Loss: 0.00993468
Epoch [35/300], Train Loss: 0.008262
Validation Loss: 0.01002117
Epoch [36/300], Train Loss: 0.008241
Validation Loss: 0.00983487
Epoch [37/300], Train Loss: 0.008319
Validation Loss: 0.01009260
Epoch [38/300], Train Loss: 0.008551
Validation Loss: 0.01002431
Epoch [39/300], Train Loss: 0.008192
Validation Loss: 0.00999207
Epoch [40/300], Train Loss: 0.008265
Validation Loss: 0.00988209
Epoch [41/300], Train Loss: 0.008158
Validation Loss: 0.00986224
Epoch [42/300], Train Loss: 0.008121
Validation Loss: 0.00987855
Epoch [43/300], Train Loss: 0.008100
Validation Loss: 0.00992098
Epoch [44/300], Train Loss: 0.008097
Validation Loss: 0.00986207
Epoch [45/300], Train Loss: 0.008089
Validation Loss: 0.00978131
Epoch [46/300], Train Loss: 0.008131
Validation Loss: 0.00978852
Epoch [47/300], Train Loss: 0.008073
Validation Loss: 0.00978682
Epoch [48/300], Train Loss: 0.008054
Validation Loss: 0.01000369
Epoch [49/300], Train Loss: 0.008072
Validation Loss: 0.00987228
Epoch [50/300], Train Loss: 0.008029
Validation Loss: 0.00976004
Epoch [51/300], Train Loss: 0.007994
Validation Loss: 0.00983028
Epoch [52/300], Train Loss: 0.008038
Validation Loss: 0.00983151
Epoch [53/300], Train Loss: 0.008085
Validation Loss: 0.00981243
Epoch [54/300], Train Loss: 0.008160
Validation Loss: 0.00969914
Epoch [55/300], Train Loss: 0.008074
Validation Loss: 0.00968663
Epoch [56/300], Train Loss: 0.007937
Validation Loss: 0.00980195
Epoch [57/300], Train Loss: 0.007927
Validation Loss: 0.00966517
Epoch [58/300], Train Loss: 0.007956
Validation Loss: 0.00968905
Epoch [59/300], Train Loss: 0.007920
Validation Loss: 0.00970733
Epoch [60/300], Train Loss: 0.007937
Validation Loss: 0.00972889
Epoch [61/300], Train Loss: 0.007918
Validation Loss: 0.00972508
Epoch [62/300], Train Loss: 0.007938
Validation Loss: 0.00969597
Epoch [63/300], Train Loss: 0.007914
Validation Loss: 0.00963599
Epoch [64/300], Train Loss: 0.007985
Validation Loss: 0.00967649
Epoch [65/300], Train Loss: 0.008005
Validation Loss: 0.00965392
Epoch [66/300], Train Loss: 0.007888
Validation Loss: 0.00969026
Epoch [67/300], Train Loss: 0.007869
Validation Loss: 0.00964680
Epoch [68/300], Train Loss: 0.007886
Validation Loss: 0.00969902
Epoch [69/300], Train Loss: 0.007922
Validation Loss: 0.00970945
Epoch [70/300], Train Loss: 0.007886
Validation Loss: 0.00968264
Epoch [71/300], Train Loss: 0.007831
Validation Loss: 0.00989399
Epoch [72/300], Train Loss: 0.007917
Validation Loss: 0.00954483
Epoch [73/300], Train Loss: 0.007906
Validation Loss: 0.00975707
Epoch [74/300], Train Loss: 0.007898
Validation Loss: 0.00982379
Epoch [75/300], Train Loss: 0.007856
Validation Loss: 0.00956273
Epoch [76/300], Train Loss: 0.007834
Validation Loss: 0.00960500
Epoch [77/300], Train Loss: 0.007835
Validation Loss: 0.00967252
Epoch [78/300], Train Loss: 0.007844
Validation Loss: 0.01003894
Epoch [79/300], Train Loss: 0.008490
Validation Loss: 0.00980746
Epoch [80/300], Train Loss: 0.007975
Validation Loss: 0.00969091
Epoch [81/300], Train Loss: 0.007817
Validation Loss: 0.00968495
Epoch [82/300], Train Loss: 0.007790
Validation Loss: 0.00956482
Early stopping triggered

Evaluating model for: Tablet
Run 24/72 completed in 225.73 seconds with: {'MAE': np.float32(0.7408508), 'MSE': np.float32(1.4636678), 'RMSE': np.float32(1.2098213), 'SAE': np.float32(0.0023598166), 'NDE': np.float32(0.27839598)}

Run 25/72: hidden=256, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Tablet
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.039580
Validation Loss: 0.01644517
Epoch [2/300], Train Loss: 0.013546
Validation Loss: 0.01243600
Epoch [3/300], Train Loss: 0.011709
Validation Loss: 0.01107842
Epoch [4/300], Train Loss: 0.010835
Validation Loss: 0.01060993
Epoch [5/300], Train Loss: 0.010144
Validation Loss: 0.00990133
Epoch [6/300], Train Loss: 0.009750
Validation Loss: 0.00968497
Epoch [7/300], Train Loss: 0.009343
Validation Loss: 0.00921716
Epoch [8/300], Train Loss: 0.009067
Validation Loss: 0.00907083
Epoch [9/300], Train Loss: 0.008766
Validation Loss: 0.00905543
Epoch [10/300], Train Loss: 0.008477
Validation Loss: 0.00824533
Epoch [11/300], Train Loss: 0.008214
Validation Loss: 0.00804969
Epoch [12/300], Train Loss: 0.007989
Validation Loss: 0.00790697
Epoch [13/300], Train Loss: 0.007823
Validation Loss: 0.00772372
Epoch [14/300], Train Loss: 0.007756
Validation Loss: 0.00760961
Epoch [15/300], Train Loss: 0.007613
Validation Loss: 0.00751697
Epoch [16/300], Train Loss: 0.007554
Validation Loss: 0.00760719
Epoch [17/300], Train Loss: 0.007453
Validation Loss: 0.00745785
Epoch [18/300], Train Loss: 0.007388
Validation Loss: 0.00749724
Epoch [19/300], Train Loss: 0.007320
Validation Loss: 0.00755122
Epoch [20/300], Train Loss: 0.007234
Validation Loss: 0.00726030
Epoch [21/300], Train Loss: 0.007191
Validation Loss: 0.00720992
Epoch [22/300], Train Loss: 0.007134
Validation Loss: 0.00712858
Epoch [23/300], Train Loss: 0.007060
Validation Loss: 0.00704578
Epoch [24/300], Train Loss: 0.007003
Validation Loss: 0.00698405
Epoch [25/300], Train Loss: 0.006993
Validation Loss: 0.00706530
Epoch [26/300], Train Loss: 0.006889
Validation Loss: 0.00682104
Epoch [27/300], Train Loss: 0.006803
Validation Loss: 0.00694241
Epoch [28/300], Train Loss: 0.006783
Validation Loss: 0.00670997
Epoch [29/300], Train Loss: 0.006638
Validation Loss: 0.00673463
Epoch [30/300], Train Loss: 0.006322
Validation Loss: 0.00691385
Epoch [31/300], Train Loss: 0.005556
Validation Loss: 0.00493614
Epoch [32/300], Train Loss: 0.004624
Validation Loss: 0.00400065
Epoch [33/300], Train Loss: 0.004118
Validation Loss: 0.00379883
Epoch [34/300], Train Loss: 0.003812
Validation Loss: 0.00347020
Epoch [35/300], Train Loss: 0.003644
Validation Loss: 0.00339667
Epoch [36/300], Train Loss: 0.003524
Validation Loss: 0.00323773
Epoch [37/300], Train Loss: 0.003434
Validation Loss: 0.00328187
Epoch [38/300], Train Loss: 0.003362
Validation Loss: 0.00307604
Epoch [39/300], Train Loss: 0.003283
Validation Loss: 0.00305828
Epoch [40/300], Train Loss: 0.003178
Validation Loss: 0.00299376
Epoch [41/300], Train Loss: 0.003153
Validation Loss: 0.00286032
Epoch [42/300], Train Loss: 0.003031
Validation Loss: 0.00296267
Epoch [43/300], Train Loss: 0.003032
Validation Loss: 0.00320775
Epoch [44/300], Train Loss: 0.003011
Validation Loss: 0.00270023
Epoch [45/300], Train Loss: 0.002834
Validation Loss: 0.00264011
Epoch [46/300], Train Loss: 0.002761
Validation Loss: 0.00257503
Epoch [47/300], Train Loss: 0.002776
Validation Loss: 0.00253275
Epoch [48/300], Train Loss: 0.002949
Validation Loss: 0.00284755
Epoch [49/300], Train Loss: 0.002801
Validation Loss: 0.00261792
Epoch [50/300], Train Loss: 0.002694
Validation Loss: 0.00254584
Epoch [51/300], Train Loss: 0.002649
Validation Loss: 0.00246594
Epoch [52/300], Train Loss: 0.002604
Validation Loss: 0.00244463
Epoch [53/300], Train Loss: 0.002620
Validation Loss: 0.00275152
Epoch [54/300], Train Loss: 0.002591
Validation Loss: 0.00242459
Epoch [55/300], Train Loss: 0.002609
Validation Loss: 0.00239644
Epoch [56/300], Train Loss: 0.002593
Validation Loss: 0.00241742
Epoch [57/300], Train Loss: 0.002536
Validation Loss: 0.00238554
Epoch [58/300], Train Loss: 0.002615
Validation Loss: 0.00238980
Epoch [59/300], Train Loss: 0.002518
Validation Loss: 0.00241336
Epoch [60/300], Train Loss: 0.002510
Validation Loss: 0.00238932
Epoch [61/300], Train Loss: 0.002500
Validation Loss: 0.00248331
Epoch [62/300], Train Loss: 0.002476
Validation Loss: 0.00239581
Epoch [63/300], Train Loss: 0.002600
Validation Loss: 0.00236823
Epoch [64/300], Train Loss: 0.002456
Validation Loss: 0.00234565
Epoch [65/300], Train Loss: 0.002437
Validation Loss: 0.00232674
Epoch [66/300], Train Loss: 0.002449
Validation Loss: 0.00240569
Epoch [67/300], Train Loss: 0.002475
Validation Loss: 0.00260749
Epoch [68/300], Train Loss: 0.002438
Validation Loss: 0.00230656
Epoch [69/300], Train Loss: 0.002754
Validation Loss: 0.00236521
Epoch [70/300], Train Loss: 0.002477
Validation Loss: 0.00230020
Epoch [71/300], Train Loss: 0.002427
Validation Loss: 0.00231668
Epoch [72/300], Train Loss: 0.002452
Validation Loss: 0.00232349
Epoch [73/300], Train Loss: 0.002439
Validation Loss: 0.00238663
Epoch [74/300], Train Loss: 0.002395
Validation Loss: 0.00235157
Epoch [75/300], Train Loss: 0.002400
Validation Loss: 0.00226711
Epoch [76/300], Train Loss: 0.002404
Validation Loss: 0.00231125
Epoch [77/300], Train Loss: 0.002417
Validation Loss: 0.00229263
Epoch [78/300], Train Loss: 0.002361
Validation Loss: 0.00235419
Epoch [79/300], Train Loss: 0.002381
Validation Loss: 0.00229861
Epoch [80/300], Train Loss: 0.002443
Validation Loss: 0.00227283
Epoch [81/300], Train Loss: 0.002352
Validation Loss: 0.00229972
Epoch [82/300], Train Loss: 0.002363
Validation Loss: 0.00224628
Epoch [83/300], Train Loss: 0.002412
Validation Loss: 0.00234678
Epoch [84/300], Train Loss: 0.002402
Validation Loss: 0.00227382
Epoch [85/300], Train Loss: 0.002339
Validation Loss: 0.00223730
Epoch [86/300], Train Loss: 0.002488
Validation Loss: 0.00257341
Epoch [87/300], Train Loss: 0.002398
Validation Loss: 0.00244086
Epoch [88/300], Train Loss: 0.002382
Validation Loss: 0.00224288
Epoch [89/300], Train Loss: 0.002330
Validation Loss: 0.00223848
Epoch [90/300], Train Loss: 0.002317
Validation Loss: 0.00232195
Epoch [91/300], Train Loss: 0.002327
Validation Loss: 0.00230702
Epoch [92/300], Train Loss: 0.002317
Validation Loss: 0.00223506
Epoch [93/300], Train Loss: 0.002308
Validation Loss: 0.00223580
Epoch [94/300], Train Loss: 0.002306
Validation Loss: 0.00224349
Epoch [95/300], Train Loss: 0.002316
Validation Loss: 0.00222593
Epoch [96/300], Train Loss: 0.002320
Validation Loss: 0.00225660
Epoch [97/300], Train Loss: 0.002300
Validation Loss: 0.00221786
Epoch [98/300], Train Loss: 0.002328
Validation Loss: 0.00226010
Epoch [99/300], Train Loss: 0.002305
Validation Loss: 0.00223850
Epoch [100/300], Train Loss: 0.002311
Validation Loss: 0.00221556
Epoch [101/300], Train Loss: 0.002295
Validation Loss: 0.00222647
Epoch [102/300], Train Loss: 0.002293
Validation Loss: 0.00221072
Epoch [103/300], Train Loss: 0.002311
Validation Loss: 0.00226100
Epoch [104/300], Train Loss: 0.002284
Validation Loss: 0.00221579
Epoch [105/300], Train Loss: 0.002287
Validation Loss: 0.00236040
Epoch [106/300], Train Loss: 0.002268
Validation Loss: 0.00222701
Epoch [107/300], Train Loss: 0.002277
Validation Loss: 0.00224182
Epoch [108/300], Train Loss: 0.002266
Validation Loss: 0.00221930
Epoch [109/300], Train Loss: 0.002280
Validation Loss: 0.00225411
Epoch [110/300], Train Loss: 0.002304
Validation Loss: 0.00222513
Epoch [111/300], Train Loss: 0.002266
Validation Loss: 0.00221335
Epoch [112/300], Train Loss: 0.002255
Validation Loss: 0.00218933
Epoch [113/300], Train Loss: 0.002299
Validation Loss: 0.00238119
Epoch [114/300], Train Loss: 0.002269
Validation Loss: 0.00221975
Epoch [115/300], Train Loss: 0.002257
Validation Loss: 0.00221478
Epoch [116/300], Train Loss: 0.002290
Validation Loss: 0.00225163
Epoch [117/300], Train Loss: 0.002260
Validation Loss: 0.00222351
Epoch [118/300], Train Loss: 0.002259
Validation Loss: 0.00222009
Epoch [119/300], Train Loss: 0.002269
Validation Loss: 0.00221795
Epoch [120/300], Train Loss: 0.002258
Validation Loss: 0.00220959
Epoch [121/300], Train Loss: 0.002247
Validation Loss: 0.00220458
Epoch [122/300], Train Loss: 0.002243
Validation Loss: 0.00219654
Early stopping triggered

Evaluating model for: Tablet
Run 25/72 completed in 3183.29 seconds with: {'MAE': np.float32(0.38116902), 'MSE': np.float32(0.35410705), 'RMSE': np.float32(0.59506893), 'SAE': np.float32(0.009908641), 'NDE': np.float32(0.13657422)}

Run 26/72: hidden=256, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Tablet
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.025427
Validation Loss: 0.01322693
Epoch [2/300], Train Loss: 0.011531
Validation Loss: 0.01060183
Epoch [3/300], Train Loss: 0.010033
Validation Loss: 0.00960771
Epoch [4/300], Train Loss: 0.009330
Validation Loss: 0.00910374
Epoch [5/300], Train Loss: 0.008731
Validation Loss: 0.00856906
Epoch [6/300], Train Loss: 0.008388
Validation Loss: 0.00829028
Epoch [7/300], Train Loss: 0.008071
Validation Loss: 0.00810684
Epoch [8/300], Train Loss: 0.007890
Validation Loss: 0.00780356
Epoch [9/300], Train Loss: 0.007644
Validation Loss: 0.00780455
Epoch [10/300], Train Loss: 0.007576
Validation Loss: 0.00756464
Epoch [11/300], Train Loss: 0.007482
Validation Loss: 0.00745327
Epoch [12/300], Train Loss: 0.007330
Validation Loss: 0.00739073
Epoch [13/300], Train Loss: 0.007274
Validation Loss: 0.00726751
Epoch [14/300], Train Loss: 0.007181
Validation Loss: 0.00715389
Epoch [15/300], Train Loss: 0.007087
Validation Loss: 0.00708218
Epoch [16/300], Train Loss: 0.007007
Validation Loss: 0.00700531
Epoch [17/300], Train Loss: 0.006919
Validation Loss: 0.00691665
Epoch [18/300], Train Loss: 0.006844
Validation Loss: 0.00741147
Epoch [19/300], Train Loss: 0.006738
Validation Loss: 0.00698400
Epoch [20/300], Train Loss: 0.006402
Validation Loss: 0.00622448
Epoch [21/300], Train Loss: 0.005418
Validation Loss: 0.00433041
Epoch [22/300], Train Loss: 0.003997
Validation Loss: 0.00348848
Epoch [23/300], Train Loss: 0.003580
Validation Loss: 0.00307739
Epoch [24/300], Train Loss: 0.003443
Validation Loss: 0.00298755
Epoch [25/300], Train Loss: 0.003252
Validation Loss: 0.00281266
Epoch [26/300], Train Loss: 0.003057
Validation Loss: 0.00273475
Epoch [27/300], Train Loss: 0.002956
Validation Loss: 0.00275968
Epoch [28/300], Train Loss: 0.002878
Validation Loss: 0.00262505
Epoch [29/300], Train Loss: 0.002773
Validation Loss: 0.00267870
Epoch [30/300], Train Loss: 0.002735
Validation Loss: 0.00254915
Epoch [31/300], Train Loss: 0.002639
Validation Loss: 0.00248685
Epoch [32/300], Train Loss: 0.002584
Validation Loss: 0.00242424
Epoch [33/300], Train Loss: 0.002536
Validation Loss: 0.00236583
Epoch [34/300], Train Loss: 0.002535
Validation Loss: 0.00234629
Epoch [35/300], Train Loss: 0.002527
Validation Loss: 0.00227696
Epoch [36/300], Train Loss: 0.002508
Validation Loss: 0.00233108
Epoch [37/300], Train Loss: 0.002431
Validation Loss: 0.00228294
Epoch [38/300], Train Loss: 0.002443
Validation Loss: 0.00239287
Epoch [39/300], Train Loss: 0.002410
Validation Loss: 0.00223536
Epoch [40/300], Train Loss: 0.002429
Validation Loss: 0.00232352
Epoch [41/300], Train Loss: 0.002377
Validation Loss: 0.00224980
Epoch [42/300], Train Loss: 0.002399
Validation Loss: 0.00222883
Epoch [43/300], Train Loss: 0.002356
Validation Loss: 0.00223318
Epoch [44/300], Train Loss: 0.002553
Validation Loss: 0.00249928
Epoch [45/300], Train Loss: 0.002345
Validation Loss: 0.00221996
Epoch [46/300], Train Loss: 0.002325
Validation Loss: 0.00220254
Epoch [47/300], Train Loss: 0.002381
Validation Loss: 0.00239851
Epoch [48/300], Train Loss: 0.002354
Validation Loss: 0.00218304
Epoch [49/300], Train Loss: 0.002280
Validation Loss: 0.00221360
Epoch [50/300], Train Loss: 0.002264
Validation Loss: 0.00220963
Epoch [51/300], Train Loss: 0.002289
Validation Loss: 0.00223372
Epoch [52/300], Train Loss: 0.002263
Validation Loss: 0.00215352
Epoch [53/300], Train Loss: 0.002563
Validation Loss: 0.00250090
Epoch [54/300], Train Loss: 0.002335
Validation Loss: 0.00217016
Epoch [55/300], Train Loss: 0.002275
Validation Loss: 0.00216329
Epoch [56/300], Train Loss: 0.002252
Validation Loss: 0.00214091
Epoch [57/300], Train Loss: 0.002295
Validation Loss: 0.00216131
Epoch [58/300], Train Loss: 0.002221
Validation Loss: 0.00212754
Epoch [59/300], Train Loss: 0.002231
Validation Loss: 0.00215921
Epoch [60/300], Train Loss: 0.002229
Validation Loss: 0.00215473
Epoch [61/300], Train Loss: 0.002274
Validation Loss: 0.00217859
Epoch [62/300], Train Loss: 0.002206
Validation Loss: 0.00215650
Epoch [63/300], Train Loss: 0.002213
Validation Loss: 0.00211638
Epoch [64/300], Train Loss: 0.002300
Validation Loss: 0.00218815
Epoch [65/300], Train Loss: 0.002225
Validation Loss: 0.00211109
Epoch [66/300], Train Loss: 0.002230
Validation Loss: 0.00215221
Epoch [67/300], Train Loss: 0.002218
Validation Loss: 0.00216568
Epoch [68/300], Train Loss: 0.002214
Validation Loss: 0.00211838
Epoch [69/300], Train Loss: 0.002197
Validation Loss: 0.00215947
Epoch [70/300], Train Loss: 0.002170
Validation Loss: 0.00213284
Epoch [71/300], Train Loss: 0.002163
Validation Loss: 0.00211962
Epoch [72/300], Train Loss: 0.002171
Validation Loss: 0.00223993
Epoch [73/300], Train Loss: 0.002213
Validation Loss: 0.00224379
Epoch [74/300], Train Loss: 0.002174
Validation Loss: 0.00214524
Epoch [75/300], Train Loss: 0.002185
Validation Loss: 0.00212665
Early stopping triggered

Evaluating model for: Tablet
Run 26/72 completed in 2150.43 seconds with: {'MAE': np.float32(0.38913548), 'MSE': np.float32(0.33600396), 'RMSE': np.float32(0.5796585), 'SAE': np.float32(0.00044514186), 'NDE': np.float32(0.13303736)}

Run 27/72: hidden=256, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Tablet
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.026821
Validation Loss: 0.01502759
Epoch [2/300], Train Loss: 0.011719
Validation Loss: 0.01051379
Epoch [3/300], Train Loss: 0.009877
Validation Loss: 0.00957159
Epoch [4/300], Train Loss: 0.009191
Validation Loss: 0.00891390
Epoch [5/300], Train Loss: 0.008625
Validation Loss: 0.00840385
Epoch [6/300], Train Loss: 0.008153
Validation Loss: 0.00810833
Epoch [7/300], Train Loss: 0.007927
Validation Loss: 0.00784813
Epoch [8/300], Train Loss: 0.007723
Validation Loss: 0.00784143
Epoch [9/300], Train Loss: 0.007587
Validation Loss: 0.00755170
Epoch [10/300], Train Loss: 0.007440
Validation Loss: 0.00741322
Epoch [11/300], Train Loss: 0.007352
Validation Loss: 0.00732411
Epoch [12/300], Train Loss: 0.007234
Validation Loss: 0.00733124
Epoch [13/300], Train Loss: 0.007288
Validation Loss: 0.00714837
Epoch [14/300], Train Loss: 0.007061
Validation Loss: 0.00704484
Epoch [15/300], Train Loss: 0.006925
Validation Loss: 0.00690489
Epoch [16/300], Train Loss: 0.006753
Validation Loss: 0.00674143
Epoch [17/300], Train Loss: 0.006361
Validation Loss: 0.00570845
Epoch [18/300], Train Loss: 0.005888
Validation Loss: 0.00460994
Epoch [19/300], Train Loss: 0.004501
Validation Loss: 0.00401767
Epoch [20/300], Train Loss: 0.003965
Validation Loss: 0.00341152
Epoch [21/300], Train Loss: 0.003582
Validation Loss: 0.00303386
Epoch [22/300], Train Loss: 0.003197
Validation Loss: 0.00281310
Epoch [23/300], Train Loss: 0.003235
Validation Loss: 0.00696767
Epoch [24/300], Train Loss: 0.003511
Validation Loss: 0.00271692
Epoch [25/300], Train Loss: 0.002887
Validation Loss: 0.00250833
Epoch [26/300], Train Loss: 0.002663
Validation Loss: 0.00239954
Epoch [27/300], Train Loss: 0.002546
Validation Loss: 0.00348557
Epoch [28/300], Train Loss: 0.002692
Validation Loss: 0.00242308
Epoch [29/300], Train Loss: 0.002608
Validation Loss: 0.00230859
Epoch [30/300], Train Loss: 0.002461
Validation Loss: 0.00231014
Epoch [31/300], Train Loss: 0.002418
Validation Loss: 0.00227218
Epoch [32/300], Train Loss: 0.002418
Validation Loss: 0.00226799
Epoch [33/300], Train Loss: 0.003033
Validation Loss: 0.00233571
Epoch [34/300], Train Loss: 0.002455
Validation Loss: 0.00237397
Epoch [35/300], Train Loss: 0.002420
Validation Loss: 0.00229303
Epoch [36/300], Train Loss: 0.002482
Validation Loss: 0.00232574
Epoch [37/300], Train Loss: 0.002347
Validation Loss: 0.00220858
Epoch [38/300], Train Loss: 0.002325
Validation Loss: 0.00224323
Epoch [39/300], Train Loss: 0.002316
Validation Loss: 0.00219710
Epoch [40/300], Train Loss: 0.002318
Validation Loss: 0.00218349
Epoch [41/300], Train Loss: 0.002290
Validation Loss: 0.00219535
Epoch [42/300], Train Loss: 0.002327
Validation Loss: 0.00225321
Epoch [43/300], Train Loss: 0.002274
Validation Loss: 0.00228899
Epoch [44/300], Train Loss: 0.002295
Validation Loss: 0.00227277
Epoch [45/300], Train Loss: 0.002275
Validation Loss: 0.00217857
Epoch [46/300], Train Loss: 0.002258
Validation Loss: 0.00217126
Epoch [47/300], Train Loss: 0.002264
Validation Loss: 0.00224030
Epoch [48/300], Train Loss: 0.002239
Validation Loss: 0.00215785
Epoch [49/300], Train Loss: 0.002565
Validation Loss: 0.00222323
Epoch [50/300], Train Loss: 0.002525
Validation Loss: 0.00225748
Epoch [51/300], Train Loss: 0.002261
Validation Loss: 0.00216504
Epoch [52/300], Train Loss: 0.002222
Validation Loss: 0.00216282
Epoch [53/300], Train Loss: 0.002211
Validation Loss: 0.00217749
Epoch [54/300], Train Loss: 0.002203
Validation Loss: 0.00212778
Epoch [55/300], Train Loss: 0.002223
Validation Loss: 0.00215773
Epoch [56/300], Train Loss: 0.002194
Validation Loss: 0.00212566
Epoch [57/300], Train Loss: 0.002194
Validation Loss: 0.00213619
Epoch [58/300], Train Loss: 0.002259
Validation Loss: 0.00212468
Epoch [59/300], Train Loss: 0.002190
Validation Loss: 0.00225707
Epoch [60/300], Train Loss: 0.002181
Validation Loss: 0.00213853
Epoch [61/300], Train Loss: 0.002177
Validation Loss: 0.00213996
Epoch [62/300], Train Loss: 0.002208
Validation Loss: 0.00246586
Epoch [63/300], Train Loss: 0.002200
Validation Loss: 0.00215450
Epoch [64/300], Train Loss: 0.002166
Validation Loss: 0.00210895
Epoch [65/300], Train Loss: 0.002196
Validation Loss: 0.00211529
Epoch [66/300], Train Loss: 0.002173
Validation Loss: 0.00217051
Epoch [67/300], Train Loss: 0.002162
Validation Loss: 0.00216102
Epoch [68/300], Train Loss: 0.002157
Validation Loss: 0.00209787
Epoch [69/300], Train Loss: 0.002207
Validation Loss: 0.00211677
Epoch [70/300], Train Loss: 0.002159
Validation Loss: 0.00236436
Epoch [71/300], Train Loss: 0.002175
Validation Loss: 0.00211996
Epoch [72/300], Train Loss: 0.002228
Validation Loss: 0.00227498
Epoch [73/300], Train Loss: 0.002185
Validation Loss: 0.00209261
Epoch [74/300], Train Loss: 0.002231
Validation Loss: 0.00217048
Epoch [75/300], Train Loss: 0.002148
Validation Loss: 0.00211205
Epoch [76/300], Train Loss: 0.002150
Validation Loss: 0.00210404
Epoch [77/300], Train Loss: 0.002216
Validation Loss: 0.00211570
Epoch [78/300], Train Loss: 0.002140
Validation Loss: 0.00211033
Epoch [79/300], Train Loss: 0.002131
Validation Loss: 0.00213311
Epoch [80/300], Train Loss: 0.002126
Validation Loss: 0.00210604
Epoch [81/300], Train Loss: 0.002132
Validation Loss: 0.00210021
Epoch [82/300], Train Loss: 0.002114
Validation Loss: 0.00206220
Epoch [83/300], Train Loss: 0.002134
Validation Loss: 0.00208472
Epoch [84/300], Train Loss: 0.002146
Validation Loss: 0.00208547
Epoch [85/300], Train Loss: 0.002125
Validation Loss: 0.00208518
Epoch [86/300], Train Loss: 0.002173
Validation Loss: 0.00220632
Epoch [87/300], Train Loss: 0.002380
Validation Loss: 0.00229049
Epoch [88/300], Train Loss: 0.002214
Validation Loss: 0.00213489
Epoch [89/300], Train Loss: 0.002218
Validation Loss: 0.00213744
Epoch [90/300], Train Loss: 0.002118
Validation Loss: 0.00211636
Epoch [91/300], Train Loss: 0.002108
Validation Loss: 0.00211707
Epoch [92/300], Train Loss: 0.002115
Validation Loss: 0.00213579
Early stopping triggered

Evaluating model for: Tablet
Run 27/72 completed in 2786.92 seconds with: {'MAE': np.float32(0.37473604), 'MSE': np.float32(0.3349335), 'RMSE': np.float32(0.5787344), 'SAE': np.float32(0.009825881), 'NDE': np.float32(0.13282529)}

Run 28/72: hidden=256, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Tablet
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.032738
Validation Loss: 0.01683282
Epoch [2/300], Train Loss: 0.013107
Validation Loss: 0.01185814
Epoch [3/300], Train Loss: 0.011178
Validation Loss: 0.01050227
Epoch [4/300], Train Loss: 0.010185
Validation Loss: 0.00978509
Epoch [5/300], Train Loss: 0.009492
Validation Loss: 0.00929539
Epoch [6/300], Train Loss: 0.009066
Validation Loss: 0.00891960
Epoch [7/300], Train Loss: 0.008544
Validation Loss: 0.00867033
Epoch [8/300], Train Loss: 0.008182
Validation Loss: 0.00821562
Epoch [9/300], Train Loss: 0.007770
Validation Loss: 0.00766809
Epoch [10/300], Train Loss: 0.007933
Validation Loss: 0.00757002
Epoch [11/300], Train Loss: 0.007429
Validation Loss: 0.00734718
Epoch [12/300], Train Loss: 0.007333
Validation Loss: 0.00735104
Epoch [13/300], Train Loss: 0.007290
Validation Loss: 0.00720134
Epoch [14/300], Train Loss: 0.007145
Validation Loss: 0.00709878
Epoch [15/300], Train Loss: 0.007079
Validation Loss: 0.00703522
Epoch [16/300], Train Loss: 0.007042
Validation Loss: 0.00703361
Epoch [17/300], Train Loss: 0.006973
Validation Loss: 0.00695858
Epoch [18/300], Train Loss: 0.006933
Validation Loss: 0.00709759
Epoch [19/300], Train Loss: 0.006912
Validation Loss: 0.00708939
Epoch [20/300], Train Loss: 0.006826
Validation Loss: 0.00687938
Epoch [21/300], Train Loss: 0.006757
Validation Loss: 0.00669139
Epoch [22/300], Train Loss: 0.006645
Validation Loss: 0.00697155
Epoch [23/300], Train Loss: 0.006514
Validation Loss: 0.00646437
Epoch [24/300], Train Loss: 0.005716
Validation Loss: 0.00455810
Epoch [25/300], Train Loss: 0.004422
Validation Loss: 0.00325476
Epoch [26/300], Train Loss: 0.003323
Validation Loss: 0.00264474
Epoch [27/300], Train Loss: 0.002914
Validation Loss: 0.00244252
Epoch [28/300], Train Loss: 0.002666
Validation Loss: 0.00244475
Epoch [29/300], Train Loss: 0.002672
Validation Loss: 0.00232964
Epoch [30/300], Train Loss: 0.002588
Validation Loss: 0.00236617
Epoch [31/300], Train Loss: 0.002501
Validation Loss: 0.00230789
Epoch [32/300], Train Loss: 0.002453
Validation Loss: 0.00231077
Epoch [33/300], Train Loss: 0.002541
Validation Loss: 0.00224580
Epoch [34/300], Train Loss: 0.002368
Validation Loss: 0.00256479
Epoch [35/300], Train Loss: 0.002397
Validation Loss: 0.00226186
Epoch [36/300], Train Loss: 0.002392
Validation Loss: 0.00225578
Epoch [37/300], Train Loss: 0.002353
Validation Loss: 0.00234062
Epoch [38/300], Train Loss: 0.002470
Validation Loss: 0.00223203
Epoch [39/300], Train Loss: 0.002316
Validation Loss: 0.00216402
Epoch [40/300], Train Loss: 0.002291
Validation Loss: 0.00216846
Epoch [41/300], Train Loss: 0.002288
Validation Loss: 0.00216682
Epoch [42/300], Train Loss: 0.002313
Validation Loss: 0.00222646
Epoch [43/300], Train Loss: 0.002280
Validation Loss: 0.00215470
Epoch [44/300], Train Loss: 0.002368
Validation Loss: 0.00219348
Epoch [45/300], Train Loss: 0.002335
Validation Loss: 0.00216429
Epoch [46/300], Train Loss: 0.002247
Validation Loss: 0.00217530
Epoch [47/300], Train Loss: 0.002265
Validation Loss: 0.00217462
Epoch [48/300], Train Loss: 0.002279
Validation Loss: 0.00238948
Epoch [49/300], Train Loss: 0.002263
Validation Loss: 0.00216280
Epoch [50/300], Train Loss: 0.002252
Validation Loss: 0.00224878
Epoch [51/300], Train Loss: 0.002233
Validation Loss: 0.00211234
Epoch [52/300], Train Loss: 0.002216
Validation Loss: 0.00212272
Epoch [53/300], Train Loss: 0.002218
Validation Loss: 0.00222864
Epoch [54/300], Train Loss: 0.002255
Validation Loss: 0.00216904
Epoch [55/300], Train Loss: 0.002257
Validation Loss: 0.00210571
Epoch [56/300], Train Loss: 0.002219
Validation Loss: 0.00209639
Epoch [57/300], Train Loss: 0.002416
Validation Loss: 0.00214852
Epoch [58/300], Train Loss: 0.002195
Validation Loss: 0.00215184
Epoch [59/300], Train Loss: 0.002193
Validation Loss: 0.00210623
Epoch [60/300], Train Loss: 0.002174
Validation Loss: 0.00209542
Epoch [61/300], Train Loss: 0.002189
Validation Loss: 0.00209258
Epoch [62/300], Train Loss: 0.002170
Validation Loss: 0.00210614
Epoch [63/300], Train Loss: 0.002192
Validation Loss: 0.00212879
Epoch [64/300], Train Loss: 0.002200
Validation Loss: 0.00219674
Epoch [65/300], Train Loss: 0.002168
Validation Loss: 0.00209038
Epoch [66/300], Train Loss: 0.002156
Validation Loss: 0.00210967
Epoch [67/300], Train Loss: 0.002162
Validation Loss: 0.00212926
Epoch [68/300], Train Loss: 0.002250
Validation Loss: 0.00217407
Epoch [69/300], Train Loss: 0.002156
Validation Loss: 0.00218726
Epoch [70/300], Train Loss: 0.002210
Validation Loss: 0.00207702
Epoch [71/300], Train Loss: 0.002225
Validation Loss: 0.00215451
Epoch [72/300], Train Loss: 0.002171
Validation Loss: 0.00211887
Epoch [73/300], Train Loss: 0.002158
Validation Loss: 0.00215689
Epoch [74/300], Train Loss: 0.002141
Validation Loss: 0.00218804
Epoch [75/300], Train Loss: 0.002163
Validation Loss: 0.00208022
Epoch [76/300], Train Loss: 0.002165
Validation Loss: 0.00205551
Epoch [77/300], Train Loss: 0.002175
Validation Loss: 0.00207557
Epoch [78/300], Train Loss: 0.002134
Validation Loss: 0.00214112
Epoch [79/300], Train Loss: 0.002132
Validation Loss: 0.00209647
Epoch [80/300], Train Loss: 0.002122
Validation Loss: 0.00208704
Epoch [81/300], Train Loss: 0.002141
Validation Loss: 0.00209303
Epoch [82/300], Train Loss: 0.002201
Validation Loss: 0.00209828
Epoch [83/300], Train Loss: 0.002408
Validation Loss: 0.00217770
Epoch [84/300], Train Loss: 0.002137
Validation Loss: 0.00208286
Epoch [85/300], Train Loss: 0.002117
Validation Loss: 0.00206249
Epoch [86/300], Train Loss: 0.002118
Validation Loss: 0.00204834
Epoch [87/300], Train Loss: 0.002102
Validation Loss: 0.00205950
Epoch [88/300], Train Loss: 0.002109
Validation Loss: 0.00204924
Epoch [89/300], Train Loss: 0.002109
Validation Loss: 0.00205129
Epoch [90/300], Train Loss: 0.002241
Validation Loss: 0.00207680
Epoch [91/300], Train Loss: 0.002114
Validation Loss: 0.00208657
Epoch [92/300], Train Loss: 0.002184
Validation Loss: 0.00208133
Epoch [93/300], Train Loss: 0.002181
Validation Loss: 0.00207231
Epoch [94/300], Train Loss: 0.002125
Validation Loss: 0.00210876
Epoch [95/300], Train Loss: 0.002105
Validation Loss: 0.00206183
Epoch [96/300], Train Loss: 0.002250
Validation Loss: 0.00208119
Early stopping triggered

Evaluating model for: Tablet
Run 28/72 completed in 3356.99 seconds with: {'MAE': np.float32(0.37559277), 'MSE': np.float32(0.33168903), 'RMSE': np.float32(0.5759245), 'SAE': np.float32(0.007885066), 'NDE': np.float32(0.13218038)}

Run 29/72: hidden=256, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Tablet
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.041856
Validation Loss: 0.01806027
Epoch [2/300], Train Loss: 0.017487
Validation Loss: 0.01500358
Epoch [3/300], Train Loss: 0.013463
Validation Loss: 0.01149722
Epoch [4/300], Train Loss: 0.011584
Validation Loss: 0.01044590
Epoch [5/300], Train Loss: 0.010809
Validation Loss: 0.00967997
Epoch [6/300], Train Loss: 0.010278
Validation Loss: 0.00946228
Epoch [7/300], Train Loss: 0.009939
Validation Loss: 0.00897643
Epoch [8/300], Train Loss: 0.009664
Validation Loss: 0.00847905
Epoch [9/300], Train Loss: 0.009450
Validation Loss: 0.00836015
Epoch [10/300], Train Loss: 0.009365
Validation Loss: 0.00826125
Epoch [11/300], Train Loss: 0.009156
Validation Loss: 0.00818828
Epoch [12/300], Train Loss: 0.009136
Validation Loss: 0.00817587
Epoch [13/300], Train Loss: 0.009034
Validation Loss: 0.00794363
Epoch [14/300], Train Loss: 0.008824
Validation Loss: 0.00796940
Epoch [15/300], Train Loss: 0.008791
Validation Loss: 0.00795169
Epoch [16/300], Train Loss: 0.008662
Validation Loss: 0.00773134
Epoch [17/300], Train Loss: 0.008561
Validation Loss: 0.00766954
Epoch [18/300], Train Loss: 0.008546
Validation Loss: 0.00757874
Epoch [19/300], Train Loss: 0.008455
Validation Loss: 0.00746826
Epoch [20/300], Train Loss: 0.008346
Validation Loss: 0.00738698
Epoch [21/300], Train Loss: 0.008313
Validation Loss: 0.00750727
Epoch [22/300], Train Loss: 0.008250
Validation Loss: 0.00725241
Epoch [23/300], Train Loss: 0.008166
Validation Loss: 0.00720992
Epoch [24/300], Train Loss: 0.008134
Validation Loss: 0.00717949
Epoch [25/300], Train Loss: 0.007934
Validation Loss: 0.00698438
Epoch [26/300], Train Loss: 0.007899
Validation Loss: 0.00696454
Epoch [27/300], Train Loss: 0.007825
Validation Loss: 0.00693530
Epoch [28/300], Train Loss: 0.007742
Validation Loss: 0.00679430
Epoch [29/300], Train Loss: 0.007721
Validation Loss: 0.00673902
Epoch [30/300], Train Loss: 0.007583
Validation Loss: 0.00681610
Epoch [31/300], Train Loss: 0.007527
Validation Loss: 0.00664755
Epoch [32/300], Train Loss: 0.007473
Validation Loss: 0.00672339
Epoch [33/300], Train Loss: 0.007422
Validation Loss: 0.00692302
Epoch [34/300], Train Loss: 0.007309
Validation Loss: 0.00649160
Epoch [35/300], Train Loss: 0.007240
Validation Loss: 0.00646939
Epoch [36/300], Train Loss: 0.007206
Validation Loss: 0.00667551
Epoch [37/300], Train Loss: 0.007239
Validation Loss: 0.00669913
Epoch [38/300], Train Loss: 0.007156
Validation Loss: 0.00636246
Epoch [39/300], Train Loss: 0.007095
Validation Loss: 0.00636905
Epoch [40/300], Train Loss: 0.007110
Validation Loss: 0.00635031
Epoch [41/300], Train Loss: 0.006998
Validation Loss: 0.00622770
Epoch [42/300], Train Loss: 0.007000
Validation Loss: 0.00633602
Epoch [43/300], Train Loss: 0.007039
Validation Loss: 0.00629531
Epoch [44/300], Train Loss: 0.006933
Validation Loss: 0.00613257
Epoch [45/300], Train Loss: 0.006814
Validation Loss: 0.00610439
Epoch [46/300], Train Loss: 0.006748
Validation Loss: 0.00600258
Epoch [47/300], Train Loss: 0.006666
Validation Loss: 0.00593562
Epoch [48/300], Train Loss: 0.006599
Validation Loss: 0.00591762
Epoch [49/300], Train Loss: 0.006453
Validation Loss: 0.00570166
Epoch [50/300], Train Loss: 0.006301
Validation Loss: 0.00613047
Epoch [51/300], Train Loss: 0.006057
Validation Loss: 0.00512085
Epoch [52/300], Train Loss: 0.005570
Validation Loss: 0.00459304
Epoch [53/300], Train Loss: 0.004988
Validation Loss: 0.00420157
Epoch [54/300], Train Loss: 0.004548
Validation Loss: 0.00379064
Epoch [55/300], Train Loss: 0.004353
Validation Loss: 0.00356497
Epoch [56/300], Train Loss: 0.004038
Validation Loss: 0.00329309
Epoch [57/300], Train Loss: 0.003831
Validation Loss: 0.00322031
Epoch [58/300], Train Loss: 0.003693
Validation Loss: 0.00329809
Epoch [59/300], Train Loss: 0.003684
Validation Loss: 0.00307362
Epoch [60/300], Train Loss: 0.003512
Validation Loss: 0.00303285
Epoch [61/300], Train Loss: 0.003458
Validation Loss: 0.00298898
Epoch [62/300], Train Loss: 0.003509
Validation Loss: 0.00295500
Epoch [63/300], Train Loss: 0.003366
Validation Loss: 0.00293188
Epoch [64/300], Train Loss: 0.003320
Validation Loss: 0.00285713
Epoch [65/300], Train Loss: 0.003352
Validation Loss: 0.00293292
Epoch [66/300], Train Loss: 0.003345
Validation Loss: 0.00280707
Epoch [67/300], Train Loss: 0.003287
Validation Loss: 0.00283558
Epoch [68/300], Train Loss: 0.003237
Validation Loss: 0.00277329
Epoch [69/300], Train Loss: 0.003190
Validation Loss: 0.00277267
Epoch [70/300], Train Loss: 0.003188
Validation Loss: 0.00292390
Epoch [71/300], Train Loss: 0.003163
Validation Loss: 0.00272891
Epoch [72/300], Train Loss: 0.003145
Validation Loss: 0.00279275
Epoch [73/300], Train Loss: 0.003117
Validation Loss: 0.00272167
Epoch [74/300], Train Loss: 0.003067
Validation Loss: 0.00282082
Epoch [75/300], Train Loss: 0.003082
Validation Loss: 0.00266524
Epoch [76/300], Train Loss: 0.003013
Validation Loss: 0.00276063
Epoch [77/300], Train Loss: 0.003006
Validation Loss: 0.00263932
Epoch [78/300], Train Loss: 0.002920
Validation Loss: 0.00254296
Epoch [79/300], Train Loss: 0.002899
Validation Loss: 0.00263674
Epoch [80/300], Train Loss: 0.002878
Validation Loss: 0.00248148
Epoch [81/300], Train Loss: 0.002864
Validation Loss: 0.00258023
Epoch [82/300], Train Loss: 0.002778
Validation Loss: 0.00245294
Epoch [83/300], Train Loss: 0.002783
Validation Loss: 0.00245963
Epoch [84/300], Train Loss: 0.002761
Validation Loss: 0.00238544
Epoch [85/300], Train Loss: 0.002709
Validation Loss: 0.00245863
Epoch [86/300], Train Loss: 0.002766
Validation Loss: 0.00246790
Epoch [87/300], Train Loss: 0.002735
Validation Loss: 0.00243925
Epoch [88/300], Train Loss: 0.002664
Validation Loss: 0.00239995
Epoch [89/300], Train Loss: 0.002678
Validation Loss: 0.00234844
Epoch [90/300], Train Loss: 0.002660
Validation Loss: 0.00251937
Epoch [91/300], Train Loss: 0.002651
Validation Loss: 0.00234672
Epoch [92/300], Train Loss: 0.002657
Validation Loss: 0.00235812
Epoch [93/300], Train Loss: 0.002640
Validation Loss: 0.00231548
Epoch [94/300], Train Loss: 0.002630
Validation Loss: 0.00239960
Epoch [95/300], Train Loss: 0.002657
Validation Loss: 0.00240460
Epoch [96/300], Train Loss: 0.002662
Validation Loss: 0.00229239
Epoch [97/300], Train Loss: 0.002610
Validation Loss: 0.00228557
Epoch [98/300], Train Loss: 0.002598
Validation Loss: 0.00230645
Epoch [99/300], Train Loss: 0.002564
Validation Loss: 0.00237536
Epoch [100/300], Train Loss: 0.002624
Validation Loss: 0.00227291
Epoch [101/300], Train Loss: 0.002558
Validation Loss: 0.00228401
Epoch [102/300], Train Loss: 0.002571
Validation Loss: 0.00230013
Epoch [103/300], Train Loss: 0.002624
Validation Loss: 0.00232065
Epoch [104/300], Train Loss: 0.002595
Validation Loss: 0.00229292
Epoch [105/300], Train Loss: 0.002535
Validation Loss: 0.00226128
Epoch [106/300], Train Loss: 0.002514
Validation Loss: 0.00229153
Epoch [107/300], Train Loss: 0.002693
Validation Loss: 0.00231008
Epoch [108/300], Train Loss: 0.002513
Validation Loss: 0.00228515
Epoch [109/300], Train Loss: 0.002539
Validation Loss: 0.00233149
Epoch [110/300], Train Loss: 0.002523
Validation Loss: 0.00225564
Epoch [111/300], Train Loss: 0.002536
Validation Loss: 0.00225282
Epoch [112/300], Train Loss: 0.002500
Validation Loss: 0.00224446
Epoch [113/300], Train Loss: 0.002494
Validation Loss: 0.00224703
Epoch [114/300], Train Loss: 0.002500
Validation Loss: 0.00223677
Epoch [115/300], Train Loss: 0.002525
Validation Loss: 0.00223649
Epoch [116/300], Train Loss: 0.002590
Validation Loss: 0.00228670
Epoch [117/300], Train Loss: 0.002508
Validation Loss: 0.00229248
Epoch [118/300], Train Loss: 0.002493
Validation Loss: 0.00228084
Epoch [119/300], Train Loss: 0.002508
Validation Loss: 0.00226427
Epoch [120/300], Train Loss: 0.002501
Validation Loss: 0.00224316
Epoch [121/300], Train Loss: 0.002464
Validation Loss: 0.00222566
Epoch [122/300], Train Loss: 0.002470
Validation Loss: 0.00222694
Epoch [123/300], Train Loss: 0.002462
Validation Loss: 0.00226493
Epoch [124/300], Train Loss: 0.002591
Validation Loss: 0.00227240
Epoch [125/300], Train Loss: 0.002441
Validation Loss: 0.00224784
Epoch [126/300], Train Loss: 0.002563
Validation Loss: 0.00231650
Epoch [127/300], Train Loss: 0.002464
Validation Loss: 0.00222343
Epoch [128/300], Train Loss: 0.002470
Validation Loss: 0.00261300
Epoch [129/300], Train Loss: 0.002520
Validation Loss: 0.00224297
Epoch [130/300], Train Loss: 0.002424
Validation Loss: 0.00226019
Epoch [131/300], Train Loss: 0.002476
Validation Loss: 0.00224997
Epoch [132/300], Train Loss: 0.002428
Validation Loss: 0.00222755
Epoch [133/300], Train Loss: 0.002430
Validation Loss: 0.00221746
Epoch [134/300], Train Loss: 0.002414
Validation Loss: 0.00223521
Epoch [135/300], Train Loss: 0.002485
Validation Loss: 0.00252262
Epoch [136/300], Train Loss: 0.002521
Validation Loss: 0.00221101
Epoch [137/300], Train Loss: 0.002412
Validation Loss: 0.00221734
Epoch [138/300], Train Loss: 0.002488
Validation Loss: 0.00220934
Epoch [139/300], Train Loss: 0.002417
Validation Loss: 0.00219654
Epoch [140/300], Train Loss: 0.002433
Validation Loss: 0.00223870
Epoch [141/300], Train Loss: 0.002446
Validation Loss: 0.00222430
Epoch [142/300], Train Loss: 0.002427
Validation Loss: 0.00220310
Epoch [143/300], Train Loss: 0.002404
Validation Loss: 0.00223575
Epoch [144/300], Train Loss: 0.002441
Validation Loss: 0.00221329
Epoch [145/300], Train Loss: 0.002401
Validation Loss: 0.00221621
Epoch [146/300], Train Loss: 0.002408
Validation Loss: 0.00218550
Epoch [147/300], Train Loss: 0.002425
Validation Loss: 0.00221538
Epoch [148/300], Train Loss: 0.002446
Validation Loss: 0.00221143
Epoch [149/300], Train Loss: 0.002424
Validation Loss: 0.00221666
Epoch [150/300], Train Loss: 0.002402
Validation Loss: 0.00219467
Epoch [151/300], Train Loss: 0.002392
Validation Loss: 0.00218307
Epoch [152/300], Train Loss: 0.002397
Validation Loss: 0.00220128
Epoch [153/300], Train Loss: 0.002368
Validation Loss: 0.00222869
Epoch [154/300], Train Loss: 0.002441
Validation Loss: 0.00221907
Epoch [155/300], Train Loss: 0.002396
Validation Loss: 0.00216998
Epoch [156/300], Train Loss: 0.002545
Validation Loss: 0.00219084
Epoch [157/300], Train Loss: 0.002378
Validation Loss: 0.00220229
Epoch [158/300], Train Loss: 0.002385
Validation Loss: 0.00218791
Epoch [159/300], Train Loss: 0.002370
Validation Loss: 0.00223203
Epoch [160/300], Train Loss: 0.002405
Validation Loss: 0.00219929
Epoch [161/300], Train Loss: 0.002367
Validation Loss: 0.00221596
Epoch [162/300], Train Loss: 0.002452
Validation Loss: 0.00219170
Epoch [163/300], Train Loss: 0.002371
Validation Loss: 0.00217984
Epoch [164/300], Train Loss: 0.002416
Validation Loss: 0.00225921
Epoch [165/300], Train Loss: 0.002382
Validation Loss: 0.00220121
Early stopping triggered

Evaluating model for: Tablet
Run 29/72 completed in 2167.94 seconds with: {'MAE': np.float32(0.39967787), 'MSE': np.float32(0.37039527), 'RMSE': np.float32(0.6086011), 'SAE': np.float32(0.013477267), 'NDE': np.float32(0.1398603)}

Run 30/72: hidden=256, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Tablet
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.054881
Validation Loss: 0.01908598
Epoch [2/300], Train Loss: 0.019044
Validation Loss: 0.01738863
Epoch [3/300], Train Loss: 0.016418
Validation Loss: 0.01266098
Epoch [4/300], Train Loss: 0.012594
Validation Loss: 0.01124299
Epoch [5/300], Train Loss: 0.011716
Validation Loss: 0.01051006
Epoch [6/300], Train Loss: 0.010943
Validation Loss: 0.00966018
Epoch [7/300], Train Loss: 0.010189
Validation Loss: 0.00894899
Epoch [8/300], Train Loss: 0.009759
Validation Loss: 0.00859711
Epoch [9/300], Train Loss: 0.009314
Validation Loss: 0.00809856
Epoch [10/300], Train Loss: 0.008984
Validation Loss: 0.00788741
Epoch [11/300], Train Loss: 0.008708
Validation Loss: 0.00768662
Epoch [12/300], Train Loss: 0.008540
Validation Loss: 0.00746118
Epoch [13/300], Train Loss: 0.008391
Validation Loss: 0.00733645
Epoch [14/300], Train Loss: 0.008292
Validation Loss: 0.00730491
Epoch [15/300], Train Loss: 0.008168
Validation Loss: 0.00749134
Epoch [16/300], Train Loss: 0.008067
Validation Loss: 0.00708561
Epoch [17/300], Train Loss: 0.007927
Validation Loss: 0.00700756
Epoch [18/300], Train Loss: 0.007860
Validation Loss: 0.00694220
Epoch [19/300], Train Loss: 0.007845
Validation Loss: 0.00687849
Epoch [20/300], Train Loss: 0.007774
Validation Loss: 0.00680498
Epoch [21/300], Train Loss: 0.007679
Validation Loss: 0.00678168
Epoch [22/300], Train Loss: 0.007617
Validation Loss: 0.00676234
Epoch [23/300], Train Loss: 0.007583
Validation Loss: 0.00670526
Epoch [24/300], Train Loss: 0.007524
Validation Loss: 0.00668049
Epoch [25/300], Train Loss: 0.007494
Validation Loss: 0.00661136
Epoch [26/300], Train Loss: 0.007459
Validation Loss: 0.00659983
Epoch [27/300], Train Loss: 0.007393
Validation Loss: 0.00658274
Epoch [28/300], Train Loss: 0.007358
Validation Loss: 0.00648204
Epoch [29/300], Train Loss: 0.007340
Validation Loss: 0.00645437
Epoch [30/300], Train Loss: 0.007266
Validation Loss: 0.00643623
Epoch [31/300], Train Loss: 0.007262
Validation Loss: 0.00645168
Epoch [32/300], Train Loss: 0.007243
Validation Loss: 0.00654069
Epoch [33/300], Train Loss: 0.007216
Validation Loss: 0.00638520
Epoch [34/300], Train Loss: 0.007180
Validation Loss: 0.00640200
Epoch [35/300], Train Loss: 0.007153
Validation Loss: 0.00629809
Epoch [36/300], Train Loss: 0.007142
Validation Loss: 0.00628948
Epoch [37/300], Train Loss: 0.007087
Validation Loss: 0.00627946
Epoch [38/300], Train Loss: 0.007075
Validation Loss: 0.00633076
Epoch [39/300], Train Loss: 0.007048
Validation Loss: 0.00622159
Epoch [40/300], Train Loss: 0.007014
Validation Loss: 0.00619814
Epoch [41/300], Train Loss: 0.006978
Validation Loss: 0.00611570
Epoch [42/300], Train Loss: 0.006944
Validation Loss: 0.00607316
Epoch [43/300], Train Loss: 0.006906
Validation Loss: 0.00614412
Epoch [44/300], Train Loss: 0.006889
Validation Loss: 0.00604028
Epoch [45/300], Train Loss: 0.006866
Validation Loss: 0.00623783
Epoch [46/300], Train Loss: 0.006972
Validation Loss: 0.00599861
Epoch [47/300], Train Loss: 0.006831
Validation Loss: 0.00595898
Epoch [48/300], Train Loss: 0.006765
Validation Loss: 0.00633366
Epoch [49/300], Train Loss: 0.006648
Validation Loss: 0.00570111
Epoch [50/300], Train Loss: 0.006219
Validation Loss: 0.00559088
Epoch [51/300], Train Loss: 0.005873
Validation Loss: 0.00495105
Epoch [52/300], Train Loss: 0.005386
Validation Loss: 0.00438612
Epoch [53/300], Train Loss: 0.004907
Validation Loss: 0.00401238
Epoch [54/300], Train Loss: 0.004461
Validation Loss: 0.00358951
Epoch [55/300], Train Loss: 0.004398
Validation Loss: 0.00338235
Epoch [56/300], Train Loss: 0.004051
Validation Loss: 0.00327213
Epoch [57/300], Train Loss: 0.003908
Validation Loss: 0.00319028
Epoch [58/300], Train Loss: 0.003767
Validation Loss: 0.00301305
Epoch [59/300], Train Loss: 0.003665
Validation Loss: 0.00299716
Epoch [60/300], Train Loss: 0.003564
Validation Loss: 0.00307006
Epoch [61/300], Train Loss: 0.003480
Validation Loss: 0.00301444
Epoch [62/300], Train Loss: 0.003457
Validation Loss: 0.00278827
Epoch [63/300], Train Loss: 0.003286
Validation Loss: 0.00273586
Epoch [64/300], Train Loss: 0.003280
Validation Loss: 0.00264395
Epoch [65/300], Train Loss: 0.003152
Validation Loss: 0.00264148
Epoch [66/300], Train Loss: 0.003081
Validation Loss: 0.00251519
Epoch [67/300], Train Loss: 0.002983
Validation Loss: 0.00254169
Epoch [68/300], Train Loss: 0.002912
Validation Loss: 0.00242816
Epoch [69/300], Train Loss: 0.002865
Validation Loss: 0.00240722
Epoch [70/300], Train Loss: 0.003221
Validation Loss: 0.00249776
Epoch [71/300], Train Loss: 0.002930
Validation Loss: 0.00246716
Epoch [72/300], Train Loss: 0.002884
Validation Loss: 0.00377621
Epoch [73/300], Train Loss: 0.002955
Validation Loss: 0.00243058
Epoch [74/300], Train Loss: 0.002774
Validation Loss: 0.00234010
Epoch [75/300], Train Loss: 0.002727
Validation Loss: 0.00230881
Epoch [76/300], Train Loss: 0.002707
Validation Loss: 0.00233680
Epoch [77/300], Train Loss: 0.002706
Validation Loss: 0.00229746
Epoch [78/300], Train Loss: 0.002662
Validation Loss: 0.00229391
Epoch [79/300], Train Loss: 0.002678
Validation Loss: 0.00228269
Epoch [80/300], Train Loss: 0.002651
Validation Loss: 0.00226149
Epoch [81/300], Train Loss: 0.002631
Validation Loss: 0.00224738
Epoch [82/300], Train Loss: 0.002636
Validation Loss: 0.00236012
Epoch [83/300], Train Loss: 0.002797
Validation Loss: 0.00222421
Epoch [84/300], Train Loss: 0.002600
Validation Loss: 0.00220752
Epoch [85/300], Train Loss: 0.002584
Validation Loss: 0.00221443
Epoch [86/300], Train Loss: 0.002568
Validation Loss: 0.00222178
Epoch [87/300], Train Loss: 0.002581
Validation Loss: 0.00223564
Epoch [88/300], Train Loss: 0.002554
Validation Loss: 0.00222720
Epoch [89/300], Train Loss: 0.002547
Validation Loss: 0.00220870
Epoch [90/300], Train Loss: 0.002600
Validation Loss: 0.00225801
Epoch [91/300], Train Loss: 0.002528
Validation Loss: 0.00219080
Epoch [92/300], Train Loss: 0.002522
Validation Loss: 0.00219916
Epoch [93/300], Train Loss: 0.002603
Validation Loss: 0.00218817
Epoch [94/300], Train Loss: 0.002538
Validation Loss: 0.00221069
Epoch [95/300], Train Loss: 0.002512
Validation Loss: 0.00220141
Epoch [96/300], Train Loss: 0.002534
Validation Loss: 0.00216575
Epoch [97/300], Train Loss: 0.002523
Validation Loss: 0.00220757
Epoch [98/300], Train Loss: 0.002528
Validation Loss: 0.00218063
Epoch [99/300], Train Loss: 0.002537
Validation Loss: 0.00240842
Epoch [100/300], Train Loss: 0.002514
Validation Loss: 0.00215032
Epoch [101/300], Train Loss: 0.002538
Validation Loss: 0.00213724
Epoch [102/300], Train Loss: 0.002519
Validation Loss: 0.00217081
Epoch [103/300], Train Loss: 0.002472
Validation Loss: 0.00219671
Epoch [104/300], Train Loss: 0.002508
Validation Loss: 0.00217199
Epoch [105/300], Train Loss: 0.002465
Validation Loss: 0.00214003
Epoch [106/300], Train Loss: 0.002444
Validation Loss: 0.00219796
Epoch [107/300], Train Loss: 0.002446
Validation Loss: 0.00216975
Epoch [108/300], Train Loss: 0.002422
Validation Loss: 0.00214173
Epoch [109/300], Train Loss: 0.002426
Validation Loss: 0.00212158
Epoch [110/300], Train Loss: 0.002476
Validation Loss: 0.00213591
Epoch [111/300], Train Loss: 0.002458
Validation Loss: 0.00211744
Epoch [112/300], Train Loss: 0.002417
Validation Loss: 0.00213909
Epoch [113/300], Train Loss: 0.002526
Validation Loss: 0.00239683
Epoch [114/300], Train Loss: 0.002502
Validation Loss: 0.00216616
Epoch [115/300], Train Loss: 0.002414
Validation Loss: 0.00212825
Epoch [116/300], Train Loss: 0.002425
Validation Loss: 0.00213728
Epoch [117/300], Train Loss: 0.002441
Validation Loss: 0.00211557
Epoch [118/300], Train Loss: 0.002412
Validation Loss: 0.00214167
Epoch [119/300], Train Loss: 0.002395
Validation Loss: 0.00214993
Epoch [120/300], Train Loss: 0.002420
Validation Loss: 0.00212029
Epoch [121/300], Train Loss: 0.002368
Validation Loss: 0.00210501
Epoch [122/300], Train Loss: 0.002453
Validation Loss: 0.00212505
Epoch [123/300], Train Loss: 0.002375
Validation Loss: 0.00212004
Epoch [124/300], Train Loss: 0.002410
Validation Loss: 0.00259825
Epoch [125/300], Train Loss: 0.002700
Validation Loss: 0.00214119
Epoch [126/300], Train Loss: 0.002509
Validation Loss: 0.00212227
Epoch [127/300], Train Loss: 0.002374
Validation Loss: 0.00208846
Epoch [128/300], Train Loss: 0.002368
Validation Loss: 0.00208541
Epoch [129/300], Train Loss: 0.002408
Validation Loss: 0.00214713
Epoch [130/300], Train Loss: 0.002362
Validation Loss: 0.00209794
Epoch [131/300], Train Loss: 0.002420
Validation Loss: 0.00218432
Epoch [132/300], Train Loss: 0.002348
Validation Loss: 0.00209429
Epoch [133/300], Train Loss: 0.002351
Validation Loss: 0.00211670
Epoch [134/300], Train Loss: 0.002350
Validation Loss: 0.00209372
Epoch [135/300], Train Loss: 0.002348
Validation Loss: 0.00208538
Epoch [136/300], Train Loss: 0.002346
Validation Loss: 0.00207707
Epoch [137/300], Train Loss: 0.002422
Validation Loss: 0.00208165
Epoch [138/300], Train Loss: 0.002359
Validation Loss: 0.00210120
Epoch [139/300], Train Loss: 0.002340
Validation Loss: 0.00207117
Epoch [140/300], Train Loss: 0.002347
Validation Loss: 0.00207201
Epoch [141/300], Train Loss: 0.002340
Validation Loss: 0.00212267
Epoch [142/300], Train Loss: 0.002337
Validation Loss: 0.00208644
Epoch [143/300], Train Loss: 0.002349
Validation Loss: 0.00207420
Epoch [144/300], Train Loss: 0.002321
Validation Loss: 0.00206392
Epoch [145/300], Train Loss: 0.002320
Validation Loss: 0.00209253
Epoch [146/300], Train Loss: 0.002320
Validation Loss: 0.00206297
Epoch [147/300], Train Loss: 0.002363
Validation Loss: 0.00235051
Epoch [148/300], Train Loss: 0.002336
Validation Loss: 0.00207942
Epoch [149/300], Train Loss: 0.002400
Validation Loss: 0.00208696
Epoch [150/300], Train Loss: 0.002314
Validation Loss: 0.00210607
Epoch [151/300], Train Loss: 0.002313
Validation Loss: 0.00211033
Epoch [152/300], Train Loss: 0.002300
Validation Loss: 0.00210075
Epoch [153/300], Train Loss: 0.002323
Validation Loss: 0.00209535
Epoch [154/300], Train Loss: 0.002301
Validation Loss: 0.00209102
Epoch [155/300], Train Loss: 0.002327
Validation Loss: 0.00206670
Epoch [156/300], Train Loss: 0.002292
Validation Loss: 0.00205445
Epoch [157/300], Train Loss: 0.002311
Validation Loss: 0.00210800
Epoch [158/300], Train Loss: 0.002286
Validation Loss: 0.00207467
Epoch [159/300], Train Loss: 0.002285
Validation Loss: 0.00204960
Epoch [160/300], Train Loss: 0.002287
Validation Loss: 0.00206944
Epoch [161/300], Train Loss: 0.002297
Validation Loss: 0.00211703
Epoch [162/300], Train Loss: 0.002349
Validation Loss: 0.00211373
Epoch [163/300], Train Loss: 0.002303
Validation Loss: 0.00204689
Epoch [164/300], Train Loss: 0.002281
Validation Loss: 0.00204680
Epoch [165/300], Train Loss: 0.002275
Validation Loss: 0.00206778
Epoch [166/300], Train Loss: 0.002424
Validation Loss: 0.00206704
Epoch [167/300], Train Loss: 0.002333
Validation Loss: 0.00207178
Epoch [168/300], Train Loss: 0.002318
Validation Loss: 0.00205374
Epoch [169/300], Train Loss: 0.002293
Validation Loss: 0.00204498
Epoch [170/300], Train Loss: 0.002338
Validation Loss: 0.00230134
Epoch [171/300], Train Loss: 0.002335
Validation Loss: 0.00227722
Epoch [172/300], Train Loss: 0.002359
Validation Loss: 0.00210045
Epoch [173/300], Train Loss: 0.002287
Validation Loss: 0.00205262
Epoch [174/300], Train Loss: 0.002285
Validation Loss: 0.00210802
Epoch [175/300], Train Loss: 0.002289
Validation Loss: 0.00204881
Epoch [176/300], Train Loss: 0.002265
Validation Loss: 0.00206048
Epoch [177/300], Train Loss: 0.002277
Validation Loss: 0.00209802
Epoch [178/300], Train Loss: 0.002277
Validation Loss: 0.00206565
Epoch [179/300], Train Loss: 0.002285
Validation Loss: 0.00206867
Early stopping triggered

Evaluating model for: Tablet
Run 30/72 completed in 2518.86 seconds with: {'MAE': np.float32(0.3951347), 'MSE': np.float32(0.36087835), 'RMSE': np.float32(0.6007315), 'SAE': np.float32(0.011318108), 'NDE': np.float32(0.13805182)}

Run 31/72: hidden=256, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Tablet
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.044119
Validation Loss: 0.01741107
Epoch [2/300], Train Loss: 0.017432
Validation Loss: 0.01513917
Epoch [3/300], Train Loss: 0.013452
Validation Loss: 0.01151062
Epoch [4/300], Train Loss: 0.011935
Validation Loss: 0.01073156
Epoch [5/300], Train Loss: 0.011187
Validation Loss: 0.00987522
Epoch [6/300], Train Loss: 0.010590
Validation Loss: 0.00937090
Epoch [7/300], Train Loss: 0.010172
Validation Loss: 0.00899431
Epoch [8/300], Train Loss: 0.009854
Validation Loss: 0.00868875
Epoch [9/300], Train Loss: 0.009581
Validation Loss: 0.00838116
Epoch [10/300], Train Loss: 0.009437
Validation Loss: 0.00818048
Epoch [11/300], Train Loss: 0.009177
Validation Loss: 0.00811958
Epoch [12/300], Train Loss: 0.009079
Validation Loss: 0.00807705
Epoch [13/300], Train Loss: 0.008945
Validation Loss: 0.00782793
Epoch [14/300], Train Loss: 0.008719
Validation Loss: 0.00781098
Epoch [15/300], Train Loss: 0.008720
Validation Loss: 0.00806082
Epoch [16/300], Train Loss: 0.008478
Validation Loss: 0.00752371
Epoch [17/300], Train Loss: 0.008265
Validation Loss: 0.00731441
Epoch [18/300], Train Loss: 0.008057
Validation Loss: 0.00699805
Epoch [19/300], Train Loss: 0.007844
Validation Loss: 0.00690802
Epoch [20/300], Train Loss: 0.007820
Validation Loss: 0.00680229
Epoch [21/300], Train Loss: 0.007608
Validation Loss: 0.00659767
Epoch [22/300], Train Loss: 0.007515
Validation Loss: 0.00659006
Epoch [23/300], Train Loss: 0.007509
Validation Loss: 0.00651274
Epoch [24/300], Train Loss: 0.007314
Validation Loss: 0.00670224
Epoch [25/300], Train Loss: 0.007312
Validation Loss: 0.00641749
Epoch [26/300], Train Loss: 0.007273
Validation Loss: 0.00641060
Epoch [27/300], Train Loss: 0.007178
Validation Loss: 0.00632026
Epoch [28/300], Train Loss: 0.007112
Validation Loss: 0.00627251
Epoch [29/300], Train Loss: 0.007069
Validation Loss: 0.00633827
Epoch [30/300], Train Loss: 0.007069
Validation Loss: 0.00615507
Epoch [31/300], Train Loss: 0.006988
Validation Loss: 0.00612323
Epoch [32/300], Train Loss: 0.006916
Validation Loss: 0.00654101
Epoch [33/300], Train Loss: 0.006852
Validation Loss: 0.00649044
Epoch [34/300], Train Loss: 0.006697
Validation Loss: 0.00593676
Epoch [35/300], Train Loss: 0.006511
Validation Loss: 0.00549833
Epoch [36/300], Train Loss: 0.005937
Validation Loss: 0.00468248
Epoch [37/300], Train Loss: 0.005043
Validation Loss: 0.00388230
Epoch [38/300], Train Loss: 0.004370
Validation Loss: 0.00335459
Epoch [39/300], Train Loss: 0.004080
Validation Loss: 0.00312669
Epoch [40/300], Train Loss: 0.003868
Validation Loss: 0.00319069
Epoch [41/300], Train Loss: 0.003578
Validation Loss: 0.00287001
Epoch [42/300], Train Loss: 0.003499
Validation Loss: 0.00290452
Epoch [43/300], Train Loss: 0.003307
Validation Loss: 0.00266588
Epoch [44/300], Train Loss: 0.003156
Validation Loss: 0.00256924
Epoch [45/300], Train Loss: 0.003125
Validation Loss: 0.00247732
Epoch [46/300], Train Loss: 0.003208
Validation Loss: 0.00244138
Epoch [47/300], Train Loss: 0.002835
Validation Loss: 0.00236894
Epoch [48/300], Train Loss: 0.002789
Validation Loss: 0.00231118
Epoch [49/300], Train Loss: 0.002756
Validation Loss: 0.00236365
Epoch [50/300], Train Loss: 0.002739
Validation Loss: 0.00229401
Epoch [51/300], Train Loss: 0.002700
Validation Loss: 0.00226781
Epoch [52/300], Train Loss: 0.002721
Validation Loss: 0.00226141
Epoch [53/300], Train Loss: 0.002658
Validation Loss: 0.00237938
Epoch [54/300], Train Loss: 0.002643
Validation Loss: 0.00226452
Epoch [55/300], Train Loss: 0.002614
Validation Loss: 0.00226812
Epoch [56/300], Train Loss: 0.002597
Validation Loss: 0.00219482
Epoch [57/300], Train Loss: 0.002578
Validation Loss: 0.00216772
Epoch [58/300], Train Loss: 0.002540
Validation Loss: 0.00217283
Epoch [59/300], Train Loss: 0.002523
Validation Loss: 0.00215814
Epoch [60/300], Train Loss: 0.003603
Validation Loss: 0.00295132
Epoch [61/300], Train Loss: 0.002987
Validation Loss: 0.00232605
Epoch [62/300], Train Loss: 0.002668
Validation Loss: 0.00226259
Epoch [63/300], Train Loss: 0.002595
Validation Loss: 0.00221853
Epoch [64/300], Train Loss: 0.002567
Validation Loss: 0.00218232
Epoch [65/300], Train Loss: 0.002551
Validation Loss: 0.00222025
Epoch [66/300], Train Loss: 0.002517
Validation Loss: 0.00217421
Epoch [67/300], Train Loss: 0.002506
Validation Loss: 0.00215621
Epoch [68/300], Train Loss: 0.002496
Validation Loss: 0.00214066
Epoch [69/300], Train Loss: 0.002476
Validation Loss: 0.00214139
Epoch [70/300], Train Loss: 0.002479
Validation Loss: 0.00217049
Epoch [71/300], Train Loss: 0.002454
Validation Loss: 0.00213508
Epoch [72/300], Train Loss: 0.002456
Validation Loss: 0.00212872
Epoch [73/300], Train Loss: 0.002442
Validation Loss: 0.00214757
Epoch [74/300], Train Loss: 0.002503
Validation Loss: 0.00217843
Epoch [75/300], Train Loss: 0.002448
Validation Loss: 0.00212790
Epoch [76/300], Train Loss: 0.002428
Validation Loss: 0.00213613
Epoch [77/300], Train Loss: 0.002438
Validation Loss: 0.00220031
Epoch [78/300], Train Loss: 0.002416
Validation Loss: 0.00212052
Epoch [79/300], Train Loss: 0.002404
Validation Loss: 0.00213161
Epoch [80/300], Train Loss: 0.002407
Validation Loss: 0.00211717
Epoch [81/300], Train Loss: 0.002388
Validation Loss: 0.00212729
Epoch [82/300], Train Loss: 0.002395
Validation Loss: 0.00208320
Epoch [83/300], Train Loss: 0.002399
Validation Loss: 0.00211188
Epoch [84/300], Train Loss: 0.002397
Validation Loss: 0.00207659
Epoch [85/300], Train Loss: 0.002374
Validation Loss: 0.00207546
Epoch [86/300], Train Loss: 0.002364
Validation Loss: 0.00207729
Epoch [87/300], Train Loss: 0.002364
Validation Loss: 0.00209389
Epoch [88/300], Train Loss: 0.002360
Validation Loss: 0.00207148
Epoch [89/300], Train Loss: 0.002369
Validation Loss: 0.00208076
Epoch [90/300], Train Loss: 0.002353
Validation Loss: 0.00207671
Epoch [91/300], Train Loss: 0.002332
Validation Loss: 0.00208947
Epoch [92/300], Train Loss: 0.002367
Validation Loss: 0.00209435
Epoch [93/300], Train Loss: 0.002420
Validation Loss: 0.00207416
Epoch [94/300], Train Loss: 0.002432
Validation Loss: 0.00212063
Epoch [95/300], Train Loss: 0.002556
Validation Loss: 0.00207863
Epoch [96/300], Train Loss: 0.002401
Validation Loss: 0.00208545
Epoch [97/300], Train Loss: 0.002397
Validation Loss: 0.00207128
Epoch [98/300], Train Loss: 0.002392
Validation Loss: 0.00204846
Epoch [99/300], Train Loss: 0.002312
Validation Loss: 0.00204410
Epoch [100/300], Train Loss: 0.002301
Validation Loss: 0.00205262
Epoch [101/300], Train Loss: 0.002299
Validation Loss: 0.00207358
Epoch [102/300], Train Loss: 0.002292
Validation Loss: 0.00204581
Epoch [103/300], Train Loss: 0.002300
Validation Loss: 0.00210949
Epoch [104/300], Train Loss: 0.002304
Validation Loss: 0.00205412
Epoch [105/300], Train Loss: 0.002291
Validation Loss: 0.00204027
Epoch [106/300], Train Loss: 0.002294
Validation Loss: 0.00204643
Epoch [107/300], Train Loss: 0.002275
Validation Loss: 0.00206947
Epoch [108/300], Train Loss: 0.002286
Validation Loss: 0.00205464
Epoch [109/300], Train Loss: 0.002342
Validation Loss: 0.00206913
Epoch [110/300], Train Loss: 0.002271
Validation Loss: 0.00204467
Epoch [111/300], Train Loss: 0.002300
Validation Loss: 0.00203813
Epoch [112/300], Train Loss: 0.002260
Validation Loss: 0.00204239
Epoch [113/300], Train Loss: 0.002256
Validation Loss: 0.00201890
Epoch [114/300], Train Loss: 0.002261
Validation Loss: 0.00204247
Epoch [115/300], Train Loss: 0.002265
Validation Loss: 0.00200999
Epoch [116/300], Train Loss: 0.002303
Validation Loss: 0.00204021
Epoch [117/300], Train Loss: 0.002296
Validation Loss: 0.00204927
Epoch [118/300], Train Loss: 0.002241
Validation Loss: 0.00205422
Epoch [119/300], Train Loss: 0.002266
Validation Loss: 0.00203430
Epoch [120/300], Train Loss: 0.002275
Validation Loss: 0.00202477
Epoch [121/300], Train Loss: 0.002253
Validation Loss: 0.00202672
Epoch [122/300], Train Loss: 0.002239
Validation Loss: 0.00202339
Epoch [123/300], Train Loss: 0.002274
Validation Loss: 0.00201751
Epoch [124/300], Train Loss: 0.002234
Validation Loss: 0.00205303
Epoch [125/300], Train Loss: 0.002269
Validation Loss: 0.00213528
Early stopping triggered

Evaluating model for: Tablet
Run 31/72 completed in 1896.20 seconds with: {'MAE': np.float32(0.43559957), 'MSE': np.float32(0.36570477), 'RMSE': np.float32(0.6047353), 'SAE': np.float32(0.02202225), 'NDE': np.float32(0.13897194)}

Run 32/72: hidden=256, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Tablet
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.052761
Validation Loss: 0.01844250
Epoch [2/300], Train Loss: 0.018582
Validation Loss: 0.01658843
Epoch [3/300], Train Loss: 0.014410
Validation Loss: 0.01209412
Epoch [4/300], Train Loss: 0.012479
Validation Loss: 0.01126316
Epoch [5/300], Train Loss: 0.011694
Validation Loss: 0.01031918
Epoch [6/300], Train Loss: 0.010974
Validation Loss: 0.00995919
Epoch [7/300], Train Loss: 0.010418
Validation Loss: 0.00939107
Epoch [8/300], Train Loss: 0.010026
Validation Loss: 0.00880660
Epoch [9/300], Train Loss: 0.009700
Validation Loss: 0.00856351
Epoch [10/300], Train Loss: 0.009567
Validation Loss: 0.00839477
Epoch [11/300], Train Loss: 0.009319
Validation Loss: 0.00838411
Epoch [12/300], Train Loss: 0.009182
Validation Loss: 0.00828837
Epoch [13/300], Train Loss: 0.009011
Validation Loss: 0.00795342
Epoch [14/300], Train Loss: 0.008820
Validation Loss: 0.00804864
Epoch [15/300], Train Loss: 0.008759
Validation Loss: 0.00780519
Epoch [16/300], Train Loss: 0.008570
Validation Loss: 0.00766960
Epoch [17/300], Train Loss: 0.008433
Validation Loss: 0.00752561
Epoch [18/300], Train Loss: 0.008474
Validation Loss: 0.00766656
Epoch [19/300], Train Loss: 0.008286
Validation Loss: 0.00719974
Epoch [20/300], Train Loss: 0.008981
Validation Loss: 0.00735027
Epoch [21/300], Train Loss: 0.008180
Validation Loss: 0.00715993
Epoch [22/300], Train Loss: 0.007999
Validation Loss: 0.00705893
Epoch [23/300], Train Loss: 0.007905
Validation Loss: 0.00698900
Epoch [24/300], Train Loss: 0.007810
Validation Loss: 0.00690048
Epoch [25/300], Train Loss: 0.007701
Validation Loss: 0.00677899
Epoch [26/300], Train Loss: 0.007604
Validation Loss: 0.00664261
Epoch [27/300], Train Loss: 0.007539
Validation Loss: 0.00659096
Epoch [28/300], Train Loss: 0.007446
Validation Loss: 0.00656919
Epoch [29/300], Train Loss: 0.007335
Validation Loss: 0.00643158
Epoch [30/300], Train Loss: 0.007699
Validation Loss: 0.00652860
Epoch [31/300], Train Loss: 0.007251
Validation Loss: 0.00633050
Epoch [32/300], Train Loss: 0.007209
Validation Loss: 0.00635194
Epoch [33/300], Train Loss: 0.007120
Validation Loss: 0.00630152
Epoch [34/300], Train Loss: 0.007082
Validation Loss: 0.00625045
Epoch [35/300], Train Loss: 0.007008
Validation Loss: 0.00617549
Epoch [36/300], Train Loss: 0.007009
Validation Loss: 0.00617542
Epoch [37/300], Train Loss: 0.006938
Validation Loss: 0.00617910
Epoch [38/300], Train Loss: 0.006980
Validation Loss: 0.00618246
Epoch [39/300], Train Loss: 0.006915
Validation Loss: 0.00602882
Epoch [40/300], Train Loss: 0.006817
Validation Loss: 0.00602283
Epoch [41/300], Train Loss: 0.006766
Validation Loss: 0.00592418
Epoch [42/300], Train Loss: 0.006694
Validation Loss: 0.00581952
Epoch [43/300], Train Loss: 0.006561
Validation Loss: 0.00577763
Epoch [44/300], Train Loss: 0.006397
Validation Loss: 0.00526700
Epoch [45/300], Train Loss: 0.005809
Validation Loss: 0.00440409
Epoch [46/300], Train Loss: 0.004711
Validation Loss: 0.00348608
Epoch [47/300], Train Loss: 0.004014
Validation Loss: 0.00308179
Epoch [48/300], Train Loss: 0.003639
Validation Loss: 0.00292852
Epoch [49/300], Train Loss: 0.003377
Validation Loss: 0.00265558
Epoch [50/300], Train Loss: 0.003188
Validation Loss: 0.00255538
Epoch [51/300], Train Loss: 0.003367
Validation Loss: 0.00250837
Epoch [52/300], Train Loss: 0.003000
Validation Loss: 0.00246275
Epoch [53/300], Train Loss: 0.002965
Validation Loss: 0.00237354
Epoch [54/300], Train Loss: 0.002813
Validation Loss: 0.00227732
Epoch [55/300], Train Loss: 0.002778
Validation Loss: 0.00236645
Epoch [56/300], Train Loss: 0.002714
Validation Loss: 0.00222038
Epoch [57/300], Train Loss: 0.002649
Validation Loss: 0.00225668
Epoch [58/300], Train Loss: 0.002607
Validation Loss: 0.00216583
Epoch [59/300], Train Loss: 0.002630
Validation Loss: 0.00214621
Epoch [60/300], Train Loss: 0.002550
Validation Loss: 0.00215090
Epoch [61/300], Train Loss: 0.002524
Validation Loss: 0.00214840
Epoch [62/300], Train Loss: 0.002712
Validation Loss: 0.00216436
Epoch [63/300], Train Loss: 0.002498
Validation Loss: 0.00210883
Epoch [64/300], Train Loss: 0.002471
Validation Loss: 0.00211415
Epoch [65/300], Train Loss: 0.002462
Validation Loss: 0.00207462
Epoch [66/300], Train Loss: 0.002515
Validation Loss: 0.00211419
Epoch [67/300], Train Loss: 0.003892
Validation Loss: 0.00325251
Epoch [68/300], Train Loss: 0.003287
Validation Loss: 0.00227988
Epoch [69/300], Train Loss: 0.002668
Validation Loss: 0.00220644
Epoch [70/300], Train Loss: 0.002562
Validation Loss: 0.00217349
Epoch [71/300], Train Loss: 0.002512
Validation Loss: 0.00215236
Epoch [72/300], Train Loss: 0.002467
Validation Loss: 0.00214296
Epoch [73/300], Train Loss: 0.002464
Validation Loss: 0.00217460
Epoch [74/300], Train Loss: 0.002453
Validation Loss: 0.00210334
Epoch [75/300], Train Loss: 0.002424
Validation Loss: 0.00210763
Early stopping triggered

Evaluating model for: Tablet
Run 32/72 completed in 1298.23 seconds with: {'MAE': np.float32(0.40444127), 'MSE': np.float32(0.36395222), 'RMSE': np.float32(0.60328454), 'SAE': np.float32(0.0014107203), 'NDE': np.float32(0.13863853)}

Run 33/72: hidden=256, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Tablet
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.067876
Validation Loss: 0.02106937
Epoch [2/300], Train Loss: 0.017512
Validation Loss: 0.01783418
Epoch [3/300], Train Loss: 0.014865
Validation Loss: 0.01500488
Epoch [4/300], Train Loss: 0.012680
Validation Loss: 0.01356848
Epoch [5/300], Train Loss: 0.011862
Validation Loss: 0.01263650
Epoch [6/300], Train Loss: 0.011025
Validation Loss: 0.01175365
Epoch [7/300], Train Loss: 0.010204
Validation Loss: 0.01130660
Epoch [8/300], Train Loss: 0.009814
Validation Loss: 0.01147816
Epoch [9/300], Train Loss: 0.009500
Validation Loss: 0.01034898
Epoch [10/300], Train Loss: 0.009244
Validation Loss: 0.01013381
Epoch [11/300], Train Loss: 0.009085
Validation Loss: 0.00969417
Epoch [12/300], Train Loss: 0.008867
Validation Loss: 0.00966722
Epoch [13/300], Train Loss: 0.008537
Validation Loss: 0.00923399
Epoch [14/300], Train Loss: 0.008472
Validation Loss: 0.00875906
Epoch [15/300], Train Loss: 0.008319
Validation Loss: 0.00867629
Epoch [16/300], Train Loss: 0.008020
Validation Loss: 0.00842265
Epoch [17/300], Train Loss: 0.008047
Validation Loss: 0.00836256
Epoch [18/300], Train Loss: 0.008560
Validation Loss: 0.00852135
Epoch [19/300], Train Loss: 0.007836
Validation Loss: 0.00841812
Epoch [20/300], Train Loss: 0.007715
Validation Loss: 0.00816654
Epoch [21/300], Train Loss: 0.007611
Validation Loss: 0.00812212
Epoch [22/300], Train Loss: 0.007847
Validation Loss: 0.00803141
Epoch [23/300], Train Loss: 0.007725
Validation Loss: 0.00798404
Epoch [24/300], Train Loss: 0.007700
Validation Loss: 0.00798434
Epoch [25/300], Train Loss: 0.007820
Validation Loss: 0.00820788
Epoch [26/300], Train Loss: 0.007718
Validation Loss: 0.00888369
Epoch [27/300], Train Loss: 0.007521
Validation Loss: 0.00786679
Epoch [28/300], Train Loss: 0.007450
Validation Loss: 0.00786865
Epoch [29/300], Train Loss: 0.007343
Validation Loss: 0.00785489
Epoch [30/300], Train Loss: 0.007488
Validation Loss: 0.00781789
Epoch [31/300], Train Loss: 0.007628
Validation Loss: 0.00805633
Epoch [32/300], Train Loss: 0.007324
Validation Loss: 0.00772305
Epoch [33/300], Train Loss: 0.007311
Validation Loss: 0.00781275
Epoch [34/300], Train Loss: 0.007360
Validation Loss: 0.00769573
Epoch [35/300], Train Loss: 0.007271
Validation Loss: 0.00781946
Epoch [36/300], Train Loss: 0.007132
Validation Loss: 0.00765729
Epoch [37/300], Train Loss: 0.007207
Validation Loss: 0.00836260
Epoch [38/300], Train Loss: 0.007819
Validation Loss: 0.00765640
Epoch [39/300], Train Loss: 0.007192
Validation Loss: 0.00762335
Epoch [40/300], Train Loss: 0.007373
Validation Loss: 0.00760899
Epoch [41/300], Train Loss: 0.007284
Validation Loss: 0.00832256
Epoch [42/300], Train Loss: 0.007326
Validation Loss: 0.00768024
Epoch [43/300], Train Loss: 0.007326
Validation Loss: 0.00759874
Epoch [44/300], Train Loss: 0.007055
Validation Loss: 0.00791378
Epoch [45/300], Train Loss: 0.007340
Validation Loss: 0.00768309
Epoch [46/300], Train Loss: 0.007182
Validation Loss: 0.00759217
Epoch [47/300], Train Loss: 0.007135
Validation Loss: 0.00760289
Epoch [48/300], Train Loss: 0.007111
Validation Loss: 0.00757351
Epoch [49/300], Train Loss: 0.006966
Validation Loss: 0.00766221
Epoch [50/300], Train Loss: 0.007252
Validation Loss: 0.00847260
Epoch [51/300], Train Loss: 0.007219
Validation Loss: 0.00768206
Epoch [52/300], Train Loss: 0.007116
Validation Loss: 0.00748503
Epoch [53/300], Train Loss: 0.007077
Validation Loss: 0.00752065
Epoch [54/300], Train Loss: 0.007365
Validation Loss: 0.00744876
Epoch [55/300], Train Loss: 0.006932
Validation Loss: 0.00747142
Epoch [56/300], Train Loss: 0.007192
Validation Loss: 0.00764206
Epoch [57/300], Train Loss: 0.007264
Validation Loss: 0.00750062
Epoch [58/300], Train Loss: 0.007137
Validation Loss: 0.00751333
Epoch [59/300], Train Loss: 0.006944
Validation Loss: 0.00743701
Epoch [60/300], Train Loss: 0.007009
Validation Loss: 0.00737894
Epoch [61/300], Train Loss: 0.006882
Validation Loss: 0.00735735
Epoch [62/300], Train Loss: 0.006983
Validation Loss: 0.00739410
Epoch [63/300], Train Loss: 0.007118
Validation Loss: 0.00745506
Epoch [64/300], Train Loss: 0.006992
Validation Loss: 0.00739016
Epoch [65/300], Train Loss: 0.006973
Validation Loss: 0.00732896
Epoch [66/300], Train Loss: 0.007331
Validation Loss: 0.00864846
Epoch [67/300], Train Loss: 0.007077
Validation Loss: 0.00735538
Epoch [68/300], Train Loss: 0.007130
Validation Loss: 0.00738294
Epoch [69/300], Train Loss: 0.006945
Validation Loss: 0.00736295
Epoch [70/300], Train Loss: 0.006899
Validation Loss: 0.00728233
Epoch [71/300], Train Loss: 0.007941
Validation Loss: 0.01660521
Epoch [72/300], Train Loss: 0.012593
Validation Loss: 0.01162052
Epoch [73/300], Train Loss: 0.009154
Validation Loss: 0.00956898
Epoch [74/300], Train Loss: 0.008266
Validation Loss: 0.00917624
Epoch [75/300], Train Loss: 0.007881
Validation Loss: 0.00858001
Epoch [76/300], Train Loss: 0.007531
Validation Loss: 0.00851210
Epoch [77/300], Train Loss: 0.007558
Validation Loss: 0.00855505
Epoch [78/300], Train Loss: 0.007674
Validation Loss: 0.00767582
Epoch [79/300], Train Loss: 0.007285
Validation Loss: 0.00761815
Epoch [80/300], Train Loss: 0.007164
Validation Loss: 0.00761488
Early stopping triggered

Evaluating model for: Tablet
Run 33/72 completed in 942.10 seconds with: {'MAE': np.float32(0.67051333), 'MSE': np.float32(1.1747024), 'RMSE': np.float32(1.0838369), 'SAE': np.float32(0.009997875), 'NDE': np.float32(0.2506729)}

Run 34/72: hidden=256, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Tablet
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.057825
Validation Loss: 0.01912373
Epoch [2/300], Train Loss: 0.016660
Validation Loss: 0.01796650
Epoch [3/300], Train Loss: 0.016028
Validation Loss: 0.01744947
Epoch [4/300], Train Loss: 0.015237
Validation Loss: 0.01591386
Epoch [5/300], Train Loss: 0.012788
Validation Loss: 0.01295072
Epoch [6/300], Train Loss: 0.010906
Validation Loss: 0.01172937
Epoch [7/300], Train Loss: 0.010305
Validation Loss: 0.01122750
Epoch [8/300], Train Loss: 0.009829
Validation Loss: 0.01053399
Epoch [9/300], Train Loss: 0.009274
Validation Loss: 0.00989605
Epoch [10/300], Train Loss: 0.008993
Validation Loss: 0.00958352
Epoch [11/300], Train Loss: 0.008884
Validation Loss: 0.00935974
Epoch [12/300], Train Loss: 0.008776
Validation Loss: 0.00954596
Epoch [13/300], Train Loss: 0.008555
Validation Loss: 0.00921708
Epoch [14/300], Train Loss: 0.008526
Validation Loss: 0.00909820
Epoch [15/300], Train Loss: 0.008410
Validation Loss: 0.00955544
Epoch [16/300], Train Loss: 0.008277
Validation Loss: 0.00884652
Epoch [17/300], Train Loss: 0.008273
Validation Loss: 0.00891521
Epoch [18/300], Train Loss: 0.008244
Validation Loss: 0.00868957
Epoch [19/300], Train Loss: 0.008040
Validation Loss: 0.00866148
Epoch [20/300], Train Loss: 0.007888
Validation Loss: 0.00850676
Epoch [21/300], Train Loss: 0.007805
Validation Loss: 0.00844452
Epoch [22/300], Train Loss: 0.007851
Validation Loss: 0.00837008
Epoch [23/300], Train Loss: 0.007729
Validation Loss: 0.00829743
Epoch [24/300], Train Loss: 0.007625
Validation Loss: 0.00828205
Epoch [25/300], Train Loss: 0.007928
Validation Loss: 0.00848762
Epoch [26/300], Train Loss: 0.008522
Validation Loss: 0.00915437
Epoch [27/300], Train Loss: 0.007813
Validation Loss: 0.00820087
Epoch [28/300], Train Loss: 0.007534
Validation Loss: 0.00801836
Epoch [29/300], Train Loss: 0.007445
Validation Loss: 0.00799558
Epoch [30/300], Train Loss: 0.007428
Validation Loss: 0.00813379
Epoch [31/300], Train Loss: 0.007443
Validation Loss: 0.00795750
Epoch [32/300], Train Loss: 0.007348
Validation Loss: 0.00784972
Epoch [33/300], Train Loss: 0.007209
Validation Loss: 0.00781136
Epoch [34/300], Train Loss: 0.007305
Validation Loss: 0.00784825
Epoch [35/300], Train Loss: 0.007196
Validation Loss: 0.00774037
Epoch [36/300], Train Loss: 0.007130
Validation Loss: 0.00798865
Epoch [37/300], Train Loss: 0.007206
Validation Loss: 0.00855742
Epoch [38/300], Train Loss: 0.007334
Validation Loss: 0.00768371
Epoch [39/300], Train Loss: 0.007121
Validation Loss: 0.00759369
Epoch [40/300], Train Loss: 0.007269
Validation Loss: 0.00800117
Epoch [41/300], Train Loss: 0.007145
Validation Loss: 0.00763389
Epoch [42/300], Train Loss: 0.007147
Validation Loss: 0.00821731
Epoch [43/300], Train Loss: 0.007076
Validation Loss: 0.00767393
Epoch [44/300], Train Loss: 0.006967
Validation Loss: 0.00833653
Epoch [45/300], Train Loss: 0.007104
Validation Loss: 0.00761035
Epoch [46/300], Train Loss: 0.007069
Validation Loss: 0.00745171
Epoch [47/300], Train Loss: 0.007055
Validation Loss: 0.00851794
Epoch [48/300], Train Loss: 0.007208
Validation Loss: 0.00834082
Epoch [49/300], Train Loss: 0.007161
Validation Loss: 0.00746111
Epoch [50/300], Train Loss: 0.006949
Validation Loss: 0.00740310
Epoch [51/300], Train Loss: 0.006960
Validation Loss: 0.00751376
Epoch [52/300], Train Loss: 0.006926
Validation Loss: 0.00736235
Epoch [53/300], Train Loss: 0.006952
Validation Loss: 0.00739395
Epoch [54/300], Train Loss: 0.007019
Validation Loss: 0.00731315
Epoch [55/300], Train Loss: 0.006789
Validation Loss: 0.00733172
Epoch [56/300], Train Loss: 0.006988
Validation Loss: 0.00777464
Epoch [57/300], Train Loss: 0.006989
Validation Loss: 0.00746169
Epoch [58/300], Train Loss: 0.006786
Validation Loss: 0.00732453
Epoch [59/300], Train Loss: 0.006737
Validation Loss: 0.00726595
Epoch [60/300], Train Loss: 0.006901
Validation Loss: 0.00744588
Epoch [61/300], Train Loss: 0.006723
Validation Loss: 0.00724536
Epoch [62/300], Train Loss: 0.006762
Validation Loss: 0.00728911
Epoch [63/300], Train Loss: 0.006907
Validation Loss: 0.00722138
Epoch [64/300], Train Loss: 0.006806
Validation Loss: 0.00723707
Epoch [65/300], Train Loss: 0.006774
Validation Loss: 0.00726188
Epoch [66/300], Train Loss: 0.006801
Validation Loss: 0.00720393
Epoch [67/300], Train Loss: 0.006748
Validation Loss: 0.00720737
Epoch [68/300], Train Loss: 0.006973
Validation Loss: 0.00776955
Epoch [69/300], Train Loss: 0.007118
Validation Loss: 0.00737233
Epoch [70/300], Train Loss: 0.009176
Validation Loss: 0.00774270
Epoch [71/300], Train Loss: 0.007100
Validation Loss: 0.00758571
Epoch [72/300], Train Loss: 0.006913
Validation Loss: 0.00742432
Epoch [73/300], Train Loss: 0.006833
Validation Loss: 0.00737518
Epoch [74/300], Train Loss: 0.006773
Validation Loss: 0.00738357
Epoch [75/300], Train Loss: 0.006836
Validation Loss: 0.00728666
Epoch [76/300], Train Loss: 0.006735
Validation Loss: 0.00745325
Early stopping triggered

Evaluating model for: Tablet
Run 34/72 completed in 1032.60 seconds with: {'MAE': np.float32(0.64728695), 'MSE': np.float32(1.1481035), 'RMSE': np.float32(1.0714959), 'SAE': np.float32(0.026572555), 'NDE': np.float32(0.24781871)}

Run 35/72: hidden=256, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Tablet
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.057818
Validation Loss: 0.01844837
Epoch [2/300], Train Loss: 0.016621
Validation Loss: 0.01777880
Epoch [3/300], Train Loss: 0.015292
Validation Loss: 0.01506222
Epoch [4/300], Train Loss: 0.011595
Validation Loss: 0.01177717
Epoch [5/300], Train Loss: 0.010708
Validation Loss: 0.01147745
Epoch [6/300], Train Loss: 0.010317
Validation Loss: 0.01124559
Epoch [7/300], Train Loss: 0.010052
Validation Loss: 0.01106737
Epoch [8/300], Train Loss: 0.009760
Validation Loss: 0.01080354
Epoch [9/300], Train Loss: 0.009390
Validation Loss: 0.01010318
Epoch [10/300], Train Loss: 0.009218
Validation Loss: 0.01010801
Epoch [11/300], Train Loss: 0.009140
Validation Loss: 0.00974996
Epoch [12/300], Train Loss: 0.009039
Validation Loss: 0.00989712
Epoch [13/300], Train Loss: 0.008783
Validation Loss: 0.00926183
Epoch [14/300], Train Loss: 0.008727
Validation Loss: 0.00936973
Epoch [15/300], Train Loss: 0.008576
Validation Loss: 0.00928634
Epoch [16/300], Train Loss: 0.008694
Validation Loss: 0.01023654
Epoch [17/300], Train Loss: 0.008583
Validation Loss: 0.00871564
Epoch [18/300], Train Loss: 0.008331
Validation Loss: 0.00866321
Epoch [19/300], Train Loss: 0.008231
Validation Loss: 0.00920641
Epoch [20/300], Train Loss: 0.008112
Validation Loss: 0.00856887
Epoch [21/300], Train Loss: 0.007936
Validation Loss: 0.00844741
Epoch [22/300], Train Loss: 0.008028
Validation Loss: 0.00843279
Epoch [23/300], Train Loss: 0.007855
Validation Loss: 0.00830927
Epoch [24/300], Train Loss: 0.007719
Validation Loss: 0.00847996
Epoch [25/300], Train Loss: 0.008244
Validation Loss: 0.00867335
Epoch [26/300], Train Loss: 0.007922
Validation Loss: 0.00815659
Epoch [27/300], Train Loss: 0.007712
Validation Loss: 0.00809859
Epoch [28/300], Train Loss: 0.007556
Validation Loss: 0.00802793
Epoch [29/300], Train Loss: 0.007622
Validation Loss: 0.00808064
Epoch [30/300], Train Loss: 0.008899
Validation Loss: 0.01001589
Epoch [31/300], Train Loss: 0.007968
Validation Loss: 0.00806242
Epoch [32/300], Train Loss: 0.007502
Validation Loss: 0.00786408
Epoch [33/300], Train Loss: 0.007324
Validation Loss: 0.00784316
Epoch [34/300], Train Loss: 0.007504
Validation Loss: 0.00819943
Epoch [35/300], Train Loss: 0.008912
Validation Loss: 0.00798185
Epoch [36/300], Train Loss: 0.007523
Validation Loss: 0.00802062
Epoch [37/300], Train Loss: 0.007408
Validation Loss: 0.00776115
Epoch [38/300], Train Loss: 0.007461
Validation Loss: 0.00797585
Epoch [39/300], Train Loss: 0.007241
Validation Loss: 0.00766570
Epoch [40/300], Train Loss: 0.007355
Validation Loss: 0.00789807
Epoch [41/300], Train Loss: 0.007274
Validation Loss: 0.00762568
Epoch [42/300], Train Loss: 0.007231
Validation Loss: 0.00769801
Epoch [43/300], Train Loss: 0.009870
Validation Loss: 0.01737483
Epoch [44/300], Train Loss: 0.015064
Validation Loss: 0.01675944
Epoch [45/300], Train Loss: 0.014495
Validation Loss: 0.01575908
Epoch [46/300], Train Loss: 0.012248
Validation Loss: 0.01093979
Epoch [47/300], Train Loss: 0.009440
Validation Loss: 0.01003322
Epoch [48/300], Train Loss: 0.008893
Validation Loss: 0.00942979
Epoch [49/300], Train Loss: 0.008178
Validation Loss: 0.00875995
Epoch [50/300], Train Loss: 0.007933
Validation Loss: 0.00806517
Epoch [51/300], Train Loss: 0.007666
Validation Loss: 0.00795955
Early stopping triggered

Evaluating model for: Tablet
Run 35/72 completed in 788.82 seconds with: {'MAE': np.float32(0.6791904), 'MSE': np.float32(1.2348741), 'RMSE': np.float32(1.1112489), 'SAE': np.float32(0.01788068), 'NDE': np.float32(0.25701287)}

Run 36/72: hidden=256, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Tablet
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.041476
Validation Loss: 0.01754191
Epoch [2/300], Train Loss: 0.015794
Validation Loss: 0.01724865
Epoch [3/300], Train Loss: 0.014819
Validation Loss: 0.01423503
Epoch [4/300], Train Loss: 0.010715
Validation Loss: 0.01103261
Epoch [5/300], Train Loss: 0.009859
Validation Loss: 0.01040263
Epoch [6/300], Train Loss: 0.009359
Validation Loss: 0.01014823
Epoch [7/300], Train Loss: 0.009077
Validation Loss: 0.01033875
Epoch [8/300], Train Loss: 0.008991
Validation Loss: 0.01017202
Epoch [9/300], Train Loss: 0.008811
Validation Loss: 0.00977344
Epoch [10/300], Train Loss: 0.008761
Validation Loss: 0.00956436
Epoch [11/300], Train Loss: 0.008741
Validation Loss: 0.00957460
Epoch [12/300], Train Loss: 0.008736
Validation Loss: 0.00930198
Epoch [13/300], Train Loss: 0.008492
Validation Loss: 0.00922726
Epoch [14/300], Train Loss: 0.008374
Validation Loss: 0.00915358
Epoch [15/300], Train Loss: 0.008318
Validation Loss: 0.00926096
Epoch [16/300], Train Loss: 0.008102
Validation Loss: 0.00874783
Epoch [17/300], Train Loss: 0.008217
Validation Loss: 0.00879937
Epoch [18/300], Train Loss: 0.008091
Validation Loss: 0.00855630
Epoch [19/300], Train Loss: 0.007835
Validation Loss: 0.00860995
Epoch [20/300], Train Loss: 0.007650
Validation Loss: 0.00861878
Epoch [21/300], Train Loss: 0.007720
Validation Loss: 0.00832924
Epoch [22/300], Train Loss: 0.007603
Validation Loss: 0.00931292
Epoch [23/300], Train Loss: 0.007869
Validation Loss: 0.00794407
Epoch [24/300], Train Loss: 0.007319
Validation Loss: 0.00828979
Epoch [25/300], Train Loss: 0.007742
Validation Loss: 0.00780051
Epoch [26/300], Train Loss: 0.007540
Validation Loss: 0.00802151
Epoch [27/300], Train Loss: 0.007108
Validation Loss: 0.00783698
Epoch [28/300], Train Loss: 0.007249
Validation Loss: 0.00795809
Epoch [29/300], Train Loss: 0.007208
Validation Loss: 0.00768061
Epoch [30/300], Train Loss: 0.007056
Validation Loss: 0.00760172
Epoch [31/300], Train Loss: 0.007098
Validation Loss: 0.00769160
Epoch [32/300], Train Loss: 0.007096
Validation Loss: 0.00755844
Epoch [33/300], Train Loss: 0.007020
Validation Loss: 0.00753614
Epoch [34/300], Train Loss: 0.007048
Validation Loss: 0.00760295
Epoch [35/300], Train Loss: 0.006890
Validation Loss: 0.00748996
Epoch [36/300], Train Loss: 0.006893
Validation Loss: 0.00752597
Epoch [37/300], Train Loss: 0.006917
Validation Loss: 0.00838549
Epoch [38/300], Train Loss: 0.007093
Validation Loss: 0.00754921
Epoch [39/300], Train Loss: 0.007031
Validation Loss: 0.00750290
Epoch [40/300], Train Loss: 0.007089
Validation Loss: 0.00745698
Epoch [41/300], Train Loss: 0.006887
Validation Loss: 0.00759988
Epoch [42/300], Train Loss: 0.007036
Validation Loss: 0.00813342
Epoch [43/300], Train Loss: 0.007018
Validation Loss: 0.00741137
Epoch [44/300], Train Loss: 0.006845
Validation Loss: 0.00768059
Epoch [45/300], Train Loss: 0.006845
Validation Loss: 0.00746311
Epoch [46/300], Train Loss: 0.006887
Validation Loss: 0.00733211
Epoch [47/300], Train Loss: 0.006840
Validation Loss: 0.00748276
Epoch [48/300], Train Loss: 0.006856
Validation Loss: 0.00806277
Epoch [49/300], Train Loss: 0.006964
Validation Loss: 0.00734248
Epoch [50/300], Train Loss: 0.006803
Validation Loss: 0.00731913
Epoch [51/300], Train Loss: 0.006778
Validation Loss: 0.00736704
Epoch [52/300], Train Loss: 0.006791
Validation Loss: 0.00732161
Epoch [53/300], Train Loss: 0.006874
Validation Loss: 0.00730396
Epoch [54/300], Train Loss: 0.006874
Validation Loss: 0.00728978
Epoch [55/300], Train Loss: 0.006621
Validation Loss: 0.00725029
Epoch [56/300], Train Loss: 0.006891
Validation Loss: 0.00747311
Epoch [57/300], Train Loss: 0.007101
Validation Loss: 0.00727849
Epoch [58/300], Train Loss: 0.006764
Validation Loss: 0.00729186
Epoch [59/300], Train Loss: 0.006599
Validation Loss: 0.00721301
Epoch [60/300], Train Loss: 0.006714
Validation Loss: 0.00726219
Epoch [61/300], Train Loss: 0.006629
Validation Loss: 0.00716907
Epoch [62/300], Train Loss: 0.006639
Validation Loss: 0.00727914
Epoch [63/300], Train Loss: 0.006782
Validation Loss: 0.00717262
Epoch [64/300], Train Loss: 0.006668
Validation Loss: 0.00734514
Epoch [65/300], Train Loss: 0.006659
Validation Loss: 0.00717840
Epoch [66/300], Train Loss: 0.006639
Validation Loss: 0.00712024
Epoch [67/300], Train Loss: 0.006607
Validation Loss: 0.00716195
Epoch [68/300], Train Loss: 0.006806
Validation Loss: 0.00744388
Epoch [69/300], Train Loss: 0.006628
Validation Loss: 0.00718505
Epoch [70/300], Train Loss: 0.006571
Validation Loss: 0.00709089
Epoch [71/300], Train Loss: 0.006598
Validation Loss: 0.00710412
Epoch [72/300], Train Loss: 0.006523
Validation Loss: 0.00711950
Epoch [73/300], Train Loss: 0.006533
Validation Loss: 0.00715058
Epoch [74/300], Train Loss: 0.006488
Validation Loss: 0.00741857
Epoch [75/300], Train Loss: 0.006596
Validation Loss: 0.00704903
Epoch [76/300], Train Loss: 0.006495
Validation Loss: 0.00708678
Epoch [77/300], Train Loss: 0.006771
Validation Loss: 0.00704772
Epoch [78/300], Train Loss: 0.006495
Validation Loss: 0.00710463
Epoch [79/300], Train Loss: 0.006625
Validation Loss: 0.00707245
Epoch [80/300], Train Loss: 0.006521
Validation Loss: 0.00701016
Epoch [81/300], Train Loss: 0.006509
Validation Loss: 0.00720724
Epoch [82/300], Train Loss: 0.006742
Validation Loss: 0.00706529
Epoch [83/300], Train Loss: 0.006440
Validation Loss: 0.00697265
Epoch [84/300], Train Loss: 0.006422
Validation Loss: 0.00695981
Epoch [85/300], Train Loss: 0.006513
Validation Loss: 0.00695267
Epoch [86/300], Train Loss: 0.006333
Validation Loss: 0.00697474
Epoch [87/300], Train Loss: 0.006450
Validation Loss: 0.00697286
Epoch [88/300], Train Loss: 0.006320
Validation Loss: 0.00693290
Epoch [89/300], Train Loss: 0.006484
Validation Loss: 0.00693476
Epoch [90/300], Train Loss: 0.006508
Validation Loss: 0.00697580
Epoch [91/300], Train Loss: 0.006308
Validation Loss: 0.00689195
Epoch [92/300], Train Loss: 0.006322
Validation Loss: 0.00693734
Epoch [93/300], Train Loss: 0.006228
Validation Loss: 0.00688229
Epoch [94/300], Train Loss: 0.006405
Validation Loss: 0.00708422
Epoch [95/300], Train Loss: 0.006335
Validation Loss: 0.00678043
Epoch [96/300], Train Loss: 0.006264
Validation Loss: 0.00679394
Epoch [97/300], Train Loss: 0.006339
Validation Loss: 0.00678445
Epoch [98/300], Train Loss: 0.006681
Validation Loss: 0.00719872
Epoch [99/300], Train Loss: 0.006463
Validation Loss: 0.00687702
Epoch [100/300], Train Loss: 0.006376
Validation Loss: 0.00684674
Epoch [101/300], Train Loss: 0.006336
Validation Loss: 0.00683307
Epoch [102/300], Train Loss: 0.006231
Validation Loss: 0.00677991
Epoch [103/300], Train Loss: 0.006315
Validation Loss: 0.00672226
Epoch [104/300], Train Loss: 0.006298
Validation Loss: 0.00675180
Epoch [105/300], Train Loss: 0.006265
Validation Loss: 0.00667375
Epoch [106/300], Train Loss: 0.006293
Validation Loss: 0.00685165
Epoch [107/300], Train Loss: 0.006315
Validation Loss: 0.00665160
Epoch [108/300], Train Loss: 0.006240
Validation Loss: 0.00652718
Epoch [109/300], Train Loss: 0.005996
Validation Loss: 0.00649101
Epoch [110/300], Train Loss: 0.006129
Validation Loss: 0.00636274
Epoch [111/300], Train Loss: 0.005953
Validation Loss: 0.00626536
Epoch [112/300], Train Loss: 0.005832
Validation Loss: 0.00617515
Epoch [113/300], Train Loss: 0.006113
Validation Loss: 0.00647166
Epoch [114/300], Train Loss: 0.005878
Validation Loss: 0.00603688
Epoch [115/300], Train Loss: 0.005807
Validation Loss: 0.00596144
Epoch [116/300], Train Loss: 0.005601
Validation Loss: 0.00567922
Epoch [117/300], Train Loss: 0.005373
Validation Loss: 0.00541452
Epoch [118/300], Train Loss: 0.005044
Validation Loss: 0.00492879
Epoch [119/300], Train Loss: 0.004653
Validation Loss: 0.00503769
Epoch [120/300], Train Loss: 0.004284
Validation Loss: 0.00375567
Epoch [121/300], Train Loss: 0.003788
Validation Loss: 0.00380290
Epoch [122/300], Train Loss: 0.003597
Validation Loss: 0.00340922
Epoch [123/300], Train Loss: 0.003428
Validation Loss: 0.00350219
Epoch [124/300], Train Loss: 0.003361
Validation Loss: 0.00347745
Epoch [125/300], Train Loss: 0.003256
Validation Loss: 0.00312692
Epoch [126/300], Train Loss: 0.003103
Validation Loss: 0.00310627
Epoch [127/300], Train Loss: 0.002985
Validation Loss: 0.00289988
Epoch [128/300], Train Loss: 0.002897
Validation Loss: 0.00279018
Epoch [129/300], Train Loss: 0.003508
Validation Loss: 0.00275972
Epoch [130/300], Train Loss: 0.002802
Validation Loss: 0.00275769
Epoch [131/300], Train Loss: 0.002783
Validation Loss: 0.00259967
Epoch [132/300], Train Loss: 0.002667
Validation Loss: 0.00264327
Epoch [133/300], Train Loss: 0.002736
Validation Loss: 0.00254414
Epoch [134/300], Train Loss: 0.002590
Validation Loss: 0.00252166
Epoch [135/300], Train Loss: 0.002535
Validation Loss: 0.00255437
Epoch [136/300], Train Loss: 0.002497
Validation Loss: 0.00260219
Epoch [137/300], Train Loss: 0.002474
Validation Loss: 0.00247893
Epoch [138/300], Train Loss: 0.005972
Validation Loss: 0.00289088
Epoch [139/300], Train Loss: 0.002747
Validation Loss: 0.00261597
Epoch [140/300], Train Loss: 0.002626
Validation Loss: 0.00259568
Epoch [141/300], Train Loss: 0.002585
Validation Loss: 0.00253145
Epoch [142/300], Train Loss: 0.002547
Validation Loss: 0.00250557
Epoch [143/300], Train Loss: 0.002501
Validation Loss: 0.00248056
Epoch [144/300], Train Loss: 0.002454
Validation Loss: 0.00244147
Epoch [145/300], Train Loss: 0.002433
Validation Loss: 0.00244516
Epoch [146/300], Train Loss: 0.002420
Validation Loss: 0.00238976
Epoch [147/300], Train Loss: 0.002413
Validation Loss: 0.00237708
Epoch [148/300], Train Loss: 0.002373
Validation Loss: 0.00238564
Epoch [149/300], Train Loss: 0.002379
Validation Loss: 0.00235111
Epoch [150/300], Train Loss: 0.002343
Validation Loss: 0.00237617
Epoch [151/300], Train Loss: 0.002341
Validation Loss: 0.00234883
Epoch [152/300], Train Loss: 0.002327
Validation Loss: 0.00234220
Epoch [153/300], Train Loss: 0.002307
Validation Loss: 0.00232563
Epoch [154/300], Train Loss: 0.002298
Validation Loss: 0.00233455
Epoch [155/300], Train Loss: 0.002377
Validation Loss: 0.00231549
Epoch [156/300], Train Loss: 0.002296
Validation Loss: 0.00233363
Epoch [157/300], Train Loss: 0.002357
Validation Loss: 0.00229973
Epoch [158/300], Train Loss: 0.005976
Validation Loss: 0.00377922
Epoch [159/300], Train Loss: 0.003384
Validation Loss: 0.00303722
Epoch [160/300], Train Loss: 0.002945
Validation Loss: 0.00272240
Epoch [161/300], Train Loss: 0.002746
Validation Loss: 0.00259459
Epoch [162/300], Train Loss: 0.002620
Validation Loss: 0.00269543
Epoch [163/300], Train Loss: 0.002594
Validation Loss: 0.00251938
Epoch [164/300], Train Loss: 0.002496
Validation Loss: 0.00247985
Epoch [165/300], Train Loss: 0.002502
Validation Loss: 0.00245647
Epoch [166/300], Train Loss: 0.002431
Validation Loss: 0.00244654
Epoch [167/300], Train Loss: 0.002441
Validation Loss: 0.00240177
Early stopping triggered

Evaluating model for: Tablet
Run 36/72 completed in 3227.48 seconds with: {'MAE': np.float32(0.3874168), 'MSE': np.float32(0.3225032), 'RMSE': np.float32(0.5678937), 'SAE': np.float32(0.0074883644), 'NDE': np.float32(0.13134411)}

Run 37/72: hidden=256, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Tablet
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.095926
Validation Loss: 0.06446033
Epoch [2/300], Train Loss: 0.029491
Validation Loss: 0.01906975
Epoch [3/300], Train Loss: 0.017318
Validation Loss: 0.01734893
Epoch [4/300], Train Loss: 0.016481
Validation Loss: 0.01671364
Epoch [5/300], Train Loss: 0.016489
Validation Loss: 0.01606706
Epoch [6/300], Train Loss: 0.015539
Validation Loss: 0.01543095
Epoch [7/300], Train Loss: 0.014143
Validation Loss: 0.01394836
Epoch [8/300], Train Loss: 0.013165
Validation Loss: 0.01272758
Epoch [9/300], Train Loss: 0.012287
Validation Loss: 0.01204264
Epoch [10/300], Train Loss: 0.011995
Validation Loss: 0.01171864
Epoch [11/300], Train Loss: 0.011449
Validation Loss: 0.01139780
Epoch [12/300], Train Loss: 0.010968
Validation Loss: 0.01099351
Epoch [13/300], Train Loss: 0.010440
Validation Loss: 0.01027705
Epoch [14/300], Train Loss: 0.009828
Validation Loss: 0.00997247
Epoch [15/300], Train Loss: 0.009971
Validation Loss: 0.00995514
Epoch [16/300], Train Loss: 0.009662
Validation Loss: 0.00991129
Epoch [17/300], Train Loss: 0.009587
Validation Loss: 0.00973236
Epoch [18/300], Train Loss: 0.009608
Validation Loss: 0.00961894
Epoch [19/300], Train Loss: 0.009348
Validation Loss: 0.00949326
Epoch [20/300], Train Loss: 0.009164
Validation Loss: 0.00944049
Epoch [21/300], Train Loss: 0.009213
Validation Loss: 0.00936453
Epoch [22/300], Train Loss: 0.009045
Validation Loss: 0.00926548
Epoch [23/300], Train Loss: 0.009079
Validation Loss: 0.00932549
Epoch [24/300], Train Loss: 0.009006
Validation Loss: 0.00925268
Epoch [25/300], Train Loss: 0.008894
Validation Loss: 0.00924694
Epoch [26/300], Train Loss: 0.008958
Validation Loss: 0.00904959
Epoch [27/300], Train Loss: 0.008738
Validation Loss: 0.00909028
Epoch [28/300], Train Loss: 0.008813
Validation Loss: 0.00891360
Epoch [29/300], Train Loss: 0.008748
Validation Loss: 0.00900843
Epoch [30/300], Train Loss: 0.008672
Validation Loss: 0.00882149
Epoch [31/300], Train Loss: 0.008654
Validation Loss: 0.00877529
Epoch [32/300], Train Loss: 0.008534
Validation Loss: 0.00877549
Epoch [33/300], Train Loss: 0.008547
Validation Loss: 0.00868643
Epoch [34/300], Train Loss: 0.008472
Validation Loss: 0.00860856
Epoch [35/300], Train Loss: 0.008281
Validation Loss: 0.00853325
Epoch [36/300], Train Loss: 0.008266
Validation Loss: 0.00843631
Epoch [37/300], Train Loss: 0.008329
Validation Loss: 0.00836507
Epoch [38/300], Train Loss: 0.008318
Validation Loss: 0.00828958
Epoch [39/300], Train Loss: 0.007969
Validation Loss: 0.00839472
Epoch [40/300], Train Loss: 0.008242
Validation Loss: 0.00833261
Epoch [41/300], Train Loss: 0.007972
Validation Loss: 0.00809853
Epoch [42/300], Train Loss: 0.007903
Validation Loss: 0.00806875
Epoch [43/300], Train Loss: 0.008008
Validation Loss: 0.00809100
Epoch [44/300], Train Loss: 0.007967
Validation Loss: 0.00819620
Epoch [45/300], Train Loss: 0.007835
Validation Loss: 0.00818519
Epoch [46/300], Train Loss: 0.007660
Validation Loss: 0.00790559
Epoch [47/300], Train Loss: 0.007694
Validation Loss: 0.00779105
Epoch [48/300], Train Loss: 0.007542
Validation Loss: 0.00774336
Epoch [49/300], Train Loss: 0.007542
Validation Loss: 0.00798294
Epoch [50/300], Train Loss: 0.007890
Validation Loss: 0.00782119
Epoch [51/300], Train Loss: 0.007483
Validation Loss: 0.00824984
Epoch [52/300], Train Loss: 0.007772
Validation Loss: 0.00768525
Epoch [53/300], Train Loss: 0.007452
Validation Loss: 0.00755808
Epoch [54/300], Train Loss: 0.007495
Validation Loss: 0.00762313
Epoch [55/300], Train Loss: 0.007398
Validation Loss: 0.00757358
Epoch [56/300], Train Loss: 0.007345
Validation Loss: 0.00752151
Epoch [57/300], Train Loss: 0.007199
Validation Loss: 0.00755806
Epoch [58/300], Train Loss: 0.007208
Validation Loss: 0.00770473
Epoch [59/300], Train Loss: 0.007216
Validation Loss: 0.00744415
Epoch [60/300], Train Loss: 0.007253
Validation Loss: 0.00746286
Epoch [61/300], Train Loss: 0.007329
Validation Loss: 0.00749292
Epoch [62/300], Train Loss: 0.007512
Validation Loss: 0.00881266
Epoch [63/300], Train Loss: 0.007635
Validation Loss: 0.00811537
Epoch [64/300], Train Loss: 0.007227
Validation Loss: 0.00752122
Epoch [65/300], Train Loss: 0.007347
Validation Loss: 0.00738121
Epoch [66/300], Train Loss: 0.007244
Validation Loss: 0.00734220
Epoch [67/300], Train Loss: 0.007119
Validation Loss: 0.00737193
Epoch [68/300], Train Loss: 0.007052
Validation Loss: 0.00757279
Epoch [69/300], Train Loss: 0.007352
Validation Loss: 0.00763926
Epoch [70/300], Train Loss: 0.007219
Validation Loss: 0.00730835
Epoch [71/300], Train Loss: 0.007052
Validation Loss: 0.00729915
Epoch [72/300], Train Loss: 0.007337
Validation Loss: 0.00728241
Epoch [73/300], Train Loss: 0.007099
Validation Loss: 0.00748262
Epoch [74/300], Train Loss: 0.006938
Validation Loss: 0.00733856
Epoch [75/300], Train Loss: 0.007087
Validation Loss: 0.00731254
Epoch [76/300], Train Loss: 0.007244
Validation Loss: 0.00732875
Epoch [77/300], Train Loss: 0.006945
Validation Loss: 0.00729576
Epoch [78/300], Train Loss: 0.007000
Validation Loss: 0.00735192
Epoch [79/300], Train Loss: 0.007264
Validation Loss: 0.00735219
Epoch [80/300], Train Loss: 0.007195
Validation Loss: 0.00758534
Epoch [81/300], Train Loss: 0.007089
Validation Loss: 0.00726240
Epoch [82/300], Train Loss: 0.006988
Validation Loss: 0.00725119
Epoch [83/300], Train Loss: 0.006978
Validation Loss: 0.00728104
Epoch [84/300], Train Loss: 0.006939
Validation Loss: 0.00772813
Epoch [85/300], Train Loss: 0.007074
Validation Loss: 0.00738431
Epoch [86/300], Train Loss: 0.006916
Validation Loss: 0.00756212
Epoch [87/300], Train Loss: 0.006901
Validation Loss: 0.00728271
Epoch [88/300], Train Loss: 0.006869
Validation Loss: 0.00728960
Epoch [89/300], Train Loss: 0.007111
Validation Loss: 0.00738625
Epoch [90/300], Train Loss: 0.006991
Validation Loss: 0.00718101
Epoch [91/300], Train Loss: 0.007040
Validation Loss: 0.00735369
Epoch [92/300], Train Loss: 0.006889
Validation Loss: 0.00728690
Epoch [93/300], Train Loss: 0.006885
Validation Loss: 0.00714442
Epoch [94/300], Train Loss: 0.006881
Validation Loss: 0.00719115
Epoch [95/300], Train Loss: 0.006795
Validation Loss: 0.00718137
Epoch [96/300], Train Loss: 0.006804
Validation Loss: 0.00721819
Epoch [97/300], Train Loss: 0.006998
Validation Loss: 0.00714704
Epoch [98/300], Train Loss: 0.006771
Validation Loss: 0.00731035
Epoch [99/300], Train Loss: 0.006918
Validation Loss: 0.00721140
Epoch [100/300], Train Loss: 0.006850
Validation Loss: 0.00711630
Epoch [101/300], Train Loss: 0.006880
Validation Loss: 0.00711885
Epoch [102/300], Train Loss: 0.006791
Validation Loss: 0.00713186
Epoch [103/300], Train Loss: 0.006784
Validation Loss: 0.00723051
Epoch [104/300], Train Loss: 0.006887
Validation Loss: 0.00713416
Epoch [105/300], Train Loss: 0.006796
Validation Loss: 0.00712906
Epoch [106/300], Train Loss: 0.006833
Validation Loss: 0.00713133
Epoch [107/300], Train Loss: 0.006943
Validation Loss: 0.00708439
Epoch [108/300], Train Loss: 0.006883
Validation Loss: 0.00716782
Epoch [109/300], Train Loss: 0.006872
Validation Loss: 0.00711337
Epoch [110/300], Train Loss: 0.006903
Validation Loss: 0.00741743
Epoch [111/300], Train Loss: 0.006860
Validation Loss: 0.00708038
Epoch [112/300], Train Loss: 0.006992
Validation Loss: 0.00704966
Epoch [113/300], Train Loss: 0.006802
Validation Loss: 0.00707753
Epoch [114/300], Train Loss: 0.006918
Validation Loss: 0.00705035
Epoch [115/300], Train Loss: 0.006892
Validation Loss: 0.00706646
Epoch [116/300], Train Loss: 0.006715
Validation Loss: 0.00705395
Epoch [117/300], Train Loss: 0.006705
Validation Loss: 0.00709972
Epoch [118/300], Train Loss: 0.006628
Validation Loss: 0.00707072
Epoch [119/300], Train Loss: 0.006754
Validation Loss: 0.00708716
Epoch [120/300], Train Loss: 0.006885
Validation Loss: 0.00735721
Epoch [121/300], Train Loss: 0.006998
Validation Loss: 0.00709593
Epoch [122/300], Train Loss: 0.006889
Validation Loss: 0.00709459
Early stopping triggered

Evaluating model for: Tablet
Run 37/72 completed in 697.22 seconds with: {'MAE': np.float32(0.6409789), 'MSE': np.float32(1.0754642), 'RMSE': np.float32(1.037046), 'SAE': np.float32(0.01031628), 'NDE': np.float32(0.2385234)}

Run 38/72: hidden=256, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Tablet
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.106300
Validation Loss: 0.06497889
Epoch [2/300], Train Loss: 0.027814
Validation Loss: 0.01917256
Epoch [3/300], Train Loss: 0.017049
Validation Loss: 0.01707024
Epoch [4/300], Train Loss: 0.016263
Validation Loss: 0.01621609
Epoch [5/300], Train Loss: 0.015949
Validation Loss: 0.01510829
Epoch [6/300], Train Loss: 0.014167
Validation Loss: 0.01325513
Epoch [7/300], Train Loss: 0.011874
Validation Loss: 0.01158086
Epoch [8/300], Train Loss: 0.011418
Validation Loss: 0.01131924
Epoch [9/300], Train Loss: 0.011126
Validation Loss: 0.01088082
Epoch [10/300], Train Loss: 0.010921
Validation Loss: 0.01060569
Epoch [11/300], Train Loss: 0.010605
Validation Loss: 0.01055972
Epoch [12/300], Train Loss: 0.010322
Validation Loss: 0.01037201
Epoch [13/300], Train Loss: 0.010147
Validation Loss: 0.01018034
Epoch [14/300], Train Loss: 0.009770
Validation Loss: 0.00991849
Epoch [15/300], Train Loss: 0.009651
Validation Loss: 0.00953075
Epoch [16/300], Train Loss: 0.009492
Validation Loss: 0.00945053
Epoch [17/300], Train Loss: 0.013133
Validation Loss: 0.01058110
Epoch [18/300], Train Loss: 0.009994
Validation Loss: 0.00966552
Epoch [19/300], Train Loss: 0.009540
Validation Loss: 0.01067574
Epoch [20/300], Train Loss: 0.009489
Validation Loss: 0.00939900
Epoch [21/300], Train Loss: 0.009361
Validation Loss: 0.00934332
Epoch [22/300], Train Loss: 0.009287
Validation Loss: 0.00940369
Epoch [23/300], Train Loss: 0.009266
Validation Loss: 0.00941240
Epoch [24/300], Train Loss: 0.009282
Validation Loss: 0.00938832
Epoch [25/300], Train Loss: 0.009103
Validation Loss: 0.00943285
Epoch [26/300], Train Loss: 0.009182
Validation Loss: 0.00929430
Epoch [27/300], Train Loss: 0.008896
Validation Loss: 0.00915834
Epoch [28/300], Train Loss: 0.009077
Validation Loss: 0.00915938
Epoch [29/300], Train Loss: 0.009009
Validation Loss: 0.00926438
Epoch [30/300], Train Loss: 0.008921
Validation Loss: 0.00928571
Epoch [31/300], Train Loss: 0.008922
Validation Loss: 0.00930340
Epoch [32/300], Train Loss: 0.008890
Validation Loss: 0.00904001
Epoch [33/300], Train Loss: 0.008968
Validation Loss: 0.00894232
Epoch [34/300], Train Loss: 0.008785
Validation Loss: 0.00885382
Epoch [35/300], Train Loss: 0.008656
Validation Loss: 0.00893516
Epoch [36/300], Train Loss: 0.008728
Validation Loss: 0.00890196
Epoch [37/300], Train Loss: 0.011621
Validation Loss: 0.01377178
Epoch [38/300], Train Loss: 0.012601
Validation Loss: 0.01102240
Epoch [39/300], Train Loss: 0.009696
Validation Loss: 0.00937098
Epoch [40/300], Train Loss: 0.009126
Validation Loss: 0.00899642
Epoch [41/300], Train Loss: 0.008816
Validation Loss: 0.00888588
Epoch [42/300], Train Loss: 0.008625
Validation Loss: 0.00878485
Epoch [43/300], Train Loss: 0.008658
Validation Loss: 0.00879634
Epoch [44/300], Train Loss: 0.008636
Validation Loss: 0.00882237
Epoch [45/300], Train Loss: 0.008610
Validation Loss: 0.00869968
Epoch [46/300], Train Loss: 0.008418
Validation Loss: 0.00864349
Epoch [47/300], Train Loss: 0.008510
Validation Loss: 0.00862011
Epoch [48/300], Train Loss: 0.008390
Validation Loss: 0.00867950
Epoch [49/300], Train Loss: 0.008504
Validation Loss: 0.00863372
Epoch [50/300], Train Loss: 0.008693
Validation Loss: 0.00861675
Epoch [51/300], Train Loss: 0.008304
Validation Loss: 0.00870277
Epoch [52/300], Train Loss: 0.008509
Validation Loss: 0.00861103
Epoch [53/300], Train Loss: 0.008466
Validation Loss: 0.00869047
Epoch [54/300], Train Loss: 0.008446
Validation Loss: 0.00889871
Epoch [55/300], Train Loss: 0.008353
Validation Loss: 0.00866054
Epoch [56/300], Train Loss: 0.008935
Validation Loss: 0.01015666
Epoch [57/300], Train Loss: 0.008903
Validation Loss: 0.00885936
Epoch [58/300], Train Loss: 0.008510
Validation Loss: 0.00863184
Epoch [59/300], Train Loss: 0.008368
Validation Loss: 0.00848848
Epoch [60/300], Train Loss: 0.008332
Validation Loss: 0.00859771
Epoch [61/300], Train Loss: 0.008386
Validation Loss: 0.00846922
Epoch [62/300], Train Loss: 0.008189
Validation Loss: 0.00841750
Epoch [63/300], Train Loss: 0.008259
Validation Loss: 0.00869548
Epoch [64/300], Train Loss: 0.008264
Validation Loss: 0.00849139
Epoch [65/300], Train Loss: 0.008413
Validation Loss: 0.00851819
Epoch [66/300], Train Loss: 0.008192
Validation Loss: 0.00863931
Epoch [67/300], Train Loss: 0.008104
Validation Loss: 0.00855728
Epoch [68/300], Train Loss: 0.008073
Validation Loss: 0.00856497
Epoch [69/300], Train Loss: 0.008327
Validation Loss: 0.00866365
Epoch [70/300], Train Loss: 0.008305
Validation Loss: 0.00868820
Epoch [71/300], Train Loss: 0.008450
Validation Loss: 0.00883576
Epoch [72/300], Train Loss: 0.008800
Validation Loss: 0.00871714
Early stopping triggered

Evaluating model for: Tablet
Run 38/72 completed in 486.50 seconds with: {'MAE': np.float32(0.73491037), 'MSE': np.float32(1.3177208), 'RMSE': np.float32(1.1479203), 'SAE': np.float32(0.024559317), 'NDE': np.float32(0.26402473)}

Run 39/72: hidden=256, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Tablet
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.063542
Validation Loss: 0.02437140
Epoch [2/300], Train Loss: 0.018648
Validation Loss: 0.01653257
Epoch [3/300], Train Loss: 0.015853
Validation Loss: 0.01602952
Epoch [4/300], Train Loss: 0.015230
Validation Loss: 0.01524901
Epoch [5/300], Train Loss: 0.014596
Validation Loss: 0.01326611
Epoch [6/300], Train Loss: 0.012084
Validation Loss: 0.01136093
Epoch [7/300], Train Loss: 0.010668
Validation Loss: 0.01059512
Epoch [8/300], Train Loss: 0.010504
Validation Loss: 0.01075789
Epoch [9/300], Train Loss: 0.010364
Validation Loss: 0.01023175
Epoch [10/300], Train Loss: 0.010022
Validation Loss: 0.01043428
Epoch [11/300], Train Loss: 0.010056
Validation Loss: 0.00984018
Epoch [12/300], Train Loss: 0.010130
Validation Loss: 0.01099099
Epoch [13/300], Train Loss: 0.009793
Validation Loss: 0.00984095
Epoch [14/300], Train Loss: 0.009453
Validation Loss: 0.00969675
Epoch [15/300], Train Loss: 0.009445
Validation Loss: 0.00959726
Epoch [16/300], Train Loss: 0.009364
Validation Loss: 0.00948550
Epoch [17/300], Train Loss: 0.009165
Validation Loss: 0.00943913
Epoch [18/300], Train Loss: 0.009252
Validation Loss: 0.00941086
Epoch [19/300], Train Loss: 0.009032
Validation Loss: 0.00939619
Epoch [20/300], Train Loss: 0.008829
Validation Loss: 0.00940465
Epoch [21/300], Train Loss: 0.009288
Validation Loss: 0.00968600
Epoch [22/300], Train Loss: 0.009029
Validation Loss: 0.00938340
Epoch [23/300], Train Loss: 0.008989
Validation Loss: 0.00929511
Epoch [24/300], Train Loss: 0.008897
Validation Loss: 0.00918973
Epoch [25/300], Train Loss: 0.009078
Validation Loss: 0.00913880
Epoch [26/300], Train Loss: 0.008858
Validation Loss: 0.00909184
Epoch [27/300], Train Loss: 0.008584
Validation Loss: 0.00903767
Epoch [28/300], Train Loss: 0.008689
Validation Loss: 0.00900420
Epoch [29/300], Train Loss: 0.008700
Validation Loss: 0.00896046
Epoch [30/300], Train Loss: 0.008573
Validation Loss: 0.00882677
Epoch [31/300], Train Loss: 0.008630
Validation Loss: 0.00889123
Epoch [32/300], Train Loss: 0.008511
Validation Loss: 0.00878509
Epoch [33/300], Train Loss: 0.008507
Validation Loss: 0.00876380
Epoch [34/300], Train Loss: 0.008504
Validation Loss: 0.00865765
Epoch [35/300], Train Loss: 0.008248
Validation Loss: 0.00854302
Epoch [36/300], Train Loss: 0.008241
Validation Loss: 0.00858759
Epoch [37/300], Train Loss: 0.008405
Validation Loss: 0.00856402
Epoch [38/300], Train Loss: 0.008374
Validation Loss: 0.00854456
Epoch [39/300], Train Loss: 0.008184
Validation Loss: 0.00848853
Epoch [40/300], Train Loss: 0.008217
Validation Loss: 0.00829885
Epoch [41/300], Train Loss: 0.008035
Validation Loss: 0.00822641
Epoch [42/300], Train Loss: 0.007933
Validation Loss: 0.00822422
Epoch [43/300], Train Loss: 0.008140
Validation Loss: 0.00826674
Epoch [44/300], Train Loss: 0.008649
Validation Loss: 0.00853420
Epoch [45/300], Train Loss: 0.008205
Validation Loss: 0.00826905
Epoch [46/300], Train Loss: 0.007900
Validation Loss: 0.00814810
Epoch [47/300], Train Loss: 0.007896
Validation Loss: 0.00806613
Epoch [48/300], Train Loss: 0.007752
Validation Loss: 0.00806141
Epoch [49/300], Train Loss: 0.007885
Validation Loss: 0.00860550
Epoch [50/300], Train Loss: 0.008508
Validation Loss: 0.00809536
Epoch [51/300], Train Loss: 0.007736
Validation Loss: 0.00791202
Epoch [52/300], Train Loss: 0.007852
Validation Loss: 0.00804482
Epoch [53/300], Train Loss: 0.007834
Validation Loss: 0.00788940
Epoch [54/300], Train Loss: 0.007820
Validation Loss: 0.00798335
Epoch [55/300], Train Loss: 0.007705
Validation Loss: 0.00786064
Epoch [56/300], Train Loss: 0.007636
Validation Loss: 0.00790776
Epoch [57/300], Train Loss: 0.007498
Validation Loss: 0.00777778
Epoch [58/300], Train Loss: 0.007715
Validation Loss: 0.00846422
Epoch [59/300], Train Loss: 0.008213
Validation Loss: 0.00798808
Epoch [60/300], Train Loss: 0.008043
Validation Loss: 0.00804231
Epoch [61/300], Train Loss: 0.008002
Validation Loss: 0.00789404
Epoch [62/300], Train Loss: 0.007582
Validation Loss: 0.00810079
Epoch [63/300], Train Loss: 0.007636
Validation Loss: 0.00818900
Epoch [64/300], Train Loss: 0.007390
Validation Loss: 0.00772393
Epoch [65/300], Train Loss: 0.007625
Validation Loss: 0.00770692
Epoch [66/300], Train Loss: 0.007483
Validation Loss: 0.00775085
Epoch [67/300], Train Loss: 0.007458
Validation Loss: 0.00763646
Epoch [68/300], Train Loss: 0.007285
Validation Loss: 0.00938764
Epoch [69/300], Train Loss: 0.007928
Validation Loss: 0.00784388
Epoch [70/300], Train Loss: 0.007476
Validation Loss: 0.00759811
Epoch [71/300], Train Loss: 0.007379
Validation Loss: 0.00760536
Epoch [72/300], Train Loss: 0.007648
Validation Loss: 0.00759379
Epoch [73/300], Train Loss: 0.007550
Validation Loss: 0.00765093
Epoch [74/300], Train Loss: 0.007277
Validation Loss: 0.00802037
Epoch [75/300], Train Loss: 0.007303
Validation Loss: 0.00751720
Epoch [76/300], Train Loss: 0.007529
Validation Loss: 0.00772527
Epoch [77/300], Train Loss: 0.007210
Validation Loss: 0.00750130
Epoch [78/300], Train Loss: 0.007181
Validation Loss: 0.00751522
Epoch [79/300], Train Loss: 0.007393
Validation Loss: 0.00749798
Epoch [80/300], Train Loss: 0.007252
Validation Loss: 0.00747416
Epoch [81/300], Train Loss: 0.007167
Validation Loss: 0.00736964
Epoch [82/300], Train Loss: 0.007088
Validation Loss: 0.00740304
Epoch [83/300], Train Loss: 0.007114
Validation Loss: 0.00733317
Epoch [84/300], Train Loss: 0.007078
Validation Loss: 0.00737984
Epoch [85/300], Train Loss: 0.007001
Validation Loss: 0.00890106
Epoch [86/300], Train Loss: 0.007441
Validation Loss: 0.00805807
Epoch [87/300], Train Loss: 0.007502
Validation Loss: 0.00787225
Epoch [88/300], Train Loss: 0.007115
Validation Loss: 0.00755618
Epoch [89/300], Train Loss: 0.007287
Validation Loss: 0.00781482
Epoch [90/300], Train Loss: 0.007111
Validation Loss: 0.00725885
Epoch [91/300], Train Loss: 0.006980
Validation Loss: 0.00723244
Epoch [92/300], Train Loss: 0.006875
Validation Loss: 0.00745990
Epoch [93/300], Train Loss: 0.006916
Validation Loss: 0.00720606
Epoch [94/300], Train Loss: 0.006926
Validation Loss: 0.00719258
Epoch [95/300], Train Loss: 0.006835
Validation Loss: 0.00731707
Epoch [96/300], Train Loss: 0.006843
Validation Loss: 0.00719215
Epoch [97/300], Train Loss: 0.007100
Validation Loss: 0.00739579
Epoch [98/300], Train Loss: 0.006821
Validation Loss: 0.00745763
Epoch [99/300], Train Loss: 0.006963
Validation Loss: 0.00729543
Epoch [100/300], Train Loss: 0.006878
Validation Loss: 0.00714473
Epoch [101/300], Train Loss: 0.006900
Validation Loss: 0.00715609
Epoch [102/300], Train Loss: 0.006824
Validation Loss: 0.00724478
Epoch [103/300], Train Loss: 0.006803
Validation Loss: 0.00720037
Epoch [104/300], Train Loss: 0.007096
Validation Loss: 0.00741489
Epoch [105/300], Train Loss: 0.006938
Validation Loss: 0.00720505
Epoch [106/300], Train Loss: 0.010113
Validation Loss: 0.01353419
Epoch [107/300], Train Loss: 0.008786
Validation Loss: 0.00791629
Epoch [108/300], Train Loss: 0.007484
Validation Loss: 0.00770347
Epoch [109/300], Train Loss: 0.007367
Validation Loss: 0.00761067
Epoch [110/300], Train Loss: 0.007194
Validation Loss: 0.00749719
Early stopping triggered

Evaluating model for: Tablet
Run 39/72 completed in 851.85 seconds with: {'MAE': np.float32(0.65635294), 'MSE': np.float32(1.1394097), 'RMSE': np.float32(1.0674313), 'SAE': np.float32(0.01295475), 'NDE': np.float32(0.24551204)}

Run 40/72: hidden=256, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Tablet
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.094032
Validation Loss: 0.04728325
Epoch [2/300], Train Loss: 0.022058
Validation Loss: 0.01707248
Epoch [3/300], Train Loss: 0.016635
Validation Loss: 0.01675211
Epoch [4/300], Train Loss: 0.016229
Validation Loss: 0.01655224
Epoch [5/300], Train Loss: 0.016623
Validation Loss: 0.01626356
Epoch [6/300], Train Loss: 0.015995
Validation Loss: 0.01584237
Epoch [7/300], Train Loss: 0.014429
Validation Loss: 0.01328737
Epoch [8/300], Train Loss: 0.012641
Validation Loss: 0.01179067
Epoch [9/300], Train Loss: 0.011689
Validation Loss: 0.01130708
Epoch [10/300], Train Loss: 0.011309
Validation Loss: 0.01093785
Epoch [11/300], Train Loss: 0.010807
Validation Loss: 0.01059302
Epoch [12/300], Train Loss: 0.010420
Validation Loss: 0.01042818
Epoch [13/300], Train Loss: 0.010124
Validation Loss: 0.01033096
Epoch [14/300], Train Loss: 0.009944
Validation Loss: 0.01007436
Epoch [15/300], Train Loss: 0.009907
Validation Loss: 0.00995322
Epoch [16/300], Train Loss: 0.009817
Validation Loss: 0.00986947
Epoch [17/300], Train Loss: 0.009694
Validation Loss: 0.00975796
Epoch [18/300], Train Loss: 0.009744
Validation Loss: 0.00974137
Epoch [19/300], Train Loss: 0.009561
Validation Loss: 0.00968262
Epoch [20/300], Train Loss: 0.009289
Validation Loss: 0.00955425
Epoch [21/300], Train Loss: 0.009426
Validation Loss: 0.00958940
Epoch [22/300], Train Loss: 0.009264
Validation Loss: 0.00942491
Epoch [23/300], Train Loss: 0.009315
Validation Loss: 0.00956742
Epoch [24/300], Train Loss: 0.009248
Validation Loss: 0.00945348
Epoch [25/300], Train Loss: 0.009187
Validation Loss: 0.00940738
Epoch [26/300], Train Loss: 0.009193
Validation Loss: 0.00930019
Epoch [27/300], Train Loss: 0.008983
Validation Loss: 0.00934076
Epoch [28/300], Train Loss: 0.009099
Validation Loss: 0.00919274
Epoch [29/300], Train Loss: 0.009034
Validation Loss: 0.00930778
Epoch [30/300], Train Loss: 0.008960
Validation Loss: 0.00918545
Epoch [31/300], Train Loss: 0.008948
Validation Loss: 0.00906052
Epoch [32/300], Train Loss: 0.008857
Validation Loss: 0.00904101
Epoch [33/300], Train Loss: 0.008894
Validation Loss: 0.00905408
Epoch [34/300], Train Loss: 0.008833
Validation Loss: 0.00891414
Epoch [35/300], Train Loss: 0.008621
Validation Loss: 0.00890509
Epoch [36/300], Train Loss: 0.008616
Validation Loss: 0.00886963
Epoch [37/300], Train Loss: 0.008765
Validation Loss: 0.00881862
Epoch [38/300], Train Loss: 0.008707
Validation Loss: 0.00879772
Epoch [39/300], Train Loss: 0.008466
Validation Loss: 0.00874398
Epoch [40/300], Train Loss: 0.008597
Validation Loss: 0.00867825
Epoch [41/300], Train Loss: 0.008542
Validation Loss: 0.00860043
Epoch [42/300], Train Loss: 0.008376
Validation Loss: 0.00859094
Epoch [43/300], Train Loss: 0.008431
Validation Loss: 0.00855189
Epoch [44/300], Train Loss: 0.008399
Validation Loss: 0.00867248
Epoch [45/300], Train Loss: 0.008386
Validation Loss: 0.00834395
Epoch [46/300], Train Loss: 0.008126
Validation Loss: 0.00825415
Epoch [47/300], Train Loss: 0.008126
Validation Loss: 0.00826328
Epoch [48/300], Train Loss: 0.008061
Validation Loss: 0.00824221
Epoch [49/300], Train Loss: 0.008256
Validation Loss: 0.00823349
Epoch [50/300], Train Loss: 0.008294
Validation Loss: 0.00808457
Epoch [51/300], Train Loss: 0.008027
Validation Loss: 0.00807315
Epoch [52/300], Train Loss: 0.008277
Validation Loss: 0.01067782
Epoch [53/300], Train Loss: 0.008519
Validation Loss: 0.00903824
Epoch [54/300], Train Loss: 0.008596
Validation Loss: 0.00825789
Epoch [55/300], Train Loss: 0.007927
Validation Loss: 0.00811583
Epoch [56/300], Train Loss: 0.008433
Validation Loss: 0.00815679
Epoch [57/300], Train Loss: 0.007768
Validation Loss: 0.00813625
Epoch [58/300], Train Loss: 0.007830
Validation Loss: 0.00835994
Epoch [59/300], Train Loss: 0.007765
Validation Loss: 0.00794568
Epoch [60/300], Train Loss: 0.007743
Validation Loss: 0.00796326
Epoch [61/300], Train Loss: 0.007821
Validation Loss: 0.00798055
Epoch [62/300], Train Loss: 0.007611
Validation Loss: 0.00785698
Epoch [63/300], Train Loss: 0.007558
Validation Loss: 0.00781499
Epoch [64/300], Train Loss: 0.007387
Validation Loss: 0.00777684
Epoch [65/300], Train Loss: 0.007662
Validation Loss: 0.00805457
Epoch [66/300], Train Loss: 0.007709
Validation Loss: 0.00776516
Epoch [67/300], Train Loss: 0.007413
Validation Loss: 0.00770428
Epoch [68/300], Train Loss: 0.007334
Validation Loss: 0.00763113
Epoch [69/300], Train Loss: 0.007395
Validation Loss: 0.00762180
Epoch [70/300], Train Loss: 0.007402
Validation Loss: 0.00758287
Epoch [71/300], Train Loss: 0.007477
Validation Loss: 0.00797956
Epoch [72/300], Train Loss: 0.007855
Validation Loss: 0.00763947
Epoch [73/300], Train Loss: 0.007387
Validation Loss: 0.00766243
Epoch [74/300], Train Loss: 0.007344
Validation Loss: 0.00774187
Epoch [75/300], Train Loss: 0.007467
Validation Loss: 0.00763374
Epoch [76/300], Train Loss: 0.007453
Validation Loss: 0.00769470
Epoch [77/300], Train Loss: 0.007185
Validation Loss: 0.00748388
Epoch [78/300], Train Loss: 0.007173
Validation Loss: 0.00746111
Epoch [79/300], Train Loss: 0.007318
Validation Loss: 0.00751433
Epoch [80/300], Train Loss: 0.007275
Validation Loss: 0.00757330
Epoch [81/300], Train Loss: 0.007205
Validation Loss: 0.00750025
Epoch [82/300], Train Loss: 0.007221
Validation Loss: 0.00750293
Epoch [83/300], Train Loss: 0.007230
Validation Loss: 0.00763728
Epoch [84/300], Train Loss: 0.007195
Validation Loss: 0.00742608
Epoch [85/300], Train Loss: 0.007033
Validation Loss: 0.00741232
Epoch [86/300], Train Loss: 0.007077
Validation Loss: 0.00797851
Epoch [87/300], Train Loss: 0.007168
Validation Loss: 0.00761046
Epoch [88/300], Train Loss: 0.007094
Validation Loss: 0.00748353
Epoch [89/300], Train Loss: 0.007324
Validation Loss: 0.00779614
Epoch [90/300], Train Loss: 0.007150
Validation Loss: 0.00740046
Epoch [91/300], Train Loss: 0.007075
Validation Loss: 0.00736082
Epoch [92/300], Train Loss: 0.006969
Validation Loss: 0.00740864
Epoch [93/300], Train Loss: 0.007003
Validation Loss: 0.00733488
Epoch [94/300], Train Loss: 0.006986
Validation Loss: 0.00736602
Epoch [95/300], Train Loss: 0.006938
Validation Loss: 0.00737491
Epoch [96/300], Train Loss: 0.006969
Validation Loss: 0.00735769
Epoch [97/300], Train Loss: 0.007145
Validation Loss: 0.00734326
Epoch [98/300], Train Loss: 0.006872
Validation Loss: 0.00746056
Epoch [99/300], Train Loss: 0.006957
Validation Loss: 0.00728467
Epoch [100/300], Train Loss: 0.007038
Validation Loss: 0.00737081
Epoch [101/300], Train Loss: 0.007058
Validation Loss: 0.00738757
Epoch [102/300], Train Loss: 0.006911
Validation Loss: 0.00733150
Epoch [103/300], Train Loss: 0.006873
Validation Loss: 0.00725020
Epoch [104/300], Train Loss: 0.006975
Validation Loss: 0.00730466
Epoch [105/300], Train Loss: 0.006897
Validation Loss: 0.00726094
Epoch [106/300], Train Loss: 0.006942
Validation Loss: 0.00725089
Epoch [107/300], Train Loss: 0.007015
Validation Loss: 0.00722496
Epoch [108/300], Train Loss: 0.006982
Validation Loss: 0.00742238
Epoch [109/300], Train Loss: 0.006970
Validation Loss: 0.00724808
Epoch [110/300], Train Loss: 0.006943
Validation Loss: 0.00738535
Epoch [111/300], Train Loss: 0.006897
Validation Loss: 0.00721613
Epoch [112/300], Train Loss: 0.007250
Validation Loss: 0.00741999
Epoch [113/300], Train Loss: 0.007164
Validation Loss: 0.00757614
Epoch [114/300], Train Loss: 0.007016
Validation Loss: 0.00721285
Epoch [115/300], Train Loss: 0.006983
Validation Loss: 0.00731094
Epoch [116/300], Train Loss: 0.006823
Validation Loss: 0.00719186
Epoch [117/300], Train Loss: 0.006779
Validation Loss: 0.00726192
Epoch [118/300], Train Loss: 0.006690
Validation Loss: 0.00722482
Epoch [119/300], Train Loss: 0.006851
Validation Loss: 0.00717487
Epoch [120/300], Train Loss: 0.006828
Validation Loss: 0.00721670
Epoch [121/300], Train Loss: 0.006925
Validation Loss: 0.00717682
Epoch [122/300], Train Loss: 0.006901
Validation Loss: 0.00720457
Epoch [123/300], Train Loss: 0.006923
Validation Loss: 0.00721031
Epoch [124/300], Train Loss: 0.006896
Validation Loss: 0.00724941
Epoch [125/300], Train Loss: 0.006820
Validation Loss: 0.00718658
Epoch [126/300], Train Loss: 0.006797
Validation Loss: 0.00720991
Epoch [127/300], Train Loss: 0.006826
Validation Loss: 0.00715015
Epoch [128/300], Train Loss: 0.006758
Validation Loss: 0.00734876
Epoch [129/300], Train Loss: 0.006672
Validation Loss: 0.00724413
Epoch [130/300], Train Loss: 0.006945
Validation Loss: 0.00712855
Epoch [131/300], Train Loss: 0.006676
Validation Loss: 0.00721566
Epoch [132/300], Train Loss: 0.006790
Validation Loss: 0.00711094
Epoch [133/300], Train Loss: 0.006875
Validation Loss: 0.00711207
Epoch [134/300], Train Loss: 0.006822
Validation Loss: 0.00722467
Epoch [135/300], Train Loss: 0.006825
Validation Loss: 0.00708165
Epoch [136/300], Train Loss: 0.006759
Validation Loss: 0.00714261
Epoch [137/300], Train Loss: 0.006817
Validation Loss: 0.00719314
Epoch [138/300], Train Loss: 0.006724
Validation Loss: 0.00720299
Epoch [139/300], Train Loss: 0.006897
Validation Loss: 0.00710975
Epoch [140/300], Train Loss: 0.006805
Validation Loss: 0.00708397
Epoch [141/300], Train Loss: 0.006694
Validation Loss: 0.00711837
Epoch [142/300], Train Loss: 0.006952
Validation Loss: 0.00709766
Epoch [143/300], Train Loss: 0.006579
Validation Loss: 0.00706273
Epoch [144/300], Train Loss: 0.006699
Validation Loss: 0.00711847
Epoch [145/300], Train Loss: 0.006529
Validation Loss: 0.00708107
Epoch [146/300], Train Loss: 0.006657
Validation Loss: 0.00712014
Epoch [147/300], Train Loss: 0.006605
Validation Loss: 0.00710969
Epoch [148/300], Train Loss: 0.006660
Validation Loss: 0.00711715
Epoch [149/300], Train Loss: 0.006775
Validation Loss: 0.00702458
Epoch [150/300], Train Loss: 0.006642
Validation Loss: 0.00709478
Epoch [151/300], Train Loss: 0.006734
Validation Loss: 0.00706552
Epoch [152/300], Train Loss: 0.006513
Validation Loss: 0.00706141
Epoch [153/300], Train Loss: 0.006628
Validation Loss: 0.00706295
Epoch [154/300], Train Loss: 0.006708
Validation Loss: 0.00715233
Epoch [155/300], Train Loss: 0.006777
Validation Loss: 0.00706870
Epoch [156/300], Train Loss: 0.006784
Validation Loss: 0.00705448
Epoch [157/300], Train Loss: 0.006645
Validation Loss: 0.00708821
Epoch [158/300], Train Loss: 0.006622
Validation Loss: 0.00700826
Epoch [159/300], Train Loss: 0.006603
Validation Loss: 0.00696528
Epoch [160/300], Train Loss: 0.006590
Validation Loss: 0.00697514
Epoch [161/300], Train Loss: 0.006698
Validation Loss: 0.00697214
Epoch [162/300], Train Loss: 0.006500
Validation Loss: 0.00693105
Epoch [163/300], Train Loss: 0.006631
Validation Loss: 0.00701057
Epoch [164/300], Train Loss: 0.006510
Validation Loss: 0.00734735
Epoch [165/300], Train Loss: 0.006730
Validation Loss: 0.00710470
Epoch [166/300], Train Loss: 0.006669
Validation Loss: 0.00693012
Epoch [167/300], Train Loss: 0.006501
Validation Loss: 0.00691869
Epoch [168/300], Train Loss: 0.006540
Validation Loss: 0.00782586
Epoch [169/300], Train Loss: 0.006611
Validation Loss: 0.00701134
Epoch [170/300], Train Loss: 0.006551
Validation Loss: 0.00683082
Epoch [171/300], Train Loss: 0.006388
Validation Loss: 0.00685046
Epoch [172/300], Train Loss: 0.006524
Validation Loss: 0.00688548
Epoch [173/300], Train Loss: 0.006479
Validation Loss: 0.00710879
Epoch [174/300], Train Loss: 0.006835
Validation Loss: 0.00713310
Epoch [175/300], Train Loss: 0.006725
Validation Loss: 0.00703901
Epoch [176/300], Train Loss: 0.006644
Validation Loss: 0.00710340
Epoch [177/300], Train Loss: 0.006616
Validation Loss: 0.00707376
Epoch [178/300], Train Loss: 0.006652
Validation Loss: 0.00705590
Epoch [179/300], Train Loss: 0.006591
Validation Loss: 0.00703339
Epoch [180/300], Train Loss: 0.006627
Validation Loss: 0.00699189
Early stopping triggered

Evaluating model for: Tablet
Run 40/72 completed in 1755.93 seconds with: {'MAE': np.float32(0.6380921), 'MSE': np.float32(1.0628291), 'RMSE': np.float32(1.030936), 'SAE': np.float32(0.011571482), 'NDE': np.float32(0.237118)}

Run 41/72: hidden=256, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Tablet
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.084273
Validation Loss: 0.04895778
Epoch [2/300], Train Loss: 0.024781
Validation Loss: 0.01680391
Epoch [3/300], Train Loss: 0.017332
Validation Loss: 0.01527488
Epoch [4/300], Train Loss: 0.016530
Validation Loss: 0.01467237
Epoch [5/300], Train Loss: 0.015814
Validation Loss: 0.01368923
Epoch [6/300], Train Loss: 0.014771
Validation Loss: 0.01253184
Epoch [7/300], Train Loss: 0.013031
Validation Loss: 0.01057252
Epoch [8/300], Train Loss: 0.011720
Validation Loss: 0.01012375
Epoch [9/300], Train Loss: 0.011281
Validation Loss: 0.00977873
Epoch [10/300], Train Loss: 0.010900
Validation Loss: 0.00936182
Epoch [11/300], Train Loss: 0.010563
Validation Loss: 0.00908163
Epoch [12/300], Train Loss: 0.010241
Validation Loss: 0.00866330
Epoch [13/300], Train Loss: 0.009956
Validation Loss: 0.00839080
Epoch [14/300], Train Loss: 0.009747
Validation Loss: 0.00803948
Epoch [15/300], Train Loss: 0.009545
Validation Loss: 0.00788748
Epoch [16/300], Train Loss: 0.009324
Validation Loss: 0.00784815
Epoch [17/300], Train Loss: 0.009192
Validation Loss: 0.00766312
Epoch [18/300], Train Loss: 0.009134
Validation Loss: 0.00765745
Epoch [19/300], Train Loss: 0.009042
Validation Loss: 0.00761542
Epoch [20/300], Train Loss: 0.008913
Validation Loss: 0.00749175
Epoch [21/300], Train Loss: 0.008887
Validation Loss: 0.00737425
Epoch [22/300], Train Loss: 0.008710
Validation Loss: 0.00726281
Epoch [23/300], Train Loss: 0.009085
Validation Loss: 0.00815959
Epoch [24/300], Train Loss: 0.009123
Validation Loss: 0.00760463
Epoch [25/300], Train Loss: 0.008468
Validation Loss: 0.00709523
Epoch [26/300], Train Loss: 0.009110
Validation Loss: 0.01268396
Epoch [27/300], Train Loss: 0.012754
Validation Loss: 0.00909920
Epoch [28/300], Train Loss: 0.009787
Validation Loss: 0.00781200
Epoch [29/300], Train Loss: 0.008786
Validation Loss: 0.00728990
Epoch [30/300], Train Loss: 0.008999
Validation Loss: 0.00737141
Epoch [31/300], Train Loss: 0.009229
Validation Loss: 0.00779597
Epoch [32/300], Train Loss: 0.008875
Validation Loss: 0.00738087
Epoch [33/300], Train Loss: 0.008662
Validation Loss: 0.00720733
Epoch [34/300], Train Loss: 0.008579
Validation Loss: 0.00713925
Epoch [35/300], Train Loss: 0.008641
Validation Loss: 0.00730972
Early stopping triggered

Evaluating model for: Tablet
Run 41/72 completed in 263.51 seconds with: {'MAE': np.float32(0.6274896), 'MSE': np.float32(1.0987259), 'RMSE': np.float32(1.0482013), 'SAE': np.float32(0.0122407945), 'NDE': np.float32(0.23912613)}

Run 42/72: hidden=256, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Tablet
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.106590
Validation Loss: 0.05983231
Epoch [2/300], Train Loss: 0.026519
Validation Loss: 0.01733586
Epoch [3/300], Train Loss: 0.017314
Validation Loss: 0.01527018
Epoch [4/300], Train Loss: 0.016607
Validation Loss: 0.01482833
Epoch [5/300], Train Loss: 0.016151
Validation Loss: 0.01415006
Epoch [6/300], Train Loss: 0.015464
Validation Loss: 0.01345398
Epoch [7/300], Train Loss: 0.014211
Validation Loss: 0.01174242
Epoch [8/300], Train Loss: 0.012603
Validation Loss: 0.01080140
Epoch [9/300], Train Loss: 0.011902
Validation Loss: 0.01013197
Epoch [10/300], Train Loss: 0.011257
Validation Loss: 0.00948097
Epoch [11/300], Train Loss: 0.010799
Validation Loss: 0.00929499
Epoch [12/300], Train Loss: 0.010544
Validation Loss: 0.00894828
Epoch [13/300], Train Loss: 0.010297
Validation Loss: 0.00879140
Epoch [14/300], Train Loss: 0.010149
Validation Loss: 0.00858730
Epoch [15/300], Train Loss: 0.009918
Validation Loss: 0.00829267
Epoch [16/300], Train Loss: 0.009494
Validation Loss: 0.00787941
Epoch [17/300], Train Loss: 0.009074
Validation Loss: 0.00755474
Epoch [18/300], Train Loss: 0.008859
Validation Loss: 0.00741226
Epoch [19/300], Train Loss: 0.008697
Validation Loss: 0.00722204
Epoch [20/300], Train Loss: 0.008600
Validation Loss: 0.00731590
Epoch [21/300], Train Loss: 0.008537
Validation Loss: 0.00724076
Epoch [22/300], Train Loss: 0.008498
Validation Loss: 0.00702267
Epoch [23/300], Train Loss: 0.008618
Validation Loss: 0.00730313
Epoch [24/300], Train Loss: 0.008320
Validation Loss: 0.00691956
Epoch [25/300], Train Loss: 0.008235
Validation Loss: 0.00695208
Epoch [26/300], Train Loss: 0.008208
Validation Loss: 0.00695130
Epoch [27/300], Train Loss: 0.008203
Validation Loss: 0.00678661
Epoch [28/300], Train Loss: 0.008125
Validation Loss: 0.00676956
Epoch [29/300], Train Loss: 0.008207
Validation Loss: 0.00714239
Epoch [30/300], Train Loss: 0.008283
Validation Loss: 0.00661148
Epoch [31/300], Train Loss: 0.007965
Validation Loss: 0.00654654
Epoch [32/300], Train Loss: 0.011959
Validation Loss: 0.01258907
Epoch [33/300], Train Loss: 0.013341
Validation Loss: 0.01045329
Epoch [34/300], Train Loss: 0.010707
Validation Loss: 0.00859897
Epoch [35/300], Train Loss: 0.009258
Validation Loss: 0.00746810
Epoch [36/300], Train Loss: 0.008554
Validation Loss: 0.00739746
Epoch [37/300], Train Loss: 0.008885
Validation Loss: 0.00742115
Epoch [38/300], Train Loss: 0.009068
Validation Loss: 0.00713366
Epoch [39/300], Train Loss: 0.008311
Validation Loss: 0.00698036
Epoch [40/300], Train Loss: 0.008718
Validation Loss: 0.00727913
Epoch [41/300], Train Loss: 0.008583
Validation Loss: 0.00713559
Early stopping triggered

Evaluating model for: Tablet
Run 42/72 completed in 393.84 seconds with: {'MAE': np.float32(0.6141842), 'MSE': np.float32(1.0306001), 'RMSE': np.float32(1.0151848), 'SAE': np.float32(0.025363956), 'NDE': np.float32(0.23159409)}

Run 43/72: hidden=256, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Tablet
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.085588
Validation Loss: 0.03205154
Epoch [2/300], Train Loss: 0.019611
Validation Loss: 0.01450809
Epoch [3/300], Train Loss: 0.016216
Validation Loss: 0.01415445
Epoch [4/300], Train Loss: 0.015481
Validation Loss: 0.01352853
Epoch [5/300], Train Loss: 0.014631
Validation Loss: 0.01213705
Epoch [6/300], Train Loss: 0.012537
Validation Loss: 0.01064265
Epoch [7/300], Train Loss: 0.011264
Validation Loss: 0.00956180
Epoch [8/300], Train Loss: 0.010435
Validation Loss: 0.00886285
Epoch [9/300], Train Loss: 0.010133
Validation Loss: 0.00866310
Epoch [10/300], Train Loss: 0.009889
Validation Loss: 0.00834885
Epoch [11/300], Train Loss: 0.009597
Validation Loss: 0.00797149
Epoch [12/300], Train Loss: 0.009299
Validation Loss: 0.00774963
Epoch [13/300], Train Loss: 0.009170
Validation Loss: 0.00774615
Epoch [14/300], Train Loss: 0.009079
Validation Loss: 0.00762721
Epoch [15/300], Train Loss: 0.008884
Validation Loss: 0.00736720
Epoch [16/300], Train Loss: 0.008764
Validation Loss: 0.00739544
Epoch [17/300], Train Loss: 0.008682
Validation Loss: 0.00729592
Epoch [18/300], Train Loss: 0.008679
Validation Loss: 0.00740414
Epoch [19/300], Train Loss: 0.008605
Validation Loss: 0.00724480
Epoch [20/300], Train Loss: 0.008524
Validation Loss: 0.00715809
Epoch [21/300], Train Loss: 0.008480
Validation Loss: 0.00712526
Epoch [22/300], Train Loss: 0.008435
Validation Loss: 0.00709198
Epoch [23/300], Train Loss: 0.008468
Validation Loss: 0.00708994
Epoch [24/300], Train Loss: 0.008427
Validation Loss: 0.00712238
Epoch [25/300], Train Loss: 0.008362
Validation Loss: 0.00699821
Epoch [26/300], Train Loss: 0.008346
Validation Loss: 0.00695994
Epoch [27/300], Train Loss: 0.008266
Validation Loss: 0.00690745
Epoch [28/300], Train Loss: 0.008211
Validation Loss: 0.00684634
Epoch [29/300], Train Loss: 0.008195
Validation Loss: 0.00686377
Epoch [30/300], Train Loss: 0.008242
Validation Loss: 0.00674246
Epoch [31/300], Train Loss: 0.008038
Validation Loss: 0.00673153
Epoch [32/300], Train Loss: 0.008007
Validation Loss: 0.00675698
Epoch [33/300], Train Loss: 0.007989
Validation Loss: 0.00654576
Epoch [34/300], Train Loss: 0.008019
Validation Loss: 0.00658687
Epoch [35/300], Train Loss: 0.007871
Validation Loss: 0.00645475
Epoch [36/300], Train Loss: 0.007770
Validation Loss: 0.00640712
Epoch [37/300], Train Loss: 0.007714
Validation Loss: 0.00642774
Epoch [38/300], Train Loss: 0.007657
Validation Loss: 0.00656477
Epoch [39/300], Train Loss: 0.007591
Validation Loss: 0.00625720
Epoch [40/300], Train Loss: 0.007541
Validation Loss: 0.00616909
Epoch [41/300], Train Loss: 0.007553
Validation Loss: 0.00626998
Epoch [42/300], Train Loss: 0.007595
Validation Loss: 0.00616920
Epoch [43/300], Train Loss: 0.007525
Validation Loss: 0.00620197
Epoch [44/300], Train Loss: 0.007425
Validation Loss: 0.00610198
Epoch [45/300], Train Loss: 0.007467
Validation Loss: 0.00618848
Epoch [46/300], Train Loss: 0.007389
Validation Loss: 0.00609568
Epoch [47/300], Train Loss: 0.007413
Validation Loss: 0.00607572
Epoch [48/300], Train Loss: 0.007412
Validation Loss: 0.00609133
Epoch [49/300], Train Loss: 0.007351
Validation Loss: 0.00611812
Epoch [50/300], Train Loss: 0.007360
Validation Loss: 0.00601633
Epoch [51/300], Train Loss: 0.007343
Validation Loss: 0.00603192
Epoch [52/300], Train Loss: 0.007330
Validation Loss: 0.00610330
Epoch [53/300], Train Loss: 0.007353
Validation Loss: 0.00596719
Epoch [54/300], Train Loss: 0.007314
Validation Loss: 0.00613003
Epoch [55/300], Train Loss: 0.007351
Validation Loss: 0.00601099
Epoch [56/300], Train Loss: 0.007357
Validation Loss: 0.00598801
Epoch [57/300], Train Loss: 0.007285
Validation Loss: 0.00595702
Epoch [58/300], Train Loss: 0.007453
Validation Loss: 0.00627807
Epoch [59/300], Train Loss: 0.007261
Validation Loss: 0.00597855
Epoch [60/300], Train Loss: 0.007259
Validation Loss: 0.00596978
Epoch [61/300], Train Loss: 0.007207
Validation Loss: 0.00597096
Epoch [62/300], Train Loss: 0.007238
Validation Loss: 0.00601836
Epoch [63/300], Train Loss: 0.007309
Validation Loss: 0.00594453
Epoch [64/300], Train Loss: 0.007199
Validation Loss: 0.00589852
Epoch [65/300], Train Loss: 0.007240
Validation Loss: 0.00590113
Epoch [66/300], Train Loss: 0.007204
Validation Loss: 0.00594441
Epoch [67/300], Train Loss: 0.007241
Validation Loss: 0.00589204
Epoch [68/300], Train Loss: 0.007218
Validation Loss: 0.00593671
Epoch [69/300], Train Loss: 0.007200
Validation Loss: 0.00588396
Epoch [70/300], Train Loss: 0.007190
Validation Loss: 0.00588480
Epoch [71/300], Train Loss: 0.007184
Validation Loss: 0.00590030
Epoch [72/300], Train Loss: 0.007225
Validation Loss: 0.00589016
Epoch [73/300], Train Loss: 0.007182
Validation Loss: 0.00586330
Epoch [74/300], Train Loss: 0.007153
Validation Loss: 0.00589015
Epoch [75/300], Train Loss: 0.007170
Validation Loss: 0.00593130
Epoch [76/300], Train Loss: 0.007222
Validation Loss: 0.00588038
Epoch [77/300], Train Loss: 0.007141
Validation Loss: 0.00588987
Epoch [78/300], Train Loss: 0.007151
Validation Loss: 0.00583962
Epoch [79/300], Train Loss: 0.007228
Validation Loss: 0.00599243
Epoch [80/300], Train Loss: 0.007210
Validation Loss: 0.00590791
Epoch [81/300], Train Loss: 0.007129
Validation Loss: 0.00584217
Epoch [82/300], Train Loss: 0.007078
Validation Loss: 0.00583449
Epoch [83/300], Train Loss: 0.007071
Validation Loss: 0.00607125
Epoch [84/300], Train Loss: 0.007158
Validation Loss: 0.00588700
Epoch [85/300], Train Loss: 0.007138
Validation Loss: 0.00599795
Epoch [86/300], Train Loss: 0.007131
Validation Loss: 0.00584799
Epoch [87/300], Train Loss: 0.007113
Validation Loss: 0.00585854
Epoch [88/300], Train Loss: 0.007116
Validation Loss: 0.00580741
Epoch [89/300], Train Loss: 0.007105
Validation Loss: 0.00582999
Epoch [90/300], Train Loss: 0.007069
Validation Loss: 0.00580031
Epoch [91/300], Train Loss: 0.007077
Validation Loss: 0.00582795
Epoch [92/300], Train Loss: 0.007051
Validation Loss: 0.00580384
Epoch [93/300], Train Loss: 0.007068
Validation Loss: 0.00579313
Epoch [94/300], Train Loss: 0.007062
Validation Loss: 0.00583557
Epoch [95/300], Train Loss: 0.007081
Validation Loss: 0.00583742
Epoch [96/300], Train Loss: 0.007035
Validation Loss: 0.00579782
Epoch [97/300], Train Loss: 0.007063
Validation Loss: 0.00583009
Epoch [98/300], Train Loss: 0.007055
Validation Loss: 0.00579514
Epoch [99/300], Train Loss: 0.007024
Validation Loss: 0.00579564
Epoch [100/300], Train Loss: 0.007047
Validation Loss: 0.00589363
Epoch [101/300], Train Loss: 0.007062
Validation Loss: 0.00578343
Epoch [102/300], Train Loss: 0.007027
Validation Loss: 0.00580055
Epoch [103/300], Train Loss: 0.007035
Validation Loss: 0.00578297
Epoch [104/300], Train Loss: 0.007051
Validation Loss: 0.00575285
Epoch [105/300], Train Loss: 0.007026
Validation Loss: 0.00578226
Epoch [106/300], Train Loss: 0.007005
Validation Loss: 0.00575387
Epoch [107/300], Train Loss: 0.007000
Validation Loss: 0.00577770
Epoch [108/300], Train Loss: 0.007038
Validation Loss: 0.00574273
Epoch [109/300], Train Loss: 0.007050
Validation Loss: 0.00576367
Epoch [110/300], Train Loss: 0.007008
Validation Loss: 0.00573708
Epoch [111/300], Train Loss: 0.006984
Validation Loss: 0.00575727
Epoch [112/300], Train Loss: 0.006963
Validation Loss: 0.00573100
Epoch [113/300], Train Loss: 0.007006
Validation Loss: 0.00574186
Epoch [114/300], Train Loss: 0.007009
Validation Loss: 0.00577789
Epoch [115/300], Train Loss: 0.006983
Validation Loss: 0.00572193
Epoch [116/300], Train Loss: 0.006993
Validation Loss: 0.00574023
Epoch [117/300], Train Loss: 0.006961
Validation Loss: 0.00572764
Epoch [118/300], Train Loss: 0.006945
Validation Loss: 0.00568596
Epoch [119/300], Train Loss: 0.006932
Validation Loss: 0.00576031
Epoch [120/300], Train Loss: 0.006952
Validation Loss: 0.00573671
Epoch [121/300], Train Loss: 0.006924
Validation Loss: 0.00563513
Epoch [122/300], Train Loss: 0.006913
Validation Loss: 0.00558590
Epoch [123/300], Train Loss: 0.007068
Validation Loss: 0.00563220
Epoch [124/300], Train Loss: 0.006895
Validation Loss: 0.00558083
Epoch [125/300], Train Loss: 0.006908
Validation Loss: 0.00563718
Epoch [126/300], Train Loss: 0.007064
Validation Loss: 0.00561861
Epoch [127/300], Train Loss: 0.006882
Validation Loss: 0.00556301
Epoch [128/300], Train Loss: 0.006942
Validation Loss: 0.00559422
Epoch [129/300], Train Loss: 0.006923
Validation Loss: 0.00566316
Epoch [130/300], Train Loss: 0.006912
Validation Loss: 0.00555988
Epoch [131/300], Train Loss: 0.006889
Validation Loss: 0.00555680
Epoch [132/300], Train Loss: 0.006956
Validation Loss: 0.00554261
Epoch [133/300], Train Loss: 0.006806
Validation Loss: 0.00552336
Epoch [134/300], Train Loss: 0.006812
Validation Loss: 0.00551981
Epoch [135/300], Train Loss: 0.006814
Validation Loss: 0.00547734
Epoch [136/300], Train Loss: 0.006890
Validation Loss: 0.00549937
Epoch [137/300], Train Loss: 0.006834
Validation Loss: 0.00555513
Epoch [138/300], Train Loss: 0.007007
Validation Loss: 0.00561147
Epoch [139/300], Train Loss: 0.006857
Validation Loss: 0.00578531
Epoch [140/300], Train Loss: 0.006914
Validation Loss: 0.00556441
Epoch [141/300], Train Loss: 0.006879
Validation Loss: 0.00554182
Epoch [142/300], Train Loss: 0.007471
Validation Loss: 0.00624156
Epoch [143/300], Train Loss: 0.007105
Validation Loss: 0.00581360
Epoch [144/300], Train Loss: 0.006976
Validation Loss: 0.00590350
Epoch [145/300], Train Loss: 0.006998
Validation Loss: 0.00577779
Early stopping triggered

Evaluating model for: Tablet
Run 43/72 completed in 1647.29 seconds with: {'MAE': np.float32(0.57755744), 'MSE': np.float32(0.8962113), 'RMSE': np.float32(0.94668436), 'SAE': np.float32(0.022758985), 'NDE': np.float32(0.21596713)}

Run 44/72: hidden=256, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Tablet
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.063159
Validation Loss: 0.02711900
Epoch [2/300], Train Loss: 0.018167
Validation Loss: 0.01474469
Epoch [3/300], Train Loss: 0.016150
Validation Loss: 0.01432417
Epoch [4/300], Train Loss: 0.015723
Validation Loss: 0.01403234
Epoch [5/300], Train Loss: 0.015387
Validation Loss: 0.01334612
Epoch [6/300], Train Loss: 0.013958
Validation Loss: 0.01131179
Epoch [7/300], Train Loss: 0.011759
Validation Loss: 0.00966144
Epoch [8/300], Train Loss: 0.010431
Validation Loss: 0.00876892
Epoch [9/300], Train Loss: 0.009858
Validation Loss: 0.00857685
Epoch [10/300], Train Loss: 0.009555
Validation Loss: 0.00790261
Epoch [11/300], Train Loss: 0.009305
Validation Loss: 0.00842856
Epoch [12/300], Train Loss: 0.009417
Validation Loss: 0.00769136
Epoch [13/300], Train Loss: 0.009165
Validation Loss: 0.00762709
Epoch [14/300], Train Loss: 0.009044
Validation Loss: 0.00794367
Epoch [15/300], Train Loss: 0.009075
Validation Loss: 0.00749952
Epoch [16/300], Train Loss: 0.008866
Validation Loss: 0.00751305
Epoch [17/300], Train Loss: 0.008804
Validation Loss: 0.00739409
Epoch [18/300], Train Loss: 0.008802
Validation Loss: 0.00744082
Epoch [19/300], Train Loss: 0.008758
Validation Loss: 0.00732232
Epoch [20/300], Train Loss: 0.008616
Validation Loss: 0.00727717
Epoch [21/300], Train Loss: 0.008625
Validation Loss: 0.00727756
Epoch [22/300], Train Loss: 0.008518
Validation Loss: 0.00723459
Epoch [23/300], Train Loss: 0.008599
Validation Loss: 0.00715844
Epoch [24/300], Train Loss: 0.008538
Validation Loss: 0.00725836
Epoch [25/300], Train Loss: 0.008481
Validation Loss: 0.00726915
Epoch [26/300], Train Loss: 0.008507
Validation Loss: 0.00719111
Epoch [27/300], Train Loss: 0.008431
Validation Loss: 0.00704403
Epoch [28/300], Train Loss: 0.008368
Validation Loss: 0.00709178
Epoch [29/300], Train Loss: 0.008370
Validation Loss: 0.00703604
Epoch [30/300], Train Loss: 0.008381
Validation Loss: 0.00696559
Epoch [31/300], Train Loss: 0.008217
Validation Loss: 0.00694077
Epoch [32/300], Train Loss: 0.008188
Validation Loss: 0.00690610
Epoch [33/300], Train Loss: 0.008207
Validation Loss: 0.00712939
Epoch [34/300], Train Loss: 0.008314
Validation Loss: 0.00698622
Epoch [35/300], Train Loss: 0.008168
Validation Loss: 0.00693995
Epoch [36/300], Train Loss: 0.008181
Validation Loss: 0.00684776
Epoch [37/300], Train Loss: 0.008104
Validation Loss: 0.00691502
Epoch [38/300], Train Loss: 0.008069
Validation Loss: 0.00670840
Epoch [39/300], Train Loss: 0.007968
Validation Loss: 0.00667963
Epoch [40/300], Train Loss: 0.007967
Validation Loss: 0.00663656
Epoch [41/300], Train Loss: 0.007934
Validation Loss: 0.00664815
Epoch [42/300], Train Loss: 0.007951
Validation Loss: 0.00672776
Epoch [43/300], Train Loss: 0.008043
Validation Loss: 0.00669465
Epoch [44/300], Train Loss: 0.008324
Validation Loss: 0.00718408
Epoch [45/300], Train Loss: 0.008099
Validation Loss: 0.00656872
Epoch [46/300], Train Loss: 0.007803
Validation Loss: 0.00669865
Epoch [47/300], Train Loss: 0.007757
Validation Loss: 0.00650556
Epoch [48/300], Train Loss: 0.007680
Validation Loss: 0.00647466
Epoch [49/300], Train Loss: 0.007670
Validation Loss: 0.00648239
Epoch [50/300], Train Loss: 0.007660
Validation Loss: 0.00644440
Epoch [51/300], Train Loss: 0.007603
Validation Loss: 0.00638609
Epoch [52/300], Train Loss: 0.007544
Validation Loss: 0.00638380
Epoch [53/300], Train Loss: 0.007508
Validation Loss: 0.00639371
Epoch [54/300], Train Loss: 0.007529
Validation Loss: 0.00635891
Epoch [55/300], Train Loss: 0.007478
Validation Loss: 0.00631938
Epoch [56/300], Train Loss: 0.007549
Validation Loss: 0.00636961
Epoch [57/300], Train Loss: 0.007469
Validation Loss: 0.00632286
Epoch [58/300], Train Loss: 0.007705
Validation Loss: 0.00652132
Epoch [59/300], Train Loss: 0.007434
Validation Loss: 0.00629244
Epoch [60/300], Train Loss: 0.007445
Validation Loss: 0.00631424
Epoch [61/300], Train Loss: 0.007363
Validation Loss: 0.00623045
Epoch [62/300], Train Loss: 0.007346
Validation Loss: 0.00625284
Epoch [63/300], Train Loss: 0.007423
Validation Loss: 0.00616972
Epoch [64/300], Train Loss: 0.007317
Validation Loss: 0.00622752
Epoch [65/300], Train Loss: 0.007424
Validation Loss: 0.00619005
Epoch [66/300], Train Loss: 0.007339
Validation Loss: 0.00623796
Epoch [67/300], Train Loss: 0.007308
Validation Loss: 0.00616532
Epoch [68/300], Train Loss: 0.007315
Validation Loss: 0.00621591
Epoch [69/300], Train Loss: 0.007344
Validation Loss: 0.00614693
Epoch [70/300], Train Loss: 0.007342
Validation Loss: 0.00629154
Epoch [71/300], Train Loss: 0.007287
Validation Loss: 0.00611949
Epoch [72/300], Train Loss: 0.007295
Validation Loss: 0.00616211
Epoch [73/300], Train Loss: 0.007284
Validation Loss: 0.00610308
Epoch [74/300], Train Loss: 0.007279
Validation Loss: 0.00611318
Epoch [75/300], Train Loss: 0.007230
Validation Loss: 0.00611743
Epoch [76/300], Train Loss: 0.007243
Validation Loss: 0.00604778
Epoch [77/300], Train Loss: 0.007219
Validation Loss: 0.00606857
Epoch [78/300], Train Loss: 0.007242
Validation Loss: 0.00609527
Epoch [79/300], Train Loss: 0.007325
Validation Loss: 0.00627149
Epoch [80/300], Train Loss: 0.007358
Validation Loss: 0.00617168
Epoch [81/300], Train Loss: 0.010117
Validation Loss: 0.00770306
Epoch [82/300], Train Loss: 0.007979
Validation Loss: 0.00653779
Epoch [83/300], Train Loss: 0.007606
Validation Loss: 0.00632340
Epoch [84/300], Train Loss: 0.007535
Validation Loss: 0.00651675
Epoch [85/300], Train Loss: 0.007460
Validation Loss: 0.00634724
Epoch [86/300], Train Loss: 0.007323
Validation Loss: 0.00626327
Early stopping triggered

Evaluating model for: Tablet
Run 44/72 completed in 1348.71 seconds with: {'MAE': np.float32(0.58541185), 'MSE': np.float32(0.9432247), 'RMSE': np.float32(0.97119755), 'SAE': np.float32(0.023787012), 'NDE': np.float32(0.22155935)}

Run 45/72: hidden=256, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Tablet
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.120058
Validation Loss: 0.11147499
Epoch [2/300], Train Loss: 0.091320
Validation Loss: 0.07685075
Epoch [3/300], Train Loss: 0.048407
Validation Loss: 0.02110251
Epoch [4/300], Train Loss: 0.021780
Validation Loss: 0.02168421
Epoch [5/300], Train Loss: 0.019038
Validation Loss: 0.01853005
Epoch [6/300], Train Loss: 0.017356
Validation Loss: 0.01812302
Epoch [7/300], Train Loss: 0.016507
Validation Loss: 0.01731742
Epoch [8/300], Train Loss: 0.015807
Validation Loss: 0.01674557
Epoch [9/300], Train Loss: 0.015102
Validation Loss: 0.01609733
Epoch [10/300], Train Loss: 0.014318
Validation Loss: 0.01529136
Epoch [11/300], Train Loss: 0.013423
Validation Loss: 0.01454426
Epoch [12/300], Train Loss: 0.012508
Validation Loss: 0.01384195
Epoch [13/300], Train Loss: 0.011740
Validation Loss: 0.01335829
Epoch [14/300], Train Loss: 0.011373
Validation Loss: 0.01327990
Epoch [15/300], Train Loss: 0.011182
Validation Loss: 0.01306074
Epoch [16/300], Train Loss: 0.011058
Validation Loss: 0.01303894
Epoch [17/300], Train Loss: 0.010961
Validation Loss: 0.01306634
Epoch [18/300], Train Loss: 0.010915
Validation Loss: 0.01294998
Epoch [19/300], Train Loss: 0.010751
Validation Loss: 0.01268078
Epoch [20/300], Train Loss: 0.010581
Validation Loss: 0.01242036
Epoch [21/300], Train Loss: 0.010468
Validation Loss: 0.01227706
Epoch [22/300], Train Loss: 0.010312
Validation Loss: 0.01219328
Epoch [23/300], Train Loss: 0.010179
Validation Loss: 0.01201731
Epoch [24/300], Train Loss: 0.010033
Validation Loss: 0.01180602
Epoch [25/300], Train Loss: 0.009881
Validation Loss: 0.01162999
Epoch [26/300], Train Loss: 0.009742
Validation Loss: 0.01152616
Epoch [27/300], Train Loss: 0.009607
Validation Loss: 0.01137368
Epoch [28/300], Train Loss: 0.009483
Validation Loss: 0.01126320
Epoch [29/300], Train Loss: 0.009362
Validation Loss: 0.01114196
Epoch [30/300], Train Loss: 0.009321
Validation Loss: 0.01109637
Epoch [31/300], Train Loss: 0.009194
Validation Loss: 0.01099542
Epoch [32/300], Train Loss: 0.009144
Validation Loss: 0.01099542
Epoch [33/300], Train Loss: 0.009059
Validation Loss: 0.01091033
Epoch [34/300], Train Loss: 0.008998
Validation Loss: 0.01076645
Epoch [35/300], Train Loss: 0.008891
Validation Loss: 0.01067880
Epoch [36/300], Train Loss: 0.008802
Validation Loss: 0.01062632
Epoch [37/300], Train Loss: 0.008782
Validation Loss: 0.01057563
Epoch [38/300], Train Loss: 0.008757
Validation Loss: 0.01052171
Epoch [39/300], Train Loss: 0.008734
Validation Loss: 0.01052828
Epoch [40/300], Train Loss: 0.008673
Validation Loss: 0.01055781
Epoch [41/300], Train Loss: 0.008594
Validation Loss: 0.01042730
Epoch [42/300], Train Loss: 0.008552
Validation Loss: 0.01033265
Epoch [43/300], Train Loss: 0.008542
Validation Loss: 0.01027241
Epoch [44/300], Train Loss: 0.008495
Validation Loss: 0.01023451
Epoch [45/300], Train Loss: 0.008456
Validation Loss: 0.01019395
Epoch [46/300], Train Loss: 0.008435
Validation Loss: 0.01013526
Epoch [47/300], Train Loss: 0.008341
Validation Loss: 0.01016163
Epoch [48/300], Train Loss: 0.008309
Validation Loss: 0.01000943
Epoch [49/300], Train Loss: 0.008286
Validation Loss: 0.01008625
Epoch [50/300], Train Loss: 0.008248
Validation Loss: 0.00990584
Epoch [51/300], Train Loss: 0.008173
Validation Loss: 0.01010248
Epoch [52/300], Train Loss: 0.008452
Validation Loss: 0.01040325
Epoch [53/300], Train Loss: 0.008189
Validation Loss: 0.01046991
Epoch [54/300], Train Loss: 0.008207
Validation Loss: 0.01003068
Epoch [55/300], Train Loss: 0.008111
Validation Loss: 0.00987763
Epoch [56/300], Train Loss: 0.008074
Validation Loss: 0.00997331
Epoch [57/300], Train Loss: 0.008083
Validation Loss: 0.00973211
Epoch [58/300], Train Loss: 0.007986
Validation Loss: 0.00959788
Epoch [59/300], Train Loss: 0.008041
Validation Loss: 0.00971964
Epoch [60/300], Train Loss: 0.007909
Validation Loss: 0.00955765
Epoch [61/300], Train Loss: 0.007923
Validation Loss: 0.00959182
Epoch [62/300], Train Loss: 0.007921
Validation Loss: 0.00949933
Epoch [63/300], Train Loss: 0.007896
Validation Loss: 0.00955642
Epoch [64/300], Train Loss: 0.007867
Validation Loss: 0.00953804
Epoch [65/300], Train Loss: 0.007872
Validation Loss: 0.00947255
Epoch [66/300], Train Loss: 0.007822
Validation Loss: 0.00946473
Epoch [67/300], Train Loss: 0.007819
Validation Loss: 0.00944641
Epoch [68/300], Train Loss: 0.007795
Validation Loss: 0.00984275
Epoch [69/300], Train Loss: 0.007764
Validation Loss: 0.00948609
Epoch [70/300], Train Loss: 0.007876
Validation Loss: 0.00977510
Epoch [71/300], Train Loss: 0.007783
Validation Loss: 0.00940990
Epoch [72/300], Train Loss: 0.007728
Validation Loss: 0.00964076
Epoch [73/300], Train Loss: 0.007792
Validation Loss: 0.00940509
Epoch [74/300], Train Loss: 0.007860
Validation Loss: 0.00932714
Epoch [75/300], Train Loss: 0.007685
Validation Loss: 0.00936405
Epoch [76/300], Train Loss: 0.007851
Validation Loss: 0.00961129
Epoch [77/300], Train Loss: 0.007869
Validation Loss: 0.00942076
Epoch [78/300], Train Loss: 0.007751
Validation Loss: 0.00981524
Epoch [79/300], Train Loss: 0.007740
Validation Loss: 0.00938465
Epoch [80/300], Train Loss: 0.007623
Validation Loss: 0.00927620
Epoch [81/300], Train Loss: 0.009174
Validation Loss: 0.01100184
Epoch [82/300], Train Loss: 0.008265
Validation Loss: 0.00949849
Epoch [83/300], Train Loss: 0.007770
Validation Loss: 0.01020751
Epoch [84/300], Train Loss: 0.008013
Validation Loss: 0.00976192
Epoch [85/300], Train Loss: 0.007815
Validation Loss: 0.00942302
Epoch [86/300], Train Loss: 0.007635
Validation Loss: 0.00937393
Epoch [87/300], Train Loss: 0.007576
Validation Loss: 0.00923226
Epoch [88/300], Train Loss: 0.007540
Validation Loss: 0.00927665
Epoch [89/300], Train Loss: 0.007537
Validation Loss: 0.00940039
Epoch [90/300], Train Loss: 0.007820
Validation Loss: 0.00960245
Epoch [91/300], Train Loss: 0.007591
Validation Loss: 0.00968206
Epoch [92/300], Train Loss: 0.007595
Validation Loss: 0.00920261
Epoch [93/300], Train Loss: 0.007527
Validation Loss: 0.00925568
Epoch [94/300], Train Loss: 0.007568
Validation Loss: 0.00915080
Epoch [95/300], Train Loss: 0.007475
Validation Loss: 0.00927093
Epoch [96/300], Train Loss: 0.007542
Validation Loss: 0.00928563
Epoch [97/300], Train Loss: 0.007458
Validation Loss: 0.00917642
Epoch [98/300], Train Loss: 0.007462
Validation Loss: 0.00920144
Epoch [99/300], Train Loss: 0.007633
Validation Loss: 0.00925253
Epoch [100/300], Train Loss: 0.009192
Validation Loss: 0.01038657
Epoch [101/300], Train Loss: 0.008380
Validation Loss: 0.00924243
Epoch [102/300], Train Loss: 0.007621
Validation Loss: 0.00912820
Epoch [103/300], Train Loss: 0.007463
Validation Loss: 0.00922391
Epoch [104/300], Train Loss: 0.007439
Validation Loss: 0.00910199
Epoch [105/300], Train Loss: 0.007396
Validation Loss: 0.00912341
Epoch [106/300], Train Loss: 0.007374
Validation Loss: 0.00913720
Epoch [107/300], Train Loss: 0.007382
Validation Loss: 0.00912504
Epoch [108/300], Train Loss: 0.007367
Validation Loss: 0.00908657
Epoch [109/300], Train Loss: 0.007372
Validation Loss: 0.00916130
Epoch [110/300], Train Loss: 0.007776
Validation Loss: 0.00977490
Epoch [111/300], Train Loss: 0.007656
Validation Loss: 0.00910612
Epoch [112/300], Train Loss: 0.007441
Validation Loss: 0.00914540
Epoch [113/300], Train Loss: 0.007356
Validation Loss: 0.00911916
Epoch [114/300], Train Loss: 0.007418
Validation Loss: 0.00910248
Epoch [115/300], Train Loss: 0.007365
Validation Loss: 0.00909225
Epoch [116/300], Train Loss: 0.007371
Validation Loss: 0.00911893
Epoch [117/300], Train Loss: 0.007313
Validation Loss: 0.00905813
Epoch [118/300], Train Loss: 0.007322
Validation Loss: 0.00904156
Epoch [119/300], Train Loss: 0.007353
Validation Loss: 0.00910663
Epoch [120/300], Train Loss: 0.007301
Validation Loss: 0.00909542
Epoch [121/300], Train Loss: 0.007289
Validation Loss: 0.00902215
Epoch [122/300], Train Loss: 0.007348
Validation Loss: 0.00902885
Epoch [123/300], Train Loss: 0.007321
Validation Loss: 0.00904465
Epoch [124/300], Train Loss: 0.007272
Validation Loss: 0.00903551
Epoch [125/300], Train Loss: 0.007263
Validation Loss: 0.00901300
Epoch [126/300], Train Loss: 0.007288
Validation Loss: 0.00901914
Epoch [127/300], Train Loss: 0.007270
Validation Loss: 0.00902765
Epoch [128/300], Train Loss: 0.007262
Validation Loss: 0.00897622
Epoch [129/300], Train Loss: 0.007263
Validation Loss: 0.00903307
Epoch [130/300], Train Loss: 0.007233
Validation Loss: 0.00900421
Epoch [131/300], Train Loss: 0.007257
Validation Loss: 0.00898810
Epoch [132/300], Train Loss: 0.007252
Validation Loss: 0.00900964
Epoch [133/300], Train Loss: 0.007214
Validation Loss: 0.00902394
Epoch [134/300], Train Loss: 0.007263
Validation Loss: 0.00893138
Epoch [135/300], Train Loss: 0.007205
Validation Loss: 0.00900840
Epoch [136/300], Train Loss: 0.007224
Validation Loss: 0.00919165
Epoch [137/300], Train Loss: 0.007624
Validation Loss: 0.00916062
Epoch [138/300], Train Loss: 0.007319
Validation Loss: 0.00899354
Epoch [139/300], Train Loss: 0.007271
Validation Loss: 0.00896389
Epoch [140/300], Train Loss: 0.007190
Validation Loss: 0.00899627
Epoch [141/300], Train Loss: 0.007206
Validation Loss: 0.00893998
Epoch [142/300], Train Loss: 0.007270
Validation Loss: 0.00896943
Epoch [143/300], Train Loss: 0.007209
Validation Loss: 0.00899695
Epoch [144/300], Train Loss: 0.007180
Validation Loss: 0.00888966
Epoch [145/300], Train Loss: 0.007185
Validation Loss: 0.00891273
Epoch [146/300], Train Loss: 0.007171
Validation Loss: 0.00899607
Epoch [147/300], Train Loss: 0.007192
Validation Loss: 0.00893932
Epoch [148/300], Train Loss: 0.007114
Validation Loss: 0.00887417
Epoch [149/300], Train Loss: 0.007116
Validation Loss: 0.00889518
Epoch [150/300], Train Loss: 0.007134
Validation Loss: 0.00887482
Epoch [151/300], Train Loss: 0.007154
Validation Loss: 0.00887474
Epoch [152/300], Train Loss: 0.007107
Validation Loss: 0.00886041
Epoch [153/300], Train Loss: 0.007088
Validation Loss: 0.00884126
Epoch [154/300], Train Loss: 0.010133
Validation Loss: 0.01603222
Epoch [155/300], Train Loss: 0.014499
Validation Loss: 0.01506366
Epoch [156/300], Train Loss: 0.012645
Validation Loss: 0.01353034
Epoch [157/300], Train Loss: 0.011723
Validation Loss: 0.01286815
Epoch [158/300], Train Loss: 0.010916
Validation Loss: 0.01201609
Epoch [159/300], Train Loss: 0.010089
Validation Loss: 0.01135472
Epoch [160/300], Train Loss: 0.009496
Validation Loss: 0.01089279
Epoch [161/300], Train Loss: 0.009046
Validation Loss: 0.01058749
Epoch [162/300], Train Loss: 0.008732
Validation Loss: 0.01033686
Epoch [163/300], Train Loss: 0.008431
Validation Loss: 0.01005972
Early stopping triggered

Evaluating model for: Tablet
Run 45/72 completed in 604.41 seconds with: {'MAE': np.float32(0.8609597), 'MSE': np.float32(1.5225419), 'RMSE': np.float32(1.2339132), 'SAE': np.float32(0.0014571573), 'NDE': np.float32(0.2839398)}

Run 46/72: hidden=256, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Tablet
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.115926
Validation Loss: 0.10489132
Epoch [2/300], Train Loss: 0.082102
Validation Loss: 0.06128768
Epoch [3/300], Train Loss: 0.032431
Validation Loss: 0.02154668
Epoch [4/300], Train Loss: 0.017894
Validation Loss: 0.01923244
Epoch [5/300], Train Loss: 0.016616
Validation Loss: 0.01700567
Epoch [6/300], Train Loss: 0.015968
Validation Loss: 0.01714050
Epoch [7/300], Train Loss: 0.015724
Validation Loss: 0.01667894
Epoch [8/300], Train Loss: 0.015561
Validation Loss: 0.01654259
Epoch [9/300], Train Loss: 0.015355
Validation Loss: 0.01645369
Epoch [10/300], Train Loss: 0.015111
Validation Loss: 0.01608085
Epoch [11/300], Train Loss: 0.014811
Validation Loss: 0.01588312
Epoch [12/300], Train Loss: 0.014411
Validation Loss: 0.01546813
Epoch [13/300], Train Loss: 0.013825
Validation Loss: 0.01466257
Epoch [14/300], Train Loss: 0.012951
Validation Loss: 0.01376901
Epoch [15/300], Train Loss: 0.011869
Validation Loss: 0.01303120
Epoch [16/300], Train Loss: 0.011271
Validation Loss: 0.01300784
Epoch [17/300], Train Loss: 0.011014
Validation Loss: 0.01269016
Epoch [18/300], Train Loss: 0.010791
Validation Loss: 0.01254063
Epoch [19/300], Train Loss: 0.010576
Validation Loss: 0.01229782
Epoch [20/300], Train Loss: 0.010383
Validation Loss: 0.01206738
Epoch [21/300], Train Loss: 0.010208
Validation Loss: 0.01191161
Epoch [22/300], Train Loss: 0.009996
Validation Loss: 0.01177689
Epoch [23/300], Train Loss: 0.009788
Validation Loss: 0.01160513
Epoch [24/300], Train Loss: 0.009708
Validation Loss: 0.01139894
Epoch [25/300], Train Loss: 0.009609
Validation Loss: 0.01130920
Epoch [26/300], Train Loss: 0.009539
Validation Loss: 0.01131728
Epoch [27/300], Train Loss: 0.009468
Validation Loss: 0.01128990
Epoch [28/300], Train Loss: 0.009444
Validation Loss: 0.01110414
Epoch [29/300], Train Loss: 0.009310
Validation Loss: 0.01103051
Epoch [30/300], Train Loss: 0.009259
Validation Loss: 0.01096243
Epoch [31/300], Train Loss: 0.009138
Validation Loss: 0.01082669
Epoch [32/300], Train Loss: 0.009047
Validation Loss: 0.01084002
Epoch [33/300], Train Loss: 0.008943
Validation Loss: 0.01062832
Epoch [34/300], Train Loss: 0.008758
Validation Loss: 0.01026158
Epoch [35/300], Train Loss: 0.008466
Validation Loss: 0.00993048
Epoch [36/300], Train Loss: 0.008376
Validation Loss: 0.00976060
Epoch [37/300], Train Loss: 0.008235
Validation Loss: 0.00976031
Epoch [38/300], Train Loss: 0.008220
Validation Loss: 0.00965967
Epoch [39/300], Train Loss: 0.008097
Validation Loss: 0.00962162
Epoch [40/300], Train Loss: 0.008119
Validation Loss: 0.00970220
Epoch [41/300], Train Loss: 0.008189
Validation Loss: 0.00962179
Epoch [42/300], Train Loss: 0.008030
Validation Loss: 0.00966464
Epoch [43/300], Train Loss: 0.007974
Validation Loss: 0.00972250
Epoch [44/300], Train Loss: 0.007947
Validation Loss: 0.00962516
Epoch [45/300], Train Loss: 0.007881
Validation Loss: 0.00964283
Epoch [46/300], Train Loss: 0.007857
Validation Loss: 0.00964147
Epoch [47/300], Train Loss: 0.007832
Validation Loss: 0.00993774
Epoch [48/300], Train Loss: 0.008547
Validation Loss: 0.01076309
Epoch [49/300], Train Loss: 0.008358
Validation Loss: 0.00992461
Early stopping triggered

Evaluating model for: Tablet
Run 46/72 completed in 231.88 seconds with: {'MAE': np.float32(0.7886666), 'MSE': np.float32(1.5447775), 'RMSE': np.float32(1.2428908), 'SAE': np.float32(0.007090185), 'NDE': np.float32(0.28600565)}

Run 47/72: hidden=256, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Tablet
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.120926
Validation Loss: 0.10995317
Epoch [2/300], Train Loss: 0.086934
Validation Loss: 0.06590708
Epoch [3/300], Train Loss: 0.034329
Validation Loss: 0.01873921
Epoch [4/300], Train Loss: 0.017878
Validation Loss: 0.01830595
Epoch [5/300], Train Loss: 0.016558
Validation Loss: 0.01702559
Epoch [6/300], Train Loss: 0.016054
Validation Loss: 0.01700818
Epoch [7/300], Train Loss: 0.015831
Validation Loss: 0.01693064
Epoch [8/300], Train Loss: 0.015691
Validation Loss: 0.01671051
Epoch [9/300], Train Loss: 0.015561
Validation Loss: 0.01673802
Epoch [10/300], Train Loss: 0.015334
Validation Loss: 0.01636386
Epoch [11/300], Train Loss: 0.015047
Validation Loss: 0.01615053
Epoch [12/300], Train Loss: 0.014610
Validation Loss: 0.01569603
Epoch [13/300], Train Loss: 0.013835
Validation Loss: 0.01459232
Epoch [14/300], Train Loss: 0.012437
Validation Loss: 0.01324042
Epoch [15/300], Train Loss: 0.011332
Validation Loss: 0.01285069
Epoch [16/300], Train Loss: 0.010895
Validation Loss: 0.01264969
Epoch [17/300], Train Loss: 0.010580
Validation Loss: 0.01231063
Epoch [18/300], Train Loss: 0.010255
Validation Loss: 0.01188238
Epoch [19/300], Train Loss: 0.009884
Validation Loss: 0.01161930
Epoch [20/300], Train Loss: 0.009755
Validation Loss: 0.01148961
Epoch [21/300], Train Loss: 0.009653
Validation Loss: 0.01144510
Epoch [22/300], Train Loss: 0.009526
Validation Loss: 0.01141226
Epoch [23/300], Train Loss: 0.009437
Validation Loss: 0.01124934
Epoch [24/300], Train Loss: 0.009307
Validation Loss: 0.01105893
Epoch [25/300], Train Loss: 0.009132
Validation Loss: 0.01068645
Epoch [26/300], Train Loss: 0.008861
Validation Loss: 0.01047213
Epoch [27/300], Train Loss: 0.008812
Validation Loss: 0.01052392
Epoch [28/300], Train Loss: 0.008639
Validation Loss: 0.01031885
Epoch [29/300], Train Loss: 0.008621
Validation Loss: 0.01024636
Epoch [30/300], Train Loss: 0.008596
Validation Loss: 0.01054311
Epoch [31/300], Train Loss: 0.008508
Validation Loss: 0.01013649
Epoch [32/300], Train Loss: 0.008340
Validation Loss: 0.01017968
Epoch [33/300], Train Loss: 0.008312
Validation Loss: 0.01000220
Epoch [34/300], Train Loss: 0.008255
Validation Loss: 0.01001672
Epoch [35/300], Train Loss: 0.008228
Validation Loss: 0.00997448
Epoch [36/300], Train Loss: 0.008172
Validation Loss: 0.00993311
Epoch [37/300], Train Loss: 0.008124
Validation Loss: 0.00995774
Epoch [38/300], Train Loss: 0.008122
Validation Loss: 0.00995301
Epoch [39/300], Train Loss: 0.008132
Validation Loss: 0.00989662
Epoch [40/300], Train Loss: 0.008135
Validation Loss: 0.00989145
Epoch [41/300], Train Loss: 0.008120
Validation Loss: 0.00982268
Epoch [42/300], Train Loss: 0.008031
Validation Loss: 0.00985063
Epoch [43/300], Train Loss: 0.008022
Validation Loss: 0.00978115
Epoch [44/300], Train Loss: 0.008031
Validation Loss: 0.00978473
Epoch [45/300], Train Loss: 0.008050
Validation Loss: 0.00993042
Epoch [46/300], Train Loss: 0.008093
Validation Loss: 0.00974976
Epoch [47/300], Train Loss: 0.007961
Validation Loss: 0.00975875
Epoch [48/300], Train Loss: 0.007931
Validation Loss: 0.00972235
Epoch [49/300], Train Loss: 0.007921
Validation Loss: 0.00979766
Epoch [50/300], Train Loss: 0.007913
Validation Loss: 0.00973210
Epoch [51/300], Train Loss: 0.007901
Validation Loss: 0.00968736
Epoch [52/300], Train Loss: 0.007917
Validation Loss: 0.00987073
Epoch [53/300], Train Loss: 0.007930
Validation Loss: 0.00990775
Epoch [54/300], Train Loss: 0.007886
Validation Loss: 0.00967330
Epoch [55/300], Train Loss: 0.007842
Validation Loss: 0.00965716
Epoch [56/300], Train Loss: 0.007810
Validation Loss: 0.00976461
Epoch [57/300], Train Loss: 0.007896
Validation Loss: 0.00961423
Epoch [58/300], Train Loss: 0.007804
Validation Loss: 0.00956672
Epoch [59/300], Train Loss: 0.007775
Validation Loss: 0.00963314
Epoch [60/300], Train Loss: 0.007740
Validation Loss: 0.00953618
Epoch [61/300], Train Loss: 0.007778
Validation Loss: 0.00955785
Epoch [62/300], Train Loss: 0.007754
Validation Loss: 0.00951701
Epoch [63/300], Train Loss: 0.007714
Validation Loss: 0.00950088
Epoch [64/300], Train Loss: 0.007707
Validation Loss: 0.00954349
Epoch [65/300], Train Loss: 0.007725
Validation Loss: 0.00947403
Epoch [66/300], Train Loss: 0.007657
Validation Loss: 0.00954905
Epoch [67/300], Train Loss: 0.007643
Validation Loss: 0.00945661
Epoch [68/300], Train Loss: 0.007615
Validation Loss: 0.00957946
Epoch [69/300], Train Loss: 0.007618
Validation Loss: 0.00941314
Epoch [70/300], Train Loss: 0.007591
Validation Loss: 0.00937263
Epoch [71/300], Train Loss: 0.007596
Validation Loss: 0.00936761
Epoch [72/300], Train Loss: 0.007612
Validation Loss: 0.00936905
Epoch [73/300], Train Loss: 0.007567
Validation Loss: 0.00932553
Epoch [74/300], Train Loss: 0.007589
Validation Loss: 0.00933581
Epoch [75/300], Train Loss: 0.007559
Validation Loss: 0.00932467
Epoch [76/300], Train Loss: 0.007540
Validation Loss: 0.00928862
Epoch [77/300], Train Loss: 0.007495
Validation Loss: 0.00928071
Epoch [78/300], Train Loss: 0.007492
Validation Loss: 0.00927483
Epoch [79/300], Train Loss: 0.007454
Validation Loss: 0.00922262
Epoch [80/300], Train Loss: 0.007428
Validation Loss: 0.00922661
Epoch [81/300], Train Loss: 0.007446
Validation Loss: 0.00922203
Epoch [82/300], Train Loss: 0.007434
Validation Loss: 0.00916293
Epoch [83/300], Train Loss: 0.007382
Validation Loss: 0.00918151
Epoch [84/300], Train Loss: 0.007387
Validation Loss: 0.00917921
Epoch [85/300], Train Loss: 0.007393
Validation Loss: 0.00915427
Epoch [86/300], Train Loss: 0.007358
Validation Loss: 0.00907648
Epoch [87/300], Train Loss: 0.007438
Validation Loss: 0.00915570
Epoch [88/300], Train Loss: 0.007327
Validation Loss: 0.00908424
Epoch [89/300], Train Loss: 0.007329
Validation Loss: 0.00912862
Epoch [90/300], Train Loss: 0.007330
Validation Loss: 0.00901686
Epoch [91/300], Train Loss: 0.007299
Validation Loss: 0.00903364
Epoch [92/300], Train Loss: 0.007251
Validation Loss: 0.00898002
Epoch [93/300], Train Loss: 0.007272
Validation Loss: 0.00896338
Epoch [94/300], Train Loss: 0.007259
Validation Loss: 0.00909038
Epoch [95/300], Train Loss: 0.007252
Validation Loss: 0.00893564
Epoch [96/300], Train Loss: 0.007255
Validation Loss: 0.00893115
Epoch [97/300], Train Loss: 0.007185
Validation Loss: 0.00887958
Epoch [98/300], Train Loss: 0.007171
Validation Loss: 0.00889284
Epoch [99/300], Train Loss: 0.007164
Validation Loss: 0.00882122
Epoch [100/300], Train Loss: 0.007128
Validation Loss: 0.00884321
Epoch [101/300], Train Loss: 0.007136
Validation Loss: 0.00877892
Epoch [102/300], Train Loss: 0.007109
Validation Loss: 0.00880868
Epoch [103/300], Train Loss: 0.007092
Validation Loss: 0.00883548
Epoch [104/300], Train Loss: 0.007099
Validation Loss: 0.00878798
Epoch [105/300], Train Loss: 0.007070
Validation Loss: 0.00878365
Epoch [106/300], Train Loss: 0.007059
Validation Loss: 0.00878710
Epoch [107/300], Train Loss: 0.007045
Validation Loss: 0.00880042
Epoch [108/300], Train Loss: 0.007064
Validation Loss: 0.00870481
Epoch [109/300], Train Loss: 0.007084
Validation Loss: 0.00879136
Epoch [110/300], Train Loss: 0.007072
Validation Loss: 0.00870061
Epoch [111/300], Train Loss: 0.007001
Validation Loss: 0.00873797
Epoch [112/300], Train Loss: 0.007022
Validation Loss: 0.00865700
Epoch [113/300], Train Loss: 0.007016
Validation Loss: 0.00864154
Epoch [114/300], Train Loss: 0.006994
Validation Loss: 0.00874458
Epoch [115/300], Train Loss: 0.007039
Validation Loss: 0.00872986
Epoch [116/300], Train Loss: 0.007047
Validation Loss: 0.00864187
Epoch [117/300], Train Loss: 0.006970
Validation Loss: 0.00863212
Epoch [118/300], Train Loss: 0.006963
Validation Loss: 0.00864717
Epoch [119/300], Train Loss: 0.006973
Validation Loss: 0.00863735
Epoch [120/300], Train Loss: 0.007013
Validation Loss: 0.00873949
Epoch [121/300], Train Loss: 0.006975
Validation Loss: 0.00865287
Epoch [122/300], Train Loss: 0.007025
Validation Loss: 0.00877136
Epoch [123/300], Train Loss: 0.007021
Validation Loss: 0.00864076
Epoch [124/300], Train Loss: 0.006920
Validation Loss: 0.00857235
Epoch [125/300], Train Loss: 0.006935
Validation Loss: 0.00859298
Epoch [126/300], Train Loss: 0.006909
Validation Loss: 0.00859912
Epoch [127/300], Train Loss: 0.006914
Validation Loss: 0.00853875
Epoch [128/300], Train Loss: 0.006926
Validation Loss: 0.00856689
Epoch [129/300], Train Loss: 0.006895
Validation Loss: 0.00855980
Epoch [130/300], Train Loss: 0.006883
Validation Loss: 0.00863211
Epoch [131/300], Train Loss: 0.006892
Validation Loss: 0.00854667
Epoch [132/300], Train Loss: 0.006899
Validation Loss: 0.00853276
Epoch [133/300], Train Loss: 0.006873
Validation Loss: 0.00857551
Epoch [134/300], Train Loss: 0.006871
Validation Loss: 0.00852491
Epoch [135/300], Train Loss: 0.006869
Validation Loss: 0.00850634
Epoch [136/300], Train Loss: 0.006871
Validation Loss: 0.00849384
Epoch [137/300], Train Loss: 0.006855
Validation Loss: 0.00857396
Epoch [138/300], Train Loss: 0.006866
Validation Loss: 0.00853310
Epoch [139/300], Train Loss: 0.006859
Validation Loss: 0.00852757
Epoch [140/300], Train Loss: 0.006850
Validation Loss: 0.00854051
Epoch [141/300], Train Loss: 0.006845
Validation Loss: 0.00849351
Epoch [142/300], Train Loss: 0.006832
Validation Loss: 0.00850024
Epoch [143/300], Train Loss: 0.006855
Validation Loss: 0.00859944
Epoch [144/300], Train Loss: 0.006838
Validation Loss: 0.00853994
Epoch [145/300], Train Loss: 0.006824
Validation Loss: 0.00847515
Epoch [146/300], Train Loss: 0.006839
Validation Loss: 0.00868976
Epoch [147/300], Train Loss: 0.006864
Validation Loss: 0.00855904
Epoch [148/300], Train Loss: 0.006844
Validation Loss: 0.00848508
Epoch [149/300], Train Loss: 0.006816
Validation Loss: 0.00850716
Epoch [150/300], Train Loss: 0.006851
Validation Loss: 0.00846268
Epoch [151/300], Train Loss: 0.006820
Validation Loss: 0.00851832
Epoch [152/300], Train Loss: 0.006810
Validation Loss: 0.00858799
Epoch [153/300], Train Loss: 0.006880
Validation Loss: 0.00847233
Epoch [154/300], Train Loss: 0.006833
Validation Loss: 0.00844786
Epoch [155/300], Train Loss: 0.006817
Validation Loss: 0.00854845
Epoch [156/300], Train Loss: 0.006809
Validation Loss: 0.00846049
Epoch [157/300], Train Loss: 0.006833
Validation Loss: 0.00852958
Epoch [158/300], Train Loss: 0.006821
Validation Loss: 0.00848794
Epoch [159/300], Train Loss: 0.006796
Validation Loss: 0.00854346
Epoch [160/300], Train Loss: 0.006799
Validation Loss: 0.00853117
Epoch [161/300], Train Loss: 0.006804
Validation Loss: 0.00846026
Epoch [162/300], Train Loss: 0.006793
Validation Loss: 0.00846148
Epoch [163/300], Train Loss: 0.006828
Validation Loss: 0.00862193
Epoch [164/300], Train Loss: 0.006841
Validation Loss: 0.00852153
Early stopping triggered

Evaluating model for: Tablet
Run 47/72 completed in 933.72 seconds with: {'MAE': np.float32(0.71425515), 'MSE': np.float32(1.2632847), 'RMSE': np.float32(1.1239594), 'SAE': np.float32(0.014172215), 'NDE': np.float32(0.258638)}

Run 48/72: hidden=256, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Tablet
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.100299
Validation Loss: 0.08928062
Epoch [2/300], Train Loss: 0.064788
Validation Loss: 0.03664625
Epoch [3/300], Train Loss: 0.021476
Validation Loss: 0.01935211
Epoch [4/300], Train Loss: 0.017602
Validation Loss: 0.01692113
Epoch [5/300], Train Loss: 0.016144
Validation Loss: 0.01726888
Epoch [6/300], Train Loss: 0.015800
Validation Loss: 0.01671346
Epoch [7/300], Train Loss: 0.015561
Validation Loss: 0.01678768
Epoch [8/300], Train Loss: 0.015409
Validation Loss: 0.01647560
Epoch [9/300], Train Loss: 0.015260
Validation Loss: 0.01644879
Epoch [10/300], Train Loss: 0.014975
Validation Loss: 0.01599692
Epoch [11/300], Train Loss: 0.014536
Validation Loss: 0.01552148
Epoch [12/300], Train Loss: 0.013712
Validation Loss: 0.01455239
Epoch [13/300], Train Loss: 0.012328
Validation Loss: 0.01380059
Epoch [14/300], Train Loss: 0.011378
Validation Loss: 0.01273355
Epoch [15/300], Train Loss: 0.010268
Validation Loss: 0.01185185
Epoch [16/300], Train Loss: 0.009866
Validation Loss: 0.01173252
Epoch [17/300], Train Loss: 0.009651
Validation Loss: 0.01163262
Epoch [18/300], Train Loss: 0.009482
Validation Loss: 0.01148595
Epoch [19/300], Train Loss: 0.009236
Validation Loss: 0.01111922
Epoch [20/300], Train Loss: 0.009051
Validation Loss: 0.01069308
Epoch [21/300], Train Loss: 0.008879
Validation Loss: 0.01050803
Epoch [22/300], Train Loss: 0.008760
Validation Loss: 0.01052659
Epoch [23/300], Train Loss: 0.008703
Validation Loss: 0.01064521
Epoch [24/300], Train Loss: 0.008714
Validation Loss: 0.01058453
Epoch [25/300], Train Loss: 0.008680
Validation Loss: 0.01021409
Epoch [26/300], Train Loss: 0.008537
Validation Loss: 0.01021991
Epoch [27/300], Train Loss: 0.008582
Validation Loss: 0.01018852
Epoch [28/300], Train Loss: 0.008495
Validation Loss: 0.01020830
Epoch [29/300], Train Loss: 0.008519
Validation Loss: 0.01021462
Epoch [30/300], Train Loss: 0.008570
Validation Loss: 0.01025993
Epoch [31/300], Train Loss: 0.008398
Validation Loss: 0.01017336
Epoch [32/300], Train Loss: 0.008488
Validation Loss: 0.01018626
Epoch [33/300], Train Loss: 0.008336
Validation Loss: 0.01009570
Epoch [34/300], Train Loss: 0.008258
Validation Loss: 0.01011232
Epoch [35/300], Train Loss: 0.008974
Validation Loss: 0.01357291
Epoch [36/300], Train Loss: 0.012102
Validation Loss: 0.01184853
Epoch [37/300], Train Loss: 0.008862
Validation Loss: 0.01031995
Epoch [38/300], Train Loss: 0.008718
Validation Loss: 0.01031695
Epoch [39/300], Train Loss: 0.008374
Validation Loss: 0.01018610
Epoch [40/300], Train Loss: 0.008315
Validation Loss: 0.01015719
Epoch [41/300], Train Loss: 0.008275
Validation Loss: 0.01007117
Epoch [42/300], Train Loss: 0.008248
Validation Loss: 0.01006961
Epoch [43/300], Train Loss: 0.008294
Validation Loss: 0.01017457
Epoch [44/300], Train Loss: 0.008229
Validation Loss: 0.01008344
Epoch [45/300], Train Loss: 0.008186
Validation Loss: 0.01006273
Epoch [46/300], Train Loss: 0.008218
Validation Loss: 0.01010948
Epoch [47/300], Train Loss: 0.008328
Validation Loss: 0.01015314
Epoch [48/300], Train Loss: 0.008357
Validation Loss: 0.01026595
Epoch [49/300], Train Loss: 0.008376
Validation Loss: 0.01009094
Epoch [50/300], Train Loss: 0.008164
Validation Loss: 0.01002405
Epoch [51/300], Train Loss: 0.008104
Validation Loss: 0.00998913
Epoch [52/300], Train Loss: 0.008084
Validation Loss: 0.01014405
Epoch [53/300], Train Loss: 0.008131
Validation Loss: 0.01019010
Epoch [54/300], Train Loss: 0.008161
Validation Loss: 0.01002878
Epoch [55/300], Train Loss: 0.008113
Validation Loss: 0.00995935
Epoch [56/300], Train Loss: 0.008078
Validation Loss: 0.00998379
Epoch [57/300], Train Loss: 0.008046
Validation Loss: 0.00996812
Epoch [58/300], Train Loss: 0.008034
Validation Loss: 0.00995402
Epoch [59/300], Train Loss: 0.008057
Validation Loss: 0.00996433
Epoch [60/300], Train Loss: 0.008010
Validation Loss: 0.00994940
Epoch [61/300], Train Loss: 0.008055
Validation Loss: 0.01008859
Epoch [62/300], Train Loss: 0.008047
Validation Loss: 0.00991712
Epoch [63/300], Train Loss: 0.008015
Validation Loss: 0.00991357
Epoch [64/300], Train Loss: 0.007992
Validation Loss: 0.00990100
Epoch [65/300], Train Loss: 0.007995
Validation Loss: 0.00989460
Epoch [66/300], Train Loss: 0.007964
Validation Loss: 0.00991304
Epoch [67/300], Train Loss: 0.007962
Validation Loss: 0.00990964
Epoch [68/300], Train Loss: 0.007950
Validation Loss: 0.00997481
Epoch [69/300], Train Loss: 0.007951
Validation Loss: 0.00986956
Epoch [70/300], Train Loss: 0.007921
Validation Loss: 0.00987392
Epoch [71/300], Train Loss: 0.007929
Validation Loss: 0.00983855
Epoch [72/300], Train Loss: 0.007914
Validation Loss: 0.00983183
Epoch [73/300], Train Loss: 0.007908
Validation Loss: 0.00984198
Epoch [74/300], Train Loss: 0.007918
Validation Loss: 0.00985771
Epoch [75/300], Train Loss: 0.007902
Validation Loss: 0.00985328
Epoch [76/300], Train Loss: 0.007889
Validation Loss: 0.00981100
Epoch [77/300], Train Loss: 0.007872
Validation Loss: 0.00983745
Epoch [78/300], Train Loss: 0.007881
Validation Loss: 0.00981560
Epoch [79/300], Train Loss: 0.007857
Validation Loss: 0.00983421
Epoch [80/300], Train Loss: 0.007881
Validation Loss: 0.00983414
Epoch [81/300], Train Loss: 0.007843
Validation Loss: 0.00978171
Epoch [82/300], Train Loss: 0.007841
Validation Loss: 0.00975602
Epoch [83/300], Train Loss: 0.007832
Validation Loss: 0.00984042
Epoch [84/300], Train Loss: 0.007853
Validation Loss: 0.00981542
Epoch [85/300], Train Loss: 0.007848
Validation Loss: 0.00979522
Epoch [86/300], Train Loss: 0.007850
Validation Loss: 0.00979715
Epoch [87/300], Train Loss: 0.007805
Validation Loss: 0.00973462
Epoch [88/300], Train Loss: 0.007782
Validation Loss: 0.00972574
Epoch [89/300], Train Loss: 0.007782
Validation Loss: 0.00971946
Epoch [90/300], Train Loss: 0.007789
Validation Loss: 0.00974100
Epoch [91/300], Train Loss: 0.007754
Validation Loss: 0.00973031
Epoch [92/300], Train Loss: 0.007745
Validation Loss: 0.00968581
Epoch [93/300], Train Loss: 0.007786
Validation Loss: 0.00968430
Epoch [94/300], Train Loss: 0.007739
Validation Loss: 0.00969446
Epoch [95/300], Train Loss: 0.007731
Validation Loss: 0.00967847
Epoch [96/300], Train Loss: 0.007714
Validation Loss: 0.00972001
Epoch [97/300], Train Loss: 0.007708
Validation Loss: 0.00963938
Epoch [98/300], Train Loss: 0.007706
Validation Loss: 0.00964873
Epoch [99/300], Train Loss: 0.007692
Validation Loss: 0.00962098
Epoch [100/300], Train Loss: 0.007673
Validation Loss: 0.00961129
Epoch [101/300], Train Loss: 0.007705
Validation Loss: 0.00962713
Epoch [102/300], Train Loss: 0.007671
Validation Loss: 0.00958485
Epoch [103/300], Train Loss: 0.007683
Validation Loss: 0.00959150
Epoch [104/300], Train Loss: 0.007652
Validation Loss: 0.00957106
Epoch [105/300], Train Loss: 0.007643
Validation Loss: 0.00956125
Epoch [106/300], Train Loss: 0.007643
Validation Loss: 0.00956953
Epoch [107/300], Train Loss: 0.007619
Validation Loss: 0.00953907
Epoch [108/300], Train Loss: 0.007622
Validation Loss: 0.00954682
Epoch [109/300], Train Loss: 0.007605
Validation Loss: 0.00954438
Epoch [110/300], Train Loss: 0.007596
Validation Loss: 0.00953261
Epoch [111/300], Train Loss: 0.007585
Validation Loss: 0.00951323
Epoch [112/300], Train Loss: 0.007577
Validation Loss: 0.00949069
Epoch [113/300], Train Loss: 0.007569
Validation Loss: 0.00948272
Epoch [114/300], Train Loss: 0.007598
Validation Loss: 0.00947159
Epoch [115/300], Train Loss: 0.007591
Validation Loss: 0.00947293
Epoch [116/300], Train Loss: 0.007546
Validation Loss: 0.00943920
Epoch [117/300], Train Loss: 0.007533
Validation Loss: 0.00943560
Epoch [118/300], Train Loss: 0.007531
Validation Loss: 0.00946121
Epoch [119/300], Train Loss: 0.007529
Validation Loss: 0.00938690
Epoch [120/300], Train Loss: 0.007503
Validation Loss: 0.00937550
Epoch [121/300], Train Loss: 0.007500
Validation Loss: 0.00937664
Epoch [122/300], Train Loss: 0.007485
Validation Loss: 0.00934711
Epoch [123/300], Train Loss: 0.007460
Validation Loss: 0.00934143
Epoch [124/300], Train Loss: 0.007443
Validation Loss: 0.00932123
Epoch [125/300], Train Loss: 0.007419
Validation Loss: 0.00926218
Epoch [126/300], Train Loss: 0.007408
Validation Loss: 0.00924373
Epoch [127/300], Train Loss: 0.007380
Validation Loss: 0.00921490
Epoch [128/300], Train Loss: 0.007375
Validation Loss: 0.00919246
Epoch [129/300], Train Loss: 0.007380
Validation Loss: 0.00925718
Epoch [130/300], Train Loss: 0.007371
Validation Loss: 0.00917322
Epoch [131/300], Train Loss: 0.007310
Validation Loss: 0.00913792
Epoch [132/300], Train Loss: 0.007292
Validation Loss: 0.00911931
Epoch [133/300], Train Loss: 0.007277
Validation Loss: 0.00910658
Epoch [134/300], Train Loss: 0.007265
Validation Loss: 0.00910239
Epoch [135/300], Train Loss: 0.007269
Validation Loss: 0.00909214
Epoch [136/300], Train Loss: 0.007246
Validation Loss: 0.00906371
Epoch [137/300], Train Loss: 0.007226
Validation Loss: 0.00920329
Epoch [138/300], Train Loss: 0.007251
Validation Loss: 0.00908095
Epoch [139/300], Train Loss: 0.007198
Validation Loss: 0.00900481
Epoch [140/300], Train Loss: 0.007167
Validation Loss: 0.00903248
Epoch [141/300], Train Loss: 0.007151
Validation Loss: 0.00893395
Epoch [142/300], Train Loss: 0.007141
Validation Loss: 0.00894237
Epoch [143/300], Train Loss: 0.007085
Validation Loss: 0.00887737
Epoch [144/300], Train Loss: 0.007126
Validation Loss: 0.00891819
Epoch [145/300], Train Loss: 0.007079
Validation Loss: 0.00882777
Epoch [146/300], Train Loss: 0.007030
Validation Loss: 0.00891460
Epoch [147/300], Train Loss: 0.007036
Validation Loss: 0.00888203
Epoch [148/300], Train Loss: 0.007009
Validation Loss: 0.00872357
Epoch [149/300], Train Loss: 0.006989
Validation Loss: 0.00872799
Epoch [150/300], Train Loss: 0.006964
Validation Loss: 0.00868905
Epoch [151/300], Train Loss: 0.006953
Validation Loss: 0.00875562
Epoch [152/300], Train Loss: 0.006894
Validation Loss: 0.00871634
Epoch [153/300], Train Loss: 0.006942
Validation Loss: 0.00860363
Epoch [154/300], Train Loss: 0.006871
Validation Loss: 0.00854640
Epoch [155/300], Train Loss: 0.006836
Validation Loss: 0.00863047
Epoch [156/300], Train Loss: 0.006807
Validation Loss: 0.00850614
Epoch [157/300], Train Loss: 0.006784
Validation Loss: 0.00848924
Epoch [158/300], Train Loss: 0.006748
Validation Loss: 0.00844478
Epoch [159/300], Train Loss: 0.006715
Validation Loss: 0.00851356
Epoch [160/300], Train Loss: 0.006705
Validation Loss: 0.00842431
Epoch [161/300], Train Loss: 0.006690
Validation Loss: 0.00835002
Epoch [162/300], Train Loss: 0.006676
Validation Loss: 0.00838396
Epoch [163/300], Train Loss: 0.006682
Validation Loss: 0.00850413
Epoch [164/300], Train Loss: 0.006737
Validation Loss: 0.00833185
Epoch [165/300], Train Loss: 0.006683
Validation Loss: 0.00839345
Epoch [166/300], Train Loss: 0.006631
Validation Loss: 0.00836759
Epoch [167/300], Train Loss: 0.006643
Validation Loss: 0.00844047
Epoch [168/300], Train Loss: 0.006654
Validation Loss: 0.00842553
Epoch [169/300], Train Loss: 0.006678
Validation Loss: 0.00831684
Epoch [170/300], Train Loss: 0.006629
Validation Loss: 0.00828748
Epoch [171/300], Train Loss: 0.006652
Validation Loss: 0.00842951
Epoch [172/300], Train Loss: 0.006656
Validation Loss: 0.00840838
Epoch [173/300], Train Loss: 0.006636
Validation Loss: 0.00824117
Epoch [174/300], Train Loss: 0.006669
Validation Loss: 0.00829961
Epoch [175/300], Train Loss: 0.006596
Validation Loss: 0.00832560
Epoch [176/300], Train Loss: 0.006595
Validation Loss: 0.00845484
Epoch [177/300], Train Loss: 0.006629
Validation Loss: 0.00830369
Epoch [178/300], Train Loss: 0.006606
Validation Loss: 0.00824393
Epoch [179/300], Train Loss: 0.006616
Validation Loss: 0.00840118
Epoch [180/300], Train Loss: 0.006645
Validation Loss: 0.00826131
Epoch [181/300], Train Loss: 0.006626
Validation Loss: 0.00830506
Epoch [182/300], Train Loss: 0.006588
Validation Loss: 0.00824006
Epoch [183/300], Train Loss: 0.006577
Validation Loss: 0.00825568
Epoch [184/300], Train Loss: 0.006587
Validation Loss: 0.00829466
Epoch [185/300], Train Loss: 0.006614
Validation Loss: 0.00821588
Epoch [186/300], Train Loss: 0.006623
Validation Loss: 0.00845797
Epoch [187/300], Train Loss: 0.006590
Validation Loss: 0.00828487
Epoch [188/300], Train Loss: 0.006572
Validation Loss: 0.00824079
Epoch [189/300], Train Loss: 0.006579
Validation Loss: 0.00820906
Epoch [190/300], Train Loss: 0.006577
Validation Loss: 0.00827881
Epoch [191/300], Train Loss: 0.006576
Validation Loss: 0.00822190
Epoch [192/300], Train Loss: 0.006578
Validation Loss: 0.00832745
Epoch [193/300], Train Loss: 0.006573
Validation Loss: 0.00823346
Epoch [194/300], Train Loss: 0.006570
Validation Loss: 0.00820543
Epoch [195/300], Train Loss: 0.006567
Validation Loss: 0.00830430
Epoch [196/300], Train Loss: 0.006552
Validation Loss: 0.00820857
Epoch [197/300], Train Loss: 0.006598
Validation Loss: 0.00836475
Epoch [198/300], Train Loss: 0.006610
Validation Loss: 0.00824061
Epoch [199/300], Train Loss: 0.006563
Validation Loss: 0.00821679
Epoch [200/300], Train Loss: 0.006552
Validation Loss: 0.00823634
Epoch [201/300], Train Loss: 0.006560
Validation Loss: 0.00819776
Epoch [202/300], Train Loss: 0.006557
Validation Loss: 0.00821014
Epoch [203/300], Train Loss: 0.006544
Validation Loss: 0.00832000
Epoch [204/300], Train Loss: 0.006596
Validation Loss: 0.00822485
Epoch [205/300], Train Loss: 0.006545
Validation Loss: 0.00821723
Epoch [206/300], Train Loss: 0.006554
Validation Loss: 0.00826814
Epoch [207/300], Train Loss: 0.006575
Validation Loss: 0.00822899
Epoch [208/300], Train Loss: 0.006571
Validation Loss: 0.00822013
Epoch [209/300], Train Loss: 0.006560
Validation Loss: 0.00828443
Epoch [210/300], Train Loss: 0.006564
Validation Loss: 0.00822524
Epoch [211/300], Train Loss: 0.006565
Validation Loss: 0.00824903
Early stopping triggered

Evaluating model for: Tablet
Run 48/72 completed in 1655.24 seconds with: {'MAE': np.float32(0.6996248), 'MSE': np.float32(1.244564), 'RMSE': np.float32(1.1156003), 'SAE': np.float32(0.006980462), 'NDE': np.float32(0.25671443)}

Run 49/72: hidden=512, seq_len=120, stride=0.25, num_layers=2
Training and evaluating model for: Tablet
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.023457
Validation Loss: 0.01275834
Epoch [2/300], Train Loss: 0.011266
Validation Loss: 0.01046399
Epoch [3/300], Train Loss: 0.009748
Validation Loss: 0.00953696
Epoch [4/300], Train Loss: 0.009159
Validation Loss: 0.00903822
Epoch [5/300], Train Loss: 0.008708
Validation Loss: 0.00861847
Epoch [6/300], Train Loss: 0.008448
Validation Loss: 0.00831032
Epoch [7/300], Train Loss: 0.008144
Validation Loss: 0.00814752
Epoch [8/300], Train Loss: 0.007942
Validation Loss: 0.00798055
Epoch [9/300], Train Loss: 0.007712
Validation Loss: 0.00775109
Epoch [10/300], Train Loss: 0.007660
Validation Loss: 0.00754578
Epoch [11/300], Train Loss: 0.007558
Validation Loss: 0.00746129
Epoch [12/300], Train Loss: 0.007321
Validation Loss: 0.00737628
Epoch [13/300], Train Loss: 0.007289
Validation Loss: 0.00731268
Epoch [14/300], Train Loss: 0.007146
Validation Loss: 0.00715656
Epoch [15/300], Train Loss: 0.006964
Validation Loss: 0.00690233
Epoch [16/300], Train Loss: 0.006855
Validation Loss: 0.00681023
Epoch [17/300], Train Loss: 0.006528
Validation Loss: 0.00640290
Epoch [18/300], Train Loss: 0.006560
Validation Loss: 0.00604038
Epoch [19/300], Train Loss: 0.005514
Validation Loss: 0.00487654
Epoch [20/300], Train Loss: 0.004536
Validation Loss: 0.00399865
Epoch [21/300], Train Loss: 0.003846
Validation Loss: 0.00344407
Epoch [22/300], Train Loss: 0.003506
Validation Loss: 0.00325234
Epoch [23/300], Train Loss: 0.003466
Validation Loss: 0.00332529
Epoch [24/300], Train Loss: 0.003175
Validation Loss: 0.00303636
Epoch [25/300], Train Loss: 0.003196
Validation Loss: 0.00294084
Epoch [26/300], Train Loss: 0.002980
Validation Loss: 0.00279212
Epoch [27/300], Train Loss: 0.002909
Validation Loss: 0.00277120
Epoch [28/300], Train Loss: 0.002842
Validation Loss: 0.00263585
Epoch [29/300], Train Loss: 0.002645
Validation Loss: 0.00245939
Epoch [30/300], Train Loss: 0.002631
Validation Loss: 0.00253574
Epoch [31/300], Train Loss: 0.002522
Validation Loss: 0.00255352
Epoch [32/300], Train Loss: 0.002496
Validation Loss: 0.00238609
Epoch [33/300], Train Loss: 0.002489
Validation Loss: 0.00231250
Epoch [34/300], Train Loss: 0.002518
Validation Loss: 0.00260049
Epoch [35/300], Train Loss: 0.002469
Validation Loss: 0.00228278
Epoch [36/300], Train Loss: 0.002422
Validation Loss: 0.00234328
Epoch [37/300], Train Loss: 0.002426
Validation Loss: 0.00231099
Epoch [38/300], Train Loss: 0.002408
Validation Loss: 0.00228333
Epoch [39/300], Train Loss: 0.002443
Validation Loss: 0.00224544
Epoch [40/300], Train Loss: 0.002326
Validation Loss: 0.00233117
Epoch [41/300], Train Loss: 0.002346
Validation Loss: 0.00226354
Epoch [42/300], Train Loss: 0.002451
Validation Loss: 0.00234733
Epoch [43/300], Train Loss: 0.002348
Validation Loss: 0.00230393
Epoch [44/300], Train Loss: 0.002327
Validation Loss: 0.00233803
Epoch [45/300], Train Loss: 0.002312
Validation Loss: 0.00221672
Epoch [46/300], Train Loss: 0.002300
Validation Loss: 0.00231254
Epoch [47/300], Train Loss: 0.002356
Validation Loss: 0.00232491
Epoch [48/300], Train Loss: 0.002356
Validation Loss: 0.00220314
Epoch [49/300], Train Loss: 0.002304
Validation Loss: 0.00219194
Epoch [50/300], Train Loss: 0.002260
Validation Loss: 0.00225232
Epoch [51/300], Train Loss: 0.002249
Validation Loss: 0.00226978
Epoch [52/300], Train Loss: 0.002545
Validation Loss: 0.00221634
Epoch [53/300], Train Loss: 0.002276
Validation Loss: 0.00229456
Epoch [54/300], Train Loss: 0.002264
Validation Loss: 0.00223818
Epoch [55/300], Train Loss: 0.002292
Validation Loss: 0.00218051
Epoch [56/300], Train Loss: 0.002238
Validation Loss: 0.00217817
Epoch [57/300], Train Loss: 0.002239
Validation Loss: 0.00218485
Epoch [58/300], Train Loss: 0.002234
Validation Loss: 0.00216966
Epoch [59/300], Train Loss: 0.002241
Validation Loss: 0.00220304
Epoch [60/300], Train Loss: 0.002244
Validation Loss: 0.00218101
Epoch [61/300], Train Loss: 0.002220
Validation Loss: 0.00216037
Epoch [62/300], Train Loss: 0.002227
Validation Loss: 0.00222171
Epoch [63/300], Train Loss: 0.002330
Validation Loss: 0.00230114
Epoch [64/300], Train Loss: 0.002206
Validation Loss: 0.00214078
Epoch [65/300], Train Loss: 0.002223
Validation Loss: 0.00221960
Epoch [66/300], Train Loss: 0.002222
Validation Loss: 0.00219640
Epoch [67/300], Train Loss: 0.002201
Validation Loss: 0.00216010
Epoch [68/300], Train Loss: 0.002354
Validation Loss: 0.00224199
Epoch [69/300], Train Loss: 0.002210
Validation Loss: 0.00215942
Epoch [70/300], Train Loss: 0.002187
Validation Loss: 0.00214986
Epoch [71/300], Train Loss: 0.002265
Validation Loss: 0.00222769
Epoch [72/300], Train Loss: 0.002197
Validation Loss: 0.00214984
Epoch [73/300], Train Loss: 0.002189
Validation Loss: 0.00214271
Epoch [74/300], Train Loss: 0.002176
Validation Loss: 0.00217504
Early stopping triggered

Evaluating model for: Tablet
Run 49/72 completed in 2188.75 seconds with: {'MAE': np.float32(0.3768657), 'MSE': np.float32(0.35088223), 'RMSE': np.float32(0.5923531), 'SAE': np.float32(0.016925635), 'NDE': np.float32(0.13595092)}

Run 50/72: hidden=512, seq_len=120, stride=0.25, num_layers=3
Training and evaluating model for: Tablet
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.023029
Validation Loss: 0.01403164
Epoch [2/300], Train Loss: 0.011644
Validation Loss: 0.01051394
Epoch [3/300], Train Loss: 0.009815
Validation Loss: 0.00959083
Epoch [4/300], Train Loss: 0.009074
Validation Loss: 0.00882083
Epoch [5/300], Train Loss: 0.008591
Validation Loss: 0.00851463
Epoch [6/300], Train Loss: 0.008235
Validation Loss: 0.00819356
Epoch [7/300], Train Loss: 0.007944
Validation Loss: 0.00787667
Epoch [8/300], Train Loss: 0.007834
Validation Loss: 0.00781048
Epoch [9/300], Train Loss: 0.007521
Validation Loss: 0.00755949
Epoch [10/300], Train Loss: 0.007324
Validation Loss: 0.00744413
Epoch [11/300], Train Loss: 0.007151
Validation Loss: 0.00721743
Epoch [12/300], Train Loss: 0.007141
Validation Loss: 0.00722999
Epoch [13/300], Train Loss: 0.006988
Validation Loss: 0.00718302
Epoch [14/300], Train Loss: 0.006926
Validation Loss: 0.00701141
Epoch [15/300], Train Loss: 0.008267
Validation Loss: 0.01294073
Epoch [16/300], Train Loss: 0.007459
Validation Loss: 0.00566365
Epoch [17/300], Train Loss: 0.005162
Validation Loss: 0.00422560
Epoch [18/300], Train Loss: 0.005659
Validation Loss: 0.01158936
Epoch [19/300], Train Loss: 0.006272
Validation Loss: 0.00407748
Epoch [20/300], Train Loss: 0.004157
Validation Loss: 0.00370994
Epoch [21/300], Train Loss: 0.003831
Validation Loss: 0.00337405
Epoch [22/300], Train Loss: 0.003553
Validation Loss: 0.00328570
Epoch [23/300], Train Loss: 0.003447
Validation Loss: 0.00338692
Epoch [24/300], Train Loss: 0.003224
Validation Loss: 0.00290418
Epoch [25/300], Train Loss: 0.003057
Validation Loss: 0.00270021
Epoch [26/300], Train Loss: 0.002897
Validation Loss: 0.00262288
Epoch [27/300], Train Loss: 0.002987
Validation Loss: 0.00275108
Epoch [28/300], Train Loss: 0.002708
Validation Loss: 0.00258872
Epoch [29/300], Train Loss: 0.002678
Validation Loss: 0.00256294
Epoch [30/300], Train Loss: 0.002619
Validation Loss: 0.00246797
Epoch [31/300], Train Loss: 0.002571
Validation Loss: 0.00272201
Epoch [32/300], Train Loss: 0.002608
Validation Loss: 0.00278823
Epoch [33/300], Train Loss: 0.002618
Validation Loss: 0.00238976
Epoch [34/300], Train Loss: 0.002525
Validation Loss: 0.00237455
Epoch [35/300], Train Loss: 0.002659
Validation Loss: 0.00240810
Epoch [36/300], Train Loss: 0.002581
Validation Loss: 0.00246442
Epoch [37/300], Train Loss: 0.002512
Validation Loss: 0.00246540
Epoch [38/300], Train Loss: 0.002500
Validation Loss: 0.00237807
Epoch [39/300], Train Loss: 0.002423
Validation Loss: 0.00231065
Epoch [40/300], Train Loss: 0.002586
Validation Loss: 0.00238599
Epoch [41/300], Train Loss: 0.002379
Validation Loss: 0.00234238
Epoch [42/300], Train Loss: 0.002446
Validation Loss: 0.00242939
Epoch [43/300], Train Loss: 0.002361
Validation Loss: 0.00234810
Epoch [44/300], Train Loss: 0.002368
Validation Loss: 0.00238219
Epoch [45/300], Train Loss: 0.004143
Validation Loss: 0.00250677
Epoch [46/300], Train Loss: 0.003733
Validation Loss: 0.00318353
Epoch [47/300], Train Loss: 0.002525
Validation Loss: 0.00236306
Epoch [48/300], Train Loss: 0.002836
Validation Loss: 0.00304175
Epoch [49/300], Train Loss: 0.002981
Validation Loss: 0.00265648
Early stopping triggered

Evaluating model for: Tablet
Run 50/72 completed in 1607.64 seconds with: {'MAE': np.float32(0.4791224), 'MSE': np.float32(0.43712324), 'RMSE': np.float32(0.66115296), 'SAE': np.float32(0.031839155), 'NDE': np.float32(0.15174116)}

Run 51/72: hidden=512, seq_len=120, stride=0.25, num_layers=4
Training and evaluating model for: Tablet
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.023755
Validation Loss: 0.01217699
Epoch [2/300], Train Loss: 0.011144
Validation Loss: 0.01031438
Epoch [3/300], Train Loss: 0.009614
Validation Loss: 0.00909737
Epoch [4/300], Train Loss: 0.008843
Validation Loss: 0.00877056
Epoch [5/300], Train Loss: 0.008411
Validation Loss: 0.00824092
Epoch [6/300], Train Loss: 0.008135
Validation Loss: 0.00799620
Epoch [7/300], Train Loss: 0.007762
Validation Loss: 0.00761260
Epoch [8/300], Train Loss: 0.007611
Validation Loss: 0.00769305
Epoch [9/300], Train Loss: 0.007317
Validation Loss: 0.00747105
Epoch [10/300], Train Loss: 0.007220
Validation Loss: 0.00724287
Epoch [11/300], Train Loss: 0.007104
Validation Loss: 0.00713175
Epoch [12/300], Train Loss: 0.007042
Validation Loss: 0.00737629
Epoch [13/300], Train Loss: 0.006939
Validation Loss: 0.00720450
Epoch [14/300], Train Loss: 0.006897
Validation Loss: 0.00702616
Epoch [15/300], Train Loss: 0.006877
Validation Loss: 0.00691695
Epoch [16/300], Train Loss: 0.006855
Validation Loss: 0.00689525
Epoch [17/300], Train Loss: 0.006699
Validation Loss: 0.00684012
Epoch [18/300], Train Loss: 0.006732
Validation Loss: 0.00727990
Epoch [19/300], Train Loss: 0.006863
Validation Loss: 0.00681583
Epoch [20/300], Train Loss: 0.006509
Validation Loss: 0.00651658
Epoch [21/300], Train Loss: 0.006135
Validation Loss: 0.00546944
Epoch [22/300], Train Loss: 0.004421
Validation Loss: 0.00375207
Epoch [23/300], Train Loss: 0.003507
Validation Loss: 0.00304738
Epoch [24/300], Train Loss: 0.002892
Validation Loss: 0.00263879
Epoch [25/300], Train Loss: 0.002682
Validation Loss: 0.00250025
Epoch [26/300], Train Loss: 0.002548
Validation Loss: 0.00246307
Epoch [27/300], Train Loss: 0.002528
Validation Loss: 0.00237985
Epoch [28/300], Train Loss: 0.002550
Validation Loss: 0.00236703
Epoch [29/300], Train Loss: 0.002628
Validation Loss: 0.00624236
Epoch [30/300], Train Loss: 0.003354
Validation Loss: 0.00242788
Epoch [31/300], Train Loss: 0.002506
Validation Loss: 0.00239836
Epoch [32/300], Train Loss: 0.002948
Validation Loss: 0.00271295
Epoch [33/300], Train Loss: 0.002519
Validation Loss: 0.00232651
Epoch [34/300], Train Loss: 0.003273
Validation Loss: 0.00381820
Epoch [35/300], Train Loss: 0.002810
Validation Loss: 0.00238332
Epoch [36/300], Train Loss: 0.002418
Validation Loss: 0.00235176
Epoch [37/300], Train Loss: 0.002374
Validation Loss: 0.00233627
Epoch [38/300], Train Loss: 0.002349
Validation Loss: 0.00231962
Epoch [39/300], Train Loss: 0.002334
Validation Loss: 0.00230033
Epoch [40/300], Train Loss: 0.002348
Validation Loss: 0.00225826
Epoch [41/300], Train Loss: 0.002314
Validation Loss: 0.00227584
Epoch [42/300], Train Loss: 0.002383
Validation Loss: 0.00227475
Epoch [43/300], Train Loss: 0.002298
Validation Loss: 0.00227041
Epoch [44/300], Train Loss: 0.002326
Validation Loss: 0.00225167
Epoch [45/300], Train Loss: 0.002306
Validation Loss: 0.00225576
Epoch [46/300], Train Loss: 0.002268
Validation Loss: 0.00244723
Epoch [47/300], Train Loss: 0.002295
Validation Loss: 0.00225004
Epoch [48/300], Train Loss: 0.002352
Validation Loss: 0.00279734
Epoch [49/300], Train Loss: 0.002482
Validation Loss: 0.00259346
Epoch [50/300], Train Loss: 0.002282
Validation Loss: 0.00223776
Epoch [51/300], Train Loss: 0.002281
Validation Loss: 0.00221756
Epoch [52/300], Train Loss: 0.002251
Validation Loss: 0.00220349
Epoch [53/300], Train Loss: 0.002245
Validation Loss: 0.00223037
Epoch [54/300], Train Loss: 0.002234
Validation Loss: 0.00225306
Epoch [55/300], Train Loss: 0.002524
Validation Loss: 0.00226889
Epoch [56/300], Train Loss: 0.002255
Validation Loss: 0.00225210
Epoch [57/300], Train Loss: 0.002240
Validation Loss: 0.00221845
Epoch [58/300], Train Loss: 0.002233
Validation Loss: 0.00221427
Epoch [59/300], Train Loss: 0.002263
Validation Loss: 0.00221357
Epoch [60/300], Train Loss: 0.002243
Validation Loss: 0.00223785
Epoch [61/300], Train Loss: 0.002220
Validation Loss: 0.00222609
Epoch [62/300], Train Loss: 0.002201
Validation Loss: 0.00235712
Early stopping triggered

Evaluating model for: Tablet
Run 51/72 completed in 2289.40 seconds with: {'MAE': np.float32(0.39004886), 'MSE': np.float32(0.3643912), 'RMSE': np.float32(0.60364825), 'SAE': np.float32(0.0098986), 'NDE': np.float32(0.13854326)}

Run 52/72: hidden=512, seq_len=120, stride=0.25, num_layers=5
Training and evaluating model for: Tablet
Dataset length: 25227 windows

Epoch [1/300], Train Loss: 0.022256
Validation Loss: 0.01192687
Epoch [2/300], Train Loss: 0.010696
Validation Loss: 0.01013160
Epoch [3/300], Train Loss: 0.009686
Validation Loss: 0.00956617
Epoch [4/300], Train Loss: 0.009283
Validation Loss: 0.00921296
Epoch [5/300], Train Loss: 0.008877
Validation Loss: 0.00897004
Epoch [6/300], Train Loss: 0.008668
Validation Loss: 0.00868500
Epoch [7/300], Train Loss: 0.008259
Validation Loss: 0.00835477
Epoch [8/300], Train Loss: 0.007978
Validation Loss: 0.00778263
Epoch [9/300], Train Loss: 0.007280
Validation Loss: 0.00725750
Epoch [10/300], Train Loss: 0.007058
Validation Loss: 0.00688980
Epoch [11/300], Train Loss: 0.006081
Validation Loss: 0.00614048
Epoch [12/300], Train Loss: 0.005312
Validation Loss: 0.00363322
Epoch [13/300], Train Loss: 0.003350
Validation Loss: 0.00324960
Epoch [14/300], Train Loss: 0.002962
Validation Loss: 0.00263135
Epoch [15/300], Train Loss: 0.002766
Validation Loss: 0.00242609
Epoch [16/300], Train Loss: 0.002566
Validation Loss: 0.00229104
Epoch [17/300], Train Loss: 0.002953
Validation Loss: 0.00337870
Epoch [18/300], Train Loss: 0.002678
Validation Loss: 0.00235789
Epoch [19/300], Train Loss: 0.002381
Validation Loss: 0.00223654
Epoch [20/300], Train Loss: 0.002377
Validation Loss: 0.00221230
Epoch [21/300], Train Loss: 0.002287
Validation Loss: 0.00222274
Epoch [22/300], Train Loss: 0.002420
Validation Loss: 0.00220917
Epoch [23/300], Train Loss: 0.002417
Validation Loss: 0.00250515
Epoch [24/300], Train Loss: 0.002611
Validation Loss: 0.00236391
Epoch [25/300], Train Loss: 0.002278
Validation Loss: 0.00218690
Epoch [26/300], Train Loss: 0.002366
Validation Loss: 0.00238530
Epoch [27/300], Train Loss: 0.002233
Validation Loss: 0.00221499
Epoch [28/300], Train Loss: 0.002459
Validation Loss: 0.00220431
Epoch [29/300], Train Loss: 0.002203
Validation Loss: 0.00216780
Epoch [30/300], Train Loss: 0.002327
Validation Loss: 0.00221990
Epoch [31/300], Train Loss: 0.002190
Validation Loss: 0.00244065
Epoch [32/300], Train Loss: 0.002190
Validation Loss: 0.00216459
Epoch [33/300], Train Loss: 0.002240
Validation Loss: 0.00222108
Epoch [34/300], Train Loss: 0.002176
Validation Loss: 0.00215211
Epoch [35/300], Train Loss: 0.002200
Validation Loss: 0.00215418
Epoch [36/300], Train Loss: 0.002218
Validation Loss: 0.00218296
Epoch [37/300], Train Loss: 0.002157
Validation Loss: 0.00216111
Epoch [38/300], Train Loss: 0.002170
Validation Loss: 0.00224422
Epoch [39/300], Train Loss: 0.002174
Validation Loss: 0.00211999
Epoch [40/300], Train Loss: 0.002313
Validation Loss: 0.00226145
Epoch [41/300], Train Loss: 0.002237
Validation Loss: 0.00217659
Epoch [42/300], Train Loss: 0.002280
Validation Loss: 0.00216496
Epoch [43/300], Train Loss: 0.002207
Validation Loss: 0.00216353
Epoch [44/300], Train Loss: 0.002159
Validation Loss: 0.00222186
Epoch [45/300], Train Loss: 0.002153
Validation Loss: 0.00214471
Epoch [46/300], Train Loss: 0.002196
Validation Loss: 0.00212190
Epoch [47/300], Train Loss: 0.002188
Validation Loss: 0.00220651
Epoch [48/300], Train Loss: 0.002150
Validation Loss: 0.00213592
Epoch [49/300], Train Loss: 0.002152
Validation Loss: 0.00216444
Early stopping triggered

Evaluating model for: Tablet
Run 52/72 completed in 2088.09 seconds with: {'MAE': np.float32(0.40879428), 'MSE': np.float32(0.34707627), 'RMSE': np.float32(0.5891318), 'SAE': np.float32(0.015676925), 'NDE': np.float32(0.13521159)}

Run 53/72: hidden=512, seq_len=120, stride=0.5, num_layers=2
Training and evaluating model for: Tablet
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.031240
Validation Loss: 0.01551845
Epoch [2/300], Train Loss: 0.013585
Validation Loss: 0.01127288
Epoch [3/300], Train Loss: 0.011244
Validation Loss: 0.01020388
Epoch [4/300], Train Loss: 0.010370
Validation Loss: 0.00913331
Epoch [5/300], Train Loss: 0.009718
Validation Loss: 0.00863839
Epoch [6/300], Train Loss: 0.009368
Validation Loss: 0.00903266
Epoch [7/300], Train Loss: 0.009186
Validation Loss: 0.00839258
Epoch [8/300], Train Loss: 0.008929
Validation Loss: 0.00790002
Epoch [9/300], Train Loss: 0.008737
Validation Loss: 0.00785563
Epoch [10/300], Train Loss: 0.008577
Validation Loss: 0.00759578
Epoch [11/300], Train Loss: 0.008422
Validation Loss: 0.00754748
Epoch [12/300], Train Loss: 0.008341
Validation Loss: 0.00760556
Epoch [13/300], Train Loss: 0.008224
Validation Loss: 0.00720451
Epoch [14/300], Train Loss: 0.008013
Validation Loss: 0.00703277
Epoch [15/300], Train Loss: 0.007875
Validation Loss: 0.00745121
Epoch [16/300], Train Loss: 0.007734
Validation Loss: 0.00681452
Epoch [17/300], Train Loss: 0.007599
Validation Loss: 0.00674610
Epoch [18/300], Train Loss: 0.007588
Validation Loss: 0.00674530
Epoch [19/300], Train Loss: 0.007498
Validation Loss: 0.00666976
Epoch [20/300], Train Loss: 0.007550
Validation Loss: 0.00666852
Epoch [21/300], Train Loss: 0.007387
Validation Loss: 0.00656857
Epoch [22/300], Train Loss: 0.007408
Validation Loss: 0.00675394
Epoch [23/300], Train Loss: 0.007370
Validation Loss: 0.00654540
Epoch [24/300], Train Loss: 0.007258
Validation Loss: 0.00665873
Epoch [25/300], Train Loss: 0.007220
Validation Loss: 0.00642766
Epoch [26/300], Train Loss: 0.007184
Validation Loss: 0.00638682
Epoch [27/300], Train Loss: 0.007153
Validation Loss: 0.00639023
Epoch [28/300], Train Loss: 0.007098
Validation Loss: 0.00632513
Epoch [29/300], Train Loss: 0.007076
Validation Loss: 0.00632843
Epoch [30/300], Train Loss: 0.006967
Validation Loss: 0.00623620
Epoch [31/300], Train Loss: 0.006957
Validation Loss: 0.00618983
Epoch [32/300], Train Loss: 0.006880
Validation Loss: 0.00647742
Epoch [33/300], Train Loss: 0.006857
Validation Loss: 0.00674103
Epoch [34/300], Train Loss: 0.006763
Validation Loss: 0.00616276
Epoch [35/300], Train Loss: 0.006719
Validation Loss: 0.00594451
Epoch [36/300], Train Loss: 0.006675
Validation Loss: 0.00597114
Epoch [37/300], Train Loss: 0.006476
Validation Loss: 0.00568882
Epoch [38/300], Train Loss: 0.006242
Validation Loss: 0.00535161
Epoch [39/300], Train Loss: 0.005718
Validation Loss: 0.00467749
Epoch [40/300], Train Loss: 0.004734
Validation Loss: 0.00380036
Epoch [41/300], Train Loss: 0.003946
Validation Loss: 0.00334824
Epoch [42/300], Train Loss: 0.003597
Validation Loss: 0.00308320
Epoch [43/300], Train Loss: 0.003288
Validation Loss: 0.00304479
Epoch [44/300], Train Loss: 0.003273
Validation Loss: 0.00278476
Epoch [45/300], Train Loss: 0.003151
Validation Loss: 0.00276005
Epoch [46/300], Train Loss: 0.003132
Validation Loss: 0.00271489
Epoch [47/300], Train Loss: 0.003010
Validation Loss: 0.00274225
Epoch [48/300], Train Loss: 0.003017
Validation Loss: 0.00296681
Epoch [49/300], Train Loss: 0.002983
Validation Loss: 0.00279964
Epoch [50/300], Train Loss: 0.002946
Validation Loss: 0.00269125
Epoch [51/300], Train Loss: 0.002976
Validation Loss: 0.00313114
Epoch [52/300], Train Loss: 0.002981
Validation Loss: 0.00259398
Epoch [53/300], Train Loss: 0.002868
Validation Loss: 0.00282042
Epoch [54/300], Train Loss: 0.002863
Validation Loss: 0.00250035
Epoch [55/300], Train Loss: 0.002831
Validation Loss: 0.00250709
Epoch [56/300], Train Loss: 0.002812
Validation Loss: 0.00251056
Epoch [57/300], Train Loss: 0.002827
Validation Loss: 0.00260059
Epoch [58/300], Train Loss: 0.002792
Validation Loss: 0.00251476
Epoch [59/300], Train Loss: 0.002810
Validation Loss: 0.00248647
Epoch [60/300], Train Loss: 0.002784
Validation Loss: 0.00253865
Epoch [61/300], Train Loss: 0.002740
Validation Loss: 0.00250343
Epoch [62/300], Train Loss: 0.002765
Validation Loss: 0.00252881
Epoch [63/300], Train Loss: 0.002737
Validation Loss: 0.00243244
Epoch [64/300], Train Loss: 0.002749
Validation Loss: 0.00250197
Epoch [65/300], Train Loss: 0.002692
Validation Loss: 0.00236959
Epoch [66/300], Train Loss: 0.002695
Validation Loss: 0.00236915
Epoch [67/300], Train Loss: 0.002629
Validation Loss: 0.00253224
Epoch [68/300], Train Loss: 0.002557
Validation Loss: 0.00225959
Epoch [69/300], Train Loss: 0.002509
Validation Loss: 0.00231779
Epoch [70/300], Train Loss: 0.002491
Validation Loss: 0.00226508
Epoch [71/300], Train Loss: 0.002477
Validation Loss: 0.00220772
Epoch [72/300], Train Loss: 0.002551
Validation Loss: 0.00228528
Epoch [73/300], Train Loss: 0.002464
Validation Loss: 0.00229403
Epoch [74/300], Train Loss: 0.002452
Validation Loss: 0.00219109
Epoch [75/300], Train Loss: 0.002406
Validation Loss: 0.00217031
Epoch [76/300], Train Loss: 0.002387
Validation Loss: 0.00223377
Epoch [77/300], Train Loss: 0.002435
Validation Loss: 0.00220379
Epoch [78/300], Train Loss: 0.002376
Validation Loss: 0.00216911
Epoch [79/300], Train Loss: 0.002373
Validation Loss: 0.00219044
Epoch [80/300], Train Loss: 0.002417
Validation Loss: 0.00216062
Epoch [81/300], Train Loss: 0.002376
Validation Loss: 0.00215881
Epoch [82/300], Train Loss: 0.002374
Validation Loss: 0.00218155
Epoch [83/300], Train Loss: 0.002360
Validation Loss: 0.00222712
Epoch [84/300], Train Loss: 0.002393
Validation Loss: 0.00214975
Epoch [85/300], Train Loss: 0.002343
Validation Loss: 0.00213827
Epoch [86/300], Train Loss: 0.002334
Validation Loss: 0.00215351
Epoch [87/300], Train Loss: 0.002375
Validation Loss: 0.00218904
Epoch [88/300], Train Loss: 0.002351
Validation Loss: 0.00218655
Epoch [89/300], Train Loss: 0.002329
Validation Loss: 0.00215697
Epoch [90/300], Train Loss: 0.002335
Validation Loss: 0.00220900
Epoch [91/300], Train Loss: 0.002422
Validation Loss: 0.00219885
Epoch [92/300], Train Loss: 0.002357
Validation Loss: 0.00216947
Epoch [93/300], Train Loss: 0.002330
Validation Loss: 0.00212402
Epoch [94/300], Train Loss: 0.002329
Validation Loss: 0.00214600
Epoch [95/300], Train Loss: 0.002316
Validation Loss: 0.00213651
Epoch [96/300], Train Loss: 0.002379
Validation Loss: 0.00312473
Epoch [97/300], Train Loss: 0.002609
Validation Loss: 0.00220199
Epoch [98/300], Train Loss: 0.002370
Validation Loss: 0.00217963
Epoch [99/300], Train Loss: 0.002340
Validation Loss: 0.00214565
Epoch [100/300], Train Loss: 0.002329
Validation Loss: 0.00210047
Epoch [101/300], Train Loss: 0.002304
Validation Loss: 0.00210994
Epoch [102/300], Train Loss: 0.002310
Validation Loss: 0.00218116
Epoch [103/300], Train Loss: 0.002334
Validation Loss: 0.00225395
Epoch [104/300], Train Loss: 0.002347
Validation Loss: 0.00213297
Epoch [105/300], Train Loss: 0.002292
Validation Loss: 0.00209746
Epoch [106/300], Train Loss: 0.002267
Validation Loss: 0.00212058
Epoch [107/300], Train Loss: 0.002284
Validation Loss: 0.00211952
Epoch [108/300], Train Loss: 0.002296
Validation Loss: 0.00210835
Epoch [109/300], Train Loss: 0.002315
Validation Loss: 0.00210735
Epoch [110/300], Train Loss: 0.002298
Validation Loss: 0.00217365
Epoch [111/300], Train Loss: 0.002288
Validation Loss: 0.00211167
Epoch [112/300], Train Loss: 0.002314
Validation Loss: 0.00223269
Epoch [113/300], Train Loss: 0.002322
Validation Loss: 0.00210625
Epoch [114/300], Train Loss: 0.002262
Validation Loss: 0.00210967
Epoch [115/300], Train Loss: 0.002271
Validation Loss: 0.00209657
Epoch [116/300], Train Loss: 0.002291
Validation Loss: 0.00208838
Epoch [117/300], Train Loss: 0.002250
Validation Loss: 0.00212850
Epoch [118/300], Train Loss: 0.002287
Validation Loss: 0.00210036
Epoch [119/300], Train Loss: 0.002267
Validation Loss: 0.00210500
Epoch [120/300], Train Loss: 0.002291
Validation Loss: 0.00211886
Epoch [121/300], Train Loss: 0.002356
Validation Loss: 0.00212370
Epoch [122/300], Train Loss: 0.002267
Validation Loss: 0.00209676
Epoch [123/300], Train Loss: 0.002247
Validation Loss: 0.00208592
Epoch [124/300], Train Loss: 0.002234
Validation Loss: 0.00210739
Epoch [125/300], Train Loss: 0.002248
Validation Loss: 0.00210278
Epoch [126/300], Train Loss: 0.002288
Validation Loss: 0.00210043
Epoch [127/300], Train Loss: 0.002251
Validation Loss: 0.00209890
Epoch [128/300], Train Loss: 0.002245
Validation Loss: 0.00228820
Epoch [129/300], Train Loss: 0.002315
Validation Loss: 0.00211354
Epoch [130/300], Train Loss: 0.002232
Validation Loss: 0.00214657
Epoch [131/300], Train Loss: 0.002297
Validation Loss: 0.00209824
Epoch [132/300], Train Loss: 0.002226
Validation Loss: 0.00209742
Epoch [133/300], Train Loss: 0.002248
Validation Loss: 0.00210973
Early stopping triggered

Evaluating model for: Tablet
Run 53/72 completed in 2021.08 seconds with: {'MAE': np.float32(0.40568674), 'MSE': np.float32(0.35583782), 'RMSE': np.float32(0.59652144), 'SAE': np.float32(0.0020350625), 'NDE': np.float32(0.1370843)}

Run 54/72: hidden=512, seq_len=120, stride=0.5, num_layers=3
Training and evaluating model for: Tablet
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.032106
Validation Loss: 0.01659446
Epoch [2/300], Train Loss: 0.016648
Validation Loss: 0.01497673
Epoch [3/300], Train Loss: 0.013190
Validation Loss: 0.01098714
Epoch [4/300], Train Loss: 0.010905
Validation Loss: 0.00962957
Epoch [5/300], Train Loss: 0.009967
Validation Loss: 0.00951097
Epoch [6/300], Train Loss: 0.009460
Validation Loss: 0.00825004
Epoch [7/300], Train Loss: 0.009104
Validation Loss: 0.00805999
Epoch [8/300], Train Loss: 0.008866
Validation Loss: 0.00780328
Epoch [9/300], Train Loss: 0.008680
Validation Loss: 0.00762504
Epoch [10/300], Train Loss: 0.008486
Validation Loss: 0.00748575
Epoch [11/300], Train Loss: 0.008290
Validation Loss: 0.00741524
Epoch [12/300], Train Loss: 0.008298
Validation Loss: 0.00734186
Epoch [13/300], Train Loss: 0.008088
Validation Loss: 0.00709601
Epoch [14/300], Train Loss: 0.007886
Validation Loss: 0.00696706
Epoch [15/300], Train Loss: 0.007943
Validation Loss: 0.00712401
Epoch [16/300], Train Loss: 0.007660
Validation Loss: 0.00671598
Epoch [17/300], Train Loss: 0.007526
Validation Loss: 0.00666690
Epoch [18/300], Train Loss: 0.007361
Validation Loss: 0.00654467
Epoch [19/300], Train Loss: 0.007291
Validation Loss: 0.00644064
Epoch [20/300], Train Loss: 0.007367
Validation Loss: 0.00657184
Epoch [21/300], Train Loss: 0.007077
Validation Loss: 0.00625122
Epoch [22/300], Train Loss: 0.007048
Validation Loss: 0.00628416
Epoch [23/300], Train Loss: 0.006741
Validation Loss: 0.00586627
Epoch [24/300], Train Loss: 0.006460
Validation Loss: 0.00543690
Epoch [25/300], Train Loss: 0.005861
Validation Loss: 0.00477904
Epoch [26/300], Train Loss: 0.005181
Validation Loss: 0.00417279
Epoch [27/300], Train Loss: 0.004664
Validation Loss: 0.00374331
Epoch [28/300], Train Loss: 0.004263
Validation Loss: 0.00369225
Epoch [29/300], Train Loss: 0.004041
Validation Loss: 0.00357639
Epoch [30/300], Train Loss: 0.003805
Validation Loss: 0.00312194
Epoch [31/300], Train Loss: 0.003588
Validation Loss: 0.00304381
Epoch [32/300], Train Loss: 0.003399
Validation Loss: 0.00303531
Epoch [33/300], Train Loss: 0.003286
Validation Loss: 0.00278403
Epoch [34/300], Train Loss: 0.003210
Validation Loss: 0.00279999
Epoch [35/300], Train Loss: 0.003034
Validation Loss: 0.00261191
Epoch [36/300], Train Loss: 0.002987
Validation Loss: 0.00260086
Epoch [37/300], Train Loss: 0.003004
Validation Loss: 0.00242762
Epoch [38/300], Train Loss: 0.002757
Validation Loss: 0.00240581
Epoch [39/300], Train Loss: 0.002795
Validation Loss: 0.00235452
Epoch [40/300], Train Loss: 0.002682
Validation Loss: 0.00253461
Epoch [41/300], Train Loss: 0.003646
Validation Loss: 0.00292695
Epoch [42/300], Train Loss: 0.002951
Validation Loss: 0.00255179
Epoch [43/300], Train Loss: 0.002828
Validation Loss: 0.00235665
Epoch [44/300], Train Loss: 0.002633
Validation Loss: 0.00231944
Epoch [45/300], Train Loss: 0.002635
Validation Loss: 0.00227411
Epoch [46/300], Train Loss: 0.002577
Validation Loss: 0.00243713
Epoch [47/300], Train Loss: 0.002513
Validation Loss: 0.00219463
Epoch [48/300], Train Loss: 0.002522
Validation Loss: 0.00219727
Epoch [49/300], Train Loss: 0.002458
Validation Loss: 0.00224612
Epoch [50/300], Train Loss: 0.002554
Validation Loss: 0.00231302
Epoch [51/300], Train Loss: 0.002527
Validation Loss: 0.00219814
Epoch [52/300], Train Loss: 0.002481
Validation Loss: 0.00226153
Epoch [53/300], Train Loss: 0.002460
Validation Loss: 0.00222904
Epoch [54/300], Train Loss: 0.002450
Validation Loss: 0.00227437
Epoch [55/300], Train Loss: 0.002480
Validation Loss: 0.00214009
Epoch [56/300], Train Loss: 0.002482
Validation Loss: 0.00215598
Epoch [57/300], Train Loss: 0.002365
Validation Loss: 0.00212915
Epoch [58/300], Train Loss: 0.002457
Validation Loss: 0.00215876
Epoch [59/300], Train Loss: 0.002374
Validation Loss: 0.00213610
Epoch [60/300], Train Loss: 0.002379
Validation Loss: 0.00212570
Epoch [61/300], Train Loss: 0.002346
Validation Loss: 0.00211585
Epoch [62/300], Train Loss: 0.002345
Validation Loss: 0.00210010
Epoch [63/300], Train Loss: 0.002354
Validation Loss: 0.00209176
Epoch [64/300], Train Loss: 0.002595
Validation Loss: 0.00211913
Epoch [65/300], Train Loss: 0.002369
Validation Loss: 0.00211184
Epoch [66/300], Train Loss: 0.002333
Validation Loss: 0.00210842
Epoch [67/300], Train Loss: 0.002319
Validation Loss: 0.00271521
Epoch [68/300], Train Loss: 0.002411
Validation Loss: 0.00215031
Epoch [69/300], Train Loss: 0.002326
Validation Loss: 0.00207880
Epoch [70/300], Train Loss: 0.002327
Validation Loss: 0.00209353
Epoch [71/300], Train Loss: 0.002309
Validation Loss: 0.00208372
Epoch [72/300], Train Loss: 0.002359
Validation Loss: 0.00231218
Epoch [73/300], Train Loss: 0.002646
Validation Loss: 0.00210164
Epoch [74/300], Train Loss: 0.002304
Validation Loss: 0.00207884
Epoch [75/300], Train Loss: 0.002281
Validation Loss: 0.00208593
Epoch [76/300], Train Loss: 0.002276
Validation Loss: 0.00210783
Epoch [77/300], Train Loss: 0.002306
Validation Loss: 0.00218644
Epoch [78/300], Train Loss: 0.002277
Validation Loss: 0.00205435
Epoch [79/300], Train Loss: 0.002294
Validation Loss: 0.00206735
Epoch [80/300], Train Loss: 0.002277
Validation Loss: 0.00208923
Epoch [81/300], Train Loss: 0.002255
Validation Loss: 0.00210815
Epoch [82/300], Train Loss: 0.002263
Validation Loss: 0.00205567
Epoch [83/300], Train Loss: 0.002295
Validation Loss: 0.00205054
Epoch [84/300], Train Loss: 0.002335
Validation Loss: 0.00208734
Epoch [85/300], Train Loss: 0.002268
Validation Loss: 0.00205435
Epoch [86/300], Train Loss: 0.002265
Validation Loss: 0.00206111
Epoch [87/300], Train Loss: 0.002253
Validation Loss: 0.00207976
Epoch [88/300], Train Loss: 0.002230
Validation Loss: 0.00203776
Epoch [89/300], Train Loss: 0.002238
Validation Loss: 0.00206268
Epoch [90/300], Train Loss: 0.002255
Validation Loss: 0.00207158
Epoch [91/300], Train Loss: 0.002341
Validation Loss: 0.00205975
Epoch [92/300], Train Loss: 0.002238
Validation Loss: 0.00204253
Epoch [93/300], Train Loss: 0.002269
Validation Loss: 0.00204632
Epoch [94/300], Train Loss: 0.002306
Validation Loss: 0.00209461
Epoch [95/300], Train Loss: 0.002266
Validation Loss: 0.00207178
Epoch [96/300], Train Loss: 0.002275
Validation Loss: 0.00206522
Epoch [97/300], Train Loss: 0.002275
Validation Loss: 0.00221328
Epoch [98/300], Train Loss: 0.002221
Validation Loss: 0.00205083
Early stopping triggered

Evaluating model for: Tablet
Run 54/72 completed in 1664.79 seconds with: {'MAE': np.float32(0.38739944), 'MSE': np.float32(0.3527485), 'RMSE': np.float32(0.59392637), 'SAE': np.float32(0.015401152), 'NDE': np.float32(0.13648795)}

Run 55/72: hidden=512, seq_len=120, stride=0.5, num_layers=4
Training and evaluating model for: Tablet
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.030397
Validation Loss: 0.01614552
Epoch [2/300], Train Loss: 0.013915
Validation Loss: 0.01093873
Epoch [3/300], Train Loss: 0.011199
Validation Loss: 0.00990309
Epoch [4/300], Train Loss: 0.010170
Validation Loss: 0.00894956
Epoch [5/300], Train Loss: 0.009568
Validation Loss: 0.00838039
Epoch [6/300], Train Loss: 0.009161
Validation Loss: 0.00834491
Epoch [7/300], Train Loss: 0.008958
Validation Loss: 0.00810656
Epoch [8/300], Train Loss: 0.008698
Validation Loss: 0.00770378
Epoch [9/300], Train Loss: 0.008470
Validation Loss: 0.00738113
Epoch [10/300], Train Loss: 0.008156
Validation Loss: 0.00720836
Epoch [11/300], Train Loss: 0.007910
Validation Loss: 0.00685260
Epoch [12/300], Train Loss: 0.007764
Validation Loss: 0.00689001
Epoch [13/300], Train Loss: 0.008055
Validation Loss: 0.00686091
Epoch [14/300], Train Loss: 0.007509
Validation Loss: 0.00656521
Epoch [15/300], Train Loss: 0.007303
Validation Loss: 0.00652131
Epoch [16/300], Train Loss: 0.007153
Validation Loss: 0.00666570
Epoch [17/300], Train Loss: 0.007134
Validation Loss: 0.00629282
Epoch [18/300], Train Loss: 0.006955
Validation Loss: 0.00622278
Epoch [19/300], Train Loss: 0.006894
Validation Loss: 0.00608430
Epoch [20/300], Train Loss: 0.006778
Validation Loss: 0.00597924
Epoch [21/300], Train Loss: 0.006353
Validation Loss: 0.00516466
Epoch [22/300], Train Loss: 0.005899
Validation Loss: 0.00447687
Epoch [23/300], Train Loss: 0.004673
Validation Loss: 0.00360452
Epoch [24/300], Train Loss: 0.004006
Validation Loss: 0.00342589
Epoch [25/300], Train Loss: 0.003778
Validation Loss: 0.00323120
Epoch [26/300], Train Loss: 0.003670
Validation Loss: 0.00299571
Epoch [27/300], Train Loss: 0.003357
Validation Loss: 0.00286194
Epoch [28/300], Train Loss: 0.003288
Validation Loss: 0.00275315
Epoch [29/300], Train Loss: 0.003170
Validation Loss: 0.00267476
Epoch [30/300], Train Loss: 0.003033
Validation Loss: 0.00256798
Epoch [31/300], Train Loss: 0.002964
Validation Loss: 0.00249025
Epoch [32/300], Train Loss: 0.002828
Validation Loss: 0.00250227
Epoch [33/300], Train Loss: 0.002844
Validation Loss: 0.00234022
Epoch [34/300], Train Loss: 0.002629
Validation Loss: 0.00226355
Epoch [35/300], Train Loss: 0.002590
Validation Loss: 0.00231394
Epoch [36/300], Train Loss: 0.002601
Validation Loss: 0.00219767
Epoch [37/300], Train Loss: 0.002663
Validation Loss: 0.00308289
Epoch [38/300], Train Loss: 0.002736
Validation Loss: 0.00227858
Epoch [39/300], Train Loss: 0.002504
Validation Loss: 0.00217816
Epoch [40/300], Train Loss: 0.002487
Validation Loss: 0.00222533
Epoch [41/300], Train Loss: 0.002402
Validation Loss: 0.00212704
Epoch [42/300], Train Loss: 0.002401
Validation Loss: 0.00211746
Epoch [43/300], Train Loss: 0.002420
Validation Loss: 0.00257704
Epoch [44/300], Train Loss: 0.002423
Validation Loss: 0.00216235
Epoch [45/300], Train Loss: 0.002395
Validation Loss: 0.00235557
Epoch [46/300], Train Loss: 0.002542
Validation Loss: 0.00208038
Epoch [47/300], Train Loss: 0.002314
Validation Loss: 0.00210023
Epoch [48/300], Train Loss: 0.002331
Validation Loss: 0.00214069
Epoch [49/300], Train Loss: 0.002330
Validation Loss: 0.00207245
Epoch [50/300], Train Loss: 0.002310
Validation Loss: 0.00211781
Epoch [51/300], Train Loss: 0.002299
Validation Loss: 0.00211773
Epoch [52/300], Train Loss: 0.002450
Validation Loss: 0.00211141
Epoch [53/300], Train Loss: 0.002283
Validation Loss: 0.00205670
Epoch [54/300], Train Loss: 0.002368
Validation Loss: 0.00204051
Epoch [55/300], Train Loss: 0.002253
Validation Loss: 0.00207397
Epoch [56/300], Train Loss: 0.002319
Validation Loss: 0.00211131
Epoch [57/300], Train Loss: 0.002971
Validation Loss: 0.00221656
Epoch [58/300], Train Loss: 0.002363
Validation Loss: 0.00207710
Epoch [59/300], Train Loss: 0.002320
Validation Loss: 0.00206161
Epoch [60/300], Train Loss: 0.002268
Validation Loss: 0.00205020
Epoch [61/300], Train Loss: 0.002253
Validation Loss: 0.00204340
Epoch [62/300], Train Loss: 0.002239
Validation Loss: 0.00201753
Epoch [63/300], Train Loss: 0.002221
Validation Loss: 0.00201768
Epoch [64/300], Train Loss: 0.002234
Validation Loss: 0.00203431
Epoch [65/300], Train Loss: 0.002221
Validation Loss: 0.00205292
Epoch [66/300], Train Loss: 0.002226
Validation Loss: 0.00202688
Epoch [67/300], Train Loss: 0.002216
Validation Loss: 0.00201289
Epoch [68/300], Train Loss: 0.002214
Validation Loss: 0.00200630
Epoch [69/300], Train Loss: 0.002198
Validation Loss: 0.00200285
Epoch [70/300], Train Loss: 0.002227
Validation Loss: 0.00202391
Epoch [71/300], Train Loss: 0.002201
Validation Loss: 0.00200202
Epoch [72/300], Train Loss: 0.002198
Validation Loss: 0.00201298
Epoch [73/300], Train Loss: 0.002237
Validation Loss: 0.00202211
Epoch [74/300], Train Loss: 0.002196
Validation Loss: 0.00215840
Epoch [75/300], Train Loss: 0.002209
Validation Loss: 0.00204834
Epoch [76/300], Train Loss: 0.002171
Validation Loss: 0.00201560
Epoch [77/300], Train Loss: 0.002232
Validation Loss: 0.00205959
Epoch [78/300], Train Loss: 0.002192
Validation Loss: 0.00202335
Epoch [79/300], Train Loss: 0.002205
Validation Loss: 0.00205164
Epoch [80/300], Train Loss: 0.002171
Validation Loss: 0.00206226
Epoch [81/300], Train Loss: 0.002206
Validation Loss: 0.00203238
Early stopping triggered

Evaluating model for: Tablet
Run 55/72 completed in 1493.84 seconds with: {'MAE': np.float32(0.39143774), 'MSE': np.float32(0.3398247), 'RMSE': np.float32(0.58294487), 'SAE': np.float32(0.000762678), 'NDE': np.float32(0.13396433)}

Run 56/72: hidden=512, seq_len=120, stride=0.5, num_layers=5
Training and evaluating model for: Tablet
Dataset length: 12633 windows

Epoch [1/300], Train Loss: 0.033707
Validation Loss: 0.01701946
Epoch [2/300], Train Loss: 0.015590
Validation Loss: 0.01202647
Epoch [3/300], Train Loss: 0.012234
Validation Loss: 0.01103490
Epoch [4/300], Train Loss: 0.011123
Validation Loss: 0.00967659
Epoch [5/300], Train Loss: 0.010451
Validation Loss: 0.00921143
Epoch [6/300], Train Loss: 0.009997
Validation Loss: 0.00922786
Epoch [7/300], Train Loss: 0.009761
Validation Loss: 0.00905555
Epoch [8/300], Train Loss: 0.009533
Validation Loss: 0.00854017
Epoch [9/300], Train Loss: 0.009294
Validation Loss: 0.00823250
Epoch [10/300], Train Loss: 0.009257
Validation Loss: 0.00812438
Epoch [11/300], Train Loss: 0.008992
Validation Loss: 0.00796074
Epoch [12/300], Train Loss: 0.008835
Validation Loss: 0.00791292
Epoch [13/300], Train Loss: 0.008718
Validation Loss: 0.00776172
Epoch [14/300], Train Loss: 0.008552
Validation Loss: 0.00781612
Epoch [15/300], Train Loss: 0.008480
Validation Loss: 0.00776627
Epoch [16/300], Train Loss: 0.008369
Validation Loss: 0.00747996
Epoch [17/300], Train Loss: 0.008270
Validation Loss: 0.00764648
Epoch [18/300], Train Loss: 0.008190
Validation Loss: 0.00726133
Epoch [19/300], Train Loss: 0.008192
Validation Loss: 0.00719090
Epoch [20/300], Train Loss: 0.008033
Validation Loss: 0.00704394
Epoch [21/300], Train Loss: 0.007833
Validation Loss: 0.00741790
Epoch [22/300], Train Loss: 0.007821
Validation Loss: 0.00692080
Epoch [23/300], Train Loss: 0.007451
Validation Loss: 0.00650475
Epoch [24/300], Train Loss: 0.007169
Validation Loss: 0.00634001
Epoch [25/300], Train Loss: 0.007065
Validation Loss: 0.00614849
Epoch [26/300], Train Loss: 0.007026
Validation Loss: 0.00608691
Epoch [27/300], Train Loss: 0.006869
Validation Loss: 0.00618928
Epoch [28/300], Train Loss: 0.006810
Validation Loss: 0.00585318
Epoch [29/300], Train Loss: 0.006379
Validation Loss: 0.00525484
Epoch [30/300], Train Loss: 0.005389
Validation Loss: 0.00364515
Epoch [31/300], Train Loss: 0.004425
Validation Loss: 0.00333341
Epoch [32/300], Train Loss: 0.003709
Validation Loss: 0.00289571
Epoch [33/300], Train Loss: 0.003547
Validation Loss: 0.00281930
Epoch [34/300], Train Loss: 0.003144
Validation Loss: 0.00269491
Epoch [35/300], Train Loss: 0.003105
Validation Loss: 0.00249920
Epoch [36/300], Train Loss: 0.002818
Validation Loss: 0.00244131
Epoch [37/300], Train Loss: 0.002655
Validation Loss: 0.00227278
Epoch [38/300], Train Loss: 0.002715
Validation Loss: 0.00236808
Epoch [39/300], Train Loss: 0.002601
Validation Loss: 0.00229665
Epoch [40/300], Train Loss: 0.002551
Validation Loss: 0.00228500
Epoch [41/300], Train Loss: 0.002492
Validation Loss: 0.00215871
Epoch [42/300], Train Loss: 0.002492
Validation Loss: 0.00216372
Epoch [43/300], Train Loss: 0.002409
Validation Loss: 0.00610880
Epoch [44/300], Train Loss: 0.003010
Validation Loss: 0.00217028
Epoch [45/300], Train Loss: 0.002421
Validation Loss: 0.00216083
Epoch [46/300], Train Loss: 0.002423
Validation Loss: 0.00210289
Epoch [47/300], Train Loss: 0.002388
Validation Loss: 0.00210436
Epoch [48/300], Train Loss: 0.002455
Validation Loss: 0.00211421
Epoch [49/300], Train Loss: 0.002338
Validation Loss: 0.00208909
Epoch [50/300], Train Loss: 0.002321
Validation Loss: 0.00208067
Epoch [51/300], Train Loss: 0.002345
Validation Loss: 0.00229976
Epoch [52/300], Train Loss: 0.002359
Validation Loss: 0.00207537
Epoch [53/300], Train Loss: 0.002845
Validation Loss: 0.00242245
Epoch [54/300], Train Loss: 0.002588
Validation Loss: 0.00213208
Epoch [55/300], Train Loss: 0.002396
Validation Loss: 0.00210241
Epoch [56/300], Train Loss: 0.002297
Validation Loss: 0.00206570
Epoch [57/300], Train Loss: 0.002266
Validation Loss: 0.00207749
Epoch [58/300], Train Loss: 0.002273
Validation Loss: 0.00209025
Epoch [59/300], Train Loss: 0.003186
Validation Loss: 0.00232662
Epoch [60/300], Train Loss: 0.002364
Validation Loss: 0.00210502
Epoch [61/300], Train Loss: 0.002275
Validation Loss: 0.00206702
Epoch [62/300], Train Loss: 0.002259
Validation Loss: 0.00205982
Epoch [63/300], Train Loss: 0.002246
Validation Loss: 0.00209159
Epoch [64/300], Train Loss: 0.002238
Validation Loss: 0.00206879
Epoch [65/300], Train Loss: 0.002239
Validation Loss: 0.00206826
Epoch [66/300], Train Loss: 0.002249
Validation Loss: 0.00210624
Epoch [67/300], Train Loss: 0.002226
Validation Loss: 0.00204903
Epoch [68/300], Train Loss: 0.002720
Validation Loss: 0.00267866
Epoch [69/300], Train Loss: 0.002467
Validation Loss: 0.00206828
Epoch [70/300], Train Loss: 0.002240
Validation Loss: 0.00206332
Epoch [71/300], Train Loss: 0.002239
Validation Loss: 0.00204903
Epoch [72/300], Train Loss: 0.002273
Validation Loss: 0.00207979
Epoch [73/300], Train Loss: 0.002216
Validation Loss: 0.00203262
Epoch [74/300], Train Loss: 0.002209
Validation Loss: 0.00202514
Epoch [75/300], Train Loss: 0.002189
Validation Loss: 0.00202968
Epoch [76/300], Train Loss: 0.002214
Validation Loss: 0.00204101
Epoch [77/300], Train Loss: 0.002221
Validation Loss: 0.00206826
Epoch [78/300], Train Loss: 0.002215
Validation Loss: 0.00202336
Epoch [79/300], Train Loss: 0.002190
Validation Loss: 0.00204051
Epoch [80/300], Train Loss: 0.002235
Validation Loss: 0.00204303
Epoch [81/300], Train Loss: 0.002233
Validation Loss: 0.00206478
Epoch [82/300], Train Loss: 0.002183
Validation Loss: 0.00202293
Epoch [83/300], Train Loss: 0.002189
Validation Loss: 0.00215762
Epoch [84/300], Train Loss: 0.002167
Validation Loss: 0.00201573
Epoch [85/300], Train Loss: 0.002163
Validation Loss: 0.00201878
Epoch [86/300], Train Loss: 0.002468
Validation Loss: 0.00205378
Epoch [87/300], Train Loss: 0.002209
Validation Loss: 0.00203807
Epoch [88/300], Train Loss: 0.002186
Validation Loss: 0.00203374
Epoch [89/300], Train Loss: 0.002451
Validation Loss: 0.00205782
Epoch [90/300], Train Loss: 0.002199
Validation Loss: 0.00204388
Epoch [91/300], Train Loss: 0.002207
Validation Loss: 0.00203784
Epoch [92/300], Train Loss: 0.002186
Validation Loss: 0.00205424
Epoch [93/300], Train Loss: 0.002174
Validation Loss: 0.00202229
Epoch [94/300], Train Loss: 0.002201
Validation Loss: 0.00204505
Early stopping triggered

Evaluating model for: Tablet
Run 56/72 completed in 2005.37 seconds with: {'MAE': np.float32(0.39274), 'MSE': np.float32(0.35413283), 'RMSE': np.float32(0.5950906), 'SAE': np.float32(0.010308562), 'NDE': np.float32(0.1367555)}

Run 57/72: hidden=512, seq_len=360, stride=0.25, num_layers=2
Training and evaluating model for: Tablet
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.039929
Validation Loss: 0.01810330
Epoch [2/300], Train Loss: 0.014858
Validation Loss: 0.01494242
Epoch [3/300], Train Loss: 0.011876
Validation Loss: 0.01251575
Epoch [4/300], Train Loss: 0.010837
Validation Loss: 0.01164465
Epoch [5/300], Train Loss: 0.010274
Validation Loss: 0.01097695
Epoch [6/300], Train Loss: 0.009439
Validation Loss: 0.01021479
Epoch [7/300], Train Loss: 0.009011
Validation Loss: 0.01007269
Epoch [8/300], Train Loss: 0.008750
Validation Loss: 0.01005545
Epoch [9/300], Train Loss: 0.008509
Validation Loss: 0.00924869
Epoch [10/300], Train Loss: 0.008311
Validation Loss: 0.00909138
Epoch [11/300], Train Loss: 0.008211
Validation Loss: 0.00982183
Epoch [12/300], Train Loss: 0.008321
Validation Loss: 0.00915012
Epoch [13/300], Train Loss: 0.007868
Validation Loss: 0.00881701
Epoch [14/300], Train Loss: 0.007898
Validation Loss: 0.00920067
Epoch [15/300], Train Loss: 0.007725
Validation Loss: 0.00863095
Epoch [16/300], Train Loss: 0.007319
Validation Loss: 0.00788458
Epoch [17/300], Train Loss: 0.007469
Validation Loss: 0.00784178
Epoch [18/300], Train Loss: 0.007317
Validation Loss: 0.00795955
Epoch [19/300], Train Loss: 0.007140
Validation Loss: 0.00794665
Epoch [20/300], Train Loss: 0.007133
Validation Loss: 0.00767849
Epoch [21/300], Train Loss: 0.007054
Validation Loss: 0.00772116
Epoch [22/300], Train Loss: 0.007132
Validation Loss: 0.00774659
Epoch [23/300], Train Loss: 0.007118
Validation Loss: 0.00753404
Epoch [24/300], Train Loss: 0.006921
Validation Loss: 0.00762836
Epoch [25/300], Train Loss: 0.007471
Validation Loss: 0.00770634
Epoch [26/300], Train Loss: 0.007125
Validation Loss: 0.00788966
Epoch [27/300], Train Loss: 0.006961
Validation Loss: 0.00746860
Epoch [28/300], Train Loss: 0.006959
Validation Loss: 0.00785338
Epoch [29/300], Train Loss: 0.006958
Validation Loss: 0.00745232
Epoch [30/300], Train Loss: 0.006914
Validation Loss: 0.00769340
Epoch [31/300], Train Loss: 0.006989
Validation Loss: 0.00772174
Epoch [32/300], Train Loss: 0.006968
Validation Loss: 0.00746520
Epoch [33/300], Train Loss: 0.006844
Validation Loss: 0.00749957
Epoch [34/300], Train Loss: 0.006941
Validation Loss: 0.00749464
Epoch [35/300], Train Loss: 0.006819
Validation Loss: 0.00739874
Epoch [36/300], Train Loss: 0.006748
Validation Loss: 0.00737992
Epoch [37/300], Train Loss: 0.006819
Validation Loss: 0.00851617
Epoch [38/300], Train Loss: 0.007076
Validation Loss: 0.00776706
Epoch [39/300], Train Loss: 0.006896
Validation Loss: 0.00733092
Epoch [40/300], Train Loss: 0.006996
Validation Loss: 0.00743202
Epoch [41/300], Train Loss: 0.006858
Validation Loss: 0.00730290
Epoch [42/300], Train Loss: 0.006893
Validation Loss: 0.00756473
Epoch [43/300], Train Loss: 0.006872
Validation Loss: 0.00730482
Epoch [44/300], Train Loss: 0.006766
Validation Loss: 0.00763350
Epoch [45/300], Train Loss: 0.006848
Validation Loss: 0.00727568
Epoch [46/300], Train Loss: 0.006800
Validation Loss: 0.00726566
Epoch [47/300], Train Loss: 0.006893
Validation Loss: 0.00771957
Epoch [48/300], Train Loss: 0.007021
Validation Loss: 0.00738986
Epoch [49/300], Train Loss: 0.006657
Validation Loss: 0.00734565
Epoch [50/300], Train Loss: 0.006788
Validation Loss: 0.00726038
Epoch [51/300], Train Loss: 0.006743
Validation Loss: 0.00738192
Epoch [52/300], Train Loss: 0.006791
Validation Loss: 0.00722296
Epoch [53/300], Train Loss: 0.006794
Validation Loss: 0.00720414
Epoch [54/300], Train Loss: 0.007130
Validation Loss: 0.00725056
Epoch [55/300], Train Loss: 0.006600
Validation Loss: 0.00718181
Epoch [56/300], Train Loss: 0.006962
Validation Loss: 0.00745666
Epoch [57/300], Train Loss: 0.006789
Validation Loss: 0.00734057
Epoch [58/300], Train Loss: 0.007981
Validation Loss: 0.00866580
Epoch [59/300], Train Loss: 0.007210
Validation Loss: 0.00750965
Epoch [60/300], Train Loss: 0.006966
Validation Loss: 0.00734061
Epoch [61/300], Train Loss: 0.006719
Validation Loss: 0.00726054
Epoch [62/300], Train Loss: 0.006729
Validation Loss: 0.00726323
Epoch [63/300], Train Loss: 0.007088
Validation Loss: 0.00810602
Epoch [64/300], Train Loss: 0.007208
Validation Loss: 0.00733490
Epoch [65/300], Train Loss: 0.006768
Validation Loss: 0.00719329
Early stopping triggered

Evaluating model for: Tablet
Run 57/72 completed in 957.65 seconds with: {'MAE': np.float32(0.6510766), 'MSE': np.float32(1.1110505), 'RMSE': np.float32(1.0540638), 'SAE': np.float32(0.012936095), 'NDE': np.float32(0.24378696)}

Run 58/72: hidden=512, seq_len=360, stride=0.25, num_layers=3
Training and evaluating model for: Tablet
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.039544
Validation Loss: 0.01740952
Epoch [2/300], Train Loss: 0.014741
Validation Loss: 0.01498210
Epoch [3/300], Train Loss: 0.011945
Validation Loss: 0.01212855
Epoch [4/300], Train Loss: 0.010707
Validation Loss: 0.01152503
Epoch [5/300], Train Loss: 0.009962
Validation Loss: 0.01099409
Epoch [6/300], Train Loss: 0.010166
Validation Loss: 0.01047645
Epoch [7/300], Train Loss: 0.010485
Validation Loss: 0.01049743
Epoch [8/300], Train Loss: 0.009256
Validation Loss: 0.01011259
Epoch [9/300], Train Loss: 0.008942
Validation Loss: 0.00971404
Epoch [10/300], Train Loss: 0.010658
Validation Loss: 0.01142656
Epoch [11/300], Train Loss: 0.009625
Validation Loss: 0.01052568
Epoch [12/300], Train Loss: 0.009023
Validation Loss: 0.00964183
Epoch [13/300], Train Loss: 0.008639
Validation Loss: 0.01063559
Epoch [14/300], Train Loss: 0.008690
Validation Loss: 0.00927521
Epoch [15/300], Train Loss: 0.008467
Validation Loss: 0.00942978
Epoch [16/300], Train Loss: 0.008172
Validation Loss: 0.00899870
Epoch [17/300], Train Loss: 0.008317
Validation Loss: 0.00886575
Epoch [18/300], Train Loss: 0.008229
Validation Loss: 0.00880549
Epoch [19/300], Train Loss: 0.008082
Validation Loss: 0.00885574
Epoch [20/300], Train Loss: 0.012897
Validation Loss: 0.01485741
Epoch [21/300], Train Loss: 0.011211
Validation Loss: 0.01097629
Epoch [22/300], Train Loss: 0.009051
Validation Loss: 0.00993948
Epoch [23/300], Train Loss: 0.008595
Validation Loss: 0.00977362
Epoch [24/300], Train Loss: 0.008307
Validation Loss: 0.00976891
Epoch [25/300], Train Loss: 0.008483
Validation Loss: 0.00882564
Epoch [26/300], Train Loss: 0.008147
Validation Loss: 0.00903440
Epoch [27/300], Train Loss: 0.008034
Validation Loss: 0.00935811
Epoch [28/300], Train Loss: 0.008611
Validation Loss: 0.00875113
Epoch [29/300], Train Loss: 0.007899
Validation Loss: 0.00835023
Epoch [30/300], Train Loss: 0.007792
Validation Loss: 0.00846571
Epoch [31/300], Train Loss: 0.009497
Validation Loss: 0.01666075
Epoch [32/300], Train Loss: 0.012968
Validation Loss: 0.01212754
Epoch [33/300], Train Loss: 0.010577
Validation Loss: 0.01050923
Epoch [34/300], Train Loss: 0.009605
Validation Loss: 0.01013166
Epoch [35/300], Train Loss: 0.009583
Validation Loss: 0.01052809
Epoch [36/300], Train Loss: 0.009428
Validation Loss: 0.00989871
Epoch [37/300], Train Loss: 0.009092
Validation Loss: 0.00971024
Epoch [38/300], Train Loss: 0.008892
Validation Loss: 0.00962648
Epoch [39/300], Train Loss: 0.008811
Validation Loss: 0.00875433
Early stopping triggered

Evaluating model for: Tablet
Run 58/72 completed in 728.61 seconds with: {'MAE': np.float32(0.7279663), 'MSE': np.float32(1.3356838), 'RMSE': np.float32(1.1557178), 'SAE': np.float32(0.015564662), 'NDE': np.float32(0.26729792)}

Run 59/72: hidden=512, seq_len=360, stride=0.25, num_layers=4
Training and evaluating model for: Tablet
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.039331
Validation Loss: 0.01766904
Epoch [2/300], Train Loss: 0.015327
Validation Loss: 0.01591539
Epoch [3/300], Train Loss: 0.011924
Validation Loss: 0.01207526
Epoch [4/300], Train Loss: 0.010573
Validation Loss: 0.01133756
Epoch [5/300], Train Loss: 0.010085
Validation Loss: 0.01061822
Epoch [6/300], Train Loss: 0.009336
Validation Loss: 0.01006975
Epoch [7/300], Train Loss: 0.009033
Validation Loss: 0.00969687
Epoch [8/300], Train Loss: 0.008818
Validation Loss: 0.00978908
Epoch [9/300], Train Loss: 0.008854
Validation Loss: 0.00911023
Epoch [10/300], Train Loss: 0.008577
Validation Loss: 0.00918722
Epoch [11/300], Train Loss: 0.008632
Validation Loss: 0.00885837
Epoch [12/300], Train Loss: 0.008348
Validation Loss: 0.00884216
Epoch [13/300], Train Loss: 0.008496
Validation Loss: 0.00881356
Epoch [14/300], Train Loss: 0.008157
Validation Loss: 0.00862125
Epoch [15/300], Train Loss: 0.008017
Validation Loss: 0.00893233
Epoch [16/300], Train Loss: 0.007750
Validation Loss: 0.00835270
Epoch [17/300], Train Loss: 0.007747
Validation Loss: 0.00847302
Epoch [18/300], Train Loss: 0.007707
Validation Loss: 0.00818420
Epoch [19/300], Train Loss: 0.007464
Validation Loss: 0.00813571
Epoch [20/300], Train Loss: 0.007479
Validation Loss: 0.00841923
Epoch [21/300], Train Loss: 0.007498
Validation Loss: 0.00841522
Epoch [22/300], Train Loss: 0.007662
Validation Loss: 0.01001663
Epoch [23/300], Train Loss: 0.007488
Validation Loss: 0.00784980
Epoch [24/300], Train Loss: 0.007162
Validation Loss: 0.00809896
Epoch [25/300], Train Loss: 0.007447
Validation Loss: 0.00767567
Epoch [26/300], Train Loss: 0.007223
Validation Loss: 0.00773378
Epoch [27/300], Train Loss: 0.007131
Validation Loss: 0.00776572
Epoch [28/300], Train Loss: 0.007350
Validation Loss: 0.00757307
Epoch [29/300], Train Loss: 0.007065
Validation Loss: 0.00748550
Epoch [30/300], Train Loss: 0.007178
Validation Loss: 0.00745165
Epoch [31/300], Train Loss: 0.006969
Validation Loss: 0.00774126
Epoch [32/300], Train Loss: 0.006946
Validation Loss: 0.00747243
Epoch [33/300], Train Loss: 0.006796
Validation Loss: 0.00733925
Epoch [34/300], Train Loss: 0.006951
Validation Loss: 0.00763804
Epoch [35/300], Train Loss: 0.007324
Validation Loss: 0.02325475
Epoch [36/300], Train Loss: 0.009541
Validation Loss: 0.00828706
Epoch [37/300], Train Loss: 0.007788
Validation Loss: 0.00816837
Epoch [38/300], Train Loss: 0.007691
Validation Loss: 0.00794460
Epoch [39/300], Train Loss: 0.007552
Validation Loss: 0.00789398
Epoch [40/300], Train Loss: 0.007514
Validation Loss: 0.00771562
Epoch [41/300], Train Loss: 0.007231
Validation Loss: 0.00765827
Epoch [42/300], Train Loss: 0.007210
Validation Loss: 0.00774090
Epoch [43/300], Train Loss: 0.007167
Validation Loss: 0.00754633
Early stopping triggered

Evaluating model for: Tablet
Run 59/72 completed in 937.95 seconds with: {'MAE': np.float32(0.66491276), 'MSE': np.float32(1.177993), 'RMSE': np.float32(1.0853539), 'SAE': np.float32(0.025678076), 'NDE': np.float32(0.25102383)}

Run 60/72: hidden=512, seq_len=360, stride=0.25, num_layers=5
Training and evaluating model for: Tablet
Dataset length: 8331 windows

Epoch [1/300], Train Loss: 0.036331
Validation Loss: 0.01771542
Epoch [2/300], Train Loss: 0.015752
Validation Loss: 0.01705836
Epoch [3/300], Train Loss: 0.012860
Validation Loss: 0.01255440
Epoch [4/300], Train Loss: 0.010780
Validation Loss: 0.01163758
Epoch [5/300], Train Loss: 0.010278
Validation Loss: 0.01129148
Epoch [6/300], Train Loss: 0.009909
Validation Loss: 0.01091042
Epoch [7/300], Train Loss: 0.009704
Validation Loss: 0.01041611
Epoch [8/300], Train Loss: 0.009508
Validation Loss: 0.01080943
Epoch [9/300], Train Loss: 0.009143
Validation Loss: 0.00981036
Epoch [10/300], Train Loss: 0.011986
Validation Loss: 0.01595905
Epoch [11/300], Train Loss: 0.010849
Validation Loss: 0.01023763
Epoch [12/300], Train Loss: 0.009077
Validation Loss: 0.00976560
Epoch [13/300], Train Loss: 0.008971
Validation Loss: 0.00938577
Epoch [14/300], Train Loss: 0.008867
Validation Loss: 0.01038287
Epoch [15/300], Train Loss: 0.008879
Validation Loss: 0.00926242
Epoch [16/300], Train Loss: 0.008352
Validation Loss: 0.00915776
Epoch [17/300], Train Loss: 0.008475
Validation Loss: 0.00934668
Epoch [18/300], Train Loss: 0.008366
Validation Loss: 0.00890313
Epoch [19/300], Train Loss: 0.008324
Validation Loss: 0.00925793
Epoch [20/300], Train Loss: 0.008127
Validation Loss: 0.00872481
Epoch [21/300], Train Loss: 0.008091
Validation Loss: 0.00891777
Epoch [22/300], Train Loss: 0.008093
Validation Loss: 0.00874875
Epoch [23/300], Train Loss: 0.007984
Validation Loss: 0.00852805
Epoch [24/300], Train Loss: 0.007760
Validation Loss: 0.00855647
Epoch [25/300], Train Loss: 0.008149
Validation Loss: 0.00834318
Epoch [26/300], Train Loss: 0.007846
Validation Loss: 0.00828629
Epoch [27/300], Train Loss: 0.007621
Validation Loss: 0.00847878
Epoch [28/300], Train Loss: 0.011005
Validation Loss: 0.01642337
Epoch [29/300], Train Loss: 0.011590
Validation Loss: 0.01023877
Epoch [30/300], Train Loss: 0.008400
Validation Loss: 0.00913282
Epoch [31/300], Train Loss: 0.008228
Validation Loss: 0.00855027
Epoch [32/300], Train Loss: 0.008004
Validation Loss: 0.00836358
Epoch [33/300], Train Loss: 0.007702
Validation Loss: 0.00821601
Epoch [34/300], Train Loss: 0.008708
Validation Loss: 0.00894953
Epoch [35/300], Train Loss: 0.007897
Validation Loss: 0.00826421
Epoch [36/300], Train Loss: 0.007543
Validation Loss: 0.00816499
Epoch [37/300], Train Loss: 0.007573
Validation Loss: 0.00811926
Epoch [38/300], Train Loss: 0.007528
Validation Loss: 0.00800571
Epoch [39/300], Train Loss: 0.007403
Validation Loss: 0.00798686
Epoch [40/300], Train Loss: 0.007548
Validation Loss: 0.00789197
Epoch [41/300], Train Loss: 0.007394
Validation Loss: 0.00788977
Epoch [42/300], Train Loss: 0.007361
Validation Loss: 0.00807351
Epoch [43/300], Train Loss: 0.007286
Validation Loss: 0.00782262
Epoch [44/300], Train Loss: 0.007457
Validation Loss: 0.00857067
Epoch [45/300], Train Loss: 0.007341
Validation Loss: 0.00780900
Epoch [46/300], Train Loss: 0.007206
Validation Loss: 0.00799539
Epoch [47/300], Train Loss: 0.008940
Validation Loss: 0.00835655
Epoch [48/300], Train Loss: 0.007468
Validation Loss: 0.00810791
Epoch [49/300], Train Loss: 0.007245
Validation Loss: 0.00814176
Epoch [50/300], Train Loss: 0.007354
Validation Loss: 0.00819844
Epoch [51/300], Train Loss: 0.007265
Validation Loss: 0.00788047
Epoch [52/300], Train Loss: 0.007226
Validation Loss: 0.00793929
Epoch [53/300], Train Loss: 0.011663
Validation Loss: 0.01624749
Epoch [54/300], Train Loss: 0.013107
Validation Loss: 0.01080523
Epoch [55/300], Train Loss: 0.008476
Validation Loss: 0.00896713
Early stopping triggered

Evaluating model for: Tablet
Run 60/72 completed in 1531.39 seconds with: {'MAE': np.float32(0.76155525), 'MSE': np.float32(1.344828), 'RMSE': np.float32(1.1596673), 'SAE': np.float32(0.013589872), 'NDE': np.float32(0.26821125)}

Run 61/72: hidden=512, seq_len=360, stride=0.5, num_layers=2
Training and evaluating model for: Tablet
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.062719
Validation Loss: 0.02330273
Epoch [2/300], Train Loss: 0.017546
Validation Loss: 0.01646218
Epoch [3/300], Train Loss: 0.015402
Validation Loss: 0.01532711
Epoch [4/300], Train Loss: 0.014058
Validation Loss: 0.01366706
Epoch [5/300], Train Loss: 0.012780
Validation Loss: 0.01216660
Epoch [6/300], Train Loss: 0.011678
Validation Loss: 0.01168722
Epoch [7/300], Train Loss: 0.011016
Validation Loss: 0.01113357
Epoch [8/300], Train Loss: 0.010742
Validation Loss: 0.01075785
Epoch [9/300], Train Loss: 0.010619
Validation Loss: 0.01043602
Epoch [10/300], Train Loss: 0.010350
Validation Loss: 0.01007239
Epoch [11/300], Train Loss: 0.009771
Validation Loss: 0.00971550
Epoch [12/300], Train Loss: 0.009280
Validation Loss: 0.00965932
Epoch [13/300], Train Loss: 0.009127
Validation Loss: 0.00940355
Epoch [14/300], Train Loss: 0.008962
Validation Loss: 0.00923702
Epoch [15/300], Train Loss: 0.009041
Validation Loss: 0.00924980
Epoch [16/300], Train Loss: 0.008886
Validation Loss: 0.00914308
Epoch [17/300], Train Loss: 0.008839
Validation Loss: 0.00904602
Epoch [18/300], Train Loss: 0.008724
Validation Loss: 0.00882245
Epoch [19/300], Train Loss: 0.008607
Validation Loss: 0.00889094
Epoch [20/300], Train Loss: 0.008356
Validation Loss: 0.00877257
Epoch [21/300], Train Loss: 0.008444
Validation Loss: 0.00876791
Epoch [22/300], Train Loss: 0.008278
Validation Loss: 0.00872829
Epoch [23/300], Train Loss: 0.008448
Validation Loss: 0.00943986
Epoch [24/300], Train Loss: 0.008935
Validation Loss: 0.00874258
Epoch [25/300], Train Loss: 0.008321
Validation Loss: 0.00853389
Epoch [26/300], Train Loss: 0.008239
Validation Loss: 0.00850424
Epoch [27/300], Train Loss: 0.008271
Validation Loss: 0.00873969
Epoch [28/300], Train Loss: 0.008177
Validation Loss: 0.00831648
Epoch [29/300], Train Loss: 0.008024
Validation Loss: 0.00825507
Epoch [30/300], Train Loss: 0.008118
Validation Loss: 0.00826860
Epoch [31/300], Train Loss: 0.007982
Validation Loss: 0.00820040
Epoch [32/300], Train Loss: 0.008520
Validation Loss: 0.00817240
Epoch [33/300], Train Loss: 0.007866
Validation Loss: 0.00812993
Epoch [34/300], Train Loss: 0.007839
Validation Loss: 0.00800238
Epoch [35/300], Train Loss: 0.007781
Validation Loss: 0.00857107
Epoch [36/300], Train Loss: 0.007737
Validation Loss: 0.00787475
Epoch [37/300], Train Loss: 0.007749
Validation Loss: 0.00800242
Epoch [38/300], Train Loss: 0.007703
Validation Loss: 0.00785921
Epoch [39/300], Train Loss: 0.007701
Validation Loss: 0.00771971
Epoch [40/300], Train Loss: 0.007604
Validation Loss: 0.00803183
Epoch [41/300], Train Loss: 0.007342
Validation Loss: 0.00755983
Epoch [42/300], Train Loss: 0.007260
Validation Loss: 0.00749761
Epoch [43/300], Train Loss: 0.007266
Validation Loss: 0.00741809
Epoch [44/300], Train Loss: 0.007401
Validation Loss: 0.00799403
Epoch [45/300], Train Loss: 0.007279
Validation Loss: 0.00770520
Epoch [46/300], Train Loss: 0.007011
Validation Loss: 0.00773766
Epoch [47/300], Train Loss: 0.007087
Validation Loss: 0.00726770
Epoch [48/300], Train Loss: 0.006865
Validation Loss: 0.00729697
Epoch [49/300], Train Loss: 0.006915
Validation Loss: 0.00732155
Epoch [50/300], Train Loss: 0.007201
Validation Loss: 0.00728588
Epoch [51/300], Train Loss: 0.006802
Validation Loss: 0.00722581
Epoch [52/300], Train Loss: 0.007090
Validation Loss: 0.00790426
Epoch [53/300], Train Loss: 0.007039
Validation Loss: 0.00724640
Epoch [54/300], Train Loss: 0.007019
Validation Loss: 0.00725187
Epoch [55/300], Train Loss: 0.006892
Validation Loss: 0.00720928
Epoch [56/300], Train Loss: 0.006814
Validation Loss: 0.00735808
Epoch [57/300], Train Loss: 0.006772
Validation Loss: 0.00728552
Epoch [58/300], Train Loss: 0.006754
Validation Loss: 0.00742734
Epoch [59/300], Train Loss: 0.006868
Validation Loss: 0.00721160
Epoch [60/300], Train Loss: 0.006842
Validation Loss: 0.00762600
Epoch [61/300], Train Loss: 0.007063
Validation Loss: 0.00716636
Epoch [62/300], Train Loss: 0.006768
Validation Loss: 0.00715692
Epoch [63/300], Train Loss: 0.006778
Validation Loss: 0.00714345
Epoch [64/300], Train Loss: 0.006637
Validation Loss: 0.00717106
Epoch [65/300], Train Loss: 0.006871
Validation Loss: 0.00720560
Epoch [66/300], Train Loss: 0.006825
Validation Loss: 0.00744880
Epoch [67/300], Train Loss: 0.007011
Validation Loss: 0.00805437
Epoch [68/300], Train Loss: 0.006882
Validation Loss: 0.00717184
Epoch [69/300], Train Loss: 0.006768
Validation Loss: 0.00712218
Epoch [70/300], Train Loss: 0.006789
Validation Loss: 0.00711958
Epoch [71/300], Train Loss: 0.006744
Validation Loss: 0.00727506
Epoch [72/300], Train Loss: 0.007095
Validation Loss: 0.00716386
Epoch [73/300], Train Loss: 0.006793
Validation Loss: 0.00722896
Epoch [74/300], Train Loss: 0.006600
Validation Loss: 0.00709504
Epoch [75/300], Train Loss: 0.006712
Validation Loss: 0.00714834
Epoch [76/300], Train Loss: 0.007009
Validation Loss: 0.00724510
Epoch [77/300], Train Loss: 0.006677
Validation Loss: 0.00714464
Epoch [78/300], Train Loss: 0.006692
Validation Loss: 0.00705616
Epoch [79/300], Train Loss: 0.006805
Validation Loss: 0.00709090
Epoch [80/300], Train Loss: 0.006796
Validation Loss: 0.00730906
Epoch [81/300], Train Loss: 0.006783
Validation Loss: 0.00704897
Epoch [82/300], Train Loss: 0.006698
Validation Loss: 0.00709551
Epoch [83/300], Train Loss: 0.006679
Validation Loss: 0.00707609
Epoch [84/300], Train Loss: 0.006650
Validation Loss: 0.00757820
Epoch [85/300], Train Loss: 0.006749
Validation Loss: 0.00717825
Epoch [86/300], Train Loss: 0.006630
Validation Loss: 0.00721537
Epoch [87/300], Train Loss: 0.006602
Validation Loss: 0.00711247
Epoch [88/300], Train Loss: 0.006586
Validation Loss: 0.00712122
Epoch [89/300], Train Loss: 0.006833
Validation Loss: 0.00738738
Epoch [90/300], Train Loss: 0.006971
Validation Loss: 0.00723923
Epoch [91/300], Train Loss: 0.007029
Validation Loss: 0.00722479
Early stopping triggered

Evaluating model for: Tablet
Run 61/72 completed in 661.56 seconds with: {'MAE': np.float32(0.6537549), 'MSE': np.float32(1.1008466), 'RMSE': np.float32(1.0492123), 'SAE': np.float32(0.021233488), 'NDE': np.float32(0.24132167)}

Run 62/72: hidden=512, seq_len=360, stride=0.5, num_layers=3
Training and evaluating model for: Tablet
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.058815
Validation Loss: 0.01767843
Epoch [2/300], Train Loss: 0.017696
Validation Loss: 0.01681118
Epoch [3/300], Train Loss: 0.015843
Validation Loss: 0.01613544
Epoch [4/300], Train Loss: 0.015141
Validation Loss: 0.01497694
Epoch [5/300], Train Loss: 0.013723
Validation Loss: 0.01224026
Epoch [6/300], Train Loss: 0.011613
Validation Loss: 0.01138495
Epoch [7/300], Train Loss: 0.010848
Validation Loss: 0.01136293
Epoch [8/300], Train Loss: 0.010908
Validation Loss: 0.01088167
Epoch [9/300], Train Loss: 0.010666
Validation Loss: 0.01058305
Epoch [10/300], Train Loss: 0.010657
Validation Loss: 0.01039620
Epoch [11/300], Train Loss: 0.010094
Validation Loss: 0.01003943
Epoch [12/300], Train Loss: 0.009407
Validation Loss: 0.01052769
Epoch [13/300], Train Loss: 0.009550
Validation Loss: 0.00971193
Epoch [14/300], Train Loss: 0.009383
Validation Loss: 0.00961843
Epoch [15/300], Train Loss: 0.009269
Validation Loss: 0.00948979
Epoch [16/300], Train Loss: 0.009307
Validation Loss: 0.00960434
Epoch [17/300], Train Loss: 0.008951
Validation Loss: 0.00914248
Epoch [18/300], Train Loss: 0.008923
Validation Loss: 0.00913625
Epoch [19/300], Train Loss: 0.008727
Validation Loss: 0.00925484
Epoch [20/300], Train Loss: 0.008500
Validation Loss: 0.00898547
Epoch [21/300], Train Loss: 0.008663
Validation Loss: 0.00883806
Epoch [22/300], Train Loss: 0.008508
Validation Loss: 0.00907856
Epoch [23/300], Train Loss: 0.008593
Validation Loss: 0.00881533
Epoch [24/300], Train Loss: 0.008385
Validation Loss: 0.00864912
Epoch [25/300], Train Loss: 0.008257
Validation Loss: 0.00891897
Epoch [26/300], Train Loss: 0.008528
Validation Loss: 0.00854628
Epoch [27/300], Train Loss: 0.008125
Validation Loss: 0.00850443
Epoch [28/300], Train Loss: 0.008134
Validation Loss: 0.00871091
Epoch [29/300], Train Loss: 0.008167
Validation Loss: 0.00861005
Epoch [30/300], Train Loss: 0.008060
Validation Loss: 0.00825761
Epoch [31/300], Train Loss: 0.007962
Validation Loss: 0.00820350
Epoch [32/300], Train Loss: 0.008094
Validation Loss: 0.00840947
Epoch [33/300], Train Loss: 0.007954
Validation Loss: 0.00810449
Epoch [34/300], Train Loss: 0.009277
Validation Loss: 0.00974228
Epoch [35/300], Train Loss: 0.008710
Validation Loss: 0.00841521
Epoch [36/300], Train Loss: 0.008475
Validation Loss: 0.01621509
Epoch [37/300], Train Loss: 0.015851
Validation Loss: 0.01550228
Epoch [38/300], Train Loss: 0.015088
Validation Loss: 0.01532374
Epoch [39/300], Train Loss: 0.014248
Validation Loss: 0.01368631
Epoch [40/300], Train Loss: 0.014638
Validation Loss: 0.01630793
Epoch [41/300], Train Loss: 0.013529
Validation Loss: 0.01302467
Epoch [42/300], Train Loss: 0.012080
Validation Loss: 0.01164265
Epoch [43/300], Train Loss: 0.010578
Validation Loss: 0.01022682
Early stopping triggered

Evaluating model for: Tablet
Run 62/72 completed in 404.83 seconds with: {'MAE': np.float32(0.9328347), 'MSE': np.float32(1.5614196), 'RMSE': np.float32(1.2495677), 'SAE': np.float32(0.0013256487), 'NDE': np.float32(0.28740394)}

Run 63/72: hidden=512, seq_len=360, stride=0.5, num_layers=4
Training and evaluating model for: Tablet
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.065531
Validation Loss: 0.02112864
Epoch [2/300], Train Loss: 0.018022
Validation Loss: 0.01666613
Epoch [3/300], Train Loss: 0.015714
Validation Loss: 0.01580425
Epoch [4/300], Train Loss: 0.014330
Validation Loss: 0.01293731
Epoch [5/300], Train Loss: 0.012041
Validation Loss: 0.01163710
Epoch [6/300], Train Loss: 0.011205
Validation Loss: 0.01132195
Epoch [7/300], Train Loss: 0.010720
Validation Loss: 0.01093563
Epoch [8/300], Train Loss: 0.010644
Validation Loss: 0.01084895
Epoch [9/300], Train Loss: 0.010398
Validation Loss: 0.01045387
Epoch [10/300], Train Loss: 0.010240
Validation Loss: 0.01035335
Epoch [11/300], Train Loss: 0.010304
Validation Loss: 0.01009761
Epoch [12/300], Train Loss: 0.009991
Validation Loss: 0.00985192
Epoch [13/300], Train Loss: 0.009344
Validation Loss: 0.00967358
Epoch [14/300], Train Loss: 0.009280
Validation Loss: 0.00945077
Epoch [15/300], Train Loss: 0.009174
Validation Loss: 0.00922667
Epoch [16/300], Train Loss: 0.009011
Validation Loss: 0.00931112
Epoch [17/300], Train Loss: 0.008941
Validation Loss: 0.00909276
Epoch [18/300], Train Loss: 0.008890
Validation Loss: 0.00898376
Epoch [19/300], Train Loss: 0.008661
Validation Loss: 0.00878661
Epoch [20/300], Train Loss: 0.008594
Validation Loss: 0.00868917
Epoch [21/300], Train Loss: 0.008499
Validation Loss: 0.00858536
Epoch [22/300], Train Loss: 0.008246
Validation Loss: 0.00851681
Epoch [23/300], Train Loss: 0.008439
Validation Loss: 0.00847426
Epoch [24/300], Train Loss: 0.008374
Validation Loss: 0.00898310
Epoch [25/300], Train Loss: 0.008901
Validation Loss: 0.00940618
Epoch [26/300], Train Loss: 0.008602
Validation Loss: 0.00876089
Epoch [27/300], Train Loss: 0.008159
Validation Loss: 0.00847488
Epoch [28/300], Train Loss: 0.008085
Validation Loss: 0.00829118
Epoch [29/300], Train Loss: 0.007962
Validation Loss: 0.00814752
Epoch [30/300], Train Loss: 0.007953
Validation Loss: 0.00880392
Epoch [31/300], Train Loss: 0.008028
Validation Loss: 0.00834986
Epoch [32/300], Train Loss: 0.008019
Validation Loss: 0.00906312
Epoch [33/300], Train Loss: 0.008270
Validation Loss: 0.00844441
Epoch [34/300], Train Loss: 0.007843
Validation Loss: 0.00917403
Epoch [35/300], Train Loss: 0.008983
Validation Loss: 0.00862724
Epoch [36/300], Train Loss: 0.007803
Validation Loss: 0.00794591
Epoch [37/300], Train Loss: 0.007750
Validation Loss: 0.00789674
Epoch [38/300], Train Loss: 0.007940
Validation Loss: 0.00789393
Epoch [39/300], Train Loss: 0.009637
Validation Loss: 0.00862440
Epoch [40/300], Train Loss: 0.008132
Validation Loss: 0.00900840
Epoch [41/300], Train Loss: 0.007729
Validation Loss: 0.00817217
Epoch [42/300], Train Loss: 0.007630
Validation Loss: 0.00770836
Epoch [43/300], Train Loss: 0.007485
Validation Loss: 0.00769553
Epoch [44/300], Train Loss: 0.007549
Validation Loss: 0.00883298
Epoch [45/300], Train Loss: 0.007707
Validation Loss: 0.00793483
Epoch [46/300], Train Loss: 0.007362
Validation Loss: 0.00762557
Epoch [47/300], Train Loss: 0.007242
Validation Loss: 0.00753821
Epoch [48/300], Train Loss: 0.007142
Validation Loss: 0.00769610
Epoch [49/300], Train Loss: 0.007252
Validation Loss: 0.00763416
Epoch [50/300], Train Loss: 0.007545
Validation Loss: 0.00747923
Epoch [51/300], Train Loss: 0.007167
Validation Loss: 0.00754350
Epoch [52/300], Train Loss: 0.007246
Validation Loss: 0.00746353
Epoch [53/300], Train Loss: 0.007164
Validation Loss: 0.00737288
Epoch [54/300], Train Loss: 0.007276
Validation Loss: 0.00751311
Epoch [55/300], Train Loss: 0.007303
Validation Loss: 0.00751183
Epoch [56/300], Train Loss: 0.007036
Validation Loss: 0.00788082
Epoch [57/300], Train Loss: 0.007127
Validation Loss: 0.00748115
Epoch [58/300], Train Loss: 0.007092
Validation Loss: 0.00783998
Epoch [59/300], Train Loss: 0.007054
Validation Loss: 0.00739930
Epoch [60/300], Train Loss: 0.007030
Validation Loss: 0.00747668
Epoch [61/300], Train Loss: 0.007602
Validation Loss: 0.00750713
Epoch [62/300], Train Loss: 0.007079
Validation Loss: 0.00742578
Epoch [63/300], Train Loss: 0.007084
Validation Loss: 0.00741388
Early stopping triggered

Evaluating model for: Tablet
Run 63/72 completed in 684.90 seconds with: {'MAE': np.float32(0.6464312), 'MSE': np.float32(1.1293086), 'RMSE': np.float32(1.0626893), 'SAE': np.float32(0.015655523), 'NDE': np.float32(0.24442135)}

Run 64/72: hidden=512, seq_len=360, stride=0.5, num_layers=5
Training and evaluating model for: Tablet
Dataset length: 4185 windows

Epoch [1/300], Train Loss: 0.059376
Validation Loss: 0.02135632
Epoch [2/300], Train Loss: 0.017572
Validation Loss: 0.01651434
Epoch [3/300], Train Loss: 0.015876
Validation Loss: 0.01621491
Epoch [4/300], Train Loss: 0.015340
Validation Loss: 0.01517501
Epoch [5/300], Train Loss: 0.013092
Validation Loss: 0.01187110
Epoch [6/300], Train Loss: 0.010926
Validation Loss: 0.01088185
Epoch [7/300], Train Loss: 0.010329
Validation Loss: 0.01059174
Epoch [8/300], Train Loss: 0.010210
Validation Loss: 0.01027714
Epoch [9/300], Train Loss: 0.010116
Validation Loss: 0.00985202
Epoch [10/300], Train Loss: 0.009968
Validation Loss: 0.01044535
Epoch [11/300], Train Loss: 0.009668
Validation Loss: 0.00953128
Epoch [12/300], Train Loss: 0.009250
Validation Loss: 0.00949310
Epoch [13/300], Train Loss: 0.009091
Validation Loss: 0.00928886
Epoch [14/300], Train Loss: 0.009018
Validation Loss: 0.00919419
Epoch [15/300], Train Loss: 0.008944
Validation Loss: 0.00908904
Epoch [16/300], Train Loss: 0.008885
Validation Loss: 0.00914866
Epoch [17/300], Train Loss: 0.008769
Validation Loss: 0.00912396
Epoch [18/300], Train Loss: 0.008788
Validation Loss: 0.00892263
Epoch [19/300], Train Loss: 0.008575
Validation Loss: 0.00885066
Epoch [20/300], Train Loss: 0.008498
Validation Loss: 0.00907817
Epoch [21/300], Train Loss: 0.008577
Validation Loss: 0.00872883
Epoch [22/300], Train Loss: 0.008550
Validation Loss: 0.00913364
Epoch [23/300], Train Loss: 0.008670
Validation Loss: 0.00871752
Epoch [24/300], Train Loss: 0.008366
Validation Loss: 0.00861836
Epoch [25/300], Train Loss: 0.008452
Validation Loss: 0.00867554
Epoch [26/300], Train Loss: 0.008393
Validation Loss: 0.00847831
Epoch [27/300], Train Loss: 0.008133
Validation Loss: 0.00862205
Epoch [28/300], Train Loss: 0.008266
Validation Loss: 0.01011976
Epoch [29/300], Train Loss: 0.010062
Validation Loss: 0.00905565
Epoch [30/300], Train Loss: 0.008416
Validation Loss: 0.00850238
Epoch [31/300], Train Loss: 0.008332
Validation Loss: 0.00853596
Epoch [32/300], Train Loss: 0.008187
Validation Loss: 0.00844245
Epoch [33/300], Train Loss: 0.008602
Validation Loss: 0.00855536
Epoch [34/300], Train Loss: 0.008243
Validation Loss: 0.00837921
Epoch [35/300], Train Loss: 0.008045
Validation Loss: 0.00841126
Epoch [36/300], Train Loss: 0.008041
Validation Loss: 0.00833387
Epoch [37/300], Train Loss: 0.008187
Validation Loss: 0.00830574
Epoch [38/300], Train Loss: 0.008257
Validation Loss: 0.00823161
Epoch [39/300], Train Loss: 0.007930
Validation Loss: 0.00855833
Epoch [40/300], Train Loss: 0.008169
Validation Loss: 0.00816752
Epoch [41/300], Train Loss: 0.008922
Validation Loss: 0.00878966
Epoch [42/300], Train Loss: 0.008316
Validation Loss: 0.00832699
Epoch [43/300], Train Loss: 0.008077
Validation Loss: 0.00839877
Epoch [44/300], Train Loss: 0.008041
Validation Loss: 0.00824050
Epoch [45/300], Train Loss: 0.008067
Validation Loss: 0.00821795
Epoch [46/300], Train Loss: 0.007837
Validation Loss: 0.00813647
Epoch [47/300], Train Loss: 0.007834
Validation Loss: 0.00811282
Epoch [48/300], Train Loss: 0.007750
Validation Loss: 0.00813631
Epoch [49/300], Train Loss: 0.007902
Validation Loss: 0.00808887
Epoch [50/300], Train Loss: 0.008091
Validation Loss: 0.00801204
Epoch [51/300], Train Loss: 0.007693
Validation Loss: 0.00800499
Epoch [52/300], Train Loss: 0.007841
Validation Loss: 0.00820469
Epoch [53/300], Train Loss: 0.007730
Validation Loss: 0.00795188
Epoch [54/300], Train Loss: 0.008447
Validation Loss: 0.03273003
Epoch [55/300], Train Loss: 0.018839
Validation Loss: 0.01590564
Epoch [56/300], Train Loss: 0.015687
Validation Loss: 0.01596323
Epoch [57/300], Train Loss: 0.015585
Validation Loss: 0.01566961
Epoch [58/300], Train Loss: 0.015532
Validation Loss: 0.01576906
Epoch [59/300], Train Loss: 0.015517
Validation Loss: 0.01563403
Epoch [60/300], Train Loss: 0.015431
Validation Loss: 0.01563769
Epoch [61/300], Train Loss: 0.015439
Validation Loss: 0.01566441
Epoch [62/300], Train Loss: 0.015318
Validation Loss: 0.01573096
Epoch [63/300], Train Loss: 0.015225
Validation Loss: 0.01564717
Early stopping triggered

Evaluating model for: Tablet
Run 64/72 completed in 871.94 seconds with: {'MAE': np.float32(1.0676302), 'MSE': np.float32(2.3666933), 'RMSE': np.float32(1.5384061), 'SAE': np.float32(0.027483746), 'NDE': np.float32(0.3538365)}

Run 65/72: hidden=512, seq_len=720, stride=0.25, num_layers=2
Training and evaluating model for: Tablet
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.082199
Validation Loss: 0.02705569
Epoch [2/300], Train Loss: 0.019319
Validation Loss: 0.01609518
Epoch [3/300], Train Loss: 0.016609
Validation Loss: 0.01461095
Epoch [4/300], Train Loss: 0.015915
Validation Loss: 0.01417960
Epoch [5/300], Train Loss: 0.015370
Validation Loss: 0.01332748
Epoch [6/300], Train Loss: 0.014445
Validation Loss: 0.01214528
Epoch [7/300], Train Loss: 0.013062
Validation Loss: 0.01123573
Epoch [8/300], Train Loss: 0.012340
Validation Loss: 0.01073402
Epoch [9/300], Train Loss: 0.011953
Validation Loss: 0.01041182
Epoch [10/300], Train Loss: 0.011609
Validation Loss: 0.01005839
Epoch [11/300], Train Loss: 0.011444
Validation Loss: 0.01002770
Epoch [12/300], Train Loss: 0.011269
Validation Loss: 0.00982304
Epoch [13/300], Train Loss: 0.011051
Validation Loss: 0.00955999
Epoch [14/300], Train Loss: 0.010868
Validation Loss: 0.00939627
Epoch [15/300], Train Loss: 0.010570
Validation Loss: 0.00889568
Epoch [16/300], Train Loss: 0.010123
Validation Loss: 0.00878655
Epoch [17/300], Train Loss: 0.009896
Validation Loss: 0.00857146
Epoch [18/300], Train Loss: 0.011279
Validation Loss: 0.01315509
Epoch [19/300], Train Loss: 0.010880
Validation Loss: 0.00883828
Epoch [20/300], Train Loss: 0.009960
Validation Loss: 0.00857338
Epoch [21/300], Train Loss: 0.012286
Validation Loss: 0.00926624
Epoch [22/300], Train Loss: 0.009966
Validation Loss: 0.00920252
Epoch [23/300], Train Loss: 0.010147
Validation Loss: 0.00862645
Epoch [24/300], Train Loss: 0.009532
Validation Loss: 0.00878920
Epoch [25/300], Train Loss: 0.009820
Validation Loss: 0.00848022
Epoch [26/300], Train Loss: 0.009878
Validation Loss: 0.00856668
Epoch [27/300], Train Loss: 0.009632
Validation Loss: 0.00834309
Epoch [28/300], Train Loss: 0.009335
Validation Loss: 0.00830112
Epoch [29/300], Train Loss: 0.009302
Validation Loss: 0.00827056
Epoch [30/300], Train Loss: 0.009344
Validation Loss: 0.00818177
Epoch [31/300], Train Loss: 0.009251
Validation Loss: 0.00823156
Epoch [32/300], Train Loss: 0.009195
Validation Loss: 0.00815672
Epoch [33/300], Train Loss: 0.009143
Validation Loss: 0.00805730
Epoch [34/300], Train Loss: 0.009252
Validation Loss: 0.00838637
Epoch [35/300], Train Loss: 0.009374
Validation Loss: 0.00824608
Epoch [36/300], Train Loss: 0.009364
Validation Loss: 0.00832460
Epoch [37/300], Train Loss: 0.009306
Validation Loss: 0.00818307
Epoch [38/300], Train Loss: 0.009108
Validation Loss: 0.00774046
Epoch [39/300], Train Loss: 0.009354
Validation Loss: 0.00786712
Epoch [40/300], Train Loss: 0.009415
Validation Loss: 0.00827858
Epoch [41/300], Train Loss: 0.013103
Validation Loss: 0.01303996
Epoch [42/300], Train Loss: 0.014043
Validation Loss: 0.01159981
Epoch [43/300], Train Loss: 0.012169
Validation Loss: 0.00942304
Epoch [44/300], Train Loss: 0.010018
Validation Loss: 0.00880685
Epoch [45/300], Train Loss: 0.010059
Validation Loss: 0.00882047
Epoch [46/300], Train Loss: 0.009653
Validation Loss: 0.00820164
Epoch [47/300], Train Loss: 0.009242
Validation Loss: 0.00804643
Epoch [48/300], Train Loss: 0.009187
Validation Loss: 0.00797529
Early stopping triggered

Evaluating model for: Tablet
Run 65/72 completed in 483.76 seconds with: {'MAE': np.float32(0.6993978), 'MSE': np.float32(1.1707141), 'RMSE': np.float32(1.0819955), 'SAE': np.float32(0.008659253), 'NDE': np.float32(0.24683565)}

Run 66/72: hidden=512, seq_len=720, stride=0.25, num_layers=3
Training and evaluating model for: Tablet
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.061631
Validation Loss: 0.01465615
Epoch [2/300], Train Loss: 0.016918
Validation Loss: 0.01417758
Epoch [3/300], Train Loss: 0.015498
Validation Loss: 0.01367583
Epoch [4/300], Train Loss: 0.014751
Validation Loss: 0.01258154
Epoch [5/300], Train Loss: 0.012717
Validation Loss: 0.01027659
Epoch [6/300], Train Loss: 0.010894
Validation Loss: 0.00952431
Epoch [7/300], Train Loss: 0.010320
Validation Loss: 0.00890186
Epoch [8/300], Train Loss: 0.009918
Validation Loss: 0.00855655
Epoch [9/300], Train Loss: 0.009648
Validation Loss: 0.00825152
Epoch [10/300], Train Loss: 0.009166
Validation Loss: 0.00748641
Epoch [11/300], Train Loss: 0.008826
Validation Loss: 0.00743265
Epoch [12/300], Train Loss: 0.009563
Validation Loss: 0.00790051
Epoch [13/300], Train Loss: 0.010609
Validation Loss: 0.00736918
Epoch [14/300], Train Loss: 0.008410
Validation Loss: 0.00712542
Epoch [15/300], Train Loss: 0.008561
Validation Loss: 0.01542380
Epoch [16/300], Train Loss: 0.011491
Validation Loss: 0.00721464
Epoch [17/300], Train Loss: 0.008386
Validation Loss: 0.00712928
Epoch [18/300], Train Loss: 0.008614
Validation Loss: 0.00909533
Epoch [19/300], Train Loss: 0.010335
Validation Loss: 0.00776747
Epoch [20/300], Train Loss: 0.008462
Validation Loss: 0.00711890
Epoch [21/300], Train Loss: 0.008199
Validation Loss: 0.00711784
Epoch [22/300], Train Loss: 0.008177
Validation Loss: 0.00710795
Epoch [23/300], Train Loss: 0.008130
Validation Loss: 0.00701094
Epoch [24/300], Train Loss: 0.008072
Validation Loss: 0.00704231
Epoch [25/300], Train Loss: 0.008081
Validation Loss: 0.00704269
Epoch [26/300], Train Loss: 0.008115
Validation Loss: 0.00695261
Epoch [27/300], Train Loss: 0.008060
Validation Loss: 0.00700963
Epoch [28/300], Train Loss: 0.011184
Validation Loss: 0.00855845
Epoch [29/300], Train Loss: 0.008697
Validation Loss: 0.00738564
Epoch [30/300], Train Loss: 0.008367
Validation Loss: 0.00711079
Epoch [31/300], Train Loss: 0.008466
Validation Loss: 0.00821636
Epoch [32/300], Train Loss: 0.008391
Validation Loss: 0.00691861
Epoch [33/300], Train Loss: 0.007977
Validation Loss: 0.00692526
Epoch [34/300], Train Loss: 0.009881
Validation Loss: 0.01044545
Epoch [35/300], Train Loss: 0.009849
Validation Loss: 0.00712424
Epoch [36/300], Train Loss: 0.008190
Validation Loss: 0.00685752
Epoch [37/300], Train Loss: 0.007972
Validation Loss: 0.00682038
Epoch [38/300], Train Loss: 0.007919
Validation Loss: 0.00686654
Epoch [39/300], Train Loss: 0.007867
Validation Loss: 0.00678665
Epoch [40/300], Train Loss: 0.007856
Validation Loss: 0.00679697
Epoch [41/300], Train Loss: 0.007844
Validation Loss: 0.00683064
Epoch [42/300], Train Loss: 0.007827
Validation Loss: 0.00673366
Epoch [43/300], Train Loss: 0.007916
Validation Loss: 0.00680324
Epoch [44/300], Train Loss: 0.007781
Validation Loss: 0.00672590
Epoch [45/300], Train Loss: 0.007781
Validation Loss: 0.00670080
Epoch [46/300], Train Loss: 0.007755
Validation Loss: 0.00662952
Epoch [47/300], Train Loss: 0.007708
Validation Loss: 0.00659594
Epoch [48/300], Train Loss: 0.007693
Validation Loss: 0.00652025
Epoch [49/300], Train Loss: 0.007663
Validation Loss: 0.00652728
Epoch [50/300], Train Loss: 0.007686
Validation Loss: 0.00652197
Epoch [51/300], Train Loss: 0.007685
Validation Loss: 0.00656116
Epoch [52/300], Train Loss: 0.007646
Validation Loss: 0.00654307
Epoch [53/300], Train Loss: 0.007609
Validation Loss: 0.00647241
Epoch [54/300], Train Loss: 0.007585
Validation Loss: 0.00654165
Epoch [55/300], Train Loss: 0.007604
Validation Loss: 0.00644145
Epoch [56/300], Train Loss: 0.007582
Validation Loss: 0.00648583
Epoch [57/300], Train Loss: 0.007577
Validation Loss: 0.00650734
Epoch [58/300], Train Loss: 0.007573
Validation Loss: 0.00648380
Epoch [59/300], Train Loss: 0.007529
Validation Loss: 0.00642097
Epoch [60/300], Train Loss: 0.007508
Validation Loss: 0.00638915
Epoch [61/300], Train Loss: 0.007473
Validation Loss: 0.00637750
Epoch [62/300], Train Loss: 0.007488
Validation Loss: 0.00636765
Epoch [63/300], Train Loss: 0.007532
Validation Loss: 0.00636172
Epoch [64/300], Train Loss: 0.007482
Validation Loss: 0.00635554
Epoch [65/300], Train Loss: 0.007471
Validation Loss: 0.00635080
Epoch [66/300], Train Loss: 0.007430
Validation Loss: 0.00638051
Epoch [67/300], Train Loss: 0.007425
Validation Loss: 0.00632974
Epoch [68/300], Train Loss: 0.007449
Validation Loss: 0.00635591
Epoch [69/300], Train Loss: 0.007447
Validation Loss: 0.00633746
Epoch [70/300], Train Loss: 0.008887
Validation Loss: 0.00719258
Epoch [71/300], Train Loss: 0.008042
Validation Loss: 0.00647234
Epoch [72/300], Train Loss: 0.007621
Validation Loss: 0.00645092
Epoch [73/300], Train Loss: 0.007554
Validation Loss: 0.00637035
Epoch [74/300], Train Loss: 0.007531
Validation Loss: 0.00639472
Epoch [75/300], Train Loss: 0.007531
Validation Loss: 0.00633936
Epoch [76/300], Train Loss: 0.007476
Validation Loss: 0.00633325
Epoch [77/300], Train Loss: 0.007490
Validation Loss: 0.00642454
Early stopping triggered

Evaluating model for: Tablet
Run 66/72 completed in 1047.37 seconds with: {'MAE': np.float32(0.5807579), 'MSE': np.float32(0.9443133), 'RMSE': np.float32(0.9717578), 'SAE': np.float32(0.004226301), 'NDE': np.float32(0.22168715)}

Run 67/72: hidden=512, seq_len=720, stride=0.25, num_layers=4
Training and evaluating model for: Tablet
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.076694
Validation Loss: 0.01616387
Epoch [2/300], Train Loss: 0.018033
Validation Loss: 0.01488378
Epoch [3/300], Train Loss: 0.016115
Validation Loss: 0.01448134
Epoch [4/300], Train Loss: 0.015925
Validation Loss: 0.01432165
Epoch [5/300], Train Loss: 0.015737
Validation Loss: 0.01388641
Epoch [6/300], Train Loss: 0.015070
Validation Loss: 0.01263122
Epoch [7/300], Train Loss: 0.012549
Validation Loss: 0.01014554
Epoch [8/300], Train Loss: 0.010747
Validation Loss: 0.00911265
Epoch [9/300], Train Loss: 0.010300
Validation Loss: 0.00886103
Epoch [10/300], Train Loss: 0.009988
Validation Loss: 0.00856820
Epoch [11/300], Train Loss: 0.009794
Validation Loss: 0.00840670
Epoch [12/300], Train Loss: 0.009520
Validation Loss: 0.00792371
Epoch [13/300], Train Loss: 0.008961
Validation Loss: 0.00748324
Epoch [14/300], Train Loss: 0.008782
Validation Loss: 0.00726887
Epoch [15/300], Train Loss: 0.008575
Validation Loss: 0.00698890
Epoch [16/300], Train Loss: 0.008521
Validation Loss: 0.00703843
Epoch [17/300], Train Loss: 0.008441
Validation Loss: 0.00698099
Epoch [18/300], Train Loss: 0.008321
Validation Loss: 0.00699379
Epoch [19/300], Train Loss: 0.008345
Validation Loss: 0.00690193
Epoch [20/300], Train Loss: 0.008253
Validation Loss: 0.00685980
Epoch [21/300], Train Loss: 0.008221
Validation Loss: 0.00683767
Epoch [22/300], Train Loss: 0.008164
Validation Loss: 0.00699160
Epoch [23/300], Train Loss: 0.008295
Validation Loss: 0.00761902
Epoch [24/300], Train Loss: 0.008139
Validation Loss: 0.00670560
Epoch [25/300], Train Loss: 0.008035
Validation Loss: 0.00672800
Epoch [26/300], Train Loss: 0.008170
Validation Loss: 0.00690949
Epoch [27/300], Train Loss: 0.008039
Validation Loss: 0.00658206
Epoch [28/300], Train Loss: 0.007965
Validation Loss: 0.00657110
Epoch [29/300], Train Loss: 0.007939
Validation Loss: 0.00651699
Epoch [30/300], Train Loss: 0.007980
Validation Loss: 0.00656894
Epoch [31/300], Train Loss: 0.007835
Validation Loss: 0.00642911
Epoch [32/300], Train Loss: 0.007775
Validation Loss: 0.00651256
Epoch [33/300], Train Loss: 0.007822
Validation Loss: 0.00637860
Epoch [34/300], Train Loss: 0.007831
Validation Loss: 0.00653463
Epoch [35/300], Train Loss: 0.007732
Validation Loss: 0.00642996
Epoch [36/300], Train Loss: 0.007614
Validation Loss: 0.00631493
Epoch [37/300], Train Loss: 0.007620
Validation Loss: 0.00646757
Epoch [38/300], Train Loss: 0.007972
Validation Loss: 0.00706852
Epoch [39/300], Train Loss: 0.007691
Validation Loss: 0.00627590
Epoch [40/300], Train Loss: 0.007495
Validation Loss: 0.00627229
Epoch [41/300], Train Loss: 0.007501
Validation Loss: 0.00664323
Epoch [42/300], Train Loss: 0.007807
Validation Loss: 0.00642981
Epoch [43/300], Train Loss: 0.007836
Validation Loss: 0.00761013
Epoch [44/300], Train Loss: 0.009132
Validation Loss: 0.00744699
Epoch [45/300], Train Loss: 0.008304
Validation Loss: 0.00659541
Epoch [46/300], Train Loss: 0.007693
Validation Loss: 0.00629290
Epoch [47/300], Train Loss: 0.007737
Validation Loss: 0.00654998
Epoch [48/300], Train Loss: 0.007582
Validation Loss: 0.00630886
Epoch [49/300], Train Loss: 0.007674
Validation Loss: 0.00634970
Epoch [50/300], Train Loss: 0.007486
Validation Loss: 0.00618067
Epoch [51/300], Train Loss: 0.007422
Validation Loss: 0.00622369
Epoch [52/300], Train Loss: 0.007380
Validation Loss: 0.00611025
Epoch [53/300], Train Loss: 0.007303
Validation Loss: 0.00612158
Epoch [54/300], Train Loss: 0.007318
Validation Loss: 0.00610860
Epoch [55/300], Train Loss: 0.007392
Validation Loss: 0.00631889
Epoch [56/300], Train Loss: 0.007379
Validation Loss: 0.00609037
Epoch [57/300], Train Loss: 0.007271
Validation Loss: 0.00628245
Epoch [58/300], Train Loss: 0.007335
Validation Loss: 0.00618232
Epoch [59/300], Train Loss: 0.007230
Validation Loss: 0.00607945
Epoch [60/300], Train Loss: 0.007299
Validation Loss: 0.00610962
Epoch [61/300], Train Loss: 0.007235
Validation Loss: 0.00602333
Epoch [62/300], Train Loss: 0.007210
Validation Loss: 0.00601460
Epoch [63/300], Train Loss: 0.007295
Validation Loss: 0.00599999
Epoch [64/300], Train Loss: 0.007177
Validation Loss: 0.00598092
Epoch [65/300], Train Loss: 0.007234
Validation Loss: 0.00598238
Epoch [66/300], Train Loss: 0.007172
Validation Loss: 0.00598238
Epoch [67/300], Train Loss: 0.007313
Validation Loss: 0.00693729
Epoch [68/300], Train Loss: 0.007742
Validation Loss: 0.00677424
Epoch [69/300], Train Loss: 0.007401
Validation Loss: 0.00606098
Epoch [70/300], Train Loss: 0.007307
Validation Loss: 0.00607435
Epoch [71/300], Train Loss: 0.007167
Validation Loss: 0.00601042
Epoch [72/300], Train Loss: 0.007206
Validation Loss: 0.00596440
Epoch [73/300], Train Loss: 0.007149
Validation Loss: 0.00597015
Epoch [74/300], Train Loss: 0.007140
Validation Loss: 0.00598762
Epoch [75/300], Train Loss: 0.007133
Validation Loss: 0.00608827
Epoch [76/300], Train Loss: 0.007209
Validation Loss: 0.00594906
Epoch [77/300], Train Loss: 0.007146
Validation Loss: 0.00603886
Epoch [78/300], Train Loss: 0.007184
Validation Loss: 0.00600456
Epoch [79/300], Train Loss: 0.007201
Validation Loss: 0.00608365
Epoch [80/300], Train Loss: 0.007202
Validation Loss: 0.00588888
Epoch [81/300], Train Loss: 0.007079
Validation Loss: 0.00591956
Epoch [82/300], Train Loss: 0.007048
Validation Loss: 0.00587686
Epoch [83/300], Train Loss: 0.007028
Validation Loss: 0.00587208
Epoch [84/300], Train Loss: 0.007073
Validation Loss: 0.00590581
Epoch [85/300], Train Loss: 0.007089
Validation Loss: 0.00590594
Epoch [86/300], Train Loss: 0.007076
Validation Loss: 0.00594934
Epoch [87/300], Train Loss: 0.007232
Validation Loss: 0.00592713
Epoch [88/300], Train Loss: 0.007096
Validation Loss: 0.00583278
Epoch [89/300], Train Loss: 0.007021
Validation Loss: 0.00581908
Epoch [90/300], Train Loss: 0.006979
Validation Loss: 0.00579760
Epoch [91/300], Train Loss: 0.007003
Validation Loss: 0.00605636
Epoch [92/300], Train Loss: 0.006998
Validation Loss: 0.00579638
Epoch [93/300], Train Loss: 0.006966
Validation Loss: 0.00578488
Epoch [94/300], Train Loss: 0.006973
Validation Loss: 0.00577911
Epoch [95/300], Train Loss: 0.006996
Validation Loss: 0.00585984
Epoch [96/300], Train Loss: 0.006953
Validation Loss: 0.00577972
Epoch [97/300], Train Loss: 0.006963
Validation Loss: 0.00594569
Epoch [98/300], Train Loss: 0.006914
Validation Loss: 0.00597885
Epoch [99/300], Train Loss: 0.006952
Validation Loss: 0.00575408
Epoch [100/300], Train Loss: 0.006926
Validation Loss: 0.00607173
Epoch [101/300], Train Loss: 0.006988
Validation Loss: 0.00578049
Epoch [102/300], Train Loss: 0.007045
Validation Loss: 0.00587667
Epoch [103/300], Train Loss: 0.006918
Validation Loss: 0.00572861
Epoch [104/300], Train Loss: 0.006916
Validation Loss: 0.00574459
Epoch [105/300], Train Loss: 0.006900
Validation Loss: 0.00574122
Epoch [106/300], Train Loss: 0.006883
Validation Loss: 0.00573440
Epoch [107/300], Train Loss: 0.006890
Validation Loss: 0.00572447
Epoch [108/300], Train Loss: 0.006891
Validation Loss: 0.00567788
Epoch [109/300], Train Loss: 0.006889
Validation Loss: 0.00570240
Epoch [110/300], Train Loss: 0.006858
Validation Loss: 0.00569316
Epoch [111/300], Train Loss: 0.006841
Validation Loss: 0.00567289
Epoch [112/300], Train Loss: 0.006821
Validation Loss: 0.00567297
Epoch [113/300], Train Loss: 0.006871
Validation Loss: 0.00576493
Epoch [114/300], Train Loss: 0.007066
Validation Loss: 0.00566282
Epoch [115/300], Train Loss: 0.006902
Validation Loss: 0.00569358
Epoch [116/300], Train Loss: 0.006856
Validation Loss: 0.00564024
Epoch [117/300], Train Loss: 0.006804
Validation Loss: 0.00566316
Epoch [118/300], Train Loss: 0.006808
Validation Loss: 0.00563045
Epoch [119/300], Train Loss: 0.006785
Validation Loss: 0.00571502
Epoch [120/300], Train Loss: 0.006806
Validation Loss: 0.00573070
Epoch [121/300], Train Loss: 0.006810
Validation Loss: 0.00566517
Epoch [122/300], Train Loss: 0.006817
Validation Loss: 0.00572936
Epoch [123/300], Train Loss: 0.006872
Validation Loss: 0.00561139
Epoch [124/300], Train Loss: 0.006808
Validation Loss: 0.00559880
Epoch [125/300], Train Loss: 0.006768
Validation Loss: 0.00558549
Epoch [126/300], Train Loss: 0.006793
Validation Loss: 0.00567430
Epoch [127/300], Train Loss: 0.006790
Validation Loss: 0.00566969
Epoch [128/300], Train Loss: 0.006810
Validation Loss: 0.00557614
Epoch [129/300], Train Loss: 0.006732
Validation Loss: 0.00554251
Epoch [130/300], Train Loss: 0.006774
Validation Loss: 0.00553177
Epoch [131/300], Train Loss: 0.006711
Validation Loss: 0.00545456
Epoch [132/300], Train Loss: 0.006641
Validation Loss: 0.00542752
Epoch [133/300], Train Loss: 0.006722
Validation Loss: 0.00538797
Epoch [134/300], Train Loss: 0.006895
Validation Loss: 0.00564144
Epoch [135/300], Train Loss: 0.006922
Validation Loss: 0.00567559
Epoch [136/300], Train Loss: 0.006841
Validation Loss: 0.00574789
Epoch [137/300], Train Loss: 0.006837
Validation Loss: 0.00566818
Epoch [138/300], Train Loss: 0.006810
Validation Loss: 0.00575278
Epoch [139/300], Train Loss: 0.006789
Validation Loss: 0.00570104
Epoch [140/300], Train Loss: 0.006787
Validation Loss: 0.00557827
Epoch [141/300], Train Loss: 0.006751
Validation Loss: 0.00557099
Epoch [142/300], Train Loss: 0.006703
Validation Loss: 0.00567585
Epoch [143/300], Train Loss: 0.006787
Validation Loss: 0.00560681
Early stopping triggered

Evaluating model for: Tablet
Run 67/72 completed in 2526.69 seconds with: {'MAE': np.float32(0.57832897), 'MSE': np.float32(0.8807428), 'RMSE': np.float32(0.93847895), 'SAE': np.float32(0.022280795), 'NDE': np.float32(0.21409535)}

Run 68/72: hidden=512, seq_len=720, stride=0.25, num_layers=5
Training and evaluating model for: Tablet
Dataset length: 4107 windows

Epoch [1/300], Train Loss: 0.048775
Validation Loss: 0.01792955
Epoch [2/300], Train Loss: 0.016566
Validation Loss: 0.01435265
Epoch [3/300], Train Loss: 0.015853
Validation Loss: 0.01421545
Epoch [4/300], Train Loss: 0.015601
Validation Loss: 0.01391195
Epoch [5/300], Train Loss: 0.014424
Validation Loss: 0.00950177
Epoch [6/300], Train Loss: 0.010638
Validation Loss: 0.00862607
Epoch [7/300], Train Loss: 0.009708
Validation Loss: 0.00853884
Epoch [8/300], Train Loss: 0.009418
Validation Loss: 0.00770569
Epoch [9/300], Train Loss: 0.009024
Validation Loss: 0.00778680
Epoch [10/300], Train Loss: 0.009321
Validation Loss: 0.00849101
Epoch [11/300], Train Loss: 0.009182
Validation Loss: 0.00770337
Epoch [12/300], Train Loss: 0.009003
Validation Loss: 0.00782664
Epoch [13/300], Train Loss: 0.011167
Validation Loss: 0.00912137
Epoch [14/300], Train Loss: 0.013285
Validation Loss: 0.01681972
Epoch [15/300], Train Loss: 0.016481
Validation Loss: 0.01336780
Epoch [16/300], Train Loss: 0.013785
Validation Loss: 0.01179695
Epoch [17/300], Train Loss: 0.011792
Validation Loss: 0.00954345
Epoch [18/300], Train Loss: 0.010261
Validation Loss: 0.00835970
Epoch [19/300], Train Loss: 0.009729
Validation Loss: 0.00912895
Epoch [20/300], Train Loss: 0.010340
Validation Loss: 0.00933693
Epoch [21/300], Train Loss: 0.009929
Validation Loss: 0.00877133
Early stopping triggered

Evaluating model for: Tablet
Run 68/72 completed in 484.41 seconds with: {'MAE': np.float32(0.72307765), 'MSE': np.float32(1.2979913), 'RMSE': np.float32(1.1392941), 'SAE': np.float32(0.008660381), 'NDE': np.float32(0.25990725)}

Run 69/72: hidden=512, seq_len=720, stride=0.5, num_layers=2
Training and evaluating model for: Tablet
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.079541
Validation Loss: 0.06311490
Epoch [2/300], Train Loss: 0.036291
Validation Loss: 0.02158422
Epoch [3/300], Train Loss: 0.017895
Validation Loss: 0.01935106
Epoch [4/300], Train Loss: 0.016064
Validation Loss: 0.01686281
Epoch [5/300], Train Loss: 0.015428
Validation Loss: 0.01683998
Epoch [6/300], Train Loss: 0.015154
Validation Loss: 0.01629556
Epoch [7/300], Train Loss: 0.014821
Validation Loss: 0.01605568
Epoch [8/300], Train Loss: 0.014420
Validation Loss: 0.01554244
Epoch [9/300], Train Loss: 0.013879
Validation Loss: 0.01493248
Epoch [10/300], Train Loss: 0.012952
Validation Loss: 0.01385312
Epoch [11/300], Train Loss: 0.011594
Validation Loss: 0.01325934
Epoch [12/300], Train Loss: 0.011142
Validation Loss: 0.01307063
Epoch [13/300], Train Loss: 0.010933
Validation Loss: 0.01280457
Epoch [14/300], Train Loss: 0.010529
Validation Loss: 0.01239944
Epoch [15/300], Train Loss: 0.010311
Validation Loss: 0.01217367
Epoch [16/300], Train Loss: 0.010144
Validation Loss: 0.01219441
Epoch [17/300], Train Loss: 0.009909
Validation Loss: 0.01177946
Epoch [18/300], Train Loss: 0.009629
Validation Loss: 0.01154141
Epoch [19/300], Train Loss: 0.009509
Validation Loss: 0.01158444
Epoch [20/300], Train Loss: 0.009424
Validation Loss: 0.01136475
Epoch [21/300], Train Loss: 0.009273
Validation Loss: 0.01133522
Epoch [22/300], Train Loss: 0.009121
Validation Loss: 0.01109311
Epoch [23/300], Train Loss: 0.008792
Validation Loss: 0.01061564
Epoch [24/300], Train Loss: 0.008729
Validation Loss: 0.01064101
Epoch [25/300], Train Loss: 0.008515
Validation Loss: 0.01042421
Epoch [26/300], Train Loss: 0.008437
Validation Loss: 0.01043885
Epoch [27/300], Train Loss: 0.008486
Validation Loss: 0.00999822
Epoch [28/300], Train Loss: 0.008427
Validation Loss: 0.00980410
Epoch [29/300], Train Loss: 0.008383
Validation Loss: 0.00998159
Epoch [30/300], Train Loss: 0.008272
Validation Loss: 0.00995283
Epoch [31/300], Train Loss: 0.008168
Validation Loss: 0.00985011
Epoch [32/300], Train Loss: 0.008113
Validation Loss: 0.00995274
Epoch [33/300], Train Loss: 0.008093
Validation Loss: 0.00993762
Epoch [34/300], Train Loss: 0.008014
Validation Loss: 0.00992874
Epoch [35/300], Train Loss: 0.008139
Validation Loss: 0.00976743
Epoch [36/300], Train Loss: 0.007978
Validation Loss: 0.00970640
Epoch [37/300], Train Loss: 0.008695
Validation Loss: 0.01028194
Epoch [38/300], Train Loss: 0.008696
Validation Loss: 0.01046198
Epoch [39/300], Train Loss: 0.008676
Validation Loss: 0.01002991
Epoch [40/300], Train Loss: 0.009147
Validation Loss: 0.01097453
Epoch [41/300], Train Loss: 0.009061
Validation Loss: 0.00993846
Epoch [42/300], Train Loss: 0.008198
Validation Loss: 0.00970431
Epoch [43/300], Train Loss: 0.007969
Validation Loss: 0.01017614
Epoch [44/300], Train Loss: 0.008493
Validation Loss: 0.00975462
Epoch [45/300], Train Loss: 0.008032
Validation Loss: 0.00992689
Epoch [46/300], Train Loss: 0.008000
Validation Loss: 0.00973136
Epoch [47/300], Train Loss: 0.007951
Validation Loss: 0.00983983
Epoch [48/300], Train Loss: 0.007851
Validation Loss: 0.00957185
Epoch [49/300], Train Loss: 0.007784
Validation Loss: 0.00962175
Epoch [50/300], Train Loss: 0.007790
Validation Loss: 0.00975316
Epoch [51/300], Train Loss: 0.007797
Validation Loss: 0.00942304
Epoch [52/300], Train Loss: 0.007749
Validation Loss: 0.00968881
Epoch [53/300], Train Loss: 0.007732
Validation Loss: 0.00985299
Epoch [54/300], Train Loss: 0.008575
Validation Loss: 0.01069305
Epoch [55/300], Train Loss: 0.008297
Validation Loss: 0.00987018
Epoch [56/300], Train Loss: 0.007991
Validation Loss: 0.00977602
Epoch [57/300], Train Loss: 0.007807
Validation Loss: 0.00958974
Epoch [58/300], Train Loss: 0.007960
Validation Loss: 0.00943361
Epoch [59/300], Train Loss: 0.011966
Validation Loss: 0.01330070
Epoch [60/300], Train Loss: 0.010975
Validation Loss: 0.01103910
Epoch [61/300], Train Loss: 0.008689
Validation Loss: 0.01011962
Early stopping triggered

Evaluating model for: Tablet
Run 69/72 completed in 311.73 seconds with: {'MAE': np.float32(0.7854711), 'MSE': np.float32(1.5276561), 'RMSE': np.float32(1.2359838), 'SAE': np.float32(0.055391178), 'NDE': np.float32(0.2844163)}

Run 70/72: hidden=512, seq_len=720, stride=0.5, num_layers=3
Training and evaluating model for: Tablet
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.080004
Validation Loss: 0.05527739
Epoch [2/300], Train Loss: 0.028815
Validation Loss: 0.01696771
Epoch [3/300], Train Loss: 0.017337
Validation Loss: 0.01725762
Epoch [4/300], Train Loss: 0.015724
Validation Loss: 0.01670269
Epoch [5/300], Train Loss: 0.015237
Validation Loss: 0.01637045
Epoch [6/300], Train Loss: 0.014945
Validation Loss: 0.01621050
Epoch [7/300], Train Loss: 0.014575
Validation Loss: 0.01581179
Epoch [8/300], Train Loss: 0.014049
Validation Loss: 0.01516303
Epoch [9/300], Train Loss: 0.013177
Validation Loss: 0.01412064
Epoch [10/300], Train Loss: 0.011778
Validation Loss: 0.01329765
Epoch [11/300], Train Loss: 0.010937
Validation Loss: 0.01268046
Epoch [12/300], Train Loss: 0.010497
Validation Loss: 0.01224888
Epoch [13/300], Train Loss: 0.010100
Validation Loss: 0.01231616
Epoch [14/300], Train Loss: 0.009822
Validation Loss: 0.01165093
Epoch [15/300], Train Loss: 0.009502
Validation Loss: 0.01098372
Epoch [16/300], Train Loss: 0.009238
Validation Loss: 0.01096495
Epoch [17/300], Train Loss: 0.009108
Validation Loss: 0.01105487
Epoch [18/300], Train Loss: 0.009118
Validation Loss: 0.01070063
Epoch [19/300], Train Loss: 0.010775
Validation Loss: 0.01191067
Epoch [20/300], Train Loss: 0.009575
Validation Loss: 0.01145673
Epoch [21/300], Train Loss: 0.009725
Validation Loss: 0.01129699
Epoch [22/300], Train Loss: 0.009509
Validation Loss: 0.01095465
Epoch [23/300], Train Loss: 0.009131
Validation Loss: 0.01120202
Epoch [24/300], Train Loss: 0.009590
Validation Loss: 0.01101403
Epoch [25/300], Train Loss: 0.009180
Validation Loss: 0.01076567
Epoch [26/300], Train Loss: 0.009009
Validation Loss: 0.01048017
Epoch [27/300], Train Loss: 0.008914
Validation Loss: 0.01083554
Epoch [28/300], Train Loss: 0.008936
Validation Loss: 0.01095247
Epoch [29/300], Train Loss: 0.008869
Validation Loss: 0.01045266
Epoch [30/300], Train Loss: 0.012164
Validation Loss: 0.01633859
Epoch [31/300], Train Loss: 0.015137
Validation Loss: 0.01601456
Epoch [32/300], Train Loss: 0.014373
Validation Loss: 0.01526992
Epoch [33/300], Train Loss: 0.013756
Validation Loss: 0.01501607
Epoch [34/300], Train Loss: 0.013202
Validation Loss: 0.01444031
Epoch [35/300], Train Loss: 0.012221
Validation Loss: 0.01334135
Epoch [36/300], Train Loss: 0.010717
Validation Loss: 0.01139478
Epoch [37/300], Train Loss: 0.009042
Validation Loss: 0.01084932
Epoch [38/300], Train Loss: 0.009345
Validation Loss: 0.01174757
Epoch [39/300], Train Loss: 0.009503
Validation Loss: 0.01111910
Early stopping triggered

Evaluating model for: Tablet
Run 70/72 completed in 268.30 seconds with: {'MAE': np.float32(0.89357066), 'MSE': np.float32(1.7080871), 'RMSE': np.float32(1.306938), 'SAE': np.float32(0.013531941), 'NDE': np.float32(0.30074376)}

Run 71/72: hidden=512, seq_len=720, stride=0.5, num_layers=4
Training and evaluating model for: Tablet
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.075014
Validation Loss: 0.04794320
Epoch [2/300], Train Loss: 0.024389
Validation Loss: 0.01891272
Epoch [3/300], Train Loss: 0.017333
Validation Loss: 0.01667681
Epoch [4/300], Train Loss: 0.015666
Validation Loss: 0.01708203
Epoch [5/300], Train Loss: 0.015278
Validation Loss: 0.01627033
Epoch [6/300], Train Loss: 0.014904
Validation Loss: 0.01600480
Epoch [7/300], Train Loss: 0.014441
Validation Loss: 0.01553601
Epoch [8/300], Train Loss: 0.013434
Validation Loss: 0.01381118
Epoch [9/300], Train Loss: 0.011340
Validation Loss: 0.01275824
Epoch [10/300], Train Loss: 0.010165
Validation Loss: 0.01167601
Epoch [11/300], Train Loss: 0.009549
Validation Loss: 0.01146328
Epoch [12/300], Train Loss: 0.009377
Validation Loss: 0.01132818
Epoch [13/300], Train Loss: 0.009263
Validation Loss: 0.01131957
Epoch [14/300], Train Loss: 0.009046
Validation Loss: 0.01071944
Epoch [15/300], Train Loss: 0.008754
Validation Loss: 0.01039539
Epoch [16/300], Train Loss: 0.008417
Validation Loss: 0.01029061
Epoch [17/300], Train Loss: 0.008547
Validation Loss: 0.01009261
Epoch [18/300], Train Loss: 0.008224
Validation Loss: 0.01058899
Epoch [19/300], Train Loss: 0.008824
Validation Loss: 0.01008316
Epoch [20/300], Train Loss: 0.008229
Validation Loss: 0.00963751
Epoch [21/300], Train Loss: 0.008261
Validation Loss: 0.01022110
Epoch [22/300], Train Loss: 0.008478
Validation Loss: 0.01254420
Epoch [23/300], Train Loss: 0.010944
Validation Loss: 0.01090845
Epoch [24/300], Train Loss: 0.008922
Validation Loss: 0.01114412
Epoch [25/300], Train Loss: 0.008776
Validation Loss: 0.01099918
Epoch [26/300], Train Loss: 0.008685
Validation Loss: 0.01067862
Epoch [27/300], Train Loss: 0.008952
Validation Loss: 0.01068310
Epoch [28/300], Train Loss: 0.009237
Validation Loss: 0.01043208
Epoch [29/300], Train Loss: 0.008510
Validation Loss: 0.01042645
Epoch [30/300], Train Loss: 0.009486
Validation Loss: 0.01516620
Early stopping triggered

Evaluating model for: Tablet
Run 71/72 completed in 268.68 seconds with: {'MAE': np.float32(1.0652705), 'MSE': np.float32(2.213122), 'RMSE': np.float32(1.4876565), 'SAE': np.float32(0.0023747836), 'NDE': np.float32(0.34232956)}

Run 72/72: hidden=512, seq_len=720, stride=0.5, num_layers=5
Training and evaluating model for: Tablet
Dataset length: 2073 windows

Epoch [1/300], Train Loss: 0.109117
Validation Loss: 0.07518902
Epoch [2/300], Train Loss: 0.033338
Validation Loss: 0.02266319
Epoch [3/300], Train Loss: 0.019083
Validation Loss: 0.01799668
Epoch [4/300], Train Loss: 0.016230
Validation Loss: 0.01734125
Epoch [5/300], Train Loss: 0.015676
Validation Loss: 0.01691108
Epoch [6/300], Train Loss: 0.015394
Validation Loss: 0.01644788
Epoch [7/300], Train Loss: 0.015011
Validation Loss: 0.01613784
Epoch [8/300], Train Loss: 0.014272
Validation Loss: 0.01496740
Epoch [9/300], Train Loss: 0.012147
Validation Loss: 0.01292252
Epoch [10/300], Train Loss: 0.010471
Validation Loss: 0.01217142
Epoch [11/300], Train Loss: 0.009996
Validation Loss: 0.01203628
Epoch [12/300], Train Loss: 0.009871
Validation Loss: 0.01175270
Epoch [13/300], Train Loss: 0.009712
Validation Loss: 0.01183797
Epoch [14/300], Train Loss: 0.009645
Validation Loss: 0.01155357
Epoch [15/300], Train Loss: 0.009536
Validation Loss: 0.01145885
Epoch [16/300], Train Loss: 0.009476
Validation Loss: 0.01142859
Epoch [17/300], Train Loss: 0.009336
Validation Loss: 0.01124223
Epoch [18/300], Train Loss: 0.009132
Validation Loss: 0.01106194
Epoch [19/300], Train Loss: 0.008874
Validation Loss: 0.01087481
Epoch [20/300], Train Loss: 0.008611
Validation Loss: 0.01034271
Epoch [21/300], Train Loss: 0.008696
Validation Loss: 0.01037701
Epoch [22/300], Train Loss: 0.008535
Validation Loss: 0.01033717
Epoch [23/300], Train Loss: 0.008631
Validation Loss: 0.01062306
Epoch [24/300], Train Loss: 0.008586
Validation Loss: 0.01068353
Epoch [25/300], Train Loss: 0.008444
Validation Loss: 0.01041961
Epoch [26/300], Train Loss: 0.008474
Validation Loss: 0.01015484
Epoch [27/300], Train Loss: 0.008358
Validation Loss: 0.01019002
Epoch [28/300], Train Loss: 0.008350
Validation Loss: 0.01013165
Epoch [29/300], Train Loss: 0.008504
Validation Loss: 0.01019608
Epoch [30/300], Train Loss: 0.008369
Validation Loss: 0.01072877
Epoch [31/300], Train Loss: 0.008340
Validation Loss: 0.01010218
Epoch [32/300], Train Loss: 0.008267
Validation Loss: 0.01018934
Epoch [33/300], Train Loss: 0.008244
Validation Loss: 0.01007459
Epoch [34/300], Train Loss: 0.008140
Validation Loss: 0.01016115
Epoch [35/300], Train Loss: 0.008194
Validation Loss: 0.01014428
Epoch [36/300], Train Loss: 0.008159
Validation Loss: 0.01001659
Epoch [37/300], Train Loss: 0.008124
Validation Loss: 0.01005082
Epoch [38/300], Train Loss: 0.008097
Validation Loss: 0.01027471
Epoch [39/300], Train Loss: 0.008331
Validation Loss: 0.01008863
Epoch [40/300], Train Loss: 0.008216
Validation Loss: 0.01009976
Epoch [41/300], Train Loss: 0.008633
Validation Loss: 0.01159184
Epoch [42/300], Train Loss: 0.008547
Validation Loss: 0.01015068
Epoch [43/300], Train Loss: 0.008295
Validation Loss: 0.01007924
Epoch [44/300], Train Loss: 0.008085
Validation Loss: 0.00997461
Epoch [45/300], Train Loss: 0.008050
Validation Loss: 0.01005493
Epoch [46/300], Train Loss: 0.008797
Validation Loss: 0.01016177
Epoch [47/300], Train Loss: 0.008204
Validation Loss: 0.01015067
Epoch [48/300], Train Loss: 0.008102
Validation Loss: 0.00998121
Epoch [49/300], Train Loss: 0.007992
Validation Loss: 0.00994948
Epoch [50/300], Train Loss: 0.007943
Validation Loss: 0.00988078
Epoch [51/300], Train Loss: 0.007938
Validation Loss: 0.00991482
Epoch [52/300], Train Loss: 0.007913
Validation Loss: 0.00990443
Epoch [53/300], Train Loss: 0.007909
Validation Loss: 0.00997697
Epoch [54/300], Train Loss: 0.007944
Validation Loss: 0.00983976
Epoch [55/300], Train Loss: 0.007874
Validation Loss: 0.00983891
Epoch [56/300], Train Loss: 0.007882
Validation Loss: 0.00992994
Epoch [57/300], Train Loss: 0.007957
Validation Loss: 0.00980786
Epoch [58/300], Train Loss: 0.007965
Validation Loss: 0.00984657
Epoch [59/300], Train Loss: 0.007989
Validation Loss: 0.01003747
Epoch [60/300], Train Loss: 0.007935
Validation Loss: 0.00982943
Epoch [61/300], Train Loss: 0.007908
Validation Loss: 0.00989805
Epoch [62/300], Train Loss: 0.007958
Validation Loss: 0.00985975
Epoch [63/300], Train Loss: 0.007897
Validation Loss: 0.00980619
Epoch [64/300], Train Loss: 0.007855
Validation Loss: 0.00985107
Epoch [65/300], Train Loss: 0.007815
Validation Loss: 0.00979335
Epoch [66/300], Train Loss: 0.007797
Validation Loss: 0.00979331
Epoch [67/300], Train Loss: 0.007861
Validation Loss: 0.00982988
Epoch [68/300], Train Loss: 0.007787
Validation Loss: 0.00987250
Epoch [69/300], Train Loss: 0.007739
Validation Loss: 0.00970050
Epoch [70/300], Train Loss: 0.007745
Validation Loss: 0.00970494
Epoch [71/300], Train Loss: 0.007761
Validation Loss: 0.00968582
Epoch [72/300], Train Loss: 0.007751
Validation Loss: 0.00978738
Epoch [73/300], Train Loss: 0.007721
Validation Loss: 0.00967583
Epoch [74/300], Train Loss: 0.007732
Validation Loss: 0.00974141
Epoch [75/300], Train Loss: 0.007745
Validation Loss: 0.00970304
Epoch [76/300], Train Loss: 0.007683
Validation Loss: 0.00965127
Epoch [77/300], Train Loss: 0.007682
Validation Loss: 0.00964444
Epoch [78/300], Train Loss: 0.007739
Validation Loss: 0.00969193
Epoch [79/300], Train Loss: 0.007660
Validation Loss: 0.00969395
Epoch [80/300], Train Loss: 0.007666
Validation Loss: 0.00961583
Epoch [81/300], Train Loss: 0.007664
Validation Loss: 0.00969896
Epoch [82/300], Train Loss: 0.007740
Validation Loss: 0.00964114
Epoch [83/300], Train Loss: 0.007665
Validation Loss: 0.00961492
Epoch [84/300], Train Loss: 0.007615
Validation Loss: 0.00961384
Epoch [85/300], Train Loss: 0.007646
Validation Loss: 0.00963597
Epoch [86/300], Train Loss: 0.007646
Validation Loss: 0.00954478
Epoch [87/300], Train Loss: 0.007742
Validation Loss: 0.00953221
Epoch [88/300], Train Loss: 0.007653
Validation Loss: 0.00961547
Epoch [89/300], Train Loss: 0.007614
Validation Loss: 0.00959376
Epoch [90/300], Train Loss: 0.007604
Validation Loss: 0.00954175
Epoch [91/300], Train Loss: 0.007564
Validation Loss: 0.00971905
Epoch [92/300], Train Loss: 0.007580
Validation Loss: 0.00953543
Epoch [93/300], Train Loss: 0.007633
Validation Loss: 0.00958849
Epoch [94/300], Train Loss: 0.007587
Validation Loss: 0.00965824
Epoch [95/300], Train Loss: 0.007661
Validation Loss: 0.00953707
Epoch [96/300], Train Loss: 0.007554
Validation Loss: 0.00947949
Epoch [97/300], Train Loss: 0.007521
Validation Loss: 0.00944771
Epoch [98/300], Train Loss: 0.007522
Validation Loss: 0.00949020
Epoch [99/300], Train Loss: 0.007496
Validation Loss: 0.00945532
Epoch [100/300], Train Loss: 0.007468
Validation Loss: 0.00942606
Epoch [101/300], Train Loss: 0.007476
Validation Loss: 0.00956961
Epoch [102/300], Train Loss: 0.007487
Validation Loss: 0.00940707
Epoch [103/300], Train Loss: 0.007451
Validation Loss: 0.00939573
Epoch [104/300], Train Loss: 0.007433
Validation Loss: 0.00938347
Epoch [105/300], Train Loss: 0.007406
Validation Loss: 0.00936983
Epoch [106/300], Train Loss: 0.007410
Validation Loss: 0.00934469
Epoch [107/300], Train Loss: 0.007402
Validation Loss: 0.00938358
Epoch [108/300], Train Loss: 0.007408
Validation Loss: 0.00938922
Epoch [109/300], Train Loss: 0.007444
Validation Loss: 0.00933570
Epoch [110/300], Train Loss: 0.007370
Validation Loss: 0.00930529
Epoch [111/300], Train Loss: 0.007373
Validation Loss: 0.00934112
Epoch [112/300], Train Loss: 0.007373
Validation Loss: 0.00926001
Epoch [113/300], Train Loss: 0.007350
Validation Loss: 0.00930689
Epoch [114/300], Train Loss: 0.007385
Validation Loss: 0.00959843
Epoch [115/300], Train Loss: 0.007503
Validation Loss: 0.00932440
Epoch [116/300], Train Loss: 0.007341
Validation Loss: 0.00926147
Epoch [117/300], Train Loss: 0.007374
Validation Loss: 0.00951180
Epoch [118/300], Train Loss: 0.007353
Validation Loss: 0.00923285
Epoch [119/300], Train Loss: 0.007361
Validation Loss: 0.00920604
Epoch [120/300], Train Loss: 0.007496
Validation Loss: 0.00925805
Epoch [121/300], Train Loss: 0.007342
Validation Loss: 0.00915949
Epoch [122/300], Train Loss: 0.007342
Validation Loss: 0.00929995
Epoch [123/300], Train Loss: 0.007441
Validation Loss: 0.00945105
Epoch [124/300], Train Loss: 0.007335
Validation Loss: 0.00928728
Epoch [125/300], Train Loss: 0.007323
Validation Loss: 0.00908713
Epoch [126/300], Train Loss: 0.007299
Validation Loss: 0.00926405
Epoch [127/300], Train Loss: 0.007304
Validation Loss: 0.00903789
Epoch [128/300], Train Loss: 0.007186
Validation Loss: 0.00945486
Epoch [129/300], Train Loss: 0.007714
Validation Loss: 0.00941338
Epoch [130/300], Train Loss: 0.007293
Validation Loss: 0.00927053
Epoch [131/300], Train Loss: 0.007267
Validation Loss: 0.00910896
Epoch [132/300], Train Loss: 0.007160
Validation Loss: 0.00893727
Epoch [133/300], Train Loss: 0.007107
Validation Loss: 0.00896458
Epoch [134/300], Train Loss: 0.007141
Validation Loss: 0.00919031
Epoch [135/300], Train Loss: 0.007138
Validation Loss: 0.00889219
Epoch [136/300], Train Loss: 0.007025
Validation Loss: 0.00885052
Epoch [137/300], Train Loss: 0.006986
Validation Loss: 0.00884396
Epoch [138/300], Train Loss: 0.006966
Validation Loss: 0.00879900
Epoch [139/300], Train Loss: 0.006943
Validation Loss: 0.00878018
Epoch [140/300], Train Loss: 0.006958
Validation Loss: 0.00885722
Epoch [141/300], Train Loss: 0.006898
Validation Loss: 0.00871817
Epoch [142/300], Train Loss: 0.006870
Validation Loss: 0.00881933
Epoch [143/300], Train Loss: 0.006866
Validation Loss: 0.00885269
Epoch [144/300], Train Loss: 0.006869
Validation Loss: 0.00866984
Epoch [145/300], Train Loss: 0.006862
Validation Loss: 0.00864005
Epoch [146/300], Train Loss: 0.006867
Validation Loss: 0.00859904
Epoch [147/300], Train Loss: 0.006809
Validation Loss: 0.00860137
Epoch [148/300], Train Loss: 0.006750
Validation Loss: 0.00856637
Epoch [149/300], Train Loss: 0.006723
Validation Loss: 0.00860113
Epoch [150/300], Train Loss: 0.006882
Validation Loss: 0.00867754
Epoch [151/300], Train Loss: 0.006754
Validation Loss: 0.00851600
Epoch [152/300], Train Loss: 0.006685
Validation Loss: 0.00864399
Epoch [153/300], Train Loss: 0.006722
Validation Loss: 0.00865848
Epoch [154/300], Train Loss: 0.006709
Validation Loss: 0.00856550
Epoch [155/300], Train Loss: 0.006662
Validation Loss: 0.00847825
Epoch [156/300], Train Loss: 0.006640
Validation Loss: 0.00860495
Epoch [157/300], Train Loss: 0.006744
Validation Loss: 0.00874858
Epoch [158/300], Train Loss: 0.006720
Validation Loss: 0.00845787
Epoch [159/300], Train Loss: 0.006643
Validation Loss: 0.00840485
Epoch [160/300], Train Loss: 0.006604
Validation Loss: 0.00848394
Epoch [161/300], Train Loss: 0.006613
Validation Loss: 0.00838946
Epoch [162/300], Train Loss: 0.006633
Validation Loss: 0.00840183
Epoch [163/300], Train Loss: 0.006615
Validation Loss: 0.00840247
Epoch [164/300], Train Loss: 0.006654
Validation Loss: 0.00856367
Epoch [165/300], Train Loss: 0.006893
Validation Loss: 0.00873185
Epoch [166/300], Train Loss: 0.007184
Validation Loss: 0.00942225
Epoch [167/300], Train Loss: 0.007101
Validation Loss: 0.00873910
Epoch [168/300], Train Loss: 0.006764
Validation Loss: 0.00853581
Epoch [169/300], Train Loss: 0.006709
Validation Loss: 0.00834437
Epoch [170/300], Train Loss: 0.006859
Validation Loss: 0.00849157
Epoch [171/300], Train Loss: 0.006902
Validation Loss: 0.00873587
Epoch [172/300], Train Loss: 0.006864
Validation Loss: 0.00870997
Epoch [173/300], Train Loss: 0.006717
Validation Loss: 0.00844093
Epoch [174/300], Train Loss: 0.006692
Validation Loss: 0.00846822
Epoch [175/300], Train Loss: 0.006632
Validation Loss: 0.00846764
Epoch [176/300], Train Loss: 0.006580
Validation Loss: 0.00831293
Epoch [177/300], Train Loss: 0.006555
Validation Loss: 0.00831524
Epoch [178/300], Train Loss: 0.006517
Validation Loss: 0.00823862
Epoch [179/300], Train Loss: 0.006529
Validation Loss: 0.00830207
Epoch [180/300], Train Loss: 0.006531
Validation Loss: 0.00823581
Epoch [181/300], Train Loss: 0.006513
Validation Loss: 0.00828688
Epoch [182/300], Train Loss: 0.006485
Validation Loss: 0.00827747
Epoch [183/300], Train Loss: 0.006541
Validation Loss: 0.00833631
Epoch [184/300], Train Loss: 0.006504
Validation Loss: 0.00826507
Epoch [185/300], Train Loss: 0.006500
Validation Loss: 0.00818905
Epoch [186/300], Train Loss: 0.006519
Validation Loss: 0.00826774
Epoch [187/300], Train Loss: 0.006512
Validation Loss: 0.00827286
Epoch [188/300], Train Loss: 0.006523
Validation Loss: 0.00820621
Epoch [189/300], Train Loss: 0.006576
Validation Loss: 0.00854783
Epoch [190/300], Train Loss: 0.006576
Validation Loss: 0.00816696
Epoch [191/300], Train Loss: 0.006509
Validation Loss: 0.00820689
Epoch [192/300], Train Loss: 0.006507
Validation Loss: 0.00821219
Epoch [193/300], Train Loss: 0.006519
Validation Loss: 0.00820893
Epoch [194/300], Train Loss: 0.006479
Validation Loss: 0.00817227
Epoch [195/300], Train Loss: 0.006472
Validation Loss: 0.00817101
Epoch [196/300], Train Loss: 0.006545
Validation Loss: 0.00824868
Epoch [197/300], Train Loss: 0.006601
Validation Loss: 0.00865536
Epoch [198/300], Train Loss: 0.006608
Validation Loss: 0.00819680
Epoch [199/300], Train Loss: 0.006487
Validation Loss: 0.00821221
Epoch [200/300], Train Loss: 0.006460
Validation Loss: 0.00820168
Early stopping triggered

Evaluating model for: Tablet
Run 72/72 completed in 2316.61 seconds with: {'MAE': np.float32(0.69564885), 'MSE': np.float32(1.2201636), 'RMSE': np.float32(1.1046102), 'SAE': np.float32(0.0013853161), 'NDE': np.float32(0.25418547)}
    hidden_size  seq_length  stride  num_layers  eval_result
26          256         120    0.25           4     0.374736
27          256         120    0.25           5     0.375593
48          512         120    0.25           2     0.376866
24          256         120    0.25           2     0.381169
53          512         120    0.50           3     0.387399
..          ...         ...     ...         ...          ...
69          512         720    0.50           3     0.893571
61          512         360    0.50           3     0.932835
70          512         720    0.50           4     1.065271
63          512         360    0.50           5     1.067630
17          128         720    0.25           3     1.114372

[72 rows x 5 columns]
